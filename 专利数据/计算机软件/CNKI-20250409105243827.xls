<html xmlns:o='urn:schemas-microsoft-com:office:office' xmlns:x='urn:schemas-microsoft-com:office:excel' xmlns='http://www.w3.org/TR/REC-html40'><head><style>table td,th{vnd.ms-excel.numberformat:@;text-align: center;} table th{color:red}</style><title></title><meta http-equiv='Content-Type' content="text/html; charset=utf-8"></head><body><table cellspacing='0' border='1'>     <tr>   <td style='vnd.ms-excel.numberformat:@'>SrcDatabase-来源库</td>   <td style='vnd.ms-excel.numberformat:@'>Author-作者</td>   <td style='vnd.ms-excel.numberformat:@'>Applicant-申请人</td>   <td style='vnd.ms-excel.numberformat:@'>Title-题名</td>   <td style='vnd.ms-excel.numberformat:@'>CountryName-国省名称</td>   <td style='vnd.ms-excel.numberformat:@'>PubNo-公开号</td>   <td style='vnd.ms-excel.numberformat:@'>PubTime-公开日期</td>   <td style='vnd.ms-excel.numberformat:@'>Summary-摘要</td>   <td style='vnd.ms-excel.numberformat:@'>Claims-主权项</td>   <td style='vnd.ms-excel.numberformat:@'>CLC-中图分类号</td>  </tr>  <tr>   <td>中国专利</td>   <td>         刘洁;              施楚民;              冯俊杰;              黄璐;              陈炼翰;              李凯欣;                   余思远       </td>   <td>中山大学</td>   <td>一种环芯光纤优化设计的方法</td>   <td>广东省</td>   <td>CN110543746B</td>   <td>2023-04-07</td>   <td>本发涉及一种环芯光纤优化设计的方法,所述方法通过BP神经网络建立光纤设计参数与模式间耦合积分系数的非线性关系,同时在符合拉制工艺的结构限制条件下,利用遗传算法快速找到模间耦合系数最小的最优结构,从而实现低损耗、低模式组间耦合的环芯光纤的快速设计。所述方法创新性利用了环芯光纤的耦合积分系数作为优化目标进行神经网络的训练,打破了现有多模光纤模间实现低耦合理论上主要依靠增加模间有效折射率差的常规。同时将神经网络的输出值作为遗传算法的适应度函数值,相对于传统的电磁场仿真计算得到适应度函数值,具有更为快速的环芯光纤设计优化流程。</td>   <td>1.一种环芯光纤优化设计的方法,其特征在于,所述方法包括以下步骤：S1：根据光纤设计通用模型构建神经网络的训练样本,并对训练样本进行预处理；包括以下步骤：S101、确定光纤设计通用模型：光纤包层外直径为标准125μm,最大的芯层-包层相对折射率差为0.008,芯层设计有四层结构；芯层内径和外径是确定的,以保证固定的模式组数量和径向一阶传导模式；环形纤芯内包层与外包层折射率一致,其余芯层的折射率呈阶跃式分布；S102、确定输入、输出变量：选取每一层芯层半径与芯层-包层相对折射率差作为输入变量,选取目标相邻高阶间的模式组间耦合积分系数C-(lm)作为输出变量；S103、准备训练样本：确定好各输入变量的范围以及取值间隔后,通过电磁场计算方法得出各输入变量下的耦合积分系数C-(lm)的大小,构造神经网络的训练样本并保存；S104、样本预处理：对样本输入输出变量作预处理,使样本输入输出变量处于[0,1]之间；S2：根据S1预处理后的训练样本,构建并训练BP神经网络模型；S3：利用遗传算法寻找限定条件下的最优值：以各输入设计参量为个体产生种群,基于训练完成的BP神经网络,构建种群适应度函数,在限定条件下,寻找适应度值最高的个体来寻找各设计参量的最优值；S4、二次验证结果：根据遗传算法的优化结果获取若干组效果最优的参数组合,通过常规电磁场计算方法对参数进行二次验证,判断优化结果是否正确,若正确,则将结果返回给设计者,若不正确,则返回S2。</td>   <td>G06F30/23;G06F30/27;G06N3/084;G06N3/086</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   吕文静       </td>   <td>中山大学</td>   <td>一种无参考对比度失真图像质量评价方法</td>   <td>广东省</td>   <td>CN110570420B</td>   <td>2023-04-07</td>   <td>本发明提供的一种无参考对比度失真图像质量评价方法,包括：对对比度失真图像提取多种颜色空间内的颜色矩和信息熵特征,构建描述图像失真的特征集；根据图像失真的特征集与先验分数结合构建训练集,构建图像质量评价的预测模型；提取待评价图像的对比度失真特征集,利用图像质量评价预测模型进行计算,预测待评价图像的图像质量。本发明提供的一种无参考对比度失真图像质量评价方法,既融合多颜色空间又使用颜色矩和信息熵特征联合,很好的保证检测的准确性和有效性,填补了无参考对比度失真图像质量评价领域的空缺。</td>   <td>1.一种无参考对比度失真图像质量评价方法,其特征在于,包括以下步骤：S1：对对比度失真图像提取多种颜色空间内的颜色矩和信息熵特征,构建描述图像失真的特征集；包括以下步骤：S11：将图像从RGB颜色空间转换到XYZ颜色空间,再将图像从XYZ颜色空间转换到CIELab颜色空间；其中,RGB颜色空间的三个通道分别记为：R,G,B；CIELab颜色空间的三个通道分别记为：L,a,b；所述的将图像从RGB颜色空间转换到XYZ颜色空间,具体转换公式为：                  所述的将图像从XYZ颜色空间转换到CIELab颜色空间,具体转换公式为：                  因此,根据每张图片得到6个颜色通道分量,即：R,G,B和L,a,b；S12：对步骤S11得到的6个颜色通道提取一到三阶中心颜色矩特征,记为其中,用i＝{1,2,3}表示颜色矩的阶,用j＝{R,G,B,L,a,b}表示不同颜色空间的颜色通道；具体的：用I表示一张图像,颜色矩是多阶的,此处设置为3,利用中心矩进行计算,具体计算公式为：firstMoment(I)＝E(I)                                    其中,E是一个求平均的运算符；将步骤S11得到的6个颜色通道进行颜色矩特征提取,记为其中,用i＝{1,2,3}表示颜色矩的阶,用j＝{R,G,b,L,a,b}表示不同颜色空间的颜色通道；S13：对步骤s11得到的6个颜色通道提取信息熵特征,记为H-j,用j＝{R,G,b,L,a,b}表示不同颜色空间的颜色通道；所述信息熵用来描述图片的信息复杂度,其计算公式为：                  其中,P-i(I)表示图像中某像素强度为i出现的概率；对S11中得到的6个颜色通道分别提取信息熵特征,记作H-j,j＝{R,G,B,L,a,b}表示不同颜色空间的颜色通道；由此,将颜色矩特征与信息熵特征结合,得到描述图像对比度失真的特征向量f：          /&gt;S2：根据图像失真的特征集与先验分数结合构建训练集,构建图像质量评价的预测模型；S3：提取待评价图像的对比度失真特征集,利用图像质量评价预测模型进行计算,预测待评价图像的图像质量。</td>   <td>G06T7/00;G06T7/90;G06V10/766;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              郭叙森;                   康德开       </td>   <td>中山大学</td>   <td>一种融合图像分割与分类的细胞图像语义分割方法</td>   <td>广东省</td>   <td>CN110675368B</td>   <td>2023-04-07</td>   <td>本发明涉及一种融合图像分割与分类的细胞图像语义分割方法,将细胞图像数据预处理后分别经过双线性细粒度分类神经网络和通过OSTU算法及填充算法进行处理,分别得到细胞分类模型和细胞分割图,将细胞分类模型对细胞分割图的前景连通区域进行预测,将预测结果赋给该连通区域从而得到逐区域的分类结果,结合分割得到的背景区域,最终得到细胞测试图像的语义分割结果。本发明融合了传统阈值方法以及深度学习方法实现对细胞图像的精确语义分割,与传统细胞图像分割方法相比,本发明还能够得到细胞的语义信息,并且是逐像素的语义类别,能够运用于细胞污染的鉴定以及隔离。</td>   <td>1.一种融合图像分割与分类的细胞图像语义分割方法,其特征在于,包括如下步骤：步骤一：构建细胞图像数据集,将细胞的相差显微镜数据按照细胞的类别分成七大类；步骤二：对图像数据进行预处理；图像数据预处理包括背景光照均一化以及灰度值均一化；背景光照均一化的操作步骤为：S1：统计细胞图像数据库中单个细胞在图像中的平均大小；S2：将细胞图像转为灰度图,并使用尺寸大于细胞大小的高斯卷积核与细胞图像进行卷积,得到细胞图像的背景光照亮度图像；S3：将细胞灰度图像减去背景光照强度,并逐像素加上背景光照均值,得到背景光照均一化之后的细胞图像,并将处理后灰度值小于0的像素的灰度值置为零,大于255的置为255步骤三：构建双线性细粒度分类神经网络,将步骤二中预处理后的图像输入双线性细粒度分类神经网络,双线性细粒度分类神经网络输出为图像中细胞的类别；步骤四：训练步骤三中的双线性细粒度分类神经网络使用梯度下降算法优化总体损失值,直到算法收敛且损失值不再下降后,保存网络参数,得到细胞分类模型；步骤五：将步骤二中预处理后的图像转化为细胞分割图；步骤六：使用步骤四中的细胞分类模型对步骤五中的细胞分割图每个前景连通区域进行采样预测,将预测结果赋给该连通区域从而得到逐区域的分类结果,结合分割得到的背景区域,最终得到细胞测试图像的语义分割结果。</td>   <td>G06T7/00;G06T7/11;G06V10/764;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘渊;                   潘嵘       </td>   <td>中山大学</td>   <td>一种提高闲聊对话系统回答丰富性的方法</td>   <td>广东省</td>   <td>CN110795550B</td>   <td>2023-04-07</td>   <td>本发明涉及一种提高闲聊对话系统回答丰富性的方法,将查询语句和回答语句进行分词和词性标注后放入Transformer模型并对模型进行训练中。对于需要回答的查询语句进行分词和词性标注,并通过PMI公式获得回答语句的关键词。将获得的关键词输入训练好的模型中得到对应的回答语句,并输出得分最高的回答语句。利用Transformer模型代替了传统的循环神经网络模型,能使模型更加关注到语句中不同位置间的依赖关系,从而生成更加流畅的语句,使得语句不丧失语义相关性。</td>   <td>1.一种提高闲聊对话系统回答丰富性的方法,其特征在于,包括如下步骤：步骤一：获取样本数量为N,样本形式为查询语句或回答语句；步骤二：对每个样本的查询语句和回答语句进行分词和词性标注,分别得到查询语句的查询词汇和查询词汇的词性,回答语句的回答词汇和回答词汇的词性；步骤三：建立查询词汇的文件频率表、回答词汇的文件频率表以及查询词汇和回答词汇每对共同出现的共现文件频率表；步骤四：采用训练样本训练Transformer模型,包括向前模型和向后模型；步骤五：对输入的查询语句进行分词和词性标注,并采用逐点互信息指标进行计算,得到逐点互信息值最高的三个回答语句词汇作为关键词；逐点互信息值的计算公式为：                  其中,表示查询语句、回答语句词汇的共现文件频率次数,/&gt;表示查询语句词汇的文件频率,/&gt;表示回答语句词汇的文件频率,/&gt;表示训练数据集总pair对数,alpha为可控参数；逐点互信息值最高的三个回答语句词汇作为关键词的公式如下：                  其中,m为查询语句分词后的词汇数量,为查询语句分词后的词汇,r为回答语句词汇的词汇；步骤六：将三个关键词输入向后模型的解码器部分,得到三个前半句回答语句,再将三个前半句回答语句分别作为向前模型的解码器部分的输入,得到三个回答语句；步骤七：使用打分函数对步骤六中的回答语句进行重排序,最终输出分数最高的回答语句；所述打分函数的公式为：                  其中,为查询语句,/&gt;为回答语句。</td>   <td>G06F16/332;G06F16/33;G06F40/126;G06F40/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         戴斯铭;              潘嵘;                   毛明志       </td>   <td>中山大学</td>   <td>一种提高推荐系统多样性的推荐列表重排名方法</td>   <td>广东省</td>   <td>CN110825967B</td>   <td>2023-04-07</td>   <td>本发明涉及一种提高推荐系统多样性的推荐列表重排名方法,首先采用原有的推荐方法获得推荐列表,然后计算用户的熵值,利用该熵值获得推荐列表的排名阀值,排名阀值结合本方法的重排名核心公式,获得新的推荐列表。本发明与现有的参数化排名方法相比,能够考虑到用户对于推荐列表多样性的不同需求,因此其推荐的物品更加贴合人们的真实感受,也考虑了不同用户对于同一物品的评分偏差。并且在准确性与多样性的平衡上,适当地提高多样性,但对于准确性的影响很小。</td>   <td>1.一种提高推荐系统多样性的推荐列表重排名方法,其特征在于,包括如下步骤：步骤一：输入用户-物品评分矩阵R,物品类型矩阵T,推荐列表长度N,通过推荐；采用推荐系统获得推荐列表,并预测未知评分R～*；步骤二：利用标准排名方法以及预测得到的评分来获得每个用户的推荐列表的标准排名,该方法对应排序公式为：rank-(standard)(i)＝R～*(u,i)～(-1)其中,R～*(u,i)指根据预测评分由低到高的排名,那么添加上-1的幂则表示按照预测评分由高到低进行排名；步骤三：计算用户的熵值λ(u),包括物品流行度的熵值和物品类型的熵值,并通过将物品流行度的熵值和物品类型的熵值相加获得用户的熵值；在所述步骤三中,物品流行度的熵值的计算公式为：                  其中,k表示用户的度数,H(k)表示度数为k的用户对应的物品流行度的熵值,而p-i表示特定度数的物品对应的概率；度数指在同一数据集中该物品被购买的总次数,n(k)则指不同的用户度数总的数量。物品类型的熵值的计算公式为：                  其中,H-2(u)指用户物品类型的熵值,u指单个的用户,n(type)指物品的类型总数,而p-i指用户u已评分的物品中该物品属于类型i的概率步骤四：根据用户的熵值计算用户的推荐列表的排名阀值T-(rank),使用该排名阀值对推荐列表进行重新排序,具体公式如下：T-(rank)＝M*N*λ(u)                  其中,rank-x(i)是非标准排名方法,rating则指某一个具体评分,T-H是指加入推荐列表物品对应的最低评分或是该用户所有已评分物品的平均评分,N是指top-N推荐列表的长度,M是本方法中需要进行调节的超参数。</td>   <td>G06F16/9535;G06F16/958</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;                   陈浩基       </td>   <td>中山大学</td>   <td>一种自主更新的室内定位方法</td>   <td>广东省</td>   <td>CN110826448B</td>   <td>2023-04-07</td>   <td>本发明公开了一种自主更新的室内定位方法,包括以下步骤：构建特征提取网络；构建隐马尔可夫模型；构建新地标检测网络；计算新地标的二维平面坐标；将计算出的新地标二维平面坐标写入数据库；依据新地标的ROI和类别与未改变地标的ROI和类别作为训练数据,得到新的特征提取网络。通过结合隐马尔可夫模型和运动恢复结构技术,对特征提取网络的输出进行判断,能够进一步减少特征提取网络的分类误差,有效降低了误判率；同时,通过构建新地标检测网络,能够确定三维点云的水平面和新地标的相对位置,进而将新地标的三维坐标映射回平面地图空间,完成室内地图更新,并不需要耗费大量人力去更新维护室内平面地图,大大减少了视频室内定位的后期维护成本。</td>   <td>1.一种自主更新的室内定位方法,其特征在于,基于运动恢复结构和隐马尔可夫模型,具体包括以下步骤：步骤S1,构建特征提取网络,所述特征提取网络以拍摄的视频帧为输入,各视频帧对应的地标ROI和类别为输出；步骤S2,构建隐马尔可夫模型,对所述特征提取网络输出的地标ROI和类别进行判断,判断是否有新地标,若有,则执行步骤S3,若没有,则停止更新；步骤S3,构建新地标检测网络,所述新地标检测网络以拍摄的视频帧为输入,输出各视频帧对应的新地标ROI和类别与未改变地标的ROI和类别；步骤S4,依据未改变的地标ROI和类别与新地标ROI和类别,计算出新地标的二维平面坐标；步骤S5,将计算出的新地标二维平面坐标写入数据库,同时删除发生改变的地标的相应数据；步骤S6,依据新地标的ROI和类别与未改变地标的ROI和类别作为训练数据,得到新的特征提取网络,完成更新；其中,所述步骤S4包括以下步骤：从新地标视频中提取视频帧构建初始点云；将新地标ROI和类别与发生改变的地标ROI和类别注册进入初始点云；将三维点云映射至二维水平面；依据聚类算法,得到新地标的二维平面坐标；根据SFM工具估计的视频帧相机位置和用户手机陀螺仪读数,能够将三维点云映射至二维水平面,然后将新地标ROI和发生改变的地标ROI标记的点云特征点根据聚类算法得到聚类中心点,最后结合平面地图上的墙壁约束,以未改变的旧地标为锚点,根据新旧地标聚类中心点之间的相对距离,即可得到新地标的二维平面坐标。</td>   <td>G06V20/40;G06V10/25;G06V10/75;G06V10/764;G06F16/75;G06F16/787</td>  </tr>        <tr>   <td>中国专利</td>   <td>         印鉴;              陈波;                   朱怀杰       </td>   <td>中山大学</td>   <td>一种基于会面点的最优组次序路径查询方法</td>   <td>广东省</td>   <td>CN110826761B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于会面点的最优组次序路径查询方法,属于路径规划技术领域。本发明能高效处理多用户查询场景下基于会面点的最优组次序路径查询,提出了OGSRM算法框架,该框架能够求解基于会面点的最优组次序路径也能快速的求解相应的高质量近似解,另外该框架具有很高的灵活性能使用不同的候选点启发式式函数、最优次序路径算法和近似最优次序路径算法。</td>   <td>1.一种基于会面点的最优组次序路径查询方法,其特征在于,包括以下步骤：步骤S1：初始化OGSRM算法框架参数λ,μ,h,ALGO-OSR和ALGO-AOSR,其中λ是停止参数,μ是精确限制参数,h是候选点的启发式函数,ALGO-OSR为任意最优次序路径查询算法,ALGO-AOSR为任意近似最优次序路径查询算法；步骤S2：初始化最优组次序路径变量routes为空；步骤S3：使用h计算所有会面候选点的启发式函数值并将候选点按其启发式函数值升序排列；步骤S4：按S3产生的候选点排列顺序依次检查每个候选点d,如果d的启发式函数值的λ倍大于或等于当前routes中路径的最大值或者所有候选点检查完毕,转到S6,否则执行S5后继续执行S4；步骤S5：前μ×100％用户使用ALGO-OSR算法查询,剩余用户使用ALGO-AOSR算法查询,如果查询得到结果中用户组的路径中的最大值比routes中路径最大值小,更新routes为当前查询结果；步骤S6：返回最优组次序路径routes。</td>   <td>G06Q10/047</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢梓莹;                   潘嵘       </td>   <td>中山大学</td>   <td>一种基于语句关系的词向量训练方法</td>   <td>广东省</td>   <td>CN110852072B</td>   <td>2023-04-07</td>   <td>本发明涉及一种基于语句关系的词向量训练方法,在预训练第一阶段的预训练中,加入中文句子的句子间关系对模型进行训练,以及将自注意力算法中矩阵K、Q、V矩阵的计算使用神经网络的非线性的计算方式。本方法能结合中文的语言特点更好地表达单词的多义性。并且本发明将自注意力算法中矩阵K、Q、V矩阵的计算使用神经网络的非线性方法,能够更充分地表达向量间的映射关系。</td>   <td>1.一种基于语句关系的词向量训练方法,其特征在于,包括如下步骤：步骤一：将训练数据集中的所有单词挑出并编号,并建立单词表；训练数据集中的每个单词对应一个数字编号；步骤二：将若干组句子组作为训练样本,句子组包括两个句子和两个句子的关系,将句子中的单词进行编号,将两个句子的关系转换为数字标签；句子中的单词的编号对应单词表中的单词编号；在两个句子之间插入一个代表句子间隔的符号；在两个句子的开头插入一个代表任务类型的分类符号；步骤三：将句子单词进行编号后,输入对应的词嵌入向量,对每个单词都设置维度向量表达；步骤四：将embedding得到的维度向量输入自注意力算法中非线性映射的transformer算法；self-attention中非线性计算矩阵K、Q、V矩阵的非线性方法是神经网络,神经网络的计算方式为：                                                      其中,reLu(·)代表激活函数,n代表神经网络的层数；x代表单词的嵌入向量；W-K,W-Q,W-V,分别是算法提取K、Q、V矩阵的矩阵参数；b-K,b-Q,b-V代表算法提取K、Q、V矩阵的矩阵偏置；g-K(x),g-Q(x),g-V(x)代表算法提取K、Q、V矩阵的每一层神经网络的计算函数；代表算法提取K、Q、V矩阵的n层神经网络计算函数；步骤五：最后一层的第一个transformer输出向量经过全连接层输出句子关系的数字标签；步骤六：通过迭代训练得到算法框架的参数,预训练阶段得到模型参数,提取了相关的句子结构；在进行下一阶段的任务时,以预训练得到的参数为基础,再结合具体任务数据进行训练预测下游任务标签。</td>   <td>G06F40/211;G06F40/284;G06F16/33;G06F16/35;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡跃新;              郑亿庆;              余晋刚;              李远清;                   刘楚       </td>   <td>中山大学孙逸仙纪念医院;华南理工大学</td>   <td>一种基于深度学习的具有智能图像分类诊断功能的可视耳内镜</td>   <td>广东省</td>   <td>CN111191684B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于深度学习的具有智能图像分类诊断功能的可视耳内镜,包括镜体、检测笔,所述镜体具有显示屏,所述镜体内置有图像分类诊断器,所述图像分类诊断器与所述检测笔通过数据传输线相连接,所述检测笔用于检测获得患者的耳内镜图像,并且将检测得到的耳内镜图像传输给所述的图像分类诊断器,所述图像分类诊断器包括构建模块、训练模块、验证模块和诊断模块,该可视耳内镜能够实现患者内耳镜的可视化检测以及智能诊断。</td>   <td>1.一种基于深度学习的具有智能图像分类诊断功能的可视耳内镜,包括镜体(1)、检测笔(2),所述镜体(1)具有显示屏(11),其特征在于,所述镜体(1)内置有图像分类诊断器,所述图像分类诊断器与所述检测笔(2)通过数据传输线(3)相连接,所述检测笔(2)用于检测获得患者的耳内镜图像,并且将检测得到的耳内镜图像传输给所述的图像分类诊断器,所述图像分类诊断器包括构建模块、训练模块、验证模块和诊断模块,其中,构建模块：用于从医院病例数据库中选取耳内镜图像构建耳内镜数据集,将数据集划分为测试集以及训练集；训练模块：用于加载预训练的神经网络模型,在所得到的训练集上微调预训练的神经网络模型,获得训练得到的神经网络模型；验证模块：用于在测试集上验证所述训练模块训练得到的神经网络模型的性能,筛选出最优神经网络模型；诊断模块：通过所述验证模块获得的最优神经网络模型,用于对检测笔(2)检测到的患者的耳内镜图像进行智能分类诊断,输出该耳内镜图像的分类诊断结果,通过显示屏(11)将患者的耳内镜图像以及该耳内镜图像的分类诊断结果显示出来,从而实现耳内镜的可视化检测以及智能诊断；所述分类诊断分为四类,四分类评价标准如下：(1)耳内镜图像无病变,正常鼓膜为一椭圆形灰白色半透明状薄膜,紧张部有光锥,判为类别0；(2)分泌性中耳炎鼓室负压内陷、渗出液、鼓室积液、鼓膜失去正常光泽,呈淡黄、橙红或琥珀色、鼓室未充满时可见气泡征或气液平面、锤骨短突突起,光锥变短,判为类别1；(3)慢性化脓性中耳炎活动期可见鼓膜穿孔,流脓,并有红肿发炎症状,判为类别2；(4)慢性化脓性中耳炎静止期可见鼓膜穿孔,干燥,无流脓和发炎症状,判为类别3。</td>   <td>G06V10/764;G06V10/82;G06V10/774;G06N3/045;G06N3/084;G06N3/082;A61B1/227</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡弘康;                   权小军       </td>   <td>中山大学</td>   <td>一种基于目标情感分析数据集的数据增强方法</td>   <td>广东省</td>   <td>CN111324744B</td>   <td>2023-04-07</td>   <td>本发明公开一种基于目标情感分析数据集的数据增强方法,包括采集目标领域内的数据集；对文本进行分词处理得到对应的单词序列,用全词掩盖方法掩盖待增强文本中的非情感表达的单词与待训练文本中的随机单词；将预处理后的待训练文本输入语言模型BERT进行训练,BERT对文本中每个单词对应的隐藏状态计算其概率分布及损失,相加所有被掩盖单词的损失并把其反向传播更新BERT的参数至模型收敛；把预处理后的待增强文本输入收敛后的BERT中,随机采样单词出现概率作为新目标,用其替换文本中的目标,得到增强后的新样本。本发明能预测出更符合语境的单词,从而得到基于目标情感分析任务的数据增强后的新样本。</td>   <td>1.一种基于目标情感分析数据集的数据增强方法,其特征在于,包括：S10预训练语言模型BERT：采集目标领域内的数据集预训练语言模型BERT；S20对文本预处理：对待增强文本进行分词处理得到其对应的单词序列,从待增强文本的单词序列中挑选出非情感类单词作为目标,用全词掩盖方法掩盖目标；从待训练文本的单词序列中随机挑选单词用全词掩盖方法掩盖；所述语言模型BERT包括：分词模块,用于对输入的文本基于语义进行分词生成单词序列；掩盖模块,用于从单词序列中挑选单词以用遮掩词掩盖；词嵌入模块,用于对掩盖后的单词序列编码成神经网络能够识别的单词向量序列E且将其输入Transformer模块,其中每个单词对应的向量均包括语义信息和该单词在文本中的位置信息,被掩盖的非情感类词的语义信息用遮掩词代替；Transformer模块,由多个Transformer网络堆叠而成,每个Transformer网络均采用了多头自注意力机制,第一个Transformer网络将单词向量序列E作为输入,其他Transformer网络的输入是前一个Transformer网络的输出,以获取单词向量序列E中每个单词以不同的权重注意单词向量序列中的所有单词,并对单词向量序列E中每个单词加权求和得到新单词向量序列H；输出模块,用于根据其语义和位置对应的隐藏状态获取新单词向量序列H中每个单词在语言模型BERT词表中所分配的概率；损失模块,用于根据被掩盖词的语义信息和其位置上每个单词的概率采用交叉熵计算在训练过程中每个被掩盖词的损失之和,再反向传播以更新网络参数；采样模块,用于在增强阶段,随机采样输出模块输出概率的一个单词作为新目标；替换模块,用于将新目标替换文本中的目标,得到增强后的新样本；所述S20具体包括：S201从语料中随机选择一段文本,对这段文本根据空格或者标点进行分词,得到其对应的单词序列；S202从待增强文本的单词序列中挑选出非情感类词作为掩盖目标；从待训练文本的单词序列中随机挑选单词；S203从S202所挑选出的掩盖目标或单词按词根和词缀进行子词切分,用遮盖词分别对所切分的所有目标或单词的子词掩盖；S30将预处理后的待训练文本输入预训练后的语言模型BERT进行训练,语言模型BERT对文本中每个单词根据其语义和位置对应的隐藏状态计算其概率分布及损失,相加所有被掩盖目标的损失得到文本总损失,把文本总损失反向传播更新语言模型BERT的参数至模型收敛；S40把预处理后的待增强文本输入收敛后的语言模型BERT中,随机采样单词出现概率作为新目标,将新目标替换文本中的目标,得到增强后的新样本。</td>   <td>G06F16/36;G06N3/0455;G06N3/047;G06N3/084;G06F40/289;G06F40/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李阳辉;              康显桂;              胡建芳;                   林小拉       </td>   <td>中山大学</td>   <td>基于移动深度学习引擎的移动端人像智能背景替换方法</td>   <td>广东省</td>   <td>CN111369430B</td>   <td>2023-04-07</td>   <td>本发明提出一种基于移动深度学习引擎的移动端人像智能背景替换方法,至少包括以下步骤：S1.选取待训练的卷积神经网络模型；S2.在服务端训练卷积神经网络模型；S3.基于移动深度学习引擎,结合自适应多级模型选择策略,将卷积神经网络模型部署在移动端；S4.利用选择得出的最优卷积神经网络模型进行人像智能背景替换。本发明在移动设备上就能实现背景替换的功能,解决了因网络因素导致人像背景替换的处理效率和成功率低的问题；另外,在进行卷积神经网络模型移动端的部署时,结合了自适应多级模型选择策略,达到根据用户设备差异有效选择最优模型的目的,提升用户使用体验。</td>   <td>1.一种基于移动深度学习引擎的移动端人像智能背景替换方法,其特征在于,至少包括：S1.选取待训练的卷积神经网络模型；S2.在服务端训练卷积神经网络模型；在服务端训练卷积神经网络模型的过程为：S201.获取人像分割数据集,所述人像分割数据集包括原始图像和掩码图像；S202.对人像分割数据集中的原始图像进行格式处理,对掩码图像进行标签转换；S203.根据需求比例,将人像分割数据集划分为训练集和验证集；S204.确定训练平台,并将训练集和验证集的数据转换为训练平台要求的格式；S205.将转换格式后的训练集和验证集输入卷积神经网络模型,对卷积神经网络模型进行训练；S3.基于移动深度学习引擎,结合自适应多级模型选择策略,将卷积神经网络模型部署在移动端；卷积神经网络模型部署在移动端的过程为：S301.构建移动深度学习引擎文件；S302.将服务端训练后的卷积神经网络模型转换为与移动深度学习引擎匹配的格式；S303.将卷积神经网络模型量化；S304.将未量化的原卷积神经网络模型及量化后的卷积神经网络模型加入移动端集成开发环境的目录；S304.将移动深度学习引擎文件加入编程配置；S305.调用移动深度学习引擎文件,结合自适应多级模型选择策略,使用本地或相机图片进行人像分割神经网络推断,获取掩码,根据掩码和背景图片进行逐像素替换；S4.利用选择得出的最优卷积神经网络模型进行人像智能背景替换。</td>   <td>G06T3/00;G06T1/40;G06V10/26;G06V10/82;G06V10/774;G06V10/94;G06N3/0464;G06N3/0495;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   李文盛       </td>   <td>中山大学</td>   <td>一种双手姿势的实时检测方法</td>   <td>广东省</td>   <td>CN111539288B</td>   <td>2023-04-07</td>   <td>本发明公开了一种双手姿势的实时检测方法,通过采用2d关节点位置和3d关节点位置进行双手姿势重建,能够重建出两只手的骨架模型,即使是复杂交互的双手姿势也能够清楚地构建,解决了现有技术存在的无法对复杂交互的双手姿势进行检测的问题,同时,通过采用2d关节点位置和3d关节点位置进行拟合的方式,能够降低重建两只手骨架模型的运算难度,提升重建双手骨架模型的速度,从而保证了检测双手姿势的实时性,从而解决了现有技术存在的难以实现实时性的问题。</td>   <td>1.一种双手姿势的实时检测方法,所述方法基于单目摄像机,其特征在于：所述方法具体包括以下步骤：步骤S1,通过单目摄像机捕捉到双手单帧图像,将所述单帧图像输入到图像分割网络进行分割,分割出包括左手、右手和背景三种类别的分割结果；步骤S2,依据分割结果提取出包括左手2d关节点位置的左手热度图和包括右手2d关节点位置的右手热度图；步骤S3,依据包括左手2d关节点位置的左手热度图和包括右手2d关节点位置的右手热度图,计算出左手3d关节点位置和右手3d关节点位置；步骤S4,将左手2d关节点位置和左手3d关节点位置与左手骨架模型进行拟合,并将右手2d关节点位置和右手3d关节点位置与右手骨架模型进行拟合,得到左右手骨架模型的参数,从而得到双手的姿势；其中,步骤S4具体包括：使用一个运动的骨架模型拟合于预测得到的2d/3d关节点；每只手的骨架模型包括26个自由度,t∈R～3和R∈SO(3)分别表示根关节点的全局位置以及旋转角度,θ∈R～(20)表示手指的关节角；记Θ＝{t,R,θ}作为骨架模型的参数,通过变换M(Θ)∈R～(21×3)得到手部关节点的全局位置,记左右手骨架参数分别为Θ-L和Θ-R,Θ-H＝{Θ-L,Θ-R}表示双手的骨架参数,通过最小化下式使得骨架模型拟合于3d关节点,其中J-i表示第i个3d关节点的全局位置：                  除此之外,还使用2d关节点作为额外的约束以使得预测得到的结果能够更加拟合于原图中手部的特征,通过最小化下式使得骨架拟合于2d关节点,其中u-i表示第i个2d关节点的位置,π用于将3d关节点投影到2d平面：                  为了使得手部骨架模型的姿势保持正常,需要保证手部关节不要有大角度的弯曲,因此需要对关节角添加限制,在此处我们仅对第一帧预测得到的参数进行约束,设和/&gt;分别为第i个关节角的上限与下限,通过下式对关节角进行监督：                  为了避免相邻帧之间重建得到的手部姿势幅度过大的变化,需要对相邻两帧预测得到的参数的变化率进行约束,如下式所示：                  通过上述四式对骨架拟合过程进行约束,通过最小化下面的能量方程拟合得到Θ-H,其中w为各项所占的比重,在预测第一帧的参数时w-3不为0,在后续的预测中,w-3为0：E＝ω-1E-(3D)+ω-2E-(2D)+ω-3E在训练的时候,首先对左右手分割、2d关节点预测以及3d关节点预测任务分别进行预训练,随后对2d/3d关节点的预测进行端到端的训练。</td>   <td>G06V40/10;G06V10/26;G06V10/42;G06V10/82;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              林彬;              甘叔玮;              王杰;                   杨夏       </td>   <td>中山大学</td>   <td>一种基于成像特性的空间弱小多目标检测方法及系统</td>   <td>广东省</td>   <td>CN111696096B</td>   <td>2023-04-07</td>   <td>本发明公开一种基于成像特性的空间弱小多目标检测方法,首先通过中值滤波来平滑图像的噪声；再通过卷积操作寻找图像的高亮区域以获得所有局部最大像素值点；然后根据局部最大像素值点在卷积图像中的分布特征,设定多个子图半径,以局部最大像素值点为中心按子图半径在卷积图像内提取多个子图,构建与子图相同尺度且满足高斯分布的核函数；接着计算目标特性参数,通过该目标特性参数可准确提取各个局部最大像素值点的特征；最后根据目标特性参数,计算局部最大像素值点的MLTC值,根据MLTC值,确定待检测图像中的目标点,并根据MLTC值剔除所述目标点中的重复目标点,获得待检测图像中的空间弱小目标,该方法可实现高数量、高精度的目标检测,检测过程简单高效。</td>   <td>1.一种基于成像特性的空间弱小多目标检测方法,其特征在于,包括：获取带有多个空间弱小目标的待检测图像；对所述待检测图像进行中值滤波,获得平滑图像；根据预先设置的卷积核对所述平滑图像进行卷积处理,获得卷积图像内的局部最大像素值点；根据所述局部最大像素值点在所述卷积图像中的分布特征,设定多个子图半径,以所述局部最大像素值点为中心按所述子图半径在所述卷积图像内提取多个子图,构建与所述子图相同尺度且满足高斯分布的核函数；根据所述核函数以及所述局部最大像素值点,确定所述子图的目标特性参数中的能量响应度、能量集中度,以及根据所述子图,确定所述目标特性参数中的能量转移度；根据所述目标特性参数,计算局部最大像素值点的MLTC值,根据所述MLTC值,确定所述子图中的目标点,并根据所述MLTC值剔除所述目标点中的重复目标点,获得所述待检测图像中的空间弱小目标,包括：根据所述目标特性参数,计算局部最大像素值点的MLTC值为：                                    r(x-i,y-i)＝2σ(12)式中,表示同一局部最大像素值点不同半经子图的多尺度局部目标特征值,σ-j表示子图半径；MLTC(x-i,y-i)表示局部最大像素值点的多尺度局部目标特征值；和/&gt;分别表示能量响应度阈值、能量集中度阈值和能量转移度阈值；n表示局部最大像素值点的数量；m表示子图半径数量；r(x-i,y-i)表示局部最大像素值点的多尺度局部目标特征值对应的子图半径；σ表示方差；根据所述MLTC值,确定所述子图中的目标点；并根据所述MLTC值,若非零局部最大像素值点对应的子图半径范围内存在≥2个的目标点,则选择MLTC值最大的目标点作为空间弱小目标,其余目标点作为重复目标点并剔除所述重复目标点,获得所述图像中的空间弱小目标。</td>   <td>G06T7/00;G06T5/00;G06V10/46;G06V10/75</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              谢宇光;              单广威;                   印鉴       </td>   <td>中山大学</td>   <td>基于眼部运动细微特征的早期疲劳检测方法及系统</td>   <td>广东省</td>   <td>CN112434611B</td>   <td>2023-04-07</td>   <td>本发明涉及计算机视觉及视频分析技术领域,为基于眼部运动细微特征的早期疲劳检测方法及系统,其方法包括：检测出视频帧序列的人脸位置图像、人脸特征点位置；识别出帧序列中的眨眼帧序列以及眼球运动帧序列,将视频帧序列划分为眨眼与眼球运动交替的帧序列；获取关于每次眨眼的眨眼信息特征、眼球运动信息特征,并融合、组合为眼部运动细微特征序列；训练基于时序的神经网络模型得到疲劳程度检测模型；将需要预测的视频帧序列进行处理,获得人员的眼部运动细微特征序列,输入到疲劳程度检测模型中,判断出当前人员的疲劳程度。本发明可有效检测视频序列中人员的疲劳程度,检测结果包括：清醒、早期疲劳、疲劳,实现早期疲劳的检测。</td>   <td>1.基于眼部运动细微特征的早期疲劳检测方法,其特征在于,包括以下步骤：S1、按序从视频帧序列中读取出每帧图像信息,然后使用人脸检测算法检测出每一帧的人脸位置图像,再通过人脸位置图像及人脸特征点检测算法,检测出对应该帧的人脸特征点位置；S2、获得视频帧序列的若干帧人脸特征点位置后,通过眨眼检测算法,识别出这些帧序列中的眨眼帧序列以及眼球运动帧序列,两次眨眼帧序列之间的帧序列即为眼球运动帧序列,从而将视频帧序列划分为眨眼与眼球运动交替的帧序列；S3、对得到的每段眨眼帧序列,应用眨眼特征提取算法,获取关于每次眨眼的眨眼信息特征；S4、对得到的每段眼球运动帧序列,应用眼球运动信息提取算法,获取每次眨眼间的眼球运动信息特征；S5、将眨眼信息特征与眼球运动信息特征融合为眼部运动细微特征,并以时间序列的方式组合作为眼部运动细微特征序列；S6、对视频训练数据集,通过上述步骤S1-S5提取每个视频的眼部运动细微特征序列,存入到基于时序的神经网络模型中进行训练学习,得到疲劳程度检测模型；S7、对需要预测的视频,将相应的视频帧序列通过步骤S1-S5进行处理,获得视频帧序列中人员的眼部运动细微特征序列；然后将眼部运动细微特征序列输入到训练好的疲劳程度检测模型中,疲劳程度检测模型判断出人员的眼部运动模式属于哪种疲劳程度的运动模式,从而判断出当前人员的疲劳程度；步骤S4中,首先求得每帧对应的眼睛虹膜的两侧边缘垂直线位置,再根据人脸特征点中对应眼睛角点的位置,求得边缘的相对水平坐标,然后根据帧差信息,利用稳定的那端垂直线来计算眼球运动信息特征。</td>   <td>G06V40/16;G06V20/40;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         文永明;              方译权;                   成慧       </td>   <td>中山大学</td>   <td>基于几何约束协同注意力网络的6D位姿估计方法和装置</td>   <td>广东省</td>   <td>CN113269830B</td>   <td>2023-04-07</td>   <td>本发明公开了基于几何约束协同注意力网络的6D位姿估计方法和装置,方法包括：从场景图像中提取第一图像块和第二图像块；从第一图像块中提取第一稠密特征,以及从第二图像块中提取第二稠密特征；对第一稠密特征进行采样处理得到第一采样特征,并对第二稠密特征进行采样处理得到第二采样特征；将第一采样特征和第二采样特征进行连接,得到场景全局特征；确定模型几何特征；根据场景全局特征和模型几何特征,确定协同注意力响应图；根据协同注意力响应图确定总体多模态特征；将总体多模态特征输入位姿估计网络中,预测得到对象的6D位姿。本发明能够提高位姿估计的性能,可广泛应用于机器人视觉技术领域。</td>   <td>1.基于几何约束协同注意力网络的6D位姿估计方法,其特征在于,包括：从场景图像中提取第一图像块和第二图像块；从所述第一图像块中提取第一稠密特征,以及从所述第二图像块中提取第二稠密特征；对所述第一稠密特征进行采样处理得到第一采样特征,并对所述第二稠密特征进行采样处理得到第二采样特征；将所述第一采样特征和所述第二采样特征进行连接,得到场景全局特征；确定模型几何特征；根据场景几何特征和所述模型几何特征,确定协同注意力响应图；根据所述协同注意力响应图确定总体多模态特征；将所述总体多模态特征输入位姿估计网络中,预测得到对象的6D位姿；所述将所述第一采样特征和所述第二采样特征进行连接,得到场景全局特征,包括：对所述第一图像块和所述第二图像块进行裁剪处理,得到裁剪后的图像块；确定所述第一采样特征和所述第二采样特征进行连接后得到的连接结果；根据多层感知器和最大池化函数,对所述连接结果进行处理,得到所述裁剪后的图像块的场景全局特征；所述确定模型几何特征,包括：采用最远点采样算法进行特征采样,得到模型几何特征；根据所述模型几何特征,通过多层感知器和最大池化函数,生成模型全局特征；所述方法还包括构建所述协同注意力响应图的几何约束条件的步骤,该步骤包括：通过真实姿态将场景点云中的点转换为对象模型的点云所在的标准姿态中；计算转换后的点与对象模型中所有点之间的距离为：                  计算转换后的点的法线与对象模型中的点的法线之间的角度为：                  根据所述距离和角度,计算权重为：                  根据所述权重计算几何约束的损失为：                  根据所述几何约束的损失进行引导,训练协同注意力模块；其中,为转换后的场景点云中的第i点,/&gt;为对象模型点云中的第j点,d-(i,j)为转换后的场景点云中的第i点与对象模型点云中的第j点之间的距离,/&gt;为转换后的场景点云中的第i点的法向量,/&gt;代表法向量/&gt;的向量模,/&gt;为对象模型点云中的第j点的法向量,/&gt;为法向量/&gt;的向量模,θ-(i,j)为转换后的场景点云中的第i点的法线与对象模型点云中的第j点的法线之间的角度,w-(i,j)为转换后的场景点云中的第i点与对象模型点云中的第j点之间的权重,α和β为实验调整的正参数,/&gt;为几何约束的损失,A-(i,j)为转换后的场景点云中的第i点所对应的场景几何特征与对象模型点云中的第j点所对应的模型几何特征之间的相似度,N为随机采样的点数量。</td>   <td>G06T7/73;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭卫文;              欧阳孔雷;              黄承赓;              韩瑜;                   古博       </td>   <td>中山大学</td>   <td>一种基于迁移学习的设备集群跨域故障预测方法及系统</td>   <td>广东省</td>   <td>CN113342476B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于迁移学习的设备集群跨域故障预测方法及系统,该方法包括：采集源域和目标域中设备的信号,得到原始监测数据；基于连续异常点检测方法对原始监测数据进行初识别,得到早期故障节点；进行信号校准和特征提取处理,得到故障特征集；基于故障特征集对预构建的域自适应迁移学习MLP-DCNN双神经网络进行训练,得到预测模型；实时采集目标域设备的时频域数据并输入到预测模型,实现故障检测。该系统包括：数据获取模块、初识别模块、故障特征提取模块、训练模块和故障检测模块。通过使用本发明,解决了跨域的制造设备之间的迁移故障预测。本发明作为一种基于迁移学习的设备集群跨域故障预测方法及系统,可广泛应用于设备运维管理领域。</td>   <td>1.一种基于迁移学习的设备集群跨域故障预测方法,其特征在于,包括以下步骤：基于传感器采集源域和目标域中设备的信号,得到原始监测数据；基于连续异常点检测方法对原始监测数据进行初识别,得到早期故障节点；对原始监测数据中早期故障节点后的数据进行信号校准和特征提取处理,得到故障特征集；基于故障特征集对预构建的域自适应迁移学习MLP-DCNN双神经网络进行训练,所述预构建的域自适应迁移学习MLP-DCNN双神经网络包括多层全连接网络和深度卷积神经网络；将故障特征集中源域和目标域的1-D时序特征融合,得到融合时序特征；将故障特征集中源域和目标域的2-D时频谱特征融合,得到融合时频谱特征；以融合时序特征作为多层全连接网络的输入,以融合时频谱特征作为深度卷积神经网络的输入,得到输出双重子网络的输出特征；将双重子网络的输出特征进行连接,并基于自适应优化算法反向传播迭代更新训练神经网络参数,得到预测模型；实时采集目标域设备的时频域数据并输入到预测模型,实现故障检测。</td>   <td>G06F9/455;G06F18/214;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              岳九涛;              魏朋旭;                   林倞       </td>   <td>中山大学</td>   <td>一种基于频域的真实图像超分辨鲁棒方法及装置</td>   <td>广东省</td>   <td>CN113436073B</td>   <td>2023-04-07</td>   <td>本申请实施例提供了一种基于频域的真实图像超分辨鲁棒方法及装置,所述方法包括：接收总图像数据,判断所述总图像数据是否为对抗样本的图像数据,在所述图像数据为对抗样本的图像数据时,将所述总图像数据发送至随机频域掩盖模块；将所述总图像数据转换为频域的第一图像数据,掩盖掉所述第一图像数据中的多个高频分量,并得到第二图像数据,将所述第二图像数据转换为时域中的第三图像数据,并将所述第三图像数据发送至真实超分辨模型；基于所述第三图像数据生成对应于所述总图像数据的具有更清晰的细节和更好的保真度的图像。</td>   <td>1.一种基于频域的真实图像超分辨鲁棒方法,其特征在于,所述方法包括：接收总图像数据,判断所述总图像数据是否为对抗样本的图像数据,在所述总图像数据为对抗样本的图像数据时,将所述总图像数据发送至随机频域掩盖模块；在所述随机频域掩盖模块中,将所述总图像数据转换为频域下的第一图像数据,通过掩盖掉所述第一图像数据中的多个高频分量,得到第二图像数据,将所述第二图像数据转换为时域下的第三图像数据,并将所述第三图像数据发送至真实超分辨模型,其中,所述随机频域掩盖模块嵌入到所述真实超分辨模型中；具体地；将所述总图像数据基于离散余弦变换转换为频域下的第一图像数据/&gt;,并采样每一个频域掩码图/&gt;,所述/&gt;为总图像数据的高,所述/&gt;为总图像数据的宽,所述/&gt;为总图像数据的通道数；通过哈达玛积算法/&gt;得到第二图像数据,其中/&gt;表示为哈达玛积；将所述第二图像数据转换为时域下的第三图像数据,并将所述第三图像数据发送至真实超分辨模型；基于所述第三图像数据生成对应于所述总图像数据的具有更清晰的细节和更好的保真度的图像。</td>   <td>G06T3/40;G06V10/774;G06V10/82;G06N3/0464;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙伟;              官明哲;                   张武军       </td>   <td>中山大学</td>   <td>基于文本生成对抗网络的个人数字空间数据脱敏的方法</td>   <td>广东省</td>   <td>CN112861179B</td>   <td>2023-04-07</td>   <td>本发明提供一种基于文本生成对抗网络的个人数字空间数据脱敏的方法,包括以下步骤：S1：获取个人数字空间中待脱敏处理的数据文件,构建文本生成对抗网络模型；S2：解析待脱敏处理的数据文件,得到包含敏感信息的解析文件；S3：将解析文件作为源数据输入文本生成对抗网络模型进行训练；S4：判断训练后的文本生成对抗网络模型是否收敛,若是,则得到与源数据具有相同统计特性的脱敏文本数据；若否,则返回步骤S3。本发明提供一种基于文本生成对抗网络的个人数字空间数据脱敏的方法,解决了现有的数据脱敏技术在医疗场景下应用时会改变医疗源数据的结构化格式的问题。</td>   <td>1.基于文本生成对抗网络的个人数字空间数据脱敏的方法,其特征在于,包括以下步骤：S1：获取个人数字空间中待脱敏处理的数据文件,构建文本生成对抗网络模型；所述文本生成对抗网络模型包括生成器和判别器；S2：解析待脱敏处理的数据文件,得到包含敏感信息的解析文件；S3：将解析文件作为源数据输入文本生成对抗网络模型进行训练；在步骤S3中,结合Monte Carlo搜索的策略对文本生成对抗网络模型进行训练；对文本生成对抗网络模型进行训练的具体步骤为：将源数据的单词编码后得到的向量输入循环神经网络的嵌入层,得到嵌入层向量x-1,...,x-T,输出隐藏层向量h-1,...,h-T,得到h-t＝R(h-(t-1),x-t)其中,h-(t-1)是前一个状态的隐藏层向量,h-t、x-t分别是当前状态的隐藏层向量和嵌入层向量；t≤T,T为词向量序号,R为RNN网络；将隐藏层向量通过循环神经网络的softmax层得到当前状态生成的序列Y-(1：t)中y-t的分布概率：p(y-t|x-1,...,x-t)＝softmax(b+Wh-t)其中,b为偏置向量,W为权重矩阵,y-t为长度为t的序列；对于当前句子的奖励Q,表示为Q＝D(Y-(1：t))对于一个n次的Monte Carlo搜索,表示为                  运行Monte Carlo搜索的策略从当前状态到序列结束获得N次输出序列,从而获得更为准确的奖励Q,表示为                  对于每个序列,将嵌入层向量x-1,...,x-T连接起来,表示当前的一个序列                  其中,为按行连接操作；通过卷积核ω对序列向量d-(1：T)进行卷积操作                  其中,为对应位置相乘,ρ为非线性函数,c-i为卷积层的输出值；经过池化层后得到向量c＝max(c-1,...,c-(T-l+1)),通过全连接层的sigmoid函数输出该序列判别为“真实”的概率,即奖励Q；根据奖励Q的高低来更新生成器的参数,从而减小生成句子的损失；经过循环训练使得判别器误差最小时模型收敛；S4：判断训练后的文本生成对抗网络模型是否收敛,若是,则得到与源数据具有相同统计特性的脱敏文本数据；若否,则返回步骤S3。</td>   <td>G06F21/62;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭键清;              张弛;              吴皓轩;                   韩瑜       </td>   <td>中山大学</td>   <td>一种柔性机器人的操作空间轨迹优化方法、系统及装置</td>   <td>广东省</td>   <td>CN112862812B</td>   <td>2023-04-07</td>   <td>本发明公开了一种柔性机器人的操作空间轨迹优化方法、系统及装置,该方法包括：获取图像并进行预处理；对预处理后的图像进行特征提取；基于提取的椭圆参数计算柔性机器人的末端位姿和臂型参数；计算误差；构建空间优化模型并得到最优关节角度；判断到误差小于预设阈值,优化结束。该系统包括：图像处理模块、特征提取模块、运动学参数计算模块、误差计算模块、轨迹优化模块和阈值判断模块。该装置包括基座、柔性机器人、固定相机、辅助相机和辅助机械臂。通过使用本发明,能实时感知柔性机器人臂型,提高机器人的运动精度。本发明作为一种柔性机器人的操作空间轨迹优化方法、系统及装置,可广泛应用于机器人轨迹优化领域。</td>   <td>1.一种柔性机器人的操作空间轨迹优化方法,其特征在于,包括以下步骤：获取臂杆截面图像并对图像进行预处理,得到预处理后的臂杆图像；对预处理后的臂杆图像进行边缘检测,得到离散的椭圆像素点；对离散的椭圆像素点进行拟合,得到粗略椭圆拟合参数；将各相机的坐标系统一到同一坐标系下；构建多目融合位姿测量误差的优化模型并对各个相机获取的椭圆参数进行优化；多目融合位姿测量误差的优化模型的表达式如下；                                    其中,k代表像平面上椭圆弧上第k个像素点,E表示拟合后的椭圆标志,/&gt;表示第i号相机测量得到的末端位置和第1号相机测量得到的末端位置在第1号相机系下的相对偏差,/&gt;表示第i号相机测量得到的末端法向量和第1号相机测量得到的末端法向量在第1号相机系下的相对偏差,/&gt;表示表示第i号相机测量拟合后的椭圆中心横坐标,/&gt;表示第i号相机获取第k个离散像素点的横坐标,/&gt;表示第i号相机测量拟合后的椭圆中心纵坐标,/&gt;表示第i号相机获取第k个离散像素点的纵坐标,/&gt;表示第i号相机测量拟合后的椭圆短半轴,/&gt;表示第i号相机测量拟合后的椭圆长半轴,/&gt;表示第i号相机测量拟合后的椭圆偏置角；基于粒子群优化算法对多目融合位姿测量误差的优化模型进行求解,得到精确椭圆参数；基于椭圆参数计算得到柔性机器人的末端位姿和臂型参数；根据柔性机器人的末端位姿、臂型参数和对应的期望值计算末端位姿差和臂型误差；根据末端位姿差和预构建的空间优化模型,得到最优关节角度；判断到臂型误差和末端位姿差小于预设阈值,优化结束。</td>   <td>G06T7/00;G06T7/13;G06T7/73;G06T5/00;G06N3/006</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              吴迪邦;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种基于深度学习的大肠空腔区及肠内容物标注方法</td>   <td>广东省</td>   <td>CN112950599B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于深度学习的大肠空腔区及肠内容物标注方法,该方法包括：获取CT腹腔图像并对图像中的相关区域进行区域合并,得到区域合并后图像；将区域合并后图像进行图像拆分,得到拆分后图像；基于预训练的分割网络对拆分后图像进行分割,得到大肠区域图；根据大肠区域图对大肠区域进行标注,得到标注图；将标注图与输入的CT腹腔图像进行图像拼接,得到带标注的CT腹腔图像。本发明方法能够自动对输入的CT腹腔图像的大肠空腔区及肠内容物区域进行标注。本发明作为一种基于深度学习的大肠空腔区及肠内容物标注方法,可广泛应用于图像处理领域。</td>   <td>1.一种基于深度学习的大肠空腔区及肠内容物标注方法,其特征在于,包括以下步骤：获取CT腹腔图像并对图像中的相关区域进行区域合并,得到区域合并后图像；将区域合并后图像进行图像拆分,得到拆分后图像；基于预训练的分割网络对拆分后图像进行分割,得到大肠区域图；根据大肠区域图和输入的CT腹腔图,分别对大肠空腔区及肠内容物进行标注,得到标注图；将标注图与输入的CT腹腔图像进行图像拼接,得到带标注的CT腹腔图像；所述获取CT腹腔图像并对图像中的相关区域进行区域合并,得到区域合并后图像这一步骤,其具体包括；获取CT腹腔图像；将CT腹腔图像内与肠内容物颜色接近的像素点进行去除；将去除部分像素点后的CT腹腔图像中的肠内容物区域和大肠空腔区域进行合并,得到区域合并后图像；所述基于预训练的分割网络对拆分后图像进行分割,得到大肠区域图这一步骤,其具体包括；基于编码器对输入的拆分后图像进行特征提取,得到特征信息；基于ConvLSTM模块连接各层编码器的特征信息并进行特征拼接,得到拼接后的特征信息；基于带注意力机制的解码器将拼接后的特征信息还原；基于分类模块输出属于大肠区域的像素点的概率值并将像素点整合,得到大肠区域图；所述将区域合并后图像进行图像拆分,得到拆分后图像这一步骤,其具体包括；将区域合并后图像等比率分割成3*3的图像块,并将相邻图层的同一对应位置的图像块组成一个五张图片形成的图像组,得到拆分后图像；所述预训练的分割网络的训练步骤包括；获取训练用CT腹腔图像并对训练用CT腹腔图像进行数据增强,得到增强训练图像；将增强训练图像结合图像对应的真实标签,构建训练集；基于训练集中的CT腹腔图像对预构建的分割网络进行训练,得到预测标签；基于预测标签与对应的真实标签计算误差损失；根据误差损失对预构建的分割网络进行参数更新,得到训练完成的分割网络。</td>   <td>G06T7/00;G06T7/11;G06T7/187;G06T3/40;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王培源;              郭列维;                   张秀兰       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于神经网络的防近视方法和装置</td>   <td>广东省</td>   <td>CN114120357B</td>   <td>2023-04-07</td>   <td>本发明属于神经网络技术领域,公开了一种基于神经网络的防近视方法和装置。所述防近视方法包括：获取待检测图像,所述待检测图像包括人体上半身图像和被视物体；将待检测图像输入到预先训练好的神经网络模型,获取人体的头部区域和被视区域；获取头部区域和被视区域之间的第一距离；将第一距离和标准阅读距离进行比较,若所述第一距离小于标准阅读距离,则发出第一提醒。有益效果：采用了神经网络对头部区域和阅读区域进行识别,通过摄像装置获取头部区域和阅读区域的距离,避免了青少年穿戴防近视设备的问题,可以避免穿戴防近视设备的诸多不良影响。</td>   <td>1.一种基于神经网络的防近视方法,其特征在于,包括：获取待检测图像,所述待检测图像包括人体上半身图像和被视物体；将待检测图像输入到预先训练好的神经网络模型,获取人体的头部区域和被视区域；获取头部区域和被视区域之间的第一距离；将第一距离和标准阅读距离进行比较,若所述第一距离小于标准阅读距离,则发出第一提醒；在将待检测图像输入到预先训练好的神经网络模块后,所述防近视方法还包括：根据所述神经网络模型获取人体空间向量并将获取到的人体空间向量和预存的标准坐姿的人体空间向量进行比较；若获取到的人体空间向量和预存的标准坐姿的人体空间向量的相似度未超过预设的第一阈值,则发出第二提醒；其中,在进行相似度判断分为两种方式,一种是单独的计算所获得的躯干向量和手臂向量的空间位置关系,以及躯干向量、手臂向量和被视物的空间位置关系；另一种是,通过大数据收集标准的青少年坐姿安全范围；将获得的躯干向量和手臂向量与大数据收集到的进行比对；所述神经网络模型包括：浅层神经网络、中层神经网络、深层神经网络和输出层神经网络；所述浅层神经网络用于检测和提取待检测图像中复杂结构的边界特征,所述边界特征为待检测图像中像素值有较大差异的横线、竖线和正交线；所述中层神经网络用于接收浅层神经网络提取的边界特征并对边界特征进行组合得到若干第一轮廓；所述深层神经网络用于接收中层神经网络得到的第一轮廓并对第一轮廓进行组合得到第一形体,所述第一形体包括：头部和被视物体；对第一形体进行标定得到头部区域和被视区域；所述输出层神经网络用于接收深层神经网络得到的第一形体,并利用空间函数和深度相机获取第一距离；所述根据所述神经网络模型获取人体空间向量并将获取到的人体空间向量和预存的标准坐姿的人体空间向量进行比较,具体为：所述第一形体还包括：躯干和手臂；采用第三标记对躯干和手臂进行标记,并获取第三标记的空间坐标,根据第三标记的空间坐标得到躯干向量和手臂向量；将躯干向量和手臂向量和标准坐姿的人体空间向量进行比较,判断相似度是否大于预设的第一阈值；所述手臂向量包括肩部和手肘组成的第一向量和手肘和手腕组成的第二向量；所述将躯干向量和手臂向量和标准坐姿的人体空间向量进行比较,判断相似度是否大于预设的第一阈值,具体为：将躯干向量和手臂向量的组合输入到预先训练好的姿势判定神经网络,由姿势判定神经网络输出输入的躯干向量和手臂向量的组合和标准姿势的人体空间向量的相似度并判定相似度是否大于预设的第一阈值。</td>   <td>G06V40/10;G06V20/00;G06V10/25;G06V10/774;G06V10/74;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈泽涛;              林义雄;              施梦汝;              王小双;              曾培生;              龚卓弘;              刘海雯;                   陈卓凡       </td>   <td>中山大学附属口腔医院</td>   <td>一种基于人工智能的前牙即刻种植测量分析方法</td>   <td>广东省</td>   <td>CN113112477B</td>   <td>2023-04-07</td>   <td>为了解决即刻种植术前各项软硬组织指标测量时存在的精度不足及耗时问题,本发明提供了一种基于人工智能前牙即刻种植测量分析方法,其通过先行构建标准化前牙即刻种植相关软硬组织数据库,并依托该数据库对Resnet神经网络算法进行训练优化,搭建具备前牙即刻种植相关软硬组织测量的高精度、高可行性AI算法,临床通过输入患者的口腔硬组织数据及口腔表面数据,即可得到前牙即刻种植术前各项软硬组织及角度指标,本发明基于人工智能神经网络,旨在通过卷积神经网络算法获得前牙美学区即刻种植相关的软硬组织指标测量数据,提高测量精度及速度,减轻临床口腔医生负担,提高工作效率,促进完善的即刻种植方案的决策与制定。</td>   <td>1.一种基于人工智能的前牙即刻种植测量分析方法,其特征在于,包含以下步骤：S1、构建标准化前牙即刻种植相关软硬组织数据库；具体包括以下步骤：S1.1构建口腔软硬组织图像数据影像学资料库；批量收集患者口腔硬组织数据及口腔表面数据,通过种植分析软件导入同一患者的口腔硬组织数据DICOM文件及口腔表面数据STL文件,分别在两组数据上标记3组或3组以上的对应点,将口腔硬组织数据及口腔表面数据进行标准化拟合处理,构建具有口腔软硬组织图像数据的影像学资料库；S1.2选定测量截面；分别以颌平面、人体正中线为水平参考平面和垂直参考平面,绘制标准牙弓曲线,并在横断面上选取拟测量牙位,截取牙髓腔最大矢状面作为测量平面,标记,保存；S1.3构建标准化前牙即刻种植相关软硬组织数据库；由受过系统性训练的人员对资料库图像,按照规范化测量标准进行前牙即刻种植相关软硬组织指标测量,构建包含硬组织指标、软组织指标及角度指标在内的标准化测量数据库,与步骤S1.1构建的口腔软硬组织图像数据影像学资料库对应匹配,构建标准化前牙即刻种植相关软硬组织数据库；S2、构建以Resnet卷积神经网络为基础的软硬组织测量模型；具体包括以下步骤：S2.1搭建具备模型拟合及截面选取能力的Resnet神经网络；构建包含多层卷积层的Resnet神经网络,输入原始口腔硬组织数据DICOM文件、口腔表面数据STL文件及对应的模型拟合数据、标准牙弓曲线及矢状测量截面,通过对原始数据三维拟合及归一化处理,搭建具备模型拟合及截面选取能力的Resnet神经网络并输出与输入文件对应的矢状测量截面；S2.2搭建具备图像识别与测量分析能力的Resnet神经网络；构建包含多层卷积层的Resnet神经网络,输入步骤S1建立的标准化前牙即刻种植相关软硬组织数据库及步骤S2.1所述的矢状测量截面,并通过数据扩增及超参数的调整对包含多层卷积层的Resnet神经网络进行训练和优化,最终构建具备即刻种植相关软硬组织测量的AI算法；S3、构建上前牙即刻种植相关软硬组织指标AI测量系统,具体包括以下步骤：S3.1输入患者信息；在步骤S2中搭建的Resnet神经网络内输入包含患者口腔硬组织数据的DICOM文件及口腔表面数据的STL文件；S3.2 Resnet神经网络输出；通过Resnet卷积神经网络,输出具有口腔软硬组织图像的影像学数据、标准牙弓曲线、上前牙矢状测量截面以及相应硬组织指标、软组织指标和角度指标的测量结果；S3.3临床医生根据人工智能测量系统得到的前牙即刻种植相关软硬组织及角度数据后,对患者进行前牙美学区即刻种植治疗方案的制定。</td>   <td>G06T7/00;G06T7/60;G06N3/0464;G16H30/00;G16H50/80;A61C8/00;A61C19/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         祁胜亮;                   黄华兵       </td>   <td>中山大学</td>   <td>一种基于深度学习的森林砍伐变化的检测方法及装置</td>   <td>广东省</td>   <td>CN114708514B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于深度学习的森林砍伐变化的检测方法及装置,所述方法包括：分别获取第一SAR图像数据集和第二光学图像数据集,并对所述第一SAR图像数据集进行去除噪声等预处理,得到第一处理图像数据集；基于第一处理图像数据集的极化波段构建特征图像集,以及基于第一处理图像数据集和第二光学图像数据集中的森林砍伐变化内容构建特征标注信息；利用所述特征图像集和所述特征标注信息对预设的深度学习模型进行模型训练得到训练模型,并使用所述训练模型检测森林砍伐的变化状态。本发明可以在采集图像数据后,对图像数据进行去除噪声等预处理,并利用处理后的数据对深度学习模型进行模型训和变化检测,从而能减少噪声的干扰,提高检测的准确率。</td>   <td>1.一种基于深度学习的森林砍伐变化的检测方法,其特征在于,所述方法包括：分别获取第一SAR图像数据集和第二光学图像数据集,并对所述第一SAR图像数据集进行去除噪声预处理,得到第一处理图像数据集；基于所述第一处理图像数据集的极化波段构建特征图像集,以及基于所述第一处理图像数据集和第二光学图像数据集中的森林砍伐变化内容构建特征标注信息；利用所述特征图像集和所述特征标注信息对预设的深度学习模型进行模型训练得到训练模型,并使用所述训练模型检测森林砍伐的变化状态；所述第一处理图像数据集包括训练数据集和测试数据集；所述基于所述第一处理图像数据集的极化波段构建特征图像集,包括：任意选择同一地点的两个不同时间节点,按照所述两个时间节点从所述第一处理图像数据集提取第一图像波段集,所述第一图像波段集包括垂直发射且水平接收的极化波段,以及垂直发射且垂直接收的极化波段；计算所述第一图像波段集中每个所述极化波段的变异系数,并利用所述变异系数构建对应的变异系数图；将所述第一图像波段集的极化波段合并得到合并特征图,以所述变异系数图和所述合并特征图合并为特征图像集。</td>   <td>G06V20/13;G06V10/26;G06N3/0464;G06N3/08;G06V10/774;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         付青;              苏奕星;                   陈一山       </td>   <td>中山大学</td>   <td>一种基于逆向预测历史数据集的光伏功率预测方法及系统</td>   <td>广东省</td>   <td>CN114881341B</td>   <td>2023-04-07</td>   <td>本发明提出一种基于逆向预测历史数据集的光伏功率预测方法及系统,涉及光伏发电的技术领域,从获取的数据中选取自最新时刻开始,一定逆向时间跨度的历史数据集,以逆向滚动预测过去的光伏功率,避免每次均对所有不同时间跨度的历史数据集进行预测的繁复计算方式,初步降低光伏功率预测的计算量,而后以逆向滚动预测确定的历史数据集样本数目为基础点,搜寻最佳历史数据集样本数目,优化用于光伏预测的历史数据集,进一步提升后续光伏功率预测的精度。</td>   <td>1.一种基于逆向预测历史数据集的光伏功率预测方法,其特征在于,包括：S1.从光伏发电的历史数据库中获取数据,并从获取的数据中选取自最新时刻开始,一定逆向时间跨度的历史数据集；S2.选定光伏预测算法,利用历史数据集的数据逆向滚动预测过去的光伏功率,将光伏功率逆向滚动预测结果与对应的逆向时刻的实际光伏功率结果比较,比较结果用预测误差指标表示,得到预测误差指标随逆向时间跨度变化的趋势曲线；S3.确定预测误差指标随逆向时间跨度变化的趋势曲线中的最低点对应的逆向时间跨度,得出逆向时间跨度对应的历史数据集样本数目；S4.以S3确定的历史数据集样本数目为基础点,搜寻最佳历史数据集样本数目；S5.以最佳的历史数据集样本数目对应的历史数据集进光伏功率预测。</td>   <td>G06Q10/04;G06Q50/06;G06F16/9537</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   熊少堂       </td>   <td>中山大学</td>   <td>一种回报期与预报期观测降水一致性检验方法及系统</td>   <td>广东省</td>   <td>CN115934764A</td>   <td>2023-04-07</td>   <td>本发明提出一种回报期与预报期观测降水一致性检验方法与系统,包括全球降水站点观测栅格数据；将进行降水一致性检验空间区域内的降水数据划分为回报期降水数据和预报期降水数据；对回报期降水数据的总体分布和预报期降水数据的总体分布进行检验,若回报期降水数据的总体分布与预报期降水数据的总体分布存在差异,则判断回报期与预报期的降水一致性发生变化；基于自举法计算回报期降水数据和预报期降水数据均值变化和方差变化,根据所述均值变化和方差变化判别回报期与预报期的降水一致性变化的类型。本发明能够判断不同时期的水文要素时间序列一致性是否发生变化,有助于对长时间的水文要素时间序列系统进行分析。</td>   <td>1.一种回报期与预报期观测降水一致性检验方法,其特征在于,包括以下步骤：选定进行降水一致性检验的空间区域和时间范围；获取全球降水站点观测栅格数据；根据选定的空间区域对所述全球降水站点观测栅格数据进行空间维度的裁剪,得到选定的空间区域内的降水数据；根据选定的时间范围,将选定的空间区域内的降水数据划分为回报期降水数据和预报期降水数据；对回报期降水数据的总体分布和预报期降水数据的总体分布进行检验,若回报期降水数据的总体分布与预报期降水数据的总体分布存在差异,则判断回报期与预报期的降水一致性发生变化；当判断回报期与预报期的降水一致性发生变化时,基于自举法计算回报期降水数据和预报期降水数据均值变化和方差变化,根据所述均值变化和方差变化判别回报期与预报期的降水一致性变化的类型。</td>   <td>G06F16/2455;G06F16/29;G01W1/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈志广;              卢宇彤;              肖敏广;              刘志勇;                   翁灵玲       </td>   <td>中山大学</td>   <td>一种基于众核处理器集群的等值面图可视化方法及系统</td>   <td>广东省</td>   <td>CN115935034A</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于众核处理器集群的等值面图可视化方法及系统,本发明方法包括：各计算节点并行读取各自的点集数据；各计算节点分别通过多核并行的方式首先沿着体素X-Y-Z三条边的方向计算各层数据分片中等值点的位置偏移量,然后并行遍历计算体素中各个边上的等值点的坐标,最后并行遍历各体素连接三个等值点构建三角形图元并形成局部等值面；合并各计算节点的局部等值面,绘制全局等值面,并输出等值面图。本发明能够利用众核处理器集群的多计算节点、各个计算节点的多核心实现等值面图可视化的并行化执行,所需辅助内存少,减少了冗余计算,能够有效提升等值面图可视化的效率,尤其适合用于大规模数据集的等值面图可视化处理。</td>   <td>1.一种基于众核处理器集群的等值面图可视化方法,其特征在于,包括：S101,各计算节点并行读取各自的点集数据；S102,各计算节点分别将点集数据沿着X-Y-Z三条边中任一者的方向划分为多层数据分片,根据点集数据以及预设的等值面阈值集合,通过多核并行的方式沿着体素X-Y-Z三条边的方向计算各层数据分片中等值点的位置偏移量；S103,各计算节点分别根据点集数据以及预设的等值面阈值集合,通过多核并行的方式遍历计算体素中各个边上的等值点的坐标；S104,各计算节点分别根据各层数据分片的位置偏移量以及等值点的坐标,通过多核并行的方式遍历各体素,依次连接三个等值点构建三角形图元,最终形成局部等值面；S105,合并各计算节点的局部等值面,绘制全局等值面,并输出等值面图。</td>   <td>G06F16/904;G06F9/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴文斌;              姜乃斌;              李捷;              马宇;                   王亚辉       </td>   <td>中山大学</td>   <td>一种基于特征线的空间区域分解并行加速方法及系统</td>   <td>广东省</td>   <td>CN115935598A</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于特征线的空间区域分解并行加速方法及系统,该方法包括：通过特征线方法对反应堆堆芯进行计算,得到细网格与特征线段；获取特征线与细网格交点的出射角通量并进行计算,得到细网格的平均标通量；通过内外迭代策略对细网格的平均标通量进行求解,得到中子标通量分布和堆芯增值因子。通过使用本发明,通过并行广义极小残差算法,加速空间区域分解内界面角通量的收敛,提高收敛速率,进而提高空间区域分解并行MOC方法的计算效率。本发明作为一种基于特征线的空间区域分解并行加速方法及系统,可广泛应用于核反应堆堆芯设计和反应堆物理数值计算领域。</td>   <td>1.一种基于特征线的空间区域分解并行加速方法,其特征在于,包括以下步骤：通过特征线方法对反应堆堆芯进行计算,得到细网格与特征线段；获取特征线与细网格交点的出射角通量并进行计算,得到细网格的平均标通量；通过内外迭代策略对细网格的平均标通量进行求解,得到中子标通量分布和堆芯增值因子。</td>   <td>G06F30/20;G06F17/12;G06F17/10;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              徐福仁;              林昊;              蔡倬;              张文锋;                   纳颖泉       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>多任务模型生成方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115935991A</td>   <td>2023-04-07</td>   <td>本申请涉及一种多任务生成模型方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取第二语言表征模型；基于第二历史文本数据的原始训练集和第二语言表征模型得到中间语言表征模型和中间语义向量；基于中间语义向量和原始实体识别模型得到中间实体识别模型；基于中间语义向量和原始情感分析模型得到中间情感分析模型；将中间语言表征模型分别与中间实体识别模型和中间情感分析模型连接组成多任务模型,基于原始训练集和多任务模型生成多个候选多任务模型；基于第二历史文本数据的测试集对各个候选多任务模型评估,计算各个候选多任务模型的评价结果；基于评价结果确定目标多任务模型。采用本方法能提高挖掘文本语义信息的效率。</td>   <td>1.一种多任务模型生成方法,其特征在于,所述方法包括：获取第一语言表征模型,所述第一语言表征模型是基于第一历史文本数据对原始语言表征模型训练得到的；获取第二语言表征模型,所述第二语言表征模型是通过第二历史文本数据对应的增强训练集对第一语言表征模型进行训练得到的；基于所述第二历史文本数据对应的原始训练集对所述第二语言表征模型进行训练,得到中间语言表征模型和所述原始训练集对应的中间语义向量；基于所述中间语义向量对原始实体识别模型进行训练,得到中间实体识别模型；基于各个所述中间语义向量对原始情感分析模型进行训练,得到中间情感分析模型；将所述中间语言表征模型分别与中间实体识别模型和中间情感分析模型连接组成多任务模型,基于所述原始训练集对所述多任务模型进行多次训练,生成对应的多个候选多任务模型；基于所述第二历史文本数据对应的测试集对各个所述候选多任务模型进行测试评估,记录各个候选多任务模型对应的中间实体识别模型的第一评价结果和中间情感分析模型的第二评价结果；基于所述第一评价结果和第二评价结果从所述多个候选多任务模型中确定目标多任务模型。</td>   <td>G06F40/295;G06F40/30;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              欧广盛;              林昊;              赵山河;              张文锋;                   林华春       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>资源处理方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115936701A</td>   <td>2023-04-07</td>   <td>本申请涉及一种资源处理方法、装置、计算机设备和存储介质。方法包括：从原始属性信息中提取原始资源,从资源提供方的资源方账户中转移原始资源到智能合约中进行存储；获取中间方的第一状态信息；对资源转移发起方进行身份认证,记录当前时间戳；在身份认证通过的情况下,当资源转移发起方为中间方时,获取中间方的目标属性信息；根据目标属性信息、当前时间戳和原始属性信息进行比较,得到比较结果；当比较结果表征允许资源转移时,且中间方的第一状态信息为正常状态时,根据原始属性信息从原始资源中转移第一目标资源至中间方对应的中间方账户中,并对原始资源和目标属性信息进行更新。采用本方法能够提高交易的安全性和交易的效率。</td>   <td>1.一种基于区块链的资源处理方法,其特征在于,所述方法包括：将预设的原始属性信息存储在智能合约中,从所述原始属性信息中提取得到产品需求方向资源提供方请求借调的原始资源,并从所述资源提供方对应的资源方账户中转移所述原始资源到所述智能合约中进行存储；获取所述产品需求方提供的中间方的第一状态信息；响应于资源转移发起方的资源转移请求,对所述资源转移发起方进行身份认证,并记录当前时间戳；在身份认证通过的情况下,当所述资源转移发起方为所述中间方时,获取所述中间方的目标属性信息；根据所述目标属性信息、所述当前时间戳和所述原始属性信息进行比较,得到比较结果；当所述比较结果表征允许资源转移时,且所述中间方的第一状态信息为正常状态时,根据所述原始属性信息从存储在所述智能合约中的原始资源中转移第一目标资源至所述中间方对应的中间方账户中,并对所述原始资源和所述目标属性信息进行更新。</td>   <td>G06Q20/38;G06Q20/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴瑞臻;              刘华清;              张智;              陆正齐;                   韩蓝青       </td>   <td>中山大学附属第三医院;清华珠三角研究院</td>   <td>脑小血管病的类型检测方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN115937159A</td>   <td>2023-04-07</td>   <td>本申请公开了一种脑小血管病的类型检测方法、装置、设备及介质,该方法获取待检测目标的MRI图像和临床信息；MRI图像包括多层图像切片；将MRI图像输入到出血点检测模型中,通过出血点检测模型检测各层图像切片中的出血点,并生成和每层图像切片一一对应的出血点掩膜图像；对各层所述图像切片和对应的出血点掩膜图像进行合并,得到第一双通道图像,并提取所述第一双通道图像的第一图像特征；对所述第一图像特征进行融合处理,将得到的第一融合图像特征和临床信息输入到分类器中,得到待检测目标对应的脑小血管病的类型检测结果。该方法可高效、准确、快速地辅助病理诊断,有利于减轻医务人员的工作负担。本申请可广泛应用于人工智能技术领域内。</td>   <td>1.一种脑小血管病的类型检测方法,其特征在于,所述方法包括：获取待检测目标的MRI图像和临床信息；所述MRI图像包括多层图像切片；将所述MRI图像输入到出血点检测模型中,通过所述出血点检测模型检测各层所述图像切片中的出血点,并生成和每层所述图像切片一一对应的出血点掩膜图像；对各层所述图像切片和对应的出血点掩膜图像进行合并,得到第一双通道图像,并提取所述第一双通道图像的第一图像特征；对所述第一图像特征进行融合处理,得到第一融合图像特征；将所述第一融合图像特征和所述临床信息输入到分类器中,得到所述待检测目标对应的脑小血管病的类型检测结果。</td>   <td>G06T7/00;G06T7/73;G06V10/40;G06V10/764;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗玉;              陈炫荣;              凌捷;                   姚顺       </td>   <td>广东工业大学;中山大学附属第一医院</td>   <td>一种3DCNN和放射组学垂体瘤分型评估方法、系统和存储介质</td>   <td>广东省</td>   <td>CN115937181A</td>   <td>2023-04-07</td>   <td>本发明公开的一种3DCNN和放射组学垂体瘤分型评估方法、系统和存储介质,所述方法包括：在医学影像之中提取三维肿瘤区域,首先利用传统影像组学方法进行固定特征提取；随后从三维肿瘤区域之中提取出多个三维肿瘤子区域,并将其输入到3D-CNN之中进行三维特征提取；最后,融合3D-CNN影像特征、传统影像组学特征和临床信息对患者的脑肿瘤分型进行建模预测。此外,为增加3D-CNN特征提取的准确性和可解释性,构造一个辅助任务来协助3D-CNN对脑肿瘤特征的学习和刻画,该辅助任务和主线预测任务共享网络的前几层,使得网络更具方向性和针对性。本发明通过获取的脑肿瘤患者的医学影像信息进行肿瘤分型预测,有更高的准确率和适用性。</td>   <td>1.一种3DCNN和放射组学垂体瘤分型评估方法,其特征在于,包括：获取医学影像(SPGR)；对所述医学影像(SPGR)进行肿瘤切割,得到完整的三维肿瘤区域；对所述完整的三维肿瘤区域进行分割,得到多个三维肿瘤子区域；将所述多个三维肿瘤子区域输入到预设的3DCNN模型,得到预测垂体瘤分型信息。</td>   <td>G06T7/00;G06T7/11;G06T17/00;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张琳;              杨易木;              李雁;              王铭辉;              林华月;              谭炳华;              梁春豪;              许可;                   雷凯       </td>   <td>中山大学</td>   <td>基于多尺度融合和注意力机制的肺癌病理图像分类系统</td>   <td>广东省</td>   <td>CN115937576A</td>   <td>2023-04-07</td>   <td>本发明提出一种基于多尺度融合和注意力机制的肺癌病理图像分类系统,涉及病理图像处理的技术领域,解决了在当前癌病理图像分类的方式中,分类效率低,不利于病理诊断的问题,首先构建肺癌病理图像分类模型,肺癌病理图像分类模型包含依次连接的多尺度特征提取和融合模块及基于注意力机制的特征聚合模块,利用了多尺度融合的方式增强模型的鲁棒性,进一步结合基于注意力机制的特征聚合模块,提高了模型的灵活性和自适应性,接着对构建的肺癌病理图像分类模型进行训练,利用训练好的肺癌病理图像分类模型对肺癌病理图像进行分类,优化了肺癌病理图像分类模型的结构,降低训练复杂度,提高训练速度,从而提升了肺癌诊断效率和分类精度。</td>   <td>1.一种基于多尺度融合和注意力机制的肺癌病理图像分类系统,其特征在于,所述系统包括：病理图像采集模块,用于获取肺癌病理图像,组成第一图像数据集；病理图像处理模块,用于对第一图像数据集中的肺癌病理图像进行预处理,得到第二图像数据集；肺癌病理图像分类模型构建模块,用于构建肺癌病理图像分类模型,所述肺癌病理图像分类模型包括依次连接的多尺度特征提取融合模块及基于注意力机制的特征聚合模块；训练模块,利用第二图像数据集对构建的肺癌病理图像分类模型进行训练,得到训练好的肺癌病理图像分类模型,所述训练好的肺癌病理图像分类模型用于肺癌病理图像的分类。</td>   <td>G06V10/764;G06V10/25;G06V10/774;G06V10/80;G06V10/82;G06N3/045;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李颖;              李郇;              江千腾;              王永甜;              陈銮;                   李敏胜       </td>   <td>奥格科技股份有限公司;中山大学</td>   <td>一种基于社交媒体图片数据的乡村地理标签更新方法</td>   <td>广东省</td>   <td>CN115937668A</td>   <td>2023-04-07</td>   <td>本发明针对现有技术的局限性,提出了一种基于社交媒体图片数据的乡村地理标签更新方法,通过将多种深度学习方法相结合,在保证预测效率的前提下,提高了预测准确率；其能够自动更新图片标签,同时针对多种不同的场景进行分类,适用性广、有效提高了乡村地理标签更新效率,降低了人工成本和工作强度。</td>   <td>1.一种基于社交媒体图片数据的乡村地理标签更新方法,其特征在于,包括以下步骤：S1,获取由社交媒体采集到的包含乡村地理内容的待预测图像；S2,将所述待预测图像输入经过预设的目标检测数据集训练过的目标检测网络中,检测出所述待预测图像中包含的乡村设施,获得所述待预测图像关于乡村设施场景的分类结果；S3,将所述待预测图像输入经过预设的多标签分类数据集训练过的多标签分类网络中,获得所述待预测图像关于乡村环境场景的分类结果；S4,对所述步骤S2以及S3的分类结果合并,完成对所述待预测图像的乡村地理标签更新。</td>   <td>G06V20/10;G06V10/764;G06V10/774;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              陈泓栩;              卢知之;                   谢晓华       </td>   <td>中山大学</td>   <td>一种端到端的集装箱号码识别方法及系统</td>   <td>广东省</td>   <td>CN115937862A</td>   <td>2023-04-07</td>   <td>本发明公开了一种端到端的集装箱号码识别方法及系统,该方法包括：将集装箱图片输入至预训练的识别模型；基于显著性前景感知网络对输入图片进行特征提取和分割；基于LSTM网络对文本显著性特征图进行字符增强；基于位置编码层对时间步长进行编码并输出查询向量；基于自注意力机制模型,以文本显著性特征图作为值输入、字符增强特征作为键输入、查询向量作为查询输入,输出特征向量；基于线性层对特征向量进行输出,得到识别结果。该系统包括：输入模块、显著性前景感知模块、字符特征增强模块、位置编码模块、自注意力机制模块和线性输出模块。通过使用本发明,能够准确定位并识别出集装箱号码和集装箱尺寸,可广泛应用于数据识别领域。</td>   <td>1.一种端到端的集装箱号码识别方法,其特征在于,包括以下步骤：获取集装箱图片并将集装箱图片输入至预训练的识别模型；基于显著性前景感知网络对输入图片进行特征提取和分割,得到文本显著性特征图；基于LSTM网络对文本显著特征图进行字符增强,得到字符增强特征；基于位置编码层对时间步长进行编码并输出查询向量；基于自注意力机制模型,以文本显著性特征图作为值输入、字符增强特征作为键输入、查询向量作为查询输入,输出特征向量；基于线性层对特征向量进行输出,得到识别结果。</td>   <td>G06V30/148;G06V30/18;G06V30/19</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚和瑞;              欧阳能太;              余运芳;                   谭钰洁       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>宫颈液基薄层细胞学的辅助筛查系统、应用方法及模型</td>   <td>广东省</td>   <td>CN115938561A</td>   <td>2023-04-07</td>   <td>本发明公开了一种宫颈液基薄层细胞学的辅助筛查系统、应用方法及模型,所述系统包括：收集模块,用于收集海量扫描的宫颈液基薄层细胞学的电子图像；标注模块,识别每张电子图像的异常细胞,在电子图像中勾画异常细胞,并对异常细胞添加真实标签；训练模块,用于对异常细胞对应的真实标签进行模型训练得到细胞级诊断模型,利用细胞级诊断模型输出的信息训练得到片级诊断模型；诊断与筛查模块,用于利用片级诊断模型进行细胞的诊断与筛查；诊断效能模块,用于分别获取比较筛查结果、辅助筛查结果以及诊断筛查结果,分别计算每个结果的诊断效能。本发明可以增加模型的识别能力,也可以进一步提高模型的识别能力,提高识别的准确率和识别效率。</td>   <td>1.一种宫颈液基薄层细胞学的辅助筛查系统,其特征在于,所述系统包括：收集模块,用于收集海量扫描的宫颈液基薄层细胞学的电子数字图像,其中,每张所述扫描电子图像包括多种不同的细胞；标注模块,识别每张所述电子图像的异常细胞,在所述电子图像中勾画所述异常细胞,并对所述异常细胞添加真实标签；训练模块,用于基于预设的深度学习算法对所述异常细胞对应的真实标签进行模型训练得到细胞级诊断模型,以所述细胞级诊断模型输出的信息作为输入信息训练得到片级诊断模型；诊断与筛查模块,用于利用所述片级诊断模型进行细胞的诊断与筛查；诊断效能模块,用于分别获取比较筛查结果、辅助筛查结果以及诊断筛查结果,分别计算所述比较筛查结果、所述辅助筛查结果和所述诊断筛查结果的诊断效能,其中,所述比较筛查结果、所述辅助筛查结果和所述诊断筛查结果为采集批量标准患者的数据并按照等比例划分后,分别通过比较筛查员、辅助筛查员和所述片级诊断模型作诊断筛查得到。</td>   <td>G16H50/20;G16H30/00;G06T7/00;G06T7/10;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙伟;                   李创丰       </td>   <td>中山大学</td>   <td>一种基于混合特征的多架构物联网恶意应用分析方法</td>   <td>广东省</td>   <td>CN115906070A</td>   <td>2023-04-04</td>   <td>本发明公开了一种基于混合特征的多架构物联网恶意应用分析方法,涉及物联网安全领域,具体步骤为：S1.获取训练用的恶意应用样本和待分析的恶意应用样本；S2.对得到的训练用的恶意应用样本和待分析的恶意应用样本进行自动分析,并得到训练用的自动分析结果和待分析的自动分析结果；S3.对得到的训练用的自动分析结果和待分析的自动分析结果进行特征工程,得到训练用的样本混合特征和待分析的样本混合特征；S4.根据得到的训练用的样本混合特征训练机器学习模型,得到训练好的机器学习模型；S5.将得到的待分析的自动分析结果和待分析的样本混合特征,输入步骤S4训练好的机器学习模型对待分析的恶意应用样本的家族进行分类。本发明解决了现有技术检测步骤繁琐,效率低下,准确度低的问题,且具有步骤简单,效率高,准确度高的特点。</td>   <td>1.一种基于混合特征的多架构物联网恶意应用分析方法,其特征在于：具体步骤为：S1.获取训练用的恶意应用样本和待分析的恶意应用样本；S2.对得到的训练用的恶意应用样本和待分析的恶意应用样本进行自动分析,并得到训练用的自动分析结果和待分析的自动分析结果；S3.对得到的训练用的自动分析结果和待分析的自动分析结果进行特征工程,得到训练用的样本混合特征和待分析的样本混合特征；S4.根据得到的训练用的样本混合特征训练机器学习模型,得到训练好的机器学习模型；S5.将得到的待分析的自动分析结果和待分析的样本混合特征,输入步骤S4训练好的机器学习模型对待分析的恶意应用样本的家族进行分类。</td>   <td>G06F21/56;G06F21/55;G06F21/53;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘鲁华;              黄祺威;                   邓泽晓       </td>   <td>中山大学</td>   <td>一种基于数据库的弹道诸元快速解算方法</td>   <td>广东省</td>   <td>CN115906269A</td>   <td>2023-04-04</td>   <td>本发明公开了一种基于数据库的弹道诸元快速解算方法,该方法包括：构建助推滑翔导弹的助推段运动模型；基于助推段运动模型,设定助推段飞行程序,得到助推段终端状态；通过自适应网格剖分方法对助推段终端状态进行剖分处理,得到网格特征点；根据网格特征点上的助推段终端状态,确定助推段的弹道诸元数据,构建诸元数据库,通过对目标的助推段终端状态临近的四个特征点进行插值处理,得到助推滑翔导弹助推段弹道诸元。通过使用本发明,使得导弹能够在适应不同的飞行任务时进一步提高其弹道诸元的解算速度与减小飞行高度的误差。本发明作为一种基于数据库的弹道诸元快速解算方法,可广泛应用于导弹以及运载火箭助推段制导技术领域。</td>   <td>1.一种基于数据库的弹道诸元快速解算方法,其特征在于,包括以下步骤：构建助推滑翔导弹的助推段运动模型；基于助推段运动模型,设定助推段飞行程序,得到助推段终端状态；通过自适应网格剖分方法对助推段终端状态进行剖分处理,得到网格特征点；根据网格特征点以及助推段终端状态,确定助推段的弹道诸元数据,构建诸元数据库；基于诸元数据库,通过对助推段终端状态临近的四个特征点进行插值处理,得到助推滑翔导弹助推段弹道诸元。</td>   <td>G06F30/15;G06F30/23;G06F16/58;G06T17/20;G06F111/10;G06F111/04;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李贺;              黄承赓;              彭卫文;              古博;              韩瑜;                   欧阳孔雷       </td>   <td>中山大学</td>   <td>基于定位精度可靠性的工业机器人公差设计方法及系统</td>   <td>广东省</td>   <td>CN115906536A</td>   <td>2023-04-04</td>   <td>本发明公开了基于定位精度可靠性的工业机器人公差设计方法及系统,该方法包括：对工业机器人连杆坐标系的齐次变换矩阵进行微分变换处理,构建定位精度极限状态函数；建立工业机器人公差设计的内外试验表；根据内外试验表和定位精度极限状态函数,计算工业机器人定位精度的失效概率；根据信噪比计算公式和定位精度失效概率对运动学参数公差重要性进行排序并指导工业机器人运动学参数公差方案的设计。通过使用本发明,能够收紧和放松工业机器人各个部件的运动学参数公差,在相同的生产条件下有效提高工业机器人的定位精度。本发明作为基于定位精度可靠性的工业机器人公差设计方法及系统,可广泛应用于工业机器人公差设计技术领域。</td>   <td>1.基于定位精度可靠性的工业机器人公差设计方法,其特征在于,包括以下步骤：对工业机器人连杆坐标系的齐次变换矩阵进行微分变换处理,构建定位精度极限状态函数；根据正交试验法和均匀试验法,建立工业机器人公差设计的内外试验表；根据工业机器人公差设计的内外试验表和定位精度极限状态函数,计算工业机器人定位精度的失效概率；根据信噪比计算公式和定位精度失效概率对运动学参数公差重要性进行排序,实现指导工业机器人运动学参数公差方案的设计。</td>   <td>G06F30/20;G06F30/17;G06F17/16;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴文斌;              郑竞超;              王志强;              谢择怿;              潘依婷;              姜乃斌;              李捷;              马宇;                   王亚辉       </td>   <td>中山大学</td>   <td>一种六角形堆芯MOC并行计算的通信优化方法及系统</td>   <td>广东省</td>   <td>CN115907188A</td>   <td>2023-04-04</td>   <td>本申请属于六角形堆芯计算技术领域,公开了一种六角形堆芯MOC并行计算的通信优化方法及系统。该方法通过对六角形堆芯进行几何预处理,得到所述六角形堆芯中所有六角形组件的进程编号；基于所述进程编号,确定所有六角形组件的需要进行通讯任务的相邻六角形组件的进程编号,进行通信任务分析,生成邻边关系文件；将所述邻边关系文件转化为图文件,将所述图文件输入到图划分程序中进行节点分布的划分,得到图划分结果；根据所述图划分结果,对六角形堆芯的所有六角形组件的通讯任务进行节点划分。实现在各节点计算任务均匀分配的前提下使得通信任务尽可能在节点内进行,提升通信任务的并行效率。</td>   <td>1.一种六角形堆芯MOC并行计算的通信优化方法,其特征在于,所述方法包括：对六角形堆芯进行几何预处理,得到所述六角形堆芯中所有六角形组件的进程编号；基于所述进程编号,确定所有六角形组件的需要进行通讯任务的相邻六角形组件的进程编号,进行通信任务分析,生成邻边关系文件；将所述邻边关系文件转化为图文件,将所述图文件输入到图划分程序中进行节点分布的划分,得到图划分结果；根据所述图划分结果,对六角形堆芯的所有六角形组件的通讯任务进行节点划分。</td>   <td>G06Q10/04;G06F30/20;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         涂新军;              周宗林;              王天;              陈晓宏;              林凯荣;                   刘智勇       </td>   <td>中山大学</td>   <td>一种社会经济干旱评估方法</td>   <td>广东省</td>   <td>CN115907286A</td>   <td>2023-04-04</td>   <td>本发明公开了一种社会经济干旱评估方法,涉及干旱评估领域,包括以下步骤：S1：根据流域水资源的供水和需水关系,计算流域水资源供需可靠性指数WSDRI；S2：采用对数Logistic分布函数对水资源供需可靠性指数WSDRI拟合后进行标准化转换,得到标准化水资源供需可靠性指数SWSDRI；S3：采用游程理论提取社会经济干旱事件,识别社会经济干旱属性,得到干旱历时和干旱烈度；S4：通过Copula函数,模拟干旱历时和干旱烈度的联合分布,计算联合超越概率；S5：基于干旱历时和干旱烈度的联合超越概率,划分社会经济干旱等级。本发明从天然情形出发,考虑到不同流域干旱缺水时的严重程度,为流域干旱评估和水资源风险管理提供技术支撑。</td>   <td>1.一种社会经济干旱评估方法,其特征在于,包括以下步骤：S1：根据流域水资源的供水和需水关系,计算流域水资源供需可靠性指数WSDRI；S2：采用对数Logistic分布函数对水资源供需可靠性指数WSDRI拟合后进行标准化转换,得到标准化水资源供需可靠性指数SWSDRI；S3：采用游程理论提取社会经济干旱事件,识别社会经济干旱属性,得到干旱历时和干旱烈度；S4：通过Copula函数,模拟干旱历时和干旱烈度的联合分布,计算联合超越概率；S5：基于干旱历时和干旱烈度的联合超越概率,划分社会经济干旱等级。</td>   <td>G06Q10/063;G06Q50/06;G06Q50/26;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李磊鑫;              张云青;              谢俊琨;                   刘坤华       </td>   <td>中山大学</td>   <td>一种面向低重叠率的点云配准方法</td>   <td>广东省</td>   <td>CN115908112A</td>   <td>2023-04-04</td>   <td>本发明提出一种面向低重叠率的点云配准方法,涉及三维点云配准的技术领域,首先采集源点云和目标点云,然后对源点云和目标点云进行特征提取和下采样,对下采样后的点云在点云邻域范围内进行位置编码,提升了特征表达能力,将位置编码结果与特征相加,接着通过注意力模块和最优传输理论结合,提高点云的同名点对位于点云重叠部分的概率,进而提高点云配准精度,基于相似矩阵的最优传输,不但能求出匹配点对,还能筛去缺失对应点的关键点,通过分数机制和空间相容性原理,构建可信点对集合直接求解转换矩阵,缩短点云配准所花费的时间。</td>   <td>1.一种面向低重叠率的点云配准方法,其特征在于,所述方法包括以下步骤：S1.获取源点云数据和目标点云数据；S2.对源点云和目标点云下采样至同一密度后归一化点云,然后对点云进行空间卷积,实现特征提取,获得下采样后的点云及每个点云对应的特征；S3.对下采样后的点云在点云邻域范围内进行位置编码,将位置编码结果与特征相加后,输入注意力模块,输出源点云和目标点云对应的特征；S4.将S3得到的特征做内积,得到相似矩阵,相似矩阵的元素为源点云与目标点云对应点特征的内积,对相似矩阵进行扩充处理后,求解相似矩阵的最优传输,得到分数矩阵；S5.从分数矩阵中确定源点云与目标点云的同名点对集合,从同名点对集合中通过空间相容性进一步筛选出多个可信同名点对集合；S6.对于每个可信同名点对集合,通过分数阈值,确定可信点对集合中分数大于分数阈值的同名点对,然后基于此类同名点对,求得源点云到目标点云的转换矩阵,完成点云配准。</td>   <td>G06T3/00;G06F17/16;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁北辰;              樊天慧;              卢坤炜;              冯国栋;                   陈超核       </td>   <td>中山大学;华南理工大学</td>   <td>一种基于ResNeXt网络的焊缝跟踪方法</td>   <td>广东省</td>   <td>CN115908281A</td>   <td>2023-04-04</td>   <td>本发明公开了一种基于ResNeXt网络的焊缝跟踪方法,方法包括：对所述样本焊缝图像信息进行图像预处理,得到训练集；根据所述训练集,通过ResNeXt网络搭建学习模型进行训练,获得焊缝中心特征提取点模型；根据所述焊缝中心特征提取点模型获取待识别对应的焊缝特征点信息；根据所述焊缝特征点信息,生成机器人控制模块的焊接工作路径；根据所述焊接工作路径控制机器人控制模块的工作。本发明提高了准确率和精度,可广泛应用于图像处理技术领域。</td>   <td>1.一种基于ResNeXt网络的焊缝跟踪方法,其特征在于,包括：采集样本焊缝图像信息；对所述样本焊缝图像信息进行图像预处理,得到训练集；根据所述训练集,通过ResNeXt网络搭建学习模型进行训练,获得焊缝中心特征提取点模型；根据所述焊缝中心特征提取点模型获取待识别对应的焊缝特征点信息；根据所述焊缝特征点信息,生成机器人控制模块的焊接工作路径；根据所述焊接工作路径控制机器人控制模块的工作。</td>   <td>G06T7/00;G06T7/13;G06T7/246;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;                   李浩源       </td>   <td>中山大学</td>   <td>基于时序坐标信息的单阶段多人网格模型构建方法及系统</td>   <td>广东省</td>   <td>CN115908585A</td>   <td>2023-04-04</td>   <td>本发明公开了基于时序坐标信息的单阶段多人网格模型构建方法及系统,方法包括：获取现实场景视频；通过神经网络对现实场景视频进行特征提取,预测人物中心图、相机参数图和人物参数图；利用人物中心热力图对相机参数图和人物参数图进行聚焦处理,并基于神经网络进行空间和时间关系建模,建模人物模型之间的时空联系,预测最终的相机参数图与人物参数图；找出人物中心热力图中判断为人的区域,并索引到对应的相机参数图与人物参数图,生成人物模型。本发明避免了显式检测和显式跟踪带来的算力消耗,实现了人物模型回归的简易性、低算力消耗和精准性,可广泛应用于计算机技术领域。</td>   <td>1.基于时序坐标信息的单阶段多人网格模型构建方法,其特征在于,包括：获取现实场景视频；通过神经网络对所述现实场景视频进行特征提取,并根据提取到的特征预测人物中心图、相机参数图和人物参数图；利用人物中心热力图对所述相机参数图和所述人物参数图进行聚焦处理,并基于神经网络进行空间和时间关系建模,建模人物模型之间的时空联系,预测最终的相机参数图与人物参数图；找出人物中心热力图中判断为人的区域,并索引到对应的相机参数图与人物参数图,生成人物模型。</td>   <td>G06T7/80;G06T3/40;G06T7/246;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓明亮;              李颖;              李郇;              王勉;              江千腾;                   许伟攀       </td>   <td>奥格科技股份有限公司;中山大学</td>   <td>基于AI的建筑平面图参数化识别方法</td>   <td>广东省</td>   <td>CN115908900A</td>   <td>2023-04-04</td>   <td>本发明针对现有技术的局限性,提出了一种基于AI的建筑平面图参数化识别方法；本发明可以只提取需要的构件,剔除掉无关的干扰构件；经过构件间的缝隙消除以及墙体规则化、墙体切割等一系列后处理操作,再参考墙体获取墙柱、门、窗等。最后通过识别比例尺获得每个像素点代表的长度,结合识别出的比例尺和提取出来的墙体、墙柱、门、窗的关键点坐标信息,用于构建三维的建筑模型。本发明可以实现智能地对平面图中构件关键坐标点的快速提取,降低人工识别平面图的成本,提高三维建模构建的效率。</td>   <td>1.一种基于AI的建筑平面图参数化识别方法,其特征在于,包括以下步骤：S1,获取待处理的建筑平面图；S2,运用预设的语义分割模型提取所述建筑平面图中的构件的掩膜,所述构件包括墙体、墙柱、门以及窗；消除所述掩膜之间的缝隙；S3,根据所述步骤S2的结果,获取墙体的拐点坐标；对其中的连接墙体进行分割后,以墙体的拐点坐标作为参考,获取墙柱、门以及窗的坐标；S4,识别所述建筑平面图的比例尺,获得所述建筑平面图一个像素所对应的物理长度；S5,输出所述步骤S3以及S4的结果,完成对所述建筑平面图的参数化识别。</td>   <td>G06V10/764;G06V10/26;G06V10/28;G06V10/762;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭晓军;              石艳丽;              张晓飞;              安亚松;              陈俊峰;                   唐侨       </td>   <td>中山大学;惠州市德赛西威汽车电子股份有限公司</td>   <td>局部-全局自适应引导增强的车辆重识别方法及系统</td>   <td>广东省</td>   <td>CN115909036A</td>   <td>2023-04-04</td>   <td>本发明公开了一种局部-全局自适应引导增强的车辆重识别方法及系统,该方法包括：对训练图像进行图像预处理并构建训练集；基于训练集对局部-全局自适应引导增强的车辆重识别协同表示网络进行训练；所述局部-全局自适应引导增强的车辆重识别协同表示网络包括基于VisionTransformer的骨干网络模块和基于局部注意力引导的自适应优化特征编码模块；获取待查询图像和图库集,对待查询图像在图库集进行检索匹配,得到匹配结果。该系统包括：预处理单元、网络训练单元和检索匹配单元。通过使用本发明,能够提高车辆重识别的精确度。本发明可广泛应用于车辆重识别领域。</td>   <td>1.局部-全局自适应引导增强的车辆重识别方法,其特征在于,包括以下步骤：对训练图像进行图像预处理并构建训练集；基于训练集对局部-全局自适应引导增强的车辆重识别协同表示网络进行训练,得到训练完备的局部-全局自适应引导增强的车辆重识别协同表示网络；所述局部-全局自适应引导增强的车辆重识别协同表示网络包括基于VisionTransformer的骨干网络模块和基于局部注意力引导的自适应优化特征编码模块；获取待查询图像和图库集,并基于训练完备的局部-全局自适应引导增强的车辆重识别协同表示网络对待查询图像在图库集进行检索匹配,得到匹配结果。</td>   <td>G06V20/00;G06V10/774;G06V10/44;G06V10/82;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              陈宇洋;              郭殿升;                   王巨宏       </td>   <td>中山大学;腾讯科技(深圳)有限公司</td>   <td>异常视频的识别方法、装置、设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN115909116A</td>   <td>2023-04-04</td>   <td>本申请公开了一种异常视频的识别方法、装置、设备及计算机可读存储介质,涉及深度学习领域。该方法包括：获取n个样本视频片段,在第i次迭代循环训练过程中,通过第i-1次迭代训练得到的第i个分析模型对样本视频片段进行分析,得到第i组异常预测结果,i≥1且i为整数,对第i组异常预测结果进行平衡分布处理,得到与n个样本视频片段对应的第i组伪标签,基于第i组异常预测结果和第i组伪标签之间的差异,对第i个分析模型进行训练,得到在第i次迭代循环训练过程中的第i+1个分析模型,直至分析模型的训练符合训练结果条件,得到异常分析模型。不仅节省人工标注标签所耗费的人力,还能够提高异常分析模型的识别精度。</td>   <td>1.一种异常视频的识别方法,其特征在于,所述方法包括：获取n个样本视频片段,所述样本视频片段为用于对异常分析模型进行训练的视频帧构成的片段,n≥2且n为整数；在第i次迭代循环训练过程中,通过第i-1次迭代训练得到的第i个分析模型对所述样本视频片段进行分析,得到第i组异常预测结果,i≥1且i为整数；对所述第i组异常预测结果进行平衡分布处理,得到与所述n个样本视频片段对应的第i组伪标签；基于所述第i组异常预测结果和所述第i组伪标签之间的差异,对所述第i个分析模型进行训练,得到在第i次迭代循环训练过程中的第i+1个分析模型,直至所述分析模型的训练符合训练结果条件,得到异常分析模型,所述异常分析模型用于对异常视频进行识别。</td>   <td>G06V20/40;G06V10/82;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢晓华;              张鑫;                   赖剑煌       </td>   <td>中山大学</td>   <td>基于循环条件随机场的跨摄像头群体检测方法</td>   <td>广东省</td>   <td>CN115909198A</td>   <td>2023-04-04</td>   <td>本发明针对现有技术的局限性,提出了一种基于循环条件随机场的跨摄像头群体检测方法,在行人轨迹生成方面,本发明提供的方法不仅能够利用表观相似的行人中行人时空信息生成行人轨迹,还会利用时空概率高的行人中的表观信息来生成行人轨迹,在提高行人轨迹生成准确率的同时,还可以提升行人检索的准确率；在行人轨迹度量方面,本发明提供的方法不仅可以判别不是同一个群体中的行人轨迹,还可以对同个群体中,由于轨迹生成和检索过程中,产生的断连,错连等噪声具有很好的抗噪声能力。</td>   <td>1.一种基于循环条件随机场的跨摄像头群体检测方法,其特征在于,包括以下步骤：S1,获取视频监控摄像头网络的单摄像头跟踪轨迹集合,通过将所述单摄像头跟踪轨迹集合中的时空信息输入预设的时空模型,获得所述单摄像头跟踪轨迹集合的时空概率图；S2,通过将所述单摄像头跟踪轨迹集合中的图像信息输入预设的表观特征模型,获得所述图像信息的表观特征向量；对所述图像信息的表观特征向量进行计算,获得各单摄像头跟踪轨迹的表观特征相似邻接矩阵；S3,以所述表观特征相似邻接矩阵以及时空概率图交替作为被优化矩阵与辅助矩阵,根据从辅助矩阵提取出的邻接信息,迭代执行条件随机场优化；S4,通过对经过所述步骤S3优化后的表观特征相似邻接矩阵进行聚类,获得所述图像信息的行人跨摄像头轨迹；S5,获取待检测群体的行人图片序列；通过将所述行人图片序列输入所述表观特征模型,获得所述行人图片序列的表观特征向量；将行人图片序列的表观特征向量与所述图像信息的表观特征向量进行比较,从所述行人跨摄像头轨迹中获得关于所述行人图片序列中的行人的跨摄像头轨迹检索结果；S6,对各行人的跨摄像头轨迹检索结果进行两两比较,通过判定各行人之间是否有共同的跨摄像头轨迹,进而判断各行人是否属于同一群体。</td>   <td>G06V20/52;G06V20/40;G06V10/40;G06V10/762;G06T7/246;G06F17/16;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              宋鄂;              陆强;                   稂洪水       </td>   <td>深圳市诺龙技术股份有限公司;中山大学·深圳;中山大学</td>   <td>一种基于视频分析的场景变更检测方法与系统</td>   <td>广东省</td>   <td>CN115909219A</td>   <td>2023-04-04</td>   <td>本发明公开了一种基于视频分析的场景变更检测系统、方法、装置和存储介质,包括获取视频图像数据,对视频图像数据进行处理,获取目标要素,按照在视频图像数据中的顺序,遍历各视频帧,根据当前视频帧对应的目标要素与场景基准标的物,确定当前视频帧对应的第一场景相似度,当第一场景相似度小于第一阈值,更新场景基准标的物,反之则维持场景基准标的物不变。本发明基于深度学习提取到的场景中不变要素的深度特征,无需人工设计深度特征,提高了场景描述特征的鲁棒性；保持场景变化判断标准的自动更新,一方面有利于更加精准地判断视频帧是否发生场景变化,另一方面有利于提升场景变更检测自动化程度。本发明广泛应用于图像处理技术领域。</td>   <td>1.一种基于视频分析的场景变更检测方法,其特征在于,所述基于视频分析的场景变更检测方法包括：获取视频图像数据；所述视频图像数据包括多个视频帧；对所述视频图像数据进行处理,获取各所述视频帧各自对应的目标要素；根据所述视频图像数据,设定场景基准标的物的初始值；按照在所述视频图像数据中的顺序,遍历各所述视频帧；对于遍历过程中的任一当前视频帧,根据所述当前视频帧对应的所述目标要素与所述场景基准标的物,确定所述当前视频帧对应的第一场景相似度,当所述第一场景相似度小于第一阈值,更新所述场景基准标的物,反之则维持所述场景基准标的物不变；经过更新或者维持的所述场景基准标的物,用于确定后续视频帧对应的第一场景相似度。</td>   <td>G06V20/52;G06V20/40;G06V10/74;G06V10/764;G06V10/25;G06V10/26;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姜园;                   张皓天       </td>   <td>中山大学</td>   <td>一种基于混沌加权随机融合的射频指纹识别方法</td>   <td>广东省</td>   <td>CN115909423A</td>   <td>2023-04-04</td>   <td>本发明公开一种基于混沌加权随机融合的射频指纹识别方法,包括：S1：采集各电台个体的射频信号；S2：对采集得到的射频信号进行预处理,得到射频指纹数据集；S3：将所述射频指纹数据集划分为训练集和测试集；S4：从所述训练集中选择指定数量的原始样本,利用混沌序列对所述原始样本进行加权融合,产生新样本,并得到增强后的训练集；S5：利用增强后的数据集训练神经网络,得到训练好的神经网络；S6：利用所述测试集对训练好的神经网络进行性能检验；S7：利用通过性能检验的神经网络实现射频指纹识别。本发明将随机特性良好的混沌序列与RI算法结合,从而提升生成样本的多样性与最大数量,具有更好的识别准确率与鲁棒性。</td>   <td>1.一种基于混沌加权随机融合的射频指纹识别方法,其特征在于,包括以下步骤：S1：采集各电台个体的射频信号；S2：对采集得到的射频信号进行预处理,得到射频指纹数据集；S3：将所述射频指纹数据集划分为训练集和测试集；S4：从所述训练集中选择指定数量的原始样本,利用混沌序列对所述原始样本进行加权融合,产生新样本,并得到增强后的训练集,所述混沌序列由混沌生成函数生成；S5：利用增强后的数据集训练神经网络,得到训练好的神经网络,所述神经网络根据输入的射频指纹,输出射频指纹对应的电台标号；S6：利用所述测试集对训练好的神经网络进行性能检验；S7：利用通过性能检验的神经网络实现射频指纹识别。</td>   <td>G06V40/12;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王茂华;              虞幼军;              陈学华;              孙恺;                   谭玲梅       </td>   <td>佛山市第一人民医院(中山大学附属佛山医院)</td>   <td>耳科问诊辅助方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN115910319A</td>   <td>2023-04-04</td>   <td>本申请涉及医疗信息化技术领域,尤其是一种耳科问诊辅助方法、装置、电子设备及存储介质。该方法包括：采集问诊中的语音数据；采集病人的体征数据和身份数据；根据所述语音数据和所述体征数据获得问诊中生成的即时病历信息；根据所述身份数据从预先构建的数据库中获得病人的历史病历信息,获取所述病人的历史病历信息对应的历史处理策略信息；根据所述病人的历史病历信息对应的历史处理策略信息生成与所述即时病历信息对应的即时处理策略信息。本申请的技术方案无需全程依赖于医生个人,通过问诊时的智能化大大提高了问诊效率。</td>   <td>1.一种耳科问诊辅助方法,其特征在于,包括：采集问诊中的语音数据；采集病人的体征数据和身份数据；根据所述语音数据和所述体征数据获得问诊中生成的即时病历信息；根据所述身份数据从预先构建的数据库中获得病人的历史病历信息,获取所述病人的历史病历信息对应的历史处理策略信息；根据所述病人的历史病历信息对应的历史处理策略信息生成与所述即时病历信息对应的即时处理策略信息。</td>   <td>G16H50/20;G16H50/70;G16H10/60;G06F18/241;G06F40/289</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              沈智华;              覃军友;              张小虎;                   钟立军       </td>   <td>中山大学</td>   <td>一种星图配准方法及系统</td>   <td>广东省</td>   <td>CN115526921A</td>   <td>2022-12-27</td>   <td>本发明公开了一种星图配准方法及系统,该方法包括：获取基准图像和待配准图像并进行区块划分；在待配准图像每个区块中选取模板图像,并与基准图像进行模板匹配,得到整像素精度的匹配坐标点；根据整像素精度的匹配坐标点构建曲面模型,并对曲面模型进行计算得到亚像素匹配结果；根据亚像素匹配结果计算得到待配准图像的单应矩阵；对待配准图像进行目标检测,并利用单应矩阵对目标检测结果进行配准。该系统包括：区块划分模块、模板匹配模块、曲面构建模块、计算模块和配准模块。通过使用本发明,能够减少配准时间且提高精度。本发明作为一种星图配准方法及系统,可广泛应用于天文观测技术领域。</td>   <td>1.一种星图配准方法,其特征在于,包括以下步骤：获取基准图像和待配准图像并进行区块划分；在待配准图像每个区块中选取模板图像,并与基准图像进行模板匹配,得到整像素精度的匹配坐标点；根据整像素精度的匹配坐标点构建曲面模型,并对曲面模型进行计算得到亚像素匹配结果；根据亚像素匹配结果计算得到待配准图像的单应矩阵；对待配准图像进行目标检测,并利用单应矩阵对目标检测结果进行配准。</td>   <td>G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;                   刘鲁       </td>   <td>中山大学</td>   <td>一种区块链构造方法</td>   <td>广东省</td>   <td>CN109859044B</td>   <td>2022-12-27</td>   <td>本发明涉及一种基于有向无环图和权益证明的区块链构造方法,涉及客户端、区块链节点两类逻辑主体。区块链节点把时间划分为不同的世代,在每个世代的开始根据节点权益等信息确定该世代的区块链节点列表,客户端节点通过分布式应用DAPP产生应用消息,封装为净交易NT,并通过网络发送给多个区块链节点；之后区块链节点接收NT,封装为区块链交易BT,并通过网络发给其它区块链节点,当区块链节点接收到BT,形成有向无环图,更新不稳定NT的权重证明,当权重证明超过权重门限后,NT稳定,区块链节点通过合约执行稳定NT所含应用消息,更新NT所属账户的状态。该发明能够并行的确认交易,具有较好的安全性和效率。</td>   <td>1.一种区块链构造方法,包括客户端节点、区块链节点两类逻辑节点,所述区块链节点划分为三类：用于发出区块链交易BT的活动区块链节点、不发出区块链交易BT但准备成为活动区块链节点的准区块链节点、和不发出区块链交易也不准备成为活动区块链节点的静默区块链节点；其中,客户端节点包含网络模块、净交易NT模块和分布式应用DAPP模块；区块链节点包含网络模块、NT/BT模块、节点管理模块、合约模块、状态数据库模块、交易数据库/缓存模块；所述网络模块完成网络通信的功能；所述NT模块封装DAPP的应用消息、生成NT；所述DAPP模块提供面向用户的应用；所述净交易NT是客户端节点向区块链节点发送的内容,至少包括应用消息、预付权益数、NT的生成时间、客户端节点的计数器、客户端节点的公钥、客户端的数字签名；所述状态数据库模块用于存储所有账户的权益、计数器状态；所述NT/BT模块用于解析并封装NT、生成BT；所述区块链交易BT是一个活动区块链节点向其它区块链节点发出的内容,至少包括NT、2个或多个其它BT的哈希值、该活动区块链节点的公钥、区块链交易的生成时间,该活动区块链节点的计数器,该活动区块链节点的数字签名；所述节点管理模块用于改变区块链节点的类别,从静默区块链节点成为准区块链节点,从准区块链节点成为活动区块链节点；合约模块用于执行净交易及其中的应用消息,改变状态数据库中账户的内容；合约变量是在区块链节点的合约模块使用的参数；所述交易数据库/缓存模块用于缓存BT和存储BT；所述方法包含如下步骤：S1)区块链节点把时间按照时间周期T划分为不同的时间段,每个时间段称为世代,T是一个大于0的实数；把最开始的时间段作为第一个世代,称为世代0；接下来的第二个世代称为世代1,以此类推；第i+1个世代表示为世代i,i为大于等于1的正整数；在每个世代开始的时间点确定该世代的所有活动区块链节点并形成该世代的活动区块链节点列表,每个世代的活动区块链节点列表的长度有固定的上限NC,所述NC表示一个正整数；区块链节点还在除第一个世代外的每个世代开始的时间点确定该世代之前形成的状态数据库的默克尔根；S2)客户端节点通过DAPP产生应用消息,并通过NT封装应用消息,发送NT给多个当前世代的活动区块链节点；当前世代的活动区块链节点接收NT,判断NT的合法性；如果合法就封装为BT,插入本地的交易数据库,并经由网络发给当前其它区块链节点；S3)区块链节点接收BT,验证BT的合法性,验证不通过放弃处理该BT；否则通过交易数据库和缓存形成区块链交易的有向无环图,采用发送BT的区块链节点的权重来更新该BT包含的不稳定NT和该BT直接、间接引用的BT所包含的不稳定NT的权重证明；当权重证明超过权重门限后,NT稳定；S4)区块链节点通过合约模块执行稳定的NT,更新该NT所含公钥对应账户的状态,更新根据合约代码授权更改的账户状态。</td>   <td>G06Q40/04;G06Q20/38</td>  </tr>        <tr>   <td>中国专利</td>   <td>         符顺;              谢晓华;                   陈翔       </td>   <td>中山大学</td>   <td>基于单帧人脸图像的实时三维人脸重建方法</td>   <td>广东省</td>   <td>CN109377557B</td>   <td>2022-12-27</td>   <td>本发明公开了一种基于单帧人脸图像的实时三维人脸重建方法,步骤如下：从摄像头获取人脸图像,对图像进行人脸检测与人脸特征点定位与标注；根据人脸特征点的定位进行头部的姿态计算,获得图像中头部的旋转参数；使用特征点进行人脸归一化,计算归一化后的人脸深度信息；使用人脸深度信息,对标准头部三维网格模型进行变形；根据特征点与输入图像获得人体头部纹理图像；利用旋转参数与归一化获得变形后的头部网格点与纹理图像的直接映射关系；使用变形后的头部网格点、纹理图像与两者间的对应关系进行三维绘制与渲染,并展示给用户。本方法通过展示时纹理代替深度细节信息实现加速与纹理直接映射三维模型简化映射运算,达到三维重建的实时效果。</td>   <td>1.一种基于单帧人脸图像的实时三维人脸重建方法,其特征在于,所述的实时三维人脸重建方法包括以下步骤：S1、从摄像头获取人脸图像作为输入,对人脸图像进行人脸检测与人脸特征点定位与标注,如果存在人脸,则将人脸特征点标注在人脸图像上；S2、根据人脸特征点的定位进行头部的姿态计算,获得人脸图像中头部的旋转参数；S3、使用人脸特征点进行人脸归一化,计算归一化后的人脸深度信息；S4、使用人脸深度信息,对标准头部三维网格模型进行变形；所述的步骤S4中对标准头部三维网格模型进行变形的过程如下：S41、以两个眼睛中心以及鼻尖的坐标为基准,获得标准头部三维网格模型中的点到归一化后每个像素点深度信息的仿射矩阵,分别计算归一化图像与标准头部三维网格模型在人脸正面方向上两个眼睛中心点的距离与两个眼睛中心连线的中点到鼻尖点距离的比值,再用标准头部三维网格模型的比值除以归一化图像的比值,获得拉伸系数；S42、利用仿射矩阵,调整标准头部三维网格模型中脸部点的深度信息；S43、将标准头部三维网格模型中点到标准头部三维网格模型中鼻根点在左右方向上的差值与所述的拉伸系数相乘获得新的差值,最后利用新的差值,与标准头部三维网格模型中鼻根点左右方向上的值相加,成为该点的左右方向的值,对标准头部三维网格模型中点进行横向拉伸；S5、根据人脸特征点与摄像头输入的人脸图像获得人体头部纹理图像；S6、使用旋转参数与归一化,获得变形后的头部网格点与纹理图像的直接映射关系；S7、使用变形后的头部网格点、纹理图像与以上两者间的直接映射关系进行三维重建与渲染,并展示给用户。</td>   <td>G06T17/00;G06V40/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈嘉谦;              朱艺;              沈金龙;              顾佳良;              吴昱焜;                   衣杨       </td>   <td>中山大学</td>   <td>一种视频中人体行为识别的方法</td>   <td>广东省</td>   <td>CN109508684B</td>   <td>2022-12-27</td>   <td>本发明涉及人工智能领域,更具体的,涉及一种视频中人体行为识别的方法,本发明的主要算法思想为：首先对输入的视频片段进行预处理,使用六参数仿射模型模拟摄像机运动,通过仿射模型获取运动轨迹；接着对视频基于时间显著性和空间显著性进行关键帧提取；然后对关键帧提取改进密集轨迹,同时选择双流卷积神经网络作为特征提取器,对关键帧提取深度学习特征；对提取出来的特征进行归一化,并基于视频表示的对特征进行融合,融合基于深度特征的视频表示与基于改进密集轨迹特征的视频表示。本发明融合手工设计的改进密集轨迹特征IDT和深度学习特征,可更有效的挖掘两种特征的互补信息与视频中的行为模式,在视频人体行为识别取得更好的效果。</td>   <td>1.一种视频中人体行为识别的方法,其特征在于,具体包括以下步骤：步骤S1：对视频进行预处理,获取整个视频所有帧的改进后的密集轨迹；步骤S2：基于时间显著性和空间显著性对视频进行关键帧提取；步骤S3：通过关键帧筛选步骤S1中获得的密集轨迹,对于关键帧的密集轨迹进行保留,去除非关键帧的密集轨迹；步骤S4：在改进后的密集轨迹的基础上对视频进行基于层次轨迹束的视频表示；步骤S5：提取关键帧的深度学习特征,对视频进行基于深度特征的视频表示；步骤S6：将基于层次轨迹束的视频表示和基于深度特征的视频表示进行融合；步骤S7：对融合后的视频进行SVM分类；步骤S4的具体步骤如下：步骤S401：将密集轨迹L＝[p-0,…,p-15]构建以轨迹特征点为中心的时空立方体,将其划分为小的时空块；所述的时空块的大小为2*2*3；步骤S402：对每个时空块计算相应的梯度特征、光流特征以及运动边界特征,计算其梯度直方图HOG、光流直方图HOF、运动边界直方图MBH特征描述符；HOG是将360°按每45°分成8个bin,以每个特征点为中心的时空块划分出的时空立方体中,每个像素的梯度大小和方向设为n(x)和θ(x),则每个像素点在第j个bin上的分量HOF计算方式与HOG类似,仅在HOG的基础上加入了0方向,用以表示大小为0或者极其小的光流分量的个数,分量共9维；MBH将光流场分为水平分量I-u和垂直分量I-v,分别在x和y的光流图像上独立计算各自分量的HOG特征(MBHx-j、MBHy-j)；步骤S403：每个叠加时空块得到结合补偿轨迹的局部特征描述符梯度直方图Trj-HOG、光流直方图Trj-HOF以及运动边界直方图Trj-MBH,定义如下：                                                      步骤S404：随机采样256000条补偿轨迹,构建高斯混合模型GMM,构建视觉词典,GMM生成式模型可以表示为：                  其中K是高斯核的个数,θ表示参数模型{π-k,μ-k,k＝1,…,K},其中π-k,μ-k分别表示先验模式概率、均值向量,ζ(x′,μ-k,∑k)表示D维高斯分布,D是降维后的补偿轨迹维度特征；设特征集合为利用最大似然估计得出最优的GMM参数对特征描述符采用FV编码,估计特征空间点对应的概率密度函数；步骤S405：利用高斯分布来拟合全部特征点,从而得层次轨迹束特征；步骤S5的具体步骤如下：步骤S501：采用混合时空双流网络,包括输入为单视频帧的空间卷积网络以及输入为累积光流；其中,单视频帧的大小为224*224*3；累积光流为224*224*2F的时间卷积网络,F为累积层数,设置为10；并采用UCF101数据集的第一个划分作为预训练数据集,预训练结束后把混合时空双流网络作为通用特征提取器,对其他视频提取卷积特征图谱；步骤S502：混合层对时间特征和空间特征分别进行混合,对空间层采用sum融合方式,在任意时刻的融合空间特征图谱y-(i,j,d)表示为：                  其中1≤i≤H,1≤j≤W,1≤d≤CH,H、W、CH分别对应视频的高度、宽度和通道数；步骤S503：对时间层采用3D池化,对任意根据空间特征图谱在t＝1…T时间内叠加的时间特征图谱使用大小为H′*W′*L′的3D池化立方块对特征图谱进行最大池化；步骤S504：保留并获取混合处理后的特征图谱,表示为C(X)＝{C-s,C-t},其中H、W、L、CH分别对应视频X的高度、宽度、时间长度和通道数,C-s和C-t分别表示空间网络的特征图谱集合以及时间网络的特征图谱集合；步骤S505：对特征图谱采用归一化策略来抑制部分神经元的激活突发问题,特征图谱归一化包括时空归一化和通道归一化两种方式；步骤S506：进行时空归一化处理,对每一个通道独立归一化操作特征图谱,确保对于每个单独通道中特征图谱的范围；对C(X)中的任意特征图谱时空归一化特征为：                  其中为第n个时空特征图谱的最大值；步骤S507：进行通道归一化处理,对每个像素点在三个通道上的值得到归一化图谱,把每个点的特征值保持在一定的范围,使每个点具有相同的权重；对C(X)中的任意特征图谱通道归一化特征为：                  其中为在(x,y,z)位置上不同特征通道的最大值；步骤S508：在以改进密集轨迹为中心的3D时空块中,进行轨迹池化操作,计算出基于局部轨迹对齐的特征描述符,即TDD特征。</td>   <td>G06V40/20;G06V20/40;G06T7/269</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周毅;                   杨日东       </td>   <td>中山大学</td>   <td>一种局部K近邻缺失值插补系统与方法</td>   <td>广东省</td>   <td>CN109933579B</td>   <td>2022-12-27</td>   <td>本发明提供一种局部K近邻缺失值插补系统,判断模块用于判断不完全样本T-i中每个缺失属性j,投影模块对数据集T进行投影,在数据集T中求得满足条件的数据集T’：数据集T’中的属性在T-i中未缺失的属性不缺失、在T-i当前插补的属性j也不缺失。其次,数据计算模块在T’中求得T-i的K近邻T-(iK)。逻辑处理模块对不完全样本T-i的缺失属性j进行分析,若当前样本的缺失属性j是分类属性,则将T-(iK)在属性j的取值的众数插补到T-i的缺失属性j中；否则将T-(iK)在属性j的取值的平均数插补到T-i的缺失属性j中。本发明提供的一种局部K近邻插补系统在缺失率小的情况下,性能略优于传统K近邻插补法；在缺失率较大的情况下,性能远胜于传统K近邻插补法。</td>   <td>1.一种局部K近邻缺失值插补系统,其特征在于,包括输入模块、归一化模块、判断模块、投影模块、数据计算模块、逻辑处理模块和输出模块；所述的输入模块用于输入包含不完全样本的数据集T与K近邻的参数K；所述的归一化模块用于对数据集T进行归一化操作；所述的判断模块用于判断数据集T中的不完全样本T-i的缺失属性,设j为当前插补的缺失属性；所述的投影模块用于对数据集T进行投影,遍历T,求出T中满足相应要求的样本集T′,其中样本T-i中未缺失的属性在T′中也不缺失；样本T-i当前的缺失属性j在T′中也不缺失；所述的数据计算模块用于计算不完全样本T-i与样本集T′中的每个样本T′-s的距离,根据计算的距离得到不完全样本T-i的K个最近邻样本T-(iK)；所述的逻辑处理模块用于对不完全样本T-i的缺失属性j进行分析,若不完全样本T-i的缺失属性j是分类属性,则将K个最近邻样本T-(iK)在属性j的取值的众数插补到不完全样本T-i的缺失属性j中；若不完全样本T-i的缺失属性j是数值属性,则将K个最近邻样本T-(iK)在属性j的取值的平均数插补到不完全样本T-i的缺失属性j中；所述的输出模块用于输出插补完成的数据集T。</td>   <td>G06F16/215;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余顺争;                   曾旺       </td>   <td>中山大学</td>   <td>一种基于SDN的云安全功能调度系统</td>   <td>广东省</td>   <td>CN109947534B</td>   <td>2022-12-27</td>   <td>本发明公开一种基于SDN的云安全功能调度系统,系统包括云安全虚拟编排模块、云安全虚拟功能模块、云安全虚拟载荷模块、云安全实现模块和虚拟资源服务端模块。该系统基于云环境下的计算资源虚拟化和网络虚拟化,定义了从单个安全功能的部署到一整套安全编排的虚拟化过程,为用户在不同网络环境下实现统一的安全功能调度建立基础。系统在实现层面利用SDN架构控制与数据的分离,因而具有简单灵活和易扩展等特点。</td>   <td>1.一种基于SDN的云安全功能调度系统,其特征在于,包括云安全虚拟编排模块、云安全虚拟功能模块、云安全虚拟载荷模块、云安全实现模块以及虚拟资源服务端模块；所述的云安全虚拟编排模块用于实现对安全编排的定义,调用云安全虚拟功能模块完成对安全编排的整体操作；所述的云安全虚拟功能模块用于建立安全配置服务器和调用云安全虚拟载荷模块完成对单个安全功能的自动配置和部署；所述的云安全虚拟载荷模块用于定义不同类型的虚拟安全载荷并实现自动化部署；所述的云安全实现模块用于接收并处理对于安全载荷的部署命令；所述的虚拟资源服务端模块用于对单个宿主机内部虚拟的虚拟机、docker和OVS的虚拟资源进行管理。</td>   <td>G06F9/455;H04L67/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘坤华;              陈龙;              袁湛楠;                   张彧       </td>   <td>中山大学</td>   <td>一种基于有向图的云制造服务优选数学模型建立方法</td>   <td>广东省</td>   <td>CN110569584B</td>   <td>2022-12-27</td>   <td>本发明提供了一种基于有向图的云制造服务优选数学模型建立方法,本发明以前k个最小和最大指标的服务组合方案为优选目标,对云制造服务组合方案分别建立目标函数和数学模型,并以结点具有资源代价的有向图进行表示,并在此基础上将结点具有资源代价的有向图转变为只有路径具有资源代价结点不具有资源代价的标准有向图,从而将服务组合优选问题转变为标准有向图的最短路径求解问题,方便服务组合方案的优选求解,提高求解效率,有效提高云制造企业生产效率,降低生产成本。</td>   <td>1.一种基于有向图的云制造服务优选数学模型建立方法,其特征在于,包括以下步骤：S1：分别建立设计服务组合方案、生产服务组合方案、产品服务组合方案和产品组合方案的前k个最小和最大指标服务组合方案数学模型；S2：根据前k个最小和最大指标服务组合方案数学模型将设计服务、生产服务、产品服务以及产品的服务组合过程通过结点具有资源代价的有向图表示；S3：将结点具有资源代价的有向图转变为只有路径具有资源代价结点不具有资源代价的标准有向图,根据标准有向图更新前k个最小和最大指标服务组合方案数学模型；所述指标包括服务时间、服务费用、制造能力和综合能力；所述设计服务、生产服务、产品服务和产品4种服务类型的前k个最小或最大指标服务组合方案的目标函数可统一表示如下：                  其中,β-(ij)P-(ij)为被选中的各子任务的资源代价,α-(ij)W-(ij,(n+1)j)为各相邻子任务之间的路径资源代价,γ-((n-l)j)W-((n-l)j,n1)为最后被选中的一个子任务到需求方的路径资源代价；若设计服务、生产服务、产品服务和产品4种服务类型以服务时间、服务费用为指标建立目标函数时,K＝1,否则K＝1/n；n为子任务的数量；所述将结点具有资源代价的有向图转变为只有路径具有资源代价结点不具有资源代价的标准有向图具体操作如下：对于前n-1个阶段子任务,将结点的资源代价累加到由前一阶段结点到该结点的路径中,释放结点的资源代价,即该路径上的资源代价为原路径资源代价与该路径终点的结点的资源代价之和,具体公式为：W′-(ij,(i+1)j)＝W-(ij,(i+1)j)+P-(ij)S.T.i＝{1,2,...n-1}j＝{1,2,...m}其中,W′-(ij,(i+1)j)为前一阶段结点到该结点的路径的资源代价,W-(ij,(i+1)j)为原路径的资源代价,P-(ij)为路径终点的结点的资源代价；m为服务方数量；对于第n个子任务,由于此子任务实现从最后一个子任务服务方到需求方的物流运输,结点的资源代价P-(n1)为0,路径上资源代价即为原路径资源代价,具体公式为：W′-((n-1)j,n1)＝W-((n-1)j,n1)+P-(n1)        ＝W-((n-1)j,n1)式中,W′-((n-1)j,n1)为路径上的资源代价,W-((n-1)j,n1)为最后一个子任务到需求方的资源代价,P-(n1)为需求方的资源代价。</td>   <td>G06F30/20;G06F17/15;G06Q10/06;G06Q10/08;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王帅;              陈明昊;                   张佳钟       </td>   <td>中山大学</td>   <td>基于多因子进化算法的网络节点寻找方法及系统</td>   <td>广东省</td>   <td>CN115510288A</td>   <td>2022-12-23</td>   <td>本发明公开了基于多因子进化算法的网络节点寻找方法及系统,该方法包括：构建种子节点集在遭受攻击下的鲁棒影响力评估指标函数；根据鲁棒影响力评估指标函数对种子节点集进行评估,得到种子节点集的个体属性；基于种子节点集的鲁棒影响力评估指标函数,通过多因子进化算法对种子节点集的个体属性进行更新处理,得到最优种子节点集。通过使用本发明,能够在同时考虑节点攻击与链路攻击的情况下提高种子节点集个体性能的收敛速度从而很好的完成信息传播任务。本发明作为基于多因子进化算法的网络节点寻找方法及系统,可广泛应用于计算机应用技术领域。</td>   <td>1.基于多因子进化算法的网络节点寻找方法,其特征在于,包括以下步骤：构建种子节点集在遭受攻击下的鲁棒影响力评估指标函数；根据鲁棒影响力评估指标函数对种子节点集进行评估,得到种子节点集的个体属性；基于种子节点集的鲁棒影响力评估指标函数,通过多因子进化算法对种子节点集的个体属性进行更新处理,得到最优种子节点集。</td>   <td>G06F16/903;G06F16/901;G06N3/12;G06F16/9536;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄寒砚;              熊梅;              朱瑞泓;              林佳陆;                   陈琳       </td>   <td>中山大学</td>   <td>基于量纲分析和最优设计的毁伤响应函数获取方法及装置</td>   <td>广东省</td>   <td>CN115510691A</td>   <td>2022-12-23</td>   <td>本发明涉及毁伤效能评估技术领域,公开了基于量纲分析和最优设计的毁伤响应函数获取方法及装置。本发明基于量纲分析对毁伤响应指标与对应毁伤影响因素的函数关系模型进行处理,采用单点交换算法获取所得到的毁伤响应函数模型中各自变量在取值范围为[0,1]的D-R-最优设计点,其中该算法基于岭回归的思想在信息矩阵的数学表达式中引入了正则化参数；将最优设计点转化为相应自变量所属取值范围内的对应设计点,并利用该对应设计点开展试验得到的试验响应值构建样本数据集,进而进行数据拟合求解回归系数,得到毁伤响应函数。本发明在试验样本量不足的情况下能够实现较高精度的毁伤响应函数的获取,达到较高的试验效费比。</td>   <td>1.一种基于量纲分析和最优设计的毁伤响应函数获取方法,其特征在于,包括：确定毁伤响应指标及对应的毁伤影响因素,获取各所述毁伤影响因素的量纲及取值范围；构建毁伤响应指标与对应毁伤影响因素的函数关系模型,根据所述量纲及取值范围,基于量纲分析对所述函数关系模型进行处理,得到毁伤响应函数模型；采用D-(R-)最优设计单点交换算法获取所述毁伤响应函数模型中各自变量在取值范围为[0,1]的最优设计点,所述D-(R-)最优设计单点交换算法为对D-最优化设计的单点交换算法改进得到,其改进之处为在信息矩阵的数学表达式中引入岭回归的正则化参数；将各所述最优设计点转化为所述毁伤响应函数模型中相应自变量所属取值范围内的对应设计点,以转化得到的对应设计点作为试验设计点,获取利用所述试验设计点开展试验所得到的试验响应值,根据所述试验设计点和所述试验响应值构建样本数据集；根据所述样本数据集进行数据拟合求解所述毁伤响应函数模型的回归系数,得到毁伤响应函数。</td>   <td>G06F30/20;G06F17/18;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈生;              庞盈;                   胡俊俊       </td>   <td>中国科学院西北生态环境资源研究院;中山大学</td>   <td>一种基于闪电资料同化的降水预报方法及系统</td>   <td>甘肃省</td>   <td>CN115511192A</td>   <td>2022-12-23</td>   <td>本发明公开了一种基于闪电资料同化的降水预报方法及系统,方法包括对当前时刻的闪电定位数据、风云四号卫星的云顶高度数据和地面气象站的云底高度数据进行网格化预处理,获得网格化观测资料；根据网格化观测资料和当前模式背景场,进行水汽观测资料反演；将伪水汽观测资料、地面站观测资料和当前模式背景场,进行三维变分同化,获得当前时刻的分析场；在该分析场的基础上进行模式预报,获得下一时刻的预报场；将该预报场作为下一时刻的模式背景场,重复上述操作进行闪电资料循环同化,最终获得逐小时的降水预报。本实施例实现了减少对模式背景场的依赖,提高模式初始场的精确度,提高临近时刻的降水预报效果。</td>   <td>1.一种基于闪电资料同化的降水预报方法,其特征在于,包括：对当前时刻的气象数据进行网格化预处理,获得网格化观测资料；其中,所述气象数据包括闪电定位数据、云顶高度数据和云底高度数据；根据所述网格化观测资料和当前模式背景场,反演出伪水汽观测资料；将所述伪水汽观测资料、地面站观测资料和所述当前模式背景场,进行三维变分同化,获得所述当前时刻的分析场；根据所述当前时刻的所述分析场,进行模式预报,得到下一时刻的预报场,获得所述下一时刻的降水预报。</td>   <td>G06Q10/04;G06T17/05;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙慧杰;              杜畅洋;              刘万泉;                   吴雨瑶       </td>   <td>中山大学</td>   <td>基于计算机视觉的室内人员痛苦表情识别方法及系统</td>   <td>广东省</td>   <td>CN115512424A</td>   <td>2022-12-23</td>   <td>本发明涉及基于计算机视觉的室内人员痛苦表情识别方法和系统。其方法包括：获取输入视频中包含人脸的现场图像,提取人脸图像,将人脸图像输入至基于深度可分离的神经网络模型,输出与人脸图像关联的表情识别结果,神经网络模型包括多个深度可分离的剩余卷积层,在神经网络模型训练时,对原始表情数据库进行数据集合并分别重新生成三分类数据库和六分类数据库,分别采用三分类数据库和六分类数据库进行模型训练。本发明采用轻量化神经网络模型,通过数据集合并和扩充构均衡化的训练数据库,在保证整体识别准确率不变的前提下,提高识别准确率以及表情分类精度,实现实时视频监控及痛苦表情识别。</td>   <td>1.一种基于计算机视觉的室内人员痛苦表情识别方法,其特征在于,所述方法包括以下步骤：S10、获取所述计算机视觉输入视频中包含人脸的现场图像,提取人脸图像；S20、将所述人脸图像输入至基于深度可分离的神经网络模型；S30、通过所述神经网络模型输出与所述人脸图像关联的表情识别结果；其中,所述神经网络模型包括多个深度可分离的剩余卷积层；在所述神经网络模型训练时,对原始表情数据库进行数据集合并分别重新生成三分类数据库和六分类数据库,分别采用所述三分类数据库和所述六分类数据库对所述神经网络模型进行训练；其中,所述三分类数据库包括消极数据集、中性数据集和积极数据集；所述六分类数据库包括愤怒数据集、厌恶和惊讶数据集、悲伤数据集、恐惧数据集、快乐数据集和中性数据集。</td>   <td>G06V40/16;G06N3/04;G06N3/08;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡丹旦;              张莺耀;              罗震;              陈敏山;              徐盛;              张驰;                   顾德清       </td>   <td>翼健(上海)信息科技有限公司;中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>基于隐私安全计算平台的专病数据库构建方法及装置</td>   <td>上海市</td>   <td>CN115495773A</td>   <td>2022-12-20</td>   <td>本申请公开了一种基于隐私安全计算平台的专病数据库构建方法及装置,包括：基于原始数据不出域,通过数据与计算协同建立数据价值输出的新方式,实现专病库建设和专病数据安全共享协作地新范式。应用隐私安全计算平台技术构建专病库,动态实现多维度、多模态专病数据全生命周期管理与资产化医疗健康数据管理新范式。应用人工智能前沿技术在数据治理、文本数据结构化、影像数据智能处理等过程中,有助于节约数据治理处理过程的时间,且获得更高质量的标准化、结构化数据。</td>   <td>1.一种基于隐私安全计算平台的专病数据库构建方法,其特征在于,应用于隐私安全计算平台,包括：获取专病病例数据；将所述专病病例数据进行敏感信息脱敏处理；将脱敏后的专病病例数据分为文本数据、影像数据和基因数据；将文本数据输入到训练好的自然语言处理深度学习模型中进行结构化和标准化处理；将影像数据输入到训练好的计算机视觉深度学习模型中进行处理得到影像标注数据；根据基因数据对肿瘤组织和正常组织的全外显子测序数据、转录组测序数据进行批量并行分析,得到初级分析结果；结合临床信息和初级分析结果,进行统计分析得到有效的生物标志物或从分子层面解释临床现象；将结构化、标准化处理后的文本数据、影像标注数据和生物标志物或从分子层面解释的临床现象保存至数据库中。</td>   <td>G06F21/62;G06N3/04;G06N3/08;G16H10/60;G16H50/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘珍环;              周义;                   邹金秋       </td>   <td>中山大学;中国农业科学院农业资源与农业区划研究所</td>   <td>城市生态修复优先顺序识别方法、装置及电子设备</td>   <td>广东省</td>   <td>CN115496146A</td>   <td>2022-12-20</td>   <td>本发明提供一种城市生态修复优先顺序识别方法、装置及电子设备,所述方法包括：获取目标城市区域内多个生态系统服务指标在不同年份的空间分布数据并进行标准化处理；根据标准化处理后的多个生态系统服务指标在不同年份的空间分布数据,确定目标城市区域内对应预设网格尺度的每个像元在不同年份的生态系统服务簇值ESB；根据每个像元在不同年份的ESB及不透水表面指数值ISA,确定生态修复目标年份时段；针对任一目标像元,根据其在生态修复目标年份时段的ISA变化率,以及其邻域像元在生态修复目标年份时段的ESB变化率,确定其生态修复优先顺序。能够划分出城市生态修复区的优先区域,提高城市区域生态修复的高效性与经济性。</td>   <td>1.一种城市生态修复优先顺序识别方法,其特征在于,包括：获取目标城市区域内多个生态系统服务指标在不同年份的空间分布数据并进行标准化处理；根据标准化处理后的所述多个生态系统服务指标在不同年份的空间分布数据,确定所述目标城市区域内对应预设网格尺度的每个像元在不同年份的生态系统服务簇值ESB；根据所述每个像元在不同年份的ESB,以及所述每个像元在不同年份的不透水表面指数值ISA,确定生态修复目标年份时段；针对所述每个像元中的任一目标像元,根据所述目标像元在所述生态修复目标年份时段的ISA变化率,以及所述目标像元的邻域像元在所述生态修复目标年份时段的ESB变化率,确定所述目标像元的生态修复优先顺序。</td>   <td>G06K9/62;G06F17/18;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李劲嵘;              李根;              封檑;                   周榆松       </td>   <td>中山大学中山眼科中心</td>   <td>一种角膜缘定位方法及其系统</td>   <td>广东省</td>   <td>CN115496808A</td>   <td>2022-12-20</td>   <td>本发明提供了一种角膜缘定位方法及其系统,方法包括：构建多分辨率多尺寸多种形态的卷积核；对输入图像进行包括边缘提取在内的预处理；通过各个最低分辨率下的卷积核对最低分辨率下的去噪边缘图像进行卷积处理,得到定位样本；样本扩展,并筛选得到n个最优样本；进行基于最近点关联的迭代椭圆优化流程,得到包括角膜缘的圆心位置和角膜缘椭圆的几何参数在内的定位结果。本发明的方案具有鲁棒性、快速性和精确性,能够有效过滤眼睑特征对角膜缘定位识别的影响,准确、高效的实现角膜缘定位,且整体的计算量小,计算过程简单,计算效率高。</td>   <td>1.一种角膜缘定位方法,其特征在于,包括如下：基于角膜缘在眼球转动时的多种形态,构建多个分辨率、多个尺寸、多种眼球转动形态下的卷积核,并对多个卷积核进行编号；对输入图像进行包括边缘提取在内的预处理,得到仅涉及眼部区域的、多个分辨率下的去噪边缘图像；通过各个最低分辨率下的卷积核对最低分辨率下的去噪边缘图像进行卷积处理,得到n个定位样本；其中,每个定位样本中包括角膜缘的像素坐标、卷积核编号以及卷积核与去噪边缘图像的匹配程度；n为大于1的自然数；对所述定位样本进行样本扩展,并基于预设分辨率下的卷积核和去噪边缘图像对扩展的样本进行筛选,重新得到n个最优样本；以n个最优样本、各个卷积核以及最高分辨率下的去噪边缘图像为输入,进行基于最近点关联的迭代椭圆优化流程,得到包括角膜缘的圆心位置和角膜缘椭圆的几何参数在内的定位结果。</td>   <td>G06T7/73;G06T5/00;G06T7/00;G06T7/11;G06T7/13;G06V10/26;G06V10/30;G06V10/44;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱云晓;              袁鲲;              黄羽君;              刘文芬;                   郑子龙       </td>   <td>中山大学附属第七医院(深圳)</td>   <td>一种胎儿心脏结构分割测量方法、装置及计算机存储介质</td>   <td>广东省</td>   <td>CN115482190A</td>   <td>2022-12-16</td>   <td>本发明公开了一种胎儿心脏结构分割测量方法、装置及计算机存储介质,该方法包括将获取到的胎儿心脏超声图像输入到已经训练的图像深度学习分割模型中进行分析,并获取所述图像深度学习分割模型输出的分割结果,作为所述胎儿心脏超声图像的特征信息,所述胎儿心脏超声图像的特征信息包括该胎儿心脏超声图像的切面类别以及至少一个结构特征的形态；根据每个所述结构特征的形态获取该结构特征的分割边缘,并根据所述切面类别的目标信息从每个所述结构特征的分割边缘中测量得到对应的几何参数。可见,实施本发明能够快速识别胎儿心脏切面并有效地分割胎儿心脏结构进行测量,提高医生检查效率,减少误诊漏诊率。</td>   <td>1.一种胎儿心脏结构分割测量方法,其特征在于,所述方法包括：将获取到的胎儿心脏超声图像输入到已经训练的图像深度学习分割模型中进行分析,并获取所述图像深度学习分割模型输出的分割结果,作为所述胎儿心脏超声图像的特征信息,所述胎儿心脏超声图像的特征信息包括该胎儿心脏超声图像的切面类别以及至少一个结构特征的形态；根据每个所述结构特征的形态获取该结构特征的分割边缘,并根据所述切面类别的目标信息从每个所述结构特征的分割边缘中测量得到对应的几何参数。</td>   <td>G06T7/00;G06T7/12;G06T7/13;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蒋弥;              钟敏;                   程晓       </td>   <td>中山大学</td>   <td>一种时序多极化SAR同质样本选取方法</td>   <td>广东省</td>   <td>CN115291214B</td>   <td>2022-12-16</td>   <td>本发明公开了一种时序多极化SAR同质样本选取方法,如下：对原始时序多极化数据集处理,获得单视多极化强度数据集；获取配准后的单视多极化强度图像序列；将各时刻的单视多极化强度数据累加,形成总功率时序影像数据集；设计非参数自适应假设检验进行二分类；设定矩形滑动窗口,检验逐个比较矩形滑动窗口内每个空间像素的总功率时序样本与中心参考像素的时间样本的统计相似度,获得空间像素的同质样本；将每个空间像素作为中心参考像素,通过矩形滑动窗口遍历整个图像空间位置,获取每个空间像素的同质样本。本发明利用多极化数据集最大化信息量,运用自适应假设检验方法,能提高同质样本选取的精度,确保时序InSAR形变监测的可靠性。</td>   <td>1.一种时序多极化SAR同质样本选取方法,其特征在于：所述的方法包括步骤如下：S1：对原始时序多极化SAR数据集进行取模平方运算,获得单视多极化SAR强度数据集；S2：对预处理后的单视多极化SAR强度图像数据集采用强度最大互相关算法进行配准,得到配准后的单视多极化SAR强度图像序列；S3：将各时刻的单视多极化SAR强度数据分别累加,形成总功率span时序影像数据集；S4：对总功率span时序影像数据集,设计一个非参数自适应假设检验进行二分类；S5：在SAR坐标系下,对一个空间像素设定一个尺寸为m×m的矩形滑动窗口,利用S4的检验逐个比较矩形滑动窗口内每个空间像素的总功率span时序样本与中心参考像素p的时间样本的统计相似度,获得一个空间像素的同质样本；S6：将整个图像尺寸中的每个空间像素作为中心参考像素p,并开设m×m的矩形滑动窗口,按照步骤S5的方法遍历整个图像空间位置,直到获取每个空间像素的同质样本；步骤S4,根据总功率span时序影像数据集的尾重分布,围绕均值差异作为检验标准设计一个勒帕热自适应检验统计量,其表达式为：                  其中,T表示对经验分布尾重的测量,由极化SAR总功率统计分布的形态决定；LP1、LP2和LP3均是度量均值差异的统计量。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              王耿媛;              贠照强;              肖鹏;              段铮昱;              骆仲舟;                   黄远聪       </td>   <td>中山大学中山眼科中心;中山大学</td>   <td>一种眼微血管血流动力学参数自动分析方法</td>   <td>广东省</td>   <td>CN112164046B</td>   <td>2022-12-16</td>   <td>本发明提供了一种眼微血管血流动力学自动分析方法,包括如下步骤：步骤1：输入包含有眼微血管信息的视频文件中需要进行眼微血管血流动力学参数分析的图像集I-o；步骤2：对图像集合I-o中连续的图像进行图像配准；步骤3：对配准后的图像进行图像分割,得到眼微血管的分割掩码图像集S-r；步骤4：获取分割掩码图像集S-r中眼微血管的中心线；步骤5：对所述中心线进行拟合,并提取分割掩码图像中眼微血管的边缘,计算所述眼微血管的平均直径、内径和外径；步骤6：构成时空图像；步骤7：对得到的时空图像进行直方图均衡化处理；步骤8：对时空图像进行直线检测处理,对得到的直线的斜率进行统计,并得出分布最密集的斜率k；步骤9：计算眼微血管的血流速度V-a；步骤10：计算血流量、管壁切应率。</td>   <td>1.一种眼微血管血流速度的分析方法,其特征在于,包括如下步骤：步骤1：输入包含有眼微血管信息的视频文件中需要进行眼微血管血流动力学参数分析的图像集；步骤2：对图像集合中连续的图像进行图像配准,以第一张图像为固定图像,将剩余图像与第一张图像对齐,得到配准后的图像集合；步骤3：对配准后的图像进行图像分割,得到眼微血管的分割掩码图像集；步骤4：获取分割掩码图像集中眼微血管的中心线；步骤5：对所述中心线进行拟合,并提取分割掩码图像中眼微血管的边缘,根据拟合后的中心线和分割掩码图像中眼微血管的边缘计算所述眼微血管的平均观察直径、内径和外径；步骤6：提取步骤5中第一张分割掩码图像中的拟合的每一条中心线,以中心线的坐标为时空图的列,以图像集合中的图像的张数为行,构成时空图像；步骤7：对得到的时空图像进行直方图均衡化处理；步骤8：对时空图像进行直线检测处理,对得到的直线的斜率进行统计,并得出分布最密集的斜率k ；步骤9：计算眼微血管的血流速度,采用以下公式：          ,其中S表示图像像素之间的距离,单位为um,由相机确定分辨率后输入。</td>   <td>G06T7/00;G06T7/13;G06T5/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏航;              周凡;              刘海亮;              陈小燕;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>一种基于对抗网络的行为识别方法及电子设备</td>   <td>广东省</td>   <td>CN115240120B</td>   <td>2022-12-13</td>   <td>本申请适用于设备管理技术领域,提供了一种基于对抗网络的行为识别方法、装置、电子设备及存储介质,方法包括：接收待识别的目标视频数据；从目标视频数据中提取多个关键视频帧,并将关键视频帧上传至云端服务器,以通过部署于云端服务器的行为指导网络生成第一行为数据；将目标视频数据导入预设的帧间动作提取网络,得到帧间动作特征数据；将目标视频数据导入上下文注意力网络,确定目标视频数据中目标对象的第二行为数据；接收云端服务器反馈的第一行为数据,并根据动作特征信息、第一行为数据以及第二行为数据,确定目标对象的行为类别。采用上述方法能够在确保行为识别准确性的同时,能够减少本地运算的运算量。</td>   <td>1.一种基于对抗网络的行为识别方法,其特征在于,包括：接收待识别的目标视频数据；从所述目标视频数据中提取多个关键视频帧,并将所述关键视频帧上传至云端服务器,以通过部署于云端服务器的行为指导网络生成第一行为数据；将所述目标视频数据导入预设的帧间动作提取网络,得到帧间动作特征数据；所述帧间动作特征数据用于确定所述目标视频数据中相邻的视频图像帧之间的动作特征信息；将所述目标视频数据导入上下文注意力网络,确定所述目标视频数据中目标对象的第二行为数据；所述上下文注意力网络用于提取所述目标视频数据中所述目标对象与环境对象之间的相互位置关系；接收所述云端服务器反馈的所述第一行为数据,并根据所述动作特征信息、所述第一行为数据以及所述第二行为数据,确定所述目标对象的行为类别；所述第一行为数据包含多个行为标签以及至少一个伪标签；所述接收所述云端服务器反馈的所述第一行为数据,并根据所述动作特征信息、所述第一行为数据以及所述第二行为数据,确定所述目标对象的行为类别,包括：根据所述第一行为数据中的多个所述行为标签以及所述伪标签,构建行为监督矩阵；根据基于第二行为数据构建的行为识别矩阵以及所述行为监督矩阵,确定所述目标视频数据对应的第一自相关系数；若所述第一自相关系数小于或等于预设的相关阈值,则从第二行为数据中移除与所述伪标签对应的无效数据,以及为所述第二行为数据中与所述行为标签对应的关联行为数据进行数据加权,得到监督行为数据；根据所述监督行为数据以及所述动作特征信息,确定所述行为类别。</td>   <td>G06V20/40;G06V40/20;G06V10/74;G06V10/774;G06V10/80;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈楚城;                   戴宪华       </td>   <td>中山大学</td>   <td>一种针对大分辨率布匹图像中的小瑕疵的高效检验算法</td>   <td>广东省</td>   <td>CN109509187B</td>   <td>2022-12-13</td>   <td>本发明涉及一种针对大分辨率布匹图像中的小瑕疵的高效检验算法,包括：(1)通过摄像头采集图像,然后使用labelImg工具图像进行标注；(2)将处理后图像拆分成训练集和测试集,训练集用来训练检验模型,测试集用来评估检验模型性能；(3)将训练集图像和对应的类别信息位置信息等输入到改进的se-resnext101检验模型中,训练检验模型；(4)采用训练后的检验模型处理测试集中的图像,获取瑕疵的大致位置和对应的类别。本发明的方法可以对单分辨率的输入图像实现多尺度特征图的处理,从而处理多尺度图像块,这样可以适应多种不同大小的瑕疵,大幅度提高检测精度和速度；同时该算法实现在图像分类框架上获取瑕疵大致位置和处理图像中存在多种瑕疵的情况。</td>   <td>1.一种针对大分辨率布匹图像中的小瑕疵的高效检验算法,其特征在于,包括如下步骤：(1)图像采集,利用分辨率为2560*1920的摄像头对布匹图像进行拍摄,获取相关的数据集并对图像重命名,接着将图像缩放到1024*768大小,并采用label Img工具对拍摄的图像进行标注,获取图像中关于瑕疵的标签,瑕疵的标签包含了瑕疵在图像中左上角的坐标(x1,y1),右下角的坐标(x2,y2)和瑕疵的类别defectN,其中N表示数字,如果拍摄的图像中没有瑕疵,不用label Img进行处理,只记录其类别信息norm；(2)图像划分,将图像划分成训练集和测试集两部分,两个部分不存在相同的图像,训练集用来训练检验模型,测试集用来评估检验模型的性能；(3)图像预处理,包括随机上下翻转、随机左右翻转和随机光照改变,其中随机上下翻转、随机左右翻转和随机光照改变只针对训练集,当进行随机上下翻转和随机左右翻转的时候,瑕疵的坐标信息也需要做出相应的变化；(4)训练检验模型,将经过图像预处理后的训练集中的图像和标签信息输入到检验模型中进行训练,检验模型是在se-resnext101的基础上进行改进的,使得网络可以针对单分辨率的输入图像在模型上获取多尺度特征图,通过检验模型的前向传播获取每个特征图上每个特征点的类别概率值,通过Focal Loss函数计算分类损失,利用带动量的梯度下降算法反向传播训练模型；(5)布匹图像检验,将测试集中的图像输入到训练好的检验模型中提取特征并获取多尺度特征图上每个特征点的类别概率值；如果三张特征图中有两张及以上的特征图中所有特征点都判为norm,则认为该图像类别为norm,其他情况则认为图像中存在瑕疵；对于判别为存在瑕疵的图像,利用每个特征点都对应原图中的某个图像块,通过特征点的预测类别转换对应图像块的像素值获取相关的热力图,叠加多种特征图对应的热力图获得最终的热力图,由最终的热力图得到瑕疵的大致位置,对瑕疵附近的图像块取概率均值得到该瑕疵的类别,该算法可以处理图像中存在多瑕疵的情况,并得到各个瑕疵的类别和大致位置；所述步骤(4)中训练包括基于改进的se-resnext101模型进行训练步骤、迁移学习步骤、二阶段学习速率调整步骤、卷积网络提取特征步骤、自适应调整特征权重步骤、多尺度特征图处理步骤、计算Focal Loss步骤和利用带动量的梯度下降算法反向传播训练模型步骤；所述步骤(4)具体为：(4.1)将原始的se-resnext101模型最后的全局池化层代替为3个由并行的特征块全局池化层和特征块最大池化层构成的特征块池化小模块,每个小模块都是处于并行关系,每个小模块中池化层的尺寸相同但是不同模块之间的池化层的尺寸不同,另外将最后的全连接层用1个1*1大小的,步长为1的卷积操作代替,利用该改进的se-resnext101模型作为检验模型；(4.2)使用se-resnext101模型在ImageNets图像集上训练得到的权重来初始化改进的se-resnext101模型,即检验模型,只保留了除所有的偏置权重、最后的全局池化层、最后的全连接层和softmax层外的权重；(4.3)训练模型时候采用二阶段学习速率调整网络的学习速率,即在初始阶段以某个学习速率训练包括特征块池化模块在内的模型的最后三层而保持模型其他层的权重不变,在训练若干个迭代周期后对模型的最后三层使用一个较大的学习速率,其他层使用一个较小的学习速率,并按照一定的规律降低学习速率,每个迭代周期遍历训练集中所有的图像；(4.4)将训练图像输入改进的se-resnext101模型中,利用卷积操作提取特征,增大特征图的感受野,同时利用原始se-resnext101模型中包含的挤压和激励子模块使得网络能够自适应调整特征权重,突出有效特征,抑制无效特征,使得特征空间和特征通道两个维度得到改善；(4.5)对最后卷积层输出的特征图利用3个并行的特征块池化子模块,每个小模块中池化层的尺寸相同但是不同模块之间的池化层的尺寸不同,从而获取3种不同大小的特征图；对获取的特征图利用大小为1*1,步长为1的卷积操作,紧接着利用softmax计算出3种不同大小的特征图上每个特征点对应的类别概率值；(4.6)由于感受野的存在,特征图上的特征点对应原图的图像块,根据瑕疵在图像中的位置可以获知每个图像块的真实类别,从而得到对应特征点的真实类别,根据预测的类别概率值和真实的类别信息,利用Focal Loss函数计算分类损失,最后利用带动量的梯度下降算法反向传播更新检测模型参数。</td>   <td>G06T7/00;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈定安;              罗明;                   王先伟       </td>   <td>中山大学</td>   <td>一种基于对称性分析的建筑物受灾形变检测方法及系统</td>   <td>广东省</td>   <td>CN113987631B</td>   <td>2022-12-13</td>   <td>本发明公开了一种基于对称性分析的建筑物受灾形变检测方法及系统,该方法包括对原始点云进行预处理；计算得到旋转角的初始值；将建筑物体素化并求出每个体素内点量的平均值；将建筑物点云拟合至一双反射对称平面模型；构建估计模型并计算模型参数的改正数；将点云转换至模型初始位置,得到初始位置点云；将初始位置的左半点云转换至右半重叠、将前半点云转换至后半重叠；进行对称性分析。该系统包括：预处理模块、几何拟合模块和对称性分析模块。通过使用本发明,准确计算一双反射对称平面,量化建筑物的对称度,并籍此评估其受灾程度。本发明可广泛应用于地理信息科学技术领域。</td>   <td>1.一种基于对称性分析的建筑物受灾形变检测方法,其特征在于,包括以下步骤：获取原始点云并对原始点云进行预处理,得到建筑物点云；基于黄金分割法计算得到旋转角的初始值；所述旋转角的初始值的计算公式表示如下,                                    上式中,ξ表示经中心平移后X和Y范围的差,Ψ表示旋转角,将建筑物体素化,并求出每个体素内点量的平均值,利用平均值作为阈值对建筑物点云进行筛选,得到筛选后的建筑物点云；结合旋转角的初始值,将建筑物点云拟合至一双反射对称平面模型并求出一双反射对称平面参数；基于最小二乘法构建估计模型计算模型参数的改正数,并修正一双反射对称平面参数,得到修正后的一双反射对称平面参数；根据修正后的一双反射对称平面参数将点云转换至模型初始位置,得到初始位置点云；基于反射矩阵公式将初始位置的左半点云转换至右半重叠、将前半点云转换至后半重叠,得到左右重叠部分和前后重叠部分；分别计算左右重叠部分和前后重叠部分的误差,并进行对称性分析。</td>   <td>G06F30/13;G06F17/11;G01C11/00;G01B11/16;G01B11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周晓聪;                   尹林枫       </td>   <td>中山大学</td>   <td>一种关系型分布式数据库的分片存储方法及装置</td>   <td>广东省</td>   <td>CN109635037B</td>   <td>2022-12-09</td>   <td>本发明公开一种关系型分布式数据库的分片存储方法及装置,本装置用于实现本方法,本方法为以数据表为节点,以数据表间的外键约束关系为两节点间的有向边,生成有向图；将有向图转化为有向图的邻接矩阵；输入有向图的邻接矩阵及待添加节点的有效距离；对邻接矩阵的节点进行路径查找,获取所有节点路径生成路径集；删除所有节点路径的子路径获得有效路径集；将有效路径集排序成有序路径序列集；求解有向图中各个节点最小有向距离；按照排序序列遍历路径集,完成有效距离范围内的节点添加,重返删除、排序及求解步骤。本发明实现将存在连接关系的数据表划分到一个数据存储节点,有效避免数据表跨存储节点的连接操作。</td>   <td>1.一种关系型分布式数据库的分片存储方法,其特征在于,包括如下步骤：S10基于系统数据库建立有向图数据库模型,建立有向图数据库模型的步骤包括：以系统数据表为模型的节点及以系统数据表之间外键约束关系为两个节点间有向边生成的系统有向图；将系统有向图转化的邻接矩阵；在邻接矩阵以入度为0的某一节点为起点遍历其他节点获得的路径集；对路径集按节点个数多少进行排序获得的节点有向序列集；基于节点有向序列集有向性求解所得的有向图各个节点的最小有向距离；S20输入待存储数据表、其与具有对应外键约束关系节点之间的有效距离至有向图数据库模型；S30分片存储数据表：待存储数据表作为表节点基于节点有向序列集有向性遍历递归路径集,将表节点加入到在路径集有效距离范围内的节点有向序列集；S40生成新的路径集,具体步骤为：S401在邻接矩阵寻找入度为0的节点作为表节点启动遍历查找；S402判断该节点是否被访问过,若被访问过,则标记该节点,且返回S401；若未被访问过,则进入S403；S403从该节点沿着路径集中其对应的路径深度递归遍历,直至该节点无路可走；S404由该节点的所有遍历路径生成新的路径集；子路径是指被另一条节点路径完全包含的节点路径,所述S404之后还包括：S405识别并删除表节点的子路径,生成新的路径集。</td>   <td>G06F16/27;G06F16/28;G06F16/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;                   张睿       </td>   <td>中山大学</td>   <td>一种基于二次迁移学习的虹膜身份验证方法</td>   <td>广东省</td>   <td>CN110427804B</td>   <td>2022-12-09</td>   <td>本发明提出一种基于二次迁移学习的虹膜身份验证方法,包括以下步骤：采集眼球虹膜图片,进行预处理后划分为训练集和测试集；将训练集图片输入已进行预训练的深度卷积神经网络中进行迁移学习的分类训练；对训练集图片进行三元组的构造,去除深度卷积神经网络中的全连接层,再输入三元组对深度卷积神经网络进行二次迁移学习训练；将测试集图片输入深度卷积神经网络,输出特征向量后与其对应的身份信息进行验证,若验证成功,深度卷积神经网络完成训练；否则,调整结构参数后对深度卷积神经网络重新进行二次迁移学习训练；将待验证的图片输入完成训练的深度卷积神经网络中,将输出特征向量与存储有人员身份的数据库进行距离匹配,输出身份验证结果。</td>   <td>1.一种基于二次迁移学习的虹膜身份验证方法,其特征在于,包括以下步骤：S1：采集眼球虹膜图片,对所采集的图片进行预处理后,划分为训练集和测试集；S2：将所述训练集图片输入已进行预训练的深度卷积神经网络中进行迁移学习的分类训练,得到完成迁移学习训练的深度卷积神经网络；其具体步骤如下：S2.1：获取一个已进行预训练的深度卷积神经网络结构,固定所述深度卷积神经网络结构中前n个卷积层的权重参数,对所述训练集中的图片进行人工标签,其中n为正整数,且n的取值小于深度卷积神经网络的总层数；S2.2：将所述训练集中的图片输入所述深度卷积神经网络结构中,将其输出的分类预测向量与人工标签进行差值运算,构造预测误差损失函数,其公式如下：                  其中,loss(i)表示输入的第i幅训练集图片的预测误差值,g(i)表示第i幅训练集图片输入深度卷积神经网络结构后得到的分类预测向量,label(i)表示第i幅训练集图片对应的真实类别向量；S2.3：根据误差的反向传播和梯度下降原理,训练调整前n个卷积层以外的卷积层和全连接层的权重,至训练集图片的预测误差值最小,此时深度卷积神经网络中的参数收敛,得到完成迁移学习分类训练的深度卷积神经网络；S3：对所述训练集图片进行三元组的构造,并将S2步骤中完成迁移学习分类训练的深度卷积神经网络中的全连接层去除,再输入训练集图片的三元组对深度卷积神经网络进行二次迁移学习训练；其具体步骤如下：S3.1：从所述训练集中选取两张同一虹膜的不同亮度值的图片,分别设为A和P,再选取一张与A和P不相同的虹膜图片设为N,组成三元组(A,P,N)；S3.2：将S2步骤中完成迁移学习分类训练的深度卷积神经网络中的全连接层去除,将所述三元组中的图片分别单独输入上述深度卷积神经网络中,输出得到三元组的特征向量(f(A),f(P),f(N)),其中f(·)表示上述深度卷积神经网络对输入图片的特征向量提取函数；S3.3：计算所述三元组的损失函数值,其公式如下：loss(j)＝dist(f(A),f(P))-dist(f(A),f(N))其中,loss(j)表示训练集中第j个三元组的损失函数值,dist(·)表示两个特征向量之间的距离计算函数；S3.4：根据梯度下降原理,调整上述深度卷积神经网络中前n个卷积层以外的卷积层权重,至三元组的损失函数值总和最小,此时深度卷积神经网络中的参数收敛,得到完成二次迁移学习训练的深度卷积神经网络；S4：将所述测试集图片输入所述深度卷积神经网络,输出相应的特征向量后与测试集中对应的身份信息进行验证,若验证结果为成功,深度卷积神经网络完成训练；若验证结果为失败,则对深度卷积神经网络的结构参数进行调整后,跳转执行S3步骤；S5：将待身份验证的眼球虹膜图片输入所述完成训练的深度卷积神经网络中,输出得到相应的输出特征向量,然后将输出特征向量与存储有人员身份的数据库进行距离匹配,输出身份验证结果。</td>   <td>G06V40/18;G06V10/774;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈知雨;              刘思榆;              艾陶;              侯一鸣;              陈诗瑜;              余建兴;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于知识引导的地理考题生成方法和装置</td>   <td>广东省</td>   <td>CN115455167A</td>   <td>2022-12-09</td>   <td>本发明提供一种基于知识引导的地理考题生成方法,包括以下步骤：S1：获取非结构化的地理知识文本语料构建地理文本语料库；S2：设置句法模板,从地理文本语料库识别得到相应的事理句子；S3：从事理句子中抽取地理事件；S4：对地理事件进行泛化,并根据泛化后的地理事件构建结构化的地理知识图谱；S5：根据结构化的地理知识图谱构建图知识引导的序列模型；S6：基于图知识引导的序列模型生成地理考题。本发明还提供一种基于知识引导的地理考题生成装置,用于实现所述的一种基于知识引导的地理考题生成方法。本发明提供一种基于知识引导的地理考题生成方法和装置,解决了目前的机器自动命题技术只能生成简单的地理考题的问题。</td>   <td>1.一种基于知识引导的地理考题生成方法,其特征在于,包括以下步骤：S1：获取非结构化的地理知识文本语料构建地理文本语料库；S2：设置句法模板,并根据句法模板从地理文本语料库识别得到相应的事理句子；S3：基于依存句法分析和语义角色标注的方式从事理句子中抽取地理事件；S4：对地理事件进行泛化,得到泛化后的地理事件,并根据泛化后的地理事件构建结构化的地理知识图谱；S5：根据结构化的地理知识图谱构建图知识引导的序列模型；S6：基于图知识引导的序列模型生成地理考题。</td>   <td>G06F16/332;G06F16/29;G06F16/36;G06F40/30;G06F40/279;G06N3/04;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺丰;              陈伟峰;              陈志广;                   林倞       </td>   <td>中山大学</td>   <td>一种文本描述驱动的行人搜索方法</td>   <td>广东省</td>   <td>CN115455226A</td>   <td>2022-12-09</td>   <td>本发明公开了一种文本描述驱动的行人搜索方法,如下：构建基于对称Transformer的双流模型,所述的双流模型包括一个视觉Transformer编码器和一个文本Transformer编码器；对于图片,先将图片进行均分切分,将每个图片块进行图像块的线性映射后与位置编码相加作为输入视觉Transformer编码器的第一编码向量；对于文本,将每个词语先进行向量化编码,再经过词的线性映射并加上位置编码后作为输入文本Transformer编码器的第二编码向量；将视觉Transformer编码器输出的图像全局特征和文本Transformer编码器输出的文本全局特征逐一进行余弦相似度计算,找到和对应文本余弦相似度最高的图像,即可实现基于文本的行人搜索。</td>   <td>1.一种文本描述驱动的行人搜索方法,其特征在于：所述的方法包括步骤如下：构建基于对称Transformer的双流模型,所述的双流模型包括一个视觉Transformer编码器和一个文本Transformer编码器；对于图片,先将图片进行均分切分,将每个图片块进行图像块的线性映射后与位置编码相加作为输入视觉Transformer编码器的第一编码向量；所述的第一编码向量为N1个D维向量；其中,N1表示图像块数量；对于文本,将每个词语先进行向量化编码,再经过词的线性映射并加上位置编码后作为输入文本Transformer编码器的第二编码向量；所述的第二编码向量为N2个D维向量,其中,N2表示单词数量；将视觉Transformer编码器输出的图像全局特征和文本Transformer编码器输出的文本全局特征逐一进行余弦相似度计算,找到和对应文本余弦相似度最高的图像,即可实现基于文本的行人搜索。</td>   <td>G06F16/583;G06N3/08;G06V10/42;G06V10/44;G06V10/74</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              莫一凡;                   郭瀚阳       </td>   <td>中山大学</td>   <td>漏洞修复方法、装置、设备及可读存储介质</td>   <td>广东省</td>   <td>CN115455433A</td>   <td>2022-12-09</td>   <td>本申请提供了一种漏洞修复方法、装置、设备及可读存储介质,本申请在获取待修复的智能合约源代码之后,可以将待修复智能合约的源代码进行序列化得到目标语言序列,以便可将目标语言序列输入预测模型进行处理,目标语言序列经过预测模型处理后可得到预测后的目标语言序列。此后,可将所述预测后的目标语言序列进行反序列化,得到已修复的智能合约的源代码,以供推荐给研发人员。可修复不同类型的代码漏洞,并且对曾出现过的代码漏洞有相对较高的修复成功率。研发人员在编写完智能合约源代码只需将已完成的源代码传入预测模型进行运算,就可得到修复智能合约的源代码的漏洞的推荐方案,效率上相比于现有的漏洞修复方法有明显优势。</td>   <td>1.一种漏洞修复方法,其特征在于,包括：获取待修复智能合约的源代码；将所述待修复智能合约的源代码进行序列化,得到目标语言序列；利用预设的预测模型对所述目标语言序列进行处理,得到预测后的目标语言序列,其中,所述预测模型以对有漏洞的智能合约源代码进行序列化得到的初始语言序列作为训练样本,以将所述初始语言序列中,漏洞对应的语言子序列替换为修复后的语言子序列,得到的语言序列作为样本标签训练得到；将所述预测后的目标语言序列进行反序列化,得到已修复的智能合约的源代码。</td>   <td>G06F21/57</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              黄明源;                   孔雀屏       </td>   <td>中山大学</td>   <td>DeFi项目漏洞检测方法、装置、设备及可读存储介质</td>   <td>广东省</td>   <td>CN115455434A</td>   <td>2022-12-09</td>   <td>本申请公开了一种DeFi项目漏洞检测方法、装置、设备及可读存储介质,方法包括：先根据目标地址确定待检测的目标DeFi项目的源码,再确定该源码的污点汇聚点；若目标DeFi项目需要调用第三方DeFi项目的价格查询函数,则将第三方DeFi项目的价格查询函数作为污染源；并判断与污染源相关的污染源变量能否从污染源传播到污点汇聚点；若能,则将目标地址、污点汇聚点、污染源及污染源变量作为目标DeFi项目的漏洞数据进行输出。显然,本申请根据DeFi项目是否需要调用第三方DeFi项目的价格查询函数来判断是否会引发漏洞风险,实现了在攻击前对漏洞进行检测,从而规避损失,相比现有技术的在攻击发生后进行检测、仅能避免攻击造成的损失进一步扩大化,更具备现实意义。</td>   <td>1.一种DeFi项目漏洞检测方法,其特征在于,包括：获取待检测的目标DeFi项目的目标地址并确定所述目标地址的污点汇聚点；从预先建立的源码库中获取所述目标地址的目标DeFi项目的目标源码,所述源码库包含预先录入的DeFi项目的地址及其源码；判断所述目标源码是否需要调用第三方DeFi项目的价格查询函数；若是,则将所述第三方DeFi项目的价格查询函数确定为污染源；判断由所述污染源引入的污染源变量能否传播到所述污点汇聚点；若能,则将所述目标地址、所述污点汇聚点、所述污染源及所述污染源变量作为所述目标DeFi项目的漏洞数据,输出所述漏洞数据。</td>   <td>G06F21/57</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              陈翔;              叶铭熙;                   郝偲成       </td>   <td>中山大学</td>   <td>一种智能合约模糊测试方法、装置、存储介质及电子设备</td>   <td>广东省</td>   <td>CN115455435A</td>   <td>2022-12-09</td>   <td>本发明公开了一种智能合约模糊测试方法、装置、存储介质及电子设备,方法为：S1：获取智能合约数据集,构建各智能合约的函数调用图和各函数的控制流图；S2：依次运行第一测试用例集中的各测试用例,记录各测试用例覆盖的函数和基本块,删除未覆盖新函数和新基本块的测试用例,根据收集的漏洞信息和漏洞测试预言判断智能合约是否存在对应漏洞；S3：计算各测试用例到目标基本块的第一距离,将第一距离最小值对应的测试用例加入第二测试用例集,根据第二测试用例集生成新的测试用例并加入第一测试用例集；执行S2直至模糊测试结束。本发明能生成更高质量的测试用例,更高概率覆盖代码分支和触发安全漏洞,提高了安全漏洞检测的效率和准确度。</td>   <td>1.一种智能合约模糊测试方法,其特征在于,包括以下步骤：S1：获取智能合约数据集,构建各智能合约的函数调用图和各函数的控制流图；S2：依次运行第一测试用例集中的各测试用例,并记录各测试用例所覆盖的函数和基本块,若当前测试用例只覆盖了前面测试用例已覆盖的函数和基本块,则从所述第一测试用例集中删除当前测试用例,根据各测试用例运行时收集的漏洞信息和预设的漏洞测试预言判断所述智能合约中是否存在对应漏洞,所述基本块为所述控制流图中各分支对应的代码；S3：计算所述第一测试用例集中各测试用例到目标基本块的第一距离,所述目标基本块是从所有测试用例未覆盖的基本块中随机选择的,将所述第一距离的最小值对应的测试用例加入第二测试用例集,根据所述第二测试用例集中的测试用例生成若干新的测试用例,将所述新的测试用例加入所述第一测试用例集,返回执行S2直至模糊测试时间达到预设的时间阈值。</td>   <td>G06F21/57;G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              陈焕泽;                   郑沛霖       </td>   <td>中山大学</td>   <td>基于符号执行的智能合约漏洞检测方法、装置及相关设备</td>   <td>广东省</td>   <td>CN115455436A</td>   <td>2022-12-09</td>   <td>本申请公开了一种基于符号执行的智能合约漏洞检测方法、装置及相关设备,该方法包括：每当执行完一个操作码,将此时的状态数据保存到预设的共享内存中；基于所述状态数据,判断是否需要执行路径分叉；若是,获取第一探索分支和第二探索分支,并利用原先的进程执行第一探索分支,利用一个新的进程执行第二探索分支；当所有进程执行完后,基于保存于所述共享内存的所有状态数据,构建全局变量；基于所述全局变量,生成漏洞检测结果。本申请采用多进程对路径分支进行并行探索,提高了符号执行在智能合约漏洞检测中的执行效率。</td>   <td>1.一种基于符号执行的智能合约漏洞检测方法,其特征在于,包括：每当执行完一个操作码,将此时的状态数据保存到预设的共享内存中；基于所述状态数据,判断是否需要执行路径分叉；若是,获取第一探索分支和第二探索分支,并利用原先的进程执行第一探索分支,利用一个新的进程执行第二探索分支；当所有进程执行完后,基于保存于所述共享内存的所有状态数据,构建全局变量；基于所述全局变量,生成漏洞检测结果。</td>   <td>G06F21/57;G06F16/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         喻雅玲;              刘丙军;              傅健宇;                   陈毓灵       </td>   <td>中山大学</td>   <td>一种分析流域水资源工程对气象-水文干旱影响的方法</td>   <td>广东省</td>   <td>CN115455707A</td>   <td>2022-12-09</td>   <td>本发明公开一种分析流域水资源工程对气象-水文干旱影响的方法,先收集目标流域的数据,并预处理形成数据库,用以输入SWAT模型中进行水文过程的模拟,并得到模拟月流量数据,之后再对流域进行子流域及水文响应单元划分,然后对参数进行敏感性分析,选出敏感性较高的参数,再对参数进行率定与验证,确定最优值,并对此时的SWAT模型进行合理性和适用性的评价,以此得到较为优选的目标SWAT模型,最后通过目标SWAT模型构建不同的驱动因素方案进行气象-水文干旱传播的归因分析。通过本发明的方法,可有效探究水资源开发利用等对流域气象-水文干旱过程的影响,为未来流域干旱综合防治提供科学依据。</td>   <td>1.一种分析流域水资源工程对气象-水文干旱影响的方法,其特征在于,包括以下步骤：步骤1：选定目标流域,收集目标流域在一段时期内的DEM数字高程数据、土壤数据、土地利用数据、气象数据；步骤2：对土壤数据、土地利用数据、气象数据进行预处理,并构建相应数据库,将数据库输入到SWAT模型中模拟出目标流域在对应时期的水文过程,以此得到目标流域的模拟月流量数据；步骤3：将DEM数字高程数据输入SWAT模型,并在SWAT模型中对目标流域进行子流域及水文响应单元划分；步骤4：对SWAT模型的参数进行敏感性分析,获得敏感程度排名前10的参数；步骤5：根据步骤2获得的模拟月流量数据对敏感程度排名前10的参数进行率定与验证,确定各参数的最优取值,并通过纳什效率系数和决定系数评价SWAT模型进行模拟的合理性和适用性,以此得到调控好参数的目标SWAT模型；步骤6：在目标SWAT模型中,通过构建不同的驱动因素方案,从各方面模拟量化分析对气象-水文干旱传播规律影响。</td>   <td>G06F30/20;G06F16/21;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         江明;                   武晓鸽       </td>   <td>中山大学</td>   <td>一种大规模多天线通信系统调制方式盲识别方法及系统</td>   <td>广东省</td>   <td>CN115456018A</td>   <td>2022-12-09</td>   <td>本发明涉及无线通信技术领域,提出一种大规模多天线通信系统调制方式盲识别方法及系统,其中包括以下步骤：对基站BS接收的N-T个信号样本基于MDL算法进行独立UE数估计,得到任一信号样本相应的独立UE数估计值根据独立UE数估计值,基于CFICA算法对基站BS接收的N-T个信号样本进行混叠信号分离,得到任一信号样本相应的UE发射信号矩阵对任一UE发射信号矩阵进行循环平稳特征提取,构建得到N-T个CF矩阵将CF矩阵输入预设的CDBN模型进行训练,得到CDBN模型；基于完成训练的CDBN模型,对测试数据计算CF矩阵,将得到的CF矩阵输入完成训练的CDBN模型,输出调制方式盲识别结果。</td>   <td>1.一种大规模多天线通信系统调制方式盲识别方法,应用于M-MIMO系统,其特征在于,所述M-MIMO系统包括N-U个带发射天线的用户设备UE,以及装配有M根天线的基站BS；所述方法包括以下步骤：S1、对基站BS接收的N-T个信号样本基于MDL算法进行独立UE数估计,得到任一信号样本相应的独立UE数估计值其中,t＝1,2,...,N-T；S2、根据独立UE数估计值,基于CFICA算法对基站BS接收的N-T个信号样本进行混叠信号分离,得到任一信号样本相应的UE发射信号矩阵其中,S3、对任一所述UE发射信号矩阵进行循环平稳特征提取,构建得到N-T个CF矩阵S4、将CF矩阵输入预设的CDBN模型进行训练,得到CDBN模型；其中,所述CDBN模型包括堆叠设置的若干最大池化的CRBM块,以及用于生成输出的softmax层；每个CRBM块中包括一个可视层、一个检测层和一个池化层；S5、基于S4中完成训练的CDBN模型,对待盲识别的信号数据进行S1-S3操作,将得到的CF矩阵输入完成训练的CDBN模型,输出调制方式盲识别结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卞静;              程广亮;              周永章;                   李焱       </td>   <td>中山大学</td>   <td>一种基于注意力图神经网络的高性能图聚类方法</td>   <td>广东省</td>   <td>CN115456093A</td>   <td>2022-12-09</td>   <td>本发明公开了一种基于注意力图神经网络的高性能图聚类方法,如下：将获取的数据处理为属性图的结构形式；构建并使用多层图注意力神经网络对属性图进行特征抽取,获得属性图的第一隐藏表达；对完整的属性图进行子图采样,将属性图划分为若干子图；构建并使用多层图卷积神经网络分别对每个子图进行特征抽取,获得所有子图的第二隐藏表达的数据集；将第二隐藏表达的数据集中每个节点的第二隐藏表达,和第一隐藏表达进行堆叠、融合,得到最终的隐藏表达；将最终的隐藏表达输入多层感知机中,输出每个节点对每个类别的聚类分配信息。本发明能显著提升图表示学习能力,提高属性图聚类的性能,能够更精确地挖掘数据中潜在的信息和知识。</td>   <td>1.一种基于注意力图神经网络的高性能图聚类方法,其特征在于：所述的方法包括步骤如下：将获取的数据处理为属性图的结构形式；构建并使用多层图注意力神经网络对属性图进行特征抽取,获得属性图的第一隐藏表达；对完整的属性图进行子图采样,将属性图划分为若干子图；构建并使用多层图卷积神经网络分别对每个子图进行特征抽取,获得所有子图的第二隐藏表达的数据集；将第二隐藏表达的数据集中每个节点的第二隐藏表达,和第一隐藏表达进行堆叠、融合,得到最终的隐藏表达；将最终的隐藏表达输入多层感知机中,输出每个节点对每个类别的聚类分配信息。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小玲;              林浩添;              郭翀;              于姗姗;              徐正杰;                   伍本娟       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于卷积神经网络的脉络膜血管指数预测方法和装置</td>   <td>广东省</td>   <td>CN115456962A</td>   <td>2022-12-09</td>   <td>本发明公开了一种基于卷积神经网络的脉络膜血管指数预测方法和装置。该方法包括步骤：获取待识别的光学相干断层扫描图像,将所述待识别的光学相干断层扫描图像输入至基于卷积神经网络的脉络膜血管指数预测模型,输出所述预测待识别的光学相干断层扫描图像对应的脉络膜面积、管腔面积和脉络膜血管指数(CVI)。本发明提高了对脉络膜面积、管腔面积和CVI值的识别准确度。</td>   <td>1.一种基于卷积神经网络的脉络膜血管指数预测方法,其特征在于,包括以下步骤：获取待识别的光学相干断层扫描图像,将所述待识别的光学相干断层扫描图像输入至基于卷积神经网络的脉络膜血管指数预测模型,输出所述待识别的光学相干断层扫描图像对应的脉络膜面积、管腔面积和CVI值。</td>   <td>G06T7/00;G06T7/62;G06N3/04;G06N3/08;A61B3/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏航;              周凡;              刘海亮;              陈小燕;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>一种基于时空关系的行为识别方法及电子设备</td>   <td>广东省</td>   <td>CN115457660A</td>   <td>2022-12-09</td>   <td>本申请适用于设备管理技术领域,提供了一种基于时空关系的行为识别方法及电子设备,方法包括：接收待识别的目标视频数据；将所述目标视频数据导入预设的帧间动作提取网络,得到帧间动作特征数据；将所述帧间动作特征数据导入特征提取网络,输出所述目标视频数据对应的稀疏特征数据；所述特征提取网络是通过选择权重对池化融合网络内的各个卷积核进行稀疏性约束处理后生成的；将所述目标视频数据导入上下文注意力网络,确定所述目标视频数据中目标对象的步态行为数据；根据所述步态行为数据以及所述稀疏特征数据,得到所述目标对象的行为类别。采用上述方法能够大大降低了视频数据在进行行为识别过程中的计算成本,继而提高了运算效率。</td>   <td>1.一种基于时空关系的行为识别方法,其特征在于,包括：接收待识别的目标视频数据；将所述目标视频数据导入预设的帧间动作提取网络,得到帧间动作特征数据；所述帧间动作特征数据用于确定所述目标视频数据中相邻的视频图像帧之间的动作特征信息；将所述帧间动作特征数据导入特征提取网络,输出所述目标视频数据对应的稀疏特征数据；所述特征提取网络是通过选择权重对池化融合网络内的各个卷积核进行稀疏性约束处理后生成的；将所述目标视频数据导入上下文注意力网络,确定所述目标视频数据中目标对象的步态行为数据；所述上下文注意力网络用于提取所述目标视频数据中所述目标对象与环境对象之间的相互位置关系；根据所述步态行为数据以及所述稀疏特征数据,得到所述目标对象的行为类别。</td>   <td>G06V40/20;G06V20/40;G06V10/80;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>              黄慧玲       </td>   <td>中山大学附属第一医院</td>   <td>一种心脏风险评估系统、设备及介质</td>   <td>广东省</td>   <td>CN115458172A</td>   <td>2022-12-09</td>   <td>本申请公开了一种心脏风险评估系统、设备及介质,属于计算机领域,包括：数据采集模块,采集测试者在多个维度的评估数据；维度分析模块,根据评估数据,确定多个维度分别对应的风险指数或评估系数；风险确认模块,根据风险指数和评估系数,确定测试者对应的心脏风险级别。在多个维度中,从个人信息,病史信息,症状信息,家庭信息和日常作息信息等方面的内容能够更加全面对测试者的心脏风险进行评估,通过数据之间的相关性,来进行最终风险总分的计算,增加评估准确度。不仅仅提供风险评估的系统,还为风险的分析,提供了多个维度的统计数据,从而可以从年龄,性别,年纪,病症,日常习惯等等方面来分级统计产生心脏风险的可能性。</td>   <td>1.一种心脏风险评估系统,其特征在于,包括：数据采集模块,采集测试者在多个维度的评估数据,所述多个维度包括基础信息、心脏相关一般问题、心脏健康问题、遗传健康问题、运动作息信息中的至少多个；维度分析模块,根据所述评估数据,确定所述多个维度分别对应的风险指数或评估系数；风险确认模块,根据所述风险指数和评估系数,确定所述测试者对应的心脏风险级别。</td>   <td>G16H50/30;G16H10/60;A61B5/02;A61B5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林俊浩;              单云霄;                   陈龙       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的道路裂缝自动检测方法</td>   <td>广东省</td>   <td>CN110503637B</td>   <td>2022-12-06</td>   <td>本发明涉及图像识别与深度学习技术领域,更具体地,涉及一种基于卷积神经网络的道路裂缝自动检测方法。本发明基于轻量级的卷积神经网络,仅需对数据进行手动标注,根据检测衡量标准精确的和召回率来筛选并保持网络权重,在进行检测时,对图片进行(平方)压缩后,再切分成27*27大小进行检测,根据初步检测的结果对相应的裂缝区域进行多次旋转变换后再检测,更新检测结果,得到每一帧中裂缝的位置标出并响铃提示。本发明的模型是轻量级的,具有很高的召回率和精确度,可用于实时的裂缝检测,对于检测到的裂缝我们会记录其位置信息并标出,同时可以响铃警示工作人员,比以上提出的发明更具有实用性。</td>   <td>1.一种基于卷积神经网络的道路裂缝自动检测方法,其特征在于,包括以下步骤：S1.采集含有裂缝的图片数据,使用图像处理软件对图片进行像素级别的标注；S2.从原始图片中提取出w*h大小的小图片,利用统计的方法,根据小图片中裂缝像素的总数来划分正负样本并根据一定比例划分为训练集和测试集,对训练集的正样本进行旋转,翻转操作,增加训练集数据的多样性；S3.采用迁移学习的思想,边训练边测试,取在测试集中准确率和召回率综合最好的网络权重进行保存,得到一个二分类器；在所述的S3步骤中,使用卷积神经网络进行分类,包括以下步骤：S31.神经网络的参数设置；所用的模型都基于Nvidia GTX1070上的Pytorch的API,将训练的epoch设置为25,使用SGD作为优化器,模型的学习率、batch size、冲量、衰减步数和衰减率分别为0.001、256、0.9、7和0.1；S32.使用交叉熵函数作为Loss函数；表示为如下公式：                  其中,为预测值,y-i为真实值,即标注值；S33.网络选取精确度与召回率；对模型的召回率和精确度进行计算,暂存当前最好的模型的权重,所有epoch的训练结束后保存具有最好的召回率和精确度的模型,其计算公式如(2)(3)：                                    式中,Pr、Re、TP、FP和FN分别为精确度、召回率、真正例、假正例和假负例；由于在程序中无法直接获取TP、FP和FN的值,令R为检测中正样本的数目,P为预测结果中为正样本的数目,T为预测值与真实值不同的样本数目,R、P和T都是可以在程序运行时计算出来的,由R、P和T的定义,有如下关系：R＝TP+FN      (4)P＝TP+FP    (5)T＝FN+TN     (6)由上式得：                  因此精确度和召回率的公式可改写成如下形式：                                    S34.选取网络权重；召回率大于当前最好的召回率或精确度大于当前最好的精确度,则将其暂存于内存中,执行完所有的epoch后,将其保存到本地；S4.使用摄像头获取路面的图像,将输入的每一帧图片进行4x4像素邻域内的双立方插值,将像素改变为W*H；S5.将图片等分为w*h大小的检测单元并记录其位置信息,利用步骤S3训练出来的二分类器对每一个检测单元分类,输出该单元是否为裂缝单元；S6.对检测为裂缝的区域分别进行多个角度的旋转,得到多个新的样本,再次进行检测,若有两个以上被分类为裂缝,则确信其为裂缝,否则更新其为非裂缝；S7.根据步骤S6优化后的裂缝结果,标出裂缝单元在原图片的位置,如有裂缝单元,则给出提示。</td>   <td>G06T7/00;G06V10/764;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         付青;              杨航;                   朱坤       </td>   <td>中山大学</td>   <td>基于历史数据集时间跨度优化的光伏发电功率预测方法及系统</td>   <td>广东省</td>   <td>CN114819391B</td>   <td>2022-12-06</td>   <td>本发明提出一种基于历史数据集时间跨度优化的光伏发电功率预测方法,涉及光伏发电预测的技术领域,首先确定用于光伏发电功率预测的历史功率数据来源,按时间跨度调整用于预测光伏发电功率的历史数据集的样本数据数目,在历史数据集的数据样本数设置值的限定下,获取预测误差指标随历史数据集的样本数变化的趋势曲线,在预测误差指标最优点附近搜寻最优的历史数据集样本数,根据调整后的历史数据集重新进行预测,往复进行,加快最佳历史数据集样本数的搜寻过程,直至选择最佳的历史数据集样本数目,提高了光伏发电功率预测精度,避免历史数据集选取粗糙,导致计算量大及干扰大的问题。</td>   <td>1.一种基于历史数据集时间跨度优化的光伏发电功率预测方法,其特征在于,所述方法包括以下步骤：S1.确定用于光伏发电功率预测的历史功率数据来源,从历史功率数据来源中选定一定时间跨度下、具有若干数据样本数的历史数据集,并对历史数据集进行预处理；所述的预处理操作包括对历史数据集中的数据进行数据清洗,以去除历史数据集中的异常数据和干扰；S2.基于已预处理的历史数据集,利用光伏发电功率预测算法A进行光伏发电功率预测,并计算光伏发电功率预测结果的预测误差指标；S3.以P为历史数据集的数据样本数按时间跨度方向增加的间隔,将历史数据集的数据样本数增加P,利用光伏发电功率预测算法A进行光伏发电功率预测,并计算光伏发电功率预测结果的预测误差指标；S4.判断历史数据集的数据样本数是否达到设置值,若是,执行步骤S5；否则,返回步骤S3；S5.形成预测误差指标随历史数据集的样本数变化的趋势曲线,确定趋势曲线中的最低点,以最低点对应的时间跨度下样本数目的历史数据集进行光伏发电功率预测,并计算光伏发电功率预测结果的预测误差指标；S6.以P为历史数据集的数据样本数按时间跨度方向增加的间隔,将最低点对应的时间跨度下的历史数据集的数据样本数增加P,然后进行光伏发电功率预测,判断预测误差指标是否减小,若是,将历史数据集的数据样本数增加P,执行步骤S7；否则,以H为历史数据集的数据样本数按时间跨度方向减小的间隔,将历史数据集的数据样本数减少H,H≠P,执行步骤S7；S7.判断历史数据集的数据样本数是否达到设置值,若是,形成预测误差指标随历史数据集的样本数变化的趋势曲线,确定趋势曲线中的拐点,以拐点对应的时间跨度下样本数目的历史数据集进行光伏发电功率预测；否则,返回步骤S6。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/06;H02J3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         毛庆国;              梁常德;              蔡铭;              尹民;              王理民;              吴斌;              何晋勇;              万伟;                   刘永红       </td>   <td>中山大学;深圳市生态环境智能管控中心;深圳市思唯环境科技有限公司;深圳深态环境科技有限公司</td>   <td>基于glTF模型和建筑物轮廓拓展的三维渲染融合方法</td>   <td>广东省</td>   <td>CN115205433B</td>   <td>2022-12-06</td>   <td>本发明公开了基于glTF模型和建筑物轮廓拓展的三维渲染融合方法,包括：获取建筑物轮廓数据,根据建筑物轮廓数据对建筑物侧面进行排列；设置拓展步长和最大拓展距离；按照排列顺序对每个建筑物侧面进行拓展,且对建筑物侧面采用相同的拓展步长逐步进行拓展；计算建筑物侧面被glTF模型的遮挡率,根据遮挡率计算损失函数；根据损失函数获取各建筑物侧面的最优拓展距离；根据最优拓展距离对建筑物进行拓展。本发明通过对建筑物侧面进行逐步拓展,并通过计算损失函数,得到每个建筑物侧面的最优拓展距离,最后依据最优拓展距离来对建筑物进行拓展,使得建筑物轮廓得到拓展,在渲染时不被glTF模型遮挡。本发明可广泛应用于三维渲染领域。</td>   <td>1.一种基于glTF模型和建筑物轮廓拓展的三维渲染融合方法,其特征在于,包括以下步骤：获取建筑物轮廓数据,根据建筑物轮廓数据对建筑物侧面进行排列；设置拓展步长和最大拓展距离；按照排列顺序对每个建筑物侧面进行拓展,且对建筑物侧面采用相同的拓展步长逐步进行拓展；计算建筑物侧面被glTF模型的遮挡率,根据遮挡率计算损失函数；根据损失函数获取各建筑物侧面的最优拓展距离；根据最优拓展距离对建筑物进行拓展；其中,glTF模型的坐标系与建筑物的坐标系为同一坐标系。</td>   <td>G06T15/00;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄林冲;              张燕丽;              梁禹;              蒋凯;              梁尔斌;              王建伟;              杜风华;                   李树良       </td>   <td>中山大学;中铁十四局集团有限公司</td>   <td>管片环向接头弯曲模式识别方法、系统、设备和存储介质</td>   <td>广东省</td>   <td>CN115438720A</td>   <td>2022-12-06</td>   <td>本发明提供了管片环向接头弯曲模式识别方法、系统、设备和存储介质,通过获取环向接头的截面处参数信息,并根据预设分类标准对环向接头弯曲模式进行划分得到若干个环向接头弯曲模式,再根据截面处参数信息,对各个环向接头弯曲模式的环向接头进行受力变形状态分析,分别得到对应的弯矩转角表达式,并根据各个弯矩转角表达式和不同的轴力类型,得到对应不同受力状态下的临界弯矩表达式后,根据临界弯矩表达式生成环向接头内力分布区域图,以及在获取实际工程中环向接头的实测弯矩值和实测轴力值后,根据实测弯矩值、实测轴力值和环向接头内力分布区域图得到实际环向接头弯曲模式的技术方案,能够充分考虑环向接头处的非线性特性,简单高效的得到各临界弯矩的高可靠性计算公式,根据工程中所获得的弯矩和轴力值在内力区域分布图中的位置确定接头的变形模式,从而能够高效指导工程。</td>   <td>1.一种管片环向接头弯曲模式识别方法,其特征在于,所述方法包括以下步骤：获取环向接头的截面处参数信息,并根据预设分类标准对环向接头弯曲模式进行划分,得到若干个环向接头弯曲模式；所述截面处参数信息包括截面尺寸参数和截面材料参数；根据所述截面处参数信息,对各个环向接头弯曲模式的环向接头进行受力变形状态分析,分别得到对应的弯矩转角表达式；根据各个弯矩转角表达式和不同的轴力类型,得到对应不同受力状态下的临界弯矩表达式；根据各个受力状态下的临界弯矩表达式,得到环向接头内力分布区域图；获取实际工程中环向接头的实测弯矩值和实测轴力值,并根据所述实测弯矩值、实测轴力值和所述环向接头内力分布区域图,得到对应的实际环向接头弯曲模式。</td>   <td>G06K9/62;G06F30/13;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卞静;              卓绍烜;                   李焱       </td>   <td>中山大学</td>   <td>一种基于图神经网络的区块链钓鱼诈骗识别的方法</td>   <td>广东省</td>   <td>CN115438751A</td>   <td>2022-12-06</td>   <td>本发明提供一种基于图神经网络的区块链钓鱼诈骗识别的方法,对于交易数据进行预处理,将交易数据处理为交易网络图；对交易网络图进行聚类处理,得到全局视角图；对交易网络图进行采样处理,得到局部视角图；构建并训练图神经网络；将全局视角图输入训练好的图神经网络得到全局交易视角的节点嵌入；所述的节点嵌入包括交易网络的结构和边视角信息；将局部视角图输入训练好的图神经网络得到局部交易视角的节点嵌入；将全局交易视角的节点嵌入和局部交易视角的节点嵌入进行拼接后一起输入多层感知器,以实现网络钓鱼地址的分类识别。本发明基于多交易视角的数据挖掘从交易网络中更多有效信息来提高以太坊钓鱼诈骗识别的识别性能。</td>   <td>1.一种基于图神经网络的区块链钓鱼诈骗识别的方法,其特征在于：所述的方法包括以下步骤：对于交易数据进行预处理,将交易数据处理为交易网络图；对交易网络图进行聚类处理,得到全局视角图；对交易网络图进行采样处理,得到局部视角图；构建并训练多交易视角注意力图神经网络；将全局视角图输入训练好的多交易视角注意力图神经网络得到全局交易视角的节点嵌入；所述的节点嵌入包括交易网络的结构和边视角信息；将局部视角图输入训练好的多交易视角注意力图神经网络得到局部交易视角的节点嵌入；将全局交易视角的节点嵌入和局部交易视角的节点嵌入进行拼接后一起输入多层感知器,以实现网络钓鱼地址的分类识别。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         范新娟;              王方;              李焱;              庞晓琳;              秦启元;              张倩如;              尹欣科;                   白少梅       </td>   <td>中山大学附属第六医院</td>   <td>MRI图像的可疑区域分割方法、设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN115439439A</td>   <td>2022-12-06</td>   <td>本发明提供了一种MRI图像的可疑区域分割方法、设备及计算机可读存储介质,该方法包括：获取若干个直肠癌MRI图像样本；其中,每个直肠癌MRI图像样本包括多个MRI切片,每一MRI切片标注有可疑区域；对各个直肠癌MRI图像样本进行预处理,得到具有相同的像素间距和相同图像尺寸的直肠癌MRI图像样本；采用预处理后的直肠癌MRI图像样本对预先构建的U-Net网络模型进行模型训练,得到MRI图像分割模型；采用MRI图像分割模型对待检测MRI图像进行分割处理,以分割出待检测MRI图像中的可疑区域,本发明提供的MRI图像分割模型,能准确分割出MRI图像中直肠的可疑区域,图像分割更加客观、耗时短,能有效提升图像分割效果。</td>   <td>1.一种MRI图像的可疑区域分割方法,其特征在于,包括：获取若干个直肠癌MRI图像样本；其中,每个所述直肠癌MRI图像样本包括多个MRI切片,每一所述MRI切片标注有可疑区域；对各个所述直肠癌MRI图像样本进行预处理,得到具有相同的像素间距和相同图像尺寸的直肠癌MRI图像样本；采用预处理后的直肠癌MRI图像样本对预先构建的U-Net网络模型进行模型训练,得到MRI图像分割模型；采用所述MRI图像分割模型对待检测MRI图像进行分割处理,以分割出所述待检测MRI图像中的可疑区域。</td>   <td>G06T7/00;G06T7/11;G06T5/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         范新娟;              云径平;              万香波;              王方;              马腾辉;                   钟清华       </td>   <td>中山大学附属第六医院;中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>MRI图像肠损伤区域的分割方法、装置及等级评估系统</td>   <td>广东省</td>   <td>CN115439491A</td>   <td>2022-12-06</td>   <td>本发明提供了一种MRI图像肠损伤区域的分割方法、装置及等级评估系统,该MRI图像肠损伤区域的分割方法,包括：获取若干个肠损伤MRI图像样本；其中,肠损伤MRI图像样本是扫描因肿瘤放射治疗导致的慢性放射性肠损伤病例得到；对每个肠损伤MRI图像样本中的肠损伤区域进行标签化分割,得到若干个标签图像；对标签图像进行标准化和归一化处理；根据肠损伤MRI图像样本及其对应的标签图像对预先构建的U-Net网络模型进行模型训练,得到放射性肠损伤图像分割模型；采用放射性肠损伤图像分割模型对待检测MRI图像进行分割处理,以分割出待检测MRI图像中的肠损伤区域；本发明能准确分割出MRI图像中的肠损伤区域,提升图像分割效果。</td>   <td>1.一种MRI图像肠损伤区域的分割方法,其特征在于,包括：获取若干个肠损伤MRI图像样本；其中,所述肠损伤MRI图像样本是扫描因肿瘤放射治疗导致的慢性放射性肠损伤病例得到；对每个所述肠损伤MRI图像样本中的肠损伤区域进行标签化分割,得到若干个标签图像；对所述标签图像进行标准化和归一化处理；根据所述肠损伤MRI图像样本及其对应的标签图像对预先构建的U-Net网络模型进行模型训练,得到放射性肠损伤图像分割模型；采用所述放射性肠损伤图像分割模型对待检测MRI图像进行分割处理,以分割出所述待检测MRI图像中的肠损伤区域。</td>   <td>G06T7/11;G06T7/00;G06V10/764;G06V10/774;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              覃军友;              沈智华;              张小虎;              钟立军;                   宁丞浩       </td>   <td>中山大学</td>   <td>基于滑动窗口的动态轨迹融合方法及系统</td>   <td>广东省</td>   <td>CN115439508A</td>   <td>2022-12-06</td>   <td>本发明公开了一种基于滑动窗口的动态轨迹融合方法及系统,该方法包括：基于滑动窗口利用最近发现点集拟合的轨迹编目方法对空间目标轨迹进行关联,得到轨迹关联结果；基于轨迹休眠抑制的噪声轨迹过滤方法对轨迹关联结果进行过滤,得到目标轨迹；对目标轨迹的空白点与空白段进行补充融合,得到最终的目标轨迹。该系统包括：轨迹关联模块、轨迹过滤模块和补充融合模块。通过使用本发明,能够获得稳定正确的目标轨迹。本发明作为一种基于滑动窗口的动态轨迹融合方法及系统,可广泛应用于轨迹融合技术领域。</td>   <td>1.一种基于滑动窗口的动态轨迹融合方法,其特征在于,包括以下步骤：基于滑动窗口利用最近发现点集拟合的轨迹编目方法对空间目标轨迹进行关联,得到轨迹关联结果；基于轨迹休眠抑制的噪声轨迹过滤方法对轨迹关联结果进行过滤,得到目标轨迹；对目标轨迹的空白点与空白段进行补充融合,得到最终的目标轨迹。</td>   <td>G06T7/246;G06T7/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈梓阳;                   郑伟诗       </td>   <td>中山大学</td>   <td>基于KCF算法的多目标行人跟踪系统及跟踪方法</td>   <td>广东省</td>   <td>CN109615641B</td>   <td>2022-11-29</td>   <td>本发明公开了一种基于KCF算法的多目标行人跟踪系统及跟踪方法,系统包括初始化模块、单目标跟踪KCF模块、跟踪与检测匹配模块、目标移除模块、打印模块和目标新增模块；所述初始化模块,用于初始化所有变量；所述单目标跟踪KCF模块,用于对单个目标进行跟踪；所述跟踪与检测匹配模块,对每个目标的跟踪结果与画面中的检测目标进行匹配；所述目标移除模块,用于判定目标是否已经离开画面；所述打印模块,用于对所述跟踪与检测匹配模块的匹配结果,在图上画出行人的边框以及其id信息；所述目标新增模块,用于判定检测目标是否为新出现的目标。本发明基于单目标跟踪算法KCF设计出一个多目标跟踪的系统框架,实时地提供各个目标的运动轨迹以及id信息。</td>   <td>1.基于KCF算法的多目标行人跟踪系统,其特征在于,包括初始化模块、单目标跟踪KCF模块、跟踪与检测匹配模块、目标移除模块、打印模块和目标新增模块；所述初始化模块,用于初始化所有变量；所述单目标跟踪KCF模块,用于对单个目标进行跟踪；所述跟踪与检测匹配模块,对每个目标的跟踪结果与画面中的检测目标进行匹配,即区分各个目标,将各目标与跟踪轨迹链接；所述跟踪匹配模块中跟踪匹配的过程为：首先初始化模型与目标检测结果的状态管理器,然后遍历容器里的模型,对每个模型都使用单目标跟踪KCF模块里的跟踪功能进行跟踪预测,即输入当前桢图片、上一桢跟踪到的目标的边框坐标、该目标的模型到单目标跟踪KCF模块,得到当前桢跟踪到的目标的边框坐标与该目标更新后的模型,并将更新后的模型替换掉容器中的原模型；然后再将当前桢跟踪到的目标的边框坐标与当前图中所有目标检测结果进行匹配对比,检查该目标的跟踪结果是否存在于画面中,具体为计算两个边框区域的overlap重合覆盖率,若overlap大于设定的阈值,则认为匹配成功,跟踪结果与检测框是同一个目标,将检测框与该目标对应的id添加到打印列表中；而对于匹配失败的情况,则需更新模型与目标检测结果的状态管理器,记录匹配失败的模型与检测框；所述目标移除模块,用于判定目标是否已经离开画面；所述目标移除模块中,移除的具体操作为：先利用模型状态管理器挑出匹配失败的模型,作为已离开目标的候选项；模型匹配失败,说明该目标的跟踪结果在图中没有检测框与其匹配相关,并进行进一步安全检查,连续与后面n桢的检测框计算overlap,若overlap都小于设定的阈值,才真正认为该目标已经离开画面,并且将该目标所对应的模型从容器中移除；所述打印模块,根据之前的匹配结果,从打印队列中逐个取出检测框与其对应的目标id,并在图中打印出来,即将图中的行人用检测框框出来且添加上其对应id；所述目标新增模块,用于判定检测目标是否为新出现的目标,所述目标新增模块中,判定检测目标是否为新出现的目标的方法为：首先利用检测框状态管理器挑出匹配失败的检测框,将其作为新出现的目标的候选项；匹配失败的检测框,说明其与所有模型对应的目标的跟踪结果都没有匹配相关,进一步增加了一步安全检查,计算该检测框与后面n桢的跟踪结果的overlap,若overlap都小于阈值,则说明该检测框为新出现的目标；若为新出现的目标,则利用单目标跟踪KCF模块的初始化功能,输入当前帧图片与该检测框,来初始化该新目标的模型,并将该新模型放进容器内。</td>   <td>G06T7/246</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄俊文;                   倪江群       </td>   <td>中山大学</td>   <td>基于卷积神经网络的JPEG图像隐写分析方法</td>   <td>广东省</td>   <td>CN109934761B</td>   <td>2022-11-29</td>   <td>本发明公开了一种基于卷积神经网络的JPEG图像隐写分析方法,包括以下步骤：S1.构建针对JPEG图像隐写分析的卷积神经网络；S2.准备数据集；S3.初始化卷积神经网络；S4.训练卷积神经网络；S5.利用训练好的卷积神经网络对待检测图像进行隐写分析,计算出分类概率向量从而判定待检测图像是否为载密图像。本发明通过将JPEG图像隐写分析相关的领域知识内嵌到网络结构中,针对JPEG图像隐写分析设计了卷积神经网络结构及相关的参数配置；同时为网络训练引入参数增量约束机制,提高了卷积神经网络的性能,解决了现有的图像隐写分析技术中分类准确率不够高以及无法在低负载情况下直接训练网络等问题。</td>   <td>1.基于卷积神经网络的JPEG图像隐写分析方法,其特征在于,包括以下步骤：S1.构建针对JPEG图像隐写分析的卷积神经网络：包括预处理部分和深度网络部分；所述预处理部分用于预处理JPEG图像,所述深度网络部分用于提取JPEG图像隐写分析特征并进行隐写分析；S2.准备数据集：将原始图像按设定比例随机划分为训练集、验证集、测试集的载体图像,并使用隐写算法对所有载体图像进行隐写生成等量的载密图像；根据隐写算法计算所有载体图像的修改概率矩阵β,然后计算所有载体图像与载密图像相应的L-1范数嵌入失真矩阵t(β)；S3.初始化卷积神经网络：对于卷积神经网络中预处理部分的卷积层,使用高通滤波器对其卷积核进行初始化,并采用截断线性单元作为激活函数；对于除预处理部分的卷积层以外的其他卷积层均使用msra方式进行初始化；S4.训练卷积神经网络：使用AdaDelta算法在步骤S2所述的训练集中对卷积神经网络进行训练,通过验证集对训练中的网络进行验证并通过迭代更新参数直至网络收敛；使用测试集测试网络性能；S5.利用训练好的卷积神经网络对待检测图像进行隐写分析,计算出分类概率向量从而判定待检测图像是否为载密图像；步骤S1中所述的预处理部分包括第一支路,所述第一支路包含一个卷积层,用于对JPEG图像像素值进行预处理,其输出的特征图作为深度网络部分的输入；定义对应该预处理部分的卷积神经网络为Plain-CNN；步骤S1中所述的预处理部分还包括第二支路,第二支路包含一个卷积层,用于对L-1范数嵌入失真矩阵t(β)进行预处理；将第一支路和第二支路的输出对应相加得到的特征图作为深度网络部分的输入；定义对应该预处理部分的卷积神经网络为SAC-CNN；所述的第二支路中卷积层的卷积核在训练过程中不进行更新,卷积核内各元素的取值时刻保持与第一支路中卷积层的卷积核内各元素的绝对值相等,并对第一支路和第二支路中卷积层输出的特征图中所有元素进行一次求算数平方根操作。</td>   <td>G06T1/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李潇焓;              倪江群;              张东;                   苏文康       </td>   <td>中山大学</td>   <td>一种JPEG非对称数字图像隐写方法</td>   <td>广东省</td>   <td>CN110009547B</td>   <td>2022-11-29</td>   <td>本发明涉及一种JPEG非对称数字图像隐写方法,通过获取载体图像,将载体图像划分两个交织子图X-1X-2；计算载体图像的初始化失真代价值和初始化嵌入修改图R-1、R-2；优化R-1中每个DCT块的块内嵌入修改情况,更新子图X-1每个元素的代价值,获取新载密子图Y′-1和新的嵌入修改图R′-1；构造四邻域模型,结合嵌入修改图R′-1和BBC策略更新X-2中每个元素的代价值,并获取新载密子图Y′-2；将载密子图Y′-1和载密子图Y′-2进行合并,得到完整的载密图像Y′,再将其送入隐写分析器检测提出的JPEG非对称隐写算法的安全性能。本发明所提供的一种JPEG非对称数字图像隐写方法,构建了新的代价值更新方法,有效提高算法的安全性能高,通过四邻域模型的建立,实现了水平和垂直两个方向+1/-1失真代价值的同时更新,收敛速度块。</td>   <td>1.一种JPEG非对称数字图像隐写方法,其特征在于,包括以下步骤：S1：获取一张JPEG格式的载体图像X,将载体图像划分两个交织子图X-1、X-2；S2：基于JPEG图像对称隐写算法获取载体图像的初始化失真代价值C-(ori)和初始化嵌入修改图R-1、R-2；S3：优化R-1中每个DCT块的块内嵌入修改情况,更新子图X-1每个元素的代价值,通过模拟仿真嵌入获取新载密子图Y-1'和新的嵌入修改图R'-1；S4：构造四邻域模型,结合嵌入修改图R'-1和BBC策略更新X-2中每个元素的代价值,并通过模拟仿真嵌入获取新载密子图Y-2'；S5：将载密子图Y-1'和载密子图Y-2'进行合并,得到完整的载密图像Y',再将其送入隐写分析器,检测提出的JPEG非对称隐写算法的安全性能；所述步骤S3的步骤具体为：S31：统计嵌入修改图R-1当前DCT块内被修改的数量,用符号N表示,并设置DCT块是否优化的限制条件,具体为：                  S32：列出所有可能的嵌入修改组合,为了降低计算复杂度,随机选取其中一半的嵌入修改组合,即嵌入修改组合总数为K＝0.5×2～N；S33：分别计算当前DCT块的K种修改组合对应的空域嵌入失真代价C-(DCT)；S34：从K个组合的空域嵌入失真代价中选取最小失真代价C-(DCT-min)对应的嵌入修改组合作为该DCT的最优嵌入修改组合,即获取了当前DCT块内每个DCT系数的期望修改方向；S35：根据最优嵌入修改组合更新当前DCT块内每个系数的+1/-1代价值,具体为：设置块内惩罚系数w-(inner)(r-o,r-a),得到的代价值更新公式：                  其中,r-o表示期望修改方向,r-a为实际修改方向；(u,v)表示DCT块的坐标,对于512×512的图像,其取值为0≤u≤63,0≤v≤63范围的整数；(m,n)表示DCT块内系数的坐标,取值是0≤m≤7,0≤n≤7的整数；表示第(u,v)个DCT块内的(m,n)系数的初始代价值；表示第(u,v)个DCT块内的(m,n)系数更新后的新代价值；用C’-1表示由这些新代价值组成的集合；S36：将代价值C'-1和子图X-1送入模拟仿真嵌入器,获取新的载密子图Y-1',并通过与载体图像X做差,再取符号操作,获得子图X-1的新嵌入修改图R'-1。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈颖;                   谢京佑       </td>   <td>中山大学</td>   <td>多模态关联构建模型的训练方法和多模态数据检索方法</td>   <td>广东省</td>   <td>CN115409107A</td>   <td>2022-11-29</td>   <td>本申请公开了多模态关联构建模型的训练方法和多模态数据检索方法,通过构建多模态数据训练关联图,对不同模态下数据特征进行聚类处理从而得到的聚类损失函数值,通过将与每一模态的训练数据的数据特征与从对应的关联特征节点提取的补充特征信息进行特征融合,并计算融合后生成的每一模态的综合训练特征的特征差异,得到成对损失函数值,基于聚类损失函数值和成对损失函数值,调整所述多模态关联构建模型的参数,从而训练得到能够生成融合多模态间数据特征,生成每一模态的综合数据特征的多模态关联构建模型,并可通过融合后的综合数据特征得到多模态数据间的检索结果。相较于现有技术,本申请在进行跨模态检索时的检索结果准确度更高。</td>   <td>1.一种多模态关联构建模型的训练方法,其特征在于,包括：获取训练样本数据库,所述训练样本数据库中包含若干多模态训练数据集,其中每一所述多模态训练数据集中包含至少两种不同模态的训练数据,各种所述训练数据的内容标签相同；对于每一所述多模态训练数据集,分别提取其中每一模态的训练数据的数据特征,并利用K近邻算法构建所述每一模态的训练子图,所述每一模态的训练子图包含中心特征节点、邻居特征节点及特征节点间的关联关系,所述中心特征节点为表征每一模态的训练数据的数据特征的特征节点,所述邻居特征节点为表征所述训练样本数据库中与所述每一模态的训练数据的模态相同,且数据特征满足K近邻条件的各训练数据的特征节点；基于每一所述多模态训练数据集中每一模态的训练子图,利用相似性传播生成多模态数据训练关联图,其中所述多模态数据训练关联图上每一特征节点的关联特征节点为以所述每一特征节点作为中心特征节点时的各个邻居特征节点,与所述每一特征节点对应的训练数据属于同一多模态训练数据集的各个模态的训练数据的特征节点,以及分别以与所述每一特征节点对应的训练数据属于同一多模态训练数据集的各个模态的训练数据作为中心特征节点时的各个邻居特征节点；分别对所述多模态数据训练关联图中各个模态的特征节点对应的训练数据的数据特征进行维度标准化处理和聚类处理,得到各个不同模态的聚类训练图；基于所述各个不同模态的聚类训练图中各个聚类集中的特征节点对应的特征向量以及对应的内容标签,确定聚类损失函数值；对于每一所述多模态训练数据集中每一模态的训练数据的数据特征,从所述多模态数据训练关联图中与每一模态的训练数据对应的每一关联特征节点提取补充特征信息,对所述每一模态的训练数据的数据特征进行融合补充,得到每一模态的训练数据的综合训练特征,所述补充特征信息为从所述多模态数据训练关联图中与每一模态的训练数据对应的每一关联特征节点提取到的,对所述每一模态的训练数据的数据特征进行特征补充的信息,所述综合训练特征的内容标签与对应的所述每一模态的训练数据的内容标签一致；基于所述每一所述多模态训练数据集中每一模态的综合训练特征,确定成对损失函数值；基于所述聚类损失函数值和所述成对损失函数值,生成综合损失函数值；以所述综合损失函数值满足预设条件为目标,更新所述多模态关联构建模型中的参数。</td>   <td>G06K9/62;G06F16/903;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘洋;              经秉中;              李超峰;              邓一术;              陈浩华;              李彬;                   何立儒       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种危及器官自动勾画方法及系统</td>   <td>广东省</td>   <td>CN115409739A</td>   <td>2022-11-29</td>   <td>本发明公开了一种危及器官自动勾画方法及系统,通过将CBCT图像与计划CT图像模型进行优化处理后,得到经过处理后的CBCT图像和CT图像；再将经过处理后的CBCT图像和CT图像输入到自动分割模型中,通过使用自动分割模型对预处理CBCT图像和预处理CT图像进行分割得到自动分割结果后,利用预设函数对自动分割结果进行处理得到分割结果,对自动分割结果进行轮廓线提取得到自动勾画结果,通过使用该方法完成放疗计划中常见的危及器官自动勾画,且引入了对应计划CT的信息辅助,提升自动勾画准确性。</td>   <td>1.一种危及器官自动勾画方法,其特征在于,包括：接收待检测的CBCT图像和计划CT图像,并采用预设方法对所述CBCT图像和计划CT图像进行预处理,得到预处理CBCT图像和预处理计划CT图像；根据预设的自动分割模型对所述预处理CBCT图像和所述预处理计划CT图像进行处理后,得到自动分割结果,再利用预设函数对所述自动分割结果进行处理得到分割结果；对所述分割结果进行轮廓线提取得到自动勾画结果。</td>   <td>G06T5/00;G06N3/04;G06N3/08;G16H30/40;G06T7/11;G06T7/187;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王凯;                   吴洁伟       </td>   <td>中山大学</td>   <td>一种基于T1加权磁共振图像的脑结构分割系统</td>   <td>广东省</td>   <td>CN113298813B</td>   <td>2022-11-25</td>   <td>本发明公开了一种基于T1加权磁共振图像的脑结构分割系统,其系统包括：图像预处理模块、脑结构分割模块、后处理模块和分割结果展示模块。在深度学习模型的基础上,结合提出的洋葱式后处理算法,有效解决了头骨和侧脑室难以精准分割的问题。提出的后处理方法可以识别误分为灰质或白质的头骨部分和识别误分为背景的侧脑室部分,并修正分割结果。此外,本发明基于现代的软件技术设计并构建一个具有良好用户体验的图形界面。本发明的方法及系统可以为临床实践提供一个方便对大脑结构进行量化分析的工具,辅助医生诊断,减轻负担并提高诊断效率。</td>   <td>1.一种基于T1加权磁共振图像的脑结构分割系统,其特征在于：具体包括以下模块：图像预处理模块,脑结构分割模块,后处理模块和分割结果展示模块,图像预处理模块：对采集的T1加权图像进行预处理,判断图像是否在MNI空间,如不在MNI空间则先进行刚性变换对齐到MNI空间；脑结构分割模块：基于nnUNet框架训练分割模型对图像预处理模块的输出图像进行分割；后处理模块：采用洋葱式后处理方法,利用脑结构空间分布位置的先验知识对分割结果进行修正；分割结果展示模块：对分割修正图像进行展示,此模块采用前后端分离设计,后端使用Flask服务器框架和Celery异步任务框架搭建,前端与后端两者通过Socket协议进行通信；在获得最终分割结果后,此模块将分割结果重叠在原图像上,并进行可视化显示；图像预处理模块中采用FAST算法对采集的T1加权图像进行偏置场校正,并用高斯滤波去噪,判断去噪图像是否对齐到MNI空间；图像预处理模块处理的是T1加权图像；脑结构分割模块分割的脑部结构包括侧脑室、白质、灰质、脑脊液和头骨；后处理模块的实现过程为：基于脑结构空间分布位置的先验知识提出了洋葱式后处理方法,已知头骨、脑脊液、灰质、白质和侧脑室由外到内一层层包裹,像一个洋葱,用于修正初步的分割结果；I表示大脑初步分割结果,S、C、G、W和L分别表示头骨、脑脊液、灰质、白质和侧脑室的分割结果；对头骨和侧脑室的分割结果进行修正,修正的具体步骤如下：首先用I的掩膜减去头骨和脑脊液部分,得到掩膜M备用,M包括灰质、白质和误分为灰、白质的头骨部分,接着用G减去G的最大连通域,再减去此部分与M共有的部分,得到误分为灰质的头骨部分G2S,同时,求得误分为白质的头骨部分W2S,再将C加上M并减去两者的最大连通域得到误分为脑脊液的头骨部分C2S,将S加上G2S、W2S和C2S三个头骨部分得到最终头骨分割结果S*,用M与背景共有部分加上L得到最终侧脑室分割结果L*。</td>   <td>G06T7/10;G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         钟娴;              林满霞;              徐旺;              刘明;              李晓菊;              匡铭;                   谢晓燕       </td>   <td>中山大学附属第一医院</td>   <td>一种肝脏二维剪切波弹性图像的影像组学分析方法和装置</td>   <td>广东省</td>   <td>CN115393301A</td>   <td>2022-11-25</td>   <td>本发明提供了一种肝脏二维剪切波弹性图像的影像组学分析方法和装置,所述方法包括：获取肝脏的二维剪切波弹性图像；将该图像从混合图像中提取出彩色弹性图像；基于色调匹配,逐像素地重建弹性值数据,获得弹性值灰度图；进行多尺度的感兴趣区域的选取,并提取影像组学特征,获得特征集合,进而构建辅助分析决策系统,获得分析结果。相比于现有技术,通过多尺度的感兴趣区域的选取,并对其进行特征提取,实现对二维剪切波弹性图像的全面分析,兼顾了图像的局部和全局的特征信息,提高了图像的利用率；基于图像的局部和全面分析,并对硬度的分析做进一步量化,提高了分析结果的准确性。</td>   <td>1.一种肝脏二维剪切波弹性图像的影像组学分析方法,其特征在于,包括：获取肝脏的二维剪切波弹性图像；从所述二维剪切波弹性图像的混合图像中提取出彩色弹性图像；基于色调匹配,针对所述彩色弹性图像,逐像素地重建弹性值数据,获得弹性值灰度图；对所述弹性值灰度图进行多尺度的感兴趣区域的选取,并对各不同尺度的感兴趣区域进行影像组学特征提取,获得特征集合；基于所述特征集合,构建辅助分析决策系统,并通过所述辅助分析决策系统获得分析结果。</td>   <td>G06T7/00;G06V10/25;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王晓鹰;              杜玉晓;              杨钦泰;              凌宇;              刘子锋;                   李向欢       </td>   <td>中山大学附属第三医院;广东工业大学</td>   <td>一种脑电信号的多元特征融合提取的信号特征提取方法</td>   <td>广东省</td>   <td>CN115374812A</td>   <td>2022-11-22</td>   <td>本发明公开了一种脑电信号的多元特征融合提取的信号特征提取方法,该方法包括：获取脑电信号数据并对脑电信号数据进行信号预处理,得到预处理后的信号；对预处理后的信号进行多维度特征提取和矩阵构建,得到原始特征矩阵；对原始特征矩阵进行融合降维处理,得到最终特征矩阵；将最终特征矩阵输入至预训练的分类模型进行分类,输出分类结果。本发明克服了传统算法中的单域特征提取算法中的脑电信号信息不全的问题,有效提升分类性能。本发明作可广泛应用于信号处理领域。</td>   <td>1.一种脑电信号的多元特征融合提取的信号特征提取方法,其特征在于,包括以下步骤：获取脑电信号数据并对脑电信号数据进行信号预处理,得到预处理后的信号；对预处理后的信号进行多维度特征提取和矩阵构建,得到原始特征矩阵；对原始特征矩阵进行融合降维处理,得到最终特征矩阵；将最终特征矩阵输入至预训练的分类模型进行分类,输出分类结果。</td>   <td>G06K9/00;G06K9/62;A61B5/372;A61B5/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         涂新军;              王天;              周宗林;              陈晓宏;              林凯荣;                   刘智勇       </td>   <td>中山大学</td>   <td>一种综合干旱评估的标准化水循环指数方法</td>   <td>广东省</td>   <td>CN115375176A</td>   <td>2022-11-22</td>   <td>本发明公开了一种综合干旱评估的标准化水循环指数方法,涉及综合干旱监控领域,计算步骤如下：S1：选择影响水循环过程的关键因子；S2：通过D-vineCopula函数构建水循环多要素的多元高维联合分布模型；S3：根据多元高维联合分布模型,通过Kendall分布函数转化降维得到标准化水循环指数SWCI；S4：通过得到的标准化水循环指数SWCI,采用百分位数P-(SWCI)进行综合干旱等级分类。本发明采用多变量联合分布统计模拟方法,构建多个水循环关键因子的联合分布模型,通过降维设计得到标准化水循环指数,既保留了各因子边缘分布特征,又描述了多个因子之间复杂的依存关系。</td>   <td>1.一种综合干旱评估的标准化水循环指数方法,其特征在于,计算步骤如下：S1：选择影响水循环过程的多个关键因子；S2：通过D-vine Copula函数构建水循环多要素的多元高维联合分布模型；S3：根据多元高维联合分布模型,通过Kendall分布函数转化降维得到标准化水循环指数SWCI；S4：通过得到的标准化水循环指数SWCI,采用百分位数P-(SWCI)进行综合干旱等级分类。</td>   <td>G06Q10/06;G06F17/15</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   苏博为       </td>   <td>中山大学</td>   <td>基于区块链的订单处理方法、装置和服务器</td>   <td>广东省</td>   <td>CN115375310A</td>   <td>2022-11-22</td>   <td>本申请提供了一种基于区块链的订单处理方法、装置和服务器,包括接收客户通过用户端发送的订单信息；根据订单信息建立一个区块链网络；区块链网络包含一个商家节点,商家节点存储智能合约和账本；接收客户通过用户端发送的区块链网络加入请求,在区块链网络中增加客户节点,客户节点存储智能合约副本和账本副本；当商家需要修改智能合约中的订单变量时,发起第一修改变量交易并广播到用户端；接收客户发送的第一修改变量交易确认指令；执行第一修改变量交易,根据第一修改变量交易生成第一智能合约和第一账本；根据第一智能合约来更新智能合约和智能合约副本,根据第一账本来更新账本和账本副本。该方能保证订单准确性和安全性。</td>   <td>1.一种基于区块链的订单处理方法,其特征在于,所述方法应用于服务器,所述方法包括：接收客户通过用户端发送的订单信息；根据所述订单信息建立一个区块链网络；所述区块链网络包含一个商家节点,其中所述商家节点存储智能合约和账本；所述智能合约是根据订单信息确定的；接收客户通过用户端发送的区块链网络加入请求,在所述区块链网络中增加客户节点；分别将根据所述智能合约形成的智能合约副本和根据所述账本形成的账本副本发送至所述客户节点,以使所述客户节点存储所述智能合约副本和所述账本副本；当商家需要修改智能合约中的订单变量时,发起第一修改变量交易；将所述第一修改变量交易广播到用户端；接收客户通过用户端发送的第一修改变量交易确认指令；执行所述第一修改变量交易,根据所述第一修改变量交易生成第一智能合约和第一账本；根据所述第一智能合约来更新所述智能合约和所述智能合约副本；并根据所述第一账本来更新所述账本和所述账本副本。</td>   <td>G06Q20/38;G06Q20/10;G06Q30/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卓业鸿;              李轶擎;              朱颖婷;              肖辉;                   罗曼       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于AS-OCTA的图像噪声去除方法及系统</td>   <td>广东省</td>   <td>CN115375628A</td>   <td>2022-11-22</td>   <td>本发明公开了一种基于AS-OCTA的图像噪声去除方法及系统,涉及医学图像处理领域,本发明的方法包括以下步骤：通过AS-OCTA模拟眼动进而获取若干带有纯噪声的第一图像数据集合和若干不带有噪声的第二图像数据集合；将第一图像数据集合的每张图片输入改进的生成对抗网络DCGAN模型,生成若干与第一图像数据集合近似的第三图像数据集合；将第二图像数据集合的每张图片与生成的第三图像数据集合的每张图片融合,并输入残差U-Net神经网络模型,以将图像数据中的血管与噪声分离,从而重构成为第四图片数据集合；将第四图片数据集合的每张图片通过大津阈值法二值化,从而获得第五图片数据集合。本发明解决了训练数据集稀少的难题,同时提高了去除噪声的效率。</td>   <td>1.一种基于AS-OCTA的图像噪声去除方法,其特征在于,包括以下步骤：通过AS-OCTA人工模拟眼动进而获取若干带有纯噪声的第一图像数据集合和若干不带有噪声的第二图像数据集合；将所述第一图像数据集合的每张图片输入改进的生成对抗网络DCGAN模型,生成若干与所述第一图像数据集合近似的第三图像数据集合；将所述第二图像数据集合的每张图片与生成的所述第三图像数据集合的每张图片融合,并输入残差U-Net神经网络模型,以将图像数据中的血管与噪声分离,从而重构成为第四图片数据集合；将所述第四图片数据集合的每张图片通过大津阈值法二值化,从而获得第五图片数据集合。</td>   <td>G06T7/00;G06T5/00;G06N3/04;G06N3/08;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              付齐双;              林昊;              尹川学;              郭海旭;                   邬稳       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>账户数据处理方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115358827A</td>   <td>2022-11-18</td>   <td>本申请涉及一种账户数据处理方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：确定目标账户和各个被动账户之间的异常账户关联度；获取目标账户和各个被动账户之间的初始主动关联置信度,确定目标账户对应的当前主动可信度；确定各个被动账户的当前被动可信度；确定目标账户和各个被动账户之间的当前主动关联置信度；基于目标账户和同一被动账户之间的初始主动关联置信度和当前主动关联置信度之间的差异,调整相应的初始主动关联置信度,直至满足收敛条件,得到各个目标主动关联置信度,从而得到目标账户的目标主动可信度。基于目标账户的目标主动可信度确定目标账户的账户状态。采用本方法能够提高账户数据处理的准确性。</td>   <td>1.一种账户数据处理方法,其特征在于,所述方法包括：获取目标账户对应的被动账户数量,获取所述目标账户的各个被动账户所对应的主动账户数量,从所述被动账户数量中确定异常被动账户数量,从所述主动账户数量中确定异常主动账户数量；基于所述被动账户数量、所述主动账户数量、所述异常被动账户数量和所述异常主动账户数量,计算所述目标账户和所述被动账户之间的异常账户关联度,得到所述目标账户分别和各个被动账户之间的异常账户关联度；获取所述目标账户和对应的被动账户之间的初始主动关联置信度,基于所述被动账户数量、各个初始主动关联置信度和各个异常账户关联度,得到所述目标账户对应的当前主动可信度；获取所述被动账户和对应的主动账户之间的初始被动关联置信度,基于同一被动账户对应的主动账户数量和各个初始被动关联置信度,得到各个被动账户分别对应的当前被动可信度；基于所述目标账户和被动账户之间的异常账户关联度、所述目标账户对应的当前主动可信度、被动账户对应的当前被动可信度,计算所述目标账户和被动账户之间的当前主动关联置信度,得到所述目标账户分别和各个被动账户之间的当前主动关联置信度；基于所述目标账户和同一被动账户之间的初始主动关联置信度和当前主动关联置信度之间的差异,调整相应的初始主动关联置信度,直至满足收敛条件,得到所述目标账户分别和各个被动账户之间的目标主动关联置信度；基于所述目标账户对应的各个目标主动关联置信度、各个异常账户关联度和所述被动账户数量,得到所述目标账户对应的目标主动可信度；基于所述目标主动可信度,确定所述目标账户对应的账户状态。</td>   <td>G06Q30/06;G06F16/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              林格;                   林谋广       </td>   <td>中山大学</td>   <td>基于多尺度冗余卷积的肺部结节假阳性鉴别方法与系统</td>   <td>广东省</td>   <td>CN115358985A</td>   <td>2022-11-18</td>   <td>本发明公开了一种基于多尺度冗余卷积的肺部结节假阳性鉴别方法与系统。首先从肺部结节CT影像数据库中得到训练集；将训练集中的数据输入多尺度冗余卷积神经网络的冗余卷积层、Maxout模块得到关键特征图；将关键特征图输入到多尺度卷积层,得到多尺度特征图；将多尺度特征图依次输入激活函数、池化层、全连接层,经过Softmax函数的处理得出样本为假阳性样本以及阳性样本的概率；概率即可判断是否为肺部结节假阳性样本。本发明可以自动对不同种类的肺部结节的输入数据筛选关键特征,从而更加有效地从混合数据集中训练出预测网络；本发明可以自适应不同实际大小肺部结节的输入数据,在提高准确率的同时,不需要按照不同的样本尺寸训练多个网络模型。</td>   <td>1.一种基于多尺度冗余卷积的肺部结节假阳性鉴别方法,其特征在于,所述方法包括：从肺部结节CT影像数据库中取得CT影像,经过肺部结节检测模型后,得出CT影像中肺部结节预选区域的坐标,然后根据坐标从CT影像中获取大小为96×96×96的预选区域样本,并进行真假阳性样本标注,同时对标注后的样本进行数据增强,从而得到训练多尺度冗余卷积神经网络使用的训练集；将所述训练集中的数据输入所述多尺度冗余卷积神经网络,首先经过冗余卷积层的处理,获得冗余特征后,再经过Maxout模块提取关键特征,得到关键特征图；将所述关键特征图输入到所述多尺度冗余卷积神经网络中的多尺度卷积层,经过多尺度卷积操作提取多粒度的特征图后,对所得的所有特征图进行拼接得到多尺度特征图；将所述多尺度特征图依次输入所述多尺度冗余卷积神经网络中的激活函数以及池化层后,对输出的数据进行拉伸,得到一个一维的列向量,将得到的列向量作为全连接层的输入,经过Softmax函数的处理得出样本为假阳性样本以及阳性样本的概率；根据所述假阳性样本以及阳性样本的概率计算交叉熵损失,并利用交叉熵损失函数训练所述多尺度冗余卷积神经网络,最终得到训练好的肺部结节假阳性样本预测模型；用户输入待鉴别的CT影像,经过肺部结节检测模型后,得出待鉴别CT影像中肺部结节预选区域的坐标,然后根据坐标从待鉴别CT影像中获取大小为96×96×96的预选区域样本,再输入到所述肺部结节假阳性样本预测模型中,根据输出的假阳性样本以及阳性样本的概率,判断输入的待鉴别CT影像是否为肺部结节假阳性样本。</td>   <td>G06T7/00;G06V10/764;G06V10/774;G06V10/42;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;              丁麒溶;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种基于数字高程模型的内陆湖泊流域提取方法及系统</td>   <td>广东省</td>   <td>CN115359221A</td>   <td>2022-11-18</td>   <td>本发明涉及地理信息分析技术领域,提出一种基于数字高程模型的内陆湖泊流域提取方法及系统,其中：输入目标地区的数字高程模型和湖泊分布数据；计算目标地区的数字高程模型中各像元的初始栅格流向,并选取无法确定流向的像元组成洼地像元集合；识别所述洼地像元组合中的陆面洼地和湖泊洼地,得到陆面洼地像元集合和湖泊洼地像元集合；对所述数字高程模型中相应的陆面洼地像元进行有选择地填充后计算栅格流向,得到栅格流向矩阵；对所述栅格流向矩阵进行解析并构建流向多叉树；对所述湖泊分布数据进行迭代遍历,提取湖泊矢量的外围边界线相应的边缘像元,然后以湖泊边缘像元为起始像元,利用所述流向多叉树进行子树层遍历,提取得到湖泊流域边界。</td>   <td>1.一种基于数字高程模型的内陆湖泊流域提取方法,其特征在于,包括以下步骤：S1、输入目标地区的数字高程模型和湖泊分布数据；S2、计算目标地区的数字高程模型中各像元的初始栅格流向,并根据所述初始栅格流向选取无法确定流向的像元组成洼地像元集合；S3、根据所述湖泊分布数据识别所述洼地像元组合中的陆面洼地和湖泊洼地,得到陆面洼地像元集合和湖泊洼地像元集合；S4、对所述数字高程模型中相应的陆面洼地像元进行有选择地填充,然后计算栅格流向,得到栅格流向矩阵；S5、对所述栅格流向矩阵进行解析并构建流向多叉树；S6、对所述湖泊分布数据进行迭代遍历,提取湖泊矢量的外围边界线相应的边缘像元,然后以湖泊边缘像元为起始像元,利用所述流向多叉树进行子树层遍历,提取得到湖泊流域边界。</td>   <td>G06T19/00;G06F16/29</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪涛;              杨逍;                   陈小莹       </td>   <td>中山大学</td>   <td>一种污染物扩散规律计算机辅助评估方法、系统及装置</td>   <td>广东省</td>   <td>CN112884310B</td>   <td>2022-11-15</td>   <td>本发明公开了一种污染物扩散规律计算机辅助评估方法、系统及装置。通过卫星提供的各个波段的污染物数据,计算出污染物位点数据并提炼整合为污染物边界,然后采集并输入污染物扩散范围边界顶点坐标按时间顺序排列的序列,再从序列中选取任意两个时刻的污染物扩散范围边界顶点集合,利用所述两个集合计算污染物的空间扩散速度集并不断优化,将所述优化后的速度集作为微分包含蔓延离散模型的参数,用于模拟污染物扩散和设置最优控制策略。本发明解决了基于微分包含式的预测技术缺少一种可以通过实时监控数据计算污染物扩建扩散速度集的方法的问题。</td>   <td>1.一种污染物扩散规律计算机辅助评估方法,其特征在于,包括以下步骤：步骤1、通过卫星提供的各个波段的污染物数据,计算出污染物位点数据并提炼整合为污染物边界；步骤2、采集并输入污染物扩散范围边界顶点坐标按时间顺序排列的序列P＝{P-1,P-2,…,P-n},所述序列至少包括两个不同时间点的污染物扩散范围边界顶点坐标,即n≥2,其P-i＝{v-1,v-2,…,v-m}表示第i个时刻污染物扩散范围的边界近似多边形的顶点v-j的集合；步骤3、从上述序列中选取任意两个时刻的污染物扩散范围边界顶点集合P-a、P-b,其中b&gt;a,所述两个集合P-a、P-b的对应时刻的间隔记为t；步骤4、利用所述两个集合P-a、P-b计算污染物的空间扩散速度集F；步骤5、将计算得到的所述速度集F代入蔓延离散模型,比较模型模拟生成的区域边界M与实际的蔓延区域边界R,通过求解模拟生成的区域边界M与实际的蔓延区域边界R误差最小的最优化问题,进一步优化速度集F；步骤6、将所述优化后的速度集F作为微分包含蔓延离散模型的参数,用于模拟污染物扩散和设置最优控制策略；所述步骤4利用所述两个集合P-a、P-b计算污染物的空间扩散速度集F,具体为：(1)将集合P-a和P-b中的顶点按照逆时针方向排序；(2)取P-a中的每一条边e-i＝v-iv-(i+1),找到P-b当中所有位于e-i所在直线右侧的顶点,并将这些顶点分别与上述v-i做向量差,将上述计算得到的向量差记为m-(ji),其中i,j分别为上述计算中P-a,P-b顶点对应的下标；具体的,e-i所在直线右侧指的是以由v-i指向v-(i+1)为正方向的直线的右侧；a、b两点的向量差表示为a-b；(3)将(2)得到的m-(ji)依次与P-a中每一个顶点v-i做向量和,若一个m-(ji)与P-a中每一个顶点v-i的向量和所有都属于以P-b为顶点的多边形,则将m-(ji)记录到速度集F中；具体的,a、b两点的向量差表示为a+b；(4)将速度集F中的每一个向量除以时间间隔t得到新的速度集F,就是所求污染物的空间扩散速度集F；所述步骤5具体为：(1)计算初始区域I与空间扩散速度集F的Minkowski和,得到模拟生成的区域边界M；其中,Minkowski和是两个欧几里得空间的点集的和,数学定义为：A+B＝{a+b|a∈A,b∈B}；(2)通过优化模拟生成的区域边界M与实际蔓延区域边界R的误差,使其尽可能小,即求解最优化问题得到优化后的空间扩散速度集F。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         庄学彬;              曾昆;              何雨昕;              曾小慧;                   谢扬帆       </td>   <td>中山大学</td>   <td>飞行轨迹分类模型训练方法、分类方法、装置及存储介质</td>   <td>广东省</td>   <td>CN115345257A</td>   <td>2022-11-15</td>   <td>本申请提供了一种飞行轨迹分类模型训练方法、分类方法、装置及存储介质。该飞行轨迹分类模型训练方法包括：获取训练数据集；训练数据集包括多个样本数据；将训练数据集输入至初始模型进行训练,得到飞行轨迹分类模型；其中,初始模型包括线性特征提取网络、非线性特征提取网络及线性分类器；线性特征提取网络用于对飞行轨迹三个维度的线性特征进行提取并拼接得到三维线性特征,非线性特征提取网络用于提取飞行轨迹的全局特征和局部特征并进行拼接得到非线性特征,线性分类器用于基于三维线性特征及非线性特征对飞行轨迹进行分类处理输出预测结果。本申请能够减少对数据先验知识的依赖,实现对飞行器类型和机动模式的准确分类识别。</td>   <td>1.一种飞行轨迹分类模型训练方法,其特征在于,所述方法包括：获取训练数据集；所述训练数据集包括多个样本数据,每个样本数据包括飞行轨迹以及对应的期望结果,所述期望结果包括所述飞行轨迹对应的飞行器的种类及其机动模式,飞行轨迹包括飞行器在多个时刻下的三维坐标；将所述训练数据集输入至初始模型进行训练,得到飞行轨迹分类模型；其中,所述初始模型包括线性特征提取网络、非线性特征提取网络及线性分类器；所述线性特征提取网络用于对飞行轨迹三个维度的线性特征进行提取并拼接得到三维线性特征,所述非线性特征提取网络用于提取飞行轨迹的全局特征和局部特征并进行拼接得到非线性特征,所述线性分类器用于基于所述三维线性特征及所述非线性特征对飞行轨迹进行分类处理输出预测结果。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;                   杨冰       </td>   <td>中山大学</td>   <td>严重旱涝事件的时空变化分析方法、装置和设备</td>   <td>广东省</td>   <td>CN114626475B</td>   <td>2022-11-11</td>   <td>本申请提供了一种严重旱涝事件的时空变化分析方法、装置、设备和可读存储介质,首先获取预先建立目标区域在预设时间段的自校正帕默尔指数scPDSI序列；然后采用旱涝事件的国际分类对scPDSI序列进行分析,找出各个严重旱涝事件；最后计算各个严重旱涝事件的特征指标,并对特征指标进行分析,得到目标区域中严重旱涝事件的时空变化情况。本申请实施例中的严重旱涝事件的分析方法,可以快速、准确地确定出目标区域中严重旱涝事件的发展变换情况。</td>   <td>1.一种严重旱涝事件的时空变化分析方法,其特征在于,所述方法包括：获取预先建立目标区域在预设时间段的自校正帕默尔指数scPDSI序列；其中,scPDSI序列是通过scPDSI数据和替代数据,采用随机森林回归方法建立的；scPDSI数据是指scPDSI数据集存储的实测气候数据,替代数据为树轮数据和/或石笋数据；采用旱涝事件的国际分类对所述scPDSI序列进行分析,找出各个严重旱涝事件；计算各个所述严重旱涝事件的特征指标,并对所述特征指标进行分析,得到目标区域中严重旱涝事件的时空变化情况；所述方法还包括：对每一个所述严重旱涝事件进行空间分量识别,识别出严重旱涝区域；所述对每一个所述严重旱涝事件进行空间分量识别,识别出严重旱涝区域,包括：采用DBSCAN算法对每一个所述严重旱涝事件进行空间聚类分析；识别出每一个所述严重旱涝事件的所有位置相邻点,记为所述严重旱涝区域。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林铎儒;              林桢哲;              于珊珊;              林浩添;              梁小玲;                   赵欣予       </td>   <td>中山大学中山眼科中心</td>   <td>一种荧光素眼底血管造影图像的分期和病变诊断系统</td>   <td>广东省</td>   <td>CN115330714A</td>   <td>2022-11-11</td>   <td>本申请属于计算机视觉技术领域,公开了一种荧光素眼底血管造影图像的分期和病变诊断系统,该系统包括：图像预处理模块,用于获取眼底照相机在患者的荧光素眼底血管造影过程中拍摄的所有眼底图像,对所有眼底图像进行预处理,得到所有待分期图像；图像分期模块,用于通过训练好的图像分期网络模型将所有待分期图像分期为非荧光素眼底血管造影图像、动脉期图像及静脉期图像；病变分类模块,用于获取静脉期图像,并通过训练好的疾病分类网络模型对静脉期图像进行识别,得到静脉期图像对应的视网膜病变类型。本申请有望减轻临床工作负担,提高诊断效率和准确性。</td>   <td>1.一种荧光素眼底血管造影图像的分期和病变诊断系统,其特征在于,所述系统包括：图像预处理模块,用于获取眼底照相机在患者的荧光素眼底血管造影过程中拍摄的所有眼底图像,对所述所有眼底图像进行预处理,得到所有待分期图像；图像分期模块,用于通过训练好的图像分期网络模型将所述所有待分期图像分期为非荧光素眼底血管造影图像、动脉期图像及静脉期图像；其中,所述训练好的图像分期网络模型是基于不同分期的眼底图像训练得到的；病变分类模块,用于获取所述静脉期图像,并通过训练好的疾病分类网络模型对所述静脉期图像进行识别,得到所述静脉期图像对应的视网膜病变类型；其中,所述训练好的疾病分类网络模型是基于多种视网膜病变类型分别对应的静脉期图像训练得到的。</td>   <td>G06T7/00;G06V10/764;G06V10/774;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              林丹;              虞蕴湄;                   郑子彬       </td>   <td>中山大学</td>   <td>智能合约风险预测方法、装置、存储介质及计算机设备</td>   <td>广东省</td>   <td>CN115330397A</td>   <td>2022-11-11</td>   <td>本申请提供的智能合约风险预测方法、装置、存储介质及计算机设备,在对智能合约进行风险预测时,可以先获取若干智能合约,其中包括恶意合约,接着再确定每一智能合约与其他智能合约之间的相似度距离,这样便可以通过相似度距离来将各个智能合约进行聚类,当得到多个簇后,可以从多个簇中筛选出包含恶意合约的簇作为目标簇,由于每一簇中各个智能合约之间的相似度较高,因此,当目标簇中包含恶意合约时,即可界定该目标簇中除恶意合约外的其他智能合约为风险合约,从而快速预测大量智能合约的风险情况,有效提高区块链的安全性与可信任度。</td>   <td>1.一种智能合约风险预测方法,其特征在于,所述方法包括：获取若干智能合约,其中,若干智能合约中包含有恶意合约；确定每一智能合约与其他智能合约之间的相似度距离,并根据所述相似度距离对各个智能合约进行聚类,得到多个簇；从多个簇中筛选出包含恶意合约的簇作为目标簇,并将所述目标簇中除所述恶意合约外的其他智能合约预测为风险合约。</td>   <td>G06Q20/40;G06Q20/38;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林满霞;              钟娴;              苏丽娅;              龙海怡;              林晋华;              匡铭;                   谢晓燕       </td>   <td>中山大学附属第一医院</td>   <td>一种肝细胞癌侵袭边缘预测方法及系统</td>   <td>广东省</td>   <td>CN115330949A</td>   <td>2022-11-11</td>   <td>本申请属于图像处理技术领域,公开了一种肝细胞癌侵袭边缘预测方法及系统。通过获取肝细胞癌患者肿瘤的二维超声图像,在二维超声图像中绘制感兴趣区域,以患者的病理标本的最大侵袭范围为预测标准,基于深度神经网络分析二维超声图像,建立平面肝细胞癌侵袭范围评估模型,预测二维超声图像的感兴趣区域的肝癌细胞的侵袭情况；获取肝细胞癌患者肿瘤的三维超声图像,利用平面肝细胞癌侵袭范围评估模型分析三维超声图像的多个正交平面的图像数据,预测多个正交平面的侵袭范围,基于该侵袭范围生成肝细胞癌侵袭范围的立体三维数据,并通过三维成像技术将侵袭范围的立体三维数据进行可视化。实现对肿瘤侵袭范围的精确评估以及立体可视化展示。</td>   <td>1.一种肝细胞癌侵袭边缘预测方法,其特征在于,所述方法包括：基于肝细胞癌患者肿瘤的不同模态的二维超声图像,在不同模态的所述二维超声图像中绘制感兴趣区域,以患者的病理标本的最大侵袭范围为预测标准,基于深度神经网络分析不同模态的所述二维超声图像,建立平面肝细胞癌侵袭范围评估模型,基于所述平面肝细胞癌侵袭范围评估模型预测所述感兴趣区域的肝癌细胞的侵袭情况；基于肝细胞癌患者肿瘤的三维超声图像,利用所述平面肝细胞癌侵袭范围评估模型分析所述三维超声图像的多个正交平面的图像数据,预测多个所述正交平面的侵袭范围,基于多个所述正交平面的侵袭范围生成肝细胞癌侵袭范围的立体三维数据,并通过三维成像技术将侵袭范围的立体三维数据进行可视化。</td>   <td>G06T17/00;G06T7/13;G06V10/25;G06V10/82;G06N3/04;G06N3/08;A61B8/00;A61B8/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李宇;              林胜义;              谭洪舟;                   农革       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于MMSE误差准则的先验信噪比估计方法</td>   <td>广东省</td>   <td>CN105280193B</td>   <td>2022-11-08</td>   <td>本发明公开了一种用于语音增强的基于MMSE误差准则的先验信噪比估计方法,属于语音信号处理技术领域。针对语音增强技术中的先验信噪比估计问题,首先基于MMSE误差准则对含噪语音的先验信噪比作初步估计,所得的先验信噪比估计值通过维纳滤波计算得到第一个系统增益因子,利用第一个系统增益因子和含噪语音幅度谱值计算得到语音功率谱估计值,再利用所得的语音功率谱估计值和噪声的功率谱估计值对先验信噪比进行再一次估计,得到最终的先验信噪比估计值。该先验信噪比估计值代入后续的语音增强步骤中处理,得到去噪的估计清音信号。基于MMSE误差准则的先验信噪比估计方法既有效地抑制了估计清音中的背景噪声成分,又避免了对清音成分的过度损伤,使得估计清音的听觉质量得以改善,语音增强算法的性能得以提高。</td>   <td>1.一种基于MMSE误差准则的先验信噪比估计方法,其特征在于,包括：1)将含噪语音信号y-t进行分帧和加窗处理,得到含噪语音帧信号y-t(n)；2)对含噪语音帧信号y-t(n)进行离散傅里叶变换,即得到含噪语音第n帧第k频率成分的离散幅度谱值y-t(n,k)；3)对含噪语音第n帧第k频率成分的离散幅度谱值y-t(n,k)进行噪声成分功率谱的估计,得到第n帧第k频率噪声功率谱估计值通过一帧延时得到前一帧第k频率的清音幅度谱估计值并用该值计算得到前一帧第k频率清音功率谱估计值4)将含噪语音第n帧第k频率成分的离散幅度谱值y-t(n,k)和第n帧第k频率噪声的功率谱估计值用于计算第n帧第k频率语音的后验信噪比将前一帧第k频率的清音功率谱估计值和第n帧第k频率噪声功率谱估计值用于计算前一帧第k频率语音的先验信噪比5)第n帧第k频率语音的后验信噪比和前一帧第k频率先验信噪比代入到MMSE先验信噪比的估计计算中,即得到第n帧第k频率成分的MMSE先验信噪比估计值6)用维纳滤波方法和步骤5)中所得第n帧第k频率成分的MMSE先验信噪比估计值计算出第一个系统增益因子G1(n,k),利用第一个增益因子G1(n,k)和含噪语音第n帧第k频率成分的离散幅度谱值y-t(n,k)估计第n帧第k频率的语音功率谱值该功率谱估计值结合第n帧第k频率噪声功率谱估计值对先验信噪比进行再一次估计,得到最终的先验信噪比估计值7)最终的先验信噪比估计值结合含噪语音第n帧第k频率成分的幅度谱值y-t(n,k)对第n帧第k频率的清音幅度谱值进行估计,得到第n帧第k频率清音幅度谱的估计值8)对第n帧第k频率清音幅度谱估计值进行离散傅里叶逆变换,得到估计清音帧信号9)估计清音帧信号进行去窗和重叠相加处理,得到估计清音信号</td>   <td>G10L21/0232</td>  </tr>        <tr>   <td>中国专利</td>   <td>         尹阁麟;              张青;              郑伟诗;                   骆伟祺       </td>   <td>中山大学</td>   <td>一种基于多尺度生成对抗网络的伪装图像生成方法</td>   <td>广东省</td>   <td>CN112288622B</td>   <td>2022-11-08</td>   <td>本发明公开了一种基于多尺度生成对抗网络的伪装图像生成方法,包括以下步骤,构建多尺度生成对抗网络,包括多个尺度,每个尺度包括生成器、风格转换网络以及判别器；传入模型初始图像,进行预处理；生成器生成虚假图像,并与缩放到同等大小的真实图像一起输入到风格转换网络和判别器,进行判别训练；将当前尺度生成图像的放大结果经图像修改后输入到上一层尺度；重复执行判别训练、生成图像输入到上一层尺度步骤的操作,直至最顶端尺度输出最终的伪装图像。本发明通过构建多尺度对抗生成网络对单张图像进行训练,引入了风格转换网络对图像的风格进行定向判别与生成,实现利用少量数据进行伪装图像的快速生成与较好的伪装效果。</td>   <td>1.一种基于多尺度生成对抗网络的伪装图像生成方法,其特征在于,包括以下步骤：构建多尺度生成对抗网络模型,并嵌入风格转换网络,所述多尺度生成对抗网络模型包括多个尺度,每个尺度包括生成器、风格转换网络以及判别器,所述生成器、风格转换网络、判别器依次连接,所述风格转换网络用于对风格特征进行定向训练,包括预训练的分类网络VGG-19、GRAM矩阵以及步长卷积；所述多个尺度由下向上层层堆叠,尺度大小及其输入图像大小由下向上逐渐增大且最小尺度的输入为随机噪声,每一层相应的操作完成后才能进行上一层尺度的操作；利用多尺度生成对抗网络模型进行训练和应用,具体为：多尺度生成对抗网络模型的训练阶段,包括下述步骤：将随机噪声图作为最小尺度生成器的输入；判别训练,生成器生成虚假图像,并与缩放到同等大小的背景图一起输入到风格转换网络和判别器,进行判别训练；将当前尺度生成器的生成图像输入到上一层尺度；重复执行判别训练、输入到上一层尺度步骤的操作,直至最顶端尺度执行完判别训练、输入到上一层尺度步骤,完成多尺度生成对抗网络模型对背景图的拟合与训练；多尺度生成对抗网络模型的应用阶段：选择除了最小尺度以外的任一尺度作为初始尺度；传入多尺度生成对抗网络模型初始图像,将粘贴了待隐藏目标的背景图放缩到初始尺度大小,并进行混合叠加的预处理,作为当前尺度输入；当前尺度图像生成,生成器的生成图像与缩放到同等大小的粘贴了待隐藏目标的背景图进行混合操作；输入到上一层尺度,将当前尺度生成器的生成图像的放大结果输入到上一层尺度；重复当前尺度图像生成、输入到上一层尺度步骤的操作,直至最顶端尺度执行完相应操作,输出最终的伪装图像。</td>   <td>G06T3/00;G06T11/00;G06V10/774;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   张泽坤       </td>   <td>中山大学</td>   <td>一种纱线级针织衣物自动建模方法及装置</td>   <td>广东省</td>   <td>CN112530018B</td>   <td>2022-11-08</td>   <td>本发明公开了一种纱线级针织衣物自动建模方法和装置,所述方法首先获取待建模衣物的三角网格模型,然后根据三角网格模型生成针织图模型；对针织图模型进行网格重建生成针脚网格模型,然后对针脚网格模型进行螺旋化操作,将针脚网格模型自动转换为螺旋式结构,最后进行网格追踪生成待建模衣物的纱线曲线,构成出纱线级针织衣物模型。通过实施本发明实施例,能够自动化生成纱线级针织衣物模型,无需用户手动进行操作设计,极大的提高了纱线级针织衣物模型的构建效率,节约了人工成本。</td>   <td>1.一种纱线级针织衣物自动建模方法,其特征在于,包括：获取待建模衣物的三角网格模型,并根据所述三角网格模型生成所述待建模衣物的针织图模型；其中,所述针织图模型包括若干针织行,所述针织行包括针织短行或针织环行；将所述针织图模型中,每一所述针织短行起始端的短行节点以及末端的短行节点与相邻的前一针织行的对应节点连接,生成基础针脚网格模型,继而从所述基础针脚网格模型中每一行网格的最左侧网格单元开始,依次对所述基础针脚网格模型中每一行的各个网格单元进行细分操作,生成所述待建模衣物的针脚网格模型；其中,所述针脚网格模型包括若干针织面片行；所述针织面片行：包括环行面片行或短行面片行；所述细分操作包括：获取一待细分网格单元,判断所述待细分网格单元是否为转向网格单元；若所述待细分网格单元为转向网格单元,则不对所述待细分网格单元进行细分；若所述待细分网格单元不为转向网格单元,则按照以下步骤将所述待细分网格单元进行细分：判断所述待细分网格单元的形状；若,所述待细分网格单元为四边形,则将所述待细分网格单元的两条纬编边的中点进行连接,将所述待细分网格单元分割为两个新的四边形网格单元；若,所述待细分网格单元为上三角形且所述待细分网格单元右侧未进行细分的网格单元数量不为2,则将所述待细分网格单元与其右侧相邻的四边形网格单元进行合并,生成一五边形网格单元,继而将所述待细分网格单元左侧入纱纬编边的中点以及所述四边形网格单元右侧出纱纬编边的中点进行连接,将所述五边形网格单元分割为一新的四边形网格单元以及一新的五边形网格单元；若,所述待细分网格单元为下三角形且所述待细分网格单元右侧未进行细分的网格单元数量不为2,则将所述待细分网格单元与其右侧相邻的四边形网格单元进行合并,生成一五边形网格单元,继而将所述待细分网格单元左侧入纱纬编边的中点、所述待细分网格单元右侧出纱纬编边的中点以及所述四边形网格单元右侧出纱纬编边的中点进行连接,生成一六边形网格单元以及一五边形网格单元；将所述六边形网格单元进行左右分割,生成两个新的四边形网格单元；若,所述待细分网格单元为上三角形、所述待细分网格单元右侧未进行细分的网格单元数量为2且位于末端的末端网格单元为下三角形,则将所述待细分网格单元、末端网格单元以及中间的网格单元进行合并,生成一六边形网格单元；将所述待细分网格单元左侧入纱纬编边的中点、所述末端网格单元右侧出纱纬编边的中点以及中点连接线段的中点进行连接,将所述六边形网格单元分割两个新的六边形网格单元,继而分别将两个新的六边形网格单元进行左右分割,生成四个新的四边形网格单元；其中,所述中点连接线段为连接所述待细分网格单元右侧出纱纬编边的中点以及所述末端网格单元左侧入纱纬编边的中点的线段；若,所述待细分网格单元为下三角形、所述待细分网格单元右侧未进行细分的网格单元数量为2,且位于末端的末端网格单元为上三角形,则将所述待细分网格单元、末端网格单元以及中间的网格单元进行合并,生成一六边形网格单元；将所述待细分网格单元左侧入纱纬编边的中点、所述末端网格单元右侧出纱纬编边的中点以及所述中点连接线段的中点进行连接,将所述六边形网格单元分割两个新的六边形网格单元,继而分别将两个新的六边形网格单元进行左右分割,生成四个新的四边形网格单元；若,所述待细分网格单元为上三角形、所述网格单元右侧未进行细分的网格单元数量为2,且位于末端的末端网格单元也为上三角形,则将所述待细分网格单元、末端网格单元以及中间的网格单元进行合并,生成一六边形网格单元；将所述待细分网格单元左侧入纱纬编边的中点与所述末端网格单元右侧出纱纬编边的中点连接,将所述六边形网格单元分割为一新的四边形网格单元以及一新的六边形网格单元；若,所述待细分网格单元为下三角形、所述网格单元右侧未进行细分的网格单元数量为2,且位于末端的末端网格单元也为下三角形,则将所述待细分网格单元、末端网格单元以及中间的网格单元进行合并,生成一六边形网格单元；将所述待细分网格单元左侧入纱纬编边的中点、将所述待细分网格单元右侧出纱纬编边的中点、所述末端网格单元左侧入纱纬编边的中点以及所述末端网格单元右侧出纱纬编边的中点连接,将所述六边形网格单元分割成一八边形网格单元以及一新的六边形网格单元；将所述八边形网格单元分割为三个新的四边形网格单元；若所述待细分网格单元为上三角形,所述待细分网格单元右侧未进行细分的网格单元数量为2,且位于末端的末端网格单元为四边形,则将所述待细分网格单元与其右侧相邻的四边形网格单元进行合并,生成一五边形网格单元,继而将所述待细分网格单元左侧入纱纬编边的中点以及与其右侧相邻的四边形网格单元右侧出纱纬编边的中点进行连接,将所述五边形网格单元分割为一新的四边形网格单元以及一新的五边形网格单元；将位于末端的末端网格单元的两条纬编边的中点进行连接,将所述末端的末端网格单元分割为两个新的四边形网格单元；若所述待细分网格单元为下三角形,所述待细分网格单元右侧未进行细分的网格单元数量为2,且位于末端的末端网格单元为四边形,则将所述待细分网格单元与其右侧相邻的四边形网格单元进行合并,生成一五边形网格单元,继而将所述待细分网格单元左侧入纱纬编边的中点、所述待细分网格单元右侧出纱纬编边的中点以及与其右侧相邻的四边形网格单元右侧出纱纬编边的中点进行连接,生成一六边形网格单元以及一五边形网格单元；将所述六边形网格单元进行左右分割,生成两个新的四边形网格单元；将位于末端的末端网格单元的两条纬编边的中点进行连接,将所述末端的末端网格单元分割为两个新的四边形网格单元；根据待建模衣物管状部件的合并位置将所述针脚网格模型划分为若干针脚网格子模型,将每一所述针脚网格子模型进行螺旋化操作,生成若干螺旋式网格子模型；其中,所述螺旋化操作具体包括：将针脚网格子模型中任意一列网格上移预设单位,生成初步螺旋化针脚网格子模型；将所述初步螺旋化针脚网格子模型中未被移位路径穿过的短行面片行,作为待处理面片行,将所述待处理面片行末端的转向网格单元或起始端的转向网格单元移动预设单位,生成所述螺旋式网格子模型；对每一所述螺旋式网格子模型进行网格追踪,生成每一所述螺旋式网格子模型的纱线曲线,根据所有纱线曲线生成所述待建模衣物的纱线级衣物模型。</td>   <td>G06T17/20;G06F30/10;G06F30/20;G06F113/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏航;              刘海亮;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院</td>   <td>基于步态的行为识别方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN114818989B</td>   <td>2022-11-08</td>   <td>本申请适用于设备管理技术领域,提供了一种基于步态的行为识别方法、装置、终端设备及存储介质,方法包括：接收待识别的目标视频数据；将所述目标视频数据导入预设的帧间动作提取网络,得到帧间动作特征数据；将所述帧间动作特征数据导入池化融合网络,输出所述目标视频数据对应的融合特征数据；将所述目标视频数据导入上下文注意力网络,确定所述目标视频数据中目标对象的步态行为数据；根据所述步态行为数据以及所述融合特征数据,得到所述目标对象的行为类别。采用上述方法能够大大降低了视频数据在进行行为识别过程中的计算成本,继而提高了运算效率。</td>   <td>1.一种基于步态的行为识别方法,其特征在于,包括：接收待识别的目标视频数据；将所述目标视频数据导入预设的帧间动作提取网络,得到帧间动作特征数据；所述帧间动作特征数据用于确定所述目标视频数据中相邻的视频图像帧之间的动作特征信息；将所述帧间动作特征数据导入池化融合网络,输出所述目标视频数据对应的融合特征数据；将所述目标视频数据导入上下文注意力网络,确定所述目标视频数据中目标对象的步态行为数据；所述上下文注意力网络用于提取所述目标视频数据中所述目标对象与环境对象之间的相互位置关系；根据所述步态行为数据以及所述融合特征数据,得到所述目标对象的行为类别；所述将所述目标视频数据导入上下文注意力网络,确定所述目标视频数据中目标对象的步态行为数据,还包括：确定所述目标视频数据的各个视频图像帧内的目标对象以及至少一个环境对象；基于所有所述视频图像帧中的所述目标对象的各个关键特征点的第一位置坐标,确定第一上下文特征；所述关键特征点是与所述目标对象的步态相关的人体关键点；基于各个所述视频帧中所述目标对象与所述环境对象之间的相对位置关系,确定第二上下文特征；将所述第一上下文特征以及所述第二上下文特征导入所述上下文注意力网络,生成所述步态行为数据。</td>   <td>G06K9/62;G06V20/40;G06V40/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐明;              黄通毅;              张睿;              谢晓华;              林满霞;              黄光亮;              张春阳;                   谢晓燕       </td>   <td>中山大学附属第一医院</td>   <td>一种超声数据和病理成分的配准方法、装置及终端设备</td>   <td>广东省</td>   <td>CN115311131A</td>   <td>2022-11-08</td>   <td>本发明公开了一种超声数据和病理成分的配准方法、装置及终端设备,通过对待测腺体的超声图像和病理图像分别构建三维第一模型和三维第二模型,并通过建立的三维模型按照预设的配准方法进行配准,获得目标映射函数,通过数据分析设备进行目标映射函数的运算,从而完成三维第一模型和三维第二模型的配准,进而实现待测腺体超声信息和病理成分的配准。本申请通过构建待测腺体不同维度的三维模型,并结合配准方法进行配准,大大提高了待测腺体超声数据和病理成分的配准精确度,有利于促进临床医学的发展。</td>   <td>1.一种超声数据和病理成分的配准方法,其特征在于,包括：获取待测腺体的超声图像,根据所述超声图像构建三维第一模型；获取所述待测腺体的病理图像,根据所述病理图像构建三维第二模型；根据所述三维第一模型和所述三维第二模型,通过预设的配准方法,获得目标映射函数；根据所述目标映射函数,通过预设的数据分析设备进行运算操作,完成所述三维第一模型和所述三维第二模型的配准。</td>   <td>G06T3/00;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              谢志;              肖鹏;              周昊;              王耿媛;              何尧;                   邓宇晴       </td>   <td>中山大学中山眼科中心</td>   <td>基于视频数据的泪膜检测系统及方法</td>   <td>广东省</td>   <td>CN115294071A</td>   <td>2022-11-04</td>   <td>本公开描述一种基于视频数据的泪膜检测系统及方法,该系统包括获取模块,其被配置为获取针对泪膜的视频数据对应的多个检测帧并作为泪膜数据队列；状态分析模块,其被配置为基于泪膜数据队列中连续的三个检测帧中角膜区域的形状大小的变化情况确定中间的检测帧的眼睛状态；检测段分析模块,其被配置为基于由状态分析模块获得的检测帧的眼睛状态获取视频数据对应的多个检测段,并基于眼睛状态为睁开状态的检测帧确定各个检测段的检测结果；以及结果分析模块,其被配置为基于多个检测段对应的多个检测结果确定目标检测结果。由此,能够使泪膜检测的分段精度较高、支持实时分析且便捷。</td>   <td>1.一种基于视频数据的泪膜检测系统,其特征在于,包括获取模块、状态分析模块、检测段分析模块和结果分析模块；所述获取模块被配置为获取针对泪膜的所述视频数据对应的随时间变化的多个检测帧并作为泪膜数据队列；所述状态分析模块被配置为接收待分析的检测帧,获取所述泪膜数据队列中的所述待分析的检测帧位于中间且连续的三个检测帧,基于所述三个检测帧中角膜区域的形状大小的变化情况确定所述待分析的检测帧的眼睛状态,其中,所述眼睛状态包括睁开状态、睁眼过程状态和闭眼过程状态,所述角膜区域的形状大小采用相对大小表示；所述检测段分析模块被配置为读取所述泪膜数据队列中的检测帧,基于由所述状态分析模块获得的检测帧的眼睛状态获取所述视频数据对应的多个检测段,并基于所述眼睛状态为睁开状态的检测帧确定各个检测段的检测结果,其中,由所述泪膜数据队列中所述眼睛状态为睁眼过程状态的检测帧和所述眼睛状态为闭眼过程状态的检测帧分别确定各个检测段的起始帧和结束帧；以及所述结果分析模块被配置为基于所述多个检测段对应的多个检测结果确定目标检测结果。</td>   <td>G06T7/00;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴万庆;              韦程琳;              蒋明哲;                   张献斌       </td>   <td>中山大学</td>   <td>一种基于紧凑型卷积神经网络的抑郁症识别方法及系统</td>   <td>广东省</td>   <td>CN113052113B</td>   <td>2022-11-04</td>   <td>本发明提供了一种基于紧凑型卷积神经网络的抑郁症识别方法及系统,所述方法包括：获取若干个受测者的脑电信号数据；其中,所述受测者包括抑郁症受测者和正常受测者；对所述脑电信号数据进行数据预处理,并按照预设的比例将预处理后的脑电信号数据划分为训练数据集和测试数据集；将所述训练数据集输入至预先构建的紧凑型卷积神经网络,以对所述紧凑型卷积神经网络进行训练,在所述紧凑型卷积神经网络达到预设的收敛状态时,生成抑郁症识别模型；将所述测试数据集输入至所述抑郁症识别模型进行识别并分别输出抑郁症识别结果以及正常识别结果。通过实施本发明能够有效降低识别模型对数据质量的依赖性,并提高识别的准确性。</td>   <td>1.一种基于紧凑型卷积神经网络的抑郁症识别方法,其特征在于,包括：从MODMA数据集中获取若干个受测者的脑电信号数据；其中,所述受测者包括抑郁症受测者和正常受测者；对所述脑电信号数据进行数据预处理,并按照预设的比例将预处理后的脑电信号数据划分为训练数据集和测试数据集；所述数据预处理为采用Z-score标准化方法,具体包括,将长度为T秒的3通道脑电信号看作C×T的矩阵,并使用大小为t的滑动窗口将脑电信号分割为m个矩阵；其中,C表示通道数；m表示总长度时间T中时间间隔为t的数目；将所述训练数据集输入至预先构建的紧凑型卷积神经网络,以对所述紧凑型卷积神经网络进行训练,在所述紧凑型卷积神经网络达到预设的收敛状态时,生成抑郁症识别模型；其中,所述紧凑型卷积神经网络依次包含常规卷积层、Depthwise卷积层、Separable卷积层和softmax层；所述常规卷积层作为时间滤波器,提取包含脑电信号不同带通频率的特征图,且卷积核大小为(1,125)；所述Depthwise卷积层作为空间滤波器,根据常规卷积层的输出提取脑电波信号数据的空间特征,且卷积核大小为(3,1)；所述常规卷积层和所述Depthwise卷积层还包含线性激活函数linear,在应用指数线性单元ELU非线性激活函数之前,沿特征映射维进行批归一化处理；所述常规卷积层和所述Depthwise卷积层还使用了丢弃法Dropout技术和大小为(1,5)的平均池化层；所述空间滤波器的权重采用最大范围约束1正则化；所述Separable卷积层,用于分别总结每个特征映射关系后,优化合并输出特征信息,显示地解耦特征映射内部和跨特征映射的关系；所述Separable卷积层包括卷积核大小为(1,16)的Depthwise卷积、卷积核大小为(1,1)的Pointwise卷积、以及大小为(1,8)的平均池化层；将所述测试数据集输入至所述抑郁症识别模型进行识别并分别输出抑郁症识别结果以及正常识别结果。</td>   <td>G06K9/00;G06N3/04;G06N3/08;G16H20/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         许嘉棽;              李丽;              陈多宏;                   蔡日东       </td>   <td>广东旭诚科技有限公司;中山大学;广东省生态环境监测中心</td>   <td>一种基于GIS-T搭建路网机动车动态排放清单的方法</td>   <td>广东省</td>   <td>CN115293585A</td>   <td>2022-11-04</td>   <td>本发明涉及智能交通监管系统及通信的技术领域,更具体地,涉及一种基于GIS-T搭建路网机动车动态排放清单的方法。通过搭建城市交通地理专题数据库,接入交通多源数据,实现不同来源形式数据之间的归类互补、检验及转化,形成一套统一完整的可供直接引用的交通态势数据。并利用GIS-T技术,基于交通语义的关系表达,信息化路网规则。首先通过将道路处理成一条按照link完整分布的路段,再建立道路之间的拓扑连接关系,从而可以构建一套包含道路长度、道路类型、交通拓扑链接结构的交通地理信息,并以能够为计算机所理解的形式计算、查阅、存储。结合路网动态排放模型,实现分钟级别的城市机动车路网动态排放清单搭建。</td>   <td>1.一种基于GIS-T搭建路网机动车动态排放清单的方法,其特征在于,包括1)从搭建城市道路路网地图数据库入手,通过路段、路段接电、有向路段、车道要素之间的对应关系,从而建立道路路网之间的关联；2)接入交通多源数据,得到关键路口过车辆的技术水平及活动水平,结合步骤1)搭建的空间路网地图,以车辆号为连接字段,进行时空关联统一,实现由关键路口个体为基准、推演转化为有向路段流量,形成统一完整的路网运行态势数据；3)基于交通语义关系表达和计算技术的支撑,利用GIS-T技术,信息化道路路网规则,以计算机所理解的形式进行计算、查阅、存储,构建一套包含道路长度、道路类型、交通拓扑链接结构的交通地理信息系统,以便满足下列道路排放精细化计算表达的需求；4)利用步骤2)处理后的交通多源数据以及步骤3)搭建的可计算路网模型,通过计算机信息技术,采用自下而上的集计方式计算各时段、各路段的排放情况；实现以分钟为时间分辨率,道路路段为单位的空间分辨率,包含各交叉口及多种道路类型的实时动态变化的路网动态排放清单。</td>   <td>G06Q10/06;G06Q50/26;G06F21/62;G06F16/29;G06F16/215</td>  </tr>        <tr>   <td>中国专利</td>   <td>         魏清阳;              孙晓明;              孙雷;              吕召彪;              邱述洪;              李永宏;              杨钦泰;                   刘子锋       </td>   <td>北京科技大学;联通(广东)产业互联网有限公司;中山大学附属第三医院</td>   <td>一种基于视频图像的脉搏波提取方法及装置</td>   <td>北京市</td>   <td>CN115294019A</td>   <td>2022-11-04</td>   <td>本发明公开了一种基于视频图像的脉搏波提取方法及装置,所述方法包括：获取待检测者的预设身体部位在静止状态下拍摄的预设时长的视频数据；对视频数据进行处理,获取视频数据中的所有帧图像,并将获取的各帧图像分别转换为灰度格式,然后对各帧图像进行分割,提取每一帧图像中的目标区域；使用灰度重心法计算出每帧图像中的目标区域的灰度重心坐标；基于每帧图像中的目标区域的灰度重心坐标,得到原始脉搏波信号；对原始脉搏波信号进行经验模态分解,得到纯净的脉搏波信号。采用本发明的技术方案,无需复杂检测装置,可较准确的提取脉搏波的重波信号分量,减小了工作量和对人体的伤害。</td>   <td>1.一种基于视频图像的脉搏波提取方法,其特征在于,包括：获取待检测者的预设身体部位在静止状态下拍摄的预设时长的视频数据；对所述视频数据进行处理,获取所述视频数据中的所有帧图像,并将获取的各帧图像分别转换为灰度格式,然后对各帧图像进行分割,提取每一帧图像中的目标区域；其中,在各帧图像中,目标区域在图像中的位置及大小均相同；使用灰度重心法计算出每帧图像中的目标区域的灰度重心坐标；基于每帧图像中的目标区域的灰度重心坐标,得到原始脉搏波信号；对所述原始脉搏波信号进行经验模态分解,得到纯净的脉搏波信号。</td>   <td>G06T7/00;G06T5/00;A61B5/00;A61B5/024</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘弘;                   张子臻       </td>   <td>中山大学</td>   <td>一种基于深度强化学习的动态路径优化问题求解方法</td>   <td>广东省</td>   <td>CN112116129B</td>   <td>2022-11-01</td>   <td>本发明公开了一种基于深度强化学习的动态路径优化问题求解方法,包括以下步骤：S1：动态路径优化问题定义；S2：构建深度强化学习框架,所述深度强化学习框架包括四个组成部分,分别为状态、智能体、动作和奖励,所述状态包括所有顾客及所有点对之间预计所需要的通行时间,所述智能体在不同状态下进行决策,得到对应的动作,所述动作为下一位访问的顾客,所述奖励为从仓库点出发,访问所有顾客后回到仓库点所需要的时间；S3：利用深度强化学习框架得出优化后的路径。本发明利用了深度强化学习算法,将动态路径优化问题的动态环境嵌入到模型中,使得模型能感知到环境的动态变化,从而使其在极短时间内得到一个较优的解。</td>   <td>1.一种基于深度强化学习的动态路径优化问题求解方法,其特征在于,包括以下步骤：S1：动态路径优化问题定义：在有向完全图G＝(V,E)上,其中V代表点集,包含了1个仓库点、c位需要服务的顾客,用集合C表示,和n-c-1个可能需要服务的顾客的地点；E代表边集,由于动态路径优化问题是一个非对称性问题,即不保证边集E中方向相反的边长度相等,求从仓库点出发,然后访问集合C中所有的顾客恰好一次,最后回到仓库点的最小时间；S2：构建深度强化学习框架,所述深度强化学习框架包括四个组成部分,分别为状态、智能体、动作和奖励,所述状态包括所有顾客及所有点对之间预计所需要的通行时间,所述智能体在不同状态下进行决策,得到对应的动作,所述动作为下一位访问的顾客,所述奖励为从仓库点出发,访问所有顾客后回到仓库点所需要的时间；S3：利用深度强化学习框架得出优化后的路径；步骤S2中所述状态包括静态部分和动态部分,其中,静态部分包括每一位顾客的编号及在各时间片上每两个点之间预计所需的通行时间,顾客的编号为每个顾客在数据集中出现次序,动态部分包括在某一特定时刻,每两个点之间预计所需通行时间,以及每个点是否被访问；在各时间片上每两个点之间预计所需的通行时间y-i通过地图API查询得到,在t时刻,每两个点之间预计所需通行时间g-(ij)(t)通过对y-i进行三次样条拟合得到；每个点的访问情况v-i(t)初始为1,若某位顾客在t时刻被访问,则对于所有 t′＞t,都有v-i(t′)＝0；所述智能体采用一个编码解码结构的注意力模型,由编码器和解码器组成,所述编码器将所述状态的静态部分编码至每个顾客的特征向量上,解码器将所述状态的动态部分编码至中间向量,再将每位顾客的特征向量及中间向量解码到每位顾客被选为下一位访问顾客的概率p-i,之后,解码器根据每位顾客的访问状况v-i(t)和概率p-i选择下一位访问的顾客j。</td>   <td>G06Q10/04;G06N20/00;G06Q10/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林桢哲;              林铎儒;              于珊珊;              林浩添;              梁小玲;                   赵欣予       </td>   <td>中山大学中山眼科中心</td>   <td>一种荧光素眼底血管造影图像的处理系统及装置</td>   <td>广东省</td>   <td>CN114782452B</td>   <td>2022-11-01</td>   <td>本申请属于计算机视觉技术领域,公开了一种荧光素眼底血管造影图像的处理系统及装置,该系统包括：图像预处理模块,用于获取待处理的荧光素眼底血管造影图像,并对荧光素眼底血管造影图像进行预处理；病变区域及病变区域内无灌注区分割模块,用于通过预先训练的语义分割模型对经过预处理的荧光素眼底血管造影图像进行处理,确定其中的病变区域和病变区域内的无灌注区；缺血指数计算模块,用于获取病变区域的面积值和无灌注区的面积值,并计算得到荧光素眼底血管造影图像对应的适用于临床的缺血指数。本申请可以达到分割荧光素眼底血管造影图像中的病变区域及病变区域中的无灌注区、实现病变量化以及适用于多种视网膜病变的效果。</td>   <td>1.一种荧光素眼底血管造影图像的处理系统,其特征在于,所述系统包括：图像预处理模块,用于获取待处理的荧光素眼底血管造影图像,并对所述荧光素眼底血管造影图像进行预处理,所述荧光素眼底血管造影图像为预设的多种视网膜病变中任一种视网膜病变的55度的荧光素眼底血管造影图像；所述预设的多种视网膜病变包括糖尿病视网膜病变、视网膜分支静脉阻塞、视网膜中央静脉阻塞以及视网膜血管炎；病变区域及病变区域内无灌注区分割模块,用于通过预先训练的语义分割模型对经过预处理的所述荧光素眼底血管造影图像进行处理,确定其中的病变区域和位于所述病变区域内的无灌注区,所述语义分割模型是基于所述多种视网膜病变分别对应的荧光素眼底血管造影图像训练而得到的；缺血指数计算模块,用于获取所述病变区域的面积值和所述无灌注区的面积值,并计算得到所述荧光素眼底血管造影图像对应的适用于临床的缺血指数；在所述荧光素眼底血管造影图像为糖尿病视网膜病变的荧光素眼底血管造影图像时,所述病变区域及病变区域内无灌注区分割模块确定的病变区域为所述荧光素眼底血管造影图像中的整个视网膜区域；在所述荧光素眼底血管造影图像为视网膜分支静脉阻塞、视网膜中央静脉阻塞或视网膜血管炎的荧光素眼底血管造影图像时,所述病变区域及病变区域内无灌注区分割模块确定的病变区域为所述荧光素眼底血管造影图像中的视网膜分支静脉阻塞、视网膜中央静脉阻塞或视网膜血管炎的病变区域。</td>   <td>G06T7/00;G06T7/62;G06V40/18;G06V10/26;G06V10/82;G06N3/04;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王伟;              施皓然;              周永坤;              饶彬;                   王涛       </td>   <td>中山大学</td>   <td>雷达辐射源个体小样本学习识别方法、系统、装置及介质</td>   <td>广东省</td>   <td>CN115270872A</td>   <td>2022-11-01</td>   <td>本发明公开了一种雷达辐射源个体小样本学习识别方法、系统、装置及介质,其中方法包括：获取待识别数据集,将待识别数据集划分为支撑集和查询集；将支撑集和查询集输入训练后的小样本学习模型中,获得支撑集样本和查询集样本的关系分数向量；根据获得的关系分数向量对待识别数据集进行数据分类；其中,所述小样本学习模型采用三元组损失关系函数进行训练。本发明采用小样本学习的方法进行辐射源信号识别,能够较好地解决原深度学习模型数据样本不足和泛化能力差的问题。另外,采用三元组损失关系函数对模型进行训练,可增强困难样本的训练,增加困难样本的识别率,提升网络的识别性能,最终提高辐射源的识别能力。本发明可广泛应用于电磁学领域。</td>   <td>1.一种雷达辐射源个体小样本学习识别方法,其特征在于,包括以下步骤：获取待识别数据集,将待识别数据集划分为支撑集和查询集；将支撑集和查询集输入训练后的小样本学习模型中,获得支撑集样本和查询集样本的关系分数向量；根据获得的关系分数向量对待识别数据集进行数据分类；其中,所述小样本学习模型采用三元组损失关系函数进行训练。</td>   <td>G06K9/00;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王瑞轩;              孙卓浩;                   张尉卓       </td>   <td>中山大学</td>   <td>基于深度学习的图像翻拍自动检测技术</td>   <td>广东省</td>   <td>CN115272223A</td>   <td>2022-11-01</td>   <td>本申请公开了一种基于深度学习的图像翻拍自动检测技术,属于图像处理技术领域。该方法包括：获取输入的第一图像,从数据库中获取第二图像,将第一图像输入至预训练的特征提取网络模型进行特征提取得到第一特征向量,将第二图像输入至特征提取网络模型进行特征提取得到多个第二特征向量,将第一特征向量与多个第二特征向量进行相似性匹配,得到相似图像,将第一图像与相似图像进行配准,得到第一差异图像,将第一差异图像输入至预训练的二分类网络模型,得到分类结果,根据分类结果得到第一图像的类型,以及与第一图像对应的相似图像。本申请能够检测出翻拍图像并识别其对应的被翻拍的原始图像。</td>   <td>1.一种基于深度学习的图像翻拍自动检测技术,其特征在于,包括：获取输入的第一图像；获取第二图像,所述第二图像保存在数据库中；将所述第一图像输入至预训练的特征提取网络模型,通过所述特征提取网络模型对所述第一图像进行特征提取得到第一特征向量；将所述第二图像输入至所述特征提取网络模型,通过所述特征提取网络模型对所述第二图像进行特征提取得到多个第二特征向量；将所述第一特征向量与所述多个第二特征向量进行相似性匹配,得到相似图像；将所述第一图像与所述相似图像进行配准,得到第一差异图像；将所述第一差异图像输入至预训练的二分类网络模型,得到分类结果；根据所述分类结果得到所述第一图像的类型,以及与所述第一图像对应的所述相似图像,所述第一图像的类型包括翻拍图像和原始图像。</td>   <td>G06T7/00;G06F16/532;G06T3/00;G06V10/40;G06V10/74;G06V10/764;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何明光;                   施丹莉       </td>   <td>中山大学中山眼科中心</td>   <td>一种利用眼底彩照自动生成荧光造影图像的方法</td>   <td>广东省</td>   <td>CN115272255A</td>   <td>2022-11-01</td>   <td>本发明公开了一种利用眼底彩照自动生成荧光造影图像的方法,涉及构建图像模型技术领域。以眼底彩色照相和相匹配的多个时间点的眼底荧光造影图像为训练数据,训练生成对抗网络,构建由眼底彩照自动产生荧光造影图像的模型；完成模型训练后,模型可以实现以眼底彩照作为输入,生成相应的早、中、晚期荧光造影图像,所生成的荧光造影图像能够清晰显示视网膜结构和各种不同病灶的荧光特征。本发明可以减少对荧光造影这种有创、具有严重副作用风险的诊断技术的依赖,提高眼病诊断的能力。</td>   <td>1.一种利用眼底彩照自动生成荧光造影图像的方法,其特征在于,包括以下步骤：S1、采集同一眼睛的眼底彩色图像和不同造影时期的眼底荧光造影图像,眼底彩色图像和荧光造影图像上的视网膜结构位置需一一对应；S2、以眼底荧光造影图像为金标准,训练条件生成对抗网络,输入眼底彩色图像,构建由眼底彩照自动产生荧光造影图像的模型。</td>   <td>G06T7/00;G06N3/04;G06N3/08;A61B3/12;A61B3/14;A61B3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈银生;              陈泓宇;                   林富华       </td>   <td>中山大学肿瘤防治中心</td>   <td>一种胶质瘤PTEN基因突变的检测方法</td>   <td>广东省</td>   <td>CN115249229A</td>   <td>2022-10-28</td>   <td>本发明公开了一种胶质瘤PTEN基因突变的检测方法,包括获取胶质瘤患者多模态磁共振图像,将获取的多模态图像标准化,将获取标准化的多模态图像训练成深度残差网络模型以提取深度学习特征并获取类激活图,将获取的类激活图使用最大类间方差法进行二值化以获得感兴趣区域,将获取感兴趣区域多模态图像提取出降维的影像组学特征,整合提取的深度学习特征及降维的影像组学特征进行训练从而整合模型。本发明通过深度学习及影像组学方法高通量提取多模态脑磁共振影像的定量特征,借助深度学习构建预测模型,可在小样本中获取具有代表性的特征,保证模型的效能,在验证数据中具有较好的诊断准确性,有望无创地为临床诊治提供指导,具有较高的卫生经济效益。</td>   <td>1.一种胶质瘤PTEN基因突变的检测方法,其特征在于,包括以下步骤：获取胶质瘤患者T1加权,造影剂强化T1加权,T2加权,液体衰减反转恢复序列多模态磁共振图像;将获取的多模态图像进行标准化；将获取标准化的多模态图像训练成深度残差网络模型以提取深度学习特征并获取类激活图；将获取的类激活图使用最大类间方差法进行二值化以获得感兴趣区域；将获取的标准化的感兴趣区域多模态图像提取出降维的影像组学特征；整合提取的深度学习特征及提取的降维的影像组学特征进行训练从而整合模型用于预测PTEN突变状态。</td>   <td>G06T7/00;G06V10/25;G06V10/774;G06V10/82;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;              资涵琪;                   刘凯       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的图像隐写方法及系统</td>   <td>广东省</td>   <td>CN108921764B</td>   <td>2022-10-25</td>   <td>本发明公开了一种基于生成对抗网络的图像隐写方法及系统,系统包括框架设计模块、网络训练模块和性能估计模块；通过设计网络框架并构造损失函数,输入原始的随机噪声,训练整个网络,使得生成的图片尽可能地拟合原始图片库的数据分布,对最终训练得到的模型性能进行检测,分析由该模型生成的图片的视觉质量以及抗隐写分析的安全性能。本发明的抗隐写分析的安全性能较其他基于生成对抗网络的方法有2～5个多百分点的提升,和原始图片库相比,生成图像视觉质量较好且更为安全。</td>   <td>1.一种基于生成对抗网络的图像隐写方法,其特征在于,包括以下步骤：S1：在待拟合的数据库中设计网络框架,其中网络框架由三个子网络构成,包括生成器G、判别器D和隐写分析器S；S2：构建各子网络的损失函数并进行优化函数,三个子网络的损失函数均基于交叉熵损失函数,其中生成器G的损失函数设计为：          其中α＝0.02,β＝1,                                    判别器D的损失函数设计为：                  隐写分析器S的损失函数设计为：                  如上公式中G(z～((i)))表示有生成器G生成的图片,D(x)表示输入x时判别器D的输出,S(x)表示输入x时隐写分析器S的输出,Stego(x)表示对x嵌入信息后得到的结果；S3：选择随机噪声作为生成器G的输入,选择需要拟合的数据作为判别器D的输入之一,对网络进行训练,得到最终的训练模型；S4：利用基于卷积神经网络的隐写分析器S对训练模型产生的图片进行性能评估；S5：将生成器G的输出结果与原始图片库以及其他生成对抗网络模型的对抗结果进行比较。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈利;              邓小武;              彭应林;              孙文钊;                   高兴旺       </td>   <td>中山大学肿瘤防治中心</td>   <td>一种基于深度学习的医学图像配准方法及终端</td>   <td>广东省</td>   <td>CN113269815B</td>   <td>2022-10-25</td>   <td>本发明公开了一种基于深度学习的医学图像配准方法及终端,对待配准移动图像和待配准固定图像进行预处理和拼接；使用U型网络在拼接图像的基础上预测得到待配准移动图像与待配准固定图像间的流场,通过得到的流场对待配准移动图像进行重采样,从而通过无监督的学习方法避免了配准过程中对大量数据标签的依赖,提高配准的计算速度；对重采样后的待配准移动图像和待配准固定图像进行配准,并使用损失函数对配准图像进行调整,能够通过损失函数衡量配准过程中预测值与样本值的距离,进一步提高配准图像的精度；因此本发明使用U型网络进行流场预测,基于流场进行图像配准,使用损失函数进行配准图像的调整,快速准确地实现医学图像的配准。</td>   <td>1.一种基于深度学习的医学图像配准方法,其特征在于,包括步骤：获取待配准移动图像和待配准固定图像,对所述待配准移动图像和待配准固定图像进行预处理；将预处理后的所述待配准移动图像和待配准固定图像进行拼接得到拼接图像；使用U型网络对所述拼接图像进行预测得到所述待配准移动图像与待配准固定图像间的流场,根据所述流场对所述待配准移动图像进行重采样；对重采样后的待配准移动图像和待配准固定图像进行配准得到配准图像,使用多个损失函数对所述配准图像进行调整并验证调整后的配准图像；所述将预处理后的所述待配准移动图像和待配准固定图像进行拼接得到拼接图像之后包括：获取用于惩罚折叠操作的损失函数loss：loss＝cc(trueY,predY)+λ||Du-(trueX→predY)||l-2+cc(trueX,predX)+λ||Du-(predY→predX)||l-2；式中,cc表示交叉相关,trueX表示实际的固定图像,trueY表示实际的移动图像,predX表示预测的固定图像,predY表示预测的移动图像,λ表示参数,Du-(trueX→predY)表示预测扭曲图像的位移场,Du-(predY→predX)表示预测扭曲图像对应的逆位移场,|| ||l-2表示范数形式；通过用于惩罚折叠操作的损失函数和矢量化损失函数对所述拼接图像进行调整。</td>   <td>G06T7/33;G06T7/38;G06T7/269;G06T7/246;G06T7/00;G06N3/08;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁媛;                   刘慧雯       </td>   <td>中山大学</td>   <td>基于消费大数据的城市相对贫困空间测度方法和系统</td>   <td>广东省</td>   <td>CN115239380A</td>   <td>2022-10-25</td>   <td>本发明涉及人工智能技术领域,公开了基于消费大数据的城市相对贫困空间测度方法和系统,包括：根据全国人口普查数据构建目标区域的综合贫困指数；采集消费类型数据,计算得到人均消费水平分布特征指标；采集POI数据,计算得到消费设施分布特征指标；将所述人均消费水平分布特征指标和所述消费设施分布特征指标作为自变量、将所述综合贫困指数作为参考变量,输入训练好的城市贫困评估模型,计算得到城市贫困分数；根据所述城市贫困分数对城市相对贫困程度进行评估,得到城市相对贫困评估结果。本发明能够有效弥补现有的测算维度的不足,实现了城市相对贫困空间的精准识别和动态监测,提高了城市相对贫困空间测度的准确性和可实施性。</td>   <td>1.一种基于消费大数据的城市相对贫困空间测度方法,其特征在于,包括：根据全国人口普查数据构建目标区域的综合贫困指数；采集所述目标区域的消费类型数据,计算得到所述目标区域的人均消费水平分布特征指标；采集所述目标区域的POI数据,计算得到所述目标区域的消费设施分布特征指标；将所述人均消费水平分布特征指标和所述消费设施分布特征指标作为自变量、将所述综合贫困指数作为参考变量,输入训练好的城市贫困评估模型,计算得到城市贫困分数,所述城市贫困评估模型为随机森林预测模型；根据所述城市贫困分数对城市相对贫困程度进行评估,得到所述目标区域的城市相对贫困评估结果。</td>   <td>G06Q30/02;G06F16/951;G06F16/9537;G06K9/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              林辉;                   钟圳伟       </td>   <td>中山大学</td>   <td>一种基于单目摄像机的光照估计方法</td>   <td>广东省</td>   <td>CN109523617B</td>   <td>2022-10-18</td>   <td>本发明涉及计算机图形学,为基于单目摄像机的光照估计方法,包括以下步骤：单目摄像机采集RGB图像,作为深度估计的输入；构建用于单目摄像机深度估计的卷积神经网络并进行训练；将RGB图像输入到训练好的卷积神经网络进行深度估计,得到深度预测值,输出深度预测图；将深度预测值进行上采样,使深度预测图的尺寸与RGB图像相匹配,将上采样后的深度预测值作为光照估计的输入；将RGB图像转换到CIELab颜色空间下,其中的亮度通道信息作为光照估计的输入；利用亮度通道信息、深度预测值进行光照估计,将得到真实场景各方向光源信息的球谐函数系数。该方法通过单目摄像机获取真实场景中各方向光源信息,有效提高AR技术中渲染虚拟物体的逼真效果。</td>   <td>1.一种基于单目摄像机的光照估计方法,其特征在于,包括以下步骤：第一步、单目摄像机采集RGB图像,作为深度估计的输入；第二步、构建用于单目摄像机深度估计的卷积神经网络,对卷积神经网络进行训练；将RGB图像输入到训练好的卷积神经网络进行深度估计,得到深度预测值,输出深度预测图；第三步、将深度预测值进行上采样,使得深度预测图的尺寸与RGB图像相匹配,将上采样后的深度预测值作为光照估计的输入；第四步、将单目摄像机采集的RGB图像转换到CIELab颜色空间下,其中的亮度通道信息作为光照估计的输入；利用CIELab颜色空间下的亮度通道信息、深度估计到的深度预测值进行光照估计,将得到真实场景各方向光源信息的球谐函数系数；第二步所述卷积神经网络包括网络前端的卷积层和全连接层,深度估计的具体步骤如下：S21、网络前端的卷积层用于提取图像中不同种类的特征信息,全连接层用于包含整张图像的视野,并输出深度预测值；S22、对于预测深度y和真实深度y*,定义尺度不变均方误差：                  其中：                  通过对比输出像素点i、j的关系来表示误差,并令d-i＝log y-i-log y～*为像素点i预测值和真实值的差别,有以下等价定义：                  损失函数：                  S24、使用随机梯度下降法调整卷积神经网络参数使得损失函数达到最优；第三步包括如下步骤：S31、沿着深度预测图的边缘产生半径为r的区域,标志区域内的像素点为不可作为深度参考的像素点,从而产生一个与深度预测图相同尺寸的模板图像M；S32、对深度预测图进行上采样使得深度预测图与原始图像的尺寸一致；S33、将深度估计处理过程中产生的及所输出的对数域的深度预测值,转换为一般数域下的深度值；第四步的光照估计,具体步骤如下：S41、将单目摄像机采集的RGB图像转换到CIELab颜色空间下,取得亮度通道信息；S42、选用带阴影的漫反射光照模型,物体上x点的渲染结果L为：                  其中,L-i(x,ω-i)为ω-i方向上的入射光,V为可见性函数,N为x点法线,V、N通过深度信息运算得出,为x点简化的BRDF系数；漫反射光照模型中的辐射传输项为：R-(DS)＝V(ω-i)max(N-x·ω-i,0)S43、把辐射传输项投影成球谐系数：                  x-j为球谐函数采样点,N为采样点数目,Y为球谐函数基底；S44、利用球谐函数的正交性,将积分形式的渲染结果L转化为其子项的球谐函数系数的点乘形式,物体上x点的光照结果如下：                  其中,c为对应的球谐函数系数,k为球谐函数所用的频带数,I不包含BRDF项,I(x)通过亮度获得,从深度信息中获得；S45、从Z个采样点中求解以下超定方程组Ay＝b,获得光源的球谐函数的系数A是Z个采样点对应的球谐系数矩阵,每个采样点都有k～2个辐射传输的球谐系数；其中,采样点亮度过低或者在模板图像M中被标记为不可做深度参考的采样点,则视为无效采样点,需要重新选择采样点,直到采样点数目达Z个。</td>   <td>G06T15/00;G06T7/593;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苗建明;              张文睿;              郑若晗;              孙兴宇;              仝懿聪;              刘文超;              王燕云;              钟良靖;              龚喜;                   利杰       </td>   <td>中山大学</td>   <td>一种水下图像拼接方法、装置、计算机设备及存储介质</td>   <td>广东省</td>   <td>CN115205118A</td>   <td>2022-10-18</td>   <td>本申请属于图像拼接技术领域,公开了水下图像拼接方法、装置、计算机设备及存储介质,该方法包括：获取包含重叠区域的两张待匹配图像；通过SIFT算法分别提取两张待匹配图像中的特征点；对两张待匹配图像中的特征点进行匹配,得到两张待匹配图像的特征点匹配对；根据特征点匹配对计算得到其对应的单应性矩阵,并根据单应性矩阵对第一训练图像进行旋转变换和校正,得到第二训练图像；将参考图像和第二训练图像作为新的两张待匹配图像；将参考图像和第二训练图像进行粘贴式拼接,得到初级拼接图像；通过渐入渐出融合算法对初级拼接图像中的图像重叠区域进行融合处理,得到最终拼接图像。本申请可以解决水下图像的拼接重影和拼接缝隙问题。</td>   <td>1.一种水下图像拼接方法,其特征在于,所述方法包括：获取包含重叠区域的两张待匹配图像,所述两张待匹配图像包括参考图像和第一训练图像；通过SIFT算法分别提取所述两张待匹配图像中的特征点；对所述两张待匹配图像中的特征点进行匹配,得到所述两张待匹配图像的特征点匹配对；根据所述特征点匹配对计算得到其对应的单应性矩阵,并根据所述单应性矩阵对所述第一训练图像进行旋转变换和校正,得到第二训练图像；将所述参考图像和所述第二训练图像作为新的两张待匹配图像,重复所述通过SIFT算法分别提取所述两张待匹配图像中的特征点至所述对所述两张待匹配图像中的特征点进行匹配,得到所述两张待匹配图像的特征点匹配对的步骤,得到所述参考图像和所述第二训练图像的特征点匹配对；基于所述参考图像和所述第二训练图像的特征点匹配对,将所述参考图像和所述第二训练图像进行粘贴式拼接,得到初级拼接图像；通过渐入渐出融合算法对所述初级拼接图像中的图像重叠区域进行融合处理,得到最终拼接图像。</td>   <td>G06T3/40;G06T5/50;G06V10/46;G06V10/74;G06V10/75;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余向阳;              韩裘辰;              郭宇晨;                   潘少伟       </td>   <td>中山大学</td>   <td>一种基于光谱成像传感器的在线数据分析方法及装置</td>   <td>广东省</td>   <td>CN115205175A</td>   <td>2022-10-18</td>   <td>本发明公开了一种基于光谱成像传感器的在线数据分析方法及装置,方法包括：通过智能光谱成像仪获取目标物体的光谱图像数据；将所述光谱图像数据进行预处理,得到目标图像数据；通过深度学习模型对所述目标图像数据进行预测处理,得到所述目标物体的分析结果；将所述分析结果输入所述深度学习模型,对所述深度学习模型进行优化更新。本发明通过智能光谱成像仪进行光谱图像数据采集,具有较高的灵活性,可广泛应用于多种应用场景,另外,本发明智能光谱成像仪集成深度学习模型,实现数据采集、数据存储以及数据分析的一站式处理流程,效率高且成本低,可广泛应用于光学数据处理技术领域。</td>   <td>1.一种基于光谱成像传感器的在线数据分析方法,其特征在于,包括：通过智能光谱成像仪获取目标物体的光谱图像数据；将所述光谱图像数据进行预处理,得到目标图像数据；通过深度学习模型对所述目标图像数据进行预测处理,得到所述目标物体的分析结果；将所述分析结果输入所述深度学习模型,对所述深度学习模型进行优化更新。</td>   <td>G06T5/50;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         毛庆国;              梁常德;              蔡铭;              尹民;              王理民;              吴斌;              何晋勇;              万伟;                   刘永红       </td>   <td>中山大学;深圳市生态环境智能管控中心;深圳市思唯环境科技有限公司;深圳深态环境科技有限公司</td>   <td>基于glTF模型和建筑物轮廓拓展的三维渲染融合方法</td>   <td>广东省</td>   <td>CN115205433A</td>   <td>2022-10-18</td>   <td>本发明公开了基于glTF模型和建筑物轮廓拓展的三维渲染融合方法,包括：获取建筑物轮廓数据,根据建筑物轮廓数据对建筑物侧面进行排列；设置拓展步长和最大拓展距离；按照排列顺序对每个建筑物侧面进行拓展,且对建筑物侧面采用相同的拓展步长逐步进行拓展；计算建筑物侧面被glTF模型的遮挡率,根据遮挡率计算损失函数；根据损失函数获取各建筑物侧面的最优拓展距离；根据最优拓展距离对建筑物进行拓展。本发明通过对建筑物侧面进行逐步拓展,并通过计算损失函数,得到每个建筑物侧面的最优拓展距离,最后依据最优拓展距离来对建筑物进行拓展,使得建筑物轮廓得到拓展,在渲染时不被glTF模型遮挡。本发明可广泛应用于三维渲染领域。</td>   <td>1.一种基于glTF模型和建筑物轮廓拓展的三维渲染融合方法,其特征在于,包括以下步骤：获取建筑物轮廓数据,根据建筑物轮廓数据对建筑物侧面进行排列；设置拓展步长和最大拓展距离；按照排列顺序对每个建筑物侧面进行拓展,且对建筑物侧面采用相同的拓展步长逐步进行拓展；计算建筑物侧面被glTF模型的遮挡率,根据遮挡率计算损失函数；根据损失函数获取各建筑物侧面的最优拓展距离；根据最优拓展距离对建筑物进行拓展；其中,glTF模型的坐标系与建筑物的坐标系为同一坐标系。</td>   <td>G06T15/00;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭裕兰;                   陈铭林       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于多球面场景表达的新视角图像生成方法、装置和设备</td>   <td>广东省</td>   <td>CN115205463A</td>   <td>2022-10-18</td>   <td>本发明公开了基于多球面场景表达的新视角图像生成方法、装置和设备,方法包括：首先采集场景图像集合；接着对所述场景图像集合中所有图像进行图像位姿估计,获取所有图像的位姿信息；然后根据所述场景图像集合中各个图像的位姿信息,建模得到多球面场景模型；最后根据所述多球面场景模型,生成任意新视角下的目标图像。本发明提高了图像生成效率和图像生成质量,可广泛应用于图像处理技术领域。</td>   <td>1.基于多球面场景表达的新视角图像生成方法,其特征在于,包括：采集场景图像集合；对所述场景图像集合中所有图像进行图像位姿估计,获取所有图像的位姿信息；根据所述场景图像集合中各个图像的位姿信息,建模得到多球面场景模型；根据所述多球面场景模型,生成任意新视角下的目标图像。</td>   <td>G06T17/00;G06T7/73;G06T7/90;G06V10/46;G06V10/75</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄晓;              林嘉良;                   保延翔       </td>   <td>中山大学</td>   <td>一种基于多加速度传感器的瑜伽动作识别方法</td>   <td>广东省</td>   <td>CN109740418B</td>   <td>2022-10-14</td>   <td>本发明公开了一种基于多加速度传感器的瑜伽动作识别方法,步骤包括：通过设置在瑜伽运动者身上的加速度计采集加速度计的X、Y、Z三个方向的加速度数据；加速度数据发送至微处理器,微处理器将加速度数据打包通过无线传输技术发送至客户端；客户端收到数据后对数据进行对齐处理,将对齐后的所有数据排成样本数据矩阵,然后对样本数据矩阵进行预处理,提取表征动作的样本特征矩阵；将输入的样本特征矩阵与存储在数据库中动作标准特征矩阵进行匹配,实现瑜伽动作的识别。本发明采集三维加速度数据,构建标准特征序列,来进行动作的识别分析,参数可靠,简单可行,计算复杂度低,对相关硬件的要求较低,实现成本低。</td>   <td>1.一种基于多加速度传感器的瑜伽动作识别方法,其特征在于,所述方法包括如下步骤：S1：首先在瑜伽运动者的双手手腕、双脚脚腕、胸前、额头佩戴内置加速度计的微型处理器的手环、脚环、胸带、头带,采集加速度计的X、Y、Z三个方向的加速度数据；S2：瑜伽运动者运动时,加速度计感知运动者的加速度变化采集加速度数据发送至微处理器,微处理器将加速度数据打包通过无线传输技术发送至客户端；S3：客户端收到来自不同的加速度计采集的数据,利用同步技术对数据进行对齐,将对齐后的所有数据排成样本数据矩阵,然后对样本数据矩阵进行预处理,提取表征动作的样本特征矩阵；S4：手机客户端后台将样本特征矩阵与存储在数据库中动作标准特征矩阵进行匹配,实现瑜伽动作的识别；所述样本数据矩阵的计算过程如下：采集m个加速度传感器的X-Y-Z三个方向的数据,把方向记为k,k∈{x,y,z},每一个传感器的数据进行时间同步后,用三个向量分别表示三个不同方向的数据,把这三个向量都统称为单向数据向量V,把第i个传感器中k方向的单向数据向量记为Vik,则矩阵Di=(Vix,Viy,Viz)(i∈ [1,m] )可以表示第i个传感器中三个方向的数据,把所有矩阵Di都统称为三向数据矩阵D, m个传感器总共形成的m个三向数据矩阵,把所有的三向数据矩阵组合起来,记为矩阵S=(D1,…,Dm),矩阵S称为样本数据矩阵,样本数据矩阵S代表了一个瑜伽者动作的所有加速度数据；所述样本特征矩阵的计算过程如下：把第i个传感器中k方向的单向数据向量Vik进行处理和特征提取后,得到的向量记为Wik,并统称为单向特征向量W；三向特征矩阵E由单向特征向量W组成,第i个传感器的三向特征矩阵Ei=(Wix,Wiy,Wiz)(i∈ [1,m]),把m个三向特征矩阵全部组合起来,形成样本特征矩阵T=(E1,…,Em),样本特征矩阵T代表了瑜伽运动者动作的所有加速度特征；所述的标准特征矩阵T*计算过程如下：(1)采集一个固定瑜伽动作s*t个样本数据矩阵S,样本数据矩阵S包含有3m个单向数据向量,对单向数据向量进行特征提取,将单向数据向量V变成单向特征向量W ,步骤如下：(1.1)进行单向数据向量V滤波去噪、数据分组、数据补零填充处理以及数据拟合处理；(1.2)获取初始单向特征向量V；(1.3)对初始单向特征向量V消冗处理,去掉冗余数据；(2).使用步骤1.1-1.3方法将样本数据矩阵S的 3m个单向数据向量化为3m个单向特征向量,3m个单向特征向量组成样本特征矩阵T,定义获取第i个传感器第k方向的标准单向特征向量Wik*,以及获取用户单向数据向量转化成单向特征向量时,使用的最佳阈值Fik*、最佳窗口长度Nik*的具体方法；具体步骤如下：(2.1)从样本数据矩阵S中取出第i个传感器中k方向的单向数据向量Vik,共取出s*t个单向数据向量,代表不同样本中同一个传感器同一个方向的单向数据矩阵；把第j个样本数据矩阵Sj中第i个传感器k方向的单向数据向量记为Vjik,则所有s*t个Vik组成的选优矩阵Uik =(V1ik,V2ik,…,V(s*t)ik)；然后将选优Uik中的Vjik向量依次代入上面对瑜伽教练的单向数据向量V提取特征的步骤,每次Vjik向量代入都使用相同的相同窗口长度N和阈值F,最终获得s*t个关于i传感器k方向的特征序列向量｛W1ik,W2ik,…,W(s*t)ik｝；(2.2)在当前的窗口长度N和阈值F下,统计上一步获得的所有特征序列向量｛W1ik,W2ik,…,W(s*t)ik｝中相同的个数,记为C；(2.3)改变窗口长度N和阈值F,重复步骤2.1)～步骤2.2),直到第n次结束；比较每一次迭代中C的大小,若第p次迭代C值最大,则将第p次的阈值F、窗口长度N和特征序列向量分别作为第i个传感器k方向的最佳阈值Fik*、最佳窗口长度Nik*及标准单向特征向量Wik*,存入数据库；(3).一个固定的瑜伽动作通过步骤2.3可以得到其第i个传感器k方向的标准单向特征向量Wik*,以及第i个传感器k方向的单向数据向量Vik要转换成单向特征向量Wik时对应的最佳阈值Fik*及最佳窗口长度Nik*的大小,标准特征矩阵T*由3m个标准单向特征向量W*组成；因此,通过重复上面的2.1-2.3三个步骤,就可以获取所有的3m个最佳阈值Fik*、最佳窗口长度Nik*及标准特征序列Wik*,将最佳阈值Fik*、最佳窗口长度Nik*及标准特征序列Wik*组合到一起,便得到最终最佳阈值向量F*、最佳窗口长度向量N*及标准特征矩阵T*。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国玉;              周永坤;              饶彬;              王伟;              王涛;              周颖;              邹小海;                   徐峰       </td>   <td>中山大学</td>   <td>多无人机协同的干扰资源优化分配方法</td>   <td>广东省</td>   <td>CN113822534B</td>   <td>2022-10-14</td>   <td>本发明公开了多无人机协同的干扰资源优化分配方法,包括：分析干扰机干扰信号与辐射源接收目标信号之间的映射关系；将系统的干信比作为指标,根据所述映射关系建立干扰机对辐射源进行干扰的目标结群模型；根据贪心算法对所述目标结群模型进行计算,确定干扰机对各辐射源的第一干扰资源分配结果。本发明能够在干扰资源有限的情况下,合理分配干扰资源,以取得对多个辐射源的最佳干扰效果,可广泛应用于数据处理技术领域。</td>   <td>1.多无人机协同的干扰资源优化分配方法,其特征在于,包括：分析干扰机干扰信号与辐射源接收目标信号之间的映射关系；将系统的干信比作为指标,根据所述映射关系建立干扰机对辐射源进行干扰的目标结群模型；根据贪心算法对所述目标结群模型进行计算,确定干扰机对各辐射源的第一干扰资源分配结果；所述将系统的干信比作为指标,根据所述映射关系建立干扰机对辐射源进行干扰的目标结群模型,包括：建立雷达方程,以确定雷达接收处接收到的回波功率；建立干扰方程,以确定干扰信号到达雷达天线时的功率；确定雷达辐射源干信比,以确定单部干扰机对雷达辐射源进行干扰的干信比以及多部干扰机对雷达辐射源进行干扰的干信比；确定通信链路干信比,以确定单部干扰机作用下的通信链路收端的干信比以及多部干扰机作用下的通信链路收端的干信比；建立目标函数；其中,所述雷达方程的表达式为：                  其中,P-t为雷达发射功率；G-t为雷达发射天线增益；G-r为雷达接收天线增益；λ为雷达工作波长；σ为目标散射截面积；R为雷达与目标之间的距离；所述干扰方程的表达式为：                  其中,P-j为干扰机发射功率；G-j为干扰机发射天线增益；G-r(θ-j)为雷达天线对着干扰机方向的增益；λ为雷达工作波长；R-j为干扰机与雷达之间的距离；L-j为干扰机损耗损失系数；B-j为干扰信号带宽；B-r为雷达接收机带宽；所述单部干扰机对雷达辐射源进行干扰的干信比的表达式为：                  所述多部干扰机对雷达辐射源进行干扰的干信比的表达式为：                  其中,P-(jk)为第k部干扰机的发射功率；G-(jk)为第k部干扰机的发射天线增益；G-(jk)(θ-(jk))为第k部干扰机与雷达连线方向的雷达天线增益；R为雷达与目标之间的距离；L-s为雷达系统损耗；B-r为雷达接收机带宽；P-t为雷达发射功率；G-t为雷达发射天线增益；R-(jk)为雷达与第k部干扰机的距离；B-j为干扰信号带宽；σ为目标散射截面积；G-r为雷达接收天线增益；L-(jk)为第k部干扰机的损耗损失系数；B-(jk)为第k部干扰机的干扰信号带宽；所述单部干扰机作用下的通信链路收端的干信比的表达式为：                  所述多部干扰机作用下的通信链路收端的干信比的表达式为：                  其中,P-(jk)为第k部干扰机的发射功率；G-(jk)为第k部干扰机的发射天线增益；r-s为通信电台收端与目标之间的距离；P-s为通信电台的发射功率；G-s为通信电台接收天线增益；r-(jk)为通信链路收端与第k部干扰机的距离；对雷达辐射源分配的干扰机数为N-i,对通信链路接收端分配的干扰机数为N-j；对于雷达辐射源的目标函数为：                  对于通信链路收端的目标函数为：                  所述根据贪心算法对所述目标结群模型进行计算,确定干扰机对各辐射源的第一干扰资源分配结果,包括以下步骤：Step1初始状态：为每个干扰机分配一个最近的干扰机；Step2计算每个辐射源的干信比JSR-i；Step3找出干信比最小的辐射源S-(selected)＝argminJSR-i；Step4找出离该辐射源最近的干扰机J-(selected)＝argmin d is tan ce(S-(selected),J)；Step5如果干扰机J-(selected)已经被分配,则寻找下一个距离稍远的干扰机；Step6重复Step1-Step5直到所有干扰机都被完全分配。</td>   <td>G06Q10/06;G06Q10/04;G06F17/15;G06F17/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              马可;                   肖鹏       </td>   <td>中山大学中山眼科中心</td>   <td>基于海洋捕食者算法的电生理信号的分类方法及分类系统</td>   <td>广东省</td>   <td>CN113887397B</td>   <td>2022-10-14</td>   <td>本公开描述了一种基于海洋捕食者算法的电生理信号的分类方法,是融合海洋捕食者算法和基于机器学习的分类模型以在特征选择的同时优化分类模型的分类方法,包括获取电生理信号；基于目标特征集提取电生理信号的目标特征数据；并且将目标特征数据输入已训练的分类模型以获取分类结果,其中,在海洋捕食者算法中,基于超参数项和训练特征项初始化猎物矩阵和精英矩阵,基于分类模型计算猎物矩阵中每一个个体的适应度,并基于适应度迭代更新猎物矩阵和精英矩阵直至满足停止迭代的条件以获得优化后的猎物矩阵和精英矩阵并同时获取已训练的分类模型,基于优化后的猎物矩阵获取最优的特征子集作为目标特征集、以及已训练的分类模型对应的超参数。</td>   <td>1.一种基于海洋捕食者算法的电生理信号的分类方法,其特征在于,是融合海洋捕食者算法和基于机器学习的分类模型以在特征选择的同时优化所述分类模型的超参数的分类方法,包括：获取电生理信号；基于包括多个特征项的目标特征集提取所述电生理信号与所述目标特征集中的特征项对应的多个特征数据作为所述电生理信号的目标特征数据；并且将所述目标特征数据输入已训练的分类模型以获取分类结果,其中,所述分类模型为基于支持向量机的支持向量机模型和基于K最近邻分类算法的K最近邻分类模型中的一种,所述目标特征集和所述已训练的分类模型通过如下训练方法获得：构建训练样本,所述训练样本的输入数据包括多个待训练信号；提取各个待训练信号与训练特征项对应的多个特征数据作为训练特征数据,所述训练特征项包括多个特征项；基于所述分类模型的超参数的超参数项、所述训练特征项和所述训练特征数据并利用海洋捕食者算法获取所述目标特征集和所述已训练的分类模型,其中,在海洋捕食者算法中,在基于所述超参数项和所述训练特征项初始化猎物矩阵和精英矩阵中,将所述超参数项和所述训练特征项与所述猎物矩阵中的列进行一一对应,采用不同的上限和下限对所述猎物矩阵中与所述超参数项对应的列和与所述训练特征项对应的列进行初始化,基于初始化后的猎物矩阵对所述精英矩阵进行初始化,并在基于所述分类模型计算所述猎物矩阵中每一个个体的适应度中,基于个体与所述超参数项对应的元素值设置所述分类模型的超参数,基于个体与所述训练特征项对应的且经由二值化处理的元素值选择特征子集,基于所述特征子集从所述训练特征数据中选择与所述特征子集对应的数据集训练所述分类模型以获取个体分类模型,进而基于所述个体分类模型获取所述个体分类模型对应的错误率,并基于所述错误率计算个体的适应度,基于所述适应度迭代更新所述猎物矩阵和所述精英矩阵直至满足停止迭代的条件以获得优化后的猎物矩阵和精英矩阵并同时获取所述已训练的分类模型,其中,在更新所述猎物矩阵过程中,利用不同的边界值分别约束所述猎物矩阵中的与所述超参数项和所述训练特征项对应的元素值,基于所述优化后的猎物矩阵获取所述目标特征集、以及所述已训练的分类模型对应的超参数。</td>   <td>G06K9/00;G06K9/62;G06N20/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王伟;              施皓然;              周永坤;              饶彬;                   王涛       </td>   <td>中山大学</td>   <td>一种基于残差-胶囊网络的混叠辐射源信号识别方法</td>   <td>广东省</td>   <td>CN115186713A</td>   <td>2022-10-14</td>   <td>本发明公开了一种基于残差-胶囊网络的混叠辐射源信号识别方法,方法包括：获取环境中多个辐射源的辐射源信号,并将所述辐射源信号转化为时频图,以进行特征提取,其中,所述辐射源信号在时域和频域上同时重叠；通过胶囊网络的卷积层对所述辐射源信号的时频图进行初步特征提取,得到初级特征图；将所述初级特征图输入到胶囊网络的胶囊层进行特征图聚类以及降维处理,将所述初级特征图划分成多个胶囊向量；根据所述胶囊向量得到数字胶囊层信息,并根据所述数字胶囊层信息确定所述辐射源信号的识别结果。本发明提高了识别准确性,可广泛应用于计算机技术领域。</td>   <td>1.一种基于残差-胶囊网络的混叠辐射源信号识别方法,其特征在于,包括：获取环境中多个辐射源的辐射源信号,并将所述辐射源信号转化为时频图,以进行特征提取,其中,所述辐射源信号在时域和频域上同时重叠；通过胶囊网络的卷积层对所述辐射源信号的时频图进行初步特征提取,得到初级特征图；将所述初级特征图输入到胶囊网络的胶囊层进行特征图聚类以及降维处理,将所述初级特征图划分成多个胶囊向量；根据所述胶囊向量得到数字胶囊层信息,并根据所述数字胶囊层信息确定所述辐射源信号的识别结果；其中,所述胶囊网络包括卷积层和胶囊层；所述胶囊层包括主胶囊层和数字胶囊层。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张洪华;              刘超;              刘少儒;              许磊波;              严庆;              朱柯;              余先焕;              唐启彬;                   石广滋       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种适用于胆管癌MRI影像的图像分析方法及装置</td>   <td>广东省</td>   <td>CN115187520A</td>   <td>2022-10-14</td>   <td>本发明提供一种适用于胆管癌MRI影像的图像分析方法及装置。该图像分析方法包括以下步骤：步骤一,从胆管癌MRI影像中获取影像组学信息参数；步骤二,将影像组学信息参数输入预先构建好的影像组学模型,得到输出结果；步骤三,根据输出结果确定所述胆管癌MRI影像对应的分析结果；其中,影像组学信息参数包括病灶基于形状的特征参数、病灶基于微波的纹理特征参数中的至少一种。该图像分析方法能够对胆管癌MRI影像的信息进行准确的读取和分析,有利于提高胆管癌MRI影像分析结果的准确性和稳定性,解决了现有技术中对胆管癌MRI影像结果分析需要高度依赖影像科医师的临床阅片经验的问题,得到的分析结果与实际结果相符合,误差小。</td>   <td>1.一种适用于胆管癌MRI影像的图像分析方法,其特征在于,包括以下步骤：步骤一,从胆管癌MRI影像中获取影像组学信息参数；步骤二,将所述影像组学信息参数输入预先构建好的影像组学模型,得到输出结果；步骤三,根据所述输出结果确定所述胆管癌MRI影像对应的分析结果；其中,所述影像组学信息参数包括病灶基于形状的特征参数、病灶基于微波的纹理特征参数中的至少一种。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢晓燕;              黄通毅;              张睿;              徐明;              谢晓华;              郑艳玲;              庄博文;                   张春阳       </td>   <td>中山大学附属第一医院</td>   <td>一种基于超声射频信号的肿瘤组织数据处理方法及装置</td>   <td>广东省</td>   <td>CN115187575A</td>   <td>2022-10-14</td>   <td>本发明提供了一种基于超声射频信号的肿瘤组织数据处理方法及装置,通过对肿瘤组织的射频信号进行剪切波变换,获得第二射频数据,并通过预设的转化方法,将第二射频数据转化为成分特征信息空间分布矩阵,从而对肿瘤组织的射频信号进行深度挖掘,有利于为深度分析肿瘤组织提供准确的数据,提高了肿瘤组织数据的获取精确度。对本发明所生成的肿瘤组织成分特征信息空间分布矩阵进行进一步的分析,有利于提高对肿瘤组织的分辨能力。</td>   <td>1.一种基于超声射频信号的肿瘤组织数据处理方法,其特征在于,包括：获取肿瘤组织的第一射频数据；根据所述第一射频数据,通过剪切波变换,获得所述肿瘤组织的第二射频数据；根据所述第二射频数据,通过预设的转化方法,获得所述肿瘤组织的成分特征信息空间分布矩阵。</td>   <td>G06T7/00;G06T7/11;G06V10/77;G06V10/82;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘镇;              曾亮;              户威;                   周翠英       </td>   <td>中山大学</td>   <td>一种轻量化的前端实时三维建模技术</td>   <td>广东省</td>   <td>CN115187722A</td>   <td>2022-10-14</td>   <td>本发明公开了一种轻量化的前端实时三维建模技术,该技术包括：前端html页面；三维建模计算、插值代码；计算系统；矩阵式模型脚本；前端建模程序；三维模型展示操作工具；实时建模系统。该方法利用Web程序进行三维建模,调用用户计算机进行三维模型数据计算,并在前端页面利用WebGL-API、three.js进行展示。适用于对建模程序要求简洁、直观并具有实时自动化建模要求的各类工程。能规避传统建模程序操作复杂,体积庞大的缺点,降低了由数据到图形间转换的难度,通过与监测端对接,用户自定义模型刷新时间步长可实现实时自动化实时建模,可应用于各类需要计算机图形辅助的工程。</td>   <td>1.一种轻量化的前端实时三维建模技术,属于计算机前端技术领域,其特征是：构建前端建模程序,利用Web应用将用户建模数据通过用户计算机处理器进行插值计算得到具有三维模型信息的脚本代码,再返回Web前端进行脚本代码解析得到三维模型,并进行渲染以提供用户操作,具有轻量化建模的特点。前端数据接口与监测端形成对接形成实时建模系统,根据用户设定更新时间间隔,即可在相应的时间内将数字信息实时转换为可视化的三维图形信息,以便于使用者对模型实时观察,实现数据实时可视化,提高模型精度的需求。</td>   <td>G06T17/00;G06F16/958</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              钟宇森;              户威;                   刘镇       </td>   <td>中山大学</td>   <td>一种三维地质建模中新旧钻孔关联的插值方法</td>   <td>广东省</td>   <td>CN115187723A</td>   <td>2022-10-14</td>   <td>本发明属于三维地质建模领域,具体涉及一种在二次钻孔情况下,基于旧钻孔数据和新钻孔数据的空间插值方法,本方法包括以下步骤：步骤1,基于旧钻孔数据确立统一地层序列；步骤2,基于旧钻孔点位置进行Delaunay三角剖分；步骤3,通过对步骤2所得的三角剖分中的三角形进行边的约束和角度的约束确定插值点,即虚拟钻孔点,并使用合适的插值方法进行插值；步骤4,在旧钻孔点已完成插值的情况下,获得了新钻孔点数据,结合新旧钻孔点数据进行局部重塑步骤3中的三角剖分后完成插值。本发明通过改善Delaunay三角剖分保留部分旧插值点,解决了因新钻孔点的出现而需要重新确定所有空间插值点的问题,从而增加了工作效率,特别是在新钻孔点相对于旧钻孔点比较少的情况下,效果显著。</td>   <td>1.一种三维地质建模中新旧钻孔关联的插值方法,其特征在于,该方法具体包括以下步骤：步骤(1)整理旧钻孔数据,依据一种重要的沉积规律提取方法——统一地层序列方法,提取出最小异常的统一地层序列。步骤(2)遍历旧钻孔数据,确定旧钻孔点位置,依据Delaunay三角剖分法进行三角剖分,Delaunay三角剖分存在两个准则特性,其中“最大化最小角特性”要求在散点集可能形成的三角剖分中,Delaunay三角剖分所形成的三角形的最小角最大。步骤(3)由于钻孔点是离散的,不均匀的,因此可能出现或大或小的三角形,因此,通过连接各较大三角形边的中点,形成多个小三角形,重复执行该过程至所有三角形达到约束的边长,形成一系列大小相对一致的三角形,以确保点的分布较为均匀。最后使用合适的插值方法进行插值。步骤(4)在完成旧钻孔点的插值计算之后,引入新钻孔点的数据,并判断新钻孔点与旧钻孔的位置关系进行局部Delaunay三角剖分的重塑,实现在保留旧插值点数据的情形下进行局部插值。</td>   <td>G06T17/00;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              肖鹏;                   段铮昱       </td>   <td>中山大学中山眼科中心</td>   <td>结膜杯状细胞成像的图像融合方法及装置</td>   <td>广东省</td>   <td>CN115170557A</td>   <td>2022-10-11</td>   <td>本公开描述一种结膜杯状细胞成像的图像融合方法及装置,该方法包括接收对应聚焦平面集的多张初始图像,基于被测者的眼结膜的深度确定目标变焦范围,控制聚焦平面移动以获得与目标变焦范围相关的聚焦平面集；对多张初始图像进行预处理以获取多张目标图像；对多张目标图像进行配准以获取多张对齐图像；基于多张对齐图像中相同坐标的像素点获得多个像素序列；基于多方向的梯度信息确定各个像素点的聚焦效果评价值；基于各个像素点的聚焦效果评价值从各个像素序列中筛选像素点作为目标像素点；并且基于多个像素序列对应的多个目标像素点获取全焦细胞图像。由此,能够对眼结膜区域中大部分区域的结膜杯状细胞进行非接触式性成像。</td>   <td>1.一种结膜杯状细胞成像的图像融合方法,其特征在于,用于对由焦距可调的成像装置获取的位于被测者的眼结膜区域的结膜杯状细胞的细胞图像进行融合,所述图像融合方法包括：接收与聚焦平面集对应的多张初始图像,其中,基于被测者的眼结膜区域的深度确定目标变焦范围,由所述成像装置控制聚焦平面移动以获得与所述目标变焦范围相关的所述聚焦平面集,所述聚焦平面集包括多个不同的聚焦平面,所述初始图像为所述细胞图像；对所述多张初始图像进行预处理以获取多张目标图像；对所述多张目标图像进行图像配准以获取多张对齐图像,所述多张对齐图像中的相同位置的像素点对应同一空间位置；基于所述多张对齐图像中相同坐标的像素点获得多个像素序列；基于多方向的梯度信息确定各个像素序列中的各个像素点的聚焦效果评价值；基于各个像素点的聚焦效果评价值从各个像素序列中筛选像素点作为各个像素序列对应的目标像素点；并且基于所述多个像素序列对应的多个所述目标像素点获取全焦细胞图像。</td>   <td>G06T7/00;G06T7/33;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭卫文;              林雨霖;              潘美霖;                   谭晓军       </td>   <td>中山大学;东莞中山大学研究院</td>   <td>一种基于迁移学习的PEMFC跨电堆故障诊断方法及系统</td>   <td>广东省</td>   <td>CN115169492A</td>   <td>2022-10-11</td>   <td>本发明公开了一种基于迁移学习的PEMFC跨电堆故障诊断方法及系统,该方法包括：获取电堆数据并对CNN模型进行训练,得到迁移学习参数与最优电堆数据；利用迁移学习参数、最优电堆数据和电堆数据对CNN模型进行训练,得到故障诊断模型；基于故障诊断模型对待测目标电堆进行故障诊断,得到故障诊断结果。该系统包括：数据获取模块、模型构建模块和故障诊断模块。通过使用本发明,能够提高故障诊断模型准确率。本发明作为一种基于迁移学习的PEMFC跨电堆故障诊断方法及系统,可广泛应用于电堆故障诊断领域。</td>   <td>1.一种基于迁移学习的PEMFC跨电堆故障诊断方法,其特征在于,包括以下步骤：获取电堆数据并对CNN模型进行训练,得到迁移学习参数与最优电堆数据；利用迁移学习参数、最优电堆数据和电堆数据对CNN模型进行训练,得到故障诊断模型；基于故障诊断模型对待测目标电堆进行故障诊断,得到故障诊断结果。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G01R31/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄家华;              温武少;                   陈强普       </td>   <td>中山大学</td>   <td>基于对比学习与持续性学习的属性级情感分析方法、系统及存储介质</td>   <td>广东省</td>   <td>CN115169449A</td>   <td>2022-10-11</td>   <td>本发明涉及情感分析领域,为基于对比学习与持续性学习的属性级情感分析方法、系统及存储介质,方法包括：获取产品点评的文本数据；对文本数据进行预处理；使用迁移学习方法训练多个BERT-adapter模型,并将训练完成的多个BERT-adapter模型组成模型集合；其中,单个BERT-adapter模型通过在BERT模型的每一个译码器层里的前向传播网络层之后增加适配层得到；将预处理后的文本数据输入模型集合中,得到多个逻辑值分类结果；根据多个逻辑值分类结果,得到文本数据的属性级情感分析结果。本申请将对比学习用于情感分析模型中,从而使得模型达到更好地分类效果。同时基于迁移学习思想构建的模型具有知识迁移的能力也能拥有知识增强的能力,可以缓解深度学习存在的灾难性遗忘问题。</td>   <td>1.一种基于对比学习与持续性学习的属性级情感分析方法,其特征在于,包括以下步骤：获取产品点评的文本数据；对文本数据进行预处理；使用迁移学习方法训练多个BERT-adapter模型,并将训练完成的多个BERT-adapter模型组成BERT-adapter模型集合；其中,单个BERT-adapter模型,是通过在BERT模型的每一个译码器层里的前向传播网络层之后增加适配层得到；将预处理后的文本数据输入BERT-adapter模型集合中,得到多个逻辑值分类结果；根据多个逻辑值分类结果,得到文本数据的属性级情感分析结果。</td>   <td>G06K9/62;G06N3/08;G06N20/00;G06F40/211</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨钦泰;              李涵生;              罗新;              邵春奎;              陈健宁;              刘子锋;              吴晓琦;              杨林;              黄雪琨;              张雅娜;              郑瑞;              吴庆武;              吴硕;              周文豪;              梁桂贤;              邱惠军;              王心悦;              林明珍;                   屠佳杰       </td>   <td>杭州迪英加科技有限公司;中山大学附属第三医院</td>   <td>染色鼻息肉病理切片质量多维评价方法、系统及介质</td>   <td>浙江省</td>   <td>CN114511559B</td>   <td>2022-10-11</td>   <td>本发明公开的一种染色鼻息肉病理切片质量多维评价方法、系统及计算机可读存储介质,方法包括：获取鼻息肉数字全场切片图像并进行像素预处理和滤波去噪；对预处理后的图像进行组织切面完整度打分；对预处理后的图像进行切片厚薄均匀程度打分；对预处理后的图像进行刀痕、裂隙打分；对预处理后的图像进行气泡打分；对预处理后的图像进行透明度打分；对预处理后的图像进行细胞核与细胞浆染色对比清晰度打分；对预处理后的图像进行污染物打分；对预处理后的图像进行皱褶、折叠评分；将得到的各项分数加权求和得到切片图像的质量总分。本发明能够更精细、更全面的量化病理切片的质量。</td>   <td>1.一种染色鼻息肉病理切片质量多维评价方法,其特征在于,包括以下步骤：获取鼻息肉数字高倍镜显微镜图片或全场切片图像并进行像素预处理和滤波去噪；对预处理后的图像进行组织切面完整度打分；对预处理后的图像进行切片厚薄均匀程度打分；对预处理后的图像进行刀痕、裂隙打分；对预处理后的图像进行气泡打分；对预处理后的图像进行透明度打分；对预处理后的图像进行细胞核与细胞浆染色对比清晰度打分；对预处理后的图像进行污染物打分；对预处理后的图像进行皱褶、折叠评分；将得到的各项分数求和得到切片图像的质量总分；所述鼻息肉数字高倍镜显微镜图片或全场切片图像并进行像素预处理和滤波去噪具体过程为：将原始的鼻息肉数字全场切片图像低倍采样得到放大倍率为1.25的高倍镜显微镜图片全场图像；将倍率放大后的高倍镜显微镜图片或全场切片图像缩放至第一像素值图像；将第一像素值图像切分为第二像素值图像并进行高斯滤波；所述对预处理后的图像进行组织切面完整度打分具体为：利用canny算子计算图像的强度梯度,确定组织切面边缘；使用非极大值抑制算法消除组织切面误检；采用双阈值方法确定组织切面边界,使用最小连通法得到组织切面的边长P和区域面积R,利用打分公式得到组织切面完整度分数S1,所述打分公式为： S1=；所述对预处理后的图像进行切片厚薄均匀程度打分、细胞核与细胞浆染色对比清晰度打分具体过程为：利用Ostu法进行细胞分割；利用开操作消除细胞分割结果毛刺；使用Freeman链码对细胞分割结果进行实例化 ；根据实例化结果计算每个细胞的边长P及区域面积R,计算每个细胞的圆度；计算所有细胞的平均圆度,乘以得分值20得到切片厚薄均匀程度、细胞核与细胞浆染色对比清晰度得分；所述对预处理后的图像进行刀痕、裂隙打分；对预处理后的图像进行皱褶、折叠打分具体步骤为：利用区域生长的种子游走算法对预处理后的图像进行生长处理；根据得到的图像形态判断生长出的图像是否为裂缝或刀痕或皱褶；统计刀痕与裂缝、皱褶数,根据刀痕、裂缝数或皱褶数在基础分上进行减分,得到刀痕、裂隙、皱褶分数。</td>   <td>G06T7/00;G06T7/13;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢泳伦;              李中华;              郭雪梅;                   王国利       </td>   <td>中山大学</td>   <td>表面缺陷识别系统、方法及其存储介质</td>   <td>广东省</td>   <td>CN115170490A</td>   <td>2022-10-11</td>   <td>本发明公开了一种表面缺陷识别系统、方法及其存储介质。本发明包括依次连接的图像特征提取模块、特征重建模块、缺陷检测定位模块；图像特征提取模块用于对采集到的产品图像进行特征提取形成多尺寸特征；特征重建模块用于对多尺寸特征进行特征重建；特征重建模块包括依次连接的编码模块、标准化流模块、解码模块；编码模块用于将多尺寸特征变换为隐变量；标准化流模块用于将隐变量映射到标准正态分布空间；解码模块用于对标准正态分布空间的隐变量进行采样后重建新的产品图像的特征；缺陷检测定位模块用于根据特征重建模块重建的产品图像的特征进行缺陷识别,并与原始的产品图像进行比对定位缺陷的位置。本发明检测准确率高、适用性广。</td>   <td>1.一种表面缺陷识别系统,其特征在于,包括依次连接的图像特征提取模块、特征重建模块、缺陷检测定位模块；所述图像特征提取模块用于对采集到的产品图像进行特征提取形成多尺寸特征图；所述特征重建模块用于对多尺寸特征进行特征重建；特征重建模块包括依次连接的编码模块、标准化流模块、解码模块；所述编码模块用于将多尺寸特征变换为隐变量；所述标准化流模块用于将隐变量映射到标准正态分布空间；标准化流模块的结构为标准化流模型；所述解码模块用于对标准正态分布空间的隐变量进行采样后重建新的产品图像的特征；所述缺陷检测定位模块用于根据特征重建模块重建的产品图像的特征进行缺陷识别,并与原始的产品图像进行比对定位缺陷的位置。</td>   <td>G06T7/00;G06T7/73;G06T3/40;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              陈景文;              刘凌波;                   李冠彬       </td>   <td>中山大学</td>   <td>基于动态卷积网络的自然场景下人脸素描生成模型及方法</td>   <td>广东省</td>   <td>CN110580726B</td>   <td>2022-10-04</td>   <td>本发明公开了一种基于动态卷积网络的自然场景下人脸素描生成模型及方法,该方法包括：步骤S1,对所有卷积网络和全连接网络参数进行初始化；步骤S2,获取人脸图像,利用全卷积神经网络提取该人脸图像的层次化特征；步骤S3,将获得的特征利用转置卷积网络进行上采样,并利用可变形卷积网络挖掘人脸潜在区域和人脸变化形式信息；步骤S4,将特征分为多尺度区域,在各区域动态计算出自适应的滤波器权重,将滤波器权重与特征进行卷积计算得到新的特征,将多个尺度下所有区域特征组合生成高质量的人脸素描；步骤S5,根据生成的人脸素描与真实人脸素描的对比更新模型参数；步骤S6,多次迭代进行步骤S2-S5训练。</td>   <td>1.一种基于动态卷积网络的自然场景下人脸素描生成模型,包括：初始化单元,用于对模型的网络参数进行初始化；编码器单元,用于获取不经过预处理的自然场景下的人脸图像,利用全卷积神经网络提取该人脸图像的层次化特征；解码器单元,利用转置卷积网络逐渐将所述编码器单元生成的层次化特征上采样,并利用可变形卷积网络挖掘人脸潜在区域和人脸变化形式信息；人脸素描生成单元,用于将所述可变形卷积网络输出的特征分为多尺度区域,在各个区域动态计算出自适应的滤波器权重,并将滤波器权重与对应区域的特征进行卷积计算得到新的特征,将多个尺度下所有区域特征组合并生成高质量的人脸素描；更新单元,用于将所述人脸素描生成单元生成的人脸素描与真实人脸素描进行比较,通过优化目标函数的策略更新模型参数；迭代训练单元,用于多次迭代式地进行所述编码器单元、解码器单元、人脸素描生成单元以及更新单元的训练过程,直到训练过程收敛后或者达到最大迭代次数后得到最终模型。</td>   <td>G06T11/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚正安;              杨岚彬;              王讳晨;                   冯怀钰       </td>   <td>中山大学</td>   <td>一种图像色彩迁移方法、系统及计算机介质</td>   <td>广东省</td>   <td>CN115147259A</td>   <td>2022-10-04</td>   <td>本发明提供一种图像色彩迁移方法、系统及计算机介质,方法利用图像的局部特征来对色彩进行迁移,该算法能够对图像中的局部颜色细节进行迁移,使图像迁移效果得到一定程度的提升.这样解决了上述算法只利用了图像中色彩的全局统计量来作为特征,而忽略了局部信息,从而导致在源图像与目标图像之间色彩基调极不相同的情况下,其迁移效果不尽人意的问题。同时,还将全局统计量特征与局部的像素特征结合起来,可以先对源图像进行基于K近邻的色彩迁移,再对得到的图像进行一次Reinhard色彩迁移操作；或者先对源图像进行Reinhard色彩迁移,再对得到的图像进行一次基于K近邻的色彩迁移操作。这样解决了相邻像素点的色彩可能存在过度不自然的现象的问题。</td>   <td>1.一种图像色彩迁移方法,其特征在于,包括以下步骤：S1：通过色彩空间的转换矩阵将源图像S和目标图像T的RGB色彩空间转换到Lab色彩空间；S2：根据转换后的源图像S和目标图像T分别进行数据集的建立；S3：建立第一KNN回归模型和第二KNN回归模型,利用所述数据集分别训练所述第一KNN回归模型和第二KNN回归模型,得到训练好的从通道L映射到通道a的第一KNN回归模型和从通道L映射到通道b的第二KNN回归模型；S4：利用训练好的第一KNN回归模型和第二KNN回归模型,分别预测源图像S中通道L映射的通道a和通道b的值,得到映射后的图像；S5：将映射后的图像转换回RGB色彩空间,得到结果图像,实现将目标图像T的色彩迁移到源图像S上。</td>   <td>G06T3/00;G06T7/90;G06V10/74;G06V10/766;G06V10/774;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              李兆文;              林淑金;                   陈小燕       </td>   <td>中山大学</td>   <td>一种无需网络训练的草图图像翻译方法与系统</td>   <td>广东省</td>   <td>CN115147513A</td>   <td>2022-10-04</td>   <td>本发明公开了一种无需网络训练的草图图像翻译方法与系统。包括：输入用户绘制的草图并将其自动归一化成标准形式的图像；利用加权评分机制,计算草图结构的损失、图像逼真损失以及总损失；进行网络样本空间的初始基向量和权重选择；根据定义的训练目标和训练策略,通过迭代隐变量得到用户满意的拟合草图的图像,并暂存最近迭代的n个图像供用户选择；最终用户选择最符合自身需求的图像进行保存。本发明可以使用现有的已训练好的GAN生成网络得到比较好的图像,从而降低对网络的训练成本并加快用户获取反馈的速度,本并通过分类器和判别器结合的多评分机制,使得生成的图像更加拟合草图,更能满足大部分人对于生成图像的认可。</td>   <td>1.一种无需网络训练的草图图像翻译方法,其特征在于,所述方法包括：输入用户绘制的草图,将所述绘制的草图和GAN生成器分别进行初始化,然后将所述草图自动归一化成标准形式的图像S；利用草图结构判别定义、图像逼真判别损失定义和加权总损失定义相结合的加权评分机制,分别计算出所述草图结构的损失L1和所述图像逼真损失L2和L3,然后再加权并加和得到总损失L；将GAN生成器样本空间初始化时随机生成的隐变量输入到预训练好的GAN生成器中,并与所述标准形式的草图图像S一同经过所述加权评分机制进行联合评分,得到m个分值最高的隐变量定义为样本空间的基向量ζ-i并确定初始化权重,完成网络样本空间的初始基向量和权重选择；定义训练目标是寻找到一组基向量ζ-i和它对应的权重ω-i(i＝1,2,...,m),使得所述总损失L最小；定义训练策略为使用Adam优化器和阶段式下降型学习率,以逐步梯度下降来寻找到所述希望寻找到的基向量ζ-i和它对应的权重ω-i(i＝1,2,...,m),然后根据所述定义的训练目标和训练策略,通过迭代隐变量z得到用户满意的拟合草图的图像,并暂存最近迭代的n个图像供用户选择；所述迭代结束后,得到最终的草图翻译结果,用户可以在经所述迭代结束后网络分数最优的图像和暂存最近迭代的n个图像当中,选择最符合自身需求的图像进行保存。</td>   <td>G06T11/20;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁媛;                   吴庆瑜       </td>   <td>中山大学</td>   <td>一种城市空间收入差异测度方法、系统、设备和存储介质</td>   <td>广东省</td>   <td>CN115146945A</td>   <td>2022-10-04</td>   <td>本发明提供了一种城市空间收入差异测度方法、系统、设备和存储介质,通过收集包括居民个体手机使用情况、经济状况和社会状况的城市居民问卷数据并进行类别划分和同向分级处理得到问卷数据指标,再根据问卷数据指标中经济状况指标构建得到的收入消费指数,与将手机使用指标按照预设规则筛选得到的经济相关手机指标建立收入差异测度回归模型后,获取经济相关手机指标对应的手机信令数据输入收入差异测度回归模型进行空间收入差异识别,得到城市收入分级结果,并依此对城市内部不同空间的收入等级进行评估,得到对应的收入差异测度结果的技术方案,有效弥补现有空间收入差异识别的缺陷,便于对城市低收入人口和空间进行精细化识别和动态监测。</td>   <td>1.一种城市空间收入差异测度方法,其特征在于,所述方法包括以下步骤：收集城市居民问卷数据；所述城市居民问卷数据包括居民个体手机使用情况、经济状况和社会状况；将所述城市居民问卷数据进行类别划分,并对同类别数据进行同向分级处理,得到问卷数据指标；所述问卷数据指标包括手机使用指标、经济状况指标和社会状况指标；根据所述经济状况指标,构建收入消费指数；将所述手机使用指标按照预设规则进行筛选,得到经济相关手机指标,并根据所述经济相关手机指标和所述收入消费指数,建立收入差异测度回归模型；获取待测度城市区域内与所述经济相关手机指标对应的手机信令数据,并根据所述手机信令数据和所述收入差异测度回归模型进行空间收入差异识别,得到城市收入分级结果；所述手机信令数据为以空间网格单元形式导出的信令数据；所述待测度城市区域包括多个待评估尺度单元；根据所述城市收入分级结果,对城市内部不同空间的收入等级进行评估,得到对应的收入差异测度结果；所述收入差异测度结果包括多个待评估尺度单元的收入等级。</td>   <td>G06Q10/06;G06Q30/02;G06F17/18;H04W4/20;H04W4/24;H04W8/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         覃晓逸;              张东;                   李明       </td>   <td>中山大学</td>   <td>一种基于LSTM的独立说话人语音发音逆求解的方法</td>   <td>广东省</td>   <td>CN109346107B</td>   <td>2022-09-30</td>   <td>本发明涉及试验系统及其方法,更具体地涉及一种基于LSTM的独立说话人语音发音逆求解的方法,具体步骤如下：(1)首先对指定4个人音频信号以及同步的轨迹信号进行采集,通过安放传感器对上唇(Upper lip,UL)、下唇(Lower lip,LL)、下齿龈(Lower incisor,LI)、舌尖(Tongue tip,TP)、舌中(Tongue body,TB),舌根(Tongue dorsum,TD)六个点的数据进行采集；(2)在步骤(1)之后,选定鼻梁(RF)为参考点,在参考点处也放置传感器进行数据的采集。本发明第一：预测了未在训练集中出现说话人的语音发音轨迹；第二：改变输入特征,选取了效果更好、更合适的的声学特征作为网络输入,提升了RMSE和相关系数；第三：克服了轨迹采集时不连续、不平滑的特性。</td>   <td>1.一种基于LSTM的独立说话人语音发音逆求解的方法,其特征在于,具体步骤如下：(1)首先对指定4个人音频信号以及同步的轨迹信号进行采集,通过安放传感器对上唇(Upper lip,UL)、下唇(Lower lip,LL)、下齿龈(Lower incisor,LI)、舌尖(Tongue tip,TP)、舌中(Tongue body,TB),舌根(Tongue dorsum,TD)六个点的数据进行采集；(2)在步骤(1)之后,选定鼻梁(RF)为参考点,在参考点处也放置传感器进行数据的采集；(3)在步骤(2)之后,选定其中三个记为A、B、C作为训练人,D作为测试人；(4)将训练人的语音信号进行特征提取,提取梅尔频率倒谱系数(Mel FrequencyCepstrum Coefficient,MFCC)以及音素后验概率(phoneme posterior probabilities,PPP)；并且将梅尔频率倒谱系数(Mel Frequency Cepstrum Coefficient,MFCC)以及音素后验概率(phoneme posteriorprobabilities,PPP)作为联合输入特征(tandem),输入到长短期记忆网络(Long Short-Term Memory,LSTM)网络中；获取MFCC步骤中Mel滤波的公式为,                  其中,Mel(f)是把线性频率转成Mel频率的函数,f为线性频率；(5)选定训练好的模型,将D的联合输入特征(tandem)作为输入,发音轨迹作为输出；对轨迹与采集到的轨迹计算RMSE和相关系数r进行数据推测,并与参考数据对比；RMSE和相关系数r是衡量系统的两个指标；RMSE越小,误差越小,r越大,预测的轨迹与真实值的轨迹趋势越接近；公式如下：                  其中e-i是网络预测的输出,t-i是在i时间的真实值；                  其中e’是预测值的均值,t’是实际值的均值；语音音频和语音轨迹同步数据是利用NDI公司的WAVE系统采集。</td>   <td>G10L25/24;G10L15/06;G10L25/30;G10L17/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄义成;                   倪江群       </td>   <td>中山大学</td>   <td>一种在特征区域嵌入周期图的抗旋转水印方法</td>   <td>广东省</td>   <td>CN109685711B</td>   <td>2022-09-30</td>   <td>本发明提供一种在特征区域嵌入周期图的抗旋转水印方法,包括水印嵌入方法和水印提取方法,水印嵌入方法通过提取出图像的红色通道分量和蓝色通道分量,对红色通道分量做特征点检测,确定水印待嵌入区域,选择蓝色通道分量进行预处理计算图像嵌入系数JND,生成处理后的蓝色通道分量AII,进而得到彩色水印图像；同理,通过水印提取方法可提取出水印。本发明提供的一种特征区域嵌入周期图的抗旋转水印方法,有效结合了特征点定位的周期图水印算法,更好地抵抗旋转攻击,在旋转角较大时,仍然能够准确定位到嵌有水印的图像区域,从而检测出水印信息,提高水印算法的鲁棒性。</td>   <td>1.一种在特征区域嵌入周期图的抗旋转水印方法,其特征在于：包括水印嵌入方法A和水印提取方法B；其中,所述水印嵌入方法A包括以下步骤：AS1：提取RGB图像的红色通道分量A和蓝色通道分量A；AS2：对红色通道分量A进行Harris特征点检测,计算,确定水印待嵌入区域；AS3：选择蓝色通道分量A作为嵌入水印的宿主图像,对其进行预处理以减少图像自带的随机周期性并计算图像的最小可视差,得到嵌入系数JND；AS4：生成周期模板图,根据确定的待嵌入区域和嵌入系数JND,将旋转后的周期模板图分别嵌入到宿主图像中,生成处理后的蓝色通道分量AII；AS5：将嵌入水印后的蓝色通道分量AII替换原先的蓝色通道分量,即可得到最终的彩色水印图像；所述水印提取方法B包括以下步骤：BS1：提取待测图像的红色通道分量B和蓝色通道分量B；BS2：将红色通道分量B进行Harris特征点检测,确定待检测水印区域；BS3：在蓝色通道分量B对应的n个待测水印区域上,分别进行滤波预处理,提取周期图信号Ipre；BS4：对周期图信号Ipre进行自相关操作,得到图像R-(Ipre),并利用高斯滤波器对自相关矩阵图像进行二值化；BS5：利用hough直线检测,将二值化后的每一块待测区域的点连接成线,确定每一块待测区域检测出的直线角度；BS6：将得到的直线角度信息转化为比特位信息,最终通过Hamming解码为水印信息。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              赖戎;              郑子彬;                   张桔       </td>   <td>中山大学</td>   <td>基于电力系统节点重要性的耦合方法及装置</td>   <td>广东省</td>   <td>CN109919801B</td>   <td>2022-09-30</td>   <td>本发明公开一种基于电力系统节点重要性的耦合方法及装置,该装置用于实现该方法,本方法包括基于电力系统模型创建级联失效模型；对模型中的电力网络实施级联失效攻击,在保证用电节点获取常规输入功率下,动态调节每个供电节点的实际输出功率,在动态调节中获取每个供电节点在每个稳态下的输出功率,分别计算出节点影响力和节点脆弱性,两者加权求和获得节点d-0的重要性,基于节点的重要性从小到小排序生成新的电力网络,将新的电力网络与通信网络进行异配耦合,生成新的电力系统模型。本发明通过直流潮流模型计算得到节点重要性得到更准确的仿真结果,再将新的电力网络与通信网络进行异配耦合,提高电力系统网络在攻击下的鲁棒性。</td>   <td>1.一种基于电力系统节点重要性的耦合方法,其特征在于,包括如下步骤：S10将电力系统模型中的发电机节点视为供电节点,将消费节点视为用电节点,节点间电传输线路视为节点间的连线,由此抽象成电力网络；将电力系统通信网络中的通信节点按邻居节点数从小到大排序生成通信网络,由电力网络、通信网络和节点的供电或用电属性创建级联失效模型；S20初始化级联失效模型中所有节点的物理信息,对电力网络进行级联失效攻击,在保证用电节点获取常规输入功率下,动态调节每个供电节点的实际输出功率,在动态调节中获取每个供电节点在每个稳态下的输出功率；S30根据每个供电节点在每个稳态下的输出功率,使用直流潮流模型计算电力网络每条线路对应的功率值,获取电力网络在每个稳态下的网络负载和；假设电力网络中共有节点数为n,选取任一节点d-0,若节点d-0为被攻击节点,计算任一线路均不存在负荷超载时的网络负载失效比例ΔP(d-0),视ΔP(d-0)为节点d-0的影响力NI(d-0)；若节点d-0为非攻击节点,则根据其他节点d被攻击时,节点d-0状态情况计算节点d-0的存活比例,其视为节点d-0的脆弱性；对节点d-0的影响力NI(d-0)和节点d-0的脆弱性NV(d-0)加权求和获得节点d-0的重要性,将n个节点d-0按其重要性从小到大排序生成新的电力网络；S40将新的电力网络与通信网络进行异配耦合DIS,生成新的电力信息物理融合系统；所述S30中使用直流潮流模型计算方法具体为：S301结合电力网络结构和节点属性,使用直流潮流模型计算每条线路的负载情况,采用如下公式：P-(in)＝T-gP-G-T-dP-D                        (1)Θ＝BP-(in)                              (2)f-(ij)＝b-(ij)(θ-i-θ-j)                        (3)公式(1)中,假设网络中节点数为n,供电节点数为n-g,用电节点数为n-d,T-g和T-d分别是n*n-g和n*n-d的关联矩阵,其中T-g(i,j)＝1时表示供电节点j对应的是网络节点编号i；和分别表示供电节点的当前输出功率以及用电节点当前的输入功率,而计算结果P-(in)是一个n维向量,表示每个节点的功率注入情况,也就是电力来源；公式(2)中,B矩阵反映的是节点之间的电力传输能力,也就是线路的导纳,其计算结果必须满足基尔霍夫定律,即电路中任一个节点上,在任一时刻,流入节点的电流之和等于流出节点的电流之和,计算结果Θ＝[θ-1,θ-2,…,θ-n]向量表示每个节点的当前电压相位角；公式(3)中,b-(ij)是B矩阵内的元素,表示节点i和节点j之间的导纳,(θ-i-θ-j)为i和j节点之间的电压相位角的差值,计算结果f-(ij)就是节点i和j之间的线路负载,若f-(ij)超过额定功率,线路因继电保护而跳闸,导致新的线路负载的产生,从而会引发更深层次的级联失效；S302定义节点的影响力表示为攻击某个节点后对整个网络的影响,视任一线路的f-(ij)均不存在负荷超载时的网络负载失效比例ΔP(d-0)为节点的影响力NI(d-0),采用如下公式：                  其中D-0代表初始的电力网络节点集合,D-0-d-0代表攻击后级联失效的电力网络节点集合,表示网络中初始负载之和,P'-D表示当前状态下网络负载之和,而结果ΔP(d-0)表示网络中的负载损失比例；S303定义节点的脆弱性表示为在其他节点遭受攻击时,某个节点可以存活下来的比例,公式如下：                  其中suv(d-0,d)表示在其他节点d受到攻击时发生级联失效后,d-0的状态：存活为1；否则为0,|D-0|表示网络中的节点数目；S304对节点d-0的影响力NI(d-0)和节点d-0的脆弱性加权求和获得节点d-0的重要性,公式如下：IP(d-0)＝w·NI(d-0)+(1-w)·NV(d-0)                  (6)其中w为权重系数,根据经验值取值。</td>   <td>G06Q50/06;H04L41/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;              周凡;                   林谋广       </td>   <td>中山大学</td>   <td>胸腔病灶影像的轮廓提取及检测方法与系统</td>   <td>广东省</td>   <td>CN115131386A</td>   <td>2022-09-30</td>   <td>本发明公开了一种胸腔病灶影像的轮廓提取及检测的方法。包括：将输入的胸腔病灶图片进行分块,将块展平为一维向量并加入位置编码得到块嵌入,将块嵌入输入Transformer编码器提取图像特征,获得块特征编码,分别使用线性解码器和Transformer解码器将块特征编码序列解码为胸腔病灶轮廓特征图,通过连接的方式将线性解码器和Transformer解码器所得到的两种胸腔病灶轮廓特征图进行融合,并进行插值上采样得到胸腔病灶轮廓图。本发明还公开了胸腔病灶影像的轮廓提取及检测系统。本发明采用基于Transformer的方式,Transformer的注意力机制能够对长期依赖进行建模,有效地捕获全局特征,从而提高的准确率,且本发明没有借助额外的输入数据,计算速度快、模型复杂度较低。</td>   <td>1.一种胸腔病灶影像的轮廓提取及检测方法,其特征在于,所述方法包括：输入胸腔病灶图片和轮廓图片,对所输入的图片进行数据增强,并将其处理成统一的尺寸；将所述输入的胸腔病灶图片进行分块,将每个块展平为一维向量,为一维向量加入位置编码得到块嵌入；将所述块嵌入输入到Transformer编码器中提取图像特征,获得块特征编码,Transformer编码器包含L层,记输入序列为z-0,输出为包含丰富上下文语义信息的块特征编码序列z-L；分别使用线性解码器和Transformer解码器将所述块特征编码序列z-L解码为胸腔病灶轮廓特征图；采用连接的方式将所述通过线性解码器所得的胸腔病灶轮廓特征图和所述通过Transformer编码器获得的胸腔病灶轮廓特征图进行融合,并使用插值上采样获得胸腔病灶轮廓图,胸腔病灶轮廓图与原来输入的胸腔病灶图像大小相同；使用所述胸腔病灶轮廓图与输入的轮廓图计算损失函数,并利用梯度下降法重复训练所述Transformer神经网络至损失函数收敛。</td>   <td>G06T7/13;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         文永明;              黄绮恒;                   成慧       </td>   <td>中山大学</td>   <td>基于注意力机制网络的人脸生成方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113096206B</td>   <td>2022-09-23</td>   <td>本发明公开了一种基于注意力机制网络的人脸生成方法、装置、设备及介质,方法包括：获取训练图像以及训练表情目标域；根据表情基本类别与激活向量的关系,确定映射关系表；根据所述映射关系表,确定所述表情基本类别的概率向量到所述激活向量的映射规则；将所述训练图像以及所述训练表情目标域输入双向对抗性网络训练得到双向对抗性模型；根据所述映射规则,将待生成的初始人脸表情图像以及待生成的表情基本类别概率向量输入所述双向对抗性模型,确定连续的目标人脸表情图像。本发明能够处理连续的表情分布,生成连续的人脸表情图像,还能够提高模型对背景和光照条件变化的鲁棒性。</td>   <td>1.一种基于注意力机制网络的人脸生成方法,其特征在于,包括：获取训练图像以及训练表情目标域；根据表情基本类别与激活向量的关系,确定映射关系表；根据所述映射关系表,确定所述表情基本类别的概率向量到所述激活向量的映射规则；将所述训练图像以及所述训练表情目标域输入双向对抗性网络训练得到双向对抗性模型,其中,所述双向对抗性模型,用于消除注意力和颜色遮罩,以及用于评估生成图像；根据所述映射规则,将待生成的初始人脸表情图像以及待生成的表情基本类别概率向量输入所述双向对抗性模型,确定连续的目标人脸表情图像；所述根据所述映射规则,将待生成的初始人脸表情图像以及待生成的表情基本类别概率向量输入所述双向对抗性模型,确定连续的目标人脸表情图像,包括：输入所述表情基本类别的概率向量,根据所述映射规则,确定待生成的表情目标域；将所述待生成的表情目标域输入所述双向对抗性模型,输出所述连续的目标人脸表情图像；所述输入所述表情基本类别的概率向量,根据所述映射规则,确定待生成的表情目标域,包括：根据所述映射规则,确定一组超参数；根据表情目标域生成公式,结合所述超参数以及所述表情基本类别的概率向量,确定所述待生成的表情目标域；所述表情目标域生成公式为：y-g＝F(v)＝∑-iα-iT(v)；其中,y-g为所述待生成的表情目标域,F为映射函数,α-i为一组超参数中的第i个参数,T(v)为所述表情基本类别的概率向量v根据映射关系表T得到的对应的所述激活向量。</td>   <td>G06T11/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              夏文君;              郑炎辉;              宋超;                   金浩宇       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种水资源溯源管理系统</td>   <td>广东省</td>   <td>CN113177730B</td>   <td>2022-09-23</td>   <td>本发明公开了一种水资源溯源管理系统,包括：水资源数据管理模块,用于对供水、用水、耗水和排水环节的水资源数据进行采集,并通过区块链平台实现水资源数据的存储与管理；水资源溯源应用模块：用于通过智能合约对上链后的各环节的水资源数据进行分析,确定水质污染和水量漏损等水资源问题,并对其进行识别与诊断,以及用于对水资源数据进行溯源,通过对水资源数据的溯源,确定水资源问题的责任方。本系统以分布式账本的形式对各环节的水资源数据进行存储与管理,数据记录过程公开透明,通过智能合约对水量、水质问题进行识别与诊断,发现问题后通过溯源直接明确产生问题的节点,无需考虑数据真伪,降低了追责成本并提高了追责效率。</td>   <td>1.一种水资源溯源管理系统,其特征在于,包括：水资源数据管理模块和水资源溯源应用模块；所述水资源数据管理模块用于对供水、用水、耗水和排水环节上的水资源数据进行采集,并通过区块链平台实现水资源数据的存储与管理；所述区块链平台上的各节点包括水源地节点、水厂节点、用水户节点、污水处理厂节点和水管理部门节点；所述水源地节点用于对水信息进行采集,并将所述采集到的水信息数据、水源地的溯源码以及水源地的基本信息记录上链；所述水厂节点用于对供水信息数据进行采集,并将所述采集到的供水信息数据、水厂的基本信息、水源地的溯源码记录上链；所述用水户节点用于对用水信息数据进行采集,并将所述采集到的用水信息数据、用水户的基本信息、水厂的溯源码记录上链；所述污水处理厂节点用于对污水处理信息数据进行采集,并将所述采集到的污水处理信息数据、污水处理厂的基本信息、用水户的溯源码记录上链；所述水管理部门节点用于对水源地、水厂和污水处理厂的基本信息进行背书认证,并将认证通过的水源地、水厂和污水处理厂所对应的终端作为节点加入区块链中,并将监管信息记录上链；所述水资源数据管理模块通过包括多个传感器的无线传感网进行水质自动监测,获得连续的水质信息数据,并结合遥感信息和图像识别技术,通过数据融合将不同来源的所述水质信息数据加以处理、融合,得到相应水域的水质情况数据,再将所述水质情况数据经过验证加密后记录上链；所述水资源溯源应用模块包括水资源问题检测模块和水资源数据溯源模块；所述水资源问题检测模块用于通过智能合约对上链后的各环节的水资源数据进行分析,识别出水资源问题,并对水资源问题进行诊断与分析；所述水资源数据溯源模块用于对水资源数据进行溯源,当存在水资源问题时,还用于通过对各环节的水资源数据的溯源,确定所述水资源问题产生的根源节点和相应的责任方；所述水资源问题检测模块包括水量问题检测模块和水质问题检测模块；所述水量问题检测模块用于通过智能合约对上链后的各环节的水资源数据进行分析,以检测是否存在水量问题,当存在水量问题时,还用于对水量问题的严重程度进行评价,以及对供水管网中的水量漏损率和漏损节点进行诊断及定位；所述水量问题检测模块包括水量判别模块、水量问题评价模块和管网漏损检测模块；所述水量判别模块用于采用阈值法与水量平衡理论对各环节的水量进行判别,以检测是否存在水量问题；所述水量问题评价模块用于根据上链后的水资源数据中的水量数据和预设阈值的差额,对水量问题的严重程度进行评价；所述管网漏损检测模块用于对供水管网中的漏损信息进行诊断及分析；所述水质问题检测模块用于通过智能合约对上链后的各环节的水资源数据进行分析,以检测水质是否合格,当存在水质问题时,还用于对水质污染程度进行评价,并通过机器学习确定导致水质问题的原因；通过区块链的时间戳技术,将水资源在所述供水、用水、耗水和排水环节产生的数据记录在区块中并按照时间排序成链,所述水资源数据溯源模块根据所述水资源问题检测模块得出的水资源问题诊断分析结果,调取所述水资源问题出现时间前后的区块信息,并从所述区块信息中查询上下游环节的水量、水质数据追踪问题来源；所述水资源溯源应用模块还包括决策模块、责任奖惩模块、供水方资讯查询模块和评价建议模块；所述决策模块用于通过对各环节的水资源数据进行分析,为各环节的优化运行提供决策；所述责任奖惩模块用于通过智能合约对水资源问题的责任方执行奖惩操作；所述供水方资讯查询模块用于提供用水来源和各环节的水质信息的查询服务；所述评价建议模块用于为用户提供对于供水服务的投诉和评价反馈功能。</td>   <td>G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈振武;              周勇;              张枭勇;              许建荣;              张炳振;              胡海峰;              刘怡初;                   赵竟雯       </td>   <td>深圳市城市交通规划设计研究中心股份有限公司;中山大学</td>   <td>单目视觉下的三维目标检测模型的构建方法及检测方法</td>   <td>广东省</td>   <td>CN114429524B</td>   <td>2022-09-23</td>   <td>本发明公开了一种单目视觉下的三维目标检测模型的构建方法及检测方法,所述方法包括：获取带标注的训练图像集；将训练图像集作为训练数据,训练获得基于CenterNet网络的三维目标检测模型,其中,三维目标检测模型的特征提取网络包括多个特征提取模块,至少一个特征提取模块包括池化模块、注意模块以及第一融合模块,池化模块包括并列的全局最大池化层、全局平均池化层和随机池化层,注意模块包括分别与全局最大池化层、全局平均池化层和随机池化层的输出侧连接的三个子注意模块,子注意模块包括激活函数层及批处理归一化层,第一融合模块将三个子注意模块的输出融合。本发明可以简化三维目标检测网络结构,降低三维目标检测模型的训练成本。</td>   <td>1.一种单目视觉下的三维目标检测模型的构建方法,其特征在于,包括：获取带标注的训练图像集；将所述训练图像集作为训练数据,训练获得基于CenterNet网络的三维目标检测模型,其中,所述三维目标检测模型的特征提取网络包括多个特征提取模块,至少一个所述特征提取模块包括池化模块、注意模块以及第一融合模块,所述池化模块包括并列的全局最大池化层、全局平均池化层和随机池化层,所述注意模块包括分别与所述全局最大池化层、所述全局平均池化层和所述随机池化层的输出侧连接的三个子注意模块,所述子注意模块包括激活函数层及批处理归一化层,所述第一融合模块将三个所述子注意模块的输出融合；所述三维目标检测模型的特征提取网络为残差网络,所述特征提取模块还包括设置于所述第一融合模块输出侧的激活函数模块和第二融合模块,所述第一融合模块输出的特征经所述激活函数模块处理后,与输入所述特征提取模块的初始特征在所述第二融合模块融合,融合获得的特征图作为所述特征提取模块的输出特征图。</td>   <td>G06T17/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡跃新;              黄栋;                   区永康       </td>   <td>中山大学孙逸仙纪念医院;华南农业大学</td>   <td>一种基于XGBoost算法的眩晕病因诊断模型的构建方法及系统</td>   <td>广东省</td>   <td>CN115099355A</td>   <td>2022-09-23</td>   <td>本发明提供一种基于XGBoost算法的眩晕病因诊断模型的构建方法及系统。所述基于XGBoost算法的眩晕病因诊断模型的构建方法包括以下步骤：基于系统收集眩晕人群人口学信息、眩晕病史信息、眩晕相关辅助检查结果进行预处理,基于所有具有人口学信息、眩晕病史信息、眩晕相关辅助检查结果的眩晕人群构建训练样本集。本发明提供的基于XGBoost算法的眩晕病因诊断模型的构建方法及系统具有根据眩晕患者的相关信息输入,得出眩晕病因初步诊断,供临床医师参考,在临床上实现眩晕病因的精准诊断,特别是在医疗资源相对不足的地区有重大应用价值的优点。</td>   <td>1.一种基于XGBoost算法的眩晕病因诊断模型的构建方法,其特征在于,包括以下步骤：获取人群的人口学信息、眩晕病史信息、眩晕相关辅助检查结果,所述人群包括耳石症人群和非耳石症人群,所述耳石症人群包括确诊为耳石症的眩晕患者人群,所述非耳石症人群包括确诊为梅尼埃病、前庭性偏头痛、突发神经性耳聋的眩晕患者人群；对所述获取的人口学信息、眩晕病史信息、眩晕相关辅助检查结果进行预处理,基于所有预处理后数据构建训练样本集；利用所述训练样本集中的包含人口学信息、眩晕病史信息、眩晕相关辅助检查结果的耳石症和非耳石症眩晕患者样本,基于XGBoost算法,构建第一步骤分类器；利用所述训练样本集中的包含人口学信息、眩晕病史信息、眩晕相关辅助检查结果的非耳石症眩晕患者样本,基于XGBoost算法,构建第二步骤分类器；对所述第一步骤分类器和所述第二步骤分类器进行整合处理,得到眩晕病因诊断模型。</td>   <td>G06K9/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄菲妮;                   上官微       </td>   <td>中山大学</td>   <td>集成水文气象机器学习预报模型的可视化事后解释方法</td>   <td>广东省</td>   <td>CN115099416A</td>   <td>2022-09-23</td>   <td>本发明公开了集成水文气象机器学习预报模型的可视化事后解释方法,该方法包括下述步骤：建立单站点历史数据库及预报因子数据库,并进行特征选择；建立水文气象因子预报黑箱模型,并统计预报误差；事后解释方法从多个角度解释机器学习预报模型,基于MSE的特征重要性以及Shapley方法对模型结果进行可信任度评估,基于部分依赖图、个体条件期望和累积局部效应进行特征效应的可解释性分析,用于诊断模型,针对单日水文气象要素的预报,通过个体期望条件找到单日预报中表现异常的特征,根据历史数据判断其是否为特征的异常值。本发明基于事后可解释方法评估水文气象机器学习模型的特征效果,提高了模型的可靠性和鲁棒性。</td>   <td>1.集成水文气象机器学习预报模型的可视化事后解释方法,其特征在于,包括下述步骤：建立单站点历史数据库及预报因子数据库,并进行特征选择；建立水文气象因子预报黑箱模型,并统计预报误差；事后解释方法从多个角度解释机器学习预报模型,包括基于MSE的特征重要性、Shapley方法、部分依赖图、个体条件期望和累积局部效应进行解释；基于MSE的特征重要性进行解释,具体为：基于训练数据形成多棵决策树,选择袋外数据对决策树进行测试,获取预报模型的预测误差MSE,随机排列袋外数据的单个特征的特征值,获取新的预测误差MSE,并计算排列前后的预测误差MSE的差值,对每棵决策树的预测误差MSE差值进行平均,根据平均值从预报模型精度对特征进行重要性排序；基于Shapley方法进行解释,具体为：将每个特征对于预报值的贡献量转化为预报值的占比,对预测值的贡献在所有可能的特征组合上的加权求和,得到每个特征的重要性；基于部分依赖图进行解释,具体为：选取时间序列训练数据中的关注特征,基于关注特征将训练数据划分为两个子集,生成关注特征可能取值的集合,采用关注特征可能取值的集合中的数据值逐次代替关注特征,计算每次代替获得的预报值的平均值,即为部分依赖值,用于反映局地水文气象预报对象受到某因素影响时的平均变化情况；基于个体条件期望进行解释,具体为：选取单个时间点训练数据中的关注特征,基于关注特征将训练数据划分为两个子集,生成关注特征可能取值的集合,采用关注特征可能取值的集合中的数据值逐次代替关注特征,计算每次代替获得的预报值,即为单个时间点的部分依赖值,用于体现单个实例预报中特征对结果的影响；基于累积局部效应进行解释,具体为：选取单个时间点训练数据中的关注特征,基于关注特征将训练数据划分为两个子集,生成关注特征分布网格,在单个网格中,采用关注特征分布网格的数据值逐次代替关注特征,计算每次代替获得的预报值,并将网格中的预报值的差异进行平均,然后将其累积在网格上,从而反映特征效应；基于MSE的特征重要性以及Shapley方法对模型结果进行可信任度评估,基于部分依赖图、个体条件期望和累积局部效应进行特征效应的可解释性分析,用于诊断模型,针对单日水文气象要素的预报,通过个体期望条件找到单日预报中表现异常的特征,根据历史数据判断其是否为特征的异常值。</td>   <td>G06N20/00;G06N5/00;G06N3/08;G06K9/62;G06F16/904</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁朝霞;              刘达灏;              林妙钿;              徐文芳;              李超峰;                   潘泽韬       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种线上退费系统</td>   <td>广东省</td>   <td>CN115099823A</td>   <td>2022-09-23</td>   <td>本发明公开了一种线上退费系统,包括：退费申请模块,用于接收退费申请；票据申请判断模块,用于判断是否申请电子票据；退还比例判断模块,用于判断费用全退或部分退费；退费模块,用于进行费用退还；未申请电子票据全退模块,用于当未申请电子票据,费用全退时,作废虚拟票据号；未申请电子票据部分退模块,用于当未申请电子票据,部分退费时,生成新的虚拟票据号或生成新的电子票据号,并作废原虚拟票据号；已申请电子票据全退模块,用于当已申请电子票据,费用全退时,作废电子票据号；已申请电子票据部分退模块,用于当已申请电子票据,部分退费时,生成新的电子票据号并作废原电子票据号。本发明有利于提高退费效率,做到记录的留痕操作,提高系统工作效率。</td>   <td>1.一种线上退费系统,其特征在于,包括：退费申请模块,用于接收对收费记录的退费申请,所述退费申请包括票据申请信息以及退还比例信息,所述票据申请信息包括：所述收费记录未申请电子票据或者所述收费记录已申请电子票据,所述退还比例信息包括：费用全退或者部分退费,所述收费记录包括虚拟票据号以及电子票据号,所述虚拟票据号对应未申请电子票据的收费记录,所述电子票据号对应已申请电子票据的收费记录；票据申请判断模块,用于根据所述票据申请信息,判断所述收费记录是否申请电子票据；退还比例判断模块,用于根据所述退还比例信息,判断所述收费记录为费用全退还是部分退费；退费模块,用于根据所述退还比例信息进行费用退还；未申请电子票据全退模块,用于当所述票据申请判断模块判断所述收费记录未申请电子票据,且所述退还比例判断模块判断所述收费记录是费用全退时,在所述退费模块进行费用返还之后,作废所述收费记录的虚拟票据号；未申请电子票据部分退模块,用于当所述票据申请判断模块判断所述收费记录未申请电子票据,且所述退还比例判断模块判断所述收费记录是部分退费时,在所述退费模块进行费用返还之后,生成新的虚拟票据号或生成新的电子票据号,并作废所述收费记录的虚拟票据号；已申请电子票据全退模块,用于当所述票据申请判断模块判断所述收费记录已申请电子票据,且所述退还比例判断模块判断所述收费记录是费用全退时,在所述退费模块进行费用返还之后,作废所述收费记录已申请的电子票据号；已申请电子票据部分退模块,用于当所述票据申请判断模块判断所述收费记录已申请电子票据时,且所述退还比例判断模块判断所述收费记录是部分退费时,在所述退费模块进行费用返还之后,生成新的电子票据号并作废所述收费记录已申请的电子票据号。</td>   <td>G06Q20/40;G06Q20/04;G06Q20/38;G06Q10/02;G16H40/67</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              周铭枝;              郑炎辉;                   康丽       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>基于元胞自动机的河口地区盐度预测方法、系统及设备</td>   <td>广东省</td>   <td>CN115081740A</td>   <td>2022-09-20</td>   <td>本发明涉及水环境监测技术领域,公开了基于元胞自动机的河口地区盐度预测方法、系统及设备。本发明根据目标河口地区的遥感图像及水域分布定义元胞大小及空间分布,根据该地区的盐度遥感反演结果设置各元胞的初始盐度,根据径流数据设置各元胞的各项属性,并基于水动力转换机制、盐度移流机制、盐度扩散机制及水位变化规律形成元胞自动机模型的演化规则；根据演化规则对模型中所有元胞的各项属性进行迭代计算,根据得到的盐度变化数据与对应的实测盐度变化数据的比对结果进行模型各项参数的率定,得到相应的盐度预测模型,进而根据该预测模型预测目标河口地区盐度。本发明能够有效实现河口区盐度的模拟预测,解决了盐度的时间连续性预测问题。</td>   <td>1.一种基于元胞自动机的河口地区盐度预测方法,其特征在于,包括：根据目标河口地区的遥感图像及水域分布数据,设置元胞自动机模型的元胞大小及邻居结构,并设置元胞空间的墙界、流入边界和流出边界；获取目标河口地区的盐度遥感反演结果,以所述盐度遥感反演结果作为元胞自动机模型的盐度初始分布数据,根据所述盐度初始分布数据对各所述元胞的盐度进行赋值,根据所述目标河口地区的径流数据设置各所述元胞的各项属性,所述各项属性包括水位、水深、河底高程及含盐总量；构建关于元胞间水流流向变化和转移水量变化的水动力转换机制,根据所述水动力转换机制构建盐度移流机制,根据费克第一定律构建盐度扩散机制,根据实测潮位数据和降雨数据采用线性插值法得到潮汐与降雨导致的水位变化规律,将所述水位变化规律嵌入到所述水动力转换机制中,并基于得到的水动力转换机制、所述盐度移流机制和所述盐度扩散机制形成所述元胞自动机模型的演化规则；根据所述演化规则对所述元胞自动机模型中的所有元胞的各项属性进行迭代计算,将得到的盐度变化数据与对应的实测盐度变化数据进行比对,根据得到的比对结果进行所述元胞自动机模型各项参数的率定,得到相应的河口地区盐度预测模型；根据所述河口地区盐度预测模型预测目标河口地区盐度。</td>   <td>G06Q10/04;G06Q50/06;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余顺争;                   罗经伦       </td>   <td>中山大学</td>   <td>一种云安全服务功能树网络入侵检测系统</td>   <td>广东省</td>   <td>CN110298381B</td>   <td>2022-09-20</td>   <td>本发明涉及网络监控领域,更具体的,涉及一种云安全服务功能树网络入侵检测系统,所述的系统包括服务树拓扑编排模块、服务树拓扑映射模块、流特征数据库模块、全局资源监控模块；本发明利用网络功能虚拟化技术提供云安全资源；根据云安全态势灵活定制安全防御策略,在靠近网络攻击来源的方向部署云安全服务功能树,对可疑网络流量进行逐步细分识别；依据安全防御策略,可在细分后的云安全服务功能树分支中,依据当前分支的网络流特性调度相应的云安全VNF进行更细粒度处理,大大提高了网络的安全性。</td>   <td>1.一种云安全服务功能树网络入侵检测系统,其特征在于,包括服务树拓扑编排模块(1)、服务树拓扑映射模块(2)、流特征数据库模块(3)、全局资源监控模块(4)；所述流特征数据库模块(3)用于存储网络攻击的网络流特征数据,结合云安全态势选取相应的网络攻击流特征数据集构建相应的训练集；所述的服务树拓扑编排模块(1)用于结合云安全态势构建决策树分类模型,使用流特征数据库模块(3)中构建好的训练集对决策树模型进行训练与剪枝,将训练好的决策树分类模型传递给服务树拓扑映射模块(2)；所述的服务树拓扑映射模块(2)用于接收服务树拓扑编排模块(1)所构建的决策树分类模型,将决策树分类模型的决策规则匹配节点映射到相应的服务功能树节点中,在服务功能树节点完成对网络流量的匹配与分类；所述的全局资源监控模块(4)用于对流特征数据库模块(3)、服务树拓扑编排模块(1)以及服务树拓扑映射模块(2)中全网范围内的资源进行监控与维护,在云安全服务功能树拓扑的映射以及虚拟逻辑网络的构建过程中,提供底层基础设施的实际承载能力信息,优化VNF资源的映射和部署；所述的决策树分类模型对多个服务功能链进行堆叠复用来优化安全功能编排和虚拟资源部署,在靠近网络攻击来源的方向部署云安全服务功能树,对可疑网络流量进行逐步细分识别完成特异性的细粒度处理；所述的服务树拓扑映射模块(2)包括流量调度子模块(5)以及VNF资源调度子模块(6),所述的流量调度子模块(5)用于对网络数据报文进行分类治理,完成转发策略匹配；所述的VNF资源调度子模块(6)用于根据服务功能树编排策略进行按需调度与分类；所述的流量调度子模块(5)利用OpenFlow多级流表根据来源方向来对网络数据报文进行分类治理；所述的VNF资源调度子模块(6)使用Docker容器作为虚拟网络功能的承载,根据服务功能树编排策略进行按需调度。</td>   <td>G06K9/62;H04L9/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;                   宁志清       </td>   <td>中山大学</td>   <td>一种基于MapReduce的公共交通出行路径规划索引方法</td>   <td>广东省</td>   <td>CN109711633B</td>   <td>2022-09-20</td>   <td>本发明涉及一种基于MapReduce的公共交通出行路径规划索引方法,具体包括以下步骤：S1.确定时态图G的顶点集V上的全序关系,根据确定的顶点集V的全序关系对时态图G进行子图的划分；S2.对于划分的每个子图,分别使用MapReduce集群中的各个计算节点读取其分区数据,然后通过Map函数计算每个子图的弱规范路径,并将结果以映射形式保存在弱规范路径索引集I中；S3.使用Cleanup函数将弱规范路径索引集I中的每个映射转成键值对；S4.使用Reduce函数将键值对中键等于顶点v-i且顶点v-i是起点的映射加入集合I-(out)中,把键等于顶点v-j且顶点v-j是终点的映射加入集合I-(in)中,然后按照分布式时间路径索引的定义,对集合I-(out)和集合I-(in)中的映射进行排序,最后得到时态图G的分布式时间路径索引。</td>   <td>1.一种基于MapReduce的公共交通出行路径规划索引方法,其特征在于,应用MapReduce计算框架的Map函数、Cleanup函数和Reduce函数进行分布式时间路径索引的构建,具体包括以下步骤：步骤S1.确定时态图G的顶点集V上的全序关系,根据确定的顶点集V的全序关系对时态图G进行子图的划分；定义时态图：时态图G＝(V,E),其中V是G的顶点集,E是G的有向边集,e∈E由四元组构成,e＝&lt;u,v,T-d,T-a&gt;,其中u、v∈V,u表示有向边的弧尾,v表示有向边的弧头,T-d是从u到v的出发时间,T-a是从u到v的到达时间；将时态图G应用到公共交通网络时,用五元组表示一条边,即e＝&lt;u,v,T-d,T-a,b&gt;,表示交通工具b在时刻T-d从站点u出发,在时刻T-a到达站点v；步骤S2.对于划分的每个子图,分别使用MapReduce集群中的各个计算节点读取其分区数据,然后通过Map函数计算每个子图的弱规范路径,并将结果以映射形式保存在弱规范路径索引集I中；定义弱规范路径：对于时态图G＝(V,E),给定顶点集V上的一个全序关系O,u、v∈V,从顶点u到顶点v的路径P是弱规范路径当且仅当P满足：1)序限制：路径P上的所有顶点中,起点u或者终点v是全序关系O中序最高的顶点；2)支配限制：不存在从顶点u到顶点v的路径P′,使得P′满足序限制并且P′的出发时间不比P早且到达时间比P早；定义弱规范路径映射：给定时态图G＝(V,E)和V上的全序关系O,记C′为G上所有的弱规范路径集合,对于任意P∈C′,令u,v,T-d,T-a,b和p分别表示路径P的起点、终点、出发时间、到达时间、交通工具和轴点,P被映射为一个五元组i(P)＝&lt;w,T-d,T-a,b,p&gt;,且满足：如果O(u)＞O(v),则w＝v；如果O(u)＜O(v),则w＝u；则i(P)称为P的弱规范路径映射,并记I为G上所有弱规范路径映射构成的集合,i∈I；步骤 S3.使用Cleanup函数将弱规范路径索引集I中的每个映射转成键值对；步骤 S4.使用Reduce函数将键值对中键等于顶点v-i且顶点v-i是起点的映射加入集合I-(out)中,把键等于顶点v-j且顶点v-j是终点的映射加入集合I-(in)中,然后按照分布式时间路径索引的定义,对集合I-(out)和集合I-(in)中的映射进行排序,最后得到时态图G的分布式时间路径索引。</td>   <td>G06Q10/04;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;              罗玉琴;                   叶婉       </td>   <td>中山大学</td>   <td>一种基于有向无环图的区块链共识系统</td>   <td>广东省</td>   <td>CN113077343B</td>   <td>2022-09-16</td>   <td>本发明涉及一种基于有向无环图的区块链共识系统。包括委员会模块、链增长模块、排序模块以及网络模块,网络模块用于完成系统中各个模块之间的网络通信；委员会模块、链增长模块和排序模块共同完成区块链共识；委员会模块用于确认下一世代的活跃节点,第零世代的活跃链节点形成初始委员会,每个世代的委员会成员数量均为L；链增长模块用于根据当前委员会成员生成的链交易CTs更新有向无环图；排序模块首先完成普通交易NNTs的确认,形成共识,然后采用所确定的算法对确认的NNTs进行排序,形成一致的顺序。本发明将权益证明和有向无环图结合,不需要在一个委员会中运行拜占庭容错算法,也避免了需要见证节点或协调服务器的情况。</td>   <td>1.一种基于有向无环图的区块链共识系统,其特征在于,包括委员会模块、链增长模块、排序模块以及网络模块,所述的网络模块用于完成系统中各个模块之间的网络通信；所述的委员会模块、链增长模块和排序模块共同完成区块链共识；所述的委员会模块用于确认下一世代的活跃链节点,第零世代的活跃链节点形成初始委员会,每个世代的委员会成员数量均为L；所述的链增长模块用于根据当前委员会成员生成的链交易CTs更新有向无环图；所述的排序模块首先完成普通交易NNTs的确认,形成共识,然后采用所确定的算法对确认的NNTs进行排序,形成一致的顺序。</td>   <td>G06Q40/04;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王小青;              陈明瑞;                   朱宇霆       </td>   <td>中山大学</td>   <td>一种基于最大后验概率估计的SAR图像去斑方法及系统</td>   <td>广东省</td>   <td>CN115063320A</td>   <td>2022-09-16</td>   <td>本发明公开了一种基于最大后验概率估计的SAR图像去斑方法及系统,该方法包括：通过最大后验概率估计算法对SAR图像进行计算,构建SAR图像目标函数；通过交替方向乘子法对SAR图像目标函数进行分解,得到子函数；基于更新条件规则,对子函数进行求解并对SAR图像目标函数进行迭代优化处理,得到去斑无噪SAR图像。该系统包括：构建模块、分解模块和优化模块。通过使用本发明,能够实现在SAR图像目标函数不受约束的情况下提高SAR图像优化精度。本发明作为一种基于最大后验概率估计的SAR图像去斑方法及系统,可广泛应用于SAR图像处理领域。</td>   <td>1.一种基于最大后验概率估计的SAR图像去斑方法,其特征在于,包括以下步骤：通过最大后验概率估计算法对SAR图像进行计算,构建SAR图像目标函数；通过交替方向乘子法对SAR图像目标函数进行分解,得到子函数；基于更新条件规则,对子函数进行求解并对SAR图像目标函数进行迭代优化处理,得到去斑无噪SAR图像。</td>   <td>G06T5/00;G06V10/80;G06V10/82;G06F17/15;G06F17/16;G06F17/18;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         文静;              林广荣;              凌逸虹;              傅剑华;              翁泽霖;                   谢秀英       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>三级淋巴结构的识别方法、装置及设备</td>   <td>广东省</td>   <td>CN115063403A</td>   <td>2022-09-16</td>   <td>本申请提出一种三级淋巴结构的识别方法、装置及设备,其中,该三级淋巴结构的识别方法包括：获取待识别图像；基于三级淋巴结构检测模型对待识别图像进行目标检测,得到待识别图像中预选三级淋巴结构的检测框、检测概率和检测类别；三级淋巴结构检测模型为基于多个样本图像训练大规模卷积神经网络得到,样本图像中包含成熟三级淋巴结构的图像及非成熟三级淋巴结构的图像,检测框、检测概率和检测类别之间具有对应关系；基于检测框、检测概率和检测类别,从预选三级淋巴结构中确定出成熟三级淋巴结构及非成熟三级淋巴结构,得到待识别图像的识别结果。本申请实施例可以提高三级淋巴结构的识别效率和准确性。</td>   <td>1.一种三级淋巴结构的识别方法,其特征在于,包括：获取待识别图像；基于三级淋巴结构检测模型对所述待识别图像进行目标检测,得到所述待识别图像中预选三级淋巴结构的检测框、检测概率和检测类别；所述三级淋巴结构检测模型为基于多个样本图像训练大规模卷积神经网络得到,所述样本图像中包含成熟三级淋巴结构的图像及非成熟三级淋巴结构的图像,所述检测框、所述检测概率和所述检测类别之间具有对应关系；基于所述检测框、所述检测概率和所述检测类别,从所述预选三级淋巴结构中确定出成熟三级淋巴结构及非成熟三级淋巴结构,得到所述待识别图像的识别结果。</td>   <td>G06T7/00;G06V10/25;G06V10/764;G06V10/82;G06N3/04;G01N21/84</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伍伟文;                   潘嘉毅       </td>   <td>中山大学</td>   <td>基于优化迭代网络的CT图像重建方法以及系统</td>   <td>广东省</td>   <td>CN115063502A</td>   <td>2022-09-16</td>   <td>本发明公开了一种基于优化迭代网络的CT图像重建方法以及系统,本方法将迭代优化和深度学习相结合,通过将深度神经网络先验作为正则化器来探索残差测量中的深层特征,设计了一种迭代网络模型用于有限角度断层重建,本方法不是直接在图像空间上部署正则化项,而是在残差图像域上部署正则化项,可以显着提高重建图像的细节保留和收敛性；相较于现有方案,本方法采用图像后处理的训练策略,并在推理时进行迭代优化。因此,在细节保存方面提高了重建图像的质量,并且可以很容易地扩展到锥束CT。经过实验验证了本方法设计的迭代网络模型的收敛性,具有很高的稳定性。</td>   <td>1.一种基于优化迭代网络的CT图像重建方法,其特征在于,所述方法包括：构建由多个迭代子模型组成的迭代网络模型,所述迭代子模型包括神经网络,所述迭代网络模型整合所述神经网络的先验作为正则化器构建目标函数,所述目标函数包括：其中,A表示系统矩阵,y～((0))表示原始的投影数据,y表示投影域中的残差数据,表示神经网络函数,λ&gt;0表示超参数,表示弗罗贝尼乌斯范数,f表示迭代输出的图像；所述迭代网络模型的迭代表示式包括：其中,k表示迭代次数,f～((k))表示第k次迭代输出的图像；将所述原始的投影数据输入至所述迭代网络模型,得到所述迭代网络模型重建的CT图像。</td>   <td>G06T11/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈进财;              刘永红;                   罗银萍       </td>   <td>中山大学</td>   <td>面向交通环境污染模拟的城市三维建筑物快速建模方法</td>   <td>广东省</td>   <td>CN109191561B</td>   <td>2022-09-13</td>   <td>面向交通环境污染模拟的城市三维建筑物快速建模方法,其特征在于,具体步骤如下：步骤1通过数字化城市软件导出模拟区域的建筑物数据；步骤2通过程序语言软件对建筑物数据进行编程读取,并对建筑物外形数据特征进行优化,使其在保证建筑物主要形状特征的前提下,利于获取质量更好的数值计算网格；步骤3根据建筑物外形数据以及计算流动力学模拟的边界条件,设计数值模拟的计算区域；步骤4通过建模软件脚本语言,生成对应的建筑物、计算域的建模脚本；优点是,解决了真实城市场景大气污染扩散模拟过程中快速生成建筑几何模型的难题,提高了城市三维建筑建模的效率和准确度,简化城市大气污染扩散模拟的前处理过程。</td>   <td>1.面向交通环境污染模拟的城市三维建筑物快速建模方法,其特征在于,具体步骤如下：步骤1通过数字化城市软件导出模拟区域的建筑物数据；步骤2通过程序语言软件对建筑物数据进行编程读取,并对建筑物外形数据特征进行优化,使其在保证建筑物主要形状特征的前提下,利于获取质量更好的数值计算网格；步骤3根据建筑物外形数据以及计算流动力学模拟的边界条件,设计数值模拟的计算区域；步骤4通过建模软件脚本语言,生成对应的建筑物、计算域的建模脚本；步骤5在建模软件中运行建模脚本,生成建筑几何模型,其中,所述的步骤2中建筑物数据的优化主要是针对建筑物底面进行简化或修正处理,具体过程如下：步骤2.1：合并底面多边形相连且平行的边：对于底面的任一个内角θ-i,其中,i＝0,1,2,…,n-1；底面为n边形,如果|θ-i-180°|≤Θ-0,删除该内角对应的顶点,其中Θ-0为自定义的角度参数；步骤2.2：进一步合并交点到两边端点连线距离足够小的相连边：对于底面的任一个顶点p-i,如果p-i到p-(i-1)和p-(i+1)连线的最小距离d-i&lt;D-0,则删除顶点p-i,其中D-0为自定义的距离参数,且p-(-1)＝p-(n-1),p-n＝p-0；步骤2.3：底面为凹多边形时,对部分凹入部分进行填充：当底面多边形内角θ-j为大于180度的优角时,分别沿顶点编号递减和递增方向找到两个与之最近的非优角θ-i和θ-k,其中,i＝0,1,2,…,n-1；k＝0,1,2,…,n-1；i≠k,如果这两个顶点p-i、p-k之间的距离小于给定参数D-1,则移除p-i、p-k之间所有内角为优角的顶点；步骤2.4：调整建筑物底面顶点到附近建筑物底面的距离：判断建筑物底面多边形的顶点到相邻建筑物底边多边形的最小距离,若最小距离小于给定参数D-2,则按一定规则移动该顶点,使之偏离相邻的建筑物；所述步骤2.4的具体过程是：对于任意不相同的两个建筑物b-i和b-j,i&lt;j,对建筑物b-i的底面多边形的顶点进行循环,判断这些顶点到建筑物b-j底面多边形每条边的最小距离；若距离小于设定的间距参数D-2,则按照设定的规则移动该顶点,直到该顶点到建筑物b-j的距离不小于间距参数D-2；判断顶点p-i到线段l-j的最小距离步骤为：首先分别计算点p-i到线段l-j所在直线的垂直距离d-0以及到两个端点p-(j1)、p-(j2)的距离d-1、d-2,然后判断p-i到l-j的垂线是否与l-j相交；方法为以线段l-j的端点p-(j1)为原点,p-(j1)p-(j2)方向为x′轴正方向,建立新的直角坐标系x’-y’,并通过平面直角坐标变换公式得到p-i、p-(j1)、p-(j2)在新坐标系下的坐标p′-i(x′-i,y′-i)、p′-(j1)(x′-(j1),y′-(j1))、p′-(j2)(x′-(j2),y′-(j2)),若满足x′-i≤min(x′-(j1),x′-(j2))或者x′-i≥max(x′-(j1),x-(j2)′),则p-i到l-j的垂线与l-j不相交,p-i到线段l-j的最小距离为min(d-1,d-2),l-j上离p-i最近的点p-(j0)为p-(j1)或p-(j2),否则最小距离为d-0,最近的点为p-i到l-j的垂点p-(j0)′(x′-i,0),再用平面坐标变换公式反变换即可得到x-y坐标系下的垂点p-(j0)；x＝x′cosθ-y′sinθ+x-0,y＝x′sinθ+y′cosθ+y-0.移动顶点的步骤为：由前一个步骤可得到顶点p-i偏移建筑物b-j最快的方向p-(j0)p-i；为了避免p-i的移动影响建筑物b-i与其它建筑物的距离,需要强制将p-i的移动方向限制在建筑物b-i底面多边形内,方法为将方向矢量p-(j0)p-i投影到连接p-i的两条边上,并将得到的两个投影矢量相加,获得最终的移动方向矢量；令p-(j0)p-i与x轴正向的方向夹角为θ,p-i移动距离为d,则移动后p-i的坐标为(x-i+dcosθ,y-i+dsinθ)；步骤2.5：重复步骤2.1-步骤2.4,进行多次优化。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         粟涛;                   刘思煌       </td>   <td>中山大学</td>   <td>基于双一维滤波卷积核的图像锐化方法、系统及存储介质</td>   <td>广东省</td>   <td>CN115049557A</td>   <td>2022-09-13</td>   <td>本发明公开了一种基于双一维滤波卷积核的图像锐化方法、系统及存储介质,方法包括：确定第一滤波卷积核和第二滤波卷积核；通过第一滤波卷积核对待处理图像进行滤波处理得到第一边缘图像,并通过第二滤波卷积核对待处理图像进行滤波处理得到第二边缘图像；根据第一边缘图像和第二边缘图像确定第三边缘图像,进而对第三边缘图像和待处理图像进行叠加处理,得到锐化图像；其中,第一滤波卷积核为行矩阵,第二滤波卷积核为列矩阵,且行矩阵为列矩阵的转置矩阵。本发明采用互为转置矩阵的两个一维滤波卷积核进行滤波处理提取边缘图像,增强了对噪声的抗干扰能力,提高了边缘提取的准确性,进而增强了图像锐化的效果,可广泛应用于图像处理技术领域。</td>   <td>1.一种基于双一维滤波卷积核的图像锐化方法,其特征在于,包括以下步骤：确定第一滤波卷积核和第二滤波卷积核；通过所述第一滤波卷积核对待处理图像进行滤波处理得到第一边缘图像,并通过所述第二滤波卷积核对所述待处理图像进行滤波处理得到第二边缘图像；根据所述第一边缘图像和所述第二边缘图像确定第三边缘图像,进而对所述第三边缘图像和所述待处理图像进行叠加处理,得到锐化图像；其中,所述第一滤波卷积核为行矩阵,所述第二滤波卷积核为列矩阵,且所述行矩阵为所述列矩阵的转置矩阵。</td>   <td>G06T5/00;G06T5/20;G06T7/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李文楷;              黄伟钧;              胡晓梅;              刘子越;                   李佳豪       </td>   <td>中山大学</td>   <td>一种森林场景体素模型构建方法及系统</td>   <td>广东省</td>   <td>CN115049790A</td>   <td>2022-09-13</td>   <td>本发明公开了一种森林场景体素模型构建方法及系统,该方法包括：基于激光雷达获取待测区域的参考树的点云数据和冠层结构的点云数据；根据冠层结构的点云数据对参考树的点云数据进行点云转换,得到参考树的点云转换数据；根据参考树的点云转换数据将参考树填补冠层结构的点云数据的空白,生成高密度点云数据；对高密度点云数据进行体素化,构建森林场景体素模型。该系统包括：采集数据模块、点云转换模块、数据填补模块和构建模块。通过使用本发明,能够实现在大空间范围内重建森林场景的精细尺度三维结构且提高分辨率。本发明作为一种森林场景体素模型构建方法及系统,可广泛应用于激光雷达数据三维建模技术领域。</td>   <td>1.一种森林场景体素模型构建方法,其特征在于,包括以下步骤：基于激光雷达获取待测区域的参考树的点云数据和冠层结构的点云数据；根据冠层结构的点云数据对参考树的点云数据进行点云转换,得到参考树的点云转换数据；根据参考树的点云转换数据将参考树填补冠层结构的点云数据的空白,生成高密度点云数据；对高密度点云数据进行体素化,构建森林场景体素模型。</td>   <td>G06T17/00;G06V10/764;G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘家夫;              王紫宸;              王勇;                   邱周静子       </td>   <td>中山大学</td>   <td>基于深度学习的超分辨率水下图像增强方法及系统</td>   <td>广东省</td>   <td>CN115034965A</td>   <td>2022-09-09</td>   <td>本发明公开了基于深度学习的超分辨率水下图像增强方法及系统,该方法包括：基于生成对抗网络与深度残差乘法器,构建改进生成对抗网络模型；将水下图像输入改进生成对抗网络模型进行训练,生成增强超分辨率水下图像。该系统包括：构建模块和训练模块。通过使用本发明,能够在提高水下图像分辨率的同时改善水下图像的视觉质量。本发明作为基于深度学习的超分辨率水下图像增强方法及系统,可广泛应用于水下图像处理技术领域。</td>   <td>1.基于深度学习的超分辨率水下图像增强方法,其特征在于,包括以下步骤：基于生成对抗网络与深度残差乘法器,构建改进生成对抗网络模型；将水下图像输入改进生成对抗网络模型进行训练,生成增强超分辨率水下图像。</td>   <td>G06T3/40;G06T5/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              李辉忠;              杨硕;              张开翔;              范瑞彬;              白兴强;                   李成博       </td>   <td>深圳前海微众银行股份有限公司;中山大学</td>   <td>一种测试种子的确定方法及装置</td>   <td>广东省</td>   <td>CN115017048A</td>   <td>2022-09-06</td>   <td>本发明涉及金融科技(Fintech)领域,公开一种测试种子的确定方法及装置,针对目标智能合约的第i轮测试种子,基于第i轮测试种子进行第i+1轮模糊测试；针对任一个测试种子,根据测试种子在第i+1轮模糊测试中的函数调用记录,若确定测试种子在第i+1轮模糊测试中覆盖函数调用流图中的新节点,则保留测试种子作为候选测试种子；针对任一个候选测试种子,根据候选测试种子对应的新节点在函数调用流图中的调用次数和被调用次数,确定候选测试种子的种子适应度；根据各候选测试种子分别对应的种子适应度,确定出用于进行第i+2轮模糊测试的第i+1轮测试种子。基于该方式可筛选出高质量的测试种子,从而提升模糊测试的效率。</td>   <td>1.一种测试种子的确定方法,其特征在于,包括：针对目标智能合约的第i轮测试种子,基于所述第i轮测试种子进行第i+1轮模糊测试,并获取所述第i轮测试种子中的各测试种子在所述第i+1轮模糊测试中的函数调用记录；针对所述第i轮测试种子中的任一个测试种子,根据所述测试种子在所述第i+1轮模糊测试中的函数调用记录,若确定所述测试种子在所述第i+1轮模糊测试中覆盖函数调用流图中的新节点,则保留所述测试种子作为候选测试种子；其中,所述函数调用流图是以所述目标智能合约中的各函数作为节点,且对存在调用关系的两个函数进行节点连线作为调用边构建的,任一调用边标记有函数调用次数；针对所述第i轮测试种子中的任一个候选测试种子,根据所述候选测试种子对应的新节点在所述函数调用流图中的调用次数和被调用次数,确定所述候选测试种子的种子适应度；根据各候选测试种子分别对应的种子适应度,从所述第i轮测试种子中确定出用于进行第i+2轮模糊测试的第i+1轮测试种子,并返回执行针对目标智能合约的第i轮测试种子,基于所述第i轮测试种子进行第i+1轮模糊测试的步骤,直至满足所述模糊测试的预设时间。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   刘一晴       </td>   <td>中山大学</td>   <td>一种双向点云属性预测压缩方法,装置,设备及介质</td>   <td>广东省</td>   <td>CN113096198B</td>   <td>2022-08-30</td>   <td>本发明公开了一种双向点云属性预测压缩方法、装置、设备及介质,方法包括：分别计算点云数据在几何坐标轴上的标准差；根据所述标准差,确定空间偏倚系数；对所述点云数据的几何信息进行莫顿编码排序或者希尔伯特编码排序,确定莫顿序或希尔伯特序；根据所述莫顿序或希尔伯特序结合序号进行属性预测,确定属性预测值；根据所述属性预测值,对所述点云数据进行属性预测压缩。本发明实现了减少以往根据个人经验设定空间偏倚系数所带来的不确定性,能更精确地找到真实几何空间中距离最近的点,减少了在点云数据的属性压缩中的损失,可广泛应用于点云数据处理技术领域。</td>   <td>1.一种双向点云属性预测压缩方法,其特征在于,包括：分别计算点云数据在几何坐标轴上的标准差；其中,所述分别计算点云数据在几何坐标轴上的标准差,包括：根据所述点云数据的X,Y,Z坐标,确定三个一维数组；根据所述一维数组,确定所述点云数据X,Y,Z的标准差；所述标准差的计算公式为：                  其中,所述S为标准差,n为一维数组中元素的个数,i为正整数,A-i为一维数组中第i个元素,μ为一维数组中所有元素的均值；根据所述标准差,确定空间偏倚系数；其中,所述根据所述标准差,确定空间偏倚系数,包括：根据所述标准差,确定所述点云数据的坐标离散程度；根据所述坐标离散程度的大小确定空间偏倚系数；对所述点云数据的几何信息进行莫顿编码排序或者希尔伯特编码排序,确定莫顿序或希尔伯特序,其中,所述点云数据的几何信息包括所述空间偏倚系数；根据所述莫顿序或希尔伯特序结合序号进行属性预测,确定属性预测值；根据所述属性预测值,对所述点云数据进行属性预测压缩；其中,所述根据所述莫顿序或希尔伯特序结合序号进行属性预测,确定属性预测值,包括：根据所述莫顿序或希尔伯特序,对奇数点进行单向属性预测,确定所述奇数点对应的第一属性预测值；根据所述莫顿序或希尔伯特序,在所有奇数点预测完毕后,对偶数点进行双向属性预测,确定所述偶数点对应的第二属性预测值；所述根据所述莫顿序或希尔伯特序,对奇数点进行单向属性预测,确定所述奇数点对应的第一属性预测值的具体步骤为：确定单向属性预测的搜索范围为小于所述奇数点序号的奇数点；根据所述单向属性预测的搜索范围结合所述空间偏倚系数确定每个临近点的距离；所述距离的计算公式为：d-j＝|x-i-x-(ij)|+|y-i-y-(ij)|+θ*|z-i-z-(ij)|式中,d-j为距离,θ为空间偏倚系数,(x-i,y-i,z-i)为奇数点的几何坐标,(x-(ij),y-(ij),z-(ij))为临近点的几何坐标,j为正整数；根据所述单向属性预测的搜索范围确定参考点的权值,所述参考点为从所述临近点中选取至少一个距离最小的点；所述权值w-(ij)的计算公式为：                  根据所述单向属性预测的搜索范围确定所述奇数点的第一属性预测值；所述第一属性预测值的计算公式为：                  式中,为每个临近点的属性重建值,k为参考点个数。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈鹏飞;              胡子俊;                   郑子彬       </td>   <td>中山大学</td>   <td>一种数据系统异常分析模型的构建方法</td>   <td>广东省</td>   <td>CN114970994A</td>   <td>2022-08-30</td>   <td>本申请公开了一种数据系统异常分析模型的构建方法,包括：获取数据系统的若干关键性能指标KPI历史时序数据,对于每两KPI历史时序数据组成的KPI历史时序数据对,根据每一KPI历史时序数据的数据分布,确定KPI历史时序数据对的不变量得分,根据每一KPI历史时序数据对的不变量得分,确定KPI历史时序数据对是否具有不变量关系,并构建各KPI历史时序数据的不变量网络模型。由此可见,将两两KPI历史时序数据构成KPI历史时序数据对,分析KPI历史时序数据对的不变量关系,使得各KPI历史时序数据之间得到联系,由此构建得到的不变量网络模型能够表示各KPI之间的空间关系,能够高准确率地对数据系统进行故障监测。</td>   <td>1.一种数据系统异常分析模型的构建方法,其特征在于,包括：获取数据系统的若干关键性能指标KPI历史时序数据；对于每两KPI历史时序数据组成的KPI历史时序数据对,根据每一KPI历史时序数据的数据分布,确定所述KPI历史时序数据对的不变量得分；根据每一KPI历史时序数据对的不变量得分,确定所述KPI历史时序数据对是否具有不变量关系,以是否具有不变量关系作为模型构建基准,构建各KPI历史时序数据的不变量网络模型,以监测当所述若干KPI历史时序数据更新后,所述数据系统是否发生故障。</td>   <td>G06Q10/04;G06Q10/06;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              黎炜驰;              曾雪兰;              余志;              何青蔓;                   何嘉俊       </td>   <td>中山大学;广东工业大学</td>   <td>一种交通排放配额分配过程中离群数据识别的优化方法</td>   <td>广东省</td>   <td>CN114971055A</td>   <td>2022-08-30</td>   <td>本发明涉及一种交通排放配额分配过程中离群数据识别的优化方法。该方法包括构建交通排放配额分配模型、计算参考集D中各车辆各投入的单位产出投入值、采用孤立森林模型-广义超效率模型组合方法对离群车辆进行识别和将最终离群车辆从参考集D中移除,得到完成离群车辆剔除处理的参考集D”。本发明交通排放配额分配过程中离群数据识别的优化方法能够高效率地检测离群值,在配额分配过程以自动化、相对快速且准确的方式识别离群值；本发明的方法优于传统超效率模型方法,并较大程度减少了误差。</td>   <td>1.一种交通排放配额分配过程中离群数据识别的优化方法,其特征在于,包括如下步骤：S1.构建交通排放配额分配模型；S2.计算参考集D中各车辆各投入的单位产出投入值；S3.采用孤立森林模型-广义超效率模型组合方法对离群车辆进行识别；S4.将最终离群车辆从参考集D中移除,得到完成离群车辆剔除处理的参考集D”。</td>   <td>G06Q10/04;G06Q10/06;G06Q30/02;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈绍晴;              魏婷;              张琳梅;              吴俊良;                   王雅斐       </td>   <td>中山大学</td>   <td>一种城市轨道交通基础设施全生命周期碳排放动态分析方法</td>   <td>广东省</td>   <td>CN114971371A</td>   <td>2022-08-30</td>   <td>本发明公开了一种城市轨道交通基础设施全生命周期碳排放动态分析方法,包括如下步骤：S1、确定生命周期分析目标与范围；S2、分析生命周期清单；S3、计算生命周期碳排放量；S4、分析生命周期结果的不确定性；S5、动态核算生命周期碳排放；S6、根据不同情景分析生命周期碳排放动态发展路径。从生命周期视角出发,追踪了在动态时间序列上存在技术代表性变化的城市轨道交通基础设施能源足迹与碳足迹变化轨迹,可在交通基础设施全生命周期不同阶段寻求节能减碳缓解机会提供新思路,提供一种较为平衡、合理的方式来评估大规模城市交通基础设施项目规划的利弊。</td>   <td>1.一种城市轨道交通基础设施全生命周期碳排放动态分析方法,其特征在于,包括如下步骤：S1、确定生命周期分析目标与范围；S2、分析生命周期清单；S3、计算生命周期碳排放量；S4、分析生命周期结果的不确定性；S5、动态核算生命周期碳排放；S6、根据不同情景分析生命周期碳排放动态发展路径。</td>   <td>G06Q10/06;G06Q10/10;G06Q50/26;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙伟;                   陆佳星       </td>   <td>中山大学</td>   <td>一种基于区块链和可信数据空间的陶瓷溯源与鉴定方法</td>   <td>广东省</td>   <td>CN114971653A</td>   <td>2022-08-30</td>   <td>本发明公开了一种基于区块链和可信数据空间的陶瓷溯源与鉴定方法,包括步骤如下：采集陶瓷的纹理图像,构造陶瓷本身具有唯一性的纹理图像标准库；将陶瓷的烧制工艺信息、烧制时间信息、加工信息、运输信息、交易信息、纹理图像标准库保存在可信数据空间内并进行安全分级；将烧制工艺、纹理图像标准库作为数字存证信息,采用哈希算法进行加密,并以区块的形式分布存储在区块链上；将烧制时间信息、加工信息、运输信息、交易信息作为可公开基本信息直接以区块的形式上传至区块链；区块链通过广播机制更新每一份陶瓷上链的数字存证信息以及可公开基本信息；通过获取数字存证信息以及可公开基本信息完成对陶瓷的溯源；通过卷积神经网络对获取待测陶瓷的纹理图像进行识别与对比完成对陶瓷的鉴定。</td>   <td>1.一种基于区块链和可信数据空间的陶瓷溯源与鉴定方法,其特征在于：所述的方法包括步骤如下：采集陶瓷的纹理图像,构造陶瓷本身具有唯一性的纹理图像标准库；将陶瓷的烧制工艺信息、烧制时间信息、加工信息、运输信息、交易信息、纹理图像标准库作为其全生命周期数据；将全生命周期数据保存在可信数据空间内并进行安全分级；将安全等级高的烧制工艺、纹理图像标准库作为数字存证信息,采用哈希算法进行加密,并以区块的形式分布存储在区块链上；将安全等级低的烧制时间信息、加工信息、运输信息、交易信息作为可公开基本信息直接以区块的形式上传至区块链；分布式的区块链通过广播机制更新每一份陶瓷上链的数字存证信息以及可公开基本信息；通过获取数字存证信息以及可公开基本信息完成对陶瓷的溯源；通过卷积神经网络对获取待测陶瓷的纹理图像进行识别与对比完成对陶瓷的鉴定。</td>   <td>G06Q30/00;G06F21/62;G06V10/54;G06V10/82;H04L9/32;H04L9/40;H04L67/1097</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈绍晴;              张琳梅;              谭旖琦;              王湘茹;                   王雅斐       </td>   <td>中山大学</td>   <td>一种能源-水资源-碳耦合系统跨区域交互模拟系统</td>   <td>广东省</td>   <td>CN114971947A</td>   <td>2022-08-30</td>   <td>本发明公开了一种能源-水资源-碳耦合系统跨区域交互模拟系统,包括区域间投入产出模型构建,本发明开发了能源-水资源-碳耦合系统跨区域交互模拟系统,建立了区域本地的直接耦合联系和由跨区域供应链引起的间接耦合联系,并提出了耦合足迹的概念,从本土和消费的角度分析与能源相关的水资源利用(能用水)、与水资源相关的用能(水用能)和与水资源相关的碳排放(水排碳)。该跨区域能源-水资源-碳耦合系统模拟框架将足迹评估法应用于耦合分析,可帮助确定通过跨区域贸易活动影响当地能源、水资源利用和碳排放的关键部门和主导活动,从而制定出更为精准的区域节能减排和水资源高效利用策略。此外,该框架还可以推广到不同尺度下的各类环境足迹耦合问题分析,为城市和城市群的可持续资源管理提供方法论支持。</td>   <td>1.一种能源-水资源-碳耦合系统跨区域交互模拟系统,包括区域间投入产出模型构建、区域内能源-水资源-碳耦合直接流动的核算、区域间能源-水资源-碳耦合隐含流动追踪及能源-水资源-碳耦合足迹评估,其特征在于：所述区域内能源-水资源-碳耦合直接流动的核算包括能源核算、能源相关用水核算、碳排放核算、直接耗水量核算、水用能核算以及水排碳核算,所述能源-水资源-碳耦合足迹评估包括人均本土端足迹及消费端足迹。</td>   <td>G06Q50/06;G06Q50/26;G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张艳;              曲承志;              陈金涛;                   马非凡       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种点云去噪算法参数的自动调优方法及装置</td>   <td>广东省</td>   <td>CN114972066A</td>   <td>2022-08-30</td>   <td>本申请公开了一种点云去噪算法参数的自动调优方法及装置,所述方法包括：将预先配置的参数组中的各个参数代入至已有的初始点云去噪算法中,得到中间点云去噪算法,然后对待去噪点云去噪,得到去噪结果,对去噪结果的平滑度和局部密度进行评估,得到评估结果,利用评估结果对去噪算法的各个参数进行调整,得到调整后的去噪算法,并返回执行对待去噪点云去噪,得到去噪结果的步骤,直到调整次数达到预设调整次数,将预设调整次数下的各个参数组成目标参数组。可见,对去噪效果进行评估,得到去噪评估结果作为优化去噪的反馈结果,更新点云去噪算法的参数,最终得到优化后的各个参数,大大节省了人工调参的时间。</td>   <td>1.一种点云去噪算法参数的自动调优方法,其特征在于,包括：将预先配置的参数组中的各个参数代入至已有的初始点云去噪算法中,得到中间点云去噪算法；基于所述中间点云去噪算法对待去噪点云进行去噪,得到去噪结果；对所述去噪结果的平滑度和局部密度进行评估,得到评估结果；利用所述评估结果对所述中间点云去噪算法的各个参数进行调整,得到调整后的中间点云去噪算法,并返回执行基于所述中间点云去噪算法对待去噪点云进行去噪,得到去噪结果的步骤,直到调整次数达到预设调整次数,将预设调整次数下的各个参数组成目标参数组。</td>   <td>G06T5/00;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨淞然;              华平;              吕磊;                   李昊天       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种时间平均剪切力的测量方法和装置</td>   <td>广东省</td>   <td>CN114972165A</td>   <td>2022-08-30</td>   <td>本发明提供了一种时间平均剪切力的测量方法和装置,所述方法包括：读取CTA图像集和待测用户的待测CTA图像；将所述CTA图像集输入预设的图像分割网络,对所述CTA图像集进行分割,获得动脉图像集；计算所述动脉图像集中若干个动脉一一对应的时间平均剪切力；根据经过下采样的动脉图像集,结合若干个所述时间平均剪切力,构建测算网络；将所述待测CTA图像输入所述测算网络,获得所述待测用户的时间平均剪切力测量结果。相对于现有技术,解决了无法自动测量的问题,测量过程无需人工介入,降低了使用者的知识门槛；通过对动脉图像集下采样并构建测算网络,可以有效处理大量数据,提高数据处理效率。</td>   <td>1.一种时间平均剪切力的测量方法,其特征在于,包括：读取CTA图像集和待测用户的待测CTA图像；其中,所述CTA图像集包括患者图像和非患者图像；所述待测CTA图像包括被标记的动脉区域；将所述CTA图像集输入预设的图像分割网络,对所述CTA图像集进行分割,获得动脉图像集；计算所述动脉图像集中若干个动脉一一对应的时间平均剪切力；对所述动脉图像集中的每个图像进行数值归一化,并对经过数值归一化的每个图像设置若干初始点和下采样；根据经过下采样的动脉图像集,结合若干个所述时间平均剪切力,构建测算网络；将所述待测CTA图像输入所述测算网络,获得所述待测用户的时间平均剪切力测量结果。</td>   <td>G06T7/00;G06T7/174;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢红宁;                   雷婷       </td>   <td>中山大学附属第一医院</td>   <td>基于残差神经网络胎儿超声切面量化质控考核方法及装置</td>   <td>广东省</td>   <td>CN114972241A</td>   <td>2022-08-30</td>   <td>本发明公开了一种基于残差神经网络胎儿超声切面量化质控考核方法及装置,其中该方法包括：确定包括有目标胎儿结构的医疗影像数据；将所述医疗影像数据输入至训练好的切面识别残差神经网络模型,以识别得到所述医疗影像数据中的至少一个结构切面；所述切面识别残差神经网络模型为通过包括有多个标注有结构切面的训练医疗影像的训练数据集训练得到；根据所述医疗影像数据中的至少一个结构切面,以及预设的切面评分规则,确定所述医疗影像数据对应的评分信息。可见,本发明可以根据医疗影像中的切面信息对医疗影像的质量进行精确地评分,有利于实现更高效的医疗影像的质量把控,为后续的医疗数据处理提供更高质量的数据基础。</td>   <td>1.一种基于残差神经网络胎儿超声切面量化质控考核方法,其特征在于,所述方法包括：确定包括有目标胎儿结构的医疗影像数据；将所述医疗影像数据输入至训练好的切面识别残差神经网络模型,以识别得到所述医疗影像数据中的至少一个结构切面；所述切面识别残差神经网络模型为通过包括有多个标注有结构切面的训练医疗影像的训练数据集训练得到；根据所述医疗影像数据中的至少一个结构切面,以及预设的切面评分规则,确定所述医疗影像数据对应的评分信息。</td>   <td>G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;              周凡;                   陈小燕       </td>   <td>中山大学</td>   <td>基于混合增强智能的医学影像结构化自动标注方法与系统</td>   <td>广东省</td>   <td>CN114972291A</td>   <td>2022-08-30</td>   <td>本发明公开了一种基于混合增强智能的医学影像结构化自动标注方法与系统。首先初始训练ALSS模型,之后根据模型参数预测的置信图使用ClassMix方法对MAE自编码器形成的配对图像进行数据增强,再利用数据增强的人工标注影像数据对ALSS模型进行迭代训练,最后利用未标注影像数据,使用半监督损失对ALSS模型的生成器进行训练得到最终生成器,当用户输入待处理图像到最终生成器时即可完成自动结构化标注。本发明通过语义标注的方式从较模糊的低分辨率图像中为医生指明对应像素区域所属的器官结构；使用半监督方法能有效利用大量的无标注数据更好地学习胸腔部位的轮廓信息；采用的ClassMix数据增强方案能将无标注数据人工地转化为有标注数据。</td>   <td>1.一种基于混合增强智能的医学影像结构化自动标注方法,其特征在于,所述方法包括：步骤一,输入医学影像数据集,基于数据集中的标注影像数据,使用交叉熵损失和对抗损失训练ALSS模型的生成器和判别器,并得到ALSS模型的初始参数；步骤二,基于当前ALSS模型的参数,用所述生成器预测所述医学影像数据集中的未标注影像数据的语义分割掩码,用所述判别器预测对于该语义分割掩码的置信图；步骤三,使用MAE自编码器学习所述医学影像数据集中的未标注影像数据的低维隐编码空间；步骤四,取所述经过学习的MAE自编码器中的编码器部分为所述医学影像数据集中的未标注影像数据生成低维隐编码,由此为未标注影像数据的每幅图像完成配对,形成未标注图像对集合；步骤五,根据所述语义分割掩码的置信图,使用ClassMix方法对所述未标注图像对集合中的每对图像对进行数据增强,形成数据增强的人工标注影像数据；步骤六,使用所述数据增强的人工标注影像数据训练所述ALSS模型的生成器和判别器,损失函数同样为所述交叉熵损失和对抗损失；步骤七,迭代执行步骤二、步骤四、步骤五、步骤六多次,每次迭代中使用每次步骤五形成的数据增强的人工标注影像数据进行有监督学习,使所述ALSS模型的生成器和判别器的参数交替更新直至收敛；步骤八,利用所述医学影像数据集中的未标注影像数据,使用半监督损失对在步骤七中训练完成的所述ALSS模型的生成器进行训练,更新此生成器参数,得到最终生成器；步骤九,用户输入待处理的胸腔医学影像,通过所述最终生成器预测其语义分割掩码完成自动结构化标注。</td>   <td>G06T7/00;G06V10/26;G06V10/764;G06V10/82;G16H30/20;G16H50/20;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张艳;              张鑫;              马非凡;                   黄坤       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于神经网络的空间目标点云配准方法及设备</td>   <td>广东省</td>   <td>CN114972454A</td>   <td>2022-08-30</td>   <td>本申请公开一种基于神经网络的空间目标点云配准方法及设备,通过获取待配准目标对象的目标点云数据集,然后利用预训练的点云配准神经网络模型,处理目标点云数据集,以得到待配准目标对象的目标运动真值。其中,点云配准神经网络模型为,利用标注有运动真值标签的训练对象的点云数据样本集训练得到,目标运动真值为待配准目标对象在不同视角下的相对运动,最后根据目标运动真值确定待配准目标对象的架构,完成空间目标点云的配准过程。该方案可以利用训练好的点云配准神经网络模型得到待配准目标对象准确的目标旋转矩阵和目标平移向量,可以降低点云配准的误差,提高配准率。</td>   <td>1.一种基于神经网络的空间目标点云配准方法,其特征在于,包括：获取待配准目标对象的目标点云数据集；利用预训练的点云配准神经网络模型,处理所述目标点云数据集,以得到待配准目标对象的目标运动真值,其中,所述点云配准神经网络模型为,利用标注有运动真值标签的训练对象的点云数据样本集训练得到,所述目标运动真值为所述待配准目标对象在不同视角下的相对运动；根据所述目标运动真值确定所述待配准目标对象的架构,完成空间目标点云的配准过程。</td>   <td>G06T7/33;G06T7/246;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王嘉辉;              李子健;              魏杨燊;              张佰君;                   蔡志岗       </td>   <td>中山大学</td>   <td>一种基于图像高频信息的无参考图像质量评价方法</td>   <td>广东省</td>   <td>CN111652854B</td>   <td>2022-08-26</td>   <td>本发明公开一种基于图像高频信息的无参考图像质量评价方法,包括以下步骤：对待评价图像I使用低通滤波,得到二次退化图像I-(deg)；对原始待评价图像I和退化图像I-(deg)进行计算,分别得到图像的梯度图I-(grad)和退化图像的梯度图I-(grad,deg)；对梯度图I-(grad)中所有的像素值求平均值,得到第一结果；对梯度图I-(grad)进行分块操作,建立分块集合{B}；计算分块集合{B}中所有分块的像素值之和S-k；对集合C按照S的大小进行倒序排列,得到新的集合D；寻找集合D中的前L个元素和它们对应的分块B,找到在梯度图I-(deg,grad)中相同位置的分块B-(deg)；对L个分块对B,B-(deg)求结构相似度,求均值后取倒数,得到第二结果；别对第一结果和第二结果乘上合适的系数α和β后相加,得到代表图像质量的结果Quality(I)。</td>   <td>1.一种基于图像高频信息的无参考图像质量评价方法,其特征在于,包括以下步骤：S1：定义I为待评价的失真图像；定义I(i,j)表示I的中心坐标(i,j)的像素值；其中1≤i≤M,1≤j≤N,所述的M为I的宽度,N为I的高度；S2：对I进行低通滤波,得到二次退化图像I-(deg)；S3：对I使用梯度算子进行滤波,得到关于I的梯度信息图I-(grad),定义I-(grad)(i,j)表示I-(grad)的中心坐标(i,j)处的像素值；对I-(deg)使用梯度算子进行滤波,得到二次退化图像的梯度信息图I-(grad,deg),定义I-(deg,grad)(i,j)表示I-(deg,grad)的中心坐标(i,j)处的像素值；S4：定义G(i,j)为I-(grad)中所有像素值的平均值,得到代表图像全局结构信息质量的第一结果；S5：对I-(grad)进行分块操作,分块操作采取滑动窗口的方式,窗口从左上角开始,按行、按列的优先级顺序进行滑动,对应的分块记做B-(x,y),所述的x代表在行方向上为第x个分块,所述的y代表在列方向上为第y个分块,定义左上角的分块为B-(1,1),定义{B}为所有分块的集合；S6：定义S-k为{B}中所有分块的像素值之和,其中1≤k≤P,P为分块的数量；定义集合C＝{(B-k,S-k)},即每个分块与对应的像素值之和；S7：对集合{(B,S)}按照S的大小进行倒序排列,得到集合D；S8：选择集合D中的前L个元素,得到L个元素中对应每个元素中的分块B,寻找L个元素中对应每个元素在I-(deg,grad)中相同位置的分块B-(deg),得到L个分块对B,B-(deg)；S9：对分块对B,B-(deg)求结构相似度,得到结构相似度的求均值,再取倒数,所述的倒数定义为第二结果；是预设值S10：分别对第一结果和第二结果乘上系数α和β后相加,得到代表图像质量的结果Quality(I),所述的α是预设值；所述的β是预设值；S11：结合专家设定的判断规则,根据Quality(I)得到对图像质量的评价结果。</td>   <td>G06T7/00;G06T7/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         董健文;              刘斌;              张良明;              刘仲宇;              杨阳;              陈子豪;              戎利民;              刘青山;                   王远彬       </td>   <td>中山大学附属第三医院;普密特(成都)医疗科技有限公司</td>   <td>内窥镜微创手术空间成像高清图像同步精度重构方法</td>   <td>广东省</td>   <td>CN114943722A</td>   <td>2022-08-26</td>   <td>本发明公开了内窥镜微创手术空间成像高清图像同步精度重构方法,涉及图像处理技术领域。本发明包括如下步骤：步骤S1：建立图像重构的标准样本模型,对内窥镜图像进行预处理,获取内窥镜序列图像；步骤S2：对内窥镜摄像机进行标定,得到内窥镜摄像机的参数；步骤S3：得到摄像机的参数畸变情况,基于畸变情况进行特征矫正；步骤S4：矫正后代入参照项,即标准样本模型,利用计算机观察差异点,并进行二次特征修复完善；步骤S5：对图像特征点进行提取和匹配；步骤S6：进行三维摄影重建,并对模型进行可视化处理；步骤S7：完成重构。本发明通过从序列2D图像中重建出当前内窥镜视野下的三维结构,手术中观察可控性加强,参考价值高。</td>   <td>1.内窥镜微创手术空间成像高清图像同步精度重构方法,其特征在于,包括如下步骤：步骤S1：建立图像重构的标准样本模型,作为参照项,并对内窥镜图像进行预处理,获取内窥镜序列图像；步骤S2：利用摄像机非线性标定算法,对内窥镜摄像机进行标定,得到内窥镜摄像机的参数；步骤S3：基于上述步骤,得到摄像机的参数畸变情况,基于畸变情况进行特征矫正；步骤S4：矫正后代入参照项,即标准样本模型,利用计算机观察差异点,并进行二次特征修复完善；步骤S5：对内窥镜图像进行增强处理,并对图像特征点进行提取和匹配；步骤S6：基于上述匹配的图像特征点,进行三维摄影重建,并对模型进行可视化处理；步骤S7：完成内窥镜微创手术的空间成像高清图像同步精度重构。</td>   <td>G06T7/00;G06T7/246;G06T7/73;G06T7/80;G06T5/00;G06T5/20;A61B34/10;A61B34/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         侯卫生;                   刘恒光       </td>   <td>中山大学</td>   <td>一种融合深度学习和多点统计学的地质建模方法及装置</td>   <td>广东省</td>   <td>CN113963123B</td>   <td>2022-08-23</td>   <td>本发明公开了一种融合深度学习和多点统计学的地质建模方法及装置。本发明通过在三维模拟网格中将二维训练图像转换为三维训练图像,得到三维网格图像后,利用深度神经网络提取三维网格图像中的地质结构的全局空间特征来建立初始地质模型,并对初始地质模型进行序贯模拟和地层层序校验,利用多尺度EM迭代最终实现建立最优地质模型,能够融合深度学习和多点统计学进行地质建模,对具有各向异性、方向延展性、非平稳特征的地质体或地质结构进行合理的三维重构,有利于建立精细化的地质模型。</td>   <td>1.一种融合深度学习和多点统计学的地质建模方法,其特征在于,包括：将获取的二维训练图像导入三维模拟网格,得到在三维空间中表示的二维网格图像,并在所述三维模拟网格中将所述二维训练图像转换为三维训练图像,得到三维网格图像；所述在所述三维模拟网格中将所述二维训练图像转换为三维训练图像,得到三维网格图像,具体为：根据所述二维网格图像中的所有未赋值网格生成第一随机路径；通过第一移动窗口沿所述第一随机路径依次访问每一所述未赋值网格,统计在所述第一移动窗口内且在所述未赋值网格周边的所有已赋值网格的属性值,将出现次数最多的一属性值作为所述未赋值网格的属性值；在所述第一移动窗口遍历所有所述未赋值网格后,得到所述三维网格图像；分别从所述三维网格图像中提取空间模式数据和深度学习训练数据,建立空间模式数据库和深度学习训练数据集,并从所述二维网格图像中提取地层层序数据,建立地层层序数据库；根据所述三维网格图像构建深度神经网络,利用所述深度学习训练数据集训练所述深度神经网络,基于训练后的深度神经网络预测所述三维网格图像中待模拟网格的目标属性值的曲面网格体,并将所述曲面网格体中所有待模拟网格的属性值设置为所述目标属性值,建立初始地质模型；所述根据所述三维网格图像构建深度神经网络,利用所述深度学习训练数据集训练所述深度神经网络,具体为：分别根据所述三维网格图像的顶面高程数据和底面高程数据,构建顶面深度神经网络和底面深度神经网络,利用所述深度学习训练数据集训练所述顶面深度神经网络和所述底面深度神经网络；当累计训练次数达到预设训练次数或网络损失小于预设损失值时,停止训练所述顶面深度神经网络和所述底面深度神经网络,得到训练后的顶面深度神经网络和训练后的底面深度神经网络；所述基于训练后的深度神经网络预测所述三维网格图像中待模拟网格的目标属性值的曲面网格体,并将所述曲面网格体中所有待模拟网格的属性值设置为所述目标属性值,建立初始地质模型,具体为：将所述三维网格图像中的每一待模拟网格的坐标分别输入所述训练后的顶面深度神经网络和所述训练后的底面深度神经网络,得到所述目标属性值在所述待模拟网格的顶面高程数据和底面高程数据；根据所有所述待模拟网格的顶面高程数据和底面高程数据,得到顶面和底面之间的所述曲面网格体,将所述曲面网格体中的所有待模拟网格的属性值设置为所述目标属性值,建立所述初始地质模型；根据所述空间模式数据库对所述初始地质模型进行序贯模拟,得到中间地质模型,并根据所述地层层序数据库对所述中间地质模型进行地层层序校验,在校验成功时将所述中间地质模型作为地质模型,在校验失败时重新进行序贯模拟和地层层序校验直至得到所述地质模型；根据所述三维训练图像对所述地质模型进行多尺度迭代模拟,得到优化后的地质模型,并在当前尺度达到预设精度且累计迭代次数达到预设迭代次数时,将当前所述优化后的地质模型作为输出的最优地质模型。</td>   <td>G06T17/05;G06T17/20;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              肖鹏;              陈钰培;                   段铮昱       </td>   <td>中山大学中山眼科中心</td>   <td>基于注意力机制的半监督OCT图像去噪方法及装置</td>   <td>广东省</td>   <td>CN114936974A</td>   <td>2022-08-23</td>   <td>本公开描述了一种基于注意力机制的半监督OCT图像去噪方法及装置,该方法中,去噪网络包括第一网络和具有注意力机制的第二网络,在训练中,获取与第一网络对应的分别针对无标签的第一子集和有标签的第二子集的第一预测集和第二预测集、以及与第二网络对应的分别针对第一子集和第二子集的第三预测集和第四预测集,基于第一子集和第三预测集、以及基于第二子集和第二预测集分别确定第一网络的两个损失函数,基于第一子集和第一预测集、以及基于第二子集和第四预测集分别确定第二网络的两个损失函数,利用上述损失函数训练去噪网络以获得用于对OCT图像进行去噪的经训练网络。由此,能够利用少量标签数据实现对OCT图像进行去噪。</td>   <td>1.一种基于注意力机制的半监督OCT图像去噪方法,其特征在于,包括：获取待去噪OCT图像；确定经训练的去噪网络,所述去噪网络包括第一网络和具有注意力机制模块的第二网络,其中,获取样本集,所述样本集包括无标签数据的第一子集和有标签数据的第二子集,利用所述第一网络和所述第二网络分别对所述样本集进行预测,得到与所述第一网络对应的针对所述第一子集的第一预测集和针对所述第二子集的第二预测集、以及与所述第二网络对应的针对所述第一子集的第三预测集和针对所述第二子集的第四预测集,基于所述第一子集和所述第三预测集确定所述第一网络的第一损失函数,并基于所述第二子集和所述第二预测集确定所述第一网络的第二损失函数,基于所述第一子集和所述第一预测集确定所述第二网络的第三损失函数,并基于所述第二子集和所述第四预测集确定所述第二网络的第四损失函数,基于所述第一损失函数和所述第二损失函数训练所述第一网络,基于所述第三损失函数和所述第四损失函数训练所述第二网络,以获得所述经训练的去噪网络；并且将所述待去噪OCT图像输入所述经训练的去噪网络进行去噪以确定针对所述待去噪OCT图像的去噪图像。</td>   <td>G06T5/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张晓春;              陈振武;              周勇;              张枭勇;              胡海峰;              吴婷晖;              张书赫;                   邢宋隆       </td>   <td>深圳市城市交通规划设计研究中心股份有限公司;中山大学</td>   <td>一种反向链推理溯源方法、系统、计算机及存储介质</td>   <td>广东省</td>   <td>CN114462721B</td>   <td>2022-08-23</td>   <td>本发明提出一种反向链推理溯源方法、系统、计算机及存储介质,属于公共交通技术领域。首先,生成规则库和知识库；所述规则库中存储有反向链查询规则和反向链查询规则约束条件；所述知识库中存储有交通线路和路面数据；其次,输入线路问题,调用与线路问题对应的反向链查询规则,使用RETE算法找出模式下所有匹配的对象和规则；重复调用与线路问题对应的反向链查询规则直到所有反向链查询规则执行完毕；最后,所有反向链查询规则执行完后,通过Terminal节点将最终的结果进行输出。解决现有技术中存在的查找时间和信息链的时间长、无法直接查找多个直接影响问题的基础因素、交通线路问题溯源结果准确定和精确度低的技术问题。</td>   <td>1.一种反向链推理溯源方法,其特征在于,包括以下步骤：步骤1、生成规则库和知识库；所述规则库中存储有反向链查询规则和反向链查询规则约束条件；所述知识库中存储有交通线路和路面数据；所述交通线路和路面数据具体包括,所述交通线路具体包括线路ID；所述路面数据具体包括：公交线路效益健康度、公交线路速度健康度、公交线路断面车公里客流量、公交线路断面车公里客流量等级、公交线路客流量、公交线路客流量等级、公交线路断面运行速度、公交线路断面运行速度等级；所述反向链查询规则具体包括,查询规则01反向规则、查询规则02反向规则、查询规则03反向规则、查询规则04反向规则和查询规则05反向规则；所述查询规则01反向规则对应查询交通路面出现“交通路面状况一般”的线路情况；所述查询规则02反向规则对应查询交通路面出现“交通路面存在操作问题”的线路情况；所述查询规则03反向规则对应查询交通路面出现“交通路面存在线路规划问题”的线路情况；所述查询规则04反向规则对应查询交通路面出现“交通路面存在线路拥堵问题”的线路情况；所述查询规则05反向规则对应查询交通路面出现“交通路面存在其他问题”的线路情况；补集规则,若当前线路问题无法匹配某一规则时,使线路在其他规则中进行查询匹配,确保所有的线路问题匹配一次；所述反向链查询规则约束条件具体包括：查询规则01反向规则的查询约束条件是线路效益健康度为“中”且线路速度健康度为“高”或者“中”,再分别由效益健康度和速度健康度对应的链式规则查询线路ID信息,公交线路断面车公里客流量、公交线路断面客流量、线路拥挤程度、平均断面速度的等级信息,以及具体的数值,确定出现问题的具体线路情况和涉及的实体因素；查询规则02反向规则的查询约束条件是线路效益健康度为“低”且线路速度健康度为“高”,根据规则库中判断效益健康度和速度健康度等级的规则找到出现该问题的具体线路信息；查询规则03反向规则的查询约束条件是线路效益健康度为“低”且线路速度健康度为“高”或“中”,由于对线路速度健康度的查询条件为多个,使用模糊查询的方式,最终找到导致线路问题的基本实体对象因素信息；查询规则04反向规则的查询约束条件是线路效益健康度为“高”且线路速度健康度为“低”,则根据规则给出的约束条件找到对应线路的ID、公交线路断面车公里客流量、公交线路断面客流量、线路拥挤程度、平均断面速度信息,找到觉得健康度等级的关键因素,输出涉及的相关实体对象数值；查询规则05反向规则的查询约束条件是除了“好”状态之外的其他情况；步骤2、输入线路问题,调用与线路问题对应的反向链查询规则,使用RETE算法找出模式下所有匹配的对象和规则；具体包括以下步骤：步骤21、根据线路问题创建root节点,作为推理网络的数据入口；步骤22、根据线路问题调用对应反向链查询规则,从反向链查询规则里取出模式；步骤221、检查模式中的数据参数类型,如果有新的类型出现,则增加对应类型的节点；步骤222、检查模式中对应的Alpha节点是否存在,如果存在则记录下该节点的位置信息,反之则将模式作为一个Alpha节点加入到网络中,并且根据节点建立Alpha内存表；步骤223、重复步骤222直至处理完所有模式；步骤224、组合Beta节点将Beta的两个输入节点分别定义为Alpha节点1和Alpha节点2,然后与上一级Beta通过将其输入节点Alpha进行连接,将两个父节点的内存表相连变成新的内存表；步骤225、重复步骤224直到所有Beta节点都处理完成；步骤226、将规则动作Then部分封装成最后节点,记作Beta(n)；步骤3、重复步骤2,直到所有反向链查询规则执行完毕；步骤4、当所有反向链查询规则执行完后,会通过Terminal节点将最终的结果进行输出。</td>   <td>G06Q10/04;G06Q50/30;G06F16/901;G06F16/903;G06N5/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苗建明;              张文睿;              孙兴宇;              邓侃侃;              仝懿聪;              王燕云;              刘文超;              郑若晗;              龚喜;              彭超;                   刘涛       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种水下图像复原方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN114926353A</td>   <td>2022-08-19</td>   <td>本发明公开了一种水下图像复原方法、装置、设备及存储介质,通过获取原始水下图像中图块的像素值,得到背景光值；同时构建场景深度预估模型,获取场景深度,并基于场景深度对原始水下图像的后向散射分量预估值、后向散射分量值、直接分量透射率等相关参数进行预估,并将得到的背景光值、后向散射分量值和直接分量透射率代入构建的物理成像模型中进行反演退化,得到第一水下复原图像。与现有技术相比,本发明的技术方案通过获取水下图像的场景深度,对水下图像的相关参数进行预估,并对构建物理成像模型的反演退化,实现水下图像进行复原处理,减少了对人工的依赖性,提高对水下图像复原的效率和精度。</td>   <td>1.一种水下图像复原方法,其特征在于,包括：获取原始水下图像,对所述原始水下图像进行图块划分,并基于划分出的图块的像素值,得到所述原始水下图像的背景光值；构建场景深度预估模型,以使所述场景深度预估模型对所述原始水下图像进行场景深度预估,输出场景深度；对所述场景深度所对应的场景深度图进行像素点筛选,根据所筛选出的各像素点对应的通道值,计算后向散射分量预估值,并根据所述后向散射分量预估值、所述场景深度和所述背景光值,计算后向散射分量值；获取所述原始水下图像中标准化残余能量比的中值,将所述中值作为直接分量透射率的衰减参数,并将所述衰减参数和所述场景深度输入到预设的透射率公式中,得到直接分量透射率；构建物理成像模型,将所述背景光值、所述后向散射分量值和所述直接分量透射率代入所述物理成像模型中,并对所述物理成像模型进行反演退化,得到第一水下复原图像。</td>   <td>G06T5/00;G06T5/50;G06T7/194;G06T7/90;G06T7/536</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   熊少堂       </td>   <td>中山大学</td>   <td>一种水文气象集合预报偏差及可靠度的判别方法及系统</td>   <td>广东省</td>   <td>CN114912803A</td>   <td>2022-08-16</td>   <td>本发明涉及水文预报分析技术领域,提出一种水文气象集合预报偏差及可靠度的判别方法及系统,其中包括以下步骤：获取水文气象集合预报降水数据及对应的观测降水数据；对预报降水数据及对应的观测降水数据进行预处理,得到目标空间区域内且时间维度对齐的预报降水数据和观测降水数据；基于自举法对经过预处理的预报降水数据和观测降水数据进行均值齐性检验：若检验判断二者均值相等,则预报无系统偏差；否则预报存在系统偏差,判断为低可靠度预报；对于无系统偏差的预报,基于自举法对所述预报降水数据和观测降水数据进行方差齐性检验：若检验判断二者方差相等,则判断为高可靠度预报；否则判断为低可靠度预报。</td>   <td>1.一种水文气象集合预报偏差及可靠度的判别方法,其特征在于,包括以下步骤：S1、获取水文气象集合预报降水数据及对应的观测降水数据；S2、对预报降水数据及对应的观测降水数据进行预处理,得到目标空间区域内且时间维度对齐的预报降水数据和观测降水数据；S3、基于自举法对经过预处理的预报降水数据和观测降水数据进行均值齐性检验：若二者均值相等,则判断预报无系统偏差；否则判断预报存在系统偏差；对于无系统偏差的预报,基于自举法对所述预报降水数据和观测降水数据进行方差齐性检验：若检验判断二者方差相等,则判断为高可靠度预报；否则判断为低可靠度预报。</td>   <td>G06Q10/06;G06Q50/26;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏航;              周凡;              刘海亮;              林格;                   汤武惊       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>图像处理方法、装置、终端设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN114648468B</td>   <td>2022-08-16</td>   <td>本申请适用于智能监控技术领域,提供了一种图像处理方法、装置、终端设备及计算机可读存储介质,其中,图像处理方法包括：对待处理图像进行上采样操作,得到待处理图像的上采样图像；通过预设的残差网络对待处理图像的特征图进行处理,得到待处理图像的残差图像；残差网络包括n个局部残差提取块,n个局部残差提取块之间采用稠密连接方式相连；通过预设的残差增强网络对特征图进行处理,得到待处理图像的残差增强细节图像；残差增强网络包括n个卷积块,n个卷积块之间采用稠密连接方式连接；根据上采样图像、残差图像及残差增强细节图像,得到待处理图像的目标图像；目标图像的分辨率高于待处理图像的分辨率,从而提高了待处理图像的分辨率。</td>   <td>1.一种图像处理方法,其特征在于,包括：对待处理图像进行上采样操作,得到所述待处理图像的上采样图像；通过预设的残差网络对所述待处理图像的特征图进行处理,得到所述待处理图像的残差图像；所述残差网络包括n个局部残差提取块,所述n个局部残差提取块之间采用稠密连接方式相连,n为大于1的整数；通过预设的残差增强网络对所述特征图和来自所述残差网络的残差信息进行处理,得到所述待处理图像的残差增强细节图像；所述残差增强网络包括n个卷积块,所述n个卷积块之间采用稠密连接方式连接,且第i个所述卷积块与第i-1个所述局部残差提取块之间采用稠密连接方式连接,1&lt;i≤n；根据所述上采样图像、所述残差图像及所述残差增强细节图像,得到所述待处理图像的目标图像；所述目标图像的分辨率高于所述待处理图像的分辨率；所述残差增强网络还包括第二转置卷积层,所述第二转置卷积层连接在第n个所述卷积块之后；所述通过预设的残差增强网络对所述特征图和来自所述残差网络的残差信息进行处理,得到所述待处理图像的残差增强细节图像,包括：通过第1个所述卷积块对所述特征图进行卷积操作,得到第一特征信息,并输出所述第一特征信息；通过第2至第n个所述卷积块对所述特征图进行卷积操作,得到第一特征信息,并对来自前序的所有卷积块的特征信息进行卷积操作,得到第二特征信息,以及对来自局部残差提取块的残差信息进行卷积操作,得到第三特征信息,并输出所述第一特征信息、所述第二特征信息及所述第三特征信息；通过所述第二转置卷积层对来自第n个所述卷积块的所述第一特征信息、所述第二特征信息及所述第三特征信息进行转置卷积操作,得到所述残差增强细节图像。</td>   <td>G06T5/00;G06T3/40;G06N3/04;G06V10/44;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>              李永宝       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于深度神经网络的三维在体剂量重建方法及装置</td>   <td>广东省</td>   <td>CN114913261A</td>   <td>2022-08-16</td>   <td>本发明公开了一种基于深度神经网络的三维在体剂量重建方法及装置,所述方法包括：基于电子射野影像装置(EPID)采集患者的单帧或单野射野灰度图,并对所述射野灰度图进行矩阵校正得到二维单帧或单野透射剂量图；基于射野角度和反投影算法,将所述二维单帧或单野透射剂量图转化为三维单帧或单野初始剂量图；获取患者的三维结构图,将所述三维单帧或单野初始剂量图和所述三维结构图输入至经过模型训练的深度神经网络进行预测,得到三维单帧或单野剂量分布图。本发明基于矩阵校正,反投影转化和网络预测三个模块,可根据实测射野灰度图快速精准重建出患者的三维在体剂量。</td>   <td>1.一种基于深度神经网络的三维在体剂量重建方法,其特征在于,所述方法包括：基于EPID采集患者的单帧或单野射野灰度图,并对所述射野灰度图进行矩阵校正得到二维单帧或单野透射剂量图；基于射野角度和反投影算法,将所述二维单帧或单野透射剂量图转化为三维单帧或单野初始剂量图；获取患者的三维结构图,将所述三维单帧或单野初始剂量图和所述三维结构图输入至经过模型训练的深度神经网络进行预测,得到三维单帧或单野剂量分布图,其中,所述三维结构图包括：电子密度图或质量密度图。</td>   <td>G06T11/00;G06T15/06;G06N3/04;G06N3/08;A61N5/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈川;              吴哲彬;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于张量图卷积网络的节点分类方法及系统</td>   <td>广东省</td>   <td>CN114912529A</td>   <td>2022-08-16</td>   <td>本发明提供了一种基于张量图卷积网络的节点分类方法及系统,方法包括：根据图数据生成多个不同视角的单视角增强图,根据图数据和得到的多个单视角增强图进行张量化操作得到一个多视角增强图；其中,图数据包括图的邻接矩阵和特征矩阵,特征矩阵由图中所有节点的特征向量构成,多视角增强图包括邻接张量和特征张量,邻接张量的每个前切面表示对应视角的单视角增强图的邻接矩阵,特征张量的每个前切面表示对应视角的单视角增强图的特征矩阵；将多视角增强图的邻接张量和特征张量输入到训练好的张量图卷积网络模型中,输出图数据中各节点的预测分类结果。本发明从图数据预处理和模型架构提高张量图卷积网络模型的鲁棒性,遭受对抗攻击时仍较稳定。</td>   <td>1.一种基于张量图卷积网络的节点分类方法,其特征在于,包括：根据图数据生成多个不同视角的单视角增强图,根据图数据和得到的多个单视角增强图进行张量化操作得到一个多视角增强图；其中,所述图数据包括图的邻接矩阵和特征矩阵,所述特征矩阵由图中所有节点的特征向量构成,所述多视角增强图包括邻接张量和特征张量,所述邻接张量的每个前切面表示对应视角的单视角增强图的邻接矩阵,所述特征张量的每个前切面表示对应视角的单视角增强图的特征矩阵；将所述多视角增强图的邻接张量和特征张量输入到训练好的张量图卷积网络模型中,输出所述图数据中各节点的预测分类结果。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卞静;              卓绍烜;                   李焱       </td>   <td>中山大学</td>   <td>一种区块链反诈骗分析方法及系统</td>   <td>广东省</td>   <td>CN114912927A</td>   <td>2022-08-16</td>   <td>本发明公开了一种区块链反诈骗分析方法及系统,所述的方法包括步骤如下：将区块链交易数据进行预处理为具有图结构的交易图；对交易图进行整体卷积操作,得到交易图的整体结构信息,将交易图的整体结构信息输入图卷积神经网络进行嵌入学习,得到整体结构信息的节点嵌入；对交易图进行局部采样操作,得到交易图的局部结构信息,将交易图的局部结构信息输入图卷积神经网络进行嵌入学习,得到局部结构信息的节点嵌入；将整体结构信息的节点嵌入、局部结构信息的节点嵌入拼接融合后输入二分类多层神经网络进行识别,最终实现异常交易节点的识别。</td>   <td>1.一种区块链反诈骗分析方法,其特征在于：所述的方法包括步骤如下：将区块链交易数据进行预处理为具有图结构的交易图；对交易图进行整体卷积操作,得到交易图的整体结构信息,将交易图的整体结构信息输入图卷积神经网络进行嵌入学习,得到整体结构信息的节点嵌入；对交易图进行局部采样操作,得到交易图的局部结构信息,将交易图的局部结构信息输入图卷积神经网络进行嵌入学习,得到局部结构信息的节点嵌入；将整体结构信息的节点嵌入、局部结构信息的节点嵌入拼接融合后输入二分类多层神经网络进行识别,最终实现异常交易节点的识别。</td>   <td>G06Q30/00;G06N3/08;G06N3/04;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              林格;              苏航;                   汤武惊       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>图像的去雾方法、装置、终端设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN114648467B</td>   <td>2022-08-16</td>   <td>本申请适用于智能监控技术领域,提供了一种图像的去雾方法、装置、终端设备及计算机可读存储介质,其中,图像的去雾方法包括：采用暗通道先验去雾算法对待处理图像进行处理,得到粗糙透射率图；确定所述待处理图像对应的散射大气光分量；采用预先训练得到的透射图滤波网络模型对所述粗糙透射率图进行滤波处理,得到精细化透射率图；所述透射图滤波网络模型是采用卷积神经网络训练得到的,所述精细化透射率图满足透射率图的局部平滑性约束；根据所述待处理图像、所述散射大气光分量以及所述精细化透射率图,得到所述待处理图像的去雾图像,从而提升了图像的去雾效果,提高了图像质量。</td>   <td>1.一种图像的去雾方法,其特征在于,包括：采用暗通道先验去雾算法对待处理图像进行处理,得到粗糙透射率图；确定所述待处理图像对应的散射大气光分量；采用预先训练得到的透射图滤波网络模型对所述粗糙透射率图进行滤波处理,得到精细化透射率图；所述透射图滤波网络模型是采用卷积神经网络训练得到的,所述精细化透射率图满足透射率图的局部平滑性约束；根据所述待处理图像、所述散射大气光分量以及所述精细化透射率图,得到所述待处理图像的去雾图像；所述透射图滤波网络模型包括编码结构和解码结构；所述采用预先训练得到的透射图滤波网络模型对所述粗糙透射率图进行滤波处理,得到精细化透射率图,包括：通过所述编码结构对所述粗糙透射率图进行特征提取,得到所述粗糙透射率图对应的空间特征图；通过所述解码结构对所述空间特征图进行特征还原,得到所述精细化透射率图；所述编码结构包括N级残差注意力层,每一级所述残差注意力层后设置有一个下采样层；所述通过所述编码结构对所述粗糙透射率图进行特征提取,得到所述粗糙透射率图对应的空间特征图,包括：在每一级所述残差注意力层中,采用M个第一预设卷积核对本级残差注意力层的输入特征进行卷积操作,得到M个预处理特征图；第一级残差注意力层的输入特征为所述粗糙透射率图；在通道维度上对所述M个预处理特征图进行特征提取,得到目标特征向量,并将所述M个预处理特征图与所述目标特征向量相乘,得到所述输入特征对应的通道注意力图；所述目标特征向量为1×1×M的向量；在特征图维度上对所述通道注意力图进行池化处理,得到空间注意力图；所述空间注意力图的尺寸与所述预处理特征图的尺寸相同；采用第四预设卷积核对所述空间注意力图进行卷积操作,并将卷积操作后的所述空间注意力图与所述通道注意力图相乘,得到待输出特征；将所述输入特征与所述待输出特征相加,得到所述输入特征对应的残差注意力图,并将所述残差注意力图输出至本级残差注意力层后的下采样层；在每个所述下采样层对接收到的残差注意力图进行池化操作,并输出池化操作后的所述残差注意力图至下一级残差注意力层；将第N级残差注意力层后的下采样层输出的池化操作后的所述残差注意力图,确定为所述粗糙透射率图对应的空间特征图。</td>   <td>G06T5/00;G06T5/20;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;                   邓珏惠       </td>   <td>中山大学</td>   <td>一种自适应扩增类别的车款细粒度识别方法及系统</td>   <td>广东省</td>   <td>CN114913001A</td>   <td>2022-08-16</td>   <td>本发明公开了一种自适应扩增类别的车款细粒度识别方法及系统,方法包括：获取待训练的新类别数据和旧类别数据；将旧类别数据输入到细粒度车款分类网络中进行训练,输出旧类别数据的特征向量；并将新类别数据输入到训练好的细粒度车款分类网络中进行前向计算,输出新类别数据的特征向量；通过可扩增车款识别模块对所述特征向量进行基于类别中心的自适应类别扩增,输出所述新类别数据和旧类别数据对应的类别中心,完成车款识别模型的训练；将待识别数据输入训练好的所述车款识别模型,计算所述类别中心与待识别数据之间的匹配度,识别得到所述待识别数据对应的车款信息,本发明的识别准确率高且训练成本低,可广泛应用于人工智能技术领域。</td>   <td>1.一种自适应扩增类别的车款细粒度识别方法,其特征在于,包括：获取待训练的新类别数据和旧类别数据；将旧类别数据输入到细粒度车款分类网络中进行训练,输出旧类别数据的特征向量；并将新类别数据输入到训练好的细粒度车款分类网络中进行前向计算,输出新类别数据的特征向量；通过可扩增车款识别模块对所述旧类别数据和所述新类别数据的特征向量进行基于类别中心的自适应类别扩增,输出所述新类别数据和旧类别数据对应的类别中心,完成车款识别模型的训练；将待识别数据输入训练好的所述车款识别模型,计算所述类别中心与待识别数据之间的匹配度,识别得到所述待识别数据对应的车款信息；其中,所述细粒度车款分类网络包括距离度量匹配分类基础网络、类域划分增强模块和车辆特征增强模块。</td>   <td>G06Q40/02;G06K9/62;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢志;              周昊;                   何尧       </td>   <td>中山大学中山眼科中心</td>   <td>婴幼儿眼底视网膜全景影像生成采集反馈方法及系统</td>   <td>广东省</td>   <td>CN114897678A</td>   <td>2022-08-12</td>   <td>本发明公开了一种婴幼儿眼底视网膜全景影像生成采集反馈方法及系统,利用深度学习技术分别实现了配准模型和融合模型的建模设计和训练流程。通过实现影像文件监测,多图像持续配准,多图像持续融合以及全景影像图谱提示等模块功能,设计了一种婴幼儿眼底视网膜全景影像生成和反馈系统,能够在使用者采集数据过程中实时显示已采集数据的拼接图,提示已采集影像范围、未采集区域以及生成并显示视网膜全景影像。</td>   <td>1.一种婴幼儿眼底视网膜全景影像生成采集反馈方法,其特征在于,包括以下步骤：S1：采集婴幼儿眼底影像并将采集到的婴幼儿眼底影像送入至保存路径中；S2：自动监测保存路径中的是否有新的婴幼儿眼底影像,当有新的婴幼儿眼底影像时,将新的婴幼儿眼底影像送入至缓冲队列；S3：判断缓冲队列中的队列长度是否大于两个婴幼儿眼底影像,小于两个婴幼儿眼底影像时,继续等待；不小于两个婴幼儿眼底影像的话开始进行拼接和融合；S4：将缓冲队列中的两个婴幼儿眼底影像分别经过预训练的配准模型和融合模型得到拼接图；S5：监测拼接图中的视盘,以视盘为中心,将拼接图更新至预先准备的视网膜全景图谱图上；S6：根据所述视网膜全景图谱图和拼接图盘评估当前采集的影像范围和质量,决定是否继续采集数据,当确认采集完毕时,执行步骤S8；若需要继续采集数据,执行步骤S7：S7：将缓冲队列中新增的婴幼儿眼底影像与拼接图分别经过预训练的配准模型和融合模型得到新的拼接图,返回步骤S5；S8：输出当前的拼接图作为全景视网膜影像结果。</td>   <td>G06T3/40;G06T5/50;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;              周凡;                   林谋广       </td>   <td>中山大学</td>   <td>基于三维生成对抗网络的胸腔CT图像伪影去除方法与系统</td>   <td>广东省</td>   <td>CN114897726A</td>   <td>2022-08-12</td>   <td>本发明公开了一种基于三维生成对抗网络的胸腔CT图像伪影去除方法与系统。首先构建三维生成对抗网络,包括V-Net结构的生成器G,三维卷积层构成的二分类卷积神经网络的判别器D,之后构建生成损失函数和对抗性损失函数并交替训练生成器G和判别器D,形成训练好的生成对抗网络；最后用户输入待处理的伪影图像到训练好的三维生成对抗网络中,输出去除伪影的CT图像。本发明针对于胸腔CT图像所有切片组合起来是一组完整的三维立体图像的特点,将一次CT扫描所得的所有CT图像按顺序组合成三维立体图像,作为一个整体输入本发明所构建的三维生成对抗网络中,相比于对每一张CT切片图像单独计算,大大减少了工作量和计算量,效率更高。</td>   <td>1.一种基于三维生成对抗网络的胸腔CT图像伪影去除方法,其特征在于,所述方法包括：收集胸腔CT图像数据集,将收集到的无伪影图像A采用仿真软件仿真出仿真伪影图像B,无伪影图像A和仿真伪影图像B配对构成训练集,并进行数据预处理；构建三维生成对抗网络中的生成器G,该生成器G以V-Net的结构进行构建,由编码器和解码器组成,作用是输入所述仿真伪影图像B生成去除伪影图像O；构建三维生成对抗网络中的判别器D,该判别器D是三维卷积层构成的二分类卷积神经网络,作用是判断输入的所述去除伪影图像O是真实图像还是生成图像,辅助所述生成器G优化从而使所述生成器G能够生成更逼真的去除伪影图像；构建生成损失函数和对抗性损失函数,以促进所述生成器G和所述判别器D在训练过程中快速优化；利用所述损失函数和对抗性损失函数交替训练所述生成器G和所述判别器D,提高所述生成器G生成更逼真图像的能力以及所述判别器D正确判断真假图像的能力,最终形成训练好的生成对抗网络；用户输入待处理的伪影图像到所述训练好的生成对抗网络中,输出去除伪影的CT图像。</td>   <td>G06T5/00;G06T17/00;G06T3/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国玉;              周永坤;              王伟;              饶彬;              王涛;              周颖;              邹小海;                   徐峰       </td>   <td>中山大学</td>   <td>基于电磁频谱数据挖掘的社会性群体行为识别方法、计算机装置和存储介质</td>   <td>广东省</td>   <td>CN113792763B</td>   <td>2022-08-12</td>   <td>本发明公开了一种基于电磁频谱数据挖掘的社会性群体行为识别方法、计算机装置和存储介质,社会性群体行为识别方法包括：获取频段占用度和社会性群体行为的特征数据,从特征数据中提取出最优特征子集,确定频段占用度与最优特征子集之间的相关关系,对最优特征子集进行时变行为分析,获得第一时间序列,根据相关关系以及第一时间序列,构建社会性群体行为预测模型进行社会性群体行为识别等步骤。本发明只需进行物理层面的分析即可完成识别,并且监测过程不会对通信过程以及无线电环境造成干扰,在合法进行的前提下无需经过通信运营商或者用户,不会有侵犯隐私的风险,实施难度小。本发明广泛应用于数据挖掘技术领域。</td>   <td>1.一种基于电磁频谱数据挖掘的社会性群体行为识别方法,其特征在于,包括：获取第一区域中进行的无线电通信的频段占用度；获取所述第一区域中社会性群体行为的特征数据；从所述特征数据中提取出最优特征子集；通过地理加权回归模型确定所述频段占用度与所述最优特征子集之间的相关关系；通过时间序列模型对所述最优特征子集进行时变行为分析,获得第一时间序列；根据所述频段占用度与所述最优特征子集之间的相关关系以及所述第一时间序列,使用深度学习模型构建社会性群体行为预测模型；使用所述社会性群体行为预测模型进行社会性群体行为识别；所述获取所述第一区域中社会性群体行为的特征数据,包括：测量所述第一区域中的人群活动轨迹数据；对所述人群活动轨迹数据进行相关性分析、因子分析或聚类分析,所得结果作为所述特征数据。</td>   <td>G06K9/62;G06N3/08;G06F17/18;H04W4/029</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伍哲舜;              吴晓萍;                   龙云亮       </td>   <td>中山大学</td>   <td>基于在线伪标签半监督学习与个性化联邦学习的室内定位方法</td>   <td>广东省</td>   <td>CN114897063A</td>   <td>2022-08-12</td>   <td>本发明涉及室内定位技术领域,公开了一种基于在线伪标签半监督学习与个性化联邦学习的室内定位方法,包括以下步骤：S1.用户构建本地数据集,服务器构造云端数据集；S2.服务器设置有机器学习模型,并且服务器分别给各个用户发放机器学习模型,将位于用户端的机器学习模型称为本地模型,将位于用户端的机器学习模型称为本地模型；S3.用户通过本地数据集中带有标签的数据训练本地模型,得到初始本地模型；S4.服务器通过云端数据集中带有标签的数据训练全局模型,得到初始全局模型；S5.通过联邦学习得到训练后的本地模型和更新后的全局模型；S6,用户根据训练后的本地模型和更新后的全局模型,通过混合专家模型进行个性化定位。本发明解决了现有技术中忽视本地数据高度动态和定位需求差异,无法进行个性化定位的问题,并具有高效率,高精度的特点。</td>   <td>1.一种基于在线伪标签半监督学习与个性化联邦学习的室内定位方法,其特征在于：包括以下步骤：S1.用户构建本地数据集,服务器构造云端数据集；S2.服务器设置有机器学习模型,并且服务器分别给各个用户发放机器学习模型,将位于用户端的机器学习模型称为本地模型,将位于用户端的机器学习模型称为本地模型；S3.用户通过本地数据集中带有标签的数据训练本地模型,得到初始本地模型；S4.服务器通过云端数据集中带有标签的数据训练全局模型,得到初始全局模型；S5.通过联邦学习得到训练后的本地模型和更新后的全局模型；S6.用户根据训练后的本地模型和更新后的全局模型,通过混合专家模型进行个性化定位。</td>   <td>G06K9/62;G06N3/04;G06N20/00;H04W4/02;H04W4/021;H04W4/33;H04W64/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韦献革;                   赵婉滢       </td>   <td>中山大学</td>   <td>一种水资源环境承载力评价与预警指标体系构建方法</td>   <td>广东省</td>   <td>CN114897319A</td>   <td>2022-08-12</td>   <td>本发明公开了一种水资源环境承载力评价与预警指标体系构建方法,包括：基于频度分析方法,根据文献构建指标库；根据预设规则对指标库中的指标进行筛选,得到候选指标；将候选指标进行融合,得到融合信息；根据候选指标和融合信息对水管理过程进行分析并选择指标进行表征,得到最终指标；分析最终指标的因果关系并基于逻辑框架进行指标分类,得到指标体系。通过使用本发明,能够更加科学的完成体系构建,满足水域空间管理与生态文明建设考核实际需求。本发明作为一种水资源环境承载力评价与预警指标体系构建方法,可广泛应用于环境科学领域。</td>   <td>1.一种水资源环境承载力评价与预警指标体系构建方法,其特征在于,包括以下步骤：基于频度分析方法,根据文献构建指标库；根据预设规则对指标库中的指标进行筛选,得到候选指标；将候选指标进行融合,得到融合信息；根据候选指标和融合信息对水管理过程进行分析并选择指标进行表征,得到最终指标；分析最终指标的因果关系并基于逻辑框架进行指标分类,得到指标体系。</td>   <td>G06Q10/06;G06K9/62;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;                   杨冰       </td>   <td>中山大学</td>   <td>旱涝事件与人口迁移的数据分析方法、装置及相关设备</td>   <td>广东省</td>   <td>CN114897652A</td>   <td>2022-08-12</td>   <td>本申请公开了一种旱涝事件与人口迁移的数据分析方法、装置及相关设备,包括：生成各目标区域的严重干旱事件时间序列数据、严重洪涝事件时间序列数据以及人口分布时间序列数据；根据各时间序列数据：基于重心分析模型,计算得到重心分布数据；基于Mann-Kendall趋势分析法,计算得到关系趋势数据；基于皮尔逊相关系数法,计算得到相关性分析数据；基于局部多项式回归拟合法,计算得到时间演变数据；其中,所述重心分布数据、关系趋势数据、所述相关性分析数据以及所述时间演变数据用于量化旱涝事件与人口迁移的关系。本申请定量描述了洪涝事件与人口迁移之间的关系,以便于从社会人文的角度交叉印证水文历史序列背景下,对严重旱涝事件的重建和识别。</td>   <td>1.一种旱涝事件与人口迁移的数据分析方法,其特征在于,包括：获取各目标区域在预设时间范围内的气候数据及人口数据,根据所述气候数据生成各目标区域的严重干旱事件时间序列数据、严重洪涝事件时间序列数据,以及根据所述人口数据生成人口分布时间序列数据,其中,严重干旱事件及严重洪涝事件为根据帕默尔干旱指数scPDSI的干湿等级标准进行划分得到；根据各目标区域的严重干旱事件时间序列数据、严重洪涝事件时间序列数据及人口分布时间序列数据：基于重心分析模型,分别计算各目标区域在各目标时段的严重干旱事件的重心、严重洪涝事件的重心及人口分布的重心,得到重心分布数据；基于Mann-Kendall趋势分析法,分别计算各目标区域在各目标时段的严重干旱事件的正态统计变量、严重洪涝事件的正态统计变量及人口分布的正态统计变量,得到关系趋势数据；基于皮尔逊相关系数法,计算各目标区域在预设的时段中,人口分布数据分别与scPDSI均值、严重干旱事件面积占比、严重洪涝事件面积占比的相关性,得到相关性分析数据；基于局部多项式回归拟合法,对各目标区域的人口分布时间序列数据进行拟合计算,得到人口分布时间连续数据,并由所述人口分布时间连续数据、严重干旱事件时间序列数据、严重洪涝事件时间序列数据生成时间演变数据；其中,所述重心分布数据、关系趋势数据、所述相关性分析数据以及所述时间演变数据用于量化旱涝事件与人口迁移的关系。</td>   <td>G06Q50/26;G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              刘畅;                   吴贺丰       </td>   <td>中山大学</td>   <td>融合卷积网络特征和判别式相关滤波器的目标跟踪方法</td>   <td>广东省</td>   <td>CN108470355B</td>   <td>2022-08-09</td>   <td>本发明公开了一种融合卷积网络特征和判别式相关滤波器的目标跟踪方法。建立了一个端到端的轻量级网络体系结构,通过学习连续帧中丰富的流信息来训练卷积特征,改善特征表示和跟踪精度。将相关滤波跟踪组件构造为网络中的特殊层次跟踪单个图像块,在跟踪过程中,同时跟踪目标块和多个背景块,通过感知目标与周围背景块的结构关系,对目标及其周围环境辨识度高的部分建立模型,通过峰值旁瓣比和置信图峰值关系度量目标跟踪效果,在发生大面积遮挡、目标外形极度形变、光照剧烈变化等跟踪难度大的情况下,自动利用判别的背景部分进行定位。</td>   <td>1.一种融合卷积网络特征和判别式相关滤波器的目标跟踪方法,其特征在于包括以下步骤：步骤A,在离线阶段,使用视频中连续帧中的图像对训练跟踪特征神经网络；具体的,使用视频序列连续帧中丰富的流信息来训练卷积特征神经网络,卷积层由VGG的conv1组成,去除所有池层,强制输出为32个通道,对于每个训练视频,选择最近10帧内的一对图像作为一对训练对象,并且将成对的图像剪裁为125×125大小的包含跟踪对象的块传输给网络；使用权值衰减设置为ξ,学习率为1e-5的随机梯度下降法训练Siamese Network,对于每个跟踪块的相关滤波层,固定在线训练时的学习率为β,正则化系数设置为λ,在线训练和离线跟踪时的高斯空间的带宽均设置为θ；步骤B,初始化跟踪目标块和背景块集合的中心坐标、矩形框宽度和高度属性；步骤C,对图像进行surf特征点检测,找出其中最具辨别性的背景块；步骤D,按顺序将特征点集中与目标块没有交集的surf特征点块加入背景区域块集合中；步骤E,重复步骤C和步骤D,直到满足背景块数量达到需求；步骤F,对于目标块训练和背景块集合中的每个背景块训练一个分辨式相关滤波器；步骤G,构建相对目标中心的运动模型；具体的,对于在第t帧的每个背景区域块,设定它的运动状态为其中δ表示该点相对目标中心的位移向量；v为该点运动速度,目标特征点的运动状态使用进行预测,其中β t ～ N(0, β -(0 )) 是均值为0的高斯噪声,背景特征的运动状态通进行预测,其中β-t～(0,β-0)；步骤H,读取下一帧图像；步骤I,同时跟踪目标块和背景块,计算他们的跟踪结果置信图；步骤J,通过分析置信图的特征判断目标图像块和背景图像块是否跟丢；步骤K,如果目标跟踪失败,则使用背景块集合推测目标位置；步骤L,如果目标没跟丢,使用跟踪置信图确定目标位置；步骤M,如果有背景块跟踪失败,则使用辨别性更强的新的背景块替换跟踪失败的块；步骤N,根据定位到的目标点更新网络；步骤O,重复执行步骤C至步骤H,直至处理完所有图像序列。</td>   <td>G06T7/246;G06T7/277;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨钦泰;              韩蓝青;              任勇;              吴庆武;              陈健宁;              邓慧仪;              孙悦奇;              袁联雄;              王玮豪;              郑瑞;              洪海裕;              孔维封;              黄雪琨;              袁田;              邱惠军;              李权;              黄桂芳;              叶俊杰;                   王伦基       </td>   <td>中山大学附属第三医院;清华珠三角研究院</td>   <td>病理图片的处理方法</td>   <td>广东省</td>   <td>CN110717908B</td>   <td>2022-08-09</td>   <td>本发明公开了病理图片的处理方法,包括图像采集：1)对病理玻片进行完整扫描获取到数字化病理图像；2)将数字化病理图像勾画出病变区域,并将勾画区域的位置生成xml格式的文件进行保存；3)生成一个与数字化病理图像的分辨率一致的大掩膜图像；图像处理：设置切图的图片分辨率,并对数字化病理图像和大掩膜图像切图,得到一一对应的小病理图和小掩膜图的位置；计算每个小掩膜图的像素平均值P,并设定阈值G,只保存P≥G所对应的小病理图；若P＜G,所对应的小病理图则丢弃,其中P,G取值范围均是0到1。本发明对数字化病理图像,能够基于深度学习技术使用GPU并行计算与统计,降低传统病理抽样统计的误差,提高病理诊断的效率与准确率。</td>   <td>1.一种病理图片的处理方法,其特征在于包括下列步骤：图像采集：1)对数字病理玻片进行完整扫描获取到数字化病理图像；2)将所述数字化病理图像勾画出病变区域,从而得到勾画区域,并将所述勾画区域的位置生成xml格式的文件进行保存；3)生成一个与所述数字化病理图像的分辨率一致的大掩膜图像,并根据所述xml对其进行赋值,xml区域内为1,区域外为0,即勾画区域对应的像素值为1,其他区域对应的像素值为0；图像处理：设置切图的图片分辨率,读取所述数字化病理图像和所述大掩膜图像,并按照所述设置的切图的图片分辨率分别对所述数字化病理图像和所述大掩膜图像进行切图,分别得到小病理图和小掩膜图,并且小病理图和小掩膜图的位置一一对应；计算每个小掩膜图的像素平均值P,并设定阈值G,并只保存小掩膜图的像素的平均值P≥G,所对应的小病理图；若小掩膜图的像素的平均值P＜G,所对应的小病理图则丢弃,其中P,G取值范围均是0到1；所述大掩膜图、小掩膜图就是指mask图像,所述mask图像是将所述数字化病理图像中的病变区域的轮廓信息在坐标系中由x、y坐标值表示出来；所述图像采集中步骤2)中使用开源的ASAP进行勾画,形成曲线围成的区域,生成所述xml文件,所述勾画出病变区域的位置是指所述曲线的位置,所述ASAP是Automated sildeanalysis platform,即自动玻片分析平台；所述图像采集中步骤3)中调用ASAP自带的“multiresolutionimageinterface”库,生成所述勾画出病变区域的位置的所述大掩膜图像mask；所述图像处理中采用开源的openslide软件进行切图处理,即用开源的openslide库确定需要切图的放大倍数及图片分辨率,最后按照确定的放大倍数及图片分辨率在大掩膜图像mask的区域自动切图。</td>   <td>G06T7/00;G06T7/11;G06T7/187</td>  </tr>        <tr>   <td>中国专利</td>   <td>         付青;              苏奕星;                   陈一山       </td>   <td>中山大学</td>   <td>一种基于逆向预测历史数据集的光伏功率预测方法及系统</td>   <td>广东省</td>   <td>CN114881341A</td>   <td>2022-08-09</td>   <td>本发明提出一种基于逆向预测历史数据集的光伏功率预测方法及系统,涉及光伏发电的技术领域,从获取的数据中选取自最新时刻开始,一定逆向时间跨度的历史数据集,以逆向滚动预测过去的光伏功率,避免每次均对所有不同时间跨度的历史数据集进行预测的繁复计算方式,初步降低光伏功率预测的计算量,而后以逆向滚动预测确定的历史数据集样本数目为基础点,搜寻最佳历史数据集样本数目,优化用于光伏预测的历史数据集,进一步提升后续光伏功率预测的精度。</td>   <td>1.一种基于逆向预测历史数据集的光伏功率预测方法,其特征在于,包括：S1.从光伏发电的历史数据库中获取数据,并从获取的数据中选取自最新时刻开始,一定逆向时间跨度的历史数据集；S2.选定光伏预测算法,利用历史数据集的数据逆向滚动预测过去的光伏功率,将光伏功率逆向滚动预测结果与对应的逆向时刻的实际光伏功率结果比较,比较结果用预测误差指标表示,得到预测误差指标随逆向时间跨度变化的趋势曲线；S3.确定预测误差指标随逆向时间跨度变化的趋势曲线中的最低点对应的逆向时间跨度,得出逆向时间跨度对应的历史数据集样本数目；S4.以S3确定的历史数据集样本数目为基础点,搜寻最佳历史数据集样本数目；S5.以最佳的历史数据集样本数目对应的历史数据集进光伏功率预测。</td>   <td>G06Q10/04;G06Q50/06;G06F16/9537</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵春梅;                   甘程友       </td>   <td>中山大学</td>   <td>一种多层次区域土壤生态风险的评估方法</td>   <td>广东省</td>   <td>CN114881415A</td>   <td>2022-08-09</td>   <td>本发明提供一种多层次区域土壤生态风险的评估方法,所述评估方法以区域稀土暴露数据和物种毒性数据为基础,经过相互耦合的筛选性风险评估、半概率风险评估和概率风险评估,筛选出区域内优先关注的稀土元素,并以优先关注的稀土元素的生态风险代表稀土元素混合物的综合生态风险。本发明建立了一套由定性到定量的评价方法,精确反映了区域性稀土污染的生态风险。</td>   <td>1.一种多层次区域土壤生态风险的评估方法,其特征在于,所述评估方法以区域稀土暴露数据和物种毒性数据为基础,经过相互耦合的筛选性风险评估、半概率风险评估和概率风险评估,筛选出区域内优先关注的稀土元素,并以优先关注的稀土元素的生态风险代表稀土元素混合物的综合生态风险。</td>   <td>G06Q10/06;G06Q50/26;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王家彪;              朱薇儒;              赵铜铁钢;                   李银林       </td>   <td>中山大学</td>   <td>一种基于预报不确定性的水库多阶段实时优化调度方法</td>   <td>广东省</td>   <td>CN114881481A</td>   <td>2022-08-09</td>   <td>本发明公开了一种基于预报不确定性的水库多阶段实时优化调度方法,包括S1、收集并整理水库实时调度所需的数据；S2、构建水库径流预报模型,实现水库径流预报；S3、水库多阶段径流预报不确定性分析；S4、构建水库实时优化调度模型,实现水库实时优化调度；S5、对水库实时优化调度方案进行收敛性分析；S6、实施水库实时优化调度方案,并进入下一调度阶段。优点是：能够综合多阶段预报信息,同时区分考虑多阶段预报的不确定性,既能充分利用预报信息,又能尽可能降低预报不确定性对实时调度方案的影响,从而显著提高水库调度效益,对于水库预报调度具有实践价值。</td>   <td>1.一种基于预报不确定性的水库多阶段实时优化调度方法,其特征在于：包括如下步骤,S1、收集并整理水库实时调度所需的数据；S2、构建水库径流预报模型,实现水库径流预报；S3、水库多阶段径流预报不确定性分析；S4、构建水库实时优化调度模型,实现水库实时优化调度；S5、对水库实时优化调度方案进行收敛性分析；S6、实施水库实时优化调度方案,并进入下一调度阶段。</td>   <td>G06Q10/06;G06Q50/06;G06N3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭剑和;                   杨旭       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种微纳机器人目标识别与定位跟踪方法及系统</td>   <td>广东省</td>   <td>CN114882064A</td>   <td>2022-08-09</td>   <td>本发明公开了一种微纳机器人目标识别与定位跟踪方法及系统,方法包括：获取微纳机器人的运动图像和运动视频；根据运动图像和运动视频截取连续帧图像,根据连续帧图像确定差分图像进行微纳机器人目标识别；连续帧图像包括连续两帧图像或连续三帧图像；随后获取初始图像；对初始图像进行图像滤波去噪及二值化处理,得到处理图像；通过地图生成函数对处理图像进行栅格化处理,得到栅格化图像；基于栅格化图像,结合微纳机器人目标识别进行微纳机器人定位跟踪。本发明通过对微纳机器人图像序列的连续帧图进行差分运算来获得运动目标轮廓,可以有效识别运动的微纳机器人,克服传统静态目标检测的适应性差问题,可广泛应用于微纳机器人技术领域。</td>   <td>1.一种微纳机器人目标识别与定位跟踪方法,其特征在于,包括：获取微纳机器人的运动图像和运动视频；根据所述运动图像和运动视频截取连续帧图像,根据所述连续帧图像确定差分图像进行所述微纳机器人目标识别；所述连续帧图像包括连续两帧图像或连续三帧图像；获取初始图像；所述初始图像包括静止障碍物；对所述初始图像进行图像滤波去噪及二值化处理,得到处理图像；通过地图生成函数对所述处理图像进行栅格化处理,得到栅格化图像；基于所述栅格化图像,结合所述微纳机器人目标识别进行所述微纳机器人定位跟踪。</td>   <td>G06T7/20;G06T7/13;G06T5/00;G06T7/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   夏萌       </td>   <td>中山大学</td>   <td>编码器、编码器和解码器框架及多目标跟踪与分割方法</td>   <td>广东省</td>   <td>CN114882067A</td>   <td>2022-08-09</td>   <td>本发明属于神经网络技术领域,公开了编码器、编码器和解码器框架及多目标跟踪与分割方法,输入模块用于获取当前帧图片和上一帧分割结果生成的高斯分布热力图；多尺度特征生成模块,用于对输入模块得到的当前帧图片和上一帧分割结果生成的高斯分布热力图进行特征提取,生成多尺度特征,多尺度特征包括：语义特征和其它特征；记忆增强的特征编码模块用于将语义特征和当前帧的全局上下文矩阵进行关联得到记忆增强的语义特征；输出模块,用于将记忆增强的语义特征和其它特征进行组合得到特征地图。有益效果：通过设置记忆增强的特征编码模块,利用了全局上下文的信息,解决了编码器时域上的连续性问题,可以更好的实现多目标的追踪和分割。</td>   <td>1.一种编码器,其特征在于,包括：输入模块、多尺度特征生成模块、记忆增强的特征编码模块和输出模块；所述输入模块,用于获取当前帧图片和上一帧分割结果生成的高斯分布热力图；所述多尺度特征生成模块,用于对输入模块得到的当前帧图片和上一帧分割结果生成的高斯分布热力图进行特征提取,生成多尺度特征,所述多尺度特征包括：语义特征和其它特征；所述记忆增强的特征编码模块用于将语义特征和当前帧的全局上下文矩阵进行关联得到记忆增强的语义特征；所述输出模块,用于将记忆增强的语义特征和其它特征进行组合得到特征地图。</td>   <td>G06T7/215;G06T7/246;G06T9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈定安;              彭雄;                   李名豪       </td>   <td>中山大学</td>   <td>一种基于单一立方体三维点云配准方法及系统</td>   <td>广东省</td>   <td>CN114882085A</td>   <td>2022-08-09</td>   <td>本发明公开了一种基于单一立方体三维点云配准方法及系统,该方法包括：获取原始点云并根据原始点云提取骰子点云；判断到骰子点云数据完整,对骰子点云进行平面分割、旋转和图像处理,得到预处理图像；对预处理图像进行圆边缘检测和圆拟合,并进行坐标变换,得到骰子平面点数圆中心三维坐标；根据骰子平面点数圆中心三维坐标构建同名点对；计算同名点对之间的旋转矩阵和平移矩阵,并基于旋转矩阵和平移矩完成配准。该系统包括：点云提取模块、图像处理模块、中心计算模块、同名点对构建模块和配准模块。通过使用本发明,能够将两个测站所扫描的点云数据准确进行配准,得到完整的三维点云数据。本发明可广泛应用于地理信息处理领域。</td>   <td>1.一种基于单一立方体三维点云配准方法,其特征在于,包括以下步骤：获取原始点云进行降噪等预处理并根据预处理后的点云提取骰子点云；判断到骰子点云数据完整,对骰子点云进行平面分割、旋转和图像处理,得到预处理图像；对预处理图像进行圆边缘检测和圆拟合,并进行坐标变换,得到骰子平面点数圆中心三维坐标；根据骰子平面点数圆中心三维坐标构建同名点对；计算同名点对之间的旋转矩阵和平移矩阵,并基于旋转矩阵和平移矩完成粗配准。</td>   <td>G06T7/33;G06T7/13;G06T7/73;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              蒋维娜;                   牛群       </td>   <td>中山大学</td>   <td>一种基于无线信号和对抗学习的地图更新方法</td>   <td>广东省</td>   <td>CN114882140A</td>   <td>2022-08-09</td>   <td>本发明公开了一种基于无线信号和对抗学习的地图更新方法,方法包括：将采集到的信号指纹转换为高分辨率热力图的形式；采用场景约束下采样方法对所述高分辨率热力图进行下采样操作,得到对应的低分辨率热力图；在所述低分辨率热力图中随机选取方形区域,使用所述方形区域替换高分辨率热力图中对应区域,作为新的低分辨率热力图,完成训练数据的构建；将所述训练数据输入到对抗学习网络中进行训练,得到对应的重建模型；使用所述重建模型对信号地图进行重建。本发明的精度高且成本低,可广泛应用于目标定位技术领域。</td>   <td>1.一种基于无线信号和对抗学习的地图更新方法,其特征在于,包括：将采集到的信号指纹转换为高分辨率热力图的形式；采用场景约束下采样方法对所述高分辨率热力图进行下采样操作,得到对应的低分辨率热力图；在所述低分辨率热力图中随机选取方形区域,使用所述方形区域替换高分辨率热力图中对应区域,作为新的低分辨率热力图,完成训练数据的构建；将所述训练数据输入到对抗学习网络中进行训练,得到对应的重建模型；使用所述重建模型对信号地图进行重建。</td>   <td>G06T11/20;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭子晗;              由林麟;              吴承瀚;              林俊龙;              李浩源;                   侯英威       </td>   <td>中山大学</td>   <td>前后端分离的异步联邦学习方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN114861931A</td>   <td>2022-08-05</td>   <td>本发明公开了一种前后端分离的异步联邦学习方法、系统、装置及存储介质,其中方法包括：根据待训练服务,服务使用者向后端发送服务请求信息；后端接收到的服务请求信息推送给系统管理者；系统管理者设置待训练服务对应的待执行任务的全局训练策略,并将全局训练策略发送给后端,由后端开始待执行任务的异步联邦学习；后端向训练参与者发送训练通知；训练参与者训练本地模型,并将训练好的本地模型上传至后端；后端根据接收到的本地模型生成全局模型,并对全局模型进行评估；当评估通过,后端更新待训练服务的使用状态,并将更新后的使用状态返回服务使用者。本申请实施例提出的异步联邦学习系统的前后端相对独立且松耦合,能有效提高系统兼容性。</td>   <td>1.一种前后端分离的异步联邦学习方法,所述前后端分离的异步联邦学习方法应用于前后端分离的异步联邦学习系统,所述系统包括前端和后端,所述前端和所述后端之间以接口形式进行数据交换；所述前端的用户身份包括服务使用者、系统管理者和训练参与者；其特征在于,所述方法包括：根据待训练服务,所述服务使用者向所述后端发送服务请求信息；所述后端接收到的所述服务请求信息推送给所述系统管理者；根据接收到的所述服务请求信息,所述系统管理者设置所述待训练服务对应的待执行任务的全局训练策略,并将所述全局训练策略发送给所述后端；根据所述全局训练策略,所述后端开始所述待执行任务的异步联邦学习；在所述异步联邦学习的过程中,所述后端向所述训练参与者发送训练通知；根据所述训练通知,所述训练参与者训练本地模型,并将训练好的所述本地模型上传至所述后端；所述后端根据接收到的所述本地模型生成全局模型,并对所述全局模型进行评估；当评估通过,所述后端更新所述待训练服务的使用状态,并将更新后的所述使用状态返回所述服务使用者；所述服务使用者接收到所述使用状态后,向所述后端发送对应所述待训练服务的本地服务请求；根据所述本地服务请求,所述后端向所述服务使用者发送所述全局模型；所述服务使用者接收所述全局模型并进行本地服务计算,获得服务计算结果,并将所述服务计算结果在前端界面进行可视化。</td>   <td>G06N20/00;G06F9/50;G06F16/23;G06F16/27;G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              简伟涛;                   黄玮       </td>   <td>中山大学</td>   <td>一种自主式交通系统场景架构的构建方法及系统</td>   <td>广东省</td>   <td>CN114862247A</td>   <td>2022-08-05</td>   <td>本发明公开了一种自主式交通系统场景架构的构建方法及系统,方法包括：采用场景分类法对自主式交通系统场景进行分层抽象,提取具体微观场景下的需求；根据具体微观场景下的需求,确定服务对象并提取交通系统的功能对象和组分对象；结合服务对象、功能对象和组分对象,根据技术对象解析具体场景下的构成要素,并形成要素表；根据要素表,建立要素之间的关系,形成有关具体场景下的要素关联关系的规则表；基于结构化、流程化与对象化系统分析方法,解析自主式交通系统的具体场景下的要素内容及其关联规则,构建体现自主化水平的多维系统架构。本发明能够高效地构建系统完整、科学的自主式交通系统场景,可广泛应用于计算机技术领域。</td>   <td>1.一种自主式交通系统场景架构的构建方法,其特征在于,包括：采用场景分类法对自主式交通系统场景进行分层抽象,逐层分析得到宏观场景、中观场景、微观场景,提取具体微观场景下的需求；根据所述具体微观场景下的需求,确定服务对象并提取交通系统的功能对象和组分对象；结合所述服务对象、所述功能对象和所述组分对象,根据技术对象解析具体场景下的构成要素,并形成要素表；根据所述要素表中各个具体场景的构成要素,建立要素之间的关系,形成有关具体场景下的要素关联关系的规则表；基于结构化、流程化与对象化系统分析方法,解析自主式交通系统的具体场景下的要素内容及其关联规则,构建体现自主化水平的多维系统架构。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁小燕;              谢志;              周昊;              孙立梅;                   何尧       </td>   <td>中山大学中山眼科中心</td>   <td>一种早产儿视网膜病变检测方法及装置</td>   <td>广东省</td>   <td>CN114862760A</td>   <td>2022-08-05</td>   <td>本发明公开一种早产儿视网膜病变检测方法和装置,方法包括以下步骤：S1：获取待筛查个体的左右两边不同方位的眼底广角影像；S2：以待筛查个体为单位将不同方位的眼底广角影像送入预先训练好的病灶检出模型,得到每张眼底广角影像的病灶检出结果；S3：将带有病灶检出结果的不同方位的眼底广角影像进行拼接合并,得到最终的拼接图像；S4：根据最终的拼接图像得到眼底视网膜分区；S5：在分区后的图像中可视化病灶检出结果和分区标识,并按照病灶类型给出分期结果。本发明实现自动检出病灶、多方位图像拼接融合、分区、分期以及各亚型识别的完整诊断流程。</td>   <td>1.一种早产儿视网膜病变检测方法,其特征在于,包括以下步骤：S1：获取待筛查个体的左右两边不同方位的眼底广角影像；S2：以待筛查个体为单位将不同方位的眼底广角影像送入预先训练好的病灶检出模型,得到每张眼底广角影像的病灶检出结果；S3：将带有病灶检出结果的不同方位的眼底广角影像进行拼接合并,得到最终的拼接图像；S4：根据最终的拼接图像得到眼底视网膜分区；S5：在分区后的图像中可视化病灶检出结果和分区标识,并按照病灶类型给出分期结果。</td>   <td>G06T7/00;G06T3/40;G06V10/25;G06V10/774;A61B3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱杰友;                   周炳朋       </td>   <td>中山大学</td>   <td>一种基于双向循环卷积神经网络的可见光定位跟踪方法</td>   <td>广东省</td>   <td>CN114862906A</td>   <td>2022-08-05</td>   <td>本发明提出一种基于双向循环卷积神经网络的可见光定位跟踪方法,涉及可见光定位跟踪的技术领域,利用多个光电二极管在连续时刻下接收到的可见光信号,得到连续时刻下的观测数据并记录连续时刻下目标终端的位置坐标标签,对双向循环卷积神经网络模型进行训练,向训练好的双向循环卷积神经网络模型输入在线观测数据信息即可获取对应的目标终端位置定位估计,双向循环卷积神经网络模型能够挖掘并融合观测数据时间和空间特征信息,在定位估计过程中,不仅考虑当前观测信息,还根据连续时刻的观测数据信息,设计双向循环卷积神经网络提取连续时刻的时空特征信息,使得定位精度更高。</td>   <td>1.一种基于双向循环卷积神经网络的可见光定位跟踪方法,其特征在于,所述方法包括以下步骤：S1.为目标终端配备若干个光电二极管,令目标终端在室内做随机运动,利用光电二极管在每一时刻接收可见光信号,得到连续时刻下的观测数据,并记录连续时刻下目标终端的位置坐标标签；S2.构建双向循环卷积神经网络模型,双向循环卷积神经网络模型包括正向循环记忆模块与反向循环记忆模块；S3.将观测数据与位置坐标标签分别进行预处理并记录预处理过程,将预处理后的观测数据与位置坐标标签作为训练集,输入双向循环卷积神经网络,并训练网络模型参数集合,得到训练好的双向循环卷积神经网络模型；S4.以S1所述的方式,实时获取连续时刻下的观测数据并进行预处理,然后将预处理后的观测数据输入至训练好的双向循环神经网络模型；S5.正向循环记忆模块与反向循环记忆模块分别提取连续时刻下观测数据中的时空纹理特征信息并输出；S6.融合正向循环记忆模块与反向循环记忆模块提取的时空纹理特征信息,作为当前时刻双向循环神经网络模型输出的目标终端定位估计；S7.设置连续输入时刻次数最大值为T,重复执行T次S5～S6,得到T次连续时刻下的目标终端定位估计,对其进行与S3记录的预处理过程相反的操作,得到目标终端对应的连续时刻的位置估计。</td>   <td>G06T7/246;G06V10/80;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         龚瑾;              黄凯;              郭英;              宋日辉;                   谭志东       </td>   <td>中山大学附属第三医院;中山大学</td>   <td>一种用于神经外科内窥镜中的深度估计方法及系统</td>   <td>广东省</td>   <td>CN114862935A</td>   <td>2022-08-05</td>   <td>本发明提供了一种用于神经外科内窥镜中的深度估计方法及系统,一方面,本发明提供了一种用于神经外科内窥镜中的深度估计方法,本方法包括以下处理步骤,步骤1：对神经外科内窥镜进行内参标定；将内窥镜图像传回计算机并且根据步骤1测得的内参矩阵和畸变系数对照片进行校正；步骤3：利用内窥镜图像器械分割算法对校正后的图像进行器械分割,得到不包含手术器械的内窥镜图像；步骤4：利用立体匹配算法进行深度计算,在内窥镜采集图像中标注出每个物体的深度值并将标注深度后的照片进行显示。另一方面,本发明提供了一种用于神经外科内窥镜中的深度估计系统。通过本发明能够提升手术过程中进行深度估计的精度。</td>   <td>1.一种用于神经外科内窥镜中的深度估计方法,其特征在于,本方法包括以下处理步骤,步骤1：对神经外科内窥镜进行内参标定,将一张黑白间距已知的棋盘格贴在模拟手术台的桌面上,移动内窥镜在不同位置和角度对棋盘格拍摄至少10张照片,用张氏标定法计算出相机的内参矩阵A、外参矩阵[R|T]以及畸变系数[k1,k2,k3,～,p1,p2,～],其中,K1、K2、K3为径向畸变,P1、P2为切向畸变；步骤2：内窥镜采集图像作为左图,将内窥镜向左水平移动设定距离,此时最右边的照片作为右图,将内窥镜采集图像传回计算机并且根据步骤1测得的内参矩阵和畸变系数对照片进行校正；步骤3：利用内窥镜图像器械分割算法对校正后的图像进行器械分割,得到不包含手术器械的内窥镜采集图像；步骤4：对校正并且去除器械后的每对左右图,利用立体匹配算法进行深度计算,在内窥镜采集图像中标注出每个物体的深度值并将标注深度后的照片进行显示。</td>   <td>G06T7/593;G06T7/00;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨钦泰;              韩蓝青;              任勇;              吴庆武;              陈健宁;              邓慧仪;              孙悦奇;              袁联雄;              王玮豪;              郑瑞;              洪海裕;              孔维封;              黄雪琨;              袁田;              邱惠军;              李权;              黄桂芳;              叶俊杰;                   王伦基       </td>   <td>中山大学附属第三医院;清华珠三角研究院</td>   <td>基于数字病理玻片进行慢性鼻窦炎的分型方法及其系统</td>   <td>广东省</td>   <td>CN110728666B</td>   <td>2022-08-02</td>   <td>本发明公开了基于数字病理玻片进行慢性鼻窦炎的分型方法,包括下列步骤：图像采集,对慢性鼻窦炎鼻息肉玻片获取到数字化病理图像并进行勾画,生成大掩膜图像；图像预处理,得到小病理图和小掩膜图；建立训练集数据；建立深度学习量化预测模块,采用Inception V3模型及其在ImageNet数据集上进行训练得到模型参数,去掉此模型最后一层全连接层FC,并增加一层全连接层FC且其内只有一个神经元,不采用任何激活函数,设置损失函数采用均方误差MSE,设置学习率lr；整合玻片上所有小病理图片的嗜酸性粒细胞比例值,得到最终辅助诊断结果。本发明还公开了其系统。本发明通过学习训练快速得到病理图片上的嗜酸性粒细胞占比值,给出客观的、准确性高的辅助诊断结果。</td>   <td>1.一种基于数字病理玻片进行慢性鼻窦炎的分型方法,其特征在于包括下列步骤：图像采集：1)对慢性鼻窦炎鼻息肉玻片进行完整扫描获取到数字化病理图像；2)将所述数字化病理图像勾画出病变区域,从而得到勾画区域,并将所述勾画区域的位置生成xml格式的文件进行保存；3)生成一个与所述数字化病理图像的分辨率一致的大掩膜图像,并根据所述xml对其进行赋值,xml区域内为1,区域外为0,即勾画区域对应的像素值为1,其他区域对应的像素值为0；图像预处理：设置切图的图片分辨率,读取所述数字化病理图像和所述大掩膜图像,并按照所述设置的切图的图片分辨率分别对所述数字化病理图像和所述大掩膜图像进行切图,分别得到小病理图和小掩膜图,并且小病理图和小掩膜图的位置一一对应；计算每个小掩膜图的像素平均值P,并设定阈值G,并只保存小掩膜图的像素的平均值P≥G所对应的小病理图；若小掩膜图的像素的平均值P＜G所对应的小病理图则丢弃,其中P,G取值范围均是0到1；所述大掩膜图、小掩膜图均指mask图像,mask图像是将所述数字化病理图像中的病变区域的轮廓信息在坐标系中由x、y坐标值表示出来；设计训练数据集：每张小病理图片记做X,统计每张小病理图片的嗜酸性粒细胞个数及所有炎症细胞个数,嗜酸性粒细胞占炎症细胞的比例＝嗜酸性粒细胞个数/所有炎症细胞个数,统计的嗜酸性粒细胞数目N,非嗜酸性粒细胞数目M,每张图片对应的嗜酸性粒细胞比例S计算为：S＝N/(N+M),取值范围0％～100％,其中没有嗜酸性粒细胞为0％,全是嗜酸性粒细胞为100％,对前述的所有小病理图片,按照设定的比例分成训练集数据和测试集数据；建立深度学习量化预测模块：首先,采用深度学习keras框架下的Inception V3模型及其在ImageNet数据集上进行训练得到模型参数,该模型最后一层全连接层FC,其内有进行分类的神经元,并且采用softmax激活函数,去掉此模型所述的最后一层全连接层FC,并增加一层全连接层FC,新增全连接层FC只有一个神经元,不采用任何激活函数,然后设置InceptionV3的模型的损失函数loss＝‘mse’,即采用均方误差MSE,设置学习率lr,用ImageNet数据集训练得到的开源参数对InceptionV3模型进行参数初始化,最后用所述训练集数据重新训练InceptionV3模型的参数,训练次数设定为n轮,每一轮均用所述测试集数据进行测试,将测试图片输入当前得到的模型进行预测得到嗜酸性粒细胞比例的预测值P1,并将所述预测值P1与测试数据的真实标签值即所述嗜酸性粒细胞比例S,计算平均绝对误差MAE,即每个图片的所述预测值P1与所述嗜酸性粒细胞比例S之差的绝对值的平均值；将n轮中MAE最小时对应的模型参数进行保存,从而得到嗜酸性粒细胞占比模型,所述n为自然数,且n大于1,按照前述训练次数的要求进行训练；整合玻片上所有小病理图片的嗜酸性粒细胞比例值,得到慢性鼻窦炎鼻息肉玻片的最终辅助诊断结果：设定所述慢性鼻窦炎鼻息肉玻片由N张小病理图片组成,N为自然数,分别由所述嗜酸性粒细胞占比模型训练得到每张小病理图片的嗜酸性粒细胞占比值Si,i为(1,N),则该玻片最终诊断结果为N个值的平均值,D＝∑Si/N。</td>   <td>G06T7/00;G16H30/20;G06N3/04;G06N3/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              黄洋漫;              郑炎辉;              苏春生;              康丽;                   田世拓       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种城市区域水生态状态反应器构建方法、装置及反应器</td>   <td>广东省</td>   <td>CN114626771B</td>   <td>2022-08-02</td>   <td>本发明涉及水生态质量评价技术领域,公开了一种城市区域水生态状态反应器构建方法、装置及反应器。本发明根据目标城市区域的各水生态状态指数对应的指标数据确定重要指标,基于重要指标的标准化值和权重计算各水生态状态指数的水生态状态得分值,根据所面临的水生态风险确定多个驱动因子并计算各驱动因子的标准化值,进而利用多元线性逐步回归建立各水生态状态指数与驱动因子的回归方程,通过显著性检验筛选出对各水生态状态指数产生显著影响的驱动因子,最后构建以驱动因子为输入、以水生状态综合指数为输出的目标城市区域水生状态反应器。本发明解决了目前水生态状态反应器评价指标单一、灵活性低,不适用于快速城市化区域的技术问题。</td>   <td>1.一种城市区域水生态状态反应器构建方法,其特征在于,包括：确定目标城市区域的各水生态状态指数及对应的指标集,采集各所述指标集的指标数据；所述各水生态状态指数包括水生物指数、水生境指数、水质指数和水安全指数,其中反映所述水安全指数的指标包括目标城市区域人均水资源量、地级以上城市集中式饮用水水源水质达标率、城市污水处理率、城镇居民生活人均用水量和含氯度超标天数；根据所述指标数据筛选出重要指标,计算各所述重要指标的标准化值和权重,根据得到的标准化值和权重计算各水生态状态指数的水生态状态得分值；根据所述目标城市区域所面临的水生态风险确定多个驱动因子,并对各所述驱动因子进行标准化处理,得到各所述驱动因子的标准化值；根据各所述驱动因子的标准化值和各水生态状态指数的水生态状态得分值,利用多元线性逐步回归建立各水生态状态指数与驱动因子的回归方程,对建立的各回归方程进行总体显著性检验和回归系数显著性检验,根据得到的检验结果,从各驱动因子中筛选出对各水生态状态指数产生显著影响的驱动因子；建立各所述水生态状态指数对筛选出的驱动因子的响应方程,根据所述响应方程和各所述水生态状态指数的权重,构建以驱动因子为输入、以水生状态综合指数为输出的目标城市区域水生状态反应器；其中,所述根据所述目标城市区域所面临的水生态风险确定多个驱动因子,包括：确定驱动因子包括水生态环境变化因子和城市化综合指数,所述水生态环境变化因子包括目标城市区域范围内各水域的平均年径流量、下游潮位、下游盐度、污染物浓度和/或水域间的分流比,所述城市化综合指数包括目标城市区域范围内的人口密度、人均GDP、工业废水排放量、生活污水排放量、工业固体废物产生量和/或水域面积；根据得到的标准化值和权重计算各水生态状态指数的水生态状态得分值时,采用下列公式进行计算：                  式中,为水生态状态指数,为指标权重；为标准化处理后的指标值, 为水生态状态指数所包含的指标数量。</td>   <td>G06Q10/06;G06Q10/04;G06Q50/26;G06F17/18;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孔轩;              王天星;                   程文杰       </td>   <td>中山大学</td>   <td>一种深度学习支持下的全天候太阳辐射遥感预报方法</td>   <td>广东省</td>   <td>CN114841397A</td>   <td>2022-08-02</td>   <td>本发明涉及一种深度学习支持下的全天候太阳辐射遥感预报方法,包括以下步骤：S1、获取时间序列多光谱遥感数据；S2、对获取的时间序列多光谱遥感数据进行数据预处理,获得预处理的时间序列多光谱遥感数据集；S3、将获取的预处理的时间序列多光谱遥感数据集输入ConvLSTM网络模型得到瞬时太阳短波辐射预测数据或多时间尺度太阳短波辐射预测；所述ConvLSTM网络模型为面向遥感图像并结合空间注意力机制的深度学习网络模型。本发明提供的预报方法完整的考虑了太阳辐射的空间特性和时间序列特性,并且在深度神经网络中增加了空间注意力机制,更有效的捕捉了自然界中太阳辐射存在的突变。</td>   <td>1.一种深度学习支持下的全天候太阳辐射遥感预报方法,其特征在于,包括以下步骤：S1、获取时间序列多光谱遥感数据；S2、对获取的时间序列多光谱遥感数据进行数据预处理,获得预处理的时间序列多光谱遥感数据集；S3、将获取的预处理的时间序列多光谱遥感数据集输入ConvLSTM网络模型得到瞬时太阳短波辐射预测数据或多时间尺度太阳短波辐射预测；所述ConvLSTM网络模型为面向遥感图像并结合空间注意力机制的深度学习网络模型。</td>   <td>G06Q10/04;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              褚燕燕       </td>   <td>中山大学</td>   <td>事件链驱动下的多灾种耦合模型推演方法</td>   <td>广东省</td>   <td>CN114841398A</td>   <td>2022-08-02</td>   <td>本发明公开了一种事件链驱动下的多灾种耦合模型推演方法,包括以下步骤：S1、构建包括致灾因子、承灾载体、孕灾环境三级结构的事件因子及事件因子谱图；S2、构建多灾种耦合模型库；S3、确定多灾种耦合事件链的险兆因子；S4、确定多灾种耦合事件链中各个险兆因子之间的效用关系；S5、计算险兆因子之间的耦合度大小；S6、绘制多灾种耦合事件链；S7、计算得出多灾种耦合事件链的联合条件概率分布,建立多灾种耦合事件链推理原则,完成多灾种耦合模型推演。本发明采用事件链的方式,实现了多种原生灾害耦合发生演化过程的推演,进而预测多灾种耦合事件发生风险。</td>   <td>1.事件链驱动下的多灾种耦合模型推演方法,其特征在于,包括以下步骤：S1、获取暴雨事件、地质灾害事件、雷电事件、内涝灾害事件、城市生命线基础设施事故事件多种典型自然灾害事件,将上述多种典型自然灾害事件进行粒度分解,构建包括致灾因子、承灾载体、孕灾环境三级结构的事件因子及事件因子谱图；S2、根据步骤S1得到的事件因子,构建包括振颤模型、暴雨-内涝动力学模型、土壤固结沉降动力学模型、刚体疲劳断裂及腐蚀脆断动力学模型的多灾种耦合模型库；S3、根据步骤S2中构建的多灾种耦合模型库,确定暴雨事件、地质灾害事件、雷电事件、内涝灾害事件、城市生命线基础设施事故事件构成的多灾种耦合事件链中的险兆因子；S4、根据步骤S3中构建的多灾种耦合模型库,结合环境参数,确定多灾种耦合事件链中各个险兆因子之间的效用关系；S5、根据步骤S4中确定的险兆因子之间的效用关系,计算险兆因子之间的耦合度大小；S6、根据步骤S5中确定的险兆因子之间的耦合度,结合步骤S1中得到的事件因子谱图,确定险兆因子之间的相关关系,绘制多灾种耦合事件链,确定多灾种耦合事件链及其中的态势情景单元；S7、根据险兆因子的效用关系,并基于状态转移理论得出态势情景单元的状态转移概率,进而得出多灾种耦合事件链的联合条件概率分布,建立多灾种耦合事件链推理原则,完成多灾种耦合模型推演。</td>   <td>G06Q10/04;G06Q10/06;G06N5/04;G06F30/20;G06F111/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周颖;              邹小海;              沈悦;              郑鹏根;              陈洁琪;                   严嘉怡       </td>   <td>中山大学</td>   <td>一种基于多智能体的多分辨率建模方法及系统</td>   <td>广东省</td>   <td>CN114842152A</td>   <td>2022-08-02</td>   <td>本发明涉及多分辨率建模技术领域,提出一种基于多智能体的多分辨率建模方法及系统,其中包括：构建由一个感知决策智能体和多个模型智能体组成的多智能体系统；其中,感知决策智能体用于对任一模型智能体的多分辨率进行切换调度决策；模型智能体用于执行仿真运算,以及根据感知决策智能体的决策切换使用不同的分辨率模型；获取仿真服务器的资源使用状态数据,以及所有模型智能体当前运行的分辨率信息；感知决策智能体基于多分辨率切换算法输出包括各个模型智能体下一步应选择的分辨率模型的决策信号；各个模型智能体根据接收的决策信号选择使用目标分辨率模型用于执行多分辨率建模,并输出仿真结果。</td>   <td>1.一种基于多智能体的多分辨率建模方法,其特征在于,包括以下步骤：S1、构建由一个感知决策智能体和多个模型智能体组成的多智能体系统；其中,所述感知决策智能体用于对任一模型智能体的多分辨率进行切换调度决策；所述模型智能体用于执行仿真运算,以及根据所述感知决策智能体的决策切换使用不同的分辨率模型；S2、获取仿真服务器的资源使用状态数据,以及所有模型智能体当前运行的分辨率信息；S3、所述感知决策智能体根据仿真服务器的资源使用状态数据和所有模型智能体当前运行的分辨率信息,基于多分辨率切换算法输出包括各个模型智能体下一步应选择的分辨率模型的决策信号；S4、各个模型智能体根据接收的决策信号选择使用目标分辨率模型用于执行多分辨率建模,并输出仿真结果。</td>   <td>G06T17/00;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王宇辰;              王建民;              由芳;              陈慧妍;                   郭阿丽       </td>   <td>中山大学南昌研究院;中山大学深圳研究院;广州方铭交互信息科技有限公司</td>   <td>一种基于眼动控制的智能座舱HMI评测方法</td>   <td>江西省</td>   <td>CN114817021A</td>   <td>2022-07-29</td>   <td>本发明公开了一种基于动态眼动追踪技术的智能HMI评测方法及系统,包括：启动用户行为捕捉系统,进行HMI测试,获取注视焦点数据,获取头部状态数据,获取当用户视线注视/离开当前屏幕的持续时间,发送用户操作行为标签,发送HMI界面截图,采集数据,设置缺省阶段,添加阶段,匹配界面截图,输入界面元素坐标范围,生成眼动数据轨迹图,处理头部动作数据；计算各AOI平均注视时间；本发明在HMI测试中,结合捕捉到用户行为的时间,实验结束后可以根据眼动数据生成热力图、轨迹图,并统计出对元素的首次注视时间、驻留时间、首次注视持续时间等数据。本发明同时支持接入HMI系统进行评测,减少额外的开发工作量,有利于HMI原型的快速测试与迭代。</td>   <td>1.一种基于眼动控制的智能座舱HMI评测方法,包括眼动捕捉系统、HMI系统、数据采集分析系统、数据库以及服务器；其特征在于：步骤1：运行用户行为捕捉系统,并保持后台运行；步骤2：按照实验方案对HMI进行测试；步骤3：获取注视焦点数据；获取当前系统时间,与当前视线焦点坐标对应并通过接口1发送至服务器；步骤4：获取头部状态数据；将头部距离屏幕中心点位置以及头部旋转坐标与系统时间对应,并通过接口2发送至服务器；步骤5：获取当用户视线注视/离开当前屏幕时,记录用户视线注视/离开的时间点及距离上一次视线离开/注视的持续时间,并通过接口3发送至服务器；步骤6：发送用户操作行为标签；当系统监测到HMI端发生用户操作时,将用户进行操作时系统时间、操作持续时间、对应坐标等信息通过接口4发送至服务器；步骤7：发送HMI界面截图；当监测到HMI端发生用户操作时,将当前HMI界面截图及截图发生时的系统时间通过接口5发送至服务器；步骤8：采集数据；数据采集系统在开始实验后通过接口1、接口2、接口3、以及接口4采集眼动数据、用户操作数据、以及界面截图数据,并在结束实验后将相关数据保存至数据库对应表中；步骤9：设置缺省阶段；为实验过程设置阶段,每一个实验默认配置一个阶段1,阶段开始时间为实验开始时间,阶段结束时间为实验结束时间,阶段开始标签为实验开始,阶段结束标签为实验结束；步骤10：添加阶段；选择用户操作数据标签或眼动为实验添加阶段,检索选中数据中系统时间字段与当前阶段列表中各阶段开始结束时间的关系,将标签的时间作为分割阶段的时间,用户操作对应元素或HMI变化后状态作为分割阶段的标签名称；步骤11：匹配界面截图；添加阶段后,为各阶段匹HMI界面截图；将阶段的起止时间与HMI界面截图时间对应,若阶段起止时间内只包含一张图片,则自动关联为该界面；若阶段起止时间段内涉及多张图片,则由用户选择其中一张作为该阶段界面截图；步骤12：输入界面元素坐标范围；添加阶段后,测试人员输入需要关注的若干界面元素或区域在屏幕上的坐标范围；步骤13：生成眼动数据热力图；通过各阶段起止时间匹配阶段内眼动数据,生成眼动热力图,并在该阶段界面截图上叠加,分析任务过程中注视集中度以及元素对被试的吸引程度；步骤14：生成眼动数据轨迹图；通过各阶段起止时间匹配阶段内眼动数据,生成眼动数据轨迹图,并在该阶段界面截图上叠加,分析用户寻找元素的路径、哪些元素的视觉吸引力较强以及视觉搜索的轨迹,判断可用性和获取效率；步骤15：处理头部动作数据；根据头部动作数据,生成各阶段下用户头部距屏幕距离以及头部角度与初始位置偏离程度的最大值、最小值、平均值以及标准差,分析不同任务及方案下HMI屏幕对用户造成的分心程度；步骤16：计算首次注视时间及首次注视持续时间；根据该阶段下的界面元素坐标范围匹配眼动数据,计算从阶段开始到视线焦点坐标首次位于该区域内的时间以及在该区域内的停留时长,分析该元素的易发现程度以及引人注目程度；步骤17：计算各AOI平均注视时间；根据各阶段下的界面元素坐标范围匹配眼动数据,计算视线焦点停留在各区域内的时间。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              齐浩然;                   张欢荣       </td>   <td>中山大学</td>   <td>一种基于语义特征的人脸超分辨率重建方法及系统</td>   <td>广东省</td>   <td>CN114820310A</td>   <td>2022-07-29</td>   <td>本发明公开了一种基于语义特征的人脸超分辨率重建方法及系统,方法包括如下步骤：步骤一、降质阶段：将训练集的高分辨率人脸合成出含有复杂噪声和模糊分布的低分辨率人脸图像；步骤二、生成阶段：形成超分辨率人脸重建结果作为网络的输出,系统包括合成模块、放大模块、整合模块,本发明不仅提升了在多降质模态下FSR网络模型的泛化能力,同时在多降质模态下重建的SR人脸感知质量得到了增强。</td>   <td>1.一种基于语义特征的人脸超分辨率重建方法,其特征在于,包括如下步骤：步骤一、降质阶段：将训练集的高分辨率人脸合成出含有复杂噪声和模糊分布的低分辨率人脸图像；步骤二、生成阶段：所述生成阶段包括粗重建过程和精重建过程,所述粗重建过程用于将低分辨率人脸图像粗略放大至目标分辨率,所述精重建过程是基于粗重建过程的结果提取语义特征,随后语义特征和通用特征共同在语义注意力模块下整合,并最终形成超分辨率人脸重建结果作为网络的输出。</td>   <td>G06T3/40;G06N3/04;G06N3/08;G06V10/26;G06V40/16;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏航;              刘海亮;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院</td>   <td>基于步态的行为识别方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN114818989A</td>   <td>2022-07-29</td>   <td>本申请适用于设备管理技术领域,提供了一种基于步态的行为识别方法、装置、终端设备及存储介质,方法包括：接收待识别的目标视频数据；将所述目标视频数据导入预设的帧间动作提取网络,得到帧间动作特征数据；将所述帧间动作特征数据导入池化融合网络,输出所述目标视频数据对应的融合特征数据；将所述目标视频数据导入上下文注意力网络,确定所述目标视频数据中目标对象的步态行为数据；根据所述步态行为数据以及所述融合特征数据,得到所述目标对象的行为类别。采用上述方法能够大大降低了视频数据在进行行为识别过程中的计算成本,继而提高了运算效率。</td>   <td>1.一种基于步态的行为识别方法,其特征在于,包括：接收待识别的目标视频数据；将所述目标视频数据导入预设的帧间动作提取网络,得到帧间动作特征数据；所述帧间动作特征数据用于确定所述目标视频数据中相邻的视频图像帧之间的动作特征信息；将所述帧间动作特征数据导入池化融合网络,输出所述目标视频数据对应的融合特征数据；将所述目标视频数据导入上下文注意力网络,确定所述目标视频数据中目标对象的步态行为数据；所述上下文注意力网络用于提取所述目标视频数据中所述目标对象与环境对象之间的相互位置关系；根据所述步态行为数据以及所述融合特征数据,得到所述目标对象的行为类别。</td>   <td>G06K9/62;G06V20/40;G06V40/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         付青;              杨航;                   朱坤       </td>   <td>中山大学</td>   <td>基于历史数据集时间跨度优化的光伏发电功率预测方法</td>   <td>广东省</td>   <td>CN114819391A</td>   <td>2022-07-29</td>   <td>本发明提出一种基于历史数据集时间跨度优化的光伏发电功率预测方法,涉及光伏发电预测的技术领域,首先确定用于光伏发电功率预测的历史功率数据来源,按时间跨度调整用于预测光伏发电功率的历史数据集的样本数据数目,在历史数据集的数据样本数设置值的限定下,获取预测误差指标随历史数据集的样本数变化的趋势曲线,在预测误差指标最优点附近搜寻最优的历史数据集样本数,根据调整后的历史数据集重新进行预测,往复进行,加快最佳历史数据集样本数的搜寻过程,直至选择最佳的历史数据集样本数目,提高了光伏发电功率预测精度,避免历史数据集选取粗糙,导致计算量大及干扰大的问题。</td>   <td>1.一种基于历史数据集时间跨度优化的光伏发电功率预测方法,其特征在于,所述方法包括以下步骤：S1.确定用于光伏发电功率预测的历史功率数据来源,从历史功率数据来源中选定一定时间跨度下、具有若干数据样本数的历史数据集,并对历史数据集进行预处理；S2.基于已预处理的历史数据集,利用光伏发电功率预测算法A进行光伏发电功率预测,并计算光伏发电功率预测结果的预测误差指标；S3.以P为历史数据集的数据样本数按时间跨度方向增加的间隔,将历史数据集的数据样本数增加P,利用光伏发电功率预测算法A进行光伏发电功率预测,并计算光伏发电功率预测结果的预测误差指标；S4.判断历史数据集的数据样本数是否达到设置值,若是,执行步骤S5；否则,返回步骤S3；S5.形成预测误差指标随历史数据集的样本数变化的趋势曲线,确定趋势曲线中的最低点,以最低点对应的时间跨度下样本数目的历史数据集进行光伏发电功率预测,并计算光伏发电功率预测结果的预测误差指标；S6.以P为历史数据集的数据样本数按时间跨度方向增加的间隔,将最低点对应的时间跨度下的历史数据集的数据样本数增加P,然后进行光伏发电功率预测,判断预测误差指标是否减小,若是,将历史数据集的数据样本数增加P,执行步骤S7；否则,以H为历史数据集的数据样本数按时间跨度方向减小的间隔,将历史数据集的数据样本数减少H,H≠P,执行步骤S7；S7.判断历史数据集的数据样本数是否达到设置值,若是,形成预测误差指标随历史数据集的样本数变化的趋势曲线,确定趋势曲线中的拐点,以拐点对应的时间跨度下样本数目的历史数据集进行光伏发电功率预测；否则,返回步骤S6。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/06;H02J3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              诸葛盛;              何雨薇;              徐祥鹏;                   杨夏       </td>   <td>中山大学</td>   <td>一种基于共视基准的无人机集群对目标三维运动精确测量方法</td>   <td>广东省</td>   <td>CN114820703A</td>   <td>2022-07-29</td>   <td>本申请涉及一种基于共视基准的无人机集群对目标三维运动精确测量方法。所述方法包括：利用无人机集群采集的共视场景图像序列数据进行各无人机图像间的单应矩阵计算,以及共视场景中的同名特征提取,进而进行无人机间的位姿估计,再结合场景中的背景特征尺度信息,基于多目交会原理解算得到共视场景中目标的位置与运动轨迹。本方法不受GPS定位信号与太阳光照影响,可在室内外场景下使用。相较于基于静态红外相机的运动捕捉系统,具有使用场景灵活,测量范围大等优点。</td>   <td>1.一种基于共视基准的无人机集群对目标三维运动精确测量方法,其特征在于,所述方法包括：通过悬停在相同高度的多台无人机从不同视角对目标场景进行观测,并同时采集序列图像数据；对任一时间点,根据各无人机采集的所述序列图像数据,确定各无人机图像间的单应矩阵；根据预先选定的场景特征,获取任一台无人机图像中所述场景特征对应的场景特征图像坐标,根据所述各无人机图像间的单应矩阵确定所述场景特征在其他无人机图像中对应的同名场景特征图像坐标；根据预先获取的所述场景特征的实际尺寸信息,以及各无人机图像中的同名场景特征图像坐标,通过EPnP算法得到各无人机的机载相机相对所述目标场景的精确位姿关系信息；获取目标在各无人机图像中的目标图像坐标,根据所述精确位姿关系信息和目标在各无人机图像中的目标图像坐标,根据前方多目交会算法确定当前时间点目标在所述目标场景中的实际三维坐标；根据各个时间点所述序列图像数据确定的目标的实际三维坐标,得到目标在场景中的运动轨迹数据。</td>   <td>G06T7/246;G06T7/73;G06V20/17;G06V10/46;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韩瑜;              李锦铭;              古博;              温建棋;              刘梓阳;              秦臻;                   唐兆家       </td>   <td>中山大学</td>   <td>一种海上能源机组智能化运维方法及系统</td>   <td>广东省</td>   <td>CN114819225A</td>   <td>2022-07-29</td>   <td>本发明公开了一种海上能源机组智能化运维方法及系统,方法包括：获取海上能源机组的基础数据；对所述基础数据进行数据预处理,得到目标数据；将所述目标数据与预设的标准阈值进行比较,判断当前监测对象的状态信息,并根据所述状态信息确定预警启动状态,发出预警信息；根据所述预警信息进行故障诊断,生成故障诊断信息；获取历史故障诊断信息训练得到神经网络模型,并根据所述神经网络模型预测海上能源机组的实时运行状态；根据实时运行状态的预测结果以及历史故障信息,构建故障信息表；其中,所述故障信息表用于根据接收到的故障诊断信息匹配对应的故障解决方案。本发明效率高且稳定可靠,可广泛应用于计算机技术领域。</td>   <td>1.一种海上能源机组智能化运维方法,其特征在于,包括：获取海上能源机组的基础数据；对所述基础数据进行数据预处理,得到目标数据；将所述目标数据与预设的标准阈值进行比较,判断当前监测对象的状态信息,并根据所述状态信息确定预警启动状态,发出预警信息；根据所述预警信息进行故障诊断,生成故障诊断信息；获取历史故障诊断信息训练得到神经网络模型,并根据所述神经网络模型预测海上能源机组的实时运行状态；根据实时运行状态的预测结果以及历史故障信息,构建故障信息表；其中,所述故障信息表用于根据接收到的故障诊断信息匹配对应的故障解决方案。</td>   <td>G06Q10/00;G06Q50/06;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              苏航;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>一种科技服务数据的处理方法、装置以及系统</td>   <td>广东省</td>   <td>CN114818987A</td>   <td>2022-07-29</td>   <td>本发明属于智能终端的技术领域,提供了一种科技服务数据的处理方法、装置以及系统。该方法包括：获取各个第一用户终端的应用分类组的修改记录；所述修改记录包括用户终端标识和应用分类变动信息；将各个所述修改记录中的所述自定义类别关联的应用标识添加至所述自定义类别的语料库中,并根据所有所述自定义类别更新后的语料库对预设的应用分类模型进行迭代训练,得到优化分类模型；将所述优化分类模型发送给各个第二用户终端,以使所述第二用户终端基于所述优化分类模型对安装的第二应用程序进行分类。本申请实施例解决分类结果无法满足用户的个性化需求的问题。</td>   <td>1.一种科技服务数据的处理方法,其特征在于,包括：获取各个第一用户终端的应用分类组的修改记录；所述修改记录包括用户终端标识和应用分类变动信息；所述应用分类变动信息包括用户设置的自定义类别以及被定义为所述自定义类别的各个应用程序的应用标识；将各个所述修改记录中的所述自定义类别关联的应用标识添加至所述自定义类别的语料库中,并根据所有所述自定义类别更新后的语料库对预设的应用分类模型进行迭代训练,得到优化分类模型；将所述优化分类模型发送给各个第二用户终端,以使所述第二用户终端基于所述优化分类模型对安装的第二应用程序进行分类；第一应用程序以及所述第二应用程序为对科技服务数据进行处理的应用程序。</td>   <td>G06K9/62;G06F11/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              龚瑾;              郭英;              何海勇;              郭思璐;              宋日辉;                   梁宏立       </td>   <td>中山大学;中山大学附属第三医院</td>   <td>一种基于内窥镜图像的实时的神经外科手术器械分割方法</td>   <td>广东省</td>   <td>CN112396601B</td>   <td>2022-07-29</td>   <td>本发明属于医学图像处理领域和图像分割技术领域,更具体地,涉及一种基于内窥镜图像的实时的神经外科手术器械分割方法。提出了一套针对内窥镜神经外科手术场景的实时器械实例分割方法,能够应用到临床中,起到在术中实时辅助神经外科手术的作用。本发明还提出了一套针对光斑、倒影、模糊等噪声的数据增广方法,丰富样本的同时,提高模型的学习能力和适应性。</td>   <td>1.一种基于内窥镜图像的实时的神经外科手术器械分割方法,其特征在于,包括以下步骤：S1.采集内窥镜手术图像数据,采用人工标注的方式为图像打上标签,标签将前景即器械与背景进行空间上的分割和语义上的分类；构建数据集,设置交叉验证样本,建立器械实例分割数据库,分为训练集和验证集；S2.对数据集进行数据增广,包括翻转、旋转、调整图像强度、添加光斑/高斯噪声、图像混合,从而增加数据集的样本数量,丰富样本；S3.构建网络模型,包括一个特征主干网络,一个特征金字塔网络,一个原型预测分支和一个掩膜系数预测分支；输入是一个二维图像,输出为对该图像的预测结果,包括一组目标检测的边界框、掩膜以及对应类别；S4.用训练数据集作为训练样本,使用反向传播策略对步骤S3中构造的网络模型进行训练,最小化损失函数,得到优化后的网络权重；S5.测试模型,使用验证数据样本对训练好的网络模型进行测试,将验证图像输入网络模型,得到预测结果,与标签对比,判断网络是否具有较好适应性；其中,所述的图像混合具体包括以下步骤：A1.挑选图像a和图像b,其中图像b中包含有组织纹理倒影的器械；提取图a和图b标签颜色数量,其中单张图片的标签有多种颜色以区分不同的器械；A2.将图像b中的有倒影的器械裁剪下来,这个过程通过将带有倒影的器械图像的背景设为黑色(0,0,0)来得到；A3.用步骤A2得到的背景全黑的器械图对图像a进行覆盖,也就是两张图进行像素点相加,得到新图c；A4.将图b的图像标签覆盖到图a标签的对应位置,并根据颜色数量,为相应新器械的标签重新安排颜色,得到图c的标签；或,所述的图像混合具体包括以下步骤：B1.挑选图像a和图像b,提取图a和图b标签颜色数量；B2.对图像a的器械进行覆盖,包括：对图像进行旋转,有器械的部分被旋转后的图像取代；在旋转无法覆盖所有器械的情况下,用剩余有器械的部分附近的等大小区域进行覆盖,即为平移；B3.裁剪图b中的器械,将图b中的背景设为黑色(0,0,0)；B4.将除了器械之外背景全黑的图b与进行器械覆盖之后的图a进行图像相加,也就是对应的像素点相加,相加的时候对图b中器械部分的像素乘以一个系数transparency,而图a的相同部分则乘以1-transparency；相加之后图像得到新图c；图c在器械部分会有一定透明度,即能在器械上看到部分属于背景的图像,以此来模拟倒影；B5.为图c生成标签,由于图a的器械已被背景覆盖,所以图c的标签即为图b的器械标签。</td>   <td>G06T7/00;G06T7/136;G06V10/26;G06V10/774;G06V10/82;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              马琴;                   陈荣军       </td>   <td>中山大学</td>   <td>一种对模糊QR码快速去模糊的方法和系统</td>   <td>广东省</td>   <td>CN114792292A</td>   <td>2022-07-26</td>   <td>本发明提供一种对模糊QR码快速去模糊的方法和系统,涉及二维码去模糊领域。包括：S1、预处理；S2、设定最大去模糊层级max-scale,初始化模糊核函数；S3、构建第一目标函数和第二目标函数；S4、估计清晰图像；S5、估计模糊核函数；S6、如果达到max-scale,转到S11；否则转到S7；S7、如果检测到3个寻像图形,则转到S8；否则转到S9；S8、判断当前能否解码；是则转S11；否则转S9；S9、当前去模糊层级是否为max-scale–1；是则转S10；否则转S4；S10、获取图像清晰度评估值Q和阈值T,若Q＞T,则转S4；若Q＜T,则转S11；S11、输出去模糊QR码图像。在保证去模糊后的QR码图像识别率的前提下,提高了QR码图像去模糊的效率,高效准确地实现了对模糊QR码去模糊。</td>   <td>1.一种对模糊QR码快速去模糊的方法,其特征在于,包括步骤：S1、获取模糊QR码图像,并对模糊QR码图像进行预处理；S2、根据模糊QR码图像的模糊程度,设定最大去模糊层级max-scale,并初始化模糊核函数；S3、构建用于清晰图像估计的第一目标函数,以及用于模糊核函数估计的第二目标函数；S4、利用模糊QR码图像和当前的模糊核函数,以及第一目标函数,得到估计的清晰图像；S5、利用模糊QR码图像和估计的清晰图像,以及第二目标函数,得到估计的模糊核函数；S6、判断是否达到最大去模糊层级；如果达到最大去模糊层级,转到步骤S11；如果没有达到最大去模糊层级,转到步骤S7；S7、对当前层级去模糊QR码图像进行寻像图形检测,判断能检测到的寻像图形个数；如果检测到的寻像图形个数等于3,则转到步骤S8；否则转到步骤S9；S8、利用预解码模块进行解码判断,判断当前层级去模糊QR码图像能否解码；如果能够解码,则执行步骤S11；否则执行步骤S9；S9、判断当前去模糊层级是否为max-scale–1；如果是,执行步骤S10进行判断；如果否,返回重复执行步骤S4；S10、获取当前层级清晰图像的图像清晰度评估值为Q,与设定阈值T比较,从而快速判断清晰图像是否为不可处理图像；若Q＞T,则返回重复执行步骤S4；若Q＜T,则执行步骤S11；S11、输出最终去模糊QR码图像。</td>   <td>G06T5/00;G06T7/00;G06T3/00;G06K7/14;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张乐;                   胡建芳       </td>   <td>中山大学</td>   <td>基于人体骨架序列信息的人物动作视频生成方法、系统及存储介质</td>   <td>广东省</td>   <td>CN112419455B</td>   <td>2022-07-22</td>   <td>本发明公开了一种基于人体骨架序列信息的人物动作视频生成方法、系统及存储介质,所述方法包括以下步骤：利用生成器提取初始纹理特征和初始姿势特征；经转换模块转换成目标纹理特征和目标姿势特征；将目标纹理特征输入到时序模块进行修正并得到最终纹理特征表示；编码器对最终纹理特征表示进行解码得到目标图像；判别器判别生成图像的纹理和姿势并交替更新生成器和判别器。本发明利用时序模型来对人物动作视频的生成进行时序上的建模,通过学习一个视频前后不同帧之间的关联关系来提升图像质量,得到高仿真度的视频。</td>   <td>1.基于人体骨架序列信息的人物动作视频生成方法,其特征在于,利用生成器和判别器进行训练,所述生成器用于生成尽可能逼真的图像,所述判别器用于判别图像的真伪；交替更新所述生成器和判别器达到动态平衡；所述生成器的训练过程为：将第一输入部分和第二输入部分分别经编码器编码为初始纹理特征和初始姿势特征所述第一输入部分为原始图像,所述第二输入部分为初始和目标人体骨架序列热图的级联；将所述初始纹理特征和初始姿势特征输入生成器的纹理转换路径和姿势转换路径中并进行交互引导转换,得到目标纹理特征所述纹理转换路径和姿势转换路径的中间包含了多个转换模块；将多个所述目标纹理特征输入到时序模块中,并经时序模块修正后得到多帧的最终纹理特征表示；将多帧的最终纹理特征表示分别经过解码器进行解码,得到多帧的最终纹理特征对应的目标图像,最终生成动作视频；将生成器生成的多帧图像分别与视频第一帧图像组成图像对,输入到纹理判别器中,计算纹理判别器此时的输出与纹理判别器将某个样本判别为真的输出之间的误差损失,后向传播更新生成器；将生成器生成的多帧图像分别与目标人体骨架序列表示组合,输入到姿势判别器中,计算姿势判别器此时的输出与姿势判别器将某个样本判别为真的输出之间的误差损失,后向传播更新生成器；用生成器生成的多帧图像相应计算出损失函数中除GAN损失外的其他损失项并后向传播更新生成器；所述判别器的训练过程为：将视频的第一帧图像和某一帧的真实图像组成的图像对作为正样本,视频的第一帧图像和生成器生成的某一帧的图像组成的图像对作为负样本,输入到纹理判别器中计算误差损失,后向传播更新纹理判别器；将视频某一帧的真实图像与对应的人体骨架序列热图的串接作为正样本,生成器生成的视频某一帧图像与对应的人体骨架序列热图的串接作为负样本,输入到姿势判别器中计算误差损失,后向传播更新姿势判别器；所述交替更新生成器和判别器达到动态平衡具体为：在一次迭代中,生成器根据输入生成转换后的人物图像,将生成的图像分别和原图像和目标人体骨架序列表示进行组合,分别输入两个判别器计算得到对应的GAN损失项,利用生成的图像继续计算出生成器的所有损失项之后进行反向传播更新生成器参数；接着采用生成的图像分别和原图像和目标人体骨架序列表示组合作为负样本,结合以真实目标图像组合得到的正样本,分别输入到两个判别器中计算损失并反向传播更新判别器参数,提升判别器正确判别图像真伪的能力,在训练过程中交替更新生成器和判别器,最终达到动态平衡。</td>   <td>G06T13/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈翔;              朱佩敏;              郭志恒;              郭大杰;              王玺钧;              黄艳;                   张皓翔       </td>   <td>超讯通信股份有限公司;中山大学</td>   <td>信道估计模型的训练方法、信道估计方法、装置及设备</td>   <td>广东省</td>   <td>CN114781455A</td>   <td>2022-07-22</td>   <td>本公开提供了一种信道估计模型的训练方法、信道估计方法、装置及设备,训练方法包括：对所述原始信号进行采样和融合以得到样本信号；获取样本信号对应的自相关信号；确定样本信号的伪标签数据；基于样本信号、自相关信号、伪标签数据和预设的第一损失函数迭代训练初始信道估计模型,得到第一信道估计模型；基于样本信号、自相关信号和预设的第二损失函数迭代训练第一信道估计模型,得到目标信道估计模型。上述训练方法不再受限于传统方法中的相关信源和信道强假设的限制,还降低了训练成本；而且,使用了两个不同的训练过程对模型进行训练,并配置了不同的损失函数,确保了信道估计模型的准确性和稳定性。</td>   <td>1.一种信道估计模型的训练方法,包括：获取通过目标信道传输的原始信号,对所述原始信号进行采样和融合以得到样本信号,其中,所述原始信号包含多种类型的待估计信道参数；获取所述样本信号对应的自相关信号；确定所述样本信号的伪标签数据,其中,所述伪标签数据包括所述多种类型的待估计信道参数中的预设类型的待估计信道参数的期望值；基于所述样本信号、所述自相关信号、所述伪标签数据和预设的第一损失函数迭代训练初始信道估计模型,得到第一信道估计模型；其中,所述初始信道估计模型为预先构建的无监督神经网络模型,所述第一损失函数至少用于计算所述预设类型的待估计信道参数的期望值和估计值之间的差异结果；基于所述样本信号、所述自相关信号和预设的第二损失函数迭代训练所述第一信道估计模型,得到目标信道估计模型；其中,所述第二损失函数用于计算所有类型的待估计信道参数的实际值和估计值之间的融合差异结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何明光;                   施丹莉       </td>   <td>中山大学中山眼科中心</td>   <td>一种眼底彩照的视网膜动静脉及毛细血管自动标注方法</td>   <td>广东省</td>   <td>CN114782338A</td>   <td>2022-07-22</td>   <td>本发明提供了一种眼底彩照的视网膜动静脉及毛细血管自动标注方法,包括：采用来源于同一个的眼睛的匹配的眼底彩照和视网膜血管造影图像,首先基于视网膜血管造影图像提取全视网膜血管,将不同分期的视网膜血管造影图片与眼底彩照图片进行配准,使用荧光造影静脉期与动脉期显影的差异自动区分出动静脉,并且将眼底彩色照相与视网膜血管造影图像进行配准后,对眼底彩色照相中的血管特别是毛细血管进行完整的标注。本发明基于视网膜血管造影的图片,对眼底彩色照片的视网膜动静脉及毛细血管进行自动标注,该方法可以实现更准确、更快速和更完整地标注眼底彩色照相中的视网膜血管的轮廓和边界,同时具有区分视网膜动静脉的效果。</td>   <td>1.一种眼底彩照的视网膜动静脉及毛细血管自动标注方法,其特征在于,包括以下步骤：S1,根据来源于同一个眼睛的匹配的眼底彩照和视网膜血管造影图像,首先在视网膜血管造影图像中提取全视网膜血管,通过眼底造影静脉期与动脉期显影的差异,自动区分出动静脉；S2,将眼底彩色照相图像与视网膜血管造影图像进行配准,完成对眼底彩照中所有视网膜血管的轮廓和边界的完整标注,所述视网膜血管包括动静脉及毛细血管。</td>   <td>G06T7/00;G06T7/13;G06T7/11;G06T7/155;G06T7/33;G06T7/32;A61B5/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何明光;                   施丹莉       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于条件生成对抗网络的眼底彩照毛细血管标注方法</td>   <td>广东省</td>   <td>CN114782339A</td>   <td>2022-07-22</td>   <td>本发明提供了一种基于条件生成对抗网络的眼底彩照毛细血管标注方法,包括：以眼底彩色照相和相匹配的眼底荧光造影图像为基础,对眼底荧光血管造影图片提取包括视网膜毛细血管和大、中、小血管图；以提取的血管图为金标准训练生成对抗网络,使其以眼底彩照为输入,输出和金标准相似的血管图；模型完成训练,实现仅以眼底彩照作为输入,对其相应的血管结构进行预测,生成出包括视网膜毛细血管在内的所有血管的标注；对所标注的视网膜毛细血管进行分析测量。本发明将眼底荧光造影作为金标准,使用条件生成对抗网络,在眼底彩色照相中,自动产生视网膜毛细血管的标注,并使之达到与眼底荧光造影相同精度,同时实现视网膜毛细血管分析测量。</td>   <td>1.一种基于条件生成对抗网络的眼底彩照毛细血管标注方法,其特征在于,包括以下步骤：S1,以眼底彩色照相图像和相匹配的眼底荧光造影图像为基础,对眼底荧光造影的视网膜毛细血管图片进行提取；S2,使用条件生成对抗网络,以眼底荧光造影的视网膜毛细血管图片为金标准,生成包括视网膜毛细血管在内的血管网络模型；S3,基于血管网络模型,以眼底彩照作为输入,对血管结构进行预测,生成出包括视网膜毛细血管在内的所有血管的标注；S4,对所标注的视网膜毛细血管进行分析测量。</td>   <td>G06T7/00;G06T7/60;G06T7/62;G06T7/10;G06N3/04;A61B5/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢红宁;                   雷婷       </td>   <td>中山大学附属第一医院</td>   <td>基于卷积神经网络的胎儿超声关键切面识别方法及装置</td>   <td>广东省</td>   <td>CN114782407A</td>   <td>2022-07-22</td>   <td>本发明公开了一种基于卷积神经网络的胎儿超声关键切面识别方法及装置,其中该方法包括：获取包括有胎儿结构切面影像的原始超声图像数据；根据所述原始超声图像数据,确定目标超声图像数据；将所述目标超声图像数据输入训练好的分类卷积神经网络模型,得到切面类型分类结果；所述分类卷积神经网络模型为通过包括有多个标注有切面类型的训练超声图像数据的训练数据集训练得到。可见,本发明基于训练好的神经网络模型对超声图像数据中的切面信息进行准确地分类,有利于帮助医生快速对生物结构切面进行分类判断,提高检查效率,减少误诊漏诊率,同时还能促进医疗资源的有效利用,具有较大的实用价值。</td>   <td>1.一种基于卷积神经网络的胎儿超声关键切面识别方法,其特征在于,所述方法包括：获取包括有胎儿结构切面影像的原始超声图像数据；根据所述原始超声图像数据,确定目标超声图像数据；将所述目标超声图像数据输入训练好的分类卷积神经网络模型,得到切面类型分类结果；所述分类卷积神经网络模型为通过包括有多个标注有切面类型的训练超声图像数据的训练数据集训练得到。</td>   <td>G06T7/00;G06K9/62;G06N3/04;G06N3/08;G06T5/00;G16H30/40;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林桢哲;              林铎儒;              于珊珊;              林浩添;              梁小玲;                   赵欣予       </td>   <td>中山大学中山眼科中心</td>   <td>一种荧光素眼底血管造影图像的处理系统及装置</td>   <td>广东省</td>   <td>CN114782452A</td>   <td>2022-07-22</td>   <td>本申请属于计算机视觉技术领域,公开了一种荧光素眼底血管造影图像的处理系统及装置,该系统包括：图像预处理模块,用于获取待处理的荧光素眼底血管造影图像,并对荧光素眼底血管造影图像进行预处理；病变区域及病变区域内无灌注区分割模块,用于通过预先训练的语义分割模型对经过预处理的荧光素眼底血管造影图像进行处理,确定其中的病变区域和病变区域内的无灌注区；缺血指数计算模块,用于获取病变区域的面积值和无灌注区的面积值,并计算得到荧光素眼底血管造影图像对应的适用于临床的缺血指数。本申请可以达到分割荧光素眼底血管造影图像中的病变区域及病变区域中的无灌注区、实现病变量化以及适用于多种视网膜病变的效果。</td>   <td>1.一种荧光素眼底血管造影图像的处理系统,其特征在于,所述系统包括：图像预处理模块,用于获取待处理的荧光素眼底血管造影图像,并对所述荧光素眼底血管造影图像进行预处理,所述荧光素眼底血管造影图像为预设的多种视网膜病变中任一种视网膜病变的荧光素眼底血管造影图像；病变区域及病变区域内无灌注区分割模块,用于通过预先训练的语义分割模型对经过预处理的所述荧光素眼底血管造影图像进行处理,确定其中的病变区域和位于所述病变区域内的无灌注区,所述语义分割模型是基于所述多种视网膜病变分别对应的荧光素眼底血管造影图像训练而得到的；缺血指数计算模块,用于获取所述病变区域的面积值和所述无灌注区的面积值,并计算得到所述荧光素眼底血管造影图像对应的适用于临床的缺血指数。</td>   <td>G06T7/00;G06T7/62;G06V40/18;G06V10/26;G06V10/82;G06N3/04;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢红宁;                   雷婷       </td>   <td>中山大学附属第一医院</td>   <td>基于三维卷积神经网络胎儿颅脑超声结构分割方法及装置</td>   <td>广东省</td>   <td>CN114782457A</td>   <td>2022-07-22</td>   <td>本发明公开了一种基于三维卷积神经网络胎儿颅脑超声结构分割方法及装置,该方法包括：获取胎儿颅脑超声结构的原始容积数据；将胎儿颅脑超声结构的原始容积数据输入确定出的三维卷积神经网络分割模型中进行分析,并获取三维卷积神经网络分割模型输出的分析结果,作为胎儿颅脑超声结构的分割结果。可见,实施本发明能够利用三维卷积神经网络分割模型实现对胎儿颅脑超声结构的自动分割,有利于提高胎儿颅脑超声结构分割的准确率。</td>   <td>1.一种基于三维卷积神经网络胎儿颅脑超声结构分割方法,其特征在于,所述方法包括：获取胎儿颅脑超声结构的原始容积数据；将所述胎儿颅脑超声结构的原始容积数据输入确定出的三维卷积神经网络分割模型中进行分析,并获取所述三维卷积神经网络分割模型输出的分析结果,作为所述胎儿颅脑超声结构的分割结果。</td>   <td>G06T7/10;G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              谭宇帝;              周凡;                   王若梅       </td>   <td>中山大学</td>   <td>基于表面隐函数的单目图像着装人体重建方法与系统</td>   <td>广东省</td>   <td>CN114782634A</td>   <td>2022-07-22</td>   <td>本发明公开了一种基于表面隐函数的单目图像着装人体重建方法与系统。包括：获取高精度着装人体模型并进行渲染和表面采样,运用所述采样点构建训练集,提取所述渲染得到的着装人体图像的特征图和粗预测SMPL,将所述生成的SMPL体素化并使用三维卷积融合各部分的特征,得到三维空间下融合编码后的体素特征,获取给定查询点的混合局部特征,通过图卷积和交叉注意力获取空间中给定查询点的局部点云特征,训练和构建离散点占有率估算模型,生成着装人体模型。本发明具备对输入图像更好的保真性和细节恢复能力；设计的网络保证模型结构的鲁棒性,提高模型对人体图像与3D语义特征的感知和表达能力,并保证重建人体模型的完整性和细致程度,可视化效果更好。</td>   <td>1.一种基于表面隐函数的单目图像着装人体重建方法,其特征在于,所述方法包括：从数据集获取高精度着装人体模型,并在360度视角下渲染出360张着装人体图像；对所述数据集人体模型进行表面采样,并按照高斯分布对采样点延法线方向作偏移,为每个采样点设置人体内部和外部的标签数据,该部分采样点即对应训练集；通过神经网络获取所述着装人体图像的特征图,所述特征图的图像分辨率和所述着装人体图像保持一致；通过图卷积网络GCN获取针对所述着装人体图像的粗预测的基于蒙皮的参数化人体模型SMPL；将所述生成的SMPL体素化,得到三维体素空间的离散特征,对所述离散体素特征使用三维卷积融合各个部分的特征,最终得到三维空间下融合编码后的体素特征；对所述特征图的图像特征和所述三维空间下融合编码后的体素特征分别进行插值,拼接后得到给定查询点的混合局部特征；在所述SMPL粗预测模型的表面采样后进行图卷积,得到SMPL采样点融合特征图后的混合特征,再使用交叉注意力得到空间中给定查询点的局部点云特征；对所述给定查询点的混合局部特征和所述给定查询点的局部点云特征做拼接,得到最终的给定查询点的混合特征,输入到多层感知机MLP中得到给定查询点对于人体模型的占有概率,与标签值作差得到损失值,通过梯度下降类方法更新网络权重,使该损失迭代收敛至尽可能小,以此训练形成离散点占有率估算模型；设置一个单位立方体,在该单位立方体内部按用户设定的离散点分辨率设置均匀间隔分布的离散点,由所述离散点占有率估算模型得出所述离散点分辨率下所有离散点的占有率后,使用立方体匹配算法Marching Cube生成三角形面片网格模型得到最终的着装人体模型。</td>   <td>G06T17/00;G06T15/50;G06T7/593;G06V10/80;G06V10/82;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   陈泽鑫       </td>   <td>中山大学</td>   <td>一种面向出入库径流的水文情势变化分析方法</td>   <td>广东省</td>   <td>CN113077167B</td>   <td>2022-07-19</td>   <td>本发明为克服由于水库出入库流量的差异造成的水库上游和下游的水文情势变化影响河流实际水文情势变化研究的缺陷,提出一种面向出入库径流的水文情势变化分析方法,包括以下步骤：采集入库流量数据序列和出库流量数据序列,确定入库径流和出库径流的水文年；计算入库流量数据的IHA低流量与高流量所需的划分参数,以及入库流量数据的EFC划分参数；将所述IHA低流量与高流量所需的划分参数以及EFC划分参数应用于出库流量数据,分别计算入库径流和出库径流的IHA参数和EFC参数；根据所述入库径流和出库径流的IHA参数和EFC参数,采用IHA的变化范围法RVA对出入库径流的水文情势变化进行分析。</td>   <td>1.一种面向出入库径流的水文情势变化分析方法,其特征在于,包括以下步骤：采集入库流量数据序列和出库流量数据序列,确定入库径流和出库径流的水文年；计算入库流量数据的IHA低流量与高流量所需的划分参数,以及入库流量数据的EFC划分参数；将所述IHA低流量与高流量所需的划分参数以及EFC划分参数应用于出库流量数据,分别计算入库径流和出库径流的IHA参数和EFC参数；根据所述入库径流和出库径流的IHA参数和EFC参数,采用IHA的变化范围法RVA对出入库径流的水文情势变化进行分析。</td>   <td>G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李智洪;                   陶钧       </td>   <td>中山大学</td>   <td>一种基于深度学习的流场区域识别系统及方法</td>   <td>广东省</td>   <td>CN114757276A</td>   <td>2022-07-15</td>   <td>本发明公开了一种基于深度学习的流场区域识别系统及方法,系统包括：流场特征获取模块,对流场数据进行区域采样,并计算一系列采样点组的距离矩阵作为特征网络的输入；特征网络训练模块,用网络产生能够表征流场流动模式的隐向量；可视化界面模块,结合隐向量流场中寻找可能的流动模式。本发明结合了局部区域内的多条流线,从单条流线扩展到多条流线,从而可以识别以局部区域为基本单位的流场模式,因此,对于同样的场景,我们的方法能产生识别更多的流场模式。</td>   <td>1.一种基于深度学习的流场区域识别系统,包括：流场特征获取模块,对流场数据进行区域采样,并计算一系列采样点组的距离矩阵作为特征网络的输入；特征网络训练模块,用网络产生能够表征流场流动模式的隐向量；可视化界面模块,结合隐向量流场中寻找可能的流动模式。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;              罗颖;              蔡绮雯;              赵慧玲;              陈佳伟;                   黄炫超       </td>   <td>中山大学</td>   <td>一种基于定额法的需水预测方法及系统</td>   <td>广东省</td>   <td>CN114757416A</td>   <td>2022-07-15</td>   <td>本发明公开了一种基于定额法的需水预测方法,该方法包括：获取研究区域的需水项目历史统计数据,其中需水项目划分为河道内需水项目和河道外需水项目,根据河道内需水项目历史统计数据建立相应的数据指标,根据数据指标对应数据的特征,选取数学模型计算数据指标的预测值；根据河道外需水项目对应数据的特征,选取数学模型计算河道外需水项目的需水总量预测值；根据河道内需水项目的数据指标的预测值以及河道外需水项目的需水总量预测值,结合相应数据指标的用水净定额,计算得到规划水平年区域需水总量预测值；另外本发明还提供一种应用上述基于定额法的需水预测方法的系统；本发明能有效利用区域用水历史数据,计算结果具有实际应用价值。</td>   <td>1.一种基于定额法的需水预测方法,其特征在于,包括以下步骤：S1：获取研究区域的需水项目历史统计数据,其中需水项目划分为河道内需水项目和河道外需水项目,根据河道内需水项目历史统计数据建立相应的数据指标；S2：结合步骤S1所述的需水项目历史统计数据,根据河道内需水项目的数据指标对应数据的统计特征,选取相应的数学模型计算数据指标的预测值；根据河道外需水项目对应数据的统计特征,选取相应的数学模型计算河道外需水项目的需水总量预测值；S3：根据步骤S2所述的河道内需水项目的数据指标的预测值以及河道外需水项目的需水总量预测值,结合相应数据指标的用水净定额,计算得到规划水平年区域需水总量预测值。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李明;                   邹小兵       </td>   <td>昆山杜克大学;中山大学附属第三医院(中山大学肝脏病医院)</td>   <td>语音韵律异常评估方法、装置、计算机设备和存储介质</td>   <td>江苏省</td>   <td>CN109448758B</td>   <td>2022-07-12</td>   <td>本申请涉及一种孤独症语音韵律异常评估方法、装置、计算机设备和存储介质。所述方法包括：录音采集语音测试数据；提取所述语音测试数据中被测试者的语音数据,并进行语音片段划分；选出测试数据中对评估有效的语音片段；提取所述有效语音片段中的频谱特征；采用得出的评估模型对所述频谱特征进行评估。采用本方法能够能够提供客观的语音韵律异常自动量化评分,能够有效地增加诊断的客观性以及便捷性。</td>   <td>1.一种孤独症语音韵律异常评估方法,其特征在于,包括：录音采集语音测试数据；提取所述语音测试数据中被测试者的语音数据,并进行语音片段划分；选出测试数据中对评估有效的语音片段；提取所述有效语音片段中的频谱特征；采用得出的评估模型对所述频谱特征进行评估；利用交叉验证和特征分类器从所述语音片段中选出被评估者语音训练数据中对评估有效的语音片段,包括采用弃一交叉验证：从训练数据中选出一个被评估者的语音片段,剩下的训练数据训练一个分类模型用以预测所述的语音片段的韵律异常的量化得分；训练完成之后,被选中的被评估者的语音片段在所述分类模型上进行预测,得到语音片段对于语音韵律异常检测“有效”或者“无效”的预测标签,其中“有效”表示韵律异常的量化得分预测正确,“无效”表示韵律异常的量化得分预测错误；通过交叉验证得到训练数据上所有语音片段的“有效”或者“无效”的标签后,训练一个特征分类器,对所有训练数据语音片段的句子层面的特征进行“有效”或者“无效”的分类；选出测试数据中对评估有效的语音片段,包括：将测试数据语音片段句子层面的特征通过所述特征分类器进行分类,判断各所述语音片段对于语音韵律异常检测“有效”或“无效”。</td>   <td>G10L25/66;G10L25/63;G10L25/12;G10L15/01;G10L15/04;G10L15/06;G10L15/10;G10L15/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张益强;              袁均良;              骆伟祺;                   叶玮材       </td>   <td>中山大学</td>   <td>一种面向微服务的金融回测容错系统及方法</td>   <td>广东省</td>   <td>CN112819640B</td>   <td>2022-07-12</td>   <td>本发明提出一种面向微服务的金融回测容错系统及方法,涉及金融量化回测的技术领域,解决了当前金融回测出现错误时,仅以宏观的容器状态数据为判定标准,无法正确定位出错位置的问题,数据获取模块获取金融市场行情数据,数据库模块存储数据,回测模块运行回测任务,金融回测任务运行失败时容错模块采用宏观的容器状态信息和回测模块返回的错误代码相结合的办法,根据金融回测系统的数据链路来回推定位出错的位置,并输出错误恢复方法,并通过日志告警模块将容错模块不能恢复的金融回测任务运行错误信息录入日志,向管理人员发出告警通知,避免了多次无意义的重试,保证了金融回测容错系统的正确性。</td>   <td>1.一种面向微服务的金融回测容错系统,其特征在于,所述金融回测容错系统用于运行量化策略的金融回测任务,系统包括：数据获取模块,用于从金融数据提供方获取金融市场行情数据,并写入数据库模块中；数据库模块,对金融市场行情数据进行持久化存储；回测模块,从数据库模块中获取金融市场行情数据,运行金融回测任务,并在金融回测任务运行失败时,根据不同的错误现象返回不同的错误代码；容错模块,包括恢复判断单元及日志告警模块,用于实时监控采集数据获取模块、数据库模块及回测模块的容器状态信息,在金融回测任务运行失败时,根据数据获取模块、数据库模块及回测模块的容器状态信息,及回测模块返回的错误代码,分层次定义分类金融回测任务中出现的错误,形成错误处理列表,定位出错的位置,并输出错误恢复方法,通过恢复判断单元判断金融回测任务运行错误是否恢复,通过日志告警模块记录不能恢复的金融回测任务运行错误信息,并向管理人员发出金融回测任务运行失败告警通知日志告警模块,用于记录容错模块不能恢复的金融回测任务运行错误信息,并向管理人员发出任金融回测任务运行失败告警通知。</td>   <td>G06Q40/06;G06Q40/04;G06F16/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李秋萍;              梁燊;              马若飞;                   周素红       </td>   <td>中山大学</td>   <td>一种驾驶人交通安全风险评价与人车伴随分析方法及系统</td>   <td>广东省</td>   <td>CN114742293A</td>   <td>2022-07-12</td>   <td>本发明公开了一种驾驶人交通安全风险评价与人车伴随分析方法及系统,该方法包括：建立驾驶人交通安全风险评估指标,得到驾驶人多维度特征；获取训练数据集并基于驾驶人多维度特征对神经网络进行训练,得到风险评估模型；基于风险评估模型对待测数据进行评估,得到高风险人员；对区域内卡口数据和高风险人员手机轨迹数据进行数据清洗,得到高风险人车多源轨迹；基于时间和空间的制约对高风险人车多源轨迹进行相似度评价,判定驾驶人的人车伴随关系。该系统包括：特征提取模块、模型训练模块、预测模块、多源轨迹清洗模块和人车伴随研判模块。通过使用本发明,能够根据驾驶人交通安全风险等级指导分级管控。</td>   <td>1.一种驾驶人交通安全风险评价与人车伴随分析方法,其特征在于,包括以下步骤：建立驾驶人交通安全风险评估指标,得到驾驶人多维度特征；获取训练数据集并基于驾驶人多维度特征对神经网络进行训练,得到风险评估模型；基于风险评估模型对待测数据进行评估,得到高风险人员；对区域内卡口数据和高风险人员手机轨迹数据进行数据清洗,得到高风险人车多源轨迹数据；基于时间和空间的制约对高风险人车多源轨迹数据进行相似度评价,判定驾驶人的人车伴随关系。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/26;G06F16/2458;G06F16/9537;G06K9/62;G06N3/04;G06N3/08;G08G1/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;                   王和旭       </td>   <td>中山大学</td>   <td>一种波浪要素预测方法及系统</td>   <td>广东省</td>   <td>CN114742307A</td>   <td>2022-07-12</td>   <td>本发明公开了一种波浪要素预测方法及系统,方法包括：获取风场信息；根据所述风场信息进行预先预测来对初始模型进行优化验证,得到集合预测模型；根据所述集合预测模型进行正式预测,得到预测序列值；对所述预测序列值进行检验,确定满足验证要求的预测结果；通过SOM机器学习对所述预测结果进行预测结果分类处理,得到不同精度的预测模型集合；从所述精度预测模型集合中选取目标精度预测模型,将所述目标精度预测模型的预测结果加上修正值作为输出波浪要素最终预测结果；其中,所述波浪要素预测结果包括但不限于有效波高数据、波峰周期数据以及波向数据。本发明的误差小且预测效果好,可广泛应用于数据处理技术领域。</td>   <td>1.一种波浪要素预测方法,其特征在于,包括：获取风场信息；根据所述风场信息进行预先预测来对初始模型进行优化验证,得到集合预测模型；根据所述集合预测模型进行正式预测,得到预测序列值；对所述预测序列值进行检验,确定满足验证要求的预测结果；通过SOM机器学习对所述预测结果进行预测结果分类处理,得到不同精度的预测模型集合；从所述精度预测模型集合中选取目标精度预测模型,将所述目标精度预测模型的预测结果加上修正值作为输出波浪要素最终预测结果；其中,所述波浪要素预测结果包括但不限于有效波高数据、波峰周期数据以及波向数据。</td>   <td>G06Q10/04;G06Q50/06;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         由林麟;              贺俊姝;              陈坤旭;                   何家琪       </td>   <td>中山大学</td>   <td>一种面向隐私保护的联邦个性化出行服务管理方法及系统</td>   <td>广东省</td>   <td>CN114742308A</td>   <td>2022-07-12</td>   <td>本发明公开了一种面向隐私保护的联邦个性化出行服务管理方法及系统,系统包括基础数据层、业务响应层、实时数据层、辅助训练层以及用户交互层,能够完成出行者的出行任务,并提供用户操作的可视化界面以及数据结果的可视化界面。本发明能够基于联邦学习的方式,辅助系统训练出不同用户的出行模型,在保护用户隐私的前提下,为出行者提供个性化出行方案,可广泛应用于出行信息处理技术领域。</td>   <td>1.一种面向隐私保护的联邦个性化出行服务管理方法,其特征在于,包括：获取个性化出行服务系统运行的所需数据以及生成数据；响应于用户的出行请求,根据所述出行请求采用联邦学习方法确定出行信息和出行方案；实时收集相关道路的交通信息,对出行优化模型进行训练；根据所述出行信息,通过联邦学习对所述出行优化模型进行训练和更新；获取个性化出行服务系统与出行者的交互信息,响应于出行者发出的出行请求以及出行方案的选择指令,完成出行者的出行任务,并提供用户操作的可视化界面以及数据结果的可视化界面。</td>   <td>G06Q10/04;G06Q10/06;G06F21/62;G06F3/0481;G06F3/0484;G06F16/242;G06F16/26;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘家夫;                   王紫宸       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的水下图像增强方法</td>   <td>广东省</td>   <td>CN114742736A</td>   <td>2022-07-12</td>   <td>本发明公开了一种基于生成对抗网络的水下图像增强方法,具体包括以下步骤：S1、首先通过高清摄像模块在水下进行拍摄,通过补光模块在拍摄图像时提供补光功能,通过水下图像获取模块获取拍摄后的水下图像；S2、然后将图像发送至中央处理系统,中央处理系统接收后则将其图像发送至存储单元内部的原始图像库进行保存,并由标记模块对原始图像进行标号处理；本发明涉及水下图像增强技术领域。该基于生成对抗网络的水下图像增强方法,基于生成式对抗网络能够提升低质量水下图像的细节清晰度和色彩保真度,复原水下真实场景,从而提高水下图像复原的准确性和效率,提高了水下图像增强处理效果,为后续图像的使用创造了良好条件。</td>   <td>1.一种基于生成对抗网络的水下图像增强方法,其特征在于：具体包括以下步骤：S1、首先通过高清摄像模块在水下进行拍摄,通过补光模块在拍摄图像时提供补光功能,通过水下图像获取模块获取拍摄后的水下图像；S2、然后将图像发送至中央处理系统,中央处理系统接收后则将其图像发送至存储单元内部的原始图像库进行保存,并由标记模块对原始图像进行标号处理；S3、中央处理系统将图像发送至图像增强系统,在图像增强系统内部通过暗通道先验处理模块对待处理的水下图像进行去雾处理,通过拉伸处理模块对去雾处理后的水下图像进行直方图拉伸；S4、通过清晰度处理模块对拉伸后的图像进行清晰度处理,清晰度处理包括对比度增强,最后通过色彩矫正模块利用灰度世界算法对图像进行颜色矫正,最终得到增强后的水下图像；S5、将增强后的水下图像发送至存储单元内部的后处理库进行保存,且通过标记模块对增强后的水下图像进行标记,该标记与对应原始水下图像标记相同,人员需要查看指定标记的水下图像时,则通过检索提取模块对存储单元内部的图像数据进行检索提取,通过对比报告制作模块将该标记的原始图像以及增强后的图像进行对比且制作成报告,报告制作后则通过无线传输模块发送至显示终端显示出来即可。</td>   <td>G06T5/00;G06T5/40;G06F16/58;G06F16/538</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王伟;              施皓然;              周永坤;              饶彬;                   王涛       </td>   <td>中山大学</td>   <td>基于卷积块注意力的雷达个体辐射识别方法、系统及介质</td>   <td>广东省</td>   <td>CN114742091A</td>   <td>2022-07-12</td>   <td>本发明公开了一种基于卷积块注意力的雷达个体辐射识别方法、系统及介质,方法包括：构建卷积块注意力关系网络,卷积块注意力关系网络包括特征提取网络、卷积块注意力模块和相似网络；获取训练数据集,根据训练数据集训练卷积块注意力关系网络；向训练完成的卷积块注意力关系网络输入目标数据集,得到关系分数向量,目标数据集包括支撑集和查询集；根据关系分数向量,确定目标数据集的数据类型,完成雷达个体辐射源识别。本发明通过在关系网络中引入卷积块注意力模块,指导网络关注更关键的区域,增强了网络的特征提取能力,使得网络在低信噪比下仍能有较好的性能,可广泛应用于辐射源识别技术领域。</td>   <td>1.一种基于卷积块注意力的雷达个体辐射识别方法,其特征在于,包括：构建卷积块注意力关系网络,所述卷积块注意力关系网络包括特征提取网络、卷积块注意力模块和相似网络；获取训练数据集,根据所述训练数据集训练所述卷积块注意力关系网络；向训练完成的卷积块注意力关系网络输入目标数据集,得到关系分数向量,所述目标数据集包括支撑集和查询集；其中,所述支撑集用于表征标注数据,所述查询集用于表征待识别数据；根据所述关系分数向量,确定所述目标数据集的数据类型,完成雷达个体辐射源识别。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08;G01S7/41</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李茁;                   马宇       </td>   <td>中山大学</td>   <td>一种本征正交分解样本压缩方法、装置及存储介质</td>   <td>广东省</td>   <td>CN114742171A</td>   <td>2022-07-12</td>   <td>本发明公开了一种本征正交分解样本压缩方法、装置及存储介质。该方法包括：对本征正交分解原始样本内的所有元素进行两两组合,得到若干个元素组合,并分别计算每一元素组合的堆芯三维功率分布相似性,得到所有元素组合的堆芯三维功率分布相似性；遍历本征正交分解原始样本内除了第一个元素的其余元素,从当前元素所属的所有元素组合中选择目标元素组合,并根据目标元素组合的堆芯三维功率分布相似性与预设阈值的比较结果,选择保留或舍弃当前元素,得到本征正交分解原始样本内的所有保留元素；整理本征正交分解原始样本内的第一个元素和所有保留元素,得到本征正交分解压缩样本。本发明能够进一步提高堆芯功率在线重构的计算速度和计算精度。</td>   <td>1.一种本征正交分解样本压缩方法,其特征在于,包括：对本征正交分解原始样本内的所有元素进行两两组合,得到若干个元素组合,并分别计算每一所述元素组合的堆芯三维功率分布相似性,得到所有所述元素组合的堆芯三维功率分布相似性；遍历所述本征正交分解原始样本内除了第一个元素的其余元素,从当前元素所属的所有元素组合中选择目标元素组合,并根据所述目标元素组合的堆芯三维功率分布相似性与预设阈值的比较结果,选择保留或舍弃所述当前元素,得到所述本征正交分解原始样本内的所有保留元素；整理所述本征正交分解原始样本内的第一个元素和所有保留元素,得到本征正交分解压缩样本。</td>   <td>G06K9/62;G06F30/20;G06F119/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              张填峰;                   陈荣军       </td>   <td>中山大学</td>   <td>一种双阶二维码的防伪认证方法和系统</td>   <td>广东省</td>   <td>CN114742189A</td>   <td>2022-07-12</td>   <td>本发明公开了一种双阶二维码的防伪认证方法和系统,涉及多媒体图像安全防伪的技术领域,包括：根据现有纹理图案集生成双阶二维码；对双阶二维码进行两次打印和扫描,获得第一数据和第二数据后,对其进行纹理分类,并计算分类结果的Tamura粗糙度；根据分类结果的Tamura粗糙度计算认证阈值；扫描待认证的双阶二维码,计算待认证双阶二维码的Tamura粗糙度均值；将待认证双阶二维码的Tamura粗糙度均值与认证阈值进行比较,完成防伪认证。本发明利用纹理图案的Tamura粗糙度计算双阶二维码的认证阈值,更好的反映出打印扫描过程中产生的信息损失,避免了阈值偏差大的缺陷,有效提高了双阶二维码防伪认证的准确性与鲁棒性。</td>   <td>1.一种双阶二维码的防伪认证方法,其特征在于,包括：S1：根据现有纹理图案集生成双阶二维码；S2：对双阶二维码进行两次打印和扫描,获得第一数据和第二数据；S3：对第一数据和第二数据进行纹理分类,并计算分类结果的Tamura粗糙度；S4：根据分类结果的Tamura粗糙度计算认证阈值；S5：扫描待认证的双阶二维码,提取其纹理图案,计算待认证双阶二维码的Tamura粗糙度均值；S6：将待认证双阶二维码的Tamura粗糙度均值与认证阈值进行比较,完成防伪认证。</td>   <td>G06K19/06;G06K9/62;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              金佳霖;                   陈荣军       </td>   <td>中山大学</td>   <td>一种可视化二维码编码方法和系统</td>   <td>广东省</td>   <td>CN114742190A</td>   <td>2022-07-12</td>   <td>本发明提供了一种可视化二维码编码方法和系统,涉及二维码可视化技术领域。所述方法包括：S1确定初始信息和初始载体图像；S2初始信息编码为信息比特流,调整初始载体图像尺寸；S3计算第一色度第一饱和度和第一亮度,提取第一蓝色通道；S4根据信息比特流对第一蓝色通道进行调制,得到第二蓝色通道；S5根据第一色度第一饱和度第二蓝色通道,得到第二编码图像的RGB值；S6用第一亮度替换第二亮度,再转换回RGB空间,用第二蓝色通道替换第三蓝色通道,得到最终编码图像；S7嵌入定位图形,得到可视化二维码。通过保留原始图像的观感,明显提升二维条码的美观程度,并且适用于任意载体图像。</td>   <td>1.一种可视化二维码编码方法,其特征在于,包括步骤：S1、确定用于生成二维码的初始信息以及初始载体图像；S2、对初始信息进行编码得到信息比特流,根据信息比特流确定初始载体图像所需的尺寸,将初始载体图像缩放为已确定的尺寸；S3、计算初始载体图像的第一色度、第一饱和度和第一亮度,提取初始载体图像的第一蓝色通道；S4、将第一蓝色通道划分为若干个编码区域,对编码区域进行二阶小波变换和奇异值分解得到奇异值,根据比特映射规则和信息比特流对第一蓝色通道的奇异值进行调制,然后对经过奇异值调制的第一蓝色通道依次进行反变换和线性变换得到第二蓝色通道,从而实现初始信息嵌入初始载体图像；S5、根据第二蓝色通道以及第一色度和第一饱和度,得到第二编码图像；S6、计算第二编码图像的第二色度、第二饱和度和第二亮度,用第一亮度替换第二亮度得到第三编码图像,再将第三编码图像转换回RGB空间得到第三红色通道,第三绿色通道和第三蓝色通道,用第二蓝色通道替换第三蓝色通道,得到最终编码图像；S7、在最终编码图像的第二蓝色通道中嵌入定位图形,得到可视化二维码。</td>   <td>G06K19/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐世友;              张轩铭;              胡俊;                   陈曾平       </td>   <td>中山大学</td>   <td>基于数据混合的深度学习模型样本处理方法、训练方法、装置和存储介质</td>   <td>广东省</td>   <td>CN114742232A</td>   <td>2022-07-12</td>   <td>本发明公开了一种基于数据混合的深度学习模型样本处理方法、训练方法、装置和存储介质,深度学习模型样本处理方法包括获取原始输入图像、标签信息和多个攻击算法,使用攻击算法对原始输入图像进行攻击获得对抗样本,对对抗样本进行软化获得软化样本,对各软化样本进行融合获得融合样本,对标签信息进行软化获得软化标签等步骤。本发明处理得到的融合样本集成了混合类型的攻击或者其他新类型的攻击等多样化的攻击,使用融合样本训练得到的深度学习模型具有更强的鲁棒性和更平滑,在实际使用时能够适应复杂的攻击环境,有利于在保持原先准确率基本不变的情况下,更好地防御和抵抗攻击,从而提高安全性。本发明广泛应用于深度学习技术领域。</td>   <td>1.一种基于数据混合的深度学习模型样本处理方法,其特征在于,所述基于数据混合的深度学习模型样本处理方法包括：获取原始输入图像以及相应的标签信息；选择多个攻击算法；分别使用各所述攻击算法对所述原始输入图像进行攻击,获得多个对抗样本；其中,每个所述攻击算法对所述原始输入图像进行的攻击,获得一个所述对抗样本；分别对各所述对抗样本进行软化,获得多个软化样本；其中,对一个所述对抗样本进行软化,获得一个所述软化样本；对各所述软化样本进行融合,获得融合样本；对所述标签信息进行软化,获得软化标签。</td>   <td>G06N20/00;G06K9/62;G06V10/74;G06V10/80;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              杨豫婷;                   陈荣军       </td>   <td>中山大学</td>   <td>一种新型二维码的快速检测方法和系统</td>   <td>广东省</td>   <td>CN114742787A</td>   <td>2022-07-12</td>   <td>本发明公开了一种新型二维码的快速检测方法和系统,涉及二维码应用的技术领域,包括：获取模糊的BR码原始图像,包括定位图案,格式信息和数据带；对BR码原始图像进行预处理,获得预处理图像；对预处理图像进行形态学运算,获得形态学图像；对形态学图像进行边缘提取,获得连通域轮廓及其像素坐标；根据连通域轮廓像素坐标判断相应的连通域轮廓的圆度,保留具有圆形特征的连通域轮廓；在预处理图像中提取被保留的连通域轮廓对应的对象；在提取出的对象中确定定位图案,获得版本信息；利用版本信息进行解码,获得BR码原始图像中储存的数据,完成检测过程。本发明可以在模糊场景下,快速定位并识别出二维码,获得其中储存的数据。</td>   <td>1.一种新型二维码的快速检测方法,其特征在于,包括：S1：获取模糊的BR码原始图像,所述BR码原始图像包括定位图案,格式信息和数据带；所述定位图案由模糊不变图形组成,所述格式信息储存于定位图案的模糊不变特征中,所述定位图案间的区域为数据带,数据带用于储存数据；S2：对BR码原始图像进行预处理,获得预处理图像；S3：对预处理图像进行形态学运算,获得形态学图像；S4：对形态学图像进行边缘提取,获得连通域轮廓及其像素坐标；S5：根据连通域轮廓像素坐标判断相应的连通域轮廓的圆度,保留具有圆形特征的连通域轮廓；S6：根据被保留的具有圆形特征的连通域轮廓,在步骤S2获取的预处理图像中提取所述连通域轮廓对应的对象；S7：在提取出的对象中确定定位图案,获得版本信息；S8：利用版本信息进行解码,获得BR码原始图像中储存的数据,完成检测过程。</td>   <td>G06T7/00;G06T7/13;G06T7/187;G06T3/00;G06T7/73;G06V10/46;G06K7/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张磊;              刘志博;              谢鹏飞;                   胡俊       </td>   <td>中山大学</td>   <td>一种视频SAR多目标跟踪方法、装置及介质</td>   <td>广东省</td>   <td>CN114742861A</td>   <td>2022-07-12</td>   <td>本发明公开了一种视频SAR多目标跟踪方法、装置及存储介质,该方法先对视频SAR的每一帧图像进行图像配准,然后将配准后的每一帧图像输入训练好的深度神经网络中进行动目标阴影检测,能够得到高质量的检测结果,即能够精确地检测出各帧中动目标阴影位置,虚警率和漏警率较低；最后根据检测结果,使用航迹管理和全局最近邻数据关联方法进行视频SAR的多目标跟踪。本发明能够准确地对输入的视频SAR的目标进行跟踪,其跟踪产生的航迹连续、平滑,与目标的真实运动轨迹接近,具有良好的跟踪效果。本发明可广泛应用于雷达信号处理技术领域。</td>   <td>1.一种视频SAR多目标跟踪方法,其特征在于,包括：将视频SAR的每一帧图像进行图像配准；将配准后的视频SAR的每一帧图像输入训练好的深度神经网络中进行动目标阴影检测,得到检测结果；根据所述检测结果,使用航迹管理和全局最近邻数据关联方法进行视频SAR的多目标跟踪。</td>   <td>G06T7/246;G06T7/73;G06T7/33;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈刚;              赵埔田;                   孟海涛       </td>   <td>中山大学</td>   <td>基于多尺度特征提取和自适应聚合的双目立体匹配方法</td>   <td>广东省</td>   <td>CN114742875A</td>   <td>2022-07-12</td>   <td>本发明公开了基于多尺度特征提取和自适应聚合的双目立体匹配方法,包括：获取双目相机的左图和右图；对所述左图和所述右图进行多尺度特征提取,得到所述左图和所述右图在多个分辨率上的特征矩阵；计算所述特征矩阵对应的代价矩阵；将不同的所述代价矩阵进行代价聚合,融合不同尺度下和局部区域内的信息得到代价聚合值；根据所述相邻像素的代价聚合值,获取粗视差图；对所述粗视差图进行优化,得到双目立体匹配的目标视差图。本发明提高了效率和精度,可广泛应用于图像处理技术领域。</td>   <td>1.基于多尺度特征提取和自适应聚合的双目立体匹配方法,其特征在于,包括：获取双目相机的左图和右图；对所述左图和所述右图进行多尺度特征提取,得到所述左图和所述右图在多个分辨率上的特征矩阵；计算所述特征矩阵对应的代价矩阵；将不同的所述代价矩阵进行代价聚合,融合不同尺度下和局部区域内的信息得到代价聚合值；根据所述相邻像素的代价聚合值,获取粗视差图；对所述粗视差图进行优化,得到双目立体匹配的目标视差图。</td>   <td>G06T7/593;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王天星;              程文杰;                   冼宇阳       </td>   <td>中山大学</td>   <td>一种山区地表辐射量的地形校正方法</td>   <td>广东省</td>   <td>CN114742879A</td>   <td>2022-07-12</td>   <td>本申请属于遥感数据处理技术领域,具体涉及一种山区地表辐射量的地形校正方法,包括：S10、获取同期的平面地表辐射数据,所述平面地表辐射数据包括平面地表的短波辐射数据和/或长波辐射数据；S20、将所述平面地表辐射数据输入到预先建立的山区辐射量校正模型中,得到山区地表辐射量；其中,所述山区辐射量校正模型是通过预设的辐射校正系数对平面地表的辐射量进行校正后输出山区地表辐射量的数学模型；所述辐射校正系数基于像元面积和其对应的山区表面积确定。通过本申请的校正方法对山区辐射量进行校正,不仅计算量小、效率高,而且得到的辐射校正结果更加准确。</td>   <td>1.一种山区地表辐射量的地形校正方法,其特征在于,该方法包括：S10、获取同期的平面地表辐射数据,所述平面地表辐射数据包括平面地表的短波辐射数据和/或长波辐射数据；S20、将所述平面地表辐射数据输入到预先建立的山区辐射量校正模型中,得到山区地表辐射量；其中,所述山区辐射量校正模型是通过预设的辐射校正系数对平面地表的辐射量进行校正后输出山区地表辐射量的数学模型；所述辐射校正系数基于像元面积和其对应的山区表面积确定。</td>   <td>G06T7/62;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孔阳;              朱奕霖;              徐世友;                   成慧       </td>   <td>中山大学</td>   <td>一种激光雷达和相机的联合标定方法及系统</td>   <td>广东省</td>   <td>CN114742898A</td>   <td>2022-07-12</td>   <td>本发明属于传感器联合标定技术领域,更具体地,涉及一种激光雷达点云数据中的标定板角点提取方法,包括：提取点云数据中标定板的边缘点；对边缘点聚类,并对得到的聚类进行筛选得到初始聚类,记为潜在标定板对象；对潜在标定板对象进行降噪得到降噪后潜在标定板对象；将降噪后潜在标定板对象投影到平面,并结合标定板真实面积对初始聚类进一步筛选,得到目标聚类；通过直线拟合算法对目标聚类的边缘进行直线拟合得到多根边缘线,求解出多根边缘线的交点,得到标定板角点。本发明的角点提取精度更高,使得激光雷达与相机的联合标定更可靠。</td>   <td>1.一种激光雷达点云数据中的标定板角点提取方法,其特征在于,包括以下步骤：提取点云数据中标定板的边缘点；对边缘点聚类,并对得到的聚类进行筛选得到初始聚类,记为潜在标定板对象；对潜在标定板对象进行降噪得到降噪后潜在标定板对象；将降噪后潜在标定板对象投影到平面,并结合标定板真实面积对初始聚类进一步筛选,得到目标聚类；通过直线拟合算法对目标聚类的边缘进行直线拟合得到多根边缘线,求解出多根边缘线的交点,得到标定板角点。</td>   <td>G06T7/80;G06T7/13;G06T5/00;G06T7/62;G06V10/762;G06K9/62;G01S7/497</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄承赓;              韩瑜;              温建棋;              门昌昊;                   刘梓阳       </td>   <td>中山大学</td>   <td>一种基于对抗迁移学习的轴承跨工况故障预测方法</td>   <td>广东省</td>   <td>CN114722879A</td>   <td>2022-07-08</td>   <td>本发明公开了一种基于对抗迁移学习的轴承跨工况故障预测方法,该方法包括：设定不同工况并对轴承进行信号采集,得到振动信号；基于峰值度量的连续异常点检测方法,对振动信号进行识别,得到健康阶段信号和退化阶段信号；对退化阶段信号进行预处理和故障特征提取,得到故障特征集；将故障特征集输入至域对抗迁移学习双分支神经网络并进行更新训练,得到预测模型；获取待测数据并输入至预测模型,得到故障预测结果。通过使用本发明,实现了面向实际工况特征的大型风机齿轮箱高速轴滚珠轴承在不同工况下的准确寿命预测。本发明作为一种基于对抗迁移学习的轴承跨工况故障预测方法,可广泛应用于工程部件寿命预测领域。</td>   <td>1.一种基于对抗迁移学习的轴承跨工况故障预测方法,其特征在于,包括以下步骤：设定不同工况并对轴承进行信号采集,得到振动信号；基于峰值度量的连续异常点检测方法,对振动信号进行识别,得到健康阶段信号和退化阶段信号；对退化阶段信号进行预处理和故障特征提取,得到故障特征集；将故障特征集输入至域对抗迁移学习双分支神经网络并进行更新训练,得到预测模型；获取待测数据并输入至预测模型,得到故障预测结果。</td>   <td>G06K9/00;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋丹明;              郑伟诗;                   孙伟       </td>   <td>中山大学</td>   <td>基于自监督学习的无标注视频哈希检索方法及装置</td>   <td>广东省</td>   <td>CN114722902A</td>   <td>2022-07-08</td>   <td>本发明公开了一种基于自监督学习的无标注视频哈希检索方法及装置,方法为：获取视频帧数据集并划分为训练数据集及测试集,对训练数据集进行数据增强,得到增强后的数据集；建立视频哈希检索网络；使用特征提取层获取中间特征并计算中间特征的对比损失；将中间特征输入哈希层得到哈希码特征并计算哈希码特征的对比损失；对视频哈希检索网络进行训练,使用随机梯度下降法优化损失,更新网络参数直至收敛,获得训练好的检索网络；将测试集输入训练好的检索网络中进行视频检索,得到检索结果。本方法使用对比损失函数,在没有类别标注信息的情况下对视频哈希检索网络进行训练,并采用随机梯度下降法更新网络参数,得到的检索网络准确率高、结果有效。</td>   <td>1.基于自监督学习的无标注视频哈希检索方法,其特征在于,包括下述步骤：获取视频帧数据集并划分为训练数据集及测试集,对训练数据集进行数据增强,得到增强后的数据集；建立视频哈希检索网络,所述视频哈希检索网络包括特征提取层和哈希层；将增强后数据集输入视频哈希检索网络,使用特征提取层获取中间特征并计算中间特征的对比损失；将中间特征输入哈希层得到哈希码特征并计算哈希码特征的对比损失；对视频哈希检索网络进行训练,使用随机梯度下降法优化损失,更新网络参数直至收敛,获得训练好的视频哈希检索网络；将测试集输入训练好的视频哈希检索网络中进行视频检索,得到检索结果。</td>   <td>G06K9/62;G06F16/73</td>  </tr>        <tr>   <td>中国专利</td>   <td>         裴杰;              张莹;              郭韩;                   方芷辰       </td>   <td>中山大学</td>   <td>一种面向城市群的生态承载力遥感评估方法及装置</td>   <td>广东省</td>   <td>CN114723283A</td>   <td>2022-07-08</td>   <td>本发明公开了一种面向城市群的生态承载力遥感评估方法及装置,方法包括：构建城市群生态承载力评价指标体系,从生态恢复力和生态压力两方面筛选出关键评价指标集合；根据所述关键评价指标集合收集基础数据,并根据所述基础数据生成指标数据；根据AHP–PCA熵权模型计算所述指标数据的权重；根据所述指标数据和所述指标数据的权重,进行生态承载力综合评估；根据所述生态承载力综合评估的结果,进行生态承载力预测。本发明提高了对城市群生态环境质量评估的精度,可广泛应用于环境数据处理技术领域。</td>   <td>1.一种面向城市群的生态承载力遥感评估方法,其特征在于,包括：构建城市群生态承载力评价指标体系,从生态恢复力和生态压力两方面筛选出关键评价指标集合；根据所述关键评价指标集合收集基础数据,并根据所述基础数据生成指标数据；根据AHP–PCA熵权模型计算所述指标数据的权重；根据所述指标数据和所述指标数据的权重,进行生态承载力综合评估；根据所述生态承载力综合评估的结果,进行生态承载力预测。</td>   <td>G06Q10/06;G06K9/62;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蒋子规;              郑沛霖;              郑伟林;                   郑子彬       </td>   <td>中山大学</td>   <td>一种智能合约执行引擎、智能合约执行方法及相关设备</td>   <td>广东省</td>   <td>CN114723446A</td>   <td>2022-07-08</td>   <td>本申请公开了一种智能合约执行引擎、智能合约执行方法及相关设备,该执行引擎包括：接口调用单元,用于根据接口参数调用指定的智能合约；合约读取单元,用于获取目标合约内容；解释执行单元,用于对目标合约内容进行检测,将检测通过的目标合约内容解释为机器码,以及执行该机器码；数据管理单元,用于通过预封装的PHP约束类对需要持久化的世界状态进行数据库操作,以及对运行时的环境信息进行操作。由于PHP解释器是经过社区广泛支持及优化的执行引擎,具有比较稳定的执行能力；同时由于PHP执行过程是基于寄存器方式对变量进行读写,相对于基于栈进行变量读写的以太坊虚拟机,能够保持较高的执行性能,更好地支持高频的区块链业务场景。</td>   <td>1.一种智能合约执行引擎,其特征在于,包括：接口调用单元,用于根据接口参数调用指定的智能合约；合约读取单元,用于根据接口调用单元所调用的智能合约,获取目标合约内容；解释执行单元,用于对目标合约内容进行检测,将检测通过的目标合约内容解释为机器码,以及执行所述机器码；数据管理单元,用于在所述机器码的执行过程中,通过预封装的PHP约束类对需要持久化的世界状态进行数据库操作,以及通过预封装的PHP约束类对运行时的环境信息进行操作。</td>   <td>G06Q20/38;G06F9/455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李图南;              詹昭焕;                   谭光       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种可消除干扰物体影响的位姿确定方法及装置</td>   <td>广东省</td>   <td>CN114708176A</td>   <td>2022-07-05</td>   <td>本发明公开了一种可消除干扰物体影响的位姿确定方法、装置、电子设备及计算机可读存储介质,所述方法包括：获取查询图像后,在预设的图像库中查找若干张与所述查询图像对应的参考图像；将所述查询图像与每一张所述参考图像组成图像集合,并分别对每个所述图像集合内的图像进行消除干扰物处理,得到每个所述图像集合对应的相对位姿；结合若干个所述相对位姿确定目标位姿。本发明可以在筛选查询图像对应的参考图像后,可以分别识别与筛选查询图像和参照图像中的干扰物,从而消除图像中的干扰物,降低干扰物对定位的影响,以提高定位的准确率。</td>   <td>1.一种可消除干扰物体影响的位姿确定方法,其特征在于,所述方法包括：获取查询图像后,在预设的图像库中查找若干张与所述查询图像对应的参考图像；将所述查询图像与每一张所述参考图像组成图像集合,并分别对每个所述图像集合内的图像进行消除干扰物处理,得到每个所述图像集合对应的相对位姿；结合若干个所述相对位姿确定目标位姿。</td>   <td>G06T5/50;G06T7/70;G06N3/08;G06N3/04;G06V10/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭裕兰;              汪赟;                   王龙光       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于斜面代价聚合的立体匹配的方法、装置和存储介质</td>   <td>广东省</td>   <td>CN114708219A</td>   <td>2022-07-05</td>   <td>本发明公开了一种基于斜面代价聚合的立体匹配的方法、计算机装置及存储介质,包括对第一图像和第二图像进行特征图矩阵相乘处理,获得第一代价体,对第一代价体进行初始视差估计,获得初始视差图,执行多轮循环迭代操作,对最后一轮循环迭代操作得到的视差图和upmask图进行处理,获得原分辨率视差图等步骤。本发明通过在每一轮循环迭代操作中,根据目标斜面参数和目标视差图构建出多个斜面,根据各斜面进行lookup操作,可以更新斜面的参数,即斜面是可学习的,能够从局部3D空间中聚合匹配代价,减少计算和内存成本,具备较高的匹配准确性、较低的消耗成本、具有良好的实时性和运算速度。本发明广泛应用于图像处理技术领域。</td>   <td>1.一种基于斜面代价聚合的立体匹配的方法,其特征在于,所述基于斜面代价聚合的立体匹配的方法包括以下步骤：获取第一图像和第二图像；所述第一图像和所述第二图像可以组成立体对图像；对所述第一图像和所述第二图像进行特征图矩阵相乘处理,获得第一代价体；对所述第一代价体进行初始视差估计,获得初始视差图；执行多轮循环迭代操作；在每一轮所述循环迭代操作中,根据目标斜面参数和目标视差图构建出本轮的多个斜面,根据各所述斜面,对所述第一代价体中以像素为中心的邻域内执行lookup操作,追溯得到本轮的追溯代价体,对所述追溯代价体执行自适应聚合,获得本轮的上下文特征图,将目标视差图、本轮的所述追溯代价体以及本轮的所述上下文特征图输入至门激活单元,所述门激活单元输出本轮的视差图、本轮的斜面参数以及本轮的upmask图；其中,对于第一轮所述循环迭代操作,所述目标斜面参数为初始设定的斜面参数,所述目标视差图为所述初始视差图；对于除第一轮循环迭代操作之外的其他各轮所述循环迭代操作,所述目标斜面参数为上一轮循环迭代操作得到的斜面参数,所述目标视差图为上一轮循环迭代操作得到的视差图；对最后一轮循环迭代操作得到的视差图和upmask图进行处理,获得原分辨率视差图。</td>   <td>G06T7/00;G06N3/04;G06K9/62;G06V10/74</td>  </tr>        <tr>   <td>中国专利</td>   <td>         钟俊勋;              成慧;                   何流       </td>   <td>中山大学</td>   <td>一种分布式完全覆盖的机器人编队覆盖方法</td>   <td>广东省</td>   <td>CN110675002B</td>   <td>2022-07-05</td>   <td>本发明涉及多移动机器人技术领域,更具体地,涉及一种分布式完全覆盖的机器人编队覆盖方法。本发明通过将问题转化为分布式约束优化问题,使得每个机器人在求解问题的过程能够将周围的机器人也引入,既在机器人间引入合作,使得最终得到的结果质量能显著优于现有的基于梯度的方法。并且在求解分布式约束优化问题时,本发明提出了使用梯度下降优化的连续最大和算法,此算法能够在保持非中心化和拥有多项式级的时间复杂度下,求出与传统的最大和算法相近的结果,从而能够成功地应用于解决对未知区域的完全覆盖问题,并且非中心化的性质使得算法的鲁棒性更高。</td>   <td>1.一种分布式完全覆盖的机器人编队覆盖方法,其特征在于,首先将如何最大化被释放机器人的总覆盖区域的问题转化为分布式约束优化问题,然后使用梯度下降优化的连续最大和算法进行求解,并通过在变量节点和效用函数节点间互相发送信息来实现优化；其中,转化后的分布式约束优化问题形式包括以下部分：1)实体表示各个机器人；2)变量节点表示各个机器人的位置状态；3)效用函数节点表示该机器人的分割后的覆盖区域的大小,由于二维空间的连续属性,使得效用函数节点U均为连续函数；效用函数节点会与能影响其取值的变量节点相连接；4)变量节点的取值范围5)优化问题的目标函数,即机器人群的总覆盖面积表示为：                  式中,向量x-j表示所有与U-j相连的变量节点集合；其中,每个机器人执行使用梯度下降优化的连续最大和算法的运算流程包括以下步骤：S1.确定当前时刻处于通讯范围内的所有机器人,从这些机器人处收集信息q与信息r；从变量节点i向效用函数节点j发送的信息q为：                  式中,表示除j外所有与变量节点i相连的效用函数节点的下标集合,t表示当前信息的交换次数；从效用函数节点j向变量节点i发送的信息r为：                  式中,表示除i外所有与效用函数节点j相连的变量节点的下标集合,S2.使用公式(2)分别计算发送给周围各个机器人的信息q；S3.使用以下公式(4)计算周围所有机器人的理想位置x～*：                  S4.使用公式(3)分别计算发送给各个机器人的信息r,但直接使用公式(3)计算会导致运行时间过长,在此利用计算得到的理想位置x～*并使用如下公式(5)进行计算：                  S5.将计算得到的信息q与信息r分别存储并等待对应的机器人来向当前机器人请求；S6.在信息交换的过程中,每个机器人使用以下公式(6)更新最优位置状态并移动至此状态：</td>   <td>G06Q10/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄晓;              李正豪;                   保延翔       </td>   <td>中山大学</td>   <td>一种基于MEMS传感器的人体动作实时识别方法及系统</td>   <td>广东省</td>   <td>CN114692688A</td>   <td>2022-07-01</td>   <td>本发明涉及人工智能技术领域,提出一种基于MEMS传感器的人体动作实时识别方法及系统,其中：通过佩戴在人体的MEMS传感器进行人体动作数据的实时采集；预设一定长度的窗口,当实时采集的人体动作数据量达到1/4的窗口大小时,对当前窗口内的人体动作数据进行特征向量提取,将提取的特征向量输入动静态预分类模型中,用于对当前窗口标注动态动作标记或静态动作标记；当实时采集的人体动作数据量达到窗口大小时,对当前窗口内的人体动作数据进行特征向量提取,并根据当前窗口标注的标记将所提取的特征向量输入动态动作识别模型或静态动作识别模型中,动态动作识别模型或静态动作识别模型输出人体动作实时识别结果,并清洗当前窗口的标记。</td>   <td>1.一种基于MEMS传感器的人体动作实时识别方法,其特征在于,包括以下步骤：S1、通过佩戴在人体身上的MEMS传感器进行人体动作数据的实时采集；所述MEMS传感器中包括六轴传感器；S2、预设一定长度的窗口,当实时采集的人体动作数据量达到1/4的窗口大小时,对当前窗口内的人体动作数据进行特征向量提取,将提取的特征向量输入动静态预分类模型中,所述动静态预分类模型对当前窗口标注动态动作标记或静态动作标记；S3、当实时采集的人体动作数据量达到窗口大小时,对当前窗口内的人体动作数据进行特征向量提取,并根据当前窗口标注的动态动作标记或静态动作标记将所提取的特征向量输入动态动作识别模型或静态动作识别模型中,所述动态动作识别模型或静态动作识别模型输出人体动作实时识别结果,并清洗当前窗口的标记。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G01P15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈舒雅;              郑淙杰;                   王青松       </td>   <td>中山大学</td>   <td>一种雷达图像匹配方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN114692735A</td>   <td>2022-07-01</td>   <td>本发明公开了一种雷达图像匹配方法、装置、设备及存储介质。本发明通过计算待匹配的雷达图像对的相位一致性,并生成对应的第一最大矩图；基于不同尺度的小波变换,将每张第一最大矩图转换为多张降采样后的第二最大矩图,形成每张雷达图像对应的图像金字塔,提取图像金字塔中各层图像对应的控制点；将雷达图像对中不同雷达图像对应的控制点进行匹配,并将生成匹配控制点集输入到预设的多项式匹配模型,得到雷达图像对的变换参数,以使对雷达图像对进行匹配,输出匹配结果。与现有技术相比,本发明的技术方案基于不同尺度的小波变换,对生成的图像金字塔进行控制点提取,能提高后续获取控制点的数量,并基于预设的多项式匹配模型,提高匹配精度。</td>   <td>1.一种雷达图像匹配方法,其特征在于,包括：获取待匹配的雷达图像对,根据第一预设公式计算所述雷达图像对的相位一致性,并生成每张雷达图像对应的第一最大矩图；基于不同尺度的小波变换,将每张第一最大矩图转换为多张降采样后的第二最大矩图,形成每张雷达图像对应的图像金字塔,提取所述图像金字塔中各层图像对应的控制点,生成控制点集；将所述雷达图像对中不同雷达图像对应的控制点集进行匹配,生成匹配控制点集,并将所述匹配控制点集输入到预设的多项式匹配模型,得到所述雷达图像对的变换参数,基于所述变换参数,对所述雷达图像对进行匹配,输出匹配结果。</td>   <td>G06K9/62;G06T5/10;G06V10/75</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王军;              杨鹏健;                   张莱       </td>   <td>中山大学</td>   <td>基于帧内块复制的自适应图像预处理方法、装置及介质</td>   <td>广东省</td>   <td>CN114692742A</td>   <td>2022-07-01</td>   <td>本发明公开了一种基于帧内块复制的自适应图像预处理方法、装置及介质,本发明通过获取已编码区域的重建图像,将重建图像输入分类器进行判断处理,得到判断处理结果,当判断处理结果表征需要进行预处理,对重建图像进行图像增强处理得到增强图像,有利于改善重建图像的压缩伪影；获取重建图像对应的第一真实概率以及获取增强图像的第二真实概率,根据第一真实概率以及第二真实概率确定最终图像以替换重建图像,或者获取重建图像的第一像素均值以及增强图像的第二像素均值,根据第一像素均值以及第二像素均值确定最终图像以替换重建图像,有利于使更好图像质量的最终图像作为参考块,可以有效提升预测精度和编码效率,可广泛应用于视频编码领域。</td>   <td>1.基于帧内块复制的自适应图像预处理方法,其特征在于,包括：获取已编码区域的重建图像；将所述重建图像输入分类器进行判断处理,得到判断处理结果；当所述判断处理结果表征需要进行预处理,对所述重建图像进行图像增强处理,得到增强图像；获取所述重建图像对应的第一真实概率以及获取所述增强图像的第二真实概率,根据所述第一真实概率以及所述第二真实概率确定最终图像以替换所述重建图像,或者,获取所述重建图像的第一像素均值以及所述增强图像的第二像素均值,根据所述第一像素均值以及所述第二像素均值确定最终图像以替换所述重建图像。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G06V10/26;G06V10/764;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         由林麟;              陈耿祥;              徐前祥;              李宏立;                   伊莎       </td>   <td>中山大学</td>   <td>一种机动车尾气遥感检测数据的处理与分析方法</td>   <td>广东省</td>   <td>CN114692749A</td>   <td>2022-07-01</td>   <td>本发明公开了一种机动车尾气遥感检测数据的处理与分析方法,根据机动车尾气遥感检测数据,筛选初始机动车集合；对机动车尾气遥感检测数据进行测量值修正,得到尾气排放测量值呈正态分布的特征,使用正态分布下拉依达准则删除区间外数据；将测量数据校准至同一测量基准水平；将测量数据放缩至同一测量基准幅度；根据尾气排放测量值的分布特征选择超参数,分别使用两种无监督机器学习算法划分异常点后,标记两种无监督机器学习算法的异常点并集；结合无监督机器学习算法和预设的阈值,确定最终的排放超标机动车信息。本发明的准确率高、检测时间短且成本低,可广泛应用于大数据处理分析技术领域。</td>   <td>1.一种机动车尾气遥感检测数据的处理与分析方法,其特征在于,包括：根据机动车尾气遥感检测数据,筛选初始机动车集合；其中,所述机动车尾气遥感检测数据划分为柴油车数据和汽油车数据,用于针对不同类型车辆的排放数据进行处理与分析；通过差分法对所述机动车尾气遥感检测数据进行测量值修正,得到修正后的尾气排放测量值；根据尾气排放测量值呈正态分布的特征,使用正态分布下拉依达准则删除区间外数据；考虑测量设备不同时间段测量基准水平的偏移,将测量数据校准至同一测量基准水平；考虑测量设备不同时间段测量基准幅度的变化,将测量数据放缩至同一测量基准幅度；根据所述尾气排放测量值的分布特征选择超参数,分别使用两种无监督机器学习算法划分异常点后,标记两种无监督机器学习算法的异常点并集,其中,所述异常点并集用于初步判定排放超标车辆；结合无监督机器学习算法和预设的阈值对异常点并集数据进行进一步判定,确定最终的排放超标机动车信息。</td>   <td>G06K9/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         秦宗;              邹国伟;              王泽宇;              梁宏浩;                   杨柏儒       </td>   <td>中山大学</td>   <td>自适应刷新率的场色序显示驱动方法、装置及相关设备</td>   <td>广东省</td>   <td>CN114692776A</td>   <td>2022-07-01</td>   <td>本申请公开了一种自适应刷新率的场色序显示驱动方法、装置及相关设备,该方法包括：利用训练后的图像分类模型,确定与目标图像的特征相匹配的目标驱动信息,其中,该图像分类模型为以训练图像作为训练样本,以使得训练图像的平均色差值小于预设阈值的第一驱动信息,或者,当不存在使得训练图像的平均色差值小于该阈值的驱动算法时,以包含最高刷新率的第二驱动信息,作为样本标签训练得到；从预设的候选驱动算法中确定与目标驱动信息相匹配的目标驱动算法,并基于其计算得到目标图像在各个场的驱动信号。本申请根据图像内容来动态调整刷新率,并根据所述刷新率确定合适的驱动算法,能够确保图像显示中的合理的保真度以及有效降低显示器的功耗。</td>   <td>1.一种自适应刷新率的场色序显示驱动方法,其特征在于,包括：利用训练后的图像分类模型,确定与目标图像的特征相匹配的目标驱动信息,其中,所述图像分类模型为以训练图像作为训练样本,以使得训练图像的平均色差值小于预设阈值的第一驱动信息,或者,当不存在使得训练图像的平均色差值小于所述预设阈值的驱动算法时,以包含最高刷新率的第二驱动信息,作为样本标签训练得到,其中,所述第一驱动信息包括使得训练图像的平均色差值小于所述预设阈值的最小刷新率,或,具有所述最小刷新率的驱动算法；从预设的候选驱动算法中确定与所述目标驱动信息相匹配的目标驱动算法；基于所述目标驱动算法计算得到所述目标图像在各个场的模拟背光分布和透射率；根据所述模拟背光分布和透射率,计算得到所述目标图像在各个场的驱动信号。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G06V10/56;G06V10/764;G06V10/774;G06V10/75;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              王雅恬;              罗经周;              郑均;                   张靖宜       </td>   <td>中山大学</td>   <td>一种道路监控图像增强方法、系统、装置及介质</td>   <td>广东省</td>   <td>CN114693575A</td>   <td>2022-07-01</td>   <td>本发明公开了一种道路监控图像增强方法、系统、计算机装置和存储介质,道路监控图像增强方法包括对原始图像的原始特征信息进行下采样处理,使用对偶注意力单元对所获得的第一特征信息进行过滤筛选,使用加权特征融合模块对第一特征信息对应的第二特征信息进行融合处理,再使用对偶注意力单元进行过滤筛选,获得第三特征信息,使用加权特征融合模块对各第三特征信息进行融合处理,对所获得的第四特征信息进行处理,获得增强图像等步骤。本发明道路监控图像增强方法所使用的模型具有模型体积小以及端到端等优点,能够融合超分辨率处理和弱光增强处理的效果,从而能够有效适应对道路监控图像进行的图像增强处理。本发明广泛应用于图像处理技术领域。</td>   <td>1.一种道路监控图像增强方法,其特征在于,所述道路监控图像增强方法包括：获取原始图像；所述原始图像来自道路监控图像；提取所述原始图像的特征层信息,获得原始特征信息；对所述原始特征信息分别进行保持处理和至少一次下采样处理,获得多个第一特征信息；对于任一所述第一特征信息,使用对偶注意力单元进行过滤筛选,获得相应的第二特征信息,使用基于自注意力机制的加权特征融合模块,对该所述第一特征信息对应的第二特征信息以及其他所述第一特征信息对应的第二特征信息进行融合处理,再使用对偶注意力单元进行过滤筛选,获得该所述第一特征信息对应的第三特征信息；使用基于自注意力机制的加权特征融合模块,对各所述第一特征信息各自对应的第三特征信息进行融合处理,获得第四特征信息；对所述第四特征信息进行处理,获得增强图像。</td>   <td>G06T5/50;G06K9/62;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王亮;              郑嘉俊;              苏燮阳;              张志勇;              王鲁平;              丘昌镇;              李春泽;                   李登翔       </td>   <td>中山大学;深圳市安比科技有限公司;深圳市正阳升智能科技有限公司</td>   <td>一种铁路钢轨缺陷检测方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN114693617A</td>   <td>2022-07-01</td>   <td>本发明公开了一种铁路钢轨缺陷检测方法、系统、设备及存储介质,涉及计算机视觉技术领域。所述方法包括：获取钢轨表面图像数据集,得到标记数据集；采用目标检测算法对所述标记数据集进行训练,得到钢轨缺陷的检测模型；采用目标分类算法对数据集进行分类训练,得到钢轨缺陷的分类模型；获取待测钢轨图像,采用所述检测模型对所述待测钢轨图像进行检测,得到缺陷定位信息；采用所述分类模型对所述待测钢轨图像的缺陷定位信息进行类别判定,得到缺陷判定结果。本发明能够在巡检列车上高效地对复杂轨道场景下的铁路钢轨缺陷进行快速检测定位,如果发现钢轨缺陷,便可以及时定位并报警,提醒工作人员维修时对相应位置的钢轨及时采取维修措施。</td>   <td>1.一种铁路钢轨缺陷检测方法,其特征在于,包括：获取钢轨表面图像数据集,并对所述钢轨表面图像数据集内的数据缺陷进行标记,得到标记数据集；采用目标检测算法对所述标记数据集进行训练,得到钢轨缺陷的检测模型；对所述钢轨表面图像数据集内的缺陷类别进行分类,得到分类数据集；采用目标分类算法对所述分类数据集进行训练,得到钢轨缺陷的分类模型；获取待测钢轨图像,采用所述检测模型对所述待测钢轨图像进行检测,得到缺陷定位信息；采用所述分类模型对所述待测钢轨图像的缺陷定位信息进行类别判定,得到缺陷判定结果。</td>   <td>G06T7/00;G06T7/70;G06K9/62;G06V10/764;G06V10/774;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              肖鹏;              王耿媛;              黄远聪;                   李赛群       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于深度学习的角膜内皮细胞活性因子的分析方法</td>   <td>广东省</td>   <td>CN114693646A</td>   <td>2022-07-01</td>   <td>本公开提供了一种基于深度学习的角膜内皮细胞活性因子的分析方法,包括对细胞图像进行分割以得到分割图像,在分割图像中获取细胞区域图像,细胞区域图像具有位于图像中心的中心细胞,统计细胞区域图像内的细胞个数和分布密度,基于细胞个数和分布密度计算细胞区域图像的总体径向分布函数,基于总体径向分布函数获得细胞的生长势能曲线,基于生长势能曲线的变化率获得角膜内皮细胞活性因子,基于角膜内皮细胞活性因子获得细胞图像中的细胞的生理状态。本公开的分析方法,通过获得细胞图像的势能转换常数进而获得角膜内皮细胞的生理状态,在这种情况下,能够提高角膜内皮细胞的生理状态的检测效率。</td>   <td>1.一种基于深度学习的角膜内皮细胞活性因子的分析方法,其特征在于,对细胞图像进行分割以得到分割图像,在所述分割图像中获取细胞区域图像,所述细胞区域图像具有位于图像中心的中心细胞,统计所述细胞区域图像内的细胞个数和分布密度,基于所述细胞个数和所述分布密度计算所述细胞区域图像的总体径向分布函数,基于所述总体径向分布函数获得细胞的生长势能曲线,基于所述生长势能曲线的变化率获得角膜内皮细胞活性因子,基于所述角膜内皮细胞活性因子获得所述细胞图像中的细胞的生理状态。</td>   <td>G06T7/00;G06T7/11;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林天歆;              黄健;              吴少旭;              洪桂斌;                   陈雄       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>基于膀胱镜的智能AI图像标注方法及装置</td>   <td>广东省</td>   <td>CN114693774A</td>   <td>2022-07-01</td>   <td>本发明公开了一种基于膀胱镜的智能AI图像标注方法及装置,所述方法包括：当获取患者的临床信息及膀胱镜图像时,从将所述临床信息中提取若干个病情变化特征；按照时间顺序将所述若干个病情变化特征串接成病情变化文本；基于所述病情变化文本从海量患者的诊断数据中筛选至少一张目标诊断图像,并从所述目标诊断图像中提取标注参数；按照所述标注参数标注所述膀胱镜图像得到标注图像,将所述标注图像发送至膀胱镜诊断仪中,以供所述膀胱镜诊断仪中展示标注后的膀胱镜图像。本发明可以快速地对膀胱镜图像进行标注,以辅助医生进行对应的医疗诊断,提高医生的诊断效率。</td>   <td>1.一种基于膀胱镜的智能AI图像标注方法,其特征在于,所述方法包括：当获取患者的临床信息及膀胱镜图像时,从将所述临床信息中提取若干个病情变化特征；按照时间顺序将所述若干个病情变化特征串接成病情变化文本；基于所述病情变化文本从海量患者的诊断数据中筛选至少一张目标诊断图像,并从所述目标诊断图像中提取标注参数；按照所述标注参数标注所述膀胱镜图像得到标注图像,将所述标注图像发送至膀胱镜诊断仪中,以供膀胱镜诊断仪展示标注后的膀胱镜图像。</td>   <td>G06T7/70;G06T7/90;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭家莉;                   谢亚娟       </td>   <td>中山大学附属口腔医院</td>   <td>单侧正锁合下颌骨功能单元的形态学测量分析系统、方法及应用</td>   <td>广东省</td>   <td>CN114022611B</td>   <td>2022-06-28</td>   <td>本发明提供了一种单侧正锁合下颌骨功能单元的形态学测量分析系统、方法及应用,所述的形态学测量分析系统包括：CBCT扫描设备,所述CBCT扫描设备用于扫描获取单侧正锁合患者的下颌骨原始模型,对原始模型进行功能单元分区；建模单元,所述建模单元用于对每一个功能单元分别进行三维建模并镜像,得到下颌骨镜像模型；拟合单元,所述拟合单元用于将原始模型与镜像模型进行拟合并匹配,获得原始模型与镜像模型的匹配度。本发明基于CBCT的三维可视化表面匹配测量分析技术实现了对下颌骨功能单元的三维形态学测量分析,可进行直观的形态学分析,使下颌骨各个功能单元左右两侧的对称性和形态差异达到可视化和量化。</td>   <td>1.一种单侧正锁合下颌骨功能单元的形态学测量分析系统,其特征在于,所述的形态学测量分析系统包括：CBCT扫描设备,所述CBCT扫描设备用于扫描获取单侧正锁合患者的下颌骨原始模型,对原始模型进行功能单元分区；建模单元,所述建模单元用于对每一个功能单元分别进行三维建模并镜像,得到下颌骨镜像模型；拟合单元,所述拟合单元用于将原始模型与镜像模型进行拟合并匹配,获得原始模型与镜像模型的匹配度；所述CBCT扫描设备扫描获取的下颌骨图像以DICOM标准存储,并导入MIMICS软件中,经预处理得到下颌骨原始模型,对下颌骨原始模型进行可视化分割,得到若干个功能单元；所述的预处理过程包括如下步骤：(1)建立原始遮罩,将预定义的阈值设置为“骨骼”,创建下颌骨分割对象；(2)输入阈值对下颌骨图像进行精细调整；(3)使用蒙版裁剪工具选择下颌骨区域并限制分割；(4)通过编辑蒙版工具对活动蒙版的3D预览进行手动编辑操作,得到下颌骨蒙版；(5)应用蒙版平滑工具和轮廓编辑,去下颌骨蒙版中的现有伪影,得到清晰的下颌骨原始模型。</td>   <td>G06T17/00;G06T19/20;G06F30/10;G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              谢震宇;                   董浩业       </td>   <td>中山大学</td>   <td>一种可保留示例衣服细节的虚拟试穿方法及系统</td>   <td>广东省</td>   <td>CN111062777B</td>   <td>2022-06-24</td>   <td>本发明公开了一种可保留示例衣服细节的虚拟试穿方法及系统,该方法包括：步骤S1,对于一张人体图像,基于与衣服无关的人体特征表示方法,获得与衣服无关的人体特征图p；步骤S2,分别提取人体特征图p和示例衣服图c的高层特征,计算两者之间的相关性,得到代表人体特征和衣服特征相关性的张量,并基于回归网络以及薄板样条插值模块,获得变形后的衣服图步骤S3,将步骤S1获得的人体特征图p和由步骤S2得到的变形衣服图拼接作为深度学习UNet网络的输入,获得初步合成的试穿结果I-r以及掩模M；步骤S4,由掩模M将初步合成的试穿结果I-r和形变衣服图融合在一起,得到最终的试穿结果I-o。</td>   <td>1.一种可保留示例衣服细节的虚拟试穿方法,包括如下步骤：步骤S1,对于一张人体图像,基于与衣服无关的人体特征表示方法,获得与衣服无关的人体特征图p；步骤S2,分别提取人体特征图p和示例衣服图c的高层特征,并计算两个特征图之间的相关性,得到代表人体特征和衣服特征相关性的张量,将获得的张量输入回归网络以及薄板样条插值模块,获得变形后的衣服图步骤S3,将步骤S1获得的人体特征图p和由步骤S2得到的变形衣服拼接起来作为深度学习UNet网络的输入,获得初步合成的试穿结果I-r以及用于融合的掩模M；步骤S4,由掩模M将初步合成的试穿结果I-r和形变衣服图融合在一起,得到最终的试穿结果I-o。</td>   <td>G06Q30/06;G06T19/00;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王天星;              周望;                   高涛       </td>   <td>中山大学</td>   <td>一种利用遥感估算近地表气温的方法</td>   <td>广东省</td>   <td>CN114662701A</td>   <td>2022-06-24</td>   <td>本发明提供一种利用遥感估算近地表气温的方法,以全球地面观测数据和再分析数据作为数据源,全球按照纬度、土地覆盖类型等分成若干子区域；每个区域利用近10年地面观测数据和再分析数据建立数据库；建立线性或非线性模型,记为Model-1；同时,以相同样本库,建立机器学习模型,记为Model-2；两个模型进行加权融合得到每个子区域的最终模型Model-fused；针对某个区域,基于上述建立的Model-fused模型,输入利用遥感获取的参数,得到对应的近地表气温。本发明实现基于常规遥感产品的高精度、时空连续近地表气温的遥感估算,弥补已有产品精度低、时空分辨率粗甚至依赖特定传感器的缺陷。</td>   <td>1.一种利用遥感估算近地表气温的方法,其特征在于,包括以下步骤：(1)首先以全球地面观测数据和再分析数据作为数据源,全球按照纬度、土地覆盖类型等分成若干子区域；(2)每个区域利用近10年地面观测数据和再分析数据建立数据库,数据库中的每个样本变量包括,地表温度、高程、长波下行辐射、地表总净辐射、大气柱水汽含量、近地表气温；(3)基于样本数据库,建立以近地表气温为因变量,以地表温度、高程、长波下行辐射、地表总净辐射、大气柱水汽含量为自变量的线性或非线性模型,记为Model-1；同时,以相同样本库,建立机器学习模型,记为Model-2,其输入数据为地表温度、高程、长波下行辐射、地表总净辐射、大气柱水汽含量,输出数据为近地表气温；将Model-1和Model-2两个模型进行加权融合得到每个子区域的最终模型Model-fused；(4)针对某个区域,基于上述建立的Model-fused模型,输入利用遥感获取的地表温度、高程、长波下行辐射、地表总净辐射、大气柱水汽含量参数,得到对应的近地表气温。</td>   <td>G06N20/00;G06N20/20;G06N5/00;G06F16/29;G01K13/00;G01W1/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李洽;                   吴佳琪       </td>   <td>中山大学</td>   <td>基于压缩与激励机制神经网络的图像去模糊方法</td>   <td>广东省</td>   <td>CN112102177B</td>   <td>2022-06-21</td>   <td>本发明公开了一种基于压缩与激励机制神经网络的图像去模糊方法,包括以下步骤：获取训练网络所需数据集,所述数据集为多个图像对,每个图像对由模糊图像及其对应的清晰图像组成；构建压缩与激励去模糊网络,所述网络为多尺度网络,每一个尺度的构造相同,包括编码器-解码器结构以及ConvLSTM层；使用数据集对压缩与激励去模糊网络进行训练；使用训练完成的压缩与激励去模糊网络对模糊图像进行处理。本发明在SRN去模糊网络的基础上对特征处理模块中的残差块进行改进,引入压缩与激励机制,得到了应用于本发明网络的SE残差块,进而构成SEDN去模糊网络,使最终恢复的清晰图像质量上更加优秀。</td>   <td>1.基于压缩与激励机制神经网络的图像去模糊方法,其特征在于,包括以下步骤：获取训练压缩与激励机制神经网络所需数据集,所述数据集为多个图像对,每个图像对由模糊图像及其对应的清晰图像组成；构建压缩与激励去模糊神经网络,所述压缩与激励去模糊神经网络为多尺度网络,每一个尺度的构造相同,包括编码器-解码器结构以及ConvLSTM层；所述编码器-解码器结构包括用于从输入图像中抽取特征并处理的编码器部分、用于将复杂的特征复原为对应的清晰图像的解码器部分以及用于在不同的编码器-解码器层级上组合不同层级获取到的特征,对不同层级的特征加以复用的跳跃链接；所述ConvLSTM层设置在所述编码器部分与解码器部分之间,用于将编码器部分抽取与处理过的复杂特征进一步地在压缩与激励去模糊神经网络各尺度间传播；所述编码器部分包括多个顺序连接的Eblock；所述解码器部分包括多个顺序连接的Dblock；使用获取到的数据集对压缩与激励去模糊神经网络进行训练,根据数据集获取网络的输入图像,网络处理输入图像的正向过程,根据所有网络处理恢复结果,计算本次正向传播结果的损失并利用该损失更新压缩与激励去模糊神经网络中可训练参数的权重,反向更新梯度过程；所述对压缩与激励去模糊神经网络进行训练包括对数据集图像进行处理、网络正向处理图像过程以及根据损失函数值反向更新网络模型权重过程,具体为：根据数据集获取压缩与激励去模糊神经网络的输入,输入的图像对数目与压缩与激励去模糊神经网络尺度数相等,将图像对进行缩小并根据图像尺寸大小从小到大排列；压缩与激励去模糊神经网络在处理输入模糊图像的正向过程：在第一个尺度上输入尺寸最小的图像对中的模糊图像；压缩与激励去模糊神经网络内部结构处理图像,得到恢复图像；根据图像尺寸大小排列,将恢复图像上采样到次小的尺寸,将上采样得到的图像与尺寸次小的图像对中的模糊图像拼接,作为下一尺度的输入图像；重复网络内部结构处理以及上采样、拼接步骤,直至最后一个尺度的网络内部结构处理完成,得到恢复图像；计算本次正向传播结果的损失,并利用该损失更新压缩与激励去模糊神经网络中可训练参数的权重；各尺度得到的恢复图像分别用于反向更新梯度过程；使用训练完成的压缩与激励去模糊神经网络对模糊图像进行处理。</td>   <td>G06T5/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              林格;              苏航;                   汤武惊       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>图像的去雾方法、装置、终端设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN114648467A</td>   <td>2022-06-21</td>   <td>本申请适用于智能监控技术领域,提供了一种图像的去雾方法、装置、终端设备及计算机可读存储介质,其中,图像的去雾方法包括：采用暗通道先验去雾算法对待处理图像进行处理,得到粗糙透射率图；确定所述待处理图像对应的散射大气光分量；采用预先训练得到的透射图滤波网络模型对所述粗糙透射率图进行滤波处理,得到精细化透射率图；所述透射图滤波网络模型是采用卷积神经网络训练得到的,所述精细化透射率图满足透射率图的局部平滑性约束；根据所述待处理图像、所述散射大气光分量以及所述精细化透射率图,得到所述待处理图像的去雾图像,从而提升了图像的去雾效果,提高了图像质量。</td>   <td>1.一种图像的去雾方法,其特征在于,包括：采用暗通道先验去雾算法对待处理图像进行处理,得到粗糙透射率图；确定所述待处理图像对应的散射大气光分量；采用预先训练得到的透射图滤波网络模型对所述粗糙透射率图进行滤波处理,得到精细化透射率图；所述透射图滤波网络模型是采用卷积神经网络训练得到的,所述精细化透射率图满足透射率图的局部平滑性约束；根据所述待处理图像、所述散射大气光分量以及所述精细化透射率图,得到所述待处理图像的去雾图像。</td>   <td>G06T5/00;G06T5/20;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏航;              周凡;              刘海亮;              林格;                   汤武惊       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>图像处理方法、装置、终端设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN114648468A</td>   <td>2022-06-21</td>   <td>本申请适用于智能监控技术领域,提供了一种图像处理方法、装置、终端设备及计算机可读存储介质,其中,图像处理方法包括：对待处理图像进行上采样操作,得到待处理图像的上采样图像；通过预设的残差网络对待处理图像的特征图进行处理,得到待处理图像的残差图像；残差网络包括n个局部残差提取块,n个局部残差提取块之间采用稠密连接方式相连；通过预设的残差增强网络对特征图进行处理,得到待处理图像的残差增强细节图像；残差增强网络包括n个卷积块,n个卷积块之间采用稠密连接方式连接；根据上采样图像、残差图像及残差增强细节图像,得到待处理图像的目标图像；目标图像的分辨率高于待处理图像的分辨率,从而提高了待处理图像的分辨率。</td>   <td>1.一种图像处理方法,其特征在于,包括：对待处理图像进行上采样操作,得到所述待处理图像的上采样图像；通过预设的残差网络对所述待处理图像的特征图进行处理,得到所述待处理图像的残差图像；所述残差网络包括n个局部残差提取块,所述n个局部残差提取块之间采用稠密连接方式相连,n为大于1的整数；通过预设的残差增强网络对所述特征图和来自所述残差网络的残差信息进行处理,得到所述待处理图像的残差增强细节图像；所述残差增强网络包括n个卷积块,所述n个卷积块之间采用稠密连接方式连接,且第i个所述卷积块与第i-1个所述局部残差提取块之间采用稠密连接方式连接,1&lt;i≤n；根据所述上采样图像、所述残差图像及所述残差增强细节图像,得到所述待处理图像的目标图像；所述目标图像的分辨率高于所述待处理图像的分辨率。</td>   <td>G06T5/00;G06T3/40;G06N3/04;G06V10/44;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         程朦依;              税渝阳;              王晓露;              钟鹏;              黄玉如;              刘忆琨;              梁浩文;              邓冬岩;              王树颖;                   周建英       </td>   <td>中山大学;广州弥德科技有限公司</td>   <td>一种视差增强光学望远及成像系统和方法</td>   <td>广东省</td>   <td>CN114638750A</td>   <td>2022-06-17</td>   <td>本发明涉及一种视差增强光学望远及成像系统和方法,系统包括信息采集模块、信息处理模块和信息呈现模块；所述信息采集模块的输出端与所述信息处理模块的输入端电性连接,所述信息处理模块的输出端与所述信息呈现模块的输入端电性连接；所述信息采集模块用于采集两个独立串口通道的高清信号源,所述信息处理模块将高清信号源进行调节和平衡,并加载双目平衡算法和去雾算法,得到显示图像格式,所述信息呈现模块将显示图像格式进行呈现,得到视差增强的图像。上述方案中,其视差增强效果包括：去雾、双目平衡、抗抖动、抗湍流、提高信噪比的视觉感受增强效果,尤其是通过双目平衡算法和去雾算法的加载得到了优异的去雾和双目平衡效果。</td>   <td>1.一种视差增强光学望远及成像系统,其特征在于,包括信息采集模块、信息处理模块和信息呈现模块；所述信息采集模块的输出端与所述信息处理模块的输入端电性连接,所述信息处理模块的输出端与所述信息呈现模块的输入端电性连接；所述信息采集模块用于采集两个独立串口通道的高清信号源,所述信息处理模块将高清信号源进行调节和平衡,并加载双目平衡算法和去雾算法,得到显示图像格式,所述信息呈现模块将显示图像格式进行呈现,得到视差增强的图像。</td>   <td>G06T5/00;G06T5/10;G06T5/40;G02B23/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汤琪;              卢宇彤;                   陈志广       </td>   <td>中山大学</td>   <td>基于深度学习的时间序列相似度的计算方法、系统及介质</td>   <td>广东省</td>   <td>CN110766060B</td>   <td>2022-06-14</td>   <td>本发明公开了一种基于深度学习的时间序列相似度的计算方法、系统及介质,本发明基于深度学习的时间序列相似度的计算方法实施步骤包括：1)获取两个等长时间段的时间序列数据；2)将两个等长时间段的时间序列数据输入预先完成训练的基于深度学习的神经网络模型,得到两个等长时间段的时间序列数据之间的相似度。本发明综合了各种传统度量方法的优点,在时间序列相似度度量问题上比各个传统度量方法效果都好,可根据不同的需求以及不同的数据集,还可以去用同样的方法学习出适用于不同领域的数据相似度的度量方法,且针对不同问题不用再去考虑数据的内在特征而选择相似度计算方法。</td>   <td>1.一种基于深度学习的时间序列相似度的计算方法,其特征在于,实施步骤包括：1)获取两个等长时间段的时间序列数据；2)将两个等长时间段的时间序列数据输入预先完成训练的基于深度学习的神经网络模型,得到两个等长时间段的时间序列数据之间的相似度；步骤2)之前还包括训练基于深度学习的神经网络模型的步骤,详细步骤包括：S1)获取训练数据并进行预处理获取相似度特征值；S2)为训练数据打上相似度标签,所述相似度标签包括相似和不相似两种；S3)根据打上相似度标签的训练数据完成对基于深度学习的神经网络模型的训练；步骤S1)的详细步骤包括：S1.1)获取指定时间粒度的时间序列数据；S1.2)针对所有的时间序列数据进行分段线性表示,逐个计算每一个时间点的变化量△m-i并确定该时间点的变化状态值M-i,计算每个时间点的振幅A-i,计算每个时间点的时间段的占整个时间序列长度的权重tw-i；根据每一个时间点的变化状态值M-i、振幅A-i、时间段的占整个时间序列长度的权重tw-i三者综合计算该时间点的特征值；步骤S1.2)中变化状态值M-i为M={-3,-2,-1,0,1,2,3}且对应加速下降、减速下降、下降、不变、上升、减速上升和加速上升,确定该时间点的变化状态值M-i的详细步骤包括：S1.2.1)判断该时间点的变化量△m-i为0是否成立,如果成立则该时间点的变化状态值M-i为0；否则,跳转执行下一步；S1.2.2)判断该时间点的变化量△m-i和下一个时间点的变化量△m-(i+1)之间的乘积△m-i *△m-(i+1)小于0是否成立,如果成立则跳转执行步骤S1.2.3)；否则跳转执行步骤S1.2.4)；S1.2.3)判断该时间点的变化量△m-i小于0是否成立,如果成立则该时间点的变化状态值M-i为-1；否则,该时间点的变化状态值M-i为1；结束并返回；S1.2.4)计算下一个时间点的变化量△m-(i+1)、该时间点的变化量△m-i之间的差值△k-i；如果该时间点的变化量△m-i、差值△k-i均小于0,则该时间点的变化状态值M-i为-3；如果该时间点的变化量△m-i、差值△k-i均大于或等于0,则该时间点的变化状态值M-i为3；如果该时间点的变化量△m-i小于0、差值△k-i大于或等于0,则该时间点的变化状态值M-i为-2；如果该时间点的变化量△m-i大于或等于0、差值△k-i小于0,则该时间点的变化状态值M-i为2。</td>   <td>G06K9/62;G06N3/04;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何裕隆;              徐云升;              魏其遥;              方圆圆;              李江;                   赵亮       </td>   <td>中山大学附属第七医院(深圳)</td>   <td>一种基于人体关键点标注的红外图像肺部标注方法</td>   <td>广东省</td>   <td>CN114627038A</td>   <td>2022-06-14</td>   <td>本发明提供一种基于人体关键点标注的红外图像肺部标注方法,该方法包括：S10：建立人体关键点模型,通过该人体关键点模型获得待标注图像的肺部矩形框；S20：建立目标检测神经网络模型,通过该目标检测神经网络模型检测步骤S10中获得的肺部矩形框。本发明将肺部区域检测推广到了可轻易获得数据的红外热成像领域,并且结合了人体关键点以及神经网络的目标检测技术,让肺部检测的速度得到了进一步的提升。</td>   <td>1.一种基于人体关键点标注的红外图像肺部标注方法,其特征在于：该方法包括：S10：建立人体关键点模型,通过该人体关键点模型获得待标注图像的肺部矩形框；S20：建立目标检测神经网络模型,通过该目标检测神经网络模型检测步骤S10中获得的肺部矩形框。</td>   <td>G06T7/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;                   杨冰       </td>   <td>中山大学</td>   <td>严重旱涝事件的时空变化分析方法、装置和设备</td>   <td>广东省</td>   <td>CN114626475A</td>   <td>2022-06-14</td>   <td>本申请提供了一种严重旱涝事件的时空变化分析方法、装置、设备和可读存储介质,首先获取预先建立目标区域在预设时间段的自校正帕默尔指数scPDSI序列；然后采用旱涝事件的国际分类对scPDSI序列进行分析,找出各个严重旱涝事件；最后计算各个严重旱涝事件的特征指标,并对特征指标进行分析,得到目标区域中严重旱涝事件的时空变化情况。本申请实施例中的严重旱涝事件的分析方法,可以快速、准确地确定出目标区域中严重旱涝事件的发展变换情况。</td>   <td>1.一种严重旱涝事件的时空变化分析方法,其特征在于,所述方法包括：获取预先建立目标区域在预设时间段的自校正帕默尔指数scPDSI序列；采用旱涝事件的国际分类对所述scPDSI序列进行分析,找出各个严重旱涝事件；计算各个所述严重旱涝事件的特征指标,并对所述特征指标进行分析,得到目标区域中严重旱涝事件的时空变化情况。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              黄洋漫;              郑炎辉;              苏春生;              康丽;                   田世拓       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种城市区域水生态状态反应器构建方法、装置及反应器</td>   <td>广东省</td>   <td>CN114626771A</td>   <td>2022-06-14</td>   <td>本发明涉及水生态质量评价技术领域,公开了一种城市区域水生态状态反应器构建方法、装置及反应器。本发明根据目标城市区域的各水生态状态指数对应的指标数据确定重要指标,基于重要指标的标准化值和权重计算各水生态状态指数的水生态状态得分值,根据所面临的水生态风险确定多个驱动因子并计算各驱动因子的标准化值,进而利用多元线性逐步回归建立各水生态状态指数与驱动因子的回归方程,通过显著性检验筛选出对各水生态状态指数产生显著影响的驱动因子,最后构建以驱动因子为输入、以水生状态综合指数为输出的目标城市区域水生状态反应器。本发明解决了目前水生态状态反应器评价指标单一、灵活性低,不适用于快速城市化区域的技术问题。</td>   <td>1.一种城市区域水生态状态反应器构建方法,其特征在于,包括：确定目标城市区域的各水生态状态指数及对应的指标集,采集各所述指标集的指标数据；根据所述指标数据筛选出重要指标,计算各所述重要指标的标准化值和权重,根据得到的标准化值和权重计算各水生态状态指数的水生态状态得分值；根据所述目标城市区域所面临的水生态风险确定多个驱动因子,并对各所述驱动因子进行标准化处理,得到各所述驱动因子的标准化值；根据各所述驱动因子的标准化值和各水生态状态指数的水生态状态得分值,利用多元线性逐步回归建立各水生态状态指数与驱动因子的回归方程,对建立的各回归方程进行总体显著性检验和回归系数显著性检验,根据得到的检验结果,从各驱动因子中筛选出对各水生态状态指数产生显著影响的驱动因子；建立各所述水生态状态指数对筛选出的驱动因子的响应方程,根据所述响应方程和各所述水生态状态指数的权重,构建以驱动因子为输入、以水生状态综合指数为输出的目标城市区域水生状态反应器。</td>   <td>G06Q10/06;G06Q10/04;G06Q50/26;G06F17/18;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   罗俊伟       </td>   <td>中山大学</td>   <td>基于空洞卷积和特征融合的双目超分辨率图像检测方法、系统及介质</td>   <td>广东省</td>   <td>CN113344791B</td>   <td>2022-06-10</td>   <td>本发明公开了一种基于空洞卷积和特征融合的双目超分辨率图像检测方法、系统及介质,包括下述步骤：将双目图像组输入经典双目图像超分辨率网络中,生成双目超分辨率图像作为负样本集,原双目图像组作为正样本集；将正负样本数据集切成图像块并随机划分训练集图像块和测试集图像块；对图像块进行预处理,转换为灰度图像,使用高通滤波器进行滤波得到滤波图像；构建双目超分辨率图像检测网络,将训练集滤波图像输入进行训练,得到训练好的网络；将测试集滤波图像输入训练好的网络中,输出概率最大的分类对应类别,得到图像检测结果。本发明直接对输入图像进行检测,适用于各种尺寸的图像检测,具有良好的检测性能,检测用时短,可实现实时检测。</td>   <td>1.基于空洞卷积和特征融合的双目超分辨率图像检测方法,其特征在于,包括下述步骤：将双目图像组输入到经典的双目图像超分辨率网络中,生成对应的双目超分辨率图像,所述双目超分辨率图像作为负样本数据集,所述双目图像组作为正样本数据集；将正负样本数据集切成不重叠的大小一致的图像块,并随机划分为训练集图像块和测试集图像块；对训练集图像块和测试集图像块进行预处理,将RGB图像转换为灰度图像,使用高通滤波器对所述灰度图像进行滤波得到滤波图像块；构建基于空洞卷积和特征融合的双目超分辨率图像检测网络,将训练集滤波图像块输入到双目超分辨率图像检测网络中进行训练,得到训练好的网络；所述基于空洞卷积和特征融合的双目超分辨率图像检测网络包括空洞卷积组、残差块、池化层、深度特征融合和全连接层；所述空洞卷积组共有两组,每一组先使用3个不同膨胀率的空洞卷积核对输入特征图进行卷积；所述3个不同膨胀率的空洞卷积核大小均为3×3,膨胀率分别设置为{1,2,3}；每个空洞卷积核的输入输出特征图通道数不变,经过3个不同的空洞卷积后得到3个和输入特征图通道数相同的特征图；将3个特征图进行组合得到通道数为输入特征图3倍的特征图,并用1×1的卷积操作进行卷积,将通道维数减少为输入的2倍；所述残差块共有三块,每一块均包含一个卷积层和一个残差连接,所述卷积层的卷积核大小为3×3,卷积前后特征图通道数和特征图大小保持不变,每个残差块将卷积后得到的特征图和卷积前的输入按位相加；所述深度特征融合是指将不同层的输出融合在一起,具体为：将所述空洞卷积组中的第二组输出以及所述三个残差块的输出特征图组合得到4倍通道数的特征图；使用1×1的卷积操作对所述组合特征图进行卷积,将组合特征图的通道数降低至组合特征图通道数的四分之一,即原输出通道数；所述池化层为最大池化,池化核大小为2×2,步长为2,池化后特征图的大小为池化前的二分之一；池化层处理每个空洞卷积组的输出以及深度特征融合后的1×1卷积输出,将特征图的大小减少为原来的一半；所述全连接层通过Softmax函数计算输出分类概率值；将测试集滤波图像块输入到所述训练好的网络中,输出概率最大的分类对应类别,得到图像检测结果。</td>   <td>G06T3/40;G06K9/62;G06N3/04;G06N3/08;G06V10/774;G06V10/80;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         富明慧;                   林美鸿       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的桩损伤识别方法、设备及介质</td>   <td>广东省</td>   <td>CN114358091B</td>   <td>2022-06-10</td>   <td>本发明公开了一种基于卷积神经网络的桩损伤识别方法、设备及介质,其中方法包括:根据待检测桩的条件属性对待检测的桩结构建立多个模型,对模型进行求解生成待检测桩上预设位置点的速度时程曲线,基于速度时程曲线生成速度时程递归图并输入神经网络模型进行检测,输出桩损伤参数评估结果。根据待检测桩条件属性对待检测桩的桩结构进行建模,可以对待检测桩的整体状况有更为全面的分析了解。且神经网络模型,具有极强的非线性大规模参数并行分析处理能力,结合卷积神经网络处理速度时程递归图,能更好地处理桩土结构中复杂的损伤识别问题,提高桩损伤识别的准确性。</td>   <td>1.一种基于卷积神经网络的桩损伤识别方法,其特征在于,包括：根据待检测桩的条件属性对所述待检测的桩结构建立多个模型,以使所述多个模型输出所述待检测桩上预设位置点的速度时程曲线；基于所述速度时程曲线生成速度时程递归图,具体为：对所述速度时程曲线进行采样,以使所述速度时程曲线生成预设数量的速度时程数据点；根据第一预设公式对所述速度时程数据点进行差运算,生成第一矩阵；根据第二预设公式对所述速度时程数据点进行平均值运算,生成第二矩阵；根据第三预设公式对所述速度时程数据点进行阈值运算,生成第三矩阵；对所述第一矩阵、所述第二矩阵和所述第三矩阵进行归一化运算,并将归一化处理后的每一矩阵中的各元素与预设值相乘,生成三维矩阵；其中,所述三维矩阵每一元素对应所述速度时程递归图每一像素点；将所述速度时程递归图输入至预先设置的神经网络模型,以使所述神经网络模型对所述速度时程递归图进行检测,并输出所述待检测桩的损伤参数评估结果；其中,所述神经网络模型,是根据多个样本位置点的样本数据集,结合卷积神经网络训练得到的；所述样本数据集包括多个样本位置点的样本速度时程递归图以及所述样本位置点对应的样本损伤参数。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08;E02D33/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢曦;              李仁杰;              陈惠琄;                   徐冬馨       </td>   <td>中山大学</td>   <td>基于细胞穿孔的人工智能重构长周期胞内电信号方法及系统</td>   <td>广东省</td>   <td>CN114611555A</td>   <td>2022-06-10</td>   <td>本发明公开了一种基于细胞穿孔的人工智能重构长周期胞内电信号方法及系统,本发明方法利用一训练好的人工神经网络将采集的细胞胞外电信号作为输入推导重构获得对应的细胞胞内电信号；所述人工神经网络通过采集的若干细胞胞内外电信号作为训练样本,将胞外电信号作为输入,对应胞内信号作为学习目标进行训练。相比于微电极阵列-电穿孔记录细胞内电信号的方法,本发明所提出的方法可以通过细胞外电信号重构细胞内电信号,避免电穿孔仪器对细胞穿孔时造成的伤害,而且重构的细胞内动作电位具有高度准确性,为细胞研究提供更加可靠的研究信息,本发明系统包括信号采集装置和人工智能重构胞内电信号装置,系统结构简单便于推广应用。</td>   <td>1.一种基于细胞穿孔的人工智能重构长周期胞内电信号方法,其特征在于,该方法利用一训练好的人工神经网络将采集的细胞胞外电信号作为输入推导重构获得对应的细胞胞内电信号；所述人工神经网络通过采集的若干细胞胞内外电信号作为训练样本,将胞外电信号作为输入,对应胞内信号作为学习目标进行训练。</td>   <td>G06K9/00;G06N3/04;G06N3/08;G01N27/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         江峰;                   黄韬       </td>   <td>中山大学</td>   <td>高速公路服务区污水的水质水量的预测方法、系统和介质</td>   <td>广东省</td>   <td>CN114611766A</td>   <td>2022-06-10</td>   <td>本发明公开了一种高速公路服务区污水的水质水量的预测方法、系统和介质,本发明可广泛应用于污水处理技术领域。本发明通过获取的第一预设时间段内的实际车流量、实际人流量、实际性别分布、实际污水量和实际水质训练人工智能预测模型后,获取当前时间节点的实际车流量,并通过训练后的人工智能预测模型预测得到下一时间节点的预测污水量和预测水质,从而在发现预测得到的污水量和水质即将发生很大波动时,可以及时控制污水处理系统提前做好应对措施；同时,本实施例还会通过获取的第二预设时间段内的实际车流量、实际人流量、实际性别分布、实际污水量和实际水质来校验人工智能预测模型,从而提高人工智能预测模型预测结果。</td>   <td>1.一种高速公路服务区污水的水质水量的预测方法,其特征在于,包括以下步骤：获取第一预设时间段内的实际车流量、实际人流量、实际性别分布、实际污水量和实际水质作为第一数据；根据所述第一数据对人工智能预测模型进行训练；获取当前时间节点的实际车流量,所述第一预设时间段位于所述当前时间节点之前；将所述当前时间节点的实际车流量输入到训练后的所述人工智能预测模型,预测得到下一时间节点的预测污水量和预测水质；获取第二预设时间段内的实际车流量、实际人流量、实际性别分布、实际污水量和实际水质作为第二数据；根据所述第二数据校验训练后的所述人工智能预测模型。</td>   <td>G06Q10/04;G06Q50/26;G06K9/62;G06N3/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              苏博为;                   郑沛霖       </td>   <td>中山大学</td>   <td>一种恶意节点检测方法、装置、设备和存储介质</td>   <td>广东省</td>   <td>CN114612102A</td>   <td>2022-06-10</td>   <td>本申请公开一种恶意节点检测方法、装置、设备和存储介质,通过获取区块链中一个区块所包含的所有交易实际成交的顺序作为第一顺序,并获取每笔交易的汽油价格,并按照汽油价格对这个区块中的所有交易进行排序得到第二顺序,然后比较第一顺序和第二顺序,若二者不相同,则将该区块确定为目标区块,然后计算该目标区块的可获利数量是否为正值,若为正值,则确定该目标区块所对应的节点为恶意节点。该方案可以检测出区块链中哪个节点为恶意节点,从而维护区块链中交易的公平性和区块链的正常运行。</td>   <td>1.一种恶意节点检测方法,其特征在于,包括：获取区块链中一个区块所包含的所有交易的第一交易顺序和每笔交易的汽油价格,其中,所述第一交易顺序为所述所有交易实际成交的顺序；按照所述汽油价格的大小对所述区块中的所有交易进行排序,得到第二交易顺序；若第一交易顺序与第二交易顺序不同,则确定所述区块为目标区块；计算所述目标区块的可获利数量；若所述可获利数量为正值,则确定所述目标区块所对应的节点为恶意节点。</td>   <td>G06Q20/38;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何裕隆;              徐云升;              张子豪;              方圆圆;              李江;                   赵亮       </td>   <td>中山大学附属第七医院(深圳)</td>   <td>一种新型冠状病毒肺炎无症状人群筛查方法</td>   <td>广东省</td>   <td>CN114612364A</td>   <td>2022-06-10</td>   <td>本发明提供一种新型冠状病毒肺炎无症状人群筛查方法,该方法包括：S10：通过分析待筛查的红外图像单一颜色通道概率分布与预设统计模型中各类别红外图像单一颜色通道概率分布的散度,进行一级筛查；S20：通过深度学习模型,进行二级筛查。本发明通过将病灶对应的颜色通道进行筛选,在与预先建立好的统计模型进行对比,计算与不同类别标签对应的该颜色通道分布率的离散度,又增设二级筛选,通过大量学习普通肺炎和新冠肺炎肺部红外图像的形状与纹理特征,对于区分普通肺炎感染者和新冠肺炎无症状感染者肺部红外图像有较高的准确率。两层网络在运算速度和推断准确率上互补,确保模型推断的高准确率。</td>   <td>1.一种新型冠状病毒肺炎无症状人群筛查方法,其特征在于：该方法包括：S10：通过分析待筛查的红外图像单一颜色通道概率分布与预设统计模型中各类别红外图像单一颜色通道概率分布的散度,进行一级筛查；S20：通过深度学习模型,进行二级筛查。</td>   <td>G06T7/00;G16H50/80;G06N3/04;G06N3/08;G06T5/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高智凡;              张贺晔;                   冯天元       </td>   <td>中山大学</td>   <td>一种基于相邻尺度互补的冠状动脉内外膜边界分割方法</td>   <td>广东省</td>   <td>CN114612405A</td>   <td>2022-06-10</td>   <td>本发明公开了一种基于相邻尺度互补的冠状动脉内外膜边界分割方法,该方法包括：获取待测IVUS图像并输入至深度学习网络；基于多尺度密集链接的空洞卷积模块提取图像特征并建立IVUS图像和冠状动脉内膜与外膜的对应关系；基于相邻尺度的互补信息学习模块获取尺度间的互补信息,并确定冠状动脉内膜与外膜的大小和位置；基于相邻尺度的上下文补充模块获取上下文的互补信息,补充不同尺度下缺失的内膜与外膜和血管结构的相互关系；输出分割结果。通过使用本发明,能够快速精准地分割出冠状动脉内外膜边界。本发明可广泛应用于图像处理和检测领域。</td>   <td>1.一种基于相邻尺度互补的冠状动脉内外膜边界分割方法,其特征在于,包括以下步骤：获取待测IVUS图像并将待测IVUS图像输入至深度学习网络；所述深度学习网络包括多尺度密集链接的空洞卷积模块、相邻尺度的互补信息学习模块和相邻尺度的上下文补充模块；基于多尺度密集链接的空洞卷积模块对待测IVUS图像进行处理,在多个尺度下的图像提取特征并建立IVUS图像和冠状动脉内膜与外膜的对应关系；基于相邻尺度的互补信息学习模块获取尺度间的互补信息,并根据尺度间的互补信息确定冠状动脉内膜与外膜的大小和位置；基于相邻尺度的上下文补充模块获取上下文的互补信息,利用上下文的互补信息补充不同尺度下缺失的内膜与外膜和血管结构的相互关系；根据IVUS图像和冠状动脉内膜与外膜的对应关系、冠状动脉内膜与外膜的大小和位置、缺失的内膜与外膜和血管结构的相互关系,输出分割结果。</td>   <td>G06T7/00;G06T7/11;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张贺晔;              高智凡;                   冯天元       </td>   <td>中山大学</td>   <td>一种基于相邻帧一致性的冠状动脉内膜边界分割方法</td>   <td>广东省</td>   <td>CN114612407A</td>   <td>2022-06-10</td>   <td>本发明公开了一种基于相邻帧一致性的冠状动脉内膜边界分割方法,包括：获取待测OCT图像并输入至深度学习网络；基于多尺度密集链接的空洞卷积模块,提取图像特征并建立光学相干断层图像和冠状动脉内膜的对应关系；基于相邻帧信息补充模块计算光学相干断层图像中相邻帧的一致性,并获取相邻帧补充关系；根据光学相干断层图像和冠状动脉内膜的对应关系、相邻帧补充关系,输出内膜边界分割边界结果。通过使用本发明,能够快速精准地分割出冠状动脉内膜边界。本发明作为一种基于相邻帧一致性的冠状动脉内膜边界分割方法,可广泛应用于医学图像处理领域。</td>   <td>1.一种基于相邻帧一致性的冠状动脉内膜边界分割方法,其特征在于,包括以下步骤：获取待测OCT图像并输入至深度学习网络；所述深度学习网络包括多尺度密集链接的空洞卷积模块和相邻帧信息补充模块；基于多尺度密集链接的空洞卷积模块,提取图像特征并建立光学相干断层图像和冠状动脉内膜的对应关系；基于相邻帧信息补充模块计算光学相干断层图像中相邻帧的一致性,并获取相邻帧补充关系；根据光学相干断层图像和冠状动脉内膜的对应关系、相邻帧补充关系,输出内膜边界分割边界结果。</td>   <td>G06T7/00;G06T7/11;G06V10/74;G06V10/774;G06V10/82;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱祥维;              沈丹;              李天赐;              刘格陆;              戴志强;                   刘九龙       </td>   <td>中山大学</td>   <td>一种三维拓扑经验地图的构建方法、装置及相关设备</td>   <td>广东省</td>   <td>CN114612560A</td>   <td>2022-06-10</td>   <td>本申请公开了一种三维拓扑经验地图的构建方法、装置及相关设备,所述方法包括：获取设备在当前周围环境的图像信息；根据所述图像信息,获取所述设备的角速度信息、线速度信息及周围环境的特征信息；根据所述角速度信息,基于多层头朝向细胞模型,计算得到所述设备在多层头朝向细胞的方向信息表征；根据所述线速度信息,基于三维网格细胞模型,计算得到所述设备在三维网格细胞的位置信息表征；根据所述方向信息表征、所述位置信息表征以及所述特征信息,构建三维拓扑经验地图。本申请采用生物脑启发式的认知方法,实现了对三维拓扑经验地图的构建,对于满足一定精度条件下实现各种无人智能移动机器人的鲁棒稳健低功耗导航,具有重要的应用价值。</td>   <td>1.一种三维拓扑经验地图的构建方法,其特征在于,包括：获取设备在当前周围环境的图像信息；根据所述图像信息,获取所述设备的角速度信息、线速度信息及周围环境的特征信息；根据所述角速度信息,基于多层头朝向细胞模型,计算得到所述设备在多层头朝向细胞的方向信息表征；根据所述线速度信息,基于三维网格细胞模型,计算得到所述设备在三维网格细胞的位置信息表征；根据所述方向信息表征、所述位置信息表征以及所述特征信息,构建三维拓扑经验地图。</td>   <td>G06T7/73;G06T17/05;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余阳;              吕京泽;                   严有强       </td>   <td>中山大学</td>   <td>基于随机回归森林模型的容器资源供给方法及系统</td>   <td>广东省</td>   <td>CN108984269B</td>   <td>2022-06-07</td>   <td>本发明提供了一种基于随机回归森林模型的容器资源供给方法,其在负载动态变化的情况下,以用户实际响应时间和访问量为依据,迅速对变化为高负载的微服务进行扩容以解决大量用户一起访问同一个服务所造成的负载过重、响应时间过长的问题；并且当服务器为高负载服务集群提供大量容器资源后,负载突然递减时,能够对处于低负载的微服务快速回收资源,以达到保证用户服务质量和优化资源利用的目的。</td>   <td>1.一种基于随机回归森林模型的容器资源供给方法,其特征在于：包括以下步骤：S1.数据采集器周期性从网关处统计用户访问的记录详情,统计出各服务的响应时间和访问量；S2.服务调度器周期性地向数据采集器请求统计到的各个服务的响应时间和访问量,然后使用自回归时间序列方法分别基于各个服务的响应时间和访问量构建相应的预测模型,对各个服务未来一段时间内的响应时间和访问量进行预测；S3.服务调度器根据预测的响应时间判断各个服务在未来一段时间内的负载状态,形成高负载列表、低负载列表、正常负载列表,交由调度执行器处理；S4.调度执行器获得负载列表,将高负载列表和低负载列表交给有针对性弹性收缩器进行处理；所述有针对性弹性收缩器的分析处理数据模型为基于随机回归森林的模型；S5.有针对性弹性收缩器对高、低负载列表中的服务分别进行遍历处理,对于每一个服务,根据统计到的在一个周期内服务的响应和访问量得到一个数值X,在此期间保护冷却时间调度,将高、低负载列表中的服务对应的X值交由调度执行器处理,最后执行相应的调度；所述有针对性弹性收缩器的分析处理数据模型需要经过训练过程的处理,其训练的具体过程如下：(1)给定训练集S(访问量,响应时间,建议开设容器数),测试集T(访问量,响应时间,建议开设容器数),特征维数F；确定参数：使用到的CART的数量t,每棵树的深度d,每个节点使用到的特征数量f；终止条件：节点上最少样本数s,节点上最少的信息增益m；对于第1-t棵树,i＝1-t；(2)从S中有放回的抽取大小和S一样的训练集S(i),作为根节点的样本,从根节点开始训练；(3)如果当前节点上达到终止条件,则设置当前节点为叶子节点,预测输出为当前节点样本集各个样本值的平均值；然后继续训练其他节点；如果当前节点没有达到终止条件,则从F维特征中无放回的随机选取f维特征；利用这f维特征,寻找分类效果最好的一维特征k及其阈值th,当前节点上样本第k维特征小于阈值th的样本被划分到左节点,其余的被划分到右节点；继续训练其他节点；(4)重复(2)(3)直到所有节点都训练过了或者被标记为叶子节点；(5)重复(2),(3),(4)直到所有CART都被训练过；所述步骤S1对用户访问记录详情的响应时间和访问量进行实时的卡尔曼滤波处理；所述服务调度器通过设置阈值进行对比判断来得到高负载列表、低负载列表、正常负载列表,其中设置的阈值包括R-(u1)～i,R-(u2)～i,R-(u3)～i,R-(d1)～i,R-(d2)～i,R-(d3)～i,其中R-(u1)～i,R-(u2)～i,R-(u3)～i反映高负载的负载过重程度,R-(d1)～i,R-(d2)～i,R-(d3)～i反应低负载的负载过轻程度；有针对性弹性收缩器的分析处理数据模型预测得到数值X的具体过程如下：对于第1-t棵树,i＝1-t：(1)从当前树的根节点开始,根据当前节点的阈值th,判断是进入左节点(&lt;th)还是进入右节点(&gt;＝th),直到到达某个叶子节点,并输出预测值X-i；(2)重复执行(1)直到所有t棵树都输出了预测值；输出为所有树的输出的平均值X；将高、低负载列表中的服务对应的X值交由调度执行器处理的具体过程如下：对于高负载列表中的服务：根据统计到的在一个周期内服务的响应和访问量得到一个数值X,将这个X值与此服务对应的资源池容器数量Y和此服务的实际开设容器数量Z的求和结果(Y+Z)进行比较,如果X不大于(Y+Z),则直接调用资源池中的容器进行扩容处理,否则在调用资源池中的容器的基础上,再额外启动(X-Y-Z)个容器；对于低负载列表中的服务：根据统计到的在一个周期内服务的响应时间和访问量得到一个数值X,将这个X值与此服务的实际开设容器数量Z进行比较,如果X小于Z,则收回(Z-X)个容器,否则不做处理。</td>   <td>G06F9/455;G06F9/50;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王亮;              危义民;              张志勇;              苏燮阳;              王鲁平;              丘昌镇;              郑嘉俊;                   廖义冠       </td>   <td>中山大学;深圳市安比科技有限公司;深圳市正阳升智能科技有限公司</td>   <td>一种隧道形变检测方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN114581371A</td>   <td>2022-06-03</td>   <td>本发明公开了一种隧道形变检测方法、系统、设备及存储介质,涉及计算机视觉处理技术领域。所述方法,包括：根据点云数据和视频图像,识别隧道目标；对所述隧道目标进行分割,得到单独目标集,并保存在历史数据库中；其中所述单独目标集包括若干个单独目标,所述历史数据库保存有若干组不同时间检测的单独目标集；利用中轴线左右定界算法对所述历史数据库中的若干个所述单独目标集进行数据比对,得到隧道目标形变程度。本发明对点云数据进行分割处理,并结合历史数据进行数据比对,利用中轴线左右定界算法能够判断隧道是否发生形变,同时对形变区段进行定位,可以很大程度上减少轨道巡检的工作量,提高形变检测的区间精度。</td>   <td>1.一种隧道形变检测方法,其特征在于,包括：根据点云数据和视频图像,识别隧道目标；对所述隧道目标进行分割,得到单独目标集,并保存在历史数据库中；其中所述单独目标集包括若干个单独目标,所述历史数据库保存有若干组不同时间检测的单独目标集；利用中轴线左右定界算法对所述历史数据库中的若干个所述单独目标集进行数据比对,得到隧道目标形变程度。</td>   <td>G06T7/00;G06T7/11;G01B21/32;G06N3/04;G06N3/08;G06T5/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄炳升;              蔡洵;              曾英候;              陈亮亮;              冯仕庭;                   宋晨宇       </td>   <td>深圳大学;中山大学附属第一医院</td>   <td>基于深度学习的肝细胞癌磁共振图像分割系统和方法</td>   <td>广东省</td>   <td>CN110619635B</td>   <td>2022-05-31</td>   <td>本发明公开了基于深度学习的肝细胞癌磁共振图像分割系统和方法,该方法包括：获取肝细胞癌肿瘤患者的多序列磁共振成像图像；将获取的多序列磁共振成像图像输入至深度融合网络模型中,从而获得病灶分割结果图；所述深度融合网络模型包括深度卷积网络模块和多序列融合模块,所述深度卷积网络模块划分为多个序列通道,所述多序列融合模块用于融合所有序列通道处理多序列磁共振成像图像的处理结果。本发明通过深度融合网络模型来对多序列磁共振成像图像进行病灶分割,能够获得较好的分割效果,并且分割更加准确。本发明作为基于深度学习的肝细胞癌磁共振图像分割系统和方法可广泛应用于医学图像处理领域。</td>   <td>1.基于深度学习的肝细胞癌磁共振图像分割方法,其特征在于：包括以下步骤：获取肝细胞癌肿瘤患者的多序列磁共振成像图像；将获取的多序列磁共振成像图像输入至深度融合网络模型中,从而获得病灶分割结果图；所述深度融合网络模型包括深度卷积网络模块和多序列融合模块,所述深度卷积网络模块划分为多个序列通道,其中每个序列通道均用于处理所述多序列磁共振成像图像中的一个序列的磁共振成像图像,所述多序列融合模块用于融合所有序列通道处理多序列磁共振成像图像的处理结果；所述深度融合网络模型为预先训练好的深度融合网络模型,所述预先训练好的深度融合网络模型的训练步骤具体包括：获取若干个肝细胞癌肿瘤患者的多序列磁共振成像图像和多序列磁共振成像图像对应的金标准图；将获取的多序列磁共振成像图像输入深度卷积网络模块进行第一训练,从而得到磁共振成像图像对应的第一序列分割得分图；根据得到的第一序列分割得分图和所述金标准图对深度卷积网络模块的网络权重做调整直至深度卷积网络模块训练结束；将训练结束时的深度卷积网络模块的网络权重作为初始网络权重输入至深度融合网络模型中,并将获取的多序列磁共振成像图像输入深度融合网络模型进行第二训练,从而得到第二序列分割得分图；根据得到的第二序列分割得分图和所述金标准图对深度融合网络模型的网络权重做调整；所述将获取的多序列磁共振成像图像输入深度卷积网络模块进行第一训练,从而得到磁共振成像图像对应的第一序列分割得分图这一步骤,其具体包括：将获取的磁共振成像图像输入深度卷积网络中进行特征提取,从而获得特征图；将获得的特征图进行得分图重建后得到第一序列分割得分图。</td>   <td>G06T7/11;G06T7/30;G06V10/25;G06V10/80;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郝华颖;              赵一天;              蒋珊珊;              李飞;              张秀兰;                   刘江       </td>   <td>中国科学院宁波材料技术与工程研究所慈溪生物医学工程研究所;中国科学院宁波材料技术与工程研究所;中山大学中山眼科中心</td>   <td>一种基于卷积循环神经网络的AS-OCT图像的房角分类方法</td>   <td>浙江省</td>   <td>CN112712531B</td>   <td>2022-05-31</td>   <td>本发明公开一种基于卷积循环神经网络的AS-OCT图像的房角分类方法,使用全局扫描对齐方法对AS-OCT切片进行对齐操作,解决眼睛不自主运动和眼睛的光轴不适当放置的可能性导致的图像错位；采用深度学习分割算法对虹膜进行分割,从而由虹膜根部确定ACA的区域；基于卷积循环神经网络同时对二维图像和图像序列信息进行建模,提高网络对窄角和粘连的分类性能。本发明能够对开、狭窄和粘连的青光眼进行准确分类,达到世界先进水平。</td>   <td>1.一种基于卷积循环神经网络的AS-OCT图像的房角分类方法,其特征在于包括如下步骤：1)分别采集黑暗和明亮光照条件下的AS-OCT图像,得到两个AS-OCT图像序列；2)使用全局扫描对齐方法分别对两个AS-OCT图像序列进行对齐操作；3)采用深度学习分割算法对虹膜进行分割,由虹膜根部确定ACA区域,分别得到黑暗和明亮光照条件下ACA区域的AS-OCT图像序列；4)构建卷积循环神经网络,分别将黑暗和明亮光照条件下ACA区域的AS-OCT图像序列输入卷积循环神经网络,提取二维图像特征,并对两种光照条件下的二维图像特征序列进行动态分析,最后将两种光照条件下获得的动态特征融合并进行ACA分类。</td>   <td>G06T7/11;G06T7/00;G06N3/08;G06N3/04;G06K9/62;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄方军;                   钟亦友       </td>   <td>中山大学</td>   <td>基于预测误差扩展的可逆图像认证方法及系统</td>   <td>广东省</td>   <td>CN114565500A</td>   <td>2022-05-31</td>   <td>本发明涉及图像信息安全领域,为基于预测误差扩展的可逆图像认证方法及系统,包括步骤：将图像分为若干不重叠图像块,将块中像素划分为灰色集合和白色集合；计算每块的认证码；分别计算所有块中灰色集合、白色集合像素的预测误差,根据嵌入容量将块定义为差分块或平移块；对于差分块采用差值扩展的方式嵌入认证码；对于平移块采用预测误差直方图平移的方式嵌入认证码；按照嵌入方法的逆操作,依次从每块中提取出所嵌入的认证码并恢复该块,将提取出的认证码与重新生成的认证码对比,判断图像是否被篡改。本发明采用两种不同的可逆嵌入方式,对几乎所有块都能独立进行可逆认证,在相同分块大小下嵌入更多认证信息,可实现更高的篡改检测正确率。</td>   <td>1.基于预测误差扩展的可逆图像认证方法,其特征在于,包括以下步骤：S1、将图像分为若干不重叠图像块,每个图像块大小一致,并将图像块中的像素按照棋盘格划分为灰色集合和白色集合,灰色集合的图像块与白色集合的图像块交错排列；S2、根据哈希函数计算每个图像块的认证码；S3、计算灰色集合中所有图像块像素的预测误差,按照嵌入容量将图像块定义为差分块或平移块；S4、对于差分块,采用差值扩展方式嵌入认证码；对于产生溢出的像素,将其位置信息和溢出量以二进制的形式顺次保存在动态数组S＝{s-1,s-2,...,s-n}中；重复该步骤直到处理完该集合中的所有图像块；S5、对于平移块,采用预测误差直方图平移的方式嵌入认证码；对于容量V＜3的平移块只嵌入认证码；对于容量y≥3的平移块,除了嵌入V-1比特认证码,还将依次从步骤S4的动态数组S中取出1比特进行嵌入；重复该步骤直到处理完该集合中的所有图像块；S6、计算白色集合中所有图像块像素的预测误差,按照嵌入容量将图像块定义为差分块或平移块；并执行步骤S4-S5,直到所有图像块完成两层嵌入操作；S7、在认证阶段,按照嵌入方法的逆操作,依次从每个图像块中提取出所嵌入的认证码并恢复该图像块,将提取出的认证码与重新生成的认证码对比,若相同则判断图像为真实图像,若不相同则判断图像被篡改。</td>   <td>G06T1/00;G06T5/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘洁;              黄聪;                   唐钢       </td>   <td>中山大学</td>   <td>一种基于环芯光纤光斑的熔接偏移量的检测方法</td>   <td>广东省</td>   <td>CN114565595A</td>   <td>2022-05-31</td>   <td>本发明属于光纤传感技术领域,更具体地,涉及一种基于环芯光纤光斑的熔接偏移量的检测方法。利用环芯光纤稳定、形态结构区分度高的光纤光斑,对在不同错位熔接偏移量下采集到的光斑进行高精度卷积神经网络的光斑识别训练,打破了现有的仅利用少模光纤高阶模式的背向瑞利散射对光纤熔接损耗的测量的局限,实现了对熔接过程中光纤偏移量的测量,提高了熔接质量检测的准确度。</td>   <td>1.一种基于环芯光纤光斑的熔接偏移量的检测方法,其特征在于,包括以下步骤：S1.系统的搭建：搭建针对环芯光纤错位熔接的表征系统,所述系统包括：激光器、透镜、四分之一玻片、反射镜、涡旋相位板、两根待熔接的环芯光纤、光纤熔接机、CCD相机；S2.数据采集：激光器发出的光经透镜准直之后,经过四分之一玻片变成圆偏振；光传输到涡旋相位板上进行模式调制,再经由透镜耦合进第一根待熔接的环芯光纤中；在光纤熔接机中,先对准第一根和第二根待熔接的环芯光纤,后根据实验需要调整两根待熔接的环芯光纤之间的轴向偏移量；在第二根待熔接的环芯光纤的尾端,放置一个CCD相机,用来采集不同熔接偏移量情况下的光纤出射光斑；S3.光斑图像的处理：在计算机上处理采集到的光斑数据,先对两根光纤在不同偏移量下采集的每张图像与对准情况下采集到的图像的平均图像做绝对值差分处理,再将经过绝对值差分后的图像进行剪裁,作为卷积神经网络的输入图像；S4.神经网络的训练与预测：经过剪裁后的图像输入到卷积神经网络,利用卷积神经网络对图像进行训练和预测,在训练阶段,输出层预测的偏移量将与输入图像实际对应偏移量构造交叉熵损失函数,通过梯度的反向传播与随机梯度下降的方法更新卷积神经网络的参数；在预测阶段,输出层输出的数据将直接作为图像对应的偏移量。</td>   <td>G06T7/00;G06T5/50;G06N3/04;G06N3/08;G01M11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韩宇潇;              陈志广;                   卢宇彤       </td>   <td>中山大学</td>   <td>一种精准的周期性检测方法、系统及存储介质</td>   <td>广东省</td>   <td>CN114548173A</td>   <td>2022-05-27</td>   <td>本发明公开了一种精准的周期性检测方法、系统及存储介质,该方法包括：基于去除异常点方法,对捕获的时间序列进行预处理,得到预处理后的时间序列；对预处理后的时间序列进行离散小波变换去噪处理,得到不同层次的去噪时间序列；对不同层次的去噪时间序列进行自相关函数计算,得到候选周期值；结合历史数据对候选周期值进行周期性验证计算,得到最终周期值。该系统包括：第一数据获取模块、第二数据获取模块、第三数据获取模块和最终数据获取模块。通过使用本发明,能够在不降低预测效率的同时提高预测结果的精准性。本发明作为一种精准的周期性检测方法、系统及存储介质,可广泛应用于计算机数据处理技术领域。</td>   <td>1.一种精准的周期性检测方法,其特征在于,包括以下步骤：基于去除异常点方法,对捕获的时间序列进行预处理,得到预处理后的时间序列；对预处理后的时间序列进行离散小波变换去噪处理,得到不同层次的去噪时间序列；对不同层次的去噪时间序列进行自相关函数计算,得到候选周期值；结合历史数据对候选周期值进行周期性验证计算,得到最终周期值。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         范双双;              曹颖杰;              王文波;                   桂瑞       </td>   <td>中山大学</td>   <td>一种鲸类动物的检测方法、装置、移动终端及存储介质</td>   <td>广东省</td>   <td>CN114548184A</td>   <td>2022-05-27</td>   <td>本发明公开了一种鲸类动物的检测方法、装置、移动终端及存储介质,所述方法包括：获取第一回声定位信号,根据第一回声定位信号判定预设水域内存在鲸类动物时,根据第一回声定位信号控制摄像头运动,以使摄像头采集鲸类动物的初始图像信息；获取并根据初始图像信息进行移动预测,生成预测结果；根据预测结果控制摄像头运动,以使摄像头采集鲸类动物的移动图像信息,完成鲸类动物的声光融合检测。采用本发明实施例能提高鲸类动物的检测准确性和检出率。</td>   <td>1.一种鲸类动物的检测方法,其特征在于,包括：获取第一回声定位信号,根据所述第一回声定位信号判定预设水域内存在鲸类动物时,根据所述第一回声定位信号控制摄像头运动,以使所述摄像头采集所述鲸类动物的初始图像信息；获取并根据所述初始图像信息进行移动预测,生成预测结果；根据所述预测结果控制所述摄像头运动,以使所述摄像头采集所述鲸类动物的移动图像信息,完成所述鲸类动物的声光融合检测。</td>   <td>G06K9/00;G06K9/62;G06V20/05;G06V10/30;G06V10/44;G06V10/774;G06V10/764;G06V10/82;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵俊雄;              吴倩妮;                   夏俐       </td>   <td>中山大学</td>   <td>一种基于区块链的碳排放权质押融资方法和系统</td>   <td>广东省</td>   <td>CN114549169A</td>   <td>2022-05-27</td>   <td>本发明公开了一种碳排放权质押融资方法和系统,应用于区块链网络。该方法包括：融资节点将企业信息和碳排放权信息上传至区块链网络；登记节点对质押的碳排放权信息以及企业信息进行签名认证；预言机获取质押碳排放权信息,并对质押碳排放权的价值进行计算；融资节点向金融节点发起融资申请；金融节点确定贷款额度或授信额度后部署贷款合约；融资节点和金融节点共同向登记节点发出碳排放权质押登记申请；金融节点根据贷款合约向融资节点发放贷款并广播贷款发放情况；融资节点确认收到贷款后广播收款情况。本发明能够对碳排放权价值进行快速和可信确认,以管控贷款风险,提升碳排放权质押融资效率。</td>   <td>1.一种碳排放权质押融资方法,应用于区块链网络,其特征在于,包括：步骤S1：融资节点将企业信息和碳排放权信息上传至区块链网络,碳排放权信息包括碳排放权质押数量信息、碳排放权状态信息；步骤S2：全国碳排放权注册登记机构节点,在区块链网络上对质押的碳排放权信息以及企业信息进行签名认证；步骤S3：融资节点向预言机提出申请以对碳排放权价值进行计算；步骤S4：预言机从区块链网络获取质押碳排放权信息,并对质押碳排放权的价值进行计算,并将计算结果上传至区块链网络；步骤S5：融资节点在区块链网络上向金融节点发起融资申请；步骤S6：金融节点确定贷款额度或授信额度后部署贷款合约,双方进行哈希签名确认；步骤S7：融资节点和金融节点在区块链网络上共同向全国碳排放权注册登记机构节点发出碳排放权质押登记申请；步骤S8：全国碳排放权注册登记机构节点办理完碳排放权质押登记后将碳排放权质押登记通知书上传至区块链网络；步骤S9：金融节点根据贷款合约向融资节点发放贷款并在区块链网络上广播贷款发放情况；步骤S10：融资节点确认收到贷款后在区块链网络上广播收款情况。</td>   <td>G06Q40/02;G06Q40/06;G06F16/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙一言;                   倪江群       </td>   <td>中山大学</td>   <td>结合深度鲁棒水印和模板同步的抗拍摄监控视频水印方法</td>   <td>广东省</td>   <td>CN114549270A</td>   <td>2022-05-27</td>   <td>本发明针对现有技术的局限性,提出了一种结合深度鲁棒水印和模板同步的抗拍摄监控视频水印方法,巧妙地利用了监控视频中通常有部分背景内容基本不变的特点,选取部分背景图像作为水印载体；其使用的深度鲁棒水印网络能够往水印载体图像中嵌入肉眼不可见且抗拍摄的鲁棒水印；同时通过加大纹理简单区域的水印嵌入代价,引导网络尽量将水印信息嵌入在纹理复杂区域,改进了StegaStamp嵌入痕迹在图像平滑区域较明显的缺点,显著提升了水印的视觉质量。</td>   <td>1.一种结合深度鲁棒水印和模板同步的抗拍摄监控视频水印方法,其特征在于,通过以下步骤在监控视频中嵌入水印信息：S11,从监控视频中的背景区域,选取背景图像内容相对固定的矩形区域,作为水印嵌入的模板区域；S12,提取所述监控视频在流缓冲区中的视频帧,根据所述模板区域,从所述视频帧中获取截取图像作为载体图像；S13,获取所述监控视频的设备号信息以及当前时间戳,编码为二进制比特序列；将所述二进制比特序列与对应的CRC校验码以及BCH纠错码拼接,生成水印信息；S14,将所述载体图像以及水印信息,输入预设的深度鲁棒水印网络,通过所述深度鲁棒水印网络中的编码器生成水印图像；其中,所述深度鲁棒水印网络为以StegaStamp为基础、结合了图像块感知相似损失函数以及基于图像纹理模板的YUV空间差分损失函数的深度学习框架训练获得；S15,以所述水印图像对所述视频帧在模板区域的图像进行替换。</td>   <td>G06T1/00;H04N5/262</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄方军;                   李帆       </td>   <td>中山大学</td>   <td>基于深度神经网络的自适应鲁棒水印嵌入方法及系统</td>   <td>广东省</td>   <td>CN114549273A</td>   <td>2022-05-27</td>   <td>本发明涉及深度学习与鲁棒水印交叉领域,为基于深度神经网络的自适应鲁棒水印嵌入方法及系统,包括：随机选取载体图像和生成水印序列信息；对载体图像和水印序列进行预处理；对预处理后的载体图像和水印序列信息进行编码,输出修改比例图；对载体图像进行高斯滤波,计算嵌入水印序列信息时允许修改的最大值,输出阈值图；计算由水印信息映射而成的特征噪声模板,生成水印图像；对水印图像添加噪声和进行图像攻击处理操作,生成被攻击的水印图像；接收被攻击的水印图像,输出预测的水印信息序列。本发明可自适应嵌入水印信息,对于载体图像纹理复杂区域修改量大,而对于平滑区域修改量小,具有更好的视觉质量,同时有很强的鲁棒性。</td>   <td>1.基于深度神经网络的自适应鲁棒水印嵌入方法,其特征在于,包括以下步骤：S1、随机选取载体图像I-c和生成随机0-1水印序列信息Msg作为训练数据集；S2、对载体图像和水印序列信息进行预处理；S3、对预处理后的载体图像和水印序列信息进行编码,输出修改比例图M-(map)；S4、对载体图像进行高斯滤波,并计算嵌入相应的水印序列信息时允许修改的最大值,根据计算结果输出阈值图T-(map)；S5、计算由水印序列信息映射而成的特征噪声模板N-(pat),将特征噪声模板叠加到载体图像I-c上生成水印图像I-w；S6、对水印图像I-w进行相应的图像攻击处理操作和添加噪声,生成被攻击的水印图像I′-w；S7、对被攻击的水印图像I′-w进行解码,输出预测的水印信息序列Msg～p。</td>   <td>G06T1/00;G06T5/00;G06T5/10;G06T5/20;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         莫泽威;              张献伟;              葛天傲;                   卢宇彤       </td>   <td>中山大学</td>   <td>一种基于编译的核函数自动多流调度方法</td>   <td>广东省</td>   <td>CN114549277A</td>   <td>2022-05-27</td>   <td>本发明公开了一种基于编译的核函数自动多流调度方法,包括：读取源代码,识别核函数的输入与输出；根据输入与输出构建DAG；对DAG进行层次化,并根据拓扑排序为核函数赋予适当的流；为跨流同步的核函数插入事件同步代码；生成可执行文件。本发明是首个通过LLVM编译器框架将串行的GPU核函数通过CUDA框架的多流机制并行化,从而提高程序性能与GPU硬件利用率。该发明不引入额外的编程模型与运行时开销,减小了开发者的学习成本与开发成本。同时该发明使用的流调度算法将存在数据依赖关系的核函数的运行时机临近安排,尽可能提高GPU对数据的访存效率,从而提高程序性能。</td>   <td>1.一种基于编译的核函数自动多流调度方法,其特征在于,包括以下步骤：步骤1、读取源代码,识别核函数的输入与输出；步骤2、根据输入与输出构建DAG；步骤3、对DAG进行层次化,并根据拓扑排序为核函数赋予适当的流；步骤4、为跨流同步的核函数插入事件同步代码；步骤5、生成可执行文件。</td>   <td>G06T1/20;G06F9/50;G06F8/41</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              许晓倩;              魏朋旭;              毛明志;                   林倞       </td>   <td>中山大学</td>   <td>基于无监督领域自适应的图像超分辨方法及装置</td>   <td>广东省</td>   <td>CN114549322A</td>   <td>2022-05-27</td>   <td>本申请公开了一种基于无监督领域自适应的图像超分辨方法及装置,在源域能访问到成对的LR和HR数据,目标域仅能访问到LR数据的情况下,实现源域模型到目标域的迁移,通过设计两个对称的分支网络(源分支网络和目标分支网络),共同处理源域和目标域数据,并采用域间对抗自适应机制,通过不同域之间的对抗实现域间迁移；采用域内对抗自适应机制,通过域内对抗实现两个分支之间的对齐,同时添加重建一致性约束和VGG损失,以确保训练过程的稳定性,从而使适应到目标域的SR网络存在性能稳定。</td>   <td>1.一种基于无监督领域自适应的图像超分辨方法,其特征在于,包括：获取目标相机的第一低分辨率LR图像和源相机的图像对,所述图像对包含第二LR图像和高分辨率HR图像；将所述第一LR图像和所述第二LR图像,输入到预设的对偶对抗网络模型,输出多个最终超分辨SR图像,所述对偶对抗网络模型包括针对所述第二LR图像所在源域的源分支网络和针对所述第一LR图像所在目标域的目标分支网络；根据多个所述最终SR图像和所述HR图像,确定所述对偶对抗网络模型的损失函数值,并根据所述损失函数值更新所述对偶对抗网络模型的模型参数,直至所述损失函数值小于预设值,得到目标超分辨网络,所述损失函数值包含重建损失值、源域内容损失值、目标域内容损失值、目标域VGG损失值、源域与目标域之间的域间损失值、源域的域内损失值以及目标域的域内损失值；利用所述目标超分辨网络中的目标分支网络,对目标相机采集的目标LR图像进行处理,输出目标SR图像。</td>   <td>G06T3/40;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              梁松亮;              林格;                   苏卓       </td>   <td>中山大学</td>   <td>基于雨线特征重构的多维聚合网络的图像去雨方法与系统</td>   <td>广东省</td>   <td>CN114549334A</td>   <td>2022-05-27</td>   <td>本发明公开了基于雨线特征重构的多维聚合网络的图像去雨方法与系统。包括：首先,从数据库中获取图像数据集,进行图像预处理,为所获取的图像加上雨线效果；其次,构建包括构建深域特征重构模块和广域特征重构等模块,构建基于雨线特征重构提取的多维聚合网络,输入为有雨图像,得到多维聚合特征,经过图像重建模块,输出为去雨图像；然后,进行网络训练,获到训练好的多维聚合网络；最后,将待处理的有雨图像输入训练好的基于雨线特征重构提取的多维聚合网络,输出去雨图像。本发明提出的多维聚合网络更为高效,其特征模块可学习到雨线复杂多变的形态提取图像中不同尺度的信息,可最大限度地保留图像细节,获得图像视觉效果更好。</td>   <td>1.基于雨线特征重构的多维聚合网络的图像去雨方法,其特征在于,所述方法包括：从数据库中获取图像数据集,进行图像预处理,为所获取的图像加上雨线效果,并构建训练集和测试集；构建深域特征重构模块和广域特征重构模块,输入待重构特征分别进行通道重构和空间重构,分别输出深域重构特征和广域重构特征；构建雨线特征重构提取模块,由所述深域特征重构模块和所述广域特征重构模块组成,将所述深域重构特征和所述广域重构特征沿通道维度拼接,并进行卷积等操作,得到中间特征；构建多维特征聚合模块,对输入的所述中间特征进行多维聚合,输出聚合后的多维聚合特征；构建基于雨线特征重构提取的多维聚合网络,主要由卷积块、所述雨线特征重构提取模块、所述多维特征聚合模块和图像重建模块组成,其输入为有雨图像,得到所述多维聚合特征,经过图像重建模块,输出为去雨图像；利用所述训练集,使用多重损失训练所述基于雨线特征重构提取的多维聚合网络,并使用所述测试集进行测试验证,获到训练好的基于雨线特征重构提取的多维聚合网络；将待处理的有雨图像输入所述训练好的基于雨线特征重构提取的多维聚合网络,输出去雨图像。</td>   <td>G06T5/00;G06V10/774;G06V10/82;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭键清;                   陈启瀚       </td>   <td>中山大学</td>   <td>一种医疗器械自主识别定位方法、系统及介质</td>   <td>广东省</td>   <td>CN114549640A</td>   <td>2022-05-27</td>   <td>本发明公开了一种医疗器械自主识别定位方法、系统及介质,方法包括以下步骤：获取图片,然后进行数据预处理；对预处理后的数据通过优化训练算法进行优化训练,通过优化误差表达和调整误差权重,加快箭头包围盒的训练收敛速度；优化训练得到的最佳权重用于实时预测,实时预测的输出通过输出约束模型保证箭头落在包围盒内部；根据所述输出约束模型,通过箭头包围盒生成算法以坐标转换方式生成对应的箭头包围盒；通过器械数目判断选择对应的焦点生成区域算法,根据所述箭头包围盒生成对应的跟踪区域,实现器械定位。本发明实现多种医疗器械的快速准确识别,实时准确地给出器械的位置和角度等关键信息,提高医疗器械自动识别的准确性和实时性。</td>   <td>1.一种医疗器械自主识别定位方法,其特征在于,包括以下步骤：获取图片,然后进行数据预处理,对标注的数据进行数据增强,然后将数据划分成训练集、验证集和测试集；其中,数据增强包括反转、裁剪和拼接；对预处理后的数据通过优化训练算法进行优化训练,通过优化误差表达和调整误差权重,加快箭头包围盒的训练收敛速度；优化训练得到的最佳权重用于实时预测,实时预测的输出通过输出约束模型保证箭头落在包围盒内部；根据所述输出约束模型,通过箭头包围盒生成算法以坐标转换方式生成对应的箭头包围盒；通过器械数目判断选择对应的焦点生成区域算法,根据所述箭头包围盒生成对应的跟踪区域,实现器械定位,为器械跟踪提供指导。</td>   <td>G06T7/73;G06V10/25;G06V10/774;G06V10/82;G06N3/04;G06N3/08;A61B90/90;A61B34/20;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         闫立伟;              朱爽;              刘小林;              戚剑;              朱庆棠;              陆遥;              郭永泽;              喻莎;              卢宇彤;              张曦;              杜云飞;                   林焘       </td>   <td>中山大学附属第一医院;中山大学数据科学与计算机学院;中山大学国家超级计算广州中心</td>   <td>人体周围神经内部束型结构三维重建可视化集成方法</td>   <td>广东省</td>   <td>CN107278316B</td>   <td>2022-05-24</td>   <td>一种人体周围神经内部束型结构三维重建可视化集成方法。该方法包括：获取人的周围神经,用碘剂染色联合冷冻干燥法制备离体神经标本；利用Micro CT扫描经前期处理的周围神经,获得二维图像,并对所述二维图像进行二值化处理再根据纹理特征进行图像分割,获取神经束图像；将所述分割的图像利用超级计算机重建为可视化模型。该获取图像的方法使扫描精度达到了重建神经束的要求；可视化模型可为临床达到神经束间吻合提供立体化的解剖图谱；同时获取的三维数据可为生物制造神经生物材料到达精准修复建立了模板。</td>   <td>1.一种人周围神经束可视化模型的构建方法,所述人周围神经束各处具有基本相同的密度,所述构建方法包括：步骤1)：获取人的周围神经,先用固定剂固定所述周围神经,其中所述固定剂为3.5％-4.5％多聚甲醛或9％-11％的戊二醛溶液,然后对所述周围神经进行切段,再用碘剂对所述周围神经进行染色,其中所述碘剂为40％-50％的碘溶液,步骤2)：在步骤1)之后,将所述周围神经置于液氮中速冻,再将所述周围神经置于冷冻干燥机中以使用冷冻干燥方法处理所述周围神经,从而除去所述周围神经中的水分；步骤3)：利用Micro CT扫描预处理的周围神经,获得二维图像,其中视野直径设置为9mm,体素大小设置为3um,并对所述二维图像进行二值化处理,再根据纹理特征进行图像分割,获取神经束图像；步骤4)：将所述神经束图像重建为可视化模型。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何慧;                   马争鸣       </td>   <td>中山大学</td>   <td>一种基于黎曼流形切空间和局部同胚的SPD数据的字典学习算法</td>   <td>广东省</td>   <td>CN114528917A</td>   <td>2022-05-24</td>   <td>本发明研究SPD数据字典学习的问题。SPD数据的全体并不构成线性空间,而字典学习本质上就是稀疏线性编码,因此,字典学习不能直接在SPD数据上进行。SPD数据在一定的拓扑结构和黎曼度量之下可以构成一个黎曼流形,而黎曼流形的切空间都是有限维的Hilbert空间,与欧式空间同构。因此,本发明提出另一种SPD数据字典学习的算法,首先把SPD数据变换到SPD黎曼流形的切空间,在切空间上进行字典学习。由SPD黎曼流形的切空间就是对称矩阵空间,而对称矩阵包含SPD矩阵。因此,本发明提出的SPD数据变换方法,在数据形态和性质上带来变化都是最小的。进一步,在字典学习的过程中,本发明还添加字典学习样本与样本字典编码之间局部同胚的正则化约束。</td>   <td>1.一种基于黎曼流形切空间和局部同胚的SPD数据的字典学习算法,其特征在于：A.提出一种基于黎曼流形切空间的非欧数据机器学习的框架,所谓非欧数据就是数据全体不构成欧式空间的数据,例如SPD数据,目前,非欧数据在机器学习中日渐普遍,但是,大多数机器学习算法都是基于欧式空间研发,因此,这些机器学习算法不能直接应用于非欧数据,目前,常用的方法是把非欧数据变换到RKHS,RKHS是无限维的Hilbert空间,也不是欧式空间,变换的数据还需要进一步变换到RKHS的一个有限维子空间,这就是所谓基于RKHS子空间学习的非欧数据机器学习框架,虽然,非欧数据的全体不构成一个欧式空间,但却往往可以构成一个黎曼流形,而黎曼流形的切空间都是有限维的Hilbert空间,本质上就是欧式空间,因此,本文提出另一种非欧数据机器学习的框架,在这个框架中,首先对非欧数据集赋予一定的拓扑结构和黎曼度量,使其成为一个黎曼流形,然后把黎曼流形的数据变换到黎曼流形的切空间,最后根据具有的机器学习的任务,利用黎曼流形的测地距离和切空间的线性和内积运算在切空间中进行机器学习。B.提出一种基于黎曼流形切空间的SPD数据字典学习算法(RMTS-SPDDL),SPD数据是目前机器学习最常见的非欧数据,对线性运算不具有封闭性,而字典学习涉及的主要运算是稀疏线性逼近,因此,一般来说,是不可能直接在SPD数据集上进行字典学习,如果采用RKHS子空间学习的框架,则SPD矩阵需要变换为在SPD数据集上定义的函数,数据的形态和性质都发生了重大改变,在这样变换的数据上进行机器学习,可能已经不能不是原来机器学习的初衷,本文采用本文前面提出的基于黎曼流形切空间的非欧数据机器学习的框架,把SPD数据变换到SPD黎曼流形的切空间,在切空间里进行字典学习和应用,特别地,SPD黎曼流形的切空间就是对称矩阵空间,而对称矩阵包括SPD矩阵,因此,把SPD矩阵变换成对称矩阵,在数据形态和性质上的变化都是最小的。C.提出一种基于黎曼流形切空间和局部同胚的SPD数据的字典学习算法(RMTSLH-SPDDL),在本文前面提出的RMTS-SPDDL算法中,给定的SPD字典学习样本,变换到SPD黎曼流形的切空间,在切空间中进行稀疏线性逼近,其最优的逼近系数称为SPD学习样本的字典编码,字典编码是M维欧式空间的向量,代表SPD学习样本,这里M是字典的个数,我们希望字典的构造能够使得给定的学习样本与它们的字典编码之间保持局部同胚的关系,也就是近邻连续依赖的关系,为此,我们在RMTS-SPDDL的基础上,添加了学习样本与它们的字典编码之间局部同胚的正则项,从而最终构成本文提出的RMTSLH-SDPDL算法。</td>   <td>G06K9/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林梓铠;                   潘嵘       </td>   <td>中山大学</td>   <td>基于Linear Transformer的非侵入式负荷分解方法</td>   <td>广东省</td>   <td>CN114528930A</td>   <td>2022-05-24</td>   <td>本发明针对现有技术的局限性,提出了一种基于Linear Transformer的非侵入式负荷分解方法。首次提出并使用了Linear Transformer模型进行非侵入负荷分解,在总体精度不变的情况下大大减少了训练时间；该模型改进了传统Transformer模型中注意力的计算方法,使得模型可应用与较长的时间序列,更好地学习到负荷的用电信息。</td>   <td>1.一种基于Linear Transformer的非侵入式负荷分解方法,其特征在于,包括以下步骤：S1,获取待处理的总表数据以及用电器数据；S2,将所述总表数据以及用电器数据输入到经过训练的Linear Transformer模型中,获得各用电器的功率曲线；其中,所述Linear Transformer模型包括编码器以及解码器；所述编码器依序包括分别通过残差连接与层归一化输出的多头注意力模块以及前馈网络；所述解码器依序包括分别通过残差连接与层归一化输出的遮挡多头注意力模块、多头注意力模块以及前馈网络。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         种宜松;                   倪江群       </td>   <td>中山大学</td>   <td>一种采用两阶段预编码和小波网络的鲁棒图像水印方法</td>   <td>广东省</td>   <td>CN114529442A</td>   <td>2022-05-24</td>   <td>本发明针对现有技术的局限性,提出了一种采用两阶段预编码和小波网络的鲁棒图像水印方法,将两阶段水印信息预处理方案与掩膜机制严密切合,能够通过冗余编码使得水印信息均匀地分布在图像中,同时结合掩膜机制,在图像富纹理区域嵌入强度更高的水印并且降低了水印在图像平滑区域的嵌入强度,保障了图像的视觉质量；而在水印容量上,一方面小波集成神经网络对鲁棒水印有所提升；另一方面,两阶段水印信息预处理方案的嵌入机制允许手动控制水印的冗余度,从而提升了容量。</td>   <td>1.一种采用两阶段预编码和小波网络的鲁棒图像水印方法,其特征在于,通过以下步骤进行水印信息的嵌入：S11,获取载体图像以及水印信息；计算所述载体图像的掩膜；通过两阶段预编码将所述水印信息转换为消息图像；S12,将所述载体图像以及消息图像,输入预设的鲁棒图像水印网络,通过所述鲁棒图像水印网络生成初步残差水印；所述鲁棒图像水印网络由鲁棒图像水印网络训练基础框架训练获得；所述鲁棒图像水印网络训练基础框架中包括分别由小波集成神经网络构成的编码器以及解码器；S13,将所述载体图像的掩膜以及所述初步残差水印相乘获得最终残差水印；S14,将所述最终残差水印与所述载体图像相加,获得嵌入水印后的图像。</td>   <td>G06T1/00;G06T3/40;G06T5/10;G06T9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              黄捷;                   林格       </td>   <td>中山大学</td>   <td>一种基于CNN的图像风格化方法及系统</td>   <td>广东省</td>   <td>CN108470320B</td>   <td>2022-05-20</td>   <td>本发明实施例公开了一种基于CNN的图像风格化方法及系统,其中,该方法包括：获取艺术图画作品的风格图像及现实图片；对图像进行预处理；分别对风格图像和内容图像进行图像分割,获取它们各自的多通道语义图像；构建多尺度风格化卷积神经网络,利用网络输入包含多个尺寸的内容图,得到输出图；利用深度卷积神经网络计算出风格损失值及内容损失值；结合两者,利用误差反向传播算法进行反向传播处理,更新多尺度风格化卷积神经网络权重；获取现实图片,裁剪成512*512大小,输入到多尺度风格化卷积神经网络中,得到风格化后的目标图像。在本发明实施例中,能够将任意艺术作品图片上的风格信息迁移到另一张实际图片当中,使得普通人制作出大师级别的绘画作品成为可能。</td>   <td>1.一种基于CNN的图像风格化方法,其特征在于,所述方法包括：获取艺术图画作品的风格图像及现实图片；对图像进行预处理,获得各尺度大小的风格图像和内容图像；分别对风格图像和内容图像进行图像分割,获取它们各自的多通道语义图像；构建多尺度风格化卷积神经网络,利用网络输入包含多个尺寸的内容图,得到输出图；获取风格图像和内容图像、多通道语义图像及输出图,利用深度卷积神经网络计算出输出图与风格图像之间的风格损失值及输出图与内容图像之间的内容损失值；结合风格损失值和内容损失值,利用误差反向传播算法对多尺度风格化卷积神经网络进行反向传播处理,对其进行更新网络权重；获取现实图片,裁剪成512*512大小,输入到多尺度风格化卷积神经网络中,得到风格化后的目标图像；其中,所述多尺度风格化卷积神经网络中卷积处理依次包含了一次批标准化层处理,一次线性整流层激活,一次3*3的卷积,再重复经过一次批标准化层处理,一次线性整流层激活,一次3*3的卷积,最后和输入做一个加运算,得到卷积处理的输出；其中,所述多尺度风格化卷积神经网络中拼接处理是输入中的小尺寸特征图在经过反卷积后尺寸放大一倍,然后经过一次批标准化层处理,最后与经过批标准化层处理的大尺寸输入特征图进行深度上的拼接。</td>   <td>G06T3/00;G06T7/10;G06T3/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王建峰;              王若梅;              苏卓;              周凡;                   林淑金       </td>   <td>中山大学</td>   <td>一种基于用户动态兴趣分析的时尚服装搭配推荐方法</td>   <td>广东省</td>   <td>CN109146626B</td>   <td>2022-05-20</td>   <td>本发明公开了一种基于用户动态兴趣分析的时尚服装搭配推荐方法。本发明首先通过为服装商品的特征属性建立树结构,之后根据用户设定的时间因子,把“用户—商品”评分矩阵分解为“用户—隐含特征”矩阵和“物品—隐含特征”矩阵并提取对应的关键词,然后分别根据各自出现的高频词和低频词构建特征向量,算出概率进行排序得到排序模型,根据排序模型形成物品排序列表推荐给用户。本发明可以根据用户的长期兴趣爱好和短期兴趣漂移,准确的预测出用户在一定时间范围内对服装搭配的兴趣,可以根据用户的购买记录以及对物品的评分,精确的为用户推荐喜欢的服装以及与之搭配的配件或饰品。</td>   <td>1.一种基于用户动态兴趣分析的时尚服装搭配推荐方法,其特征在于,所述方法包括：从网络以及服装商品数据库中获取服装商品的信息,包括用户评分与商品图片,以及对服装图片的分类的标记信息,组成照片库；从照片库中选取一万条数据信息作为一组样本,在样本数据集合中,分为训练集与测试集；提取服装商品的特征属性信息,依据这些信息对服装商品进行分类表示,并确定服装商品的层数；依据服装商品属性的分类与层数建立树结构,以服装配饰为总的大类即树的根节点,服装商品属性的每一层通过各自附属的属性进行相连；利用所建立的服装商品属性树,采用隐语义模型,根据用户设定的时间因子,把“用户—商品”评分矩阵分解为“用户—隐含特征”矩阵和“物品—隐含特征”矩阵；根据前述两个矩阵,分别提取“用户—特征”关键词,以及提取“物品—特征”关键词,再分别根据各自出现的高频词和低频词构建特征向量；通过“用户—物品”评分矩阵作为训练集进行学习,根据构建出的特征向量进行划分,算出概率进行排序得到排序模型,再利用测试集根据排序模型形成物品排序列表推荐给用户；其中,所述提取服装商品的特征属性信息,依据这些信息对服装商品进行分类表示,并确定服装商品的层数,具体为：依据服装商品的属性特征对服装进行分类表示,确定商品的层数；让具有相同深度的特征在同一层,通过分层表示模式从两个维度对物品所属的种类进行划分；在水平维度把物品的特征层次转化为平面结构；在垂直维度通过加权聚合附属特征的潜在因子来调整项目的潜在因子,具有相同属性特征的商品位于同一个垂直维度；其中,所述依据服装商品属性的分类与层数建立树结构,以服装配饰为总的大类即树的根节点,服装商品属性的每一层通过各自附属的属性进行相连,具体为：把服装属性的类别看成树结构,以服装配饰为总的大类即为树的根节点,分为三个小类为节点,分别为服装、鞋子、配件,在三个小类里面又分为各自不同的小类；以商品属性为树的叶节点,并且进一步考虑水平维度中两种语义丰富特征关系,即互补、替代、相互独立关系；所有的服装分为不同层次,每一个层次又通过各自的附属的属性进行相连；通过垂直维度和水平维度上项目的和特征的潜在因子相适应,来让项目继承水平维度的特征；其中,所述把“用户—商品”评分矩阵分解为“用户—隐含特征”矩阵和“物品—隐含特征”矩阵,矩阵表示为：                  R矩阵是“用户—商品”评分矩阵,矩阵值R-(ui)表示的是用户u对商品i的评分,R矩阵表示为P矩阵和Q矩阵相乘,其中P矩阵是“用户—隐含特征”矩阵,矩阵值P-(uj)表示的是用户u对类别j的兴趣度,Q矩阵是“物品—隐含特征”矩阵,矩阵值Q-(ji)表示的是商品i在种类j中的评分,评分越高,代表兴趣度越大；其中,所述根据前述两个矩阵,分别提取“用户—特征”关键词,以及提取“物品—特征”关键词,再分别根据各自出现的高频词和低频词构建特征向量,具体为：根据“用户—隐含特征”矩阵和“物品—隐含特征”矩阵,采用词袋子模型,分别提取“用户—特征”关键词,以及提取“物品—特征”关键词；记录上述提取到的关键词作为用户特征向量与物品特征向量；用户特征向量中的用户的特征关键词词频和物品特征向量中物品特征关键词词频比较低的分为低频词,一个商品被多个用户评分,或者一个用户给多个商品评分的词频划分为高频词。</td>   <td>G06Q30/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨钦泰;              李涵生;              罗新;              邵春奎;              陈健宁;              刘子锋;              吴晓琦;              杨林;              黄雪琨;              张雅娜;              郑瑞;              吴庆武;              吴硕;              周文豪;              梁桂贤;              邱惠军;              王心悦;              林明珍;                   屠佳杰       </td>   <td>杭州迪英加科技有限公司;中山大学附属第三医院</td>   <td>染色鼻息肉病理切片质量多维评价方法、系统及介质</td>   <td>浙江省</td>   <td>CN114511559A</td>   <td>2022-05-17</td>   <td>本发明公开的一种染色鼻息肉病理切片质量多维评价方法、系统及计算机可读存储介质,方法包括：获取鼻息肉数字全场切片图像并进行像素预处理和滤波去噪；对预处理后的图像进行组织切面完整度打分；对预处理后的图像进行切片厚薄均匀程度打分；对预处理后的图像进行刀痕、裂隙打分；对预处理后的图像进行气泡打分；对预处理后的图像进行透明度打分；对预处理后的图像进行细胞核与细胞浆染色对比清晰度打分；对预处理后的图像进行污染物打分；对预处理后的图像进行皱褶、折叠评分；将得到的各项分数加权求和得到切片图像的质量总分。本发明能够更精细、更全面的量化病理切片的质量。</td>   <td>1.一种染色鼻息肉病理切片质量多维评价方法,其特征在于,包括以下步骤：获取鼻息肉数字高倍镜显微镜图片或全场切片图像并进行像素预处理和滤波去噪；对预处理后的图像进行组织切面完整度打分；对预处理后的图像进行切片厚薄均匀程度打分；对预处理后的图像进行刀痕、裂隙打分；对预处理后的图像进行气泡打分；对预处理后的图像进行透明度打分；对预处理后的图像进行细胞核与细胞浆染色对比清晰度打分；对预处理后的图像进行污染物打分；对预处理后的图像进行皱褶、折叠评分；将得到的各项分数求和得到切片图像的质量总分。</td>   <td>G06T7/00;G06T7/13;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         华平;              杨淞然;              李昊天;                   吕磊       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种升主动脉图像的自动提取方法和装置</td>   <td>广东省</td>   <td>CN114511510A</td>   <td>2022-05-17</td>   <td>本发明提供了一种升主动脉图像的自动提取方法和装置,所述方法包括：获取第一数据集；其中,第一数据集包括若干升主动脉的影像学数据,且每个影像学数据在各层面的升主动脉区域均已被标注；根据已标注的各影像学数据,提取所有升主动脉区域以及对应的坐标信息并构建第二数据集；构建图像提取模型；图像提取模型设置了五个下采样结构、两个上采样结构、三个卷积集和激活函数层；将待测影像学数据输入至图像提取模型,获得升主动脉图像。本发明相对于现有技术,设置了五个下采样结构、两个上采样结构、三个卷积集,实现多尺度的特征提取,提高了不同精度升主动脉的目标综合检测能力,提取的过程耗时更短,提取效率高,图像质量更优。</td>   <td>1.一种升主动脉图像的自动提取方法,其特征在于,包括：获取第一数据集,其中,所述第一数据集包括若干个升主动脉的影像学数据,且每个影像学数据在各层面的升主动脉区域均已被标注；根据已标注的各影像学数据,提取所有升主动脉区域以及每个升主动脉区域各自对应的坐标信息,并构建第二数据集；根据所述第二数据集,构建图像提取模型；其中,所述图像提取模型设置了五个下采样结构、两个上采样结构、三个卷积集和激活函数层；其中,所述激活函数层采用logistics函数；获取待测影像学数据,并将所述待测影像学数据输入至所述图像提取模型,获得所述待测影像学数据的升主动脉图像。</td>   <td>G06T7/00;G06V10/25;G06V10/774;G06V10/82;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王瑞轩;                   张灏桓       </td>   <td>中山大学</td>   <td>基于自监督学习的胃癌分子亚型分类方法及装置</td>   <td>广东省</td>   <td>CN114511523A</td>   <td>2022-05-17</td>   <td>本发明公开了基于自监督学习的胃癌分子亚型分类方法及装置,方法包括下述步骤：获取胃癌病理图像测试集；对所述胃癌病理图像测试集中的胃癌测试病理图像分别进行预处理得到测试图像块集；将所述胃癌测试图像块根据放大倍数输入到对应的训练好的特征提取器中,得到初始测试特征向量集；对得到的胃癌测试图像块特征进行融合,输入到训练好的多层感知机分类模型中得到所述胃癌测试图像块集分类结果；对所述测试图像块集分类结果根据所属胃癌病理图像进行结合,得到所述胃癌病理图像测试集胃癌分子亚型分类结果。本发明能够充分利用病理图像的多尺度信息以及切割成图像块后图像块周围区域特征信息,同时利用其他大量无标签病理图像数据帮助提高模型性能。</td>   <td>1.基于自监督学习的胃癌分子亚型分类方法,其特征在于,包括下述步骤：获取胃癌病理图像测试集；所述胃癌病理图像测试集包括多张胃癌病理图像以及对应的癌症勾画区域；对所述胃癌病理图像测试集中的胃癌测试病理图像分别进行预处理得到测试图像块集；所述预处理为在病理图像中按照一定的步长选取一系列的切割中心点,根据肿瘤勾画区域筛选出在肿瘤区域中的中心点,在多个不同放大倍数下分别以上述切割中心点将病理图像切割成指定大小的胃癌测试图像块；将所述胃癌测试图像块根据放大倍数输入到对应的训练好的特征提取器中,得到初始测试特征向量集；所述特征提取器采用卷积神经网络；所述初始测试特征向量集由多个放大倍数下的图像块特征组成；在所述初始测试特征向量集中,对不同放大倍数下有着相同切割中心点切割得到的胃癌测试图像块特征进行融合,输入到训练好的多层感知机分类模型中得到所述胃癌测试图像块集分类结果；对所述测试图像块集分类结果根据所属胃癌病理图像进行结合,得到所述胃癌病理图像测试集胃癌分子亚型分类结果。</td>   <td>G06T7/00;G06K9/62;G06V10/764;G06V10/774;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭光;              查聪;                   黄舒怡       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种用于加快视频分析的方法、系统及介质</td>   <td>广东省</td>   <td>CN114511525A</td>   <td>2022-05-17</td>   <td>本发明公开了一种用于加快视频分析的方法、系统及介质,系统包括：分区选择器、多个检测帧率选择器、多个配置搜索模块和目标检测模型,其中：分区选择器,按照视频图像区域的易检测性自适应地将视频图像结构分为易检测区域和难检测区域；检测帧率选择器,用于对易检测区域和难检测区域使用帧率选择器进行帧率选择；配置搜索模块,用于搜索帧率选择后的图像的配置信息,直至达到目标精度,得到完整的参数配置信息组合；目标检测模型,用于将搜索到的参数配置信息组合应用视频图像的其他时间的查询中。本发明能够在保证视频分析精度,不限制视频分析系统应用场景的前提下提升视频分析效率,减小计算开销,减少推理时间开销。</td>   <td>1.一种用于加快视频分析的系统,其特征在于,包括：分区选择器、多个检测帧率选择器、多个配置搜索模块和目标检测模型,所述分区选择器输出端连接多个检测帧率选择器,所述多个检测帧率选择器分别与多个配置搜索模块连接,所述多个配置搜索模块输出端连接目标检测模型,其中：分区选择器,按照视频图像区域的易检测性自适应地将视频图像结构分为易检测区域和难检测区域；检测帧率选择器,用于对所述易检测区域和难检测区域使用帧率选择器进行帧率选择；配置搜索模块,用于搜索帧率选择后的图像的配置信息,直至达到目标精度,得到完整的参数配置信息组合；所述配置信息包括但不限于图像尺寸、目标检测器；目标检测模型,用于将搜索到的所述参数配置信息组合应用所述视频图像的其他时间的查询中。</td>   <td>G06T7/00;G06T7/11;G06F16/73;G06N3/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨泽宏;              戴冽;              徐硕瑀;              沈君;              莫颖倩;              张翔;              马剑达;              蔡兆熙;              林建子;              毛家骥;              胡辉军;                   石广滋       </td>   <td>中山大学孙逸仙纪念医院;佛山生物图腾科技有限公司</td>   <td>一种基于手部X光图像的关节炎评分方法及装置</td>   <td>广东省</td>   <td>CN114511553A</td>   <td>2022-05-17</td>   <td>本申请实施例提供一种基于手部X光图像的关节炎评分方法及装置,涉及XX技术领域,该基于手部X光图像的关节炎评分方法包括：先获取待评分的手部X光图像；再通过预先构建的手部识别模型对手部X光图像进行手部区域识别,得到手部包围框；并根据手部包围框确定手部X光图像中的待评分关键点；接着依据待评分关键点对手部X光图像进行评分,得到关节狭窄评分结果和骨侵蚀评分结果；最后根据关节狭窄评分和骨侵蚀评分,确定手部X光图像的评分结果,能够根据手部X光图像自动记性关节炎评分,不受主观判断影响,评分结果准确,评分效率高,从而有利于临床医生依据评分对病情变化进行精准判断。</td>   <td>1.一种基于手部X光图像的关节炎评分方法,其特征在于,包括：获取待评分的手部X光图像；通过预先构建的手部识别模型对所述手部X光图像进行手部区域识别,得到手部包围框；根据所述手部包围框确定所述手部X光图像中的待评分关键点；依据所述待评分关键点对所述手部X光图像进行评分,得到关节狭窄评分结果和骨侵蚀评分结果；根据所述关节狭窄评分和所述骨侵蚀评分,确定所述手部X光图像的评分结果。</td>   <td>G06T7/00;G06V40/10;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         詹宗沅;              魏朋旭;                   林倞       </td>   <td>中山大学</td>   <td>基于加权最优传输的无监督域自适应视觉目标检测方法</td>   <td>广东省</td>   <td>CN112396097B</td>   <td>2022-05-17</td>   <td>本发明公开了一种基于加权最优传输的无监督域自适应视觉目标检测方法、系统及存储介质,方法包括以下步骤：基于最优传输的域间样本对采样方法,基于加权最优传输的候选区域域间特征对齐学习,浅层全局特征对抗对齐学习,深层全局特征对抗对齐学习,上下文特征融合连接。本发明一方面解决了无监督域自适应目标检测中提案候选区域特征如何对齐的问题；另一方面,解决了最优传输算法初始的域间类别分布不均衡问题,根据候选区域类别数量重新分配最优传输算法的初始分布权重,使得两域间同类的候选区域总权重一致,有效的减少了错误类别匹配的发生,保证域差异减小的同时保持类别判别性。</td>   <td>1.基于加权最优传输的无监督域自适应视觉目标检测方法,其特征在于,包括以下步骤：基于最优传输的域间样本对采样方法,采用预训练模型对源域和目标域训练数据图像进行特征编码,全局池化得到源域和目标域数据集的特征编码,构建最优传输模型,通过最优传输算法迭代求解源域和目标域之间的图像样本匹配解,以此匹配解进行训练采样；基于加权最优传输的候选区域域间特征对齐学习,每轮训练迭代中,源域和目标域的图像分别通过检测器的特征提取单元和候选区域提取单元,输出对应图像中的候选区域,池化获得各个候选区域目标特征,根据目标类别信息重新分配源域和目标域的候选区域目标出现的权重,构建最优传输模型,通过最优传输算法迭代求解源域和目标域提案候选区域之间的匹配最优解,对匹配解的域间候选区域构建特征距离最小化目标函数；所述基于加权最优传输的候选区域域间特征对齐学习具体为：每轮训练迭代中,源域和目标域的图像分别通过检测器的特征提取单元、候选区域提取单元,输出对应图像中的候选区域,再经过池化获得各个候选区域目标特征,将特征进一步缩小,通过全局平均池化缩小特征维度；根据目标类别信息重新分配源域和目标域的候选区域目标出现的权重,使得两域间相同类别总权重保持一致并满足以下公式：                            对于任意c其中,和分别表示源域和目标域的候选区域目标出现的权重；目标域候选区域类别通过伪标签判断类别,计算源域同类总权重,再平均赋予目标域同类样本,加权后域间同类总权重一致；构建最优传输模型,通过推土机距离最优传输算法迭代求解源域和目标域提案候选区域之间的匹配最优解γ～(f,*),具体如下：          其中,                                    对匹配解的域间候选区域构建特征距离最小化目标函数,缩小源域和目标域之间的差异,目标函数如下：                  其中,α-(ot)是控制损失函数大小的参数；通过最优传输算法的解得到对应类别特征的匹配信息,进一步缩小两域间同类提案候选区域的特征距离；浅层全局特征对抗对齐学习,采用检测器骨干网络提取浅层全局特征,通过梯度逆转模块和卷积网络结构,输出全局特征各个像素位置的域判别得分；深层全局特征对抗对齐学习,采用检测器骨干网络提取浅层全局特征,通过梯度逆转模块和卷积网络结构后,再经过全连接层输出全局特征域判别得分；上下文特征融合连接,计算域判别器中间特征作为上下文信息,将该上下文特征补充到候选区域的特征中,再对融合后的特征进行分类和回归。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁媛;              刘颖;                   牛通       </td>   <td>中山大学</td>   <td>一种基于街景图片及机器学习的城市内部贫困空间测度方法及系统</td>   <td>广东省</td>   <td>CN111937016B</td>   <td>2022-05-17</td>   <td>为了构建新型的城市贫困评估方法,本发明公开一种基于街景图片及机器学习的城市内部贫困空间测度方法,包括以下步骤：根据人口普查数据构建多重剥夺指数IMD；在地图信息数据库中获取目标区域的街景图像数据；通过图像分割技术,将目标区域的街景图像数据分割为若干块街景图像数据；基于若干块街景图像数据,结合主成分分析法,得到主因子,将主因子定义为街景因子；将多重剥夺指数IMD和街景因子作为机器学习算法的输入变量,得到城市贫困分数。根据城市贫困分数对城市的贫困程度进行评估。本发明还公开了基于上述方法的一种基于街景图片及机器学习的城市内部贫困空间测度系统。本发明不仅推进城市贫困研究精细化,而且丰富城市贫困度量指标的维度。</td>   <td>1.一种基于街景图片及机器学习的城市内部贫困空间测度方法,其特征在于,包括以下步骤：根据人口普查数据构建多重剥夺指数IMD；在地图信息数据库中获取目标区域的街景图像数据；通过图像分割技术,将目标区域的街景图像数据分割为若干块街景图像数据；基于若干块街景图像数据,结合主成分分析法,得到主因子,将主因子定义为街景因子；将多重剥夺指数IMD和街景因子作为机器学习算法的输入变量,得到城市贫困分数；根据城市贫困分数对城市的贫困程度进行评估。</td>   <td>G06Q10/06;G06Q50/26;G06N20/00;G06V20/13;G06V10/26;G06V10/764;G06F16/29</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李中华;                   何冠男       </td>   <td>中山大学</td>   <td>RFID移动阅读器防碰撞资源自适应分配与动态再竞争方法</td>   <td>广东省</td>   <td>CN109784115B</td>   <td>2022-05-17</td>   <td>本发明公开了一种RFID移动阅读器防碰撞资源自适应分配与动态再竞争方法,本方法包含识别时间估计阶段、全局通信资源竞争阶段和局部通信资源再竞争配置阶段。本发明从RFID阅读器通信资源最优化分配的角度出发,RFID阅读器根据识别范围内的RFID标签数量情况,获取和释放通信资源,以实现通信资源的高效利用,最大化RFID阅读器网络识别RFID标签效率。</td>   <td>1.RFID移动阅读器防碰撞资源自适应分配与动态再竞争方法,其特征在于,所述方法包括每轮依次执行的三个连续的阶段,分别是识别时间估计阶段、全局通信资源竞争阶段和局部通信资源再竞争阶段；识别时间估计阶段：每个RFID移动阅读器首先对识别范围内的标签数量进行估计,从而估算出识别完识别范围内所有电子标签的总时间；全局通信资源竞争阶段：RFID移动阅读器在轮训服务器广播同步信号的条件下,通过竞争通信资源规则进行资源竞争,竞争资源成功的RFID移动阅读器识别标签,竞争资源失败的RFID移动阅读器进行休眠；局部通信资源再竞争阶段：识别标签的RFID移动阅读器识别完覆盖范围内标签之后,调整再竞争优先级并向邻居RFID移动阅读器发送激活信号,处于休眠状态的RFID移动阅读器根据接收到的激活信号数量,来设定再竞争优先级,然后RFID移动阅读器根据再竞争优先级进行通信资源的再竞争；所述的优先级设置方法的具体如下：局部通信资源竞争阶段开始时,初始化休眠RFID移动阅读器的再竞争优先级,再竞争优先级分为3级；当收到的屏蔽信号数量和激活信号数量相等时,休眠RFID移动阅读器的再竞争优先级设置为3；当收到的屏蔽信号数量和激活信号数量不相等时,休眠RFID移动阅读器再竞争优先级设置为2；在局部通信资源竞争阶段,若识别标签的RFID移动阅读器估算的询问时间小于或等于方法设定的执行一轮的时间,RFID移动阅读器识别完标签结束后,释放通信资源,进入休眠状态,并将RFID移动阅读器的再竞争优先级设置为1；所述的优先级为3的休眠RFID移动阅读器无需等待,可以立即开始通信资源的再竞争；如果RFID移动阅读器再竞争成功,会向邻居RFID移动阅读器发送屏蔽信号；再竞争优先级为2和1的休眠RFID移动阅读器在等待一段时间后,再根据接收到的激活信号数量和屏蔽信号数量重新确定再竞争优先级,优先级为1的休眠RFID移动阅读器等待时间比再竞争优先级为2的休眠RFID移动阅读器长。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              杨浩锴;              王雅琦;                   韦骏       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>基于区块链和联邦学习的海洋数据共享方法、系统及介质</td>   <td>广东省</td>   <td>CN114493594A</td>   <td>2022-05-13</td>   <td>本发明公开了基于区块链和联邦学习的海洋数据共享方法、系统及介质,方法包括：根据数据共享及权项分配机制搭建区块链网络；将数据共享及权项分配机制转变为智能合约；响应于数据使用方的联邦学习请求,在区块链网络进行学习检索；根据学习检索的结果,发送检索数据至数据使用方；根据检索数据,确定数据提供方；根据智能合约,在数据使用方和数据提供方之间建立支链；根据支链,数据提供方从数据使用方获取训练模型进行全局模型训练；根据智能合约结合所述全局模型训练的结果,进行参数聚合处理得到全局模型参数。本发明能够解决海洋数据分散、统一协调性差等问题,进而实现对基于区块链和联邦学习的海洋数据共享,可广泛应用于区块链技术领域。</td>   <td>1.一种基于区块链和联邦学习的海洋数据共享方法,其特征在于,包括：根据数据共享及权项分配机制搭建区块链网络；将所述数据共享及权项分配机制转变为智能合约；根据所述智能合约确定数据提供方与数据使用方的区块链权限；响应于数据使用方的联邦学习请求,在所述区块链网络进行学习检索；根据所述区块链权限,结合所述学习检索的结果发送检索数据至所述数据使用方；根据所述检索数据,确定数据提供方；根据所述智能合约,在所述数据使用方和所述数据提供方之间建立支链；根据所述支链,所述数据提供方从所述数据使用方获取训练模型进行全局模型训练；根据所述智能合约结合所述全局模型训练的结果,进行参数聚合处理得到全局模型参数。</td>   <td>G06Q20/38;G06Q20/40;G06N3/04;G06N3/08;H04L67/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘强;              王仲旭;              严修;                   马艺涛       </td>   <td>中山大学</td>   <td>城市公交事故风险因素分析方法</td>   <td>广东省</td>   <td>CN114493363A</td>   <td>2022-05-13</td>   <td>本发明属于城市公共交通安全监控技术领域,具体涉及一种城市公交事故风险因素分析方法。该方法所使用的公交事故信息处理系统包括集成安装在城市道路智慧灯杠上的中央处理器、数据转换模块、数据库、时钟模块、网关模块、信息显示模块、互联网模块、卫星定位模块、编码器和自动摄像仪；该方法包括数据采集与预处理,从人、车、路、环境四个方面选取风险因素确定公交事故特征,建立公交事故Logistic模型,确定影响城市公交安全的显著性因素,采用Apriori算法对公交事故风险因素进行关联等步骤。本发明能够快速、准确地对城市公交事故风险因素进行分析、评估。</td>   <td>1.一种城市公交事故风险因素分析方法,其特征在于：该方法所使用的公交事故信息处理系统包括集成安装在城市道路智慧灯杠上的中央处理器、数据转换模块、数据库、时钟模块、网关模块、信息显示模块、互联网模块、卫星定位模块、编码器和自动摄像仪；卫星定位模块、编码器通过数据转换模块与中央处理器通信连接；互联网模块、信息显示模块通过网关模块与中央处理器通信连接,数据库、时钟模块、自动摄像仪直接与中央处理器通信连接；中央处理器通过网关模块和互联网模块与城市公交管理部门的控制中心通信连接；该方法包括下述步骤：步骤1,采集公交车有关的道路交通事故数据信息,根据相关风险因素及事故类型制作样本数据集,进行数据预处理；步骤2,从人、车、路、环境四个方面选取风险因素,采用相关性统计分析手段,直观的分析各风险因素的影响程度,从而确定公交事故的特征；步骤3,将选取得到的样本数据集中的风险因素作为自变量,事故类型作为因变量,建立公交事故Logistic模型,确定影响城市公交安全的显著性因素；步骤4,采用Apriori算法对公交事故风险因素进行关联,挖掘人、车、路、环境四个方面的风险因素之间的关联对公交事故类型的影响；步骤5,结合Logistic回归模型分析的单因素对公交事故类型的影响和Apriori算法挖掘多因素的关联作用对事故类型的影响,分析出影响城市公交安全的风险因素。</td>   <td>G06Q10/06;G06Q50/30;G06F30/20;G06F111/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张东;                   暴媛媛       </td>   <td>中山大学</td>   <td>一种基于双路径自注意力机制的特定人语音分离方法</td>   <td>广东省</td>   <td>CN114495973A</td>   <td>2022-05-13</td>   <td>本发明公开了一种基于双路径自注意力机制的特定人语音分离方法,该方法包括：获取注册语料和混合语料；对注册语料进行梅尔谱提取并输入至预训练的说话人编码器,得到身份特征；基于预训练的语音编码器对混合语料进行处理,得到语音特征；将身份特征和语音特征融合,得到融合特征；基于预训练的信噪比估计模块对融合特征进行处理,得到信噪比估计值；将融合特征和信噪比估计值依次经过预训练的语音分离器和语音解码器,得到目标说话人的干净语音信号。通过使用本发明,够快速精准地从包含噪声和多人语音干扰的混合语料中提取出该目标说话人的声音。本发明作为一种基于双路径自注意力机制的特定人语音分离方法,可广泛应用于语音分离领域。</td>   <td>1.一种基于双路径自注意力机制的特定人语音分离方法,其特征在于,包括以下步骤：获取注册语料和混合语料；对注册语料进行梅尔谱提取并输入至预训练的说话人编码器,得到身份特征；基于预训练的语音编码器对混合语料进行处理,得到语音特征；将身份特征和语音特征融合,得到融合特征；基于预训练的信噪比估计模块对融合特征进行处理,得到信噪比估计值；将融合特征和信噪比估计值依次经过预训练的语音分离器和语音解码器,得到目标说话人的干净语音信号。</td>   <td>G10L21/0272;G10L21/0208;G10L25/24;G10L25/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴岳洲;                   潘嵘       </td>   <td>中山大学</td>   <td>联邦学习中基于反向拍卖的隐私保护激励机制训练方法</td>   <td>广东省</td>   <td>CN114493808A</td>   <td>2022-05-13</td>   <td>本发明针对现有技术的局限性,提出了一种联邦学习中基于反向拍卖的隐私保护激励机制训练方法,该方法不会发送提取器给中央服务器,仅使用生成器来拟合提取器的输出,使得联邦学习参与者上传给中央服务器的模型不直接由原始数据训练而成,因此中央服务器不能够反推出原始数据,从而保护了数据隐私；另外,本发明以反向拍卖的方式对联邦学习参与者激励,能够满足训练过程中的个人理性、真实性和预算可行性。</td>   <td>1.一种联邦学习中基于反向拍卖的隐私保护激励机制训练方法,对于包含全局分类器的中央服务器与若干包含提取器、分类器、判别器以及生成器的联邦学习参与者,其特征在于,在各轮联邦学习中：所述联邦学习参与者不会向所述中央服务器发送提取器,而是使用各自的生成器拟合提取器的输出,供所述中央服务器进行训练；所述中央服务器根据各联邦学习参与者提供的投标价以及生成器,结合反向拍卖的方式对各联邦学习参与者的分类器进行筛选；通过对筛选结果进行融合,更新全局分类器。</td>   <td>G06Q30/08;G06F21/62;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄子健;              文英鹏;              黄聃;              余伟江;                   郑馥丹       </td>   <td>中山大学</td>   <td>一种用于降雨预报后处理的自监督神经网络架构搜索方法</td>   <td>广东省</td>   <td>CN114492960A</td>   <td>2022-05-13</td>   <td>本发明公开了一种用于降雨预报后处理的自监督神经网络架构搜索方法,所述方法包括NWP模型对原始气象数据处理,得到降雨预测后处理输入数据图,将所述降雨预测后处理输入数据图输入到自监督神经网络架构搜索模型中,搜索模型利用目标网络和在线网络做对比学习,计算目标网络和在线网络的输出差异并做MSE损失计算,梯度更新目标网络和在线网络后得到搜索完毕的在线模型,使用训练数据集继续训练模型,使用HSS损失函数计算损失后梯度更新,最后获得训练完整的预测模型。本发明的有益效果在于：自监督神经网络架构搜索模型自动设计高准确度的神经网络模型,并通过引入强度分类指标HSS设计正则化函数,以提高降雨等级分类的准确性。</td>   <td>1.一种用于降雨预报后处理的自监督神经网络架构搜索方法,其特征在于,所述方法包括NWP模型对原始气象数据处理,得到降雨预测后处理输入数据图,将所述降雨预测后处理输入数据图输入到自监督神经网络架构搜索模型中,搜索模型利用目标网络和在线网络做对比学习,计算目标网络和在线网络的输出差异并做MSE损失计算,梯度更新目标网络和在线网络后得到搜索完毕的在线模型,使用训练数据集继续训练模型,使用HSS损失函数计算损失后梯度更新,最后获得训练完整的预测模型。</td>   <td>G06Q10/04;G06Q50/26;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋尔卫;              陈凯;              马嘉凡;              朱李玲;                   李顺荣       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种基于影像组学的乳腺癌保乳手术切缘状态预测模型</td>   <td>广东省</td>   <td>CN114494232A</td>   <td>2022-05-13</td>   <td>本发明提供了一种基于影像组学的乳腺癌保乳手术切缘状态预测模型,属于生物技术领域。本发明的预测模型的构建方法包括以下步骤：(1)将符合标准的乳腺癌保乳手术患者分为训练集和测试集,并采集所述符合标准的乳腺癌保乳手术患者的乳腺MRI图像；(2)在MRI图像的T1增强序列上勾画乳腺MRI的目标病灶,并在T1增强序列,T1平扫序列和T2平扫序列提取影像学特征；(3)利用后向递归特征消除的降维策略对影像学特征进行降维,再使用XGBoost算法构建基于影像组学的乳腺癌保乳手术切缘状态预测模型。本发明的预测模型使用接受保乳手术的患者的术前MRI图像,采用影像组学的分析方法建立,可以对患者保乳手术切缘状态进行预测,为手术计划的制订提供相应的参考。</td>   <td>1.一种基于影像组学的乳腺癌保乳手术切缘状态预测模型的构建方法,其特征在于,包括以下步骤：(1)将符合标准的乳腺癌保乳手术患者分为训练集和测试集,并采集所述符合标准的乳腺癌保乳手术患者的乳腺MRI图像；(2)在MRI图像的T1增强序列上勾画乳腺MRI的目标病灶,并在T1增强序列,T1平扫序列和T2平扫序列提取影像学特征；(3)利用后向递归特征消除的降维策略对影像学特征进行降维,再使用XGBoost算法构建基于影像组学的乳腺癌保乳手术切缘状态预测模型。</td>   <td>G06T7/00;G06T7/13;G06T7/181;G06T7/60;G06T7/62;A61B34/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         单云霄;              陈自博;              崔良语;                   黄凯       </td>   <td>中山大学</td>   <td>一种实时水面船只视觉跟踪系统及其方法</td>   <td>广东省</td>   <td>CN110992403B</td>   <td>2022-05-10</td>   <td>本发明涉及一种实时水面船只视觉跟踪系统及其方法,该系统包括用于获取图像的图像获取模块、卡尔曼滤波模块和自适应模块,所述卡尔曼滤波模块包括卡尔曼滤波更新模块和卡尔曼滤波预测模块；自适应模块根据图像的误差值将图像决定调用卡尔曼滤波预测模块或卡尔曼滤波更新模块进行不同的追踪流程。本发明提出的自适应模块,通过预测帧间误差以及误差的变化趋势,动态的调用卡尔曼滤波的预测与更新模块,相较于现有方法面对不同的应用场景拥有更强大的适应能力。</td>   <td>1.一种实时水面船只视觉跟踪方法,其特征在于,该方法基于视觉跟踪系统实现,所述视觉跟踪系统包括用于获取图像的图像获取模块、卡尔曼滤波模块和自适应模块,所述卡尔曼滤波模块包括卡尔曼滤波更新模块和卡尔曼滤波预测模块；所述卡尔曼滤波更新模块使用了anchor-free的目标检测网络；所述卡尔曼 滤波预测模块结合恒速运动模型；所述自适应模块预设有误差协方差矩阵阈值和梯度阈值,自适应模块将误差协方差矩阵阈值和梯度阈值与图像的误差值进行比较,并将根据比较结果选择卡尔曼滤波预测模块或卡尔曼滤波更新模块对图像进行进一步的处理；该方法具体包括如下步骤：步骤一：对图像进行预处理；步骤二：自适应模块根据图像的误差值将图像决定调用卡尔曼滤波预测模块或卡尔曼滤波更新模块,若调用卡尔曼滤波预测模块,则继续步骤三,若调用卡尔曼滤波更新模块,则跳到步骤四；自适应模块对于每一帧,计算其前面四帧的误差协方差矩阵的梯度值,求出一个误差值,若该误差值均大于误差协方差矩阵阈值和梯度阈值,则调用卡尔曼滤波更新模块；若该误差值小于误差协方差矩阵阈值或梯度阈值,则调用卡尔曼滤波预测模块；步骤三：卡尔曼滤波预测模块预测图像当前帧中船只目标的位置；步骤四：卡尔曼滤波更新模块进行更新优化当前帧中船只目标框的位置；步骤五：计算目前卡尔曼滤波中误差协方差矩阵值并进入自适应模块更新误差协方差矩阵阈值和梯度阈值,并将新的误差协方差矩阵阈值和梯度阈值作为下一帧的图像的阈值；步骤六：输出当前帧中船只目标框的位置。</td>   <td>G06T7/246;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王甲海;                   廖易天       </td>   <td>中山大学</td>   <td>基于深度强化学习的车辆路径规划方法及装置</td>   <td>广东省</td>   <td>CN114462687A</td>   <td>2022-05-10</td>   <td>本发明公开了基于深度强化学习的车辆路径规划方法及装置,方法包括：搭建车辆路径规划问题的求解框架,确定初始参数信息；搭建神经网络模型作为破坏策略；根据所述初始参数信息和所述破坏策略,将大邻域搜索过程拟合成马尔可夫决策过程；根据所述马尔可夫决策过程,通过强化学习方法训练神经网络模型；通过训练得到的神经网络模型对所述车辆路径规划问题进行求解,得到车辆路径规划结果。本发明能够缩短求解时间,且保证求解质量,可广泛应用于人工智能技术领域。</td>   <td>1.基于深度强化学习的车辆路径规划方法,其特征在于,包括：搭建车辆路径规划问题的求解框架,确定初始参数信息；搭建神经网络模型作为破坏策略；根据所述初始参数信息和所述破坏策略,将大邻域搜索过程拟合成马尔可夫决策过程；根据所述马尔可夫决策过程,通过强化学习方法训练神经网络模型；通过训练得到的神经网络模型对所述车辆路径规划问题进行求解,得到车辆路径规划结果。</td>   <td>G06Q10/04;G06Q50/30;G06N3/04;G06N3/08;G06N7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张晓春;              陈振武;              周勇;              张枭勇;              胡海峰;              吴婷晖;              张书赫;                   邢宋隆       </td>   <td>深圳市城市交通规划设计研究中心股份有限公司;中山大学</td>   <td>一种反向链推理溯源方法、系统、计算机及存储介质</td>   <td>广东省</td>   <td>CN114462721A</td>   <td>2022-05-10</td>   <td>本发明提出一种反向链推理溯源方法、系统、计算机及存储介质,属于公共交通技术领域。首先,生成规则库和知识库；所述规则库中存储有反向链查询规则和反向链查询规则约束条件；所述知识库中存储有交通线路和路面数据；其次,输入线路问题,调用与线路问题对应的反向链查询规则,使用RETE算法找出模式下所有匹配的对象和规则；重复调用与线路问题对应的反向链查询规则直到所有反向链查询规则执行完毕；最后,所有反向链查询规则执行完后,通过Terminal节点将最终的结果进行输出。解决现有技术中存在的查找时间和信息链的时间长、无法直接查找多个直接影响问题的基础因素、交通线路问题溯源结果准确定和精确度低的技术问题。</td>   <td>1.一种反向链推理溯源方法,其特征在于,包括以下步骤：步骤1、生成规则库和知识库；所述规则库中存储有反向链查询规则和反向链查询规则约束条件；所述知识库中存储有交通线路和路面数据；步骤2、输入线路问题,调用与线路问题对应的反向链查询规则,使用RETE算法找出模式下所有匹配的对象和规则；具体包括以下步骤：步骤21、根据线路问题创建root节点,作为推理网络的数据入口；步骤22、根据线路问题调用对应反向链查询规则,从反向链查询规则里取出模式；步骤221、检查模式中的数据参数类型,如果有新的类型出现,则增加对应类型的节点；步骤222、检查模式中对应的Alpha节点是否存在,如果存在则记录下该节点的位置信息,反之则将模式作为一个Alpha节点加入到网络中,并且根据节点建立Alpha内存表；步骤223、重复步骤b直至处理完所有模式；步骤224、组合Beta节点将Beta的两个输入节点分别定义为Alpha节点1和Alpha节点2,然后与上一级Beta通过将其输入节点Alpha进行连接,将两个父节点的内存表相连变成新的内存表；步骤225、重复步骤d直到所有Beta节点都处理完成；步骤226、将规则动作Then部分封装成最后节点,记作Beta(n)；步骤3、重复步骤2,直到所有反向链查询规则执行完毕；步骤4、当所有反向链查询规则执行完后,会通过Terminal节点将最终的结果进行输出。</td>   <td>G06Q10/04;G06Q50/30;G06F16/901;G06F16/903;G06N5/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              崔紫薇;              林少锋;              郭震;                   肖尧       </td>   <td>中山大学;佛山市公共交通管理有限公司</td>   <td>一种面向自主式公交信息化系统的建设时序确定方法</td>   <td>广东省</td>   <td>CN114462760A</td>   <td>2022-05-10</td>   <td>本发明公开了一种面向自主式公交信息化系统的建设时序确定方法,方法包括：获取影响自主式公交信息化系统建设时序的业务指标和数据指标；对所述业务指标和所述数据指标进行权重赋值；根据各个指标的权重值,采用线性加权求和的方法确定各个公交信息化系统的综合重要度评分；根据各个公交信息化系统的综合重要度评分,建立以信息化整体综合重要度最大为目标的0-1规划模型；根据所述0-1规划模型,结合贪心算法求解所述0-1规划模型,得到各系统所属建设批次及各批次建设时序；根据所述0-1规划模型求解结果,提出将信息化建设效率作为评价指标,对于所述自主式公交信息化系统建设时序确定方法进行定量检验；其中,所述0-1规划模型用于确定面向自主式公交信息化系统的建设时序。本发明提高了效率和准确率,可广泛应用于公交信息化领域和计算机技术领域。</td>   <td>1.一种面向自主式公交信息化系统的建设时序确定方法,其特征在于,包括：获取影响自主式公交信息化系统建设时序的业务指标和数据指标；对所述业务指标和所述数据指标进行权重赋值；根据各个指标的权重值,采用线性加权求和的方法确定各个公交信息化系统的综合重要度评分；根据各个公交信息化系统的综合重要度评分,建立以信息化整体综合重要度最大为目标的0-1规划模型；其中,所述0-1规划模型用于确定面向自主式公交信息化系统的建设时序。</td>   <td>G06Q10/06;G06Q50/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              唐亦汉;                   苏程佳       </td>   <td>中山大学</td>   <td>一种变异环境下河网区设计洪水位计算方法</td>   <td>广东省</td>   <td>CN108009565B</td>   <td>2022-05-06</td>   <td>本发明涉及水文水利工程领域,更具体地,涉及一种变异环境下河网区设计洪水位计算方法。包括以下步骤：S1.采集并提取网河区不同位置站点的年最大洪潮水位数据；S2.根据网河区各站洪潮水位序列统计特征进行分区；S3.基于S2步骤的分区结果进行站点特征分布识别；S4.基于主要环境影响要素进行特定分区站点的设计洪水位计算分析。本发明提供的一种变异环境下河网区设计洪水位计算方法,充分考虑了网河区复杂的河道影响及环境变化作用,可提高设计洪水位计算精度,可广泛应用于水文统计计算中。</td>   <td>1.一种变异环境下河网区设计洪水位计算方法,其特征在于,包括以下步骤：S1,采集并提取网河区不同位置站点的年最大洪潮水位数据；S2,根据网河区各站洪潮水位序列统计特征进行分区；所述的S2步骤包括：S21,提取各站序列特征值进行水文分区聚类识别；所述的S21步骤包括：S211,提取站点洪潮水位系列线性矩中的L-变差系数t-2、L-偏态系数t-3和L-峰度系数t-4作为站点分组聚类的影响因子；S212,定义任意两个对象之间的差异程度d(x-i,x-j),具体计算公式如下：                  S213,根据差异程度计算对象i对于类别j的隶属度u：                                    其中,θ-j为每一类的类代表值,用属同一类的所有对象的均值来表示；n为对象个数,C表示类别,m为设定聚类的类别个数；S22,对水文初步分区识别结果进行数据不和谐性检验；S23,对水文初步分区识别结果进行均匀性检验；S3,基于S2步骤的分区结果进行站点特征分布识别；所述的S3步骤包括：S31计算站点系列适线的AIC值,计算方式如下：                  式中：是数据组D(x-i,i＝1,n)的最大似然值；为模型参数的最大似然估计值；w为模型参数的个数；S32,选取AIC最小值对应的分布作为站点的最适特征分布；S4,基于主要环境影响要素进行特定分区站点的设计洪水位计算分析；所述的S4步骤包括：S41,在假定水位序列满足一致性假设的前提下,在GAMLSS模型框架的基础上选择多种常用于水位模拟的分布对其进行模拟,然后根据AIC准则选择最适分布；S42,根据成因分析选择与水位具有相关关系的指标因子作为最适分布的协变量；S43,根据最适分布的参数特征,利用协变量构建分布参数的具体表达式,以此得到不同的非一致性模型；S44,将所构建的基于GAMLSS框架的非一致性模型用于水位序列的模拟,并根据AIC准则选择最佳非一致性模型；S45,利用最佳非一致性模型即计算指定设计频率下的设计洪水位。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   李强       </td>   <td>中山大学</td>   <td>一种融合图像生成和多标签分类的异常图像检测方法</td>   <td>广东省</td>   <td>CN110766056B</td>   <td>2022-05-06</td>   <td>本发明提供一种融合图像生成和多标签分类的异常图像检测方法,该方法包括以下步骤：S1：图像重构特征提取以及降维处理；S2：利用S1得到的低维数据进行多分类概率计算,提取有效的类别概率特征；S3：将S1和S2得到的数据作为一分类器的输入得到数据异常的概率值。本方法极大地提升了高类别概率值在异常检测任务中的有效性,以及其在两类数据中的区分性,对于异常数据,可以更有效的获取特征,进而提升检测效果。</td>   <td>1.一种融合图像生成和多标签分类的异常图像检测方法,其特征在于,包括以下步骤：S1：图像重构误差特征提取以及降维处理；S2：利用S1得到的低维数据进行多分类概率计算,提取类别概率特征；S3：将S1和S2得到的数据作为分类器的输入得到数据异常的概率值；所述步骤S1的具体过程是：获取图像数据,首先对其使用生成模型模块进行数据压缩降维处理,将高维的图像数据转换为低维表示,如公式(1),同时基于低维表示进行解码重构得到图像数据的重构误差特征,如公式(2)：z＝encode(x)               (1)recon＝simi(x,decode(z))     (2)其中x表示输入的图像数据,encode函数表示生成模型中的编码器,进行数据的压缩降维操作,decode函数是生成模型中的解码器,进行数据重构的操作,simi函数是计算原数据和重构数据之间的误差函数；所述步骤S2的具体过程是：将S1中生成模型得到低维数据表示,输入到多分类器中计算不同类别概率,使用sigmoid替代softmax方法进行多分类概率计算,提取类别概率特征；其中多分类器使用卷积神经网络和全连接神经网络结合的网络结构,通过卷积神经网络可以有效提取图像数据中的局部特征,保证图像数据的平移不变性,具体如公式(3)：prob＝sigmoid(multiclassifier(z))         (3)其中multiclassifier函数表示多分类器,sigmoid表示最终的sigmoid概率计算方法；所述步骤S3的具体过程是：将S1中得到的生成模型计算得到的重构误差特征和图像数据低维表示以及S2中多分类器得到的sigmoid类别概率特征,作为分类器的输入特征得到数据异常的概率值。</td>   <td>G06K9/62;G06V10/774;G06V10/77;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         肖尧;              徐俊;                   蔡铭       </td>   <td>中山大学</td>   <td>一种基于多源数据的公交线网供需矩阵自主化构建方法</td>   <td>广东省</td>   <td>CN114444789A</td>   <td>2022-05-06</td>   <td>本发明公开了一种基于多源数据的公交线网供需矩阵自主化构建方法,方法包括：根据公交车辆GPS数据和公交站点GPS数据匹配线路名称,生成公交到站时刻表；根据所述公交到站时刻表计算公交车的发车频率,根据所述发车频率以及预设的公交车载客容量构建公交线网的供给矩阵；根据所述公交到站时刻表和IC卡数据匹配得到线路名称和刷卡时间,获取上车站点和推断下车站点后,根据所述线路名称、所述刷卡时间、所述上车站点和所述推断下车站点,构建公交线网的IC需求矩阵；根据手机信令数据提取用户的起讫点基站,通过距离映射关系分配客流需求后,构建公交线网的CSD需求矩阵。本发明提高了准确性和扩宽了适用范围,可广泛应用于交通数据处理技术领域。</td>   <td>1.一种基于多源数据的公交线网供需矩阵自主化构建方法,其特征在于,包括：根据公交车辆GPS数据和公交站点GPS数据匹配线路名称,生成公交到站时刻表；根据所述公交到站时刻表计算公交车的发车频率,根据所述发车频率以及预设的公交车载客容量构建公交线网的供给矩阵；根据所述公交到站时刻表和IC卡数据匹配得到线路名称和刷卡时间,获取上车站点和推断下车站点后,根据所述线路名称、所述刷卡时间、所述上车站点和所述推断下车站点,构建公交线网的IC需求矩阵；根据手机信令数据提取用户的起讫点基站,通过距离映射关系分配客流需求后,构建公交线网的CSD需求矩阵。</td>   <td>G06Q10/04;G06Q50/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李军;              张东冉;                   董怡君       </td>   <td>中山大学</td>   <td>一种出租车乘客流量预测方法</td>   <td>广东省</td>   <td>CN114444792A</td>   <td>2022-05-06</td>   <td>本发明提供一种出租车乘客流量预测方法,首先将上客流量和下客流量拼接到同一维度,并进行空间节点序列化,将数据归一化后得到原始数据,将原始数据划分为训练数据和测试数据；其次采用空间多头注意力算法,对训练数据进行空间注意力特征提取,得到全局空间特征；然后将全局空间特征和训练数据展平为同一维度,采用第一多层感知机进行时间特征提取,得到全局时间特征；再将全局时间特征和训练数据输入第二多层感知机进行迭代训练,得到训练好流量预测模型,再将测试数据输入预测模型,得到预测结果。本发明可有效提取全局空间特征和全局时间特征,能够对出租车乘客流量实现高精度预测。</td>   <td>1.一种出租车乘客流量预测方法,其特征在于,包括以下步骤：S1：将上客流量和下客流量抽象为空间节点并拼接到同一维度,之后将所有空间节点序列化,并进行数据归一化得到原始数据,然后将原始数据划分为训练数据和测试数据；S2：采用空间多头注意力算法,对训练数据进行空间注意力特征提取,得到全局空间特征；S3：将全局空间特征和训练数据展平为同一维度,采用第一多层感知机进行时间特征提取,得到全局时间特征；S4：将全局时间特征和训练数据输入第二多层感知机进行迭代训练,得到训练好的基于第二多层感知机的流量预测模型；S5：将测试数据输入流量预测模型进行预测,得到出租车乘客上下车的流量预测结果。</td>   <td>G06Q10/04;G06Q50/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李军;              区静怡;                   骆刚       </td>   <td>中山大学</td>   <td>一种单线路公交乘客出行数据生成方法</td>   <td>广东省</td>   <td>CN114444795A</td>   <td>2022-05-06</td>   <td>本发明公开一种单线路公交乘客出行数据生成方法,先随机得到G条候选线路,之后根据站点空间信息,得到所有候选线路的站点的空间向量,再根据空间向量,得到所有候选线路与目标线路的空间相似总值,并选出前Q个空间相似总值对应的候选线路作为优选候选线路,之后通过数据相似指数和相似度的计算,得到每条优选候选线路与目标线路的相似度,选出相似度最高的优选候选线路作为最优候选线路,最后以这个最优候选线路为学习样本,通过循环生成式对抗网络算法即可生成目标样本的乘客出行数据。本发明能基于真实数据,方便快捷且低成本地大量生成目标线路的公交乘客出行数据,生成的数据符合真实规律,且可应用于公交分析等领域。</td>   <td>1.一种单线路公交乘客出行数据生成方法,其特征在于,包括以下步骤：S1、随机选取G条公交线路作为候选线路,并获取所有候选线路的历史乘车数据和站点空间信息；S2、根据站点空间信息确定G条候选线路中所有站点的空间向量；S3、根据站点的空间向量,计算目标线路中各站点与任一条候选线路中所有站点的空间相似指数,得到该条候选线路与目标线路的空间相似总值；S4、每条候选线路均按步骤S3的方式得到一个与目标线路的空间相似总值,将所有候选线路与目标线路的空间相似总值从大到小进行排序,选出前Q个空间相似总值对应的候选线路作为优选候选线路；S5、计算目标线路中各站点与任一条优选候选线路中所有站点的数据相似指数,得到该条优选候选线路与目标线路的数据相似总值；S6、每条优选候选线路均按步骤S5的方式得到一个与目标线路的数据相似总值,根据得到的数据相似总值,计算每条优选候选线路与目标线路的相似度,选取相似度最大值对应的优选候选线路作为最优候选线路；S7、将最优候选线路和目标线路作为学习样本和目标样本；S8、通过循环生成式对抗网络算法,以学习样本的线路出行数据生成目标样本的乘客出行数据。</td>   <td>G06Q10/04;G06Q50/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张晓春;              陈振武;              张枭勇;              邓华辉;              胡海峰;              吴婷晖;              张书赫;                   邢宋隆       </td>   <td>深圳市城市交通规划设计研究中心股份有限公司;中山大学</td>   <td>一种交通线路健康度指标确定方法、计算设备及存储介质</td>   <td>广东省</td>   <td>CN114444981A</td>   <td>2022-05-06</td>   <td>本发明提供了一种交通线路健康度指标确定方法、计算设备及存储介质,该方法包括：获取交通线路数据,所述交通线路数据包括交通线路的属性信息；根据所述属性信息,将所述交通线路数据划分为至少一个类,以及确定与所述类对应的预设指标确定规则；根据划分后的所述交通线路数据和所述预设指标确定规则确定所述健康度指标。本发明的有益效果：能够提高健康度指标确定的效率。</td>   <td>1.一种交通线路健康度指标确定方法,其特征在于,包括：获取交通线路数据,所述交通线路数据包括交通线路的属性信息；根据所述属性信息,将所述交通线路数据划分为至少一个类,以及确定与所述类对应的预设指标确定规则；根据划分后的所述交通线路数据和所述预设指标确定规则确定健康度指标。</td>   <td>G06Q10/06;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         詹巽霖;              吴洋鑫;              董晓;                   梁小丹       </td>   <td>中山大学</td>   <td>一种基于多模态预训练模型的组合商品检索方法及系统</td>   <td>广东省</td>   <td>CN114445201A</td>   <td>2022-05-06</td>   <td>本发明公开了一种基于多模态预训练模型的组合商品检索方法及系统,其中方法包括步骤如下：将商品图像划分为单品图像和组合品图像；训练一个组合商品图像检测器；获取并结合组合商品图像中文本模态和图片模块的特征编码、位置编码和分段编码,学习嵌入表示,并输入构建好的多模态预训练模型；通过商品检测器提取的边界框和边界框特征作为图像特征,结合文本特征,输入多模态预训练模型进行自监督训练；采用多模态预训练模型提取单品图像的图片模态和文本模态的检索特征,并存放于检索库中；多模态预训练模型根据组合品图像中每个目标商品的边界框及边界框特征,提取图文融合的检索特征,计算组合品特征与检索库中单品特征的预先距离作为商品相似度,选取最相似的单品作为结果返回。</td>   <td>1.一种基于多模态预训练模型的组合商品检索方法,其特征在于：所述的方法包括步骤如下：S1：将商品图像划分为单品图像和组合品图像,其中所述的单品图像表示只有一个商品,组合品图像表示包括多个独立商品；S2：训练一个组合商品图像检测器,用于检测组合商品图像中的每个独立商品；S3：获取并结合组合商品图像中文本模态和图片模块的特征编码、位置编码和分段编码,由此学习嵌入表示；S4：构建多模态预训练模型,将学习到的嵌入表示作为多模态预训练模型的输入；S5：通过商品检测器提取的边界框和边界框特征作为图像特征,结合文本特征,输入到多模态预训练模型进行自监督训练；S6：将单品图像的图片模态和文本模态输入到多模态预训练模型提取检索特征,并将检索特征存放于检索库中；S7：提取组合品图像中每个目标商品的边界框及边界框特征,输入步骤S5训练好的多模态预训练模型,提取图文融合的检索特征,计算组合品特征与检索库中单品特征的余弦距离作为商品相似度,选取最相似的单品作为结果返回。</td>   <td>G06Q30/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;              苏志宏;                   陈小燕       </td>   <td>中山大学;广东融谷创新产业园有限公司</td>   <td>基于改进Faster R-CNN的医学影像脑肿瘤检测方法与系统</td>   <td>广东省</td>   <td>CN114445328A</td>   <td>2022-05-06</td>   <td>本发明公开了一种基于改进Faster R-CNN的医学影像脑肿瘤检测方法与系统。包括：从数据库中获取磁共振图像数据集；通过光流法和生成对抗网络以对数据集的图像做预处理,进行数据增强；构建改进Faster R-CNN深度网络模型；采用得到的所述数据集训练所述构建的改进Faster R-CNN深度网络模型；将需要预测的磁共振图像输入训练好的网络模型,输出脑肿瘤目标检测结果。本发明采用了基于光流法和生成对抗网络的数据增强方法,并设计了一个改进Faster R-CNN目标检测网络模型,加入了图像特征金字塔结构以及卷积门控循环单元ConvGRU模块,修改了网络训练时的数据读取方式,增强了肿瘤检测结果的连续性,提升了脑肿瘤的检索精度和查全率。</td>   <td>1.一种基于改进Faster R-CNN的医学影像脑肿瘤检测方法,其特征在于,所述方法包括：从磁共振图像数据库中获取磁共振图像数据集；通过光流法和生成对抗网络,对所述获取的数据集的图像做预处理,进行数据增强；构建改进Faster R-CNN深度网络模型,加入图像特征金字塔结构以及卷积门控循环单元ConvGRU模块,并修改网络训练时的数据读取方式；采用所述经数据增强后得到的数据集训练改进Faster R-CNN模型；将需要预测的磁共振图像输入所述训练好的改进Faster R-CNN模型,输出脑肿瘤目标检测结果。</td>   <td>G06T7/00;G06V10/40;G06V10/74;G06V10/774;G06V10/80;G06V10/82;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              张鹏       </td>   <td>中山大学·深圳;中山大学</td>   <td>遥感影像目标区域覆盖优化方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN114445355A</td>   <td>2022-05-06</td>   <td>本发明公开了一种遥感影像目标区域覆盖优化方法、装置、设备及介质,本发明通过获取第一轮廓的目标区域以及若干个第二轮廓的候选遥感影像,根据第一轮廓与第二轮廓确定目标遥感影像,计算每一目标遥感影像的独有部分面积,当最小的独有部分面积小于重复度阈值,将最小的独有部分面积对应的目标遥感影像删除,返回计算每一目标遥感影像的独有部分面积的步骤,直至最小的独有部分面积大于等于重复度阈值,当最小的独有部分面积大于等于重复度阈值,根据所有保留的目标遥感影像确定遥感影像选择方案,减少最终保留的目标遥感影像的数量,优化目标遥感影像对目标区域的覆盖,减少了人工的参与,提高了处理效率,本发明可广泛应用于遥感技术领域。</td>   <td>1.遥感影像目标区域覆盖优化方法,其特征在于,包括：获取第一轮廓的目标区域以及若干个第二轮廓的候选遥感影像；根据所述第一轮廓与所述第二轮廓确定目标遥感影像；计算每一所述目标遥感影像的独有部分面积；所述独有部分面积为每一目标遥感影像与其他的目标遥感影像不相交部分的面积；当最小的独有部分面积小于重复度阈值,将最小的独有部分面积对应的目标遥感影像删除,返回所述计算每一所述目标遥感影像的独有部分面积的步骤,直至最小的独有部分面积大于等于所述重复度阈值；当最小的独有部分面积大于等于所述重复度阈值,根据所有保留的目标遥感影像确定遥感影像选择方案。</td>   <td>G06T7/00;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李超峰;              邓一术;              经秉中;              陈浩华;                   李彬       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种鼻咽癌淋巴结区域的识别分割方法、装置及系统</td>   <td>广东省</td>   <td>CN114445421A</td>   <td>2022-05-06</td>   <td>本发明公开了一种鼻咽癌淋巴结区域的识别分割方法、装置及系统。该装置包括数据获取单元以及识别分割单元。该系统包括识别分割模块以及数据存储模块。通过端到端的从粗到细的三维深度监督卷积神经网络三维模型对待识别分割的磁共振图像进行识别分割,从而获得包括鼻咽癌淋巴结的分割区域,该识别分割方法、装置及系统提升了鼻咽癌淋巴结区域的识别分割的准确性；进一步地,本发明提供的一种鼻咽癌淋巴结区域的识别分割方法、装置及系统还通过预设的双审数据处理方法先对第一训练图像数据组进行处理以获得第二训练图像数据组,从而充分根据淋巴结的形态特点设计合理的模型,进而提升了鼻咽癌淋巴结区域的识别分割的准确性。</td>   <td>1.一种鼻咽癌淋巴结区域的识别分割方法,其特征在于,所述识别分割方法包括：获取待识别分割的磁共振图像；通过预设的淋巴识别分割模型,对所述磁共振图像进行识别分割,从而获得分割区域图像；所述淋巴识别分割模型为端到端的、从粗到细的、三维深度监督卷积神经网络三维模型。</td>   <td>G06T7/11;G06V20/64;G06K9/62;G06N3/04;G06N3/08;G06V10/774;G06V10/26;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭裕兰;              杜沛峰;                   胡俊       </td>   <td>中山大学·深圳;中山大学</td>   <td>稀疏深度图的深度补全方法、计算机装置和存储介质</td>   <td>广东省</td>   <td>CN114445475A</td>   <td>2022-05-06</td>   <td>本发明公开了一种稀疏深度图的深度补全方法、计算机装置和存储介质,深度补全方法中对对神经网络进行训练的过程包括获取彩色图像和深度图真值,对深度图真值进行等距采样获得稀疏深度图,从彩色图像和稀疏深度图提取得到多尺度特征图,对多尺度特征图回归得到初始深度图,计算像素相关性,对初始深度图进行多次迭代滤波获得稠密深度图,对稠密深度图执行多轮迭代处理过程以训练图像一致性优化模块等步骤。本发明对神经网络进行训练,可以改善图像一致性优化模块对稠密深度图的边界处像素深度的预测效果,使得图像一致性优化模块具有根据稠密深度图预测其像素点深度的能力,从使得神经网络具有深度补全的能力。本发明广泛应用于图像处理技术领域。</td>   <td>1.一种稀疏深度图的深度补全方法,其特征在于,所述稀疏深度图的深度补全方法包括：对神经网络进行训练；所述神经网络包括第一编码网络、第一解码网络、像素相关性计算模块、像素相关性优化模块和图像一致性优化模块；获取待处理图像；使用经过训练的所述神经网络,对所述待处理图像进行深度补全；所述对神经网络进行训练,包括：获取彩色图像；获取所述彩色图像对应的深度图真值；对所述深度图真值进行等距采样,获得稀疏深度图；所述第一编码网络从所述彩色图像和所述稀疏深度图提取得到多尺度特征图；所述多尺度特征图包括多个不同尺度的特征信息；所述第一解码网络对所述多尺度特征图回归得到初始深度图；所述像素相关性计算模块根据所述多尺度特征图计算像素相关性；所述像素相关性表示所述彩色图像中各像素与相邻像素之间的相关程度；所述像素相关性优化模块对所述初始深度图进行多次迭代滤波,获得稠密深度图；所述图像一致性优化模块执行多轮迭代处理过程；在一轮迭代处理过程中,根据目标深度图与所述彩色图像,确定本轮所述迭代处理过程的残差图,根据所述目标深度图和所述残差图,确定本轮所述迭代处理过程的处理结果,根据本轮所述迭代处理过程的处理结果和所述目标深度图确定损失函数值,根据所述损失函数值调整所述图像一致性优化模块、所述第一编码网络、所述第一解码网络和所述像素相关性计算模块的参数或结束训练过程；其中,当本轮所述迭代处理过程为第一轮迭代处理过程,所述目标深度图为所述稠密深度图,当本轮所述迭代处理过程不是第一轮迭代处理过程,所述目标深度图为上一轮迭代处理过程的处理结果。</td>   <td>G06T7/50;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭裕兰;              张永聪;              陈铭林;                   敖晟       </td>   <td>中山大学</td>   <td>一种基于激光雷达点云数据的三维目标检测方法</td>   <td>广东省</td>   <td>CN111681212B</td>   <td>2022-05-03</td>   <td>本发明公开了一种基于激光雷达点云数据的三维目标检测方法,所述方法根据激光雷达点云的数据特征,采取一种稠密的数据表达形式,以得到稠密的特征并将三维特征转换为二维特征,有效提高运算效率并提升运算精度。</td>   <td>1.一种基于激光雷达点云数据的三维目标检测方法,其特征在于,所述方法包括以下步骤：将点云表示成密集形的表面图,图中行数为K,其中K是激光雷达的通道数；给定一个激光雷达点p＝(x,y,z,r,l),其中(x,y,z),r和l∈{0,...,K-1}分别表示位置、反射率和点所在层数；点p位于表面图S～(h×w)的网格(h,w)中,其中h＝l,表面图根据场景的表面,将三维点投影到二维网格中,对于表面图的每个网格(h,w),通过平均网格内的所有点,获得质心点(h,w)网格内的深度的计算如下：                  其中,然后可以获得表面深度图D-(map)＝{d}∈R～(H×W)；表面深度图将深度信息存储在每个网格中；基于体素特征编码层的网格特征编码器,体素特征编码层处理表面图的每个网格以生成该网格的特征,从而生成规则的2D表曲面特征图若网格没有任何点,则使用零填充；且网格特征编码器不执行体素特征编码层中的随机采样；具有N种不同分辨率的表面图,即S～(H×W),由网格特征编码器对其分别进行独立处理,生成三个表面特征图,即然后,由特征串接得到一个多尺度表面特征F∈R～(3C×H×W)：                  此多尺度表面特征用作后续模块的初始输入；具有表面特征卷积模块,并通过增加一个低分辨率输出的网络反卷积层来获得全分辨率输出；表面特征卷积模块生成的中的前视图特征具有与其输入表面特征F相同的分辨率,但特征的维度不同；具有基于深度表面图的前视图特征从前视图到鸟瞰图的视图转换模块,不同对象的深度不同,但是从2d前视伪图像中获取的绝对深度是不相等的；从俯视图特征中得到物体的深度,并在视图变换后对高度进行回归；从热图H～O派生的点表示俯视图中检测对象中心的位置,即,x,z,而参数图P～O包含对象的参数,检测网络由一个公共特征提取器和两个分支,即热图分支和参数分支组成。</td>   <td>G06T7/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈振武;              周勇;              张枭勇;              许建荣;              张炳振;              胡海峰;              刘怡初;                   赵竟雯       </td>   <td>深圳市城市交通规划设计研究中心股份有限公司;中山大学</td>   <td>单目视觉下的三维目标检测模型的构建方法及检测方法</td>   <td>广东省</td>   <td>CN114429524A</td>   <td>2022-05-03</td>   <td>本发明公开了一种单目视觉下的三维目标检测模型的构建方法及检测方法,所述方法包括：获取带标注的训练图像集；将训练图像集作为训练数据,训练获得基于CenterNet网络的三维目标检测模型,其中,三维目标检测模型的特征提取网络包括多个特征提取模块,至少一个特征提取模块包括池化模块、注意模块以及第一融合模块,池化模块包括并列的全局最大池化层、全局平均池化层和随机池化层,注意模块包括分别与全局最大池化层、全局平均池化层和随机池化层的输出侧连接的三个子注意模块,子注意模块包括激活函数层及批处理归一化层,第一融合模块将三个子注意模块的输出融合。本发明可以简化三维目标检测网络结构,降低三维目标检测模型的训练成本。</td>   <td>1.一种单目视觉下的三维目标检测模型的构建方法,其特征在于,包括：获取带标注的训练图像集；将所述训练图像集作为训练数据,训练获得基于CenterNet网络的三维目标检测模型,其中,所述三维目标检测模型的特征提取网络包括多个特征提取模块,至少一个所述特征提取模块包括池化模块、注意模块以及第一融合模块,所述池化模块包括并列的全局最大池化层、全局平均池化层和随机池化层,所述注意模块包括分别与所述全局最大池化层、所述全局平均池化层和所述随机池化层的输出侧连接的三个子注意模块,所述子注意模块包括激活函数层及批处理归一化层,所述第一融合模块将三个所述子注意模块的输出融合。</td>   <td>G06T17/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         董春雨;              马至敏;              郭杰;              陈晓宏;              林凯荣;                   刘智勇       </td>   <td>中山大学;广东省科学院广州地理研究所</td>   <td>一种数据空间分辨率提高方法、装置、介质及终端设备</td>   <td>广东省</td>   <td>CN113077384B</td>   <td>2022-04-29</td>   <td>本发明公开了一种数据空间分辨率提高方法、装置、存储介质及终端设备,包括：将获取的预设时间段内的AVHRR NDVI数据及MODSI NDVI数据进行数据预处理,以得到月尺度数据；将所述月尺度数据输入尺度变换模型进行降尺度处理；对降尺度处理后的尺度数据进行误差分析,并根据分析结果对所述尺度变换模型进行优化。本发明能够将某一地区的AVHRR NDVI低分辨率的空间尺度转变为MODIS NDVI数据高分辨率的空间尺度,提高数据的精度,增加其可用性。</td>   <td>1.一种数据空间分辨率提高方法,其特征在于,所述方法包括：将获取的预设时间段内的AVHRR NDVI数据及MODSI NDVI数据进行数据预处理,以得到月尺度数据；将所述月尺度数据输入尺度变换模型进行降尺度处理；对降尺度处理后的尺度数据进行误差分析,并根据分析结果对所述尺度变换模型进行优化；所述尺度变换模型为：NDVI-(H,x,y,t)＝NDVI-(H,x,y,bl)×(1+K-(x,y,t)×R-(CVx,y))+ε-(x,y,t)R-(CVx,y)＝modis-CV/avhrr-CVK-(x,y,t)＝(NDVI-(L,x,y,t)-NDVI-(L,x,y,bl))/NDVI-(L,x,y,bl)其中,NDVI-(H,x,y,t)为降尺度后像素x,y和时间t的高分辨率NDVI,NDVI-(H,x,y,bl)为基准基时期x,y像素的MODIS NDVI的中位数,NDVI-(L,x,y,t)为降尺度前像素x,y和时间t的低分辨率NDVI,NDVI-(L,x,y,bl)为基线时期x,y像素的AVHRR NDVI的中位数,modis-CV、avhrr-CV为MODISNDVI与AVHRR NDVI的变异系数值,R-(CVx,y)为两种数据变异系数比值,ε-(x,y,t)为随机差异值。</td>   <td>G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨猛;                   凌颉       </td>   <td>中山大学</td>   <td>基于自适应和间隔斥力损失的全监督学习图像分类方法</td>   <td>广东省</td>   <td>CN114417994A</td>   <td>2022-04-29</td>   <td>本发明针对现有技术的局限性,提出了一种基于自适应和间隔斥力损失的全监督学习图像分类方法,通过自适应控制错误分类损失来有效扩大类间分离；考虑了最具有迷惑性的类,以便分类器可以更好地区分不同的类；该方法的时间复杂度与基于类内间隔方法的时间复杂度几乎相同；其涉及的模型迭代过程更加高效,并且在图像分类和人脸识别的应用的表现中清楚地展现了与现有基于类内间隔方法的互补性及其优越的性能。</td>   <td>1.一种基于自适应和间隔斥力损失的全监督学习图像分类方法,其特征在于,包括以下步骤：S1,获取待识别图像；S2,将所述待识别图像输入预设的图像分类模型中,获得所述待识别图像的分类结果；所述图像分类模型由在目标函数中结合了自适应斥力损失以及间隔斥力损失的深度卷积神经网络训练获得；其中,所述自适应斥力损失用于扩大类间分离,所述间隔斥力损失用于处理最具有迷惑性类别。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         董晓;              詹巽霖;              吴洋鑫;                   梁小丹       </td>   <td>中山大学</td>   <td>一种基于自协调对比学习的五模态商品预训练方法及检索系统</td>   <td>广东省</td>   <td>CN114418032A</td>   <td>2022-04-29</td>   <td>本发明公开了一种基于自协调对比学习的五模态商品预训练方法及检索系统,其中方法如下：S1：根据不同模态数据构建相应的模态特征编码提取器；S2：结合模态特征编码提取器提取的各个模态数据的特征编码、位置编码和分段编码,学习不同模态数据的嵌入表示；S3：构建自协调对比学习的多模态预训练模型；S4：将带有遮挡部分特征的不同模态数据利用模态特征编码提取器,学习得到嵌入表示输入到步骤S3的多模态预训练模型进行自监督训练,将各个模态数据进行高层语义融合,并使用自协调对比学习方法不断纠正模态间的关联性,在学习过程中恢复出所对应位置的特征。本发明实现具有高泛化性、高可用性,高准确性的组合商品检索系统。</td>   <td>1.一种基于自协调对比学习的五模态商品预训练方法,其特征在于：所述的方法包括步骤如下：S1：根据不同模态数据构建相应的模态特征编码提取器；S2：结合模态特征编码提取器提取的各个模态数据的特征编码、位置编码和分段编码,学习不同模态数据的嵌入表示；S3：构建自协调对比学习的多模态预训练模型；S4：将带有遮挡部分特征的不同模态数据利用模态特征编码提取器,学习得到嵌入表示输入到步骤S3的多模态预训练模型进行自监督训练,将各个模态数据进行高层语义融合,并使用自协调对比学习方法不断纠正模态间的关联性,在学习过程中恢复出所对应位置的特征。</td>   <td>G06K9/62;G06F16/43;G06F16/48;G06Q30/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王甲海;                   黄欢欢       </td>   <td>中山大学</td>   <td>一种基于深度强化学习的城市电动车辆调度方法和系统</td>   <td>广东省</td>   <td>CN114418213A</td>   <td>2022-04-29</td>   <td>本发明公开了一种基于深度强化学习的城市电动车辆调度方法和系统,方法为一种端到端的方法,给定问题实例作为输入,利用训练好的深度神经网络可以直接输出问题的解。具体地,提出了一个可以捕捉和提取边信息的图神经网络对策略进行建模,以有效地解决非对称车辆路径问题,且提出了一个软约束+硬约束的两阶段训练方法,以有效地处理带时间窗电动车辆路径问题中的复杂约束。与传统方法相比,它能在获得更好求解效果的前提下大幅度地缩减求解时间。</td>   <td>1.一种基于深度强化学习的城市电动车辆调度方法,其特征在于,包括以下步骤：S1：将带时间窗电动车辆路径问题建模成一个有向完全图,仓库、充电站和客户为图中的结点,任意两个结点之间通过边相连接,对需求、距离和时间数据分别进行归一化处理；S2：使用编码器分别对所述有向完全图中的点信息和边信息进行编码得到对应的特征表示；S3：使用解码器进行解码,在每步解码中根据步骤S2中得到的点和边的特征表示以及当前车辆状态信息和历史路径信息,以自回归的方式逐步构造路径,得到问题的解；S4：根据所述问题的解计算出总回报,使用REINFORCE算法对编码器和解码器的参数进行更新；S5：将训练好的编码器和解码器用于求解带时间窗电动车辆路径问题。</td>   <td>G06Q10/04;G06Q10/06;G06F30/27;G06N3/04;G06N3/08;G06F111/04;G06F111/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陆遥;              江功发;                   周元品       </td>   <td>中山大学</td>   <td>一种全数字化乳腺摄影图像合成方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN114418916A</td>   <td>2022-04-29</td>   <td>本发明公开了一种全数字化乳腺摄影图像合成方法、系统、设备及介质,方法包括：获取乳腺断层图像和初始乳腺摄影图像；将所述乳腺断层图像和所述初始乳腺摄影图像输入超分辨率网络,其中,所述超分辨率网络的损失函数包括梯度引导生成对抗网络损失函数；根据所述超分辨率网络对所述乳腺断层图像和初始乳腺摄影图像进行残差处理,确定残差图像；根据所述超分辨率网络对所述初始乳腺摄影图像进行图像上采样处理,确定上采样图像；对所述残差图像和所述上采样图像进行合成处理,确定全数字化乳腺摄影图像。本发明实施例能够使用低辐射量垂直投影生成高质量的全数字化乳腺摄影图像,可广泛应用于图像处理技术领域。</td>   <td>1.一种全数字化乳腺摄影图像合成方法,其特征在于,包括：获取乳腺断层图像和初始乳腺摄影图像；将所述乳腺断层图像和所述初始乳腺摄影图像输入超分辨率网络,其中,所述超分辨率网络的损失函数包括梯度引导生成对抗网络损失函数；根据所述超分辨率网络对所述乳腺断层图像和初始乳腺摄影图像进行残差处理,确定残差图像；根据所述超分辨率网络对所述初始乳腺摄影图像进行图像上采样处理,确定上采样图像；对所述残差图像和所述上采样图像进行合成处理,确定全数字化乳腺摄影图像。</td>   <td>G06T5/50;G06T7/00;G06N3/08;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              李龙辉;              张小虎;              刘海波;              刘纸宾;                   肖钧       </td>   <td>中山大学中山眼科中心</td>   <td>一种机器学习模型训练和晶状体悬韧带评估系统</td>   <td>广东省</td>   <td>CN114418943A</td>   <td>2022-04-29</td>   <td>本发明涉及医疗技术领域,更具体地,涉及一种机器学习模型训练和晶状体悬韧带评估系统。本发明通过对眼球图像进行优化和基于图像特征检测算法进行边缘提取,不仅提高了眼球图像质量,还使后续眼球组织的形变幅度和位移量的获取更准确。此外,还采用机器学习模型减少眼球受力信息的误差,进一步提高晶状体悬韧带生物力学状态的准确率。在此基础上,还进行了相机标定,校正镜头像差等因素引起的图像点处的畸变,以增加晶状体悬韧带生物力学状态评估的准确性。</td>   <td>1.一种机器学习模型训练系统,其特征在于,包括：采集单元,用于采集训练样本；所述训练样本包括：眼球参数以及眼球参数对应的眼球受力信息；所述眼球参数包括：角膜生物力学、角膜厚度、眼压和前房深度；训练单元,用于基于机器学习算法建立受力分析模型,并且利用所述训练样本对受力分析模型进行训练。</td>   <td>G06T7/00;G06T7/13;G06T7/80;G16H30/20;G16H50/20;G16H50/70;G06N20/00;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邝嘉健;              郑伟诗;                   高义朋       </td>   <td>中山大学</td>   <td>基于图像的逐步生成式的人体重建方法及装置</td>   <td>广东省</td>   <td>CN114419277A</td>   <td>2022-04-29</td>   <td>本发明公开了基于图像的逐步生成式的人体重建方法及装置,方法包括：提取给定人体图像的图像特征,解码生成x、y、z三个方向维度的热图,经连接编码后重新分离,再经过热图积分回归出人体关节点坐标；将人体关节点热图分布经过transfomer编码器进行人体关节点及人体网格模型顶点信息交互、人体网格模型顶点上采样以及批正则化后逐步生成最终的人体网格模型；将人体网格模型顶点坐标输入通用的SMPL模型回归器后,输出人体模型对应的人体关节点坐标,作为人体网格模型重建约束。本发明在人体三维姿态估计的基础上,引入注意力机制对不同方向维度热图分布进行优化,并采用了由粗到细的思路逐步生成人体网格模型。</td>   <td>1.基于图像的逐步生成式的人体重建方法,其特征在于,包括下述步骤：提取给定人体图像的图像特征,将所述图像特征解码生成x、y、z三个方向维度的热图,再将x、y、z三个方向维度的热图分布进行连接,编码后分离出x、y、z三个方向维度的热图分布,再经过热图积分回归出人体关节点坐标；将人体关节点热图分布经过transfomer编码器进行人体关节点及人体网格模型顶点信息交互、人体网格模型顶点上采样以及批正则化后逐步生成最终的人体网格模型；将人体关节点坐标输入人体网格模型,经过通用的SMPL模型回归器后,输出人体模型对应的人体关节点坐标,作为人体网格模型重建约束。</td>   <td>G06T17/20;G06V40/10;G06V10/766;G06V10/80;G06V10/82;G06N3/04;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡晨;              王若梅;              罗笑南;                   林淑金       </td>   <td>中山大学</td>   <td>一种基于深度网络增强服装属性识别精度的方法</td>   <td>广东省</td>   <td>CN108629367B</td>   <td>2022-04-26</td>   <td>本发明公开了一种基于深度网络增强服装属性识别精度的方法。本发明通过Mask-out策略对服装图像数据集进行处理,通过计算图像的局部特征从而改善全局特征,最终获取最优解。该过程经历了三个神经网络,多标签属性识别增强网络将输入的一维属性特征向量处理为一个一维的预测向量,多示例全卷积网络将输入的二维特征图处理为一个二维预测矩阵,弱监督属性识别网络将输入的二维预测矩阵转化为一维预测向量完成整个服装属性识别任务。在多标签属性增强网络阶段,网络通过弱标签学习接收训练数据,避免了大量人工标注工作,这使得本方法更加经济、高效；基于弱监督学习强化的属性识别网络利用局部最优解改善整张图像的属性识别精度,从而进一步提高服装属性的识别精度。</td>   <td>1.一种基于深度网络增强服装属性识别精度的方法,其特征在于,所述方法包括：获取服装图像数据以及标签数据作为初始数据集,数据集分为训练集与测试集；将初始训练集服装数据和标签数据输入多标签属性识别增强网络模型,模型学习后输出测试数据的预测信息；利用所述预测信息,并结合Mask-out策略和多示例学习策略制作多示例全卷积网络模型的训练集与测试集；将所述训练集和测试集对多示例全卷积网络模型进行训练,之后把初始的训练集服装数据输入训练好的多示例全卷积网络,输出学习到的特征分布；联合初始训练集服装数据和标签数据,以及所述特征分布,作为弱监督属性识别网络的输入；弱监督属性识别网络对服装图像中的属性信息进行识别,输出最终的识别结果；其中,所述多标签属性识别增强网络,具体为：多标签属性识别增强网络有16个卷积层,卷积核大小均为3×3,卷积操作前均对图像数据做padding＝1的操作,卷积层均接ReLU层进行非线性映射,网络包含5个池化层；卷积和池化操作后,接两个全连接层将特征映射为1×M维的向量,其中M∈Z～+,最后通过N个全连接层将一个多分类问题转化为多个二分类问题,每个全连接层接一个损失函数层,计算出每个属性存在的概率,每个图像样本得到一个1×N维的向量,记为S＝{s-i|i∈T},s-i为每个图像样本概率向量,T为样本总数；其中,Mask-out策略制作训练集与测试集,具体为：首先利用超像素分割算法处理每张图像样本,得到每个图像样本的多个超像素块标签,计算每一块超像素块的像素均值代替该图像整个超像素块中像素的值,将处理后的图像送入所述多标签属性识别增强网络得到预测向量P＝{p-i|i∈T},其中p-i为每个图像样本预测后的向量,通过p-i与所述s-i逐项做差平方,得到p′-i＝{p′-(ij)|j∈N},其中,p′-(ij)为p-i与所述s-i差值的二范数；其中,多示例学习策略制作训练集与测试集,具体为：从P′＝{p′-i|i∈T}中选取每个属性前若干个样本组成新的训练集与测试集,记优化后的数据集为P″＝{p″-i|i∈N},显然</td>   <td>G06K9/62;G06V10/774;G06V10/764;G06V30/194;G06V30/19;G06V10/82;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘冶;              李宏浩;              陈宇恒;              刘春鹏;              吕梦瑶;                   印鉴       </td>   <td>中山大学;广州赫炎大数据科技有限公司</td>   <td>用户价值预测方法、装置、存储介质及设备</td>   <td>广东省</td>   <td>CN109325640B</td>   <td>2022-04-26</td>   <td>本发明涉及一种用户价值预测方法、装置、存储介质及设备,包括：将预处理后的行为数据和对应的用户价值存储为数据集；通过数据集分别训练SVM模型、随机森林模型和决策树模型,再用训练好的模型做预测,获得各模型预测的用户价值；通过各模型预测的用户价值以及对应的实际的用户价值训练逻辑回归模型,确定最优的SVM模型、随机森林模型和决策树模型以及逻辑回归模型；获取目标产品中待分析用户的行为数据,并对行为数据进行预处理；且分别输入至最优的SVM模型、随机森林模型和决策树模型中,获得各模型预测的用户价值；将各模型预测的用户价值输入至最优的逻辑回归模型中,获得最终预测的用户价值。本发明提高了预测的准确性,提高了预测速度。</td>   <td>1.一种用户价值预测方法,其特征在于,包括如下步骤：获取目标产品中用户的行为数据以及对应的用户价值,并对所述行为数据进行预处理,且将预处理后的行为数据和对应的用户价值存储为数据集；所述用户价值为用户对目标产品的贡献程度,包括用户的活跃度以及付费内容；所述用户的行为数据包括用户的基础数据和用户的充值付费数据；所述用户的充值付费数据包括：用户的自然周平均付费数据、用户的自然月平均付费数据、用户的自然季度平均付费数据、用户的自然周平均充值数据、用户的自然月平均充值数据、以及用户的自然季度平均充值数据；对自然周、自然月、自然季度分别设置不同的权重A、B和C,其中A+B+C＝1,将用户的自然周平均付费金额与权重A的乘积作为用户的自然周平均付费数据、用户的自然月平均付费金额与权重B的乘积作为用户的自然月平均付费数据、用户的自然季度平均付费金额与权重C的乘积用户的自然季度平均付费数据、用户的自然周平均充值金额与权重A的乘积作为用户的自然周平均充值数据、用户的自然月平均充值金额与权重B的乘积作为用户的自然月平均充值数据、以及用户的自然季度平均充值金额与权重C的乘积作为用户的自然季度平均充值数据；通过数据集分别训练SVM模型、随机森林模型和决策树模型,再用训练好的模型做预测,获得各模型预测的用户价值；通过各模型预测的用户价值以及对应的实际的用户价值训练逻辑回归模型,确定最优的SVM模型、随机森林模型和决策树模型以及逻辑回归模型；在各个模型的每次训练过程中,自动化叠加或减少权重A、B和C中的其中一个值,并同时减少或增加另外2个值,以使某个值在迭代变化的过程中,另外两个值也同步迭代变化,进而使权重A、B和C中的关系始终保持A+B+C＝1；获取目标产品中待分析用户的行为数据,并对所述行为数据进行预处理；将预处理后的行为数据分别输入至最优的SVM模型、随机森林模型和决策树模型中,获得各模型预测的用户价值；将各模型预测的用户价值输入至最优的逻辑回归模型中,获得最终预测的用户价值。</td>   <td>G06Q10/04;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陶良乐;              陈湘萍;                   周凡       </td>   <td>中山大学</td>   <td>一种基于内容的多版本App更新评价方法及系统</td>   <td>广东省</td>   <td>CN109146625B</td>   <td>2022-04-26</td>   <td>本发明实施例公开了一种基于内容的多版本App更新评价方法及系统,其中,该方法包括：通过自动遍历App,获取信息并存储到数据库；获取数据库中的信息进行分析、识别处理,获得不同版本App的差异；对App的评论信息及评论时间等相关信息进行预处理,获得修改后与每个版本的App相对应的用户评论信息；获取所述修改后与每个版本的App相对应的用户评论信息,结合不同版本App的差异进行比较评分处理,获得每个App更新的综合情感分析数值。实施本发明实施例,能够为开发者提供更加全面的反馈,提高工作效率；还能为开发者提供特定功能生命周期的有关信息。</td>   <td>1.一种基于内容的多版本App更新评价方法,其特征在于,所述方法包括：通过自动遍历App,获取App信息并存储到数据库；获取数据库中的信息进行分析、识别处理,获得不同版本App的差异；获取对App应用商店的评论信息及评论时间进行预处理,获得修改后与每个版本的App相对应的用户评论信息；获取所述修改后与每个版本的App相对应的用户评论信息,结合不同版本App的差异进行比较评分处理,获得每个App更新的综合情感分析数值；其中,所述通过自动遍历App,获取App信息并存储到数据库,具体为：采用黑盒技术遍历所有App,采用智能输入生成工具模拟产生智能输入,对于每个UI,记录下其屏幕快照和UI层次结构树；存储系统层面及应用层面的过程信息,以及每个测试输入出发的方法路径信息,并修改代码,将所有信息存储到非结构性数据库中；其中,所述获取数据库中的信息进行分析、识别处理,获得不同版本App的差异,具体为：获取所述数据库中的App数据进行选取同一个App的不同版本,制成App的不同版本信息的列表,通过java语言进行编写程序,选择其中一组,即同一款App所有不同版本的列表；获取所述同一款App所有不同版本的列表,从中选取相邻两个版本的App进行提取该两个App的界面信息；获取所述两个App的界面信息,对其内容进行比较处理,获得两个具有相似性的界面；获取所述两个具有相似性的界面,对所述两个具有相似性的界面中的所有可见文字进行识别处理,获得界面内所有差异的内容。</td>   <td>G06Q30/06;G06Q10/06;G06F8/65;G06F40/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         瞿毅力;              王莹;              苏琬棋;              邓楚富;              卢宇彤;                   陈志广       </td>   <td>中山大学</td>   <td>生成配准的带病灶分割标签的多模态MRI的方法、系统及介质</td>   <td>广东省</td>   <td>CN110544275B</td>   <td>2022-04-26</td>   <td>本发明公开了一种生成配准的带病灶分割标签的多模态MRI的方法、系统及介质,本发明的方法包括获取正态分布的随机矩阵并输入生成对抗网络中训练好的结构特征解码器解码生成结构特征图；将结构特征图与随机选取的病灶分割标签图通过随机输入融合得到融合结果、并输入生成对抗网络中训练好的随机编码器得到编码；将编码输入生成对抗网络中训练好的各个模态的解码器,分别生成配准后的多模态MRI。本发明将生成对抗网络中的生成器模块化为编码器和解码器,通过多组编码器、解码器和鉴别器的组合训练,可接收一个符合设计规范的随机输入进而生成一组有病灶分割标签的配准的多模态MRI图像,可广泛应用于医学影像领域。</td>   <td>1.一种生成配准的带病灶分割标签的多模态MRI的方法,其特征在于实施步骤包括：1)从正态分布N(0,1～2)获取随机矩阵Code-(F,RM)；2)将随机矩阵Code-(F,RM)输入生成对抗网络中训练好的结构特征解码器Decoder-F解码生成结构特征图F-(RM)；3)将结构特征图F-(RM)与随机选取的病灶分割标签图L通过随机输入融合得到融合结果；4)将融合结果输入生成对抗网络中训练好的随机编码器Encoder-(RM)得到编码Code-(RM)；5)将编码Code-(RM)输入生成对抗网络中训练好的各个模态i的i模态解码器Decoder-i,分别生成配准后的i模态MRI i-g。</td>   <td>G06T7/38;G06V10/80;G06V10/82;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         关杰鸿;              郑伟诗;              林涛;              庞景龙;                   邝嘉健       </td>   <td>中山大学</td>   <td>一种单目RGB摄像头的三维重建方法、系统和介质</td>   <td>广东省</td>   <td>CN114399601A</td>   <td>2022-04-26</td>   <td>本发明公开了一种单目RGB摄像头的三维重建方法、系统和介质,方法包括：从单目RGB摄像头拍摄视频中的图像序列选取关键帧；通过特征金字塔对关键帧进行特征提取,进行残差操作获得二维特征；将二维特征导入二维编码器中提取二维结构特征,进行反投影得到3d volume；引入体素循环模块对3d volume进行重建,获得重建3d volume；将所有关键帧的重建3d volume进行特征聚合获得融合结果；将融合结果输入3d编码解码器中,提取并回归获取tsdf重建结果。本发明通过提取不同的尺度特征,保留高维度语义信息,减少计算量；引入体素循环模块,对三维特征信息进行重建并进行特征聚合,获取不同维度的信息,使重建效果更加平滑,提高了三维重建的速度和精度。</td>   <td>1.一种单目RGB摄像头的三维重建方法,其特征在于,包括下述步骤：从单目RGB摄像头拍摄视频中的图像序列选取关键帧；通过特征金字塔对关键帧进行特征提取,使用残差操作获得二维特征；将二维特征导入二维编码器中提取二维结构特征,进行反投影得到3d volume；引入体素循环模块对3d volume进行重建,获得重建3d volume；将所有关键帧的重建3d volume进行特征聚合获得融合结果；将融合结果输入3d编码解码器中,提取并回归获取tsdf重建结果。</td>   <td>G06T17/00;G06K9/62;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余顺争;                   黄海宇       </td>   <td>中山大学</td>   <td>一种基于有向图的无监督P2P流量识别方法及系统</td>   <td>广东省</td>   <td>CN114398938A</td>   <td>2022-04-26</td>   <td>本发明公开了一种基于有向图的无监督P2P流量识别方法,该方法首先使用原始网络流量,统计网络会话信息,对节点之间的连接信息进行统计,得到有向特征图；然后利用P2P连接模式的不同点,使用经过修改的无监督GraphSAGE算法,训练得到节点的特征表示；训练时使用无监督的机器学习算法对节点进行分类得到聚类中心,识别时使用节点特征与聚类中心的距离判断节点类别；最后利用节点类别达到识别P2P流量的目的。本发明不需要对网络流量样本进行标注,属于无监督算法,解决了流量识别领域对数据标注的依赖问题,提出了P2P网络流量识别的创新方法,可广泛应用于网络流量分析技术领域。</td>   <td>1.一种基于有向图的无监督P2P流量识别方法,其特征在于,包括：获取目标时间段的原始网络流量,统计得到网络会话信息；根据所述网络会话信息,统计节点之间的连接信息得到有向特征图；根据所述有向特征图,训练无监督模型得到节点嵌入集；根据所述节点嵌入集,结合无监督机器学习算法确定节点类型；根据所述节点类型,确定P2P网络流量。</td>   <td>G06K9/62;H04L43/0876</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余顺争;                   彭思洁       </td>   <td>中山大学</td>   <td>基于用户行为轮廓聚类的异常检测方法和系统</td>   <td>广东省</td>   <td>CN114398945A</td>   <td>2022-04-26</td>   <td>本发明公开了基于用户行为轮廓聚类的异常检测方法和系统,本发明通过获取至少两个用户的历史行为数据,根据预设间隔的时间窗口对历史行为数据进行第一划分处理并进行多元行为模式学习,得到每一时间窗口的第一用户行为轮廓,分别对第一用户行为轮廓进行第一聚类确定每一时间窗口对应的正常行为模式以及异常行为模式；根据历史行为数据、每一时间窗口对应的正常行为模式以及异常行为模式生成正常行为模式库和恶意行为模式库,在最大程度利用用户个人历史行为数据的前提下,进行用户集合行为模式的挖掘,从而构建了用户集合的正常行为模式库以及恶意行为模式库,提高了异常行为检测方法的有效性,本发明可广泛应用于计算机领域。</td>   <td>1.基于用户行为轮廓聚类的异常检测方法,其特征在于,包括：获取用户集合的历史行为数据；所述用户集合包括至少两个用户；根据预设间隔的时间窗口对所述历史行为数据进行第一划分处理,并对第一划分处理结果进行多元行为模式学习,得到每一所述时间窗口的第一用户行为轮廓；分别对所述第一用户行为轮廓进行第一聚类,确定每一所述时间窗口对应的正常行为模式以及异常行为模式；根据所述历史行为数据、每一所述时间窗口对应的所述正常行为模式以及所述异常行为模式,生成正常行为模式库和恶意行为模式库；根据所述正常行为模式库以及所述恶意行为模式库对待检测用户进行检测,得到检测结果。</td>   <td>G06K9/62;H04L9/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              郭贵松;              宁丞浩;              甘叔玮;              叶雪辀;                   张小虎       </td>   <td>中山大学</td>   <td>长度约束下的弹目标高精度姿态测量方法</td>   <td>广东省</td>   <td>CN110866954B</td>   <td>2022-04-22</td>   <td>本发明公开的一种长度约束下的弹目标高精度姿态测量方法,通过搭建双目立体视觉交汇测量系统,将两个摄像机置于弹尾后侧的两边,标定得到的左、右相机的内外参数以及左、右摄像机之间的平移以及旋转关系。利用双目立体视觉交汇测量系统对着靶过程中的导弹目标进行拍摄,获得导弹目标着靶时的图像,获取导弹目标的世界坐标。用导弹目标其导弹头至导弹尾部的已知长度,弥补图像测量系统沿弹体方向精度不足的问题,得到三维高精度测量结果,从而得到高精度弹体姿态。</td>   <td>1.一种长度约束下的弹目标高精度姿态测量方法,其特征在于,包括如下步骤：第一步,搭建双目立体视觉交汇测量系统；双目立体视觉交汇测量系统包括两台焦距相同的CCD摄像机；两台CCD摄像机左右对称设置在靶子的两侧,导弹目标从左、右摄像机之间进入到两相机视场区域,左、右摄像机用于记录导弹进入两相机视场区域到导弹目标到达靶子的过程的图像；其中左、右摄像机的位置坐标确定方法如下：以导弹目标垂直着靶时弹体的中点为原点O′,垂直于靶子表面的方向为z轴,平行于靶子表面且垂直于z轴的直线为x轴；探测区域为以原点O′为中心,边长为q×q的正方形区域,左、右摄像机设置在探测区域的左右两侧；以探测区域q×q的外接圆作为左、右摄像机的有效视场区域,有效视场区域的圆心为O′,半径为两摄像机的视场角均为2α,两摄像机与z轴夹角均为则左、右摄像机的位置坐标为：                                    第二步,通过对双目立体视觉交汇测量系统进行标定,得到双目立体视觉交汇测量系统中左、右摄像机的内外参数；其中左、右摄像机的内参数包括左、右摄像机的焦距f-a、f-b,左、右摄像机的外参数包括左、右摄像机之间的平移矩阵T-(ab)以及旋转矩阵R-(ab),左、右摄像机之间的平移矩阵T-(ab)以及旋转矩阵R-(ab)如下：                                    第三步,利用双目立体视觉交汇测量系统对着靶过程中的导弹目标进行拍摄,获得导弹目标着靶时的图像；第四步,获取导弹目标的世界坐标；导弹目标的世界坐标包括导弹头p-(head)坐标(x-(head),y-(head),z-(head))以及尾部p-(tail)坐标为(x-(tail),y-(tail),z-(tail))；结合第二步中标定得到的左、右相机的内外参数,使用三角测量法计算导弹头p-(head)坐标(x-(head),y-(head),z-(head))以及尾部p-(tail)坐标(x-(tail),y-(tail),z-(tail))；第五步,校正定位误差；导弹目标其导弹头至导弹尾部的长度L已知,使用L对导弹头坐标p-(head)以及导弹尾部坐标p-(tail)进行校正,得到校正后的导弹头坐标p′-(head)以及导弹尾部坐标p′-(tail),如下：(x'-(head)-x'-(tail))～2+(y'-(head)-y'-(tail))～2+(z'-(head)-z'-(tail))～2＝L～2式中,(x'-(head),y'-(head),z'-(head))为校正定位误差后导弹头部p'-(head)的世界坐标值,(x'-(tail),y'-(tail),z'-(tail))为校正定位误差后导弹尾部p′-(tail)的世界坐标值；其中,x′-(head)＝x-(head),y′-(head)＝y-(head),x′-(tail)＝x-(tail),y′-(tail)＝y-(tail),z′-(tail)＝z-(tail),校正后的导弹头部z′-(head)坐标值通过求解下式得到：                  第六步,根据校正后的导弹头坐标p′-(head)以及导弹尾部坐标p′-(tail),计算导弹目标的姿态；                                                      Δx＝x′-(head)-x′-(tail)Δy＝y′-(head)-y′-(tail)Δz＝z′-(head)-z′-(tail)式中,α为导弹目标与x轴夹角,β为导弹目标与y轴夹角,γ为导弹目标与z轴夹角；则通过上式计算得到α、β、γ,即为导弹目标的姿态。</td>   <td>G06T7/73;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪玉蓉;              黄晓霞;                   陈国林       </td>   <td>中山大学</td>   <td>环境反向散射通信信号处理方法</td>   <td>广东省</td>   <td>CN112668352B</td>   <td>2022-04-22</td>   <td>本发明公开了一种环境反向散射通信信号处理方法,其包括获取混合信号,获取混合信号在IQ域上对应的多个数据点,使用基于高斯混合模型的最大期望聚类算法对各数据点进行聚类,确定目标点簇,以及以目标点簇中各数据点对应的通信信号的可能状态,作为对混合信号的解码结果进行返回等步骤。本发明能够在多个电子标签发送的通信信号产生信号碰撞的情况下,以较高的准确率获得解码结果,从而恢复出各电子标签发送的通信信号,为在环境反向散射通信中实现并行通信提供支持,可以提高环境反向散射通信的数据吞吐量,本发明是在阅读器侧的数据处理方法,无需对电子标签的电路结构或者控制算法进行改造,因此改造成本低本发明广泛应用于通信技术领域。</td>   <td>1.一种环境反向散射通信信号处理方法,其特征在于,包括：获取混合信号；所述混合信号包括多个电子标签各自发出的通信信号,所述通信信号由所述电子标签通过反射或不反射环境信号形成；获取所述混合信号在IQ域上对应的多个数据点；其中,一个所述数据点对应一个所述通信信号的一个可能状态；所述IQ域中的数据点由所述通信信号中的I分量作为横坐标、Q分量作为纵坐标确定；使用基于高斯混合模型的最大期望聚类算法对各所述数据点进行聚类,确定目标点簇；所述目标点簇包括多个所述数据点；以所述目标点簇中各所述数据点对应的所述通信信号的可能状态,作为对所述混合信号的解码结果进行返回；所述使用基于高斯混合模型的最大期望聚类算法对各所述数据点进行聚类,确定目标点簇,包括：随机确定多个初始点簇；使用基于高斯混合模型的最大期望聚类算法调整所述初始点簇的分布,分别确定各所述数据点属于各所述初始点簇的概率；将各所述数据点唯一地归属至最大概率所属的所述初始点簇；当检测到一所述初始点簇所包括的各所述数据点能够对应全部所述电子标签,将该所述初始点簇确定为所述目标点簇；所述随机确定多个初始点簇,包括：设定个m～N所述初始点簇；其中,m为一个所述通信信号的可能状态的数量,N为所述电子标签的数量；m＝2；随机设定m～N个初始均值和m～N个初始方差；向每个所述初始点簇分别分配一个所述初始均值和一个所述初始方差；将各所述初始点簇设定为由分配到的所述初始均值和所述初始方差确定的高斯分布；所述使用基于高斯混合模型的最大期望聚类算法调整所述初始点簇的分布,分别确定各所述数据点属于各所述初始点簇的概率,包括：A.确定第k个所述初始点簇满足高斯分布其中,μ-k为第k个所述初始点簇所满足的高斯分布的均值,σ-k～2为第k个所述初始点簇所满足的高斯分布的方差；B.根据所述初始点簇满足的高斯分布,确定所述数据点x-n属于第k个所述初始点簇的概率为π-k；C.根据所述初始点簇满足的高斯分布,确定所述数据点x-n属于第k个所述初始点簇的后验概率为D.确定所述均值的极大似然估计为所述方差的极大似然估计为所述数据点x-n属于第k个所述初始点簇的概率的极大似然估计为其中N-k为第k个所述初始点簇中包括的数据点的数量；E.以步骤C和D执行迭代,直至所获得的所述数据点x-n属于第k个所述初始点簇的概率的极大似然估计收敛。</td>   <td>G06K7/10;G06K9/62;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张航;                   张子臻       </td>   <td>中山大学</td>   <td>一种基于深度强化学习的二次旅行商问题求解方法和系统</td>   <td>广东省</td>   <td>CN114386706A</td>   <td>2022-04-22</td>   <td>本发明公开一种基于深度强化学习的二次旅行商问题求解方法和系统,方法包括以下步骤：S1：定义二次旅行商问题,即在有向完全图中的某一顶点,访问剩余所有点集一次且仅一次后回到出发点所需的旅行成本；S2：构建求解二次旅行商问题的深度强化学习框架；S3：通过所述深度强化学习框架求解所述二次旅行商问题,得到访问点序列。本发明在极短时间内就能求得二次旅行商问题的近似解,避免了精确解方法求解时间过长,不能实时计算,实时响应,甚至对于问题规模的扩大,并不能得到有效解的问题；同时由于深度强化学习框架模型的拟合能力,避免了启发式算法对迭代计算框架的搭建以及设计者的专业知识的依赖。</td>   <td>1.一种基于深度强化学习的二次旅行商问题求解方法,其特征在于,包括以下步骤：S1：定义二次旅行商问题,即在有向完全图中的某一顶点,访问剩余所有点集一次且仅一次后回到出发点所需的旅行成本；S2：构建求解二次旅行商问题的深度强化学习框架；S3：通过所述深度强化学习框架求解所述二次旅行商问题,得到访问点序列。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/28;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         翦孟欣;              倪江群;                   刘庆亮       </td>   <td>中山大学</td>   <td>一种抗内插缩放攻击的鲁棒图像隐写方法</td>   <td>广东省</td>   <td>CN114387167A</td>   <td>2022-04-22</td>   <td>本发明针对现有技术的局限性,提出了一种抗内插缩放攻击的鲁棒图像隐写方法,该方法相当于通过将抗缩放的鲁棒图像隐写归结为一个多目标优化问题,在最小化缩放图像X'与载秘图像Y'的差异的同时最小化所述载体图像X与载秘图像Y差异；方法中构造了一个C∝C′的映射,即对载体图像X的失真代价函数C,通过映射得到X′→Y′嵌入的失真代价C',最终得到的载秘图像,能够让接收方有效地从攻击后的载秘图像中提取秘密信息；实用性强,对于在(0,1)区间内取值的任意缩放因子的双线性缩放信道都具有强鲁棒特性；且安全性好,即统计不可检测性较好。</td>   <td>1.一种抗内插缩放攻击的鲁棒图像隐写方法,其特征在于,包括以下步骤：S1,获取待处理的载体图像X以及秘密信息m,以预设的缩放因子对所述载体图像进行双线性插值缩放,获得缩放图像X'；S2,计算所述载体图像X的失真代价函数C,将所述失真代价函数C映射为所述缩放图像X'的失真代价函数C'；S3,根据所述失真代价函数C',采用利用STC编码将所述秘密信息m嵌入所述缩放图像X',获得载秘图像Y'；S4,对所述载秘图像Y'进行缩放逆处理,获得与所述载体图像X大小一致的载秘图像Y。</td>   <td>G06T3/40;G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         柯尊富;              李伟忠;              陈丽丽;                   杨欢       </td>   <td>中山大学附属第一医院;中山大学</td>   <td>人工智能肺癌病理免疫表型预测及辅助分型系统</td>   <td>广东省</td>   <td>CN114387214A</td>   <td>2022-04-22</td>   <td>本发明提出了人工智能肺癌病理免疫表型预测及辅助分型系统,通过对读取的数字病理切片图像进行预处理,由人工智能算法模块进行分析,将数字病理切片图像区分为正常肺组织图像和肺癌组织图像并生成初步分析意见；对肺癌组织图像进行识别并将对应的肺癌轮廓进行勾画,获取肺癌部分区域图像,再由人工智能算法模块预测肺癌免疫表现型；最后对肺癌免疫表现型进行智能整合,自动进行肺癌亚型的免疫组化分类并生成分析报告,并勾画出癌症区域,生成最终的分析报告。本方案将肺癌切片转化为数字病理切片图像的形式进入系统进行肺癌分型预测,避免了活检组织量不足而导致无法进一步进行免疫组化检测问题的出现,有效提高了检测效率,降低了检测成本。</td>   <td>1.人工智能肺癌病理免疫表型预测及辅助分型系统,其特征在于,包括数字病理切片图像读取模块(1)、图像预处理模块(2)、人工智能算法模块(3)、初步意见生成模块(4)、初步意见判断模块(5)、图像识别模块(6)、智能整合模块(7)和报告输出模块(8)；其中：数字病理切片图像读取模块(1)用于读取数字病理切片图像；图像预处理模块(2)用于将读取数字病理切片图像进行预处理；人工智能算法模块(3)用于对预处理后的数字病理切片图像进行分析,将数字病理切片图像区分为正常肺组织图像和肺癌组织图像；初步意见生成模块(4)用于根据人工智能算法模块(3)的分析结果生成初步分析意见；初步意见判断模块(5)用于对初步分析意见进行判断,若为阴性,则由报告输出模块(8)输出最终的分析报告；若为阳性,则将对应的肺癌组织图像传输至图像识别模块(6)；图像识别模块(6)用于对肺癌组织图像进行识别并将对应的肺癌轮廓进行勾画,获取肺癌部分区域图像,由人工智能算法模块(3)预测肺癌免疫表现型；智能整合模块(7)用于对预测出的肺癌免疫表现型进行智能整合,自动进行肺癌亚型的免疫组化分类分析并生成分析报告,并勾画出癌症区域；报告输出模块(8)用于根据初步意见判断模块(5)或智能整合模块(7)的输出结果生成最终的分析报告。</td>   <td>G06T7/00;G06T7/12;G06T7/13;G06V10/774;G06V10/764;G06V10/82;G06K9/62;G16H10/60;G16H15/00;G16H30/20;G16H30/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱丽叶;                   吴臻       </td>   <td>中山大学</td>   <td>一种基于三维地球模型的栅格数据可视化方法及系统</td>   <td>广东省</td>   <td>CN114387418A</td>   <td>2022-04-22</td>   <td>本发明公开了一种基于三维地球模型的栅格数据可视化方法及系统,包括：接收用户上传的栅格数据文件,并对栅格数据文件进行数据处理,获得多个格点数据；根据多个格点数据,创建Canvas元素并对其各格点进行背景颜色填充,得到数据热图；基于创建的初始三维地球模型,结合数据热图和全球的矢量数据,创建含有国界线的纹理贴图,以得到对应的交互式三维地球模型；响应用户的操作,在交互式三维地球模型上显示对应的格点数据。本发明利用栅格数据文件对应的格点数据,创建Canvas元素并对其进行背景颜色填充,然后结合全球矢量数据,得到交互式三维地球模型的纹理贴图,并通过响应用户操作,显示对应的格点数据,实现栅格数据的可视化。</td>   <td>1.一种基于三维地球模型的栅格数据可视化方法,其特征在于,包括：接收用户上传的栅格数据文件,并对所述栅格数据文件进行数据处理,获得多个格点数据；根据所述多个格点数据,创建Canvas元素；其中,所述Canvas元素的分辨率根据对应的所述多个格点数据而确定,所述Canvas元素中设置有与所述格点数据数量相同的格点,且每个格点对应一个格点数据；根据预设的填充规则,对所述Canvas元素的各格点进行背景颜色填充,得到数据热图；基于创建的初始三维地球模型,结合所述数据热图和全球的矢量数据,创建含有国界线的纹理贴图,以得到对应的交互式三维地球模型；响应用户的操作,在所述交互式三维地球模型上显示所述操作对应的格点数据。</td>   <td>G06T17/20;G06T19/20;G06T7/40;G06F16/29</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              晏斌;              李凯祥;                   全小虎       </td>   <td>中山大学</td>   <td>一种基于Spark的个性化推荐方法及系统</td>   <td>广东省</td>   <td>CN108647996B</td>   <td>2022-04-19</td>   <td>本发明公开了一种基于Spark的个性化推荐方法及系统,其中,所述个性化推荐方法包括：获取用户对商品的行为信息并进行用预处理,获取用户对商品的隐式反馈；根据用户对商品的隐式反馈进行用户对商品的交互矩阵构建处理,获取用户对商品的交互矩阵；根据用户对商品的交互矩阵进行商品相似度矩阵计算处理,获取商品相似度矩阵；根据商品相似度矩阵进行商品邻近集构建处理,获取商品邻近集；根据商品邻近集进行用户对商品的偏好值预测处理,获取用户对商品的偏好值；根据用户对商品的偏好值向用户进行商品推荐,并将推荐结果进行展示。在本发明实施例中,融合多源信息,充分利用用户对商品的行为信息,缓解数据稀疏和冷启动问题。</td>   <td>1.一种基于Spark的个性化推荐方法,其特征在于,所述个性化推荐方法,包括：获取用户对商品的行为信息并进行用预处理,获取用户对商品的隐式反馈；根据用户对商品的隐式反馈进行用户对商品的交互矩阵构建处理,获取用户对商品的交互矩阵；根据用户对商品的交互矩阵进行商品相似度矩阵计算处理,获取商品相似度矩阵；根据商品相似度矩阵进行商品邻近集构建处理,获取商品邻近集；根据商品邻近集进行用户对商品的偏好值预测处理,获取用户对商品的偏好值；根据用户对商品的偏好值向用户进行商品推荐,并将推荐结果进行展示；所述根据用户对商品的交互矩阵进行商品相似度矩阵计算处理,包括：对用户对商品的交互矩阵进行逆用户频率进行相似度计算,获取第一相似矩阵；采用卷积神经网络对用户对商品的交互矩阵进行离线计算商品的相似度矩阵,获取第二相似矩阵；对第一相似矩阵和第二相似矩阵进行线性加权融合处理,获取商品相似度矩阵；所述对用户对商品的交互矩阵进行逆用户频率进行相似度计算,获取第一相似矩阵,包括：受启发于信息检索中利用逆文档频率修正单词频率,认为活跃用户对项目相似度贡献应小于不活跃用户,引入IUF对活跃用户进行计算,以用户评分总数定义用户活跃度,取其对数的倒数作为惩罚项,获得相似度计算方式如下：                  其中,表示表示矩阵R按列求和得到的向量；表示从评分矩阵提取的商品i特征向量；g表示内积运算；按照相似度计算方式所示定义simCal,利用Spark的map算子遍历计算RDD内每一个项目对相似度,得到每一条记录为以物品对为键,它们的相似度为值的弹性分布式数据集,存入数据仓库Hive中,记为sim-item。</td>   <td>G06Q30/02;G06Q30/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡志岗;              朱晓强;              邱宇民;              李子健;              王福娟;              李佼洋;              陈建宇;                   陈梓艺       </td>   <td>中山大学</td>   <td>一种新型OCT图像显示方法</td>   <td>广东省</td>   <td>CN108986084B</td>   <td>2022-04-19</td>   <td>本发明涉及一种新型OCT图像显示方法,包括有以下步骤：S1.将OCT设备所获得的原始数据进行傅里叶变换,转换成A-扫描三维图像并实时显示输出到信号瀑布图中；S2.将OCT设备所获得的原始数据进行傅里叶变换后与手动转动的角度θ结合转换成B-扫描二维图像并实时显示输出到扇形图中；S3.结合信号瀑布图和扇形图同时显示,让医护相关人员实现定点精准检测组织。</td>   <td>1.一种新型OCT图像显示方法,其特征在于：包括有以下步骤：S1.将OCT设备所获得的原始数据进行傅里叶变换,转换成A-扫描三维图像并实时显示输出到信号瀑布图中；S2.将OCT设备所获得的原始数据进行傅里叶变换后与手动转动的角度θ结合转换成B-扫描二维图像并实时显示输出到扇形图中；S3.结合信号瀑布图和扇形图同时显示,让医护相关人员实现定点精准检测组织；所述步骤S3将B-扫描二维图像进行归一化变换和坐标变换并以灰度值显示信号强弱,从而实时显示到扇形图中。</td>   <td>G06T11/20;G06T11/00;G16H30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         文译辉;              龙宇栋;              项毅帆;              雷文斌;              文卫平;              林浩添;                   肖钧       </td>   <td>中山大学附属第一医院;中山大学中山眼科中心</td>   <td>基于图像分割卷积神经网络的鼻咽癌定位分割方法和系统</td>   <td>广东省</td>   <td>CN114372951A</td>   <td>2022-04-19</td>   <td>本发明公开了一种基于图像分割卷积神经网络的鼻咽癌定位分割方法和系统,采用WLI模式和NBI模式获取电子鼻内镜图像,将鼻内镜图像输入基于图像分割卷积神经网络的鼻咽癌诊断模型,得到诊断模型标注的恶性肿瘤区域,只需要将镜头聚焦于鼻咽腔内的可疑病变组织,诊断系统即可实时对抓取的图像进行判断,并对鼻咽癌图像中恶性肿瘤部位进行标注,并导出诊断结果,直观地判断目标病变是否为恶性肿瘤组织,并据此确定恶性肿瘤病变的边界范围,快速选择可疑的病变部位进行活检,有效提高鼻内镜下鼻咽癌检测的准确度,提高活检的检出率。</td>   <td>1.一种基于图像分割卷积神经网络的鼻咽癌定位分割方法,其特征在于步骤是：先采用WLI模式和NBI模式获取鼻咽癌组和非鼻咽癌组的电子鼻内镜图像；再将鼻内镜图像输入基于图像分割卷积神经网络的鼻咽癌诊断模型,得到诊断模型标注的恶性肿瘤区域,以辅助临床内镜医师实时诊断鼻咽部肿物的病变性质以及病变范围。</td>   <td>G06T7/00;G06T7/11;G06T7/73;G06V10/764;G06V10/82;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢志;              张昀;              周昊;                   何尧       </td>   <td>中山大学中山眼科中心</td>   <td>适应多中心图像的糖尿病视网膜病变病灶分割方法及系统</td>   <td>广东省</td>   <td>CN114372985A</td>   <td>2022-04-19</td>   <td>本发明提出了适应多中心图像的糖尿病视网膜病变病灶分割方法,包括构建多中心数据集；根据多中心数据集对CycleGAN模型进行训练,生成对应的CycleGAN模型；利用训练好的CycleGAN模型建立不同目标中心DR病灶分割数据集对应的模拟数据集；构建DR病灶分割模型进行训练,得到一个适应于多个目标中心DR病灶分割数据集眼底彩照图像风格的DR病灶分割模型并对其检测评估,得到符合要求的DR病灶分割模型；将待预测的眼底彩照图像输入训练完毕的对应DR病灶分割模型中,输出最终的分割结果。本发明还提出了病灶分割系统,仅使用含有详细病灶标注的单中心数据集与不含任何标注的多中心数据集完成对DR病灶分割模型的训练,使其对目标中心的眼底彩照图像均具有良好的病灶分割功能。</td>   <td>1.适应多中心图像的糖尿病视网膜病变病灶分割方法,其特征在于,包括以下步骤：S1：从多个中心搜集眼底彩照图像,构建多中心数据集；多中心数据集包括源中心数据集和多个目标中心数据集；其中源中心数据集包括源中心DR病灶分割数据集和源中心眼底彩照数据集；目标中心数据集包括目标中心DR病灶分割数据集和目标中心眼底彩照数据集；S2：针对某一个目标中心,对源中心眼底彩照数据集和该目标中心眼底彩照数据集中的眼底彩照图像进行预处理,采用预处理后的眼底彩照图像对CycleGAN模型进行训练,生成该目标中心的CycleGAN模型；重复执行步骤S2,直至得到所有目标中心的CycleGAN模型；S3：利用训练好的CycleGAN模型对源中心DR病灶分割数据集中的眼底彩照图像进行处理,一个CycleGAN模型建立一个模拟目标中心图像风格模拟数据集；S4：对源中心DR病灶分割数据集和每个模拟数据集进行预处理；S5：构建DR病灶分割模型并利用预处理后的源中心DR病灶分割数据集和一个模拟数据集进行训练,得到适应于一个目标中心病灶分割数据集眼底彩照图像风格的DR病灶分割模型；重复执行步骤S5,直至得到适应于所有目标中心的多个DR病灶分割模型；S6：利用源中心DR病灶分割数据集分别测试所有DR病灶分割模型对源中心DR病灶分割数据集眼底彩照图像的病灶分割性能,同时利用目标中心DR病灶分割数据集评估对应该目标中心的DR病灶分割模型对该目标中心DR病灶分割数据集眼底彩照图像的DR病灶分割性能；若DR病灶分割模型源中心的DR病灶分割性能、目标中心的DR病灶分割性能均符合要求,则输出训练完毕的DR病灶分割模型,执行步骤S7；否则,返回执行步骤S5；S7：根据待预测的眼底彩照图像所属目标中心,将其输入训练完毕的对应目标中心的DR病灶分割模型中,输出最终的分割结果,完成对DR病灶的分割。</td>   <td>G06T7/10;G06T7/66;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康乐;                   潘嵘       </td>   <td>中山大学</td>   <td>一种基于无监督特征点检测的商品对齐方法</td>   <td>广东省</td>   <td>CN109191255B</td>   <td>2022-04-15</td>   <td>本发明涉及人工智能的技术领域,更具体地,涉及一种基于无监督特征点检测的商品对齐方法。一种基于无监督特征点检测的商品对齐方法,其中,包括以下步骤：S1.特征点检测训练数据准备；S2.检测框模型训练；S3.特征点检测；S4.根据特征点坐标进行仿射变换对齐。本发明经过特征点检测对齐之后用在商品后续的识别网络上,相较于没做对齐直接识别准确率会明显更高,因为网络对于正向的物体比倾斜的物体更容易识别；对于现有的有监督特征点对齐,这个方法能节省标注成本。</td>   <td>1.一种基于无监督特征点检测的商品对齐方法,其特征在于,包括以下步骤：S1.特征点检测训练数据准备；S2.检测框模型训练；S3.特征点检测；S31.特征点编码：特征点检测器,每一个特征点都有其对应的特征点检测器；Hourglass获得原始检测分数图得到R：R＝hourglass-l(I；θ-l)∈R-g～(W×H×( K+1))；S32.softmax归一化成概率：因为这个原始分数是无界的,用softmax归一化成概率,得到检测置信度图D,Dk就是D的第K个channel,是weight map,Dk(u,v)是第k个channel中坐标为(u,v)的值；                  S33.加权平均坐标作为第k个特征点的位置(Xk,Yk),这个公式可以实现梯度反传：可以实现从下游神经网络通过特征点坐标向后传播梯度；因为Dk在实际中很少出现完全集中在单个像素中,或者完全均匀分布这种情况；                  S4.根据特征点坐标进行仿射变换对齐。</td>   <td>G06Q30/06;G06F16/953</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              黄浩洸;                   陈崇雨       </td>   <td>中山大学</td>   <td>一种像素级物体分割方法及装置</td>   <td>广东省</td>   <td>CN109377499B</td>   <td>2022-04-15</td>   <td>本发明公开了一种像素级物体分割方法及装置,所述方法包括：步骤S1,对初始获得的深度图像和彩色图像进行预处理,获得粗糙的前景物体分割结果以及其所在的包围盒区域；步骤S2,对包围盒区域中的彩色图像和深度图像进行预设尺度下的下采样,得到金字塔分辨率下的多组图像；步骤S3,基于图像像素距离,结合不同分辨率下的深度图像和彩色图像,从低分辨率到高分辨率依次对物体分割结果进行联合双边滤波；步骤S4,将经联合双边滤波处理后得到的二值化物体分割结果与初始获得的深度图像和彩色图像进行融合处理,获得最终的像素级目标分割结果,本发明可在低资源损耗的同时实现输出图像中的前景物体的像素级别分割结果的目的。</td>   <td>1.一种像素级物体分割方法,包括如下步骤：步骤S1,对初始获得的深度图像和彩色图像进行预处理,获得粗糙的前景物体分割结果以及其所在的包围盒区域；步骤S2,对包围盒区域中的彩色图像和深度图像进行预设尺度下的下采样,得到金字塔分辨率下的多组图像；步骤S3,基于图像像素距离,结合不同分辨率下的深度图像和彩色图像,从低分辨率到高分辨率依次对物体分割结果进行联合双边滤波；步骤S4,将经联合双边滤波处理后得到的初始二值化物体分割结果与初始获得的深度图像和彩色图像进行融合处理,获得最终的像素级目标分割结果；于步骤S3中,每层分辨率图像的优化采用雅克比迭代；每次雅克比迭代采用如下优化公式：                  其中,M-0为迭代优化的初始二值化物体分割结果,λ-m为初始二值化物体分割结果的权重值,λ-c,λ-d分别为彩色图像和深度图像的权重值,t为当前迭代次数,Ω-i为第i个像素点所在的滤波窗口中的像素集合,j为Ω-i中的任意一个像素点；为对彩色信息I指导的联合双边滤波结果,为对深度信息D指导的联合双边滤波结果；对于彩色信息I指导的联合双边滤波,采用如下公式：                  其中,w-f等于联合双边滤波方形窗口边长,σ-c控制对强度信息变化的敏感程度；同样,对于深度信息D指导的联合双边滤波,采用如下公式：                  其中,w-f等于联合双边滤波方形窗口边长；控制对深度信息变化的敏感程度,为包围盒内深度信息的中位数,c为传感器内部固定参数。</td>   <td>G06T7/11;G06T7/194;G06T5/20;G06T5/40;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   蒋源毅       </td>   <td>中山大学</td>   <td>一种基于马尔科夫链的区块链性能分析方法及装置</td>   <td>广东省</td>   <td>CN112001571B</td>   <td>2022-04-15</td>   <td>本发明提供了一种基于马尔科夫链的区块链性能分析方法及装置,其中,方法包括：根据区块链系统的设计参数,基于马尔科夫链建立区块链系统的状态转移模型；对所述状态转移模型进行求解,得到所述区块链系统平稳状态下的稳态解；根据所述稳态解和计算性能指标的公式计算所述区块链系统的性能指标；根据所述性能指标对所述区块链系统进行性能分析与预测。本发明基于离散时间马尔可夫链理论,建立了区块链系统的性能分析和预测模型,不仅能对采集到的数据进行事后分析或实时监测,还可以根据模型和已知数据对区块链系统的性能进行预测；本发明将交易从到达和出块的过程设置为一个整体,模型简洁直观,且运算量较小。</td>   <td>1.一种基于马尔科夫链的区块链性能分析方法,其特征在于,包括：确定区块链系统的设计参数,基于离散时间马尔科夫链建立区块链系统的状态转移模型；其中,所述设计参数具体包括：系统等待队列的最大容纳交易数和单个区块的最大容纳交易数；所述状态转移模型具体为：基于离散时间马尔科夫链理论,将每秒拆分成多个离散过程,确定新交易到达等待队列引起状态转移的第一概率和等待队列中的交易被打包进区块引起状态转移的第二概率,建立区块链系统的状态转移模型；确定新交易到达等待队列引起状态转移的第一概率和等待队列中的交易被打包进区块引起状态转移的第二概率具体包括：设每秒拆分得到的离散过程数量为n,区块链系统产生一个区块的平均时间为x秒,平均每秒到达系统等待队列的交易数量为y笔,则所述第一概率为所述第二概率为其中,所述对所述状态转移模型进行求解,得到所述区块链系统平稳状态下的稳态解；根据所述稳态解和计算性能指标的公式计算所述区块链系统的性能指标；根据所述性能指标对所述区块链系统进行性能分析与预测。</td>   <td>G06Q10/04;G06F16/27;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              钟志杰;                   陈伟利       </td>   <td>中山大学</td>   <td>一种智能庞氏骗局检测方法、装置、终端及存储介质</td>   <td>广东省</td>   <td>CN112862493B</td>   <td>2022-04-15</td>   <td>本申请公开了一种智能庞氏骗局检测方法、装置、终端及存储介质,本申请通过将庞氏骗局合约的检测以及洗钱模式账户关系的检测结合起来,对两次检测结果进行迭代交叉检测,提升了检测准确度,使最终结果更加可靠,解决了目前的智能庞氏骗局检测技术检测的准确率不稳定的技术问题。</td>   <td>1.一种智能庞氏骗局检测方法,其特征在于,包括：S1、获取待检测的目标智能合约,并提取所述目标智能合约的合约特征,所述合约特征包括：字节码特征和创建者账户特征；S2、将所述合约特征作为智能庞氏骗局合约检测模型的输入变量,以通过所述智能庞氏骗局合约检测模型的运算,获得所述智能庞氏骗局合约检测模型输出的第一检测结果；其中,所述智能庞氏骗局合约检测模型的配置过程具体包括：基于获取到的合约特征样本,将所述合约特征样本输入到初始回归树分类模型,以通过对所述初始回归树分类模型进行模型训练,得到所述智能庞氏骗局合约检测模型；S3、根据获取到的区块链交易记录以及已知骗局账户,计算各个账户与所述已知骗局账户之间的关联程度值,并根据所述关联程度值、区块链交易记录以及已知骗局账户,结合非法交易分类模型,得到洗钱关系账户集,其中所述关联程度值为根据所述账户与所述已知骗局账户之间的距离值换算得到的；S4、将洗钱嫌疑账户的创建者账户特征与所述合约特征作为所述智能庞氏骗局合约检测模型的输入变量,以通过所述智能庞氏骗局合约检测模型的运算,获得所述智能庞氏骗局合约检测模型输出的第二检测结果,其中,所述洗钱嫌疑账户包括：所述洗钱关系账户集内的洗钱关系账户,和/或,与所述洗钱关系账户相邻的账户；S5、若所述第一检测结果与所述第二检测结果一致,则输出所述目标智能合约的智能庞氏骗局检测结果,若所述第一检测结果与所述第二检测结果不一致,则根据所述第二检测结果更新所述洗钱关系账户集,然后用当前的第二检测结果作为新的第一检测结果,然后返回步骤S4,以便根据更新后洗钱关系账户集获得新的第二检测结果。</td>   <td>G06Q20/40;G06F21/56</td>  </tr>        <tr>   <td>中国专利</td>   <td>         富明慧;                   林美鸿       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的桩损伤识别方法、设备及介质</td>   <td>广东省</td>   <td>CN114358091A</td>   <td>2022-04-15</td>   <td>本发明公开了一种基于卷积神经网络的桩损伤识别方法、设备及介质,其中方法包括:根据待检测桩的条件属性对待检测的桩结构建立多个模型,对模型进行求解生成待检测桩上预设位置点的速度时程曲线,基于速度时程曲线生成速度时程递归图并输入神经网络模型进行检测,输出桩损伤参数评估结果。根据待检测桩条件属性对待检测桩的桩结构进行建模,可以对待检测桩的整体状况有更为全面的分析了解。且神经网络模型,具有极强的非线性大规模参数并行分析处理能力,结合卷积神经网络处理速度时程递归图,能更好地处理桩土结构中复杂的损伤识别问题,提高桩损伤识别的准确性。</td>   <td>1.一种基于卷积神经网络的桩损伤识别方法,其特征在于,包括：根据待检测桩的条件属性对所述待检测的桩结构建立多个模型,以使所述多个模型输出所述待检测桩上预设位置点的速度时程曲线；基于所述速度时程曲线生成速度时程递归图；将所述速度时程递归图输入至预先设置的神经网络模型,以使所述神经网络模型对所述速度时程递归图进行检测,并输出所述待检测桩的损伤参数评估结果；其中,所述神经网络模型,是根据多个样本位置点的样本数据集,结合卷积神经网络训练得到的；所述样本数据集包括多个样本位置点的样本速度时程递归图以及所述样本位置点对应的样本损伤参数。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08;E02D33/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              谢一凡;                   毛明志       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的人体风格迁移方法、设备及介质</td>   <td>广东省</td>   <td>CN114359035A</td>   <td>2022-04-15</td>   <td>本发明涉及图像分析领域,具体公开了一种基于生成对抗网络的人体风格迁移方法、设备及介质,包括识别源域图像中迁移目标所在的区域,并将该区域输出为第一分割目标；识别参考图像中迁移目标所在的区域,并将该区域输出为第二分割目标；将所述第一分割目标映射到第一中介域上,得到第三分割目标；依据所述第二分割目标,对所述第三分割目标进行风格迁移,生成第一贴图；将所述第一贴图覆盖至所述第一分割目标在所述源域图像中的区域,并将覆盖后的源域图像作为生成图像输出。本发明通过分割出迁移目标,确保了风格迁移对象的准确性；通过设置中介域,克服了不同的源域图像可能分别服从多个不同分布的问题。</td>   <td>1.一种基于生成对抗网络的人体风格迁移方法,其特征在于,运用于人体部位的风格迁移,包括：识别源域图像中迁移目标所在的区域,并将该区域输出为第一分割目标；识别参考图像中迁移目标所在的区域,并将该区域输出为第二分割目标；将所述第一分割目标映射到第一中介域上,得到第三分割目标；依据所述第二分割目标,对所述第三分割目标进行风格迁移,生成第一贴图；将所述第一贴图覆盖至所述第一分割目标在所述源域图像中的区域,并将覆盖后的源域图像作为生成图像输出。</td>   <td>G06T3/00;G06V10/26;G06V10/46;G06V10/774;G06V10/82;G06V40/10;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              褚燕燕       </td>   <td>中山大学</td>   <td>基于向量机的AFM热漂移图像修正方法、系统、介质及设备</td>   <td>广东省</td>   <td>CN114359084A</td>   <td>2022-04-15</td>   <td>本发明公开了一种基于向量机的AFM热漂移图像修正方法、系统、介质及设备,该方法包括：采用Douglas-Peuker算法提取扫描图像中的特征点；建立样本图像数据库；基于p值估计建立偏移矢量模型；采用SVM算法建立图像校核向量机；采用Lucy-Richardson算法修正AFM热漂移图像。本发明能够完成扫描图像校核修正,推动AFM的表面形貌探测系统进行高温操作实验,提高AFM的表面形貌探测系统的纳米操作环境与效率。</td>   <td>1.一种基于向量机的AFM热漂移图像修正方法,其特征在于,包括以下步骤,S1、对材料标准样本进行表面特征图像采集,得到AFM的扫描图像,采用Douglas-Peuker算法,提取扫描图像中的特征点；S2、基于步骤S1提取的特征点,连续扫描样本,并选取参照图和形变图,得到扫描样本图像数据库；S3、基于步骤S2得到的扫描样本图像数据库,采用p值估计,建立AFM的表面形貌探测系统的偏移矢量模型；S4、基于步骤S3得到的偏移矢量模型,采用SVM算法建立AFM的表面形貌探测系统的图像校核向量机；S5、基于步骤S4得到图像校核向量机,采用Lucy-Richardson算法,依赖于参照图和形变图的相对位置关系修正AFM热漂移图像。</td>   <td>G06T5/00;G06T5/20;G06V10/74;G06V10/764;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              李浩鹏;              陈泽涛;              宋日辉;              曾培生;                   刘海雯       </td>   <td>中山大学;中山大学附属口腔医院</td>   <td>一种口腔CT影像的数据增强方法</td>   <td>广东省</td>   <td>CN114359090A</td>   <td>2022-04-15</td>   <td>本发明涉及医学图像处理技术领域,更具体地,涉及一种口腔CT影像的数据增强方法；包括：S1.基于生成对抗网络对数据进行增强：向生成对抗网络中输入原始口腔CT影像数据,通过生成对抗网络对原始口腔CT影像数据进行训练,得到一个口腔CT影像数据生成模型；S2.采用生成对抗网络空间的可解释控制发现算法获取特征控制向量：使用生成对抗网络空间算法对步骤S1得到的口腔CT影像数据生成模型潜空间在欧氏空间下进行主成分分析,无监督地识别潜在特征控制向量,并对潜在特征控制向量进行人工筛选保存；S3.采用特征控制向量定向生成口腔CT影像。本发明能够在原始数据量较少的情况下生成高分辨率的口腔CT影像,以辅助口腔CT影像实现大数据智能分析。</td>   <td>1.一种口腔CT影像的数据增强方法,其特征在于,包括以下步骤：S1.基于生成对抗网络对数据进行增强：向生成对抗网络中输入原始口腔CT影像数据,通过生成对抗网络对原始口腔CT影像数据进行训练,得到一个口腔CT影像数据生成模型；S2.采用生成对抗网络空间的可解释控制发现算法获取特征控制向量：使用生成对抗网络空间算法对步骤S1得到的口腔CT影像数据生成模型潜空间在欧氏空间下进行主成分分析,无监督地识别潜在特征控制向量,并对潜在特征控制向量进行人工筛选保存；S3.采用特征控制向量定向生成口腔CT影像。</td>   <td>G06T5/00;G06N3/08;G06N3/04;G06K9/62;G06V10/77;G06V10/774;G06V10/52;G06V10/25;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         毛凯;              杨猛;                   李鹏飞       </td>   <td>中山大学</td>   <td>基于语义GAN的跨域图像风格迁移方法</td>   <td>广东省</td>   <td>CN114359526A</td>   <td>2022-04-15</td>   <td>本发明针对现有技术的局限性,提出了一种基于语义GAN的跨域图像风格迁移方法,该方法针对当前跨域图像风格迁移方法需要大量训练数据,且经常出现语义不匹配的问题,提出并应用了一种新型的基于语义生成对抗网络的跨域图像风格迁移的模型——语义GAN；该模型框架充分利用GAN的强大功能,通过结合预训练语义分割网络,生成语义分割图引入到生成器以及判别器中,有效地探索了语义信息的引导作用,解决了现有技术中语义不匹配的问题；使得该方案在训练阶段、测试阶段和实际使用时都能利用到图像的语义信息,进而更好地完成图像风格迁移任务。</td>   <td>1.一种基于语义GAN的跨域图像风格迁移方法,其特征在于,包括以下步骤：S1,获取待处理图像以及所述待处理图像的风格迁移任务；S2,将所述待处理图像输入到基于语义GAN的模型框架训练得到的跨域图像风格迁移模型,所述跨域图像风格迁移模型根据所述风格迁移任务生成所述待处理图像的跨域图像风格迁移结果；其中：所述语义GAN的模型框架中包括预训练语义分割网络S、编码器E-y、骨干网络N以及判别器D；所述骨干网络N包括编码器E-x、残差块ResBlocks以及生成器G；所述残差块ResBlocks分别连接所述预训练语义分割网络S、编码器E-y、编码器E-x以及生成器G；所述生成器G连接所述判别器D；在训练过程中：所述预训练语义分割网络S用于提取输入的风格图像的语义概率图；所述编码器E-y用于对输入的风格图像进行特征提取以及下采样操作；所述编码器E-x用于对输入的内容图像进行特征提取以及下采样操作；所述残差块ResBlocks用于根据输入的风格图像的语义概率图、特征以及输入的内容图像的特征,进行进一步的图像特征提取；所述生成器G用于根据所述残差块ResBlocks的特征提取结果,获得输入的内容图像的生成图像；所述判别器D用于对所述生成图像进行判别,计算风格特征损失。</td>   <td>G06T19/20;G06N3/04;G06N3/08;G06V10/26;G06V10/50;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         瞿毅力;              苏琬棋;              邓楚富;              王莹;              卢宇彤;                   陈志广       </td>   <td>中山大学</td>   <td>基于模块化GAN的多模态MRI与多模态CT的转换方法、系统及介质</td>   <td>广东省</td>   <td>CN110689561B</td>   <td>2022-04-12</td>   <td>本发明公开了一种基于模块化GAN的多模态MRI与多模态CT的转换方法、系统及介质,本发明转换方法包括根据所需执行的任务类型,选择GAN网络中训练好的模块来进行CT图-CT图模态转换、CT图-MRI图模态转换、MRI图-MRI图模态转换、MRI图-CT图模态转换、CT图-MRI病灶任务转换、MRI图-CT病灶任务。本发明考虑到MRI和CT内部子模态十分相似但MRI与CT两个模态又有巨大差异的情况,提出了一种采用模块化的条件GAN的转换方法,本发明可采用无监督学习方法,训练数据无需配准,在无需训练多个GAN的情况下能便利高校的实现单模态转换生成配准的多模态MRI和CT图。</td>   <td>1.一种基于模块化GAN的多模态MRI与多模态CT的转换方法,其特征在于实施步骤包括：1)判断需要执行的任务类型,若该任务为CT图-CT图模态转换则跳转执行步骤2),为CT图-MRI图模态转换则跳转执行步骤3),为MRI图-MRI图模态转换则跳转执行步骤4),为MRI图-CT图模态转换则跳转执行步骤5),为CT图-MRI病灶任务转换则跳转执行步骤6),为MRI图-CT病灶任务转换则跳转执行步骤7)；2)将完成训练后的GAN网络中的CT模态编码器与CT模态解码器组合可以得到一个CT内部多模态转换器,通过CT内部多模态转换器将输入的任意模态的CT图转换生成目标模态的CT图；退出；3)将完成训练后的GAN网络中的CT模态编码器与MRI模态解码器组合可以得到一个CT-MRI多模态转换器,通过CT-MRI多模态转换器将输入的任意模态的CT图转换生成目标模态的MRI图；退出；4)将完成训练后的GAN网络中的MRI模态编码器与MRI模态解码器组合可以得到一个MRI内部多模态转换器,通过MRI内部多模态转换器将输入的任意模态的MRI图转换生成目标模态的MRI图；退出；5)将完成训练后的GAN网络中的MRI模态编码器与CT模态解码器组合可以得到一个MRI-CT多模态转换器,通过MRI-CT多模态转换器将输入的任意模态的MRI图转换生成目标模态的CT图；退出；6)将完成训练后的GAN网络中的CT模态编码器与MRI病灶任务解码器组合即可得到一个MRI病灶任务处理器,通过MRI病灶任务处理器将输入的任意模态的CT图转换生成MRI病灶任务；退出；7)将完成训练后的GAN网络中的MRI模态编码器与CT病灶任务解码器组合即可得到一个CT病灶任务处理器,通过CT病灶任务处理器将输入的任意模态的MRI图转换生成CT病灶任务；步骤1)之前还包括训练GAN网络的步骤,详细步骤包括：S1)设计GAN网络的各个部件,所述GAN网络的各个部件包括一个MRI模态编码器、一个CT模态编码器、一个MRI模态解码器、一个CT模态解码器、一个MRI病灶任务解码器、一个CT病灶任务解码器、一个模态鉴别器和一个特征鉴别器；S2)获取具有对应病灶处理任务的配准的病灶标签label-(x)的CT多模态训练数据、具有对应病灶处理任务的配准的病灶标签label-(y)的MRI多模态训练数据作为训练数据,所述训练数据各个模态和子模态均无需配准；S3)将MRI模态编码器与CT病灶任务解码器组合即可得到CT病灶任务处理器,基于具有对应病灶处理任务的配准的病灶标签label-(x)的CT多模态训练数据进行CT病灶任务处理器的病灶任务处理训练；将CT模态编码器与MRI病灶任务解码器组合即可得到MRI病灶任务处理器,基于具有对应病灶处理任务的配准的病灶标签label-(y)的MRI多模态训练数据进行MRI病灶任务处理器的病灶任务处理训练；将CT模态编码器、CT模态解码器构成CT内部多模态转换器并基于训练数据进行CT转CT的训练,将CT模态编码器、MRI模态解码器构成CT-MRI多模态转换器并基于训练数据进行CT转MRI的训练,将MRI模态编码器、MRI模态解码器构成MRI内部多模态转换器并基于训练数据进行MRI转MRI的训练,将MRI模态编码器、CT模态解码器构成MRI-CT多模态转换器并基于训练数据进行MRI转CT的训练；S4)分别将CT多模态训练数据中病灶标签label-(x)和进行CT转CT的训练得到的病灶标签label-(x)、CT转MRI的训练得到的病灶标签label-(x)、CT病灶任务处理训练得到的病灶标签label-(x)进行对比,分别将MRI多模态训练数据中病灶标签label-(y)和进行MRI转MRI的训练得到的病灶标签label-(y)、MRI转CT的训练得到的病灶标签label-(y)、MRI病灶任务处理训练得到的病灶标签label-(y)进行对比；如果任意训练的对比结果不能达到要求则跳转执行步骤S3)继续进行训练,否则结束并退出。</td>   <td>G06T7/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘康怀;                   陈林       </td>   <td>中山大学</td>   <td>一种基于平衡碰撞二叉树的大型RFID系统丢失标签识别方法</td>   <td>广东省</td>   <td>CN114330393A</td>   <td>2022-04-12</td>   <td>本发明针对现有技术的局限性,提出了一种基于平衡碰撞二叉树的大型RFID系统丢失标签识别方法,在本领域首次提出并使用了平衡碰撞二叉树的数据结构,通过对目标RFID系统构建一颗各个叶子结点高度较为均衡的二进制查询树,相较于传统碰撞树显著地降低了高度,并进一步极大地减少了读写器广播信息的时间开销；通过对曼彻斯特编码原理和CPT树结构进行结合,彻底避免了空时隙的使用,且可仅用一比特信息从一个时隙中同步检验两个标签是否丢失,从而极大地提高了帧和时隙的利用率。在确保相同识别准确率的前提下,相比现有技术,本发明在渐进开销上最大降低了一个近为log N的倍数因子,在各类参数环境下展现出较大的性能提升,兼具良好的鲁棒性和拓展性。</td>   <td>1.一种基于平衡碰撞二叉树的大型RFID系统丢失标签识别方法,其特征在于,包括以下步骤：S1,为目标RFID系统中的各标签分别构建伪ID；S2,根据所述伪ID,构建出所述目标RFID系统的平衡碰撞二叉树；其中,所述平衡碰撞二叉树由根节点、根节点以上出度为0的叶子结点以及出度为2的内部结点构成；所述叶子结点用于执行帧中的一个单例时隙或者是一个包含两个标签的碰撞时隙；所述内部结点仅用于存储数据,不执行标签响应和识别操作；S3,基于曼彻斯特编码原理以及RFID阅读器与标签之间的先听再对话机制,从所述根结点开始,逐层递进出发到更高一层,对所述平衡碰撞二叉树中的叶子节点进行遍历,识别出所述目标RFID系统中的丢失标签。</td>   <td>G06K7/10;G06N5/00;G06K17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余超;                   黄荣恒       </td>   <td>中山大学</td>   <td>一种脓毒症治疗策略的学习方法及装置</td>   <td>广东省</td>   <td>CN114330566A</td>   <td>2022-04-12</td>   <td>本发明公开了一种脓毒症治疗策略的学习方法及装置,该方法包括：基于样本数据建立关于脓毒症治疗策略的马尔科夫决策模型；样本数据为脓毒症患者在预设时间内的病理数据；根据马尔科夫决策模型,建立脓毒症的死亡率预测模型,并获取脓毒症患者各个特征的死亡率权重；利用死亡率权重对样本数据进行标记,生成目标样本；预测脓毒症治疗策略,利用深度强化学习方法来学习治疗策略。本发明通过患者样本优先级权重进行标记,使得深度强度学习的样本质量更高,提高了模型的训练效果,避免在大量次优样本中快速陷入局部最优的问题；通过采用改进的深度强度学习算法学习治疗策略,并为AI治疗策略的动作选择增加现实限制,使得推荐的治疗策略更优。</td>   <td>1.一种脓毒症治疗策略的学习方法,其特征在于,包括：基于样本数据建立关于脓毒症治疗策略的马尔科夫决策模型；所述样本数据为脓毒症患者在预设时间内的病理数据；根据所述马尔科夫决策模型,建立脓毒症的死亡率预测模型,并获取脓毒症患者各个特征的死亡率权重；利用所述死亡率权重对样本数据进行标记,生成目标样本；预测脓毒症治疗策略,利用深度强化学习方法来学习治疗策略。</td>   <td>G06K9/62;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         由林麟;              章圣律;              刘晟;                   郭子晗       </td>   <td>中山大学</td>   <td>一种基于众包方式和激励机制的联邦学习系统</td>   <td>广东省</td>   <td>CN114330742A</td>   <td>2022-04-12</td>   <td>本发明公开了一种基于众包方式和激励机制的联邦学习系统,包括：基础数据层,用于存储联邦学习系统的数据；业务响应层,用于响应于系统用户的任务请求,根据任务请求采用众包方式进行所述联邦学习系统的任务管理,系统用户包括任务发布者和任务参与者；辅助训练层,用于根据激励机制辅助联邦学习系统的联邦学习全局模型训练,激励机制包括任务分配机制、声誉机制和奖励机制；用户交互层,用于支撑系统用户与联邦学习系统的交互,实现用户操作与数据结果的可视化。本发明能够对参与者、任务以及训练策略进行统一管理,并通过设计的激励机制鼓励数据拥有者持续参与联邦学习任务,可广泛应用于联邦学习技术领域。</td>   <td>1.一种基于众包方式和激励机制的联邦学习系统,其特征在于,包括：基础数据层,用于存储联邦学习系统的数据；业务响应层,用于响应于系统用户的任务请求,根据所述任务请求采用众包方式进行所述联邦学习系统的任务管理,所述系统用户包括任务发布者和任务参与者；辅助训练层,用于根据激励机制辅助所述联邦学习系统的联邦学习全局模型训练,所述激励机制包括任务分配机制、声誉机制和奖励机制；用户交互层,用于支撑所述系统用户与所述联邦学习系统的交互,实现用户操作与数据结果的可视化。</td>   <td>G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         贺智;              肖曼;              李心媛;                   楼桉君       </td>   <td>中山大学</td>   <td>一种基于SAR图像的任意方向舰船检测方法及系统</td>   <td>广东省</td>   <td>CN114332218A</td>   <td>2022-04-12</td>   <td>本发明公开了一种基于SAR图像的任意方向舰船检测方法及系统,该方法包括：获取原始SAR图像并输入至预训练的斑点噪声去除子网络进行去噪,得到干净SAR图像；将原始SAR图像和干净SAR图像输入至预训练的舰船方向检测子网络进行特征提取和特征融合,得到中心点置信分数、宽高、角度和中心点偏置；基于中心点置信分数进行筛选并根据宽高、角度和中心点偏置解码计算检测框角坐标。该系统包括：去噪模块、检测模块和解码计算模块。通过使用本发明,能够实现舰船的任意方向检测且具有较高的检测监测精度。本发明作为一种历基于SAR图像的任意方向舰船检测方法及系统,可广泛应用于舰船检测领域。</td>   <td>1.一种基于SAR图像的任意方向舰船检测方法,其特征在于,包括以下步骤：获取原始SAR图像并输入至预训练的斑点噪声去除子网络进行去噪,得到干净SAR图像；将原始SAR图像和干净SAR图像输入至预训练的舰船方向检测子网络进行特征提取和特征融合,得到中心点置信分数、宽高、角度和中心点偏置；基于中心点置信分数进行筛选并根据宽高、角度和中心点偏置解码计算检测框角坐标。</td>   <td>G06T7/73;G06T5/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         欧阳进武;              周翠英;                   刘镇       </td>   <td>中山大学</td>   <td>一种三维地质体概率模型建模方法</td>   <td>广东省</td>   <td>CN114332391A</td>   <td>2022-04-12</td>   <td>本发明公开了一种三维地质体概率模型建模方法,其特征是：搜集真实地质钻孔地层信息,对钻孔高程范围做区间划分；获取钻孔的地层序列状态序列,得到真实钻孔的地层变化规律；建立地层厚度的概率模型,通过随机模拟生成虚拟钻孔；建立三维地质体的总体概率模型；根据验证钻孔确定地层分界点和地层剖面线概率；根据最可能地层剖面线获取虚拟钻孔,生成三维地质体最大概率模型。本发明基于概率分析和随机模拟的方法构建的三维地质体概率模型,兼顾了建模过程中地层剖面线确定的随机性和多种可能性,能提高三维地质建模的准确性,可信度高。</td>   <td>1.一种三维地质体概率模型建模方法,包括以下步骤：(1)搜集研究区域真实地质钻孔信息,对钻孔高程做区间划分,获取钻孔的地层状态序列；(2)根据马尔科夫链原理,求解真实钻孔的概率转移矩阵,分析真实钻孔的地层变化规律；(3)建立地层概率模型,求解虚拟钻孔的概率转移矩阵,分析虚拟钻孔位置的地层变化规律；(4)随机模拟获取虚拟钻孔的地层状态；(5)根据随机模拟的虚拟钻孔地层状态结果,建立总体概率模型；(6)根据验证钻孔分析确定地层分界点概率和地层剖面线概率,得到符合实际的最大概率模型。</td>   <td>G06T17/05;G06N7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈川;              张梓旸;                   郑子彬       </td>   <td>中山大学</td>   <td>一种图节点表征信息融合处理方法、装置、终端及介质</td>   <td>广东省</td>   <td>CN114298239A</td>   <td>2022-04-08</td>   <td>本申请公开了一种图节点表征信息融合处理方法、装置、终端及介质,本申请结合结构相似性和特征相似性来生成对应的语义子图,先根据本发明中的结构相似性寻找和目标节点满足此相似性的其他节点,再通过特征相似性找到相似的节点作为其非局部邻居,并构造非局部图,同时考虑到局部信息和非局部信息的提取利用,同时在各个非局部图非局部表征信息和原始图中的局部表征信息,并通过注意力机制将二者的表征融合得到最终的表征信息,增加了模型的表达能力,从而解决现有技术仅仅停留在捕获图局部范围的信息,忽略了对非局部或具有远程依赖性的信息的提取,导致图表示学习能力受限制的技术问题。</td>   <td>1.一种图节点表征信息融合处理方法,其特征在于,包括：基于获取到的原始网络图,结合所述原始网络图的图结构拓扑关系,确定所述原始图数据中各个节点的位置感知角色属性,其中,所述节点的位置感知角色属性为用于指示在所述节点与邻近节点构成的导出子图中,所述节点的结构关系属性；根据所述节点的位置感知角色属性,对所述原始网络图中的各个节点进行分类,得到多个角色属性节点集合；基于目标节点以及所述目标节点所属的目标角色属性节点集合,通过预设的特征相似度计算方法,计算所述目标节点与相似节点间的节点特征相似度,其中,所述相似节点具体为所述目标角色属性节点集合中,除所述目标节点外的其余节点；根据所述节点特征相似度,确定所述目标节点的非局部邻居节点,再根据所述目标节点与所述非局部邻居节点,构建非局部网络图；根据所述目标节点以及所述非局部网络图,结合第一节点表示生成公式,得到所述目标节点的非局部表征信息,其中,所述第一节点表示生成公式具体包括：节点非局部表征信息计算公式以及注意力加权融合计算公式；根据所述目标节点以及所述原始网络图,结合第二节点表示生成公式,得到所述目标节点的局部表征信息,其中,所述第二节点表示生成公式具体包括：节点局部表征信息计算公式以及注意力加权融合计算公式；根据所述非局部表征信息与所述局部表征信息,通过注意力系数加权求和计算,得到所述目标节点的最终表征信息。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈鹏飞;              王雯麓;                   郑子彬       </td>   <td>中山大学</td>   <td>一种针对多元时间序列的主动异常检测方法及其相关装置</td>   <td>广东省</td>   <td>CN114298240A</td>   <td>2022-04-08</td>   <td>本申请公开了一种针对多元时间序列的主动异常检测方法及其相关装置,通过KPI数据无监督训练异常检测模型,得到无监督异常检测模型；当获取到新的KPI数据时,通过滑动窗口对新的KPI数据进行处理,得到多个时间序列样本,通过无监督异常检测模型对各时间序列样本进行异常检测,得到各时间序列样本在对应的时间观测点的异常分数；根据各时间序列样本的异常分数选择若干时间序列样本进行标签标注,得到若干有标签的时间序列样本；通过各时间序列样本的标签信息反馈训练无监督异常检测模型,得到最终异常检测模型；通过最终异常检测模型对待检测KPI数据进行异常检测,改善了现有的无监督异常检测模型存在的误报率和漏检率较高的技术问题。</td>   <td>1.一种针对多元时间序列的主动异常检测方法,其特征在于,包括：获取云原生系统的KPI数据,并通过所述KPI数据无监督训练异常检测模型,得到无监督异常检测模型；当获取到新的KPI数据时,通过滑动窗口对所述新的KPI数据进行处理,得到多个时间序列样本,并通过所述无监督异常检测模型对各所述时间序列样本进行异常检测,得到各所述时间序列样本在对应的时间观测点的异常分数；根据各所述时间序列样本的异常分数选择若干时间序列样本进行标签标注,得到若干有标签的时间序列样本；通过各时间序列样本的标签信息反馈训练所述无监督异常检测模型,得到最终异常检测模型；通过所述最终异常检测模型对待检测KPI数据进行异常检测。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余超;                   刘岳鑫       </td>   <td>中山大学</td>   <td>一种智能体群体交互的决策控制方法、装置及系统</td>   <td>广东省</td>   <td>CN114298244A</td>   <td>2022-04-08</td>   <td>本发明公开了一种智能体群体交互的决策控制方法、装置及系统。该决策控制装置包括初始交互单元、模型训练单元以及决策控制单元。该决策控制系统还包括决策控制模块以及数据存储模块。通过构建包括顶层学习模型和底层学习模型的初始决策控制模型,并对该初始决策控制模型进行顶层和底层融合训练,从而获得最终决策控制模型进而进行决策控制,该决策控制方法、装置及系统提升了智能体群体交互时的决策控制的有效性。</td>   <td>1.一种智能体群体交互的决策控制方法,其特征在于,所述决策控制方法包括：获取预设的初始决策控制模型,使智能体群体根据所述初始决策控制模型进行群体交互,从而获取初始决策控制数据组；所述初始决策控制模型包括顶层学习模型以及底层学习模型；利用所述初始决策控制数据组,训练所述顶层学习模型和所述底层学习模型,从而获得最终决策控制模型；根据所述最终决策控制模型,对所述智能体的群体交互进行决策控制。</td>   <td>G06K9/62;G06N3/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;              李效良;                   李亚龙       </td>   <td>中山大学</td>   <td>基于微外观模型的织物真实感外观渲染系统及方法</td>   <td>广东省</td>   <td>CN108694739B</td>   <td>2022-04-05</td>   <td>本发明提供了一种基于微外观模型的织物真实感外观渲染系统及方法,其中系统包括织物模型构建模块、织物模型合成模块、体纹理映射模块以及渲染模块,通过结合纤维级别的织物样本体素模型和织物照片,系统自动构建出可渲染的织物体外观模型。同时,本系统采用基于物理的渲染方法,对织物进行渲染,可生成出高真实感的织物图片。在织物三维数据合成阶段,本专利书提出了一种基于图像缝合的织物三维模型的合成方法。该方法通过缝合样本织物表面图片中多个不规则像素块对应的立体数据,来合成出织物的三维数据,进而增加渲染结果的真实性。</td>   <td>1.一种基于微外观模型的织物真实感外观渲染系统,其特征在于包括：织物样本体素模型生成模块,通过微观CT,核磁共振或超声波扫描得到的织物样本体素模型,或通过过程式方法生成织物样本体素模型；织物模型构建模块,负责根据织物样本,经过体素处理算法计算纤维方向信息以及去噪,然后结合实际采集的织物照片,利用外观匹配算法估计出外观模型的光学参数,最终重建出织物样本的三维模型；织物模型合成模块,负责把织物样本的三维模型合成为大的织物的三维模型,其中,织物模型合成模块包括样本一致合成子模块和编织设计合成子模块,样本一致合成子模块,采用基于图像缝合的织物密度立体合成方法,合成出与样本花样一致的织物模型,编织设计子模块采用基于样例的合成方法,通过利用预先处理好的有限编织织物样本数据库,支持按照设计合成多种编织织物；体纹理映射模块,通过输入织物的微观体素模型和外观模型,基于物理的渲染,可得到被扫描的织物样本图片,渲染出的织物样本图片和织物样本体素模型有着对应关系,接着通过图像缝合的方法,可把该织物样本图片合成为不同大小的织物图片,因此,可通过上述的对应关系,反向合成不同大小的织物三维体素模型,合成阶段得到的体素数据是一块平整的织物,通过采用体纹理映射方法壳映射将合成后的织物体素三维数据映射到任意网格曲面上,以渲染出各种形式的织物；渲染模块,负责把整个大织物三维模型渲染出来。</td>   <td>G06T15/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              刘付康;              朱雄泳;              陈荣军;              谢舜道;                   吴炆芳       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>一种细节增强与亮度自适应的高动态范围图像的色调映射方法</td>   <td>广东省</td>   <td>CN109410126B</td>   <td>2022-04-05</td>   <td>本发明公开了一种细节增强与亮度自适应的高动态范围图像色调映射方法。本发明对输入HDR图像亮度灰度图进行全局细节增强,计算HDR图像亮度灰度图细节增强后的对数,利用对数转换初步压缩原始场景中的亮度；再对其进行亮度直方图统计,并且计算其平均值与标准差,对直方图进行分段裁剪与补偿；再由亮度与标准差估算模型计算映射后中间低动态范围图像的平均亮度与标准差,从而求解HDR图像到中间LDR图像的亮度直方图全局映射曲线,其中由最大熵亮度估算方法自适应选出最优输出中间LDR图像亮度；接着,对中间LDR图像亮度过暗或过亮区域进行局部细节增强映射得到输出LDR图像亮度；最后将HDR图像色彩映射到输出LDR图像色彩,合并色彩空间获得输出LDR图像。本发明能将HDR图像映射到LDR图像,输出的LDR图像亮度自适应,细节增强,主观效果和谐。</td>   <td>1.一种细节增强与亮度自适应的高动态范围图像的色调映射方法,其特征在于包括有如下步骤：1)对输入高动态范围图像亮度灰度图进行全局细节增强,计算高动态范围图像亮度灰度图细节增强后的对数,利用对数转换初步压缩原始场景中的亮度；2)对全局细节增强的高动态范围图像亮度对数进行直方图统计,计算其平均值与标准差,对直方图进行分段裁剪与补偿；3)由亮度与标准差估算模型计算映射到中间低动态范围图像的平均亮度与标准差,从而求解高动态范围图像到中间低动态范围图像的亮度直方图全局映射曲线,其中由最大熵亮度估算方法自适应选出最优中间低动态范围图像亮度；4)对中间低动态范围图像亮度灰度图过暗或过亮区域进行局部细节增强映射得到输出低动态范围图像亮度；5)将高动态范围图像色彩通道映射到对应输出低动态范围图像色彩通道,合并色彩空间获得输出低动态范围图像；所述步骤1)包括：11)定义输入高动态范围图像红绿蓝三个色彩通道的数据分别为R,G,B,定义高动态范围图像亮度L-w：L-w＝0.299R+0.587G+0.114B                   (1)12)定义输入高动态范围图像大尺度纹理层为b：                  其中,I为单位矩阵；α是平衡因子,选取25～35之间；Q-x,Q-y是前向差分算子,是后向差分算子；A-x和A-y是分别包含平滑权重a-x(L-w)和a-y(L-w)的对角矩阵,平滑权重a-x(L-w)和a-y(L-w)分别定义如下：                                    其中,ε-1取0.0002；β是决定ln(L-w)梯度灵敏度的参数,选取5～5.5之间；13)计算输入高动态范围图像亮度的对数L-e：L-e＝ln(L-w)                               (5)14)定义高动态范围图像亮度细节层对数d：d＝L-e-ln(b)                             (6)15)定义高动态范围图像全局增强亮度的对数L′-e：L′-e＝λ-1ln(b)+λ-2d                          (7)其中,λ-1是修正因子,取0.94～0.98之间,λ-2是增强因子,定义为：                  其中,μ-(HDR)为输入高动态范围图像平均亮度；C为输入高动态范围图像对比度,μ-(HDR)和C分别定义如下：                                    其中,M和N是输入高动态范围图像的长和宽；L-w(i,j)表示位置为(i,j)像素点的亮度值,δ(τ,υ)＝|τ-υ|即是相邻像素间的亮度τ和亮度υ的差值绝对值,P-δ(i,j)即相邻像素间的亮度灰度差为δ的像素分布概率；像素相邻取四近邻。</td>   <td>G06T5/00;G06T5/40;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢佳锋;              胡建芳;              钟逸;              朱海昇;                   郑伟诗       </td>   <td>中山大学</td>   <td>基于迁移学习提升语义分割模型效果的框架</td>   <td>广东省</td>   <td>CN109087303B</td>   <td>2022-04-01</td>   <td>本发明公开了一种基于迁移学习提升语义分割模型效果的框架,包括下述内容：1)将迁移学习引入到语义分割领域,使得快速语义分割网络可以通过教师模型提升学生模型分割效果；2)提出一致性映射度量教师和学生模型的轮廓和纹路信息,并通过构造一致性损失函数来使得快速语义分割在细节处分割得更好；3)利用老师模型和条件随机场(CRF)模型为无标签数据生成辅助标签,并把数据加入到训练集,提升模型的泛化能力和分割效果。本发明在不引入额外模型参数,降低模型速度的情况下,提升了快速语义分割模型的准确率。</td>   <td>1.基于迁移学习提升语义分割模型效果的框架,其特征在于,包括下述步骤：构建一个新的语义分割模型基础框架,所述语义分割模型基础框架由两个不同的网络组成,分别为老师网络和学生网络,所述老师网络为学生网路提供有益于分割的知识指导,使得学生网路能学到老师网络的知识来帮助其拥有更好的分割效果,所述学生网络用于在保证其分割的速度的同时从老师网络提供的知识中学习到有益于其分割效果的知识；通过目标函数将老师网络和学生网络连接起来,所述目标函数是由基于逻辑分布变换出来的信息形式构造的,该目标函数的具体内容如下：用S和T来分别表示公式中的学生网络和老师网络：L＝L-s+r(S,T)上述公式中,L-s是交叉熵损失函数,其实际是由图片的标签与学生网络的概率分布之间求交叉熵得到的损失函数；r(S,T)代表的是老师网络与学生网络之间的知识偏差,其作为一个正则化项来正则化学生网络的学习过程,通过r(S,T)这一项,学生网络和老师网络被连接起来,并且通过最小化L目标函数可以把老师网络的知识传递到学生网络；把r(S,T)函数定义为：r(S,T)＝αL-p(S,T)+βL-c(S,T)L-p(S,T)是老师网络与学生网络之间的概率分布损失函数,定义为                  函数中的I表示batch size的数量,G表示图片的像素集合,P-S(x),P-T(x)分别是学生和老师网络在图片区域每个像素点的概率分布输出,这个损失函数的定义是学生网络的输出概率分布跟老师网络的概率分布是相似的,这个函数可以捕捉到不同分割输出的零阶知识；为了补充L-P损失函数捕捉到的零阶知识,L-C函数被用于捕捉学生网络和老师网络输出的一阶知识,定义L-C函数为：                  其中函数中的I表示batch size的数量,G表示图片的像素集合,一致性矩阵C(x)定义为B(x)意味着像素x的8个临近的像素,I(x)是对应网络像素点的逻辑分布输出；利用网络结构中的老师网络对无标签数据进行标签预测生成伪标签,并把生成标签数据加入模型的训练集中,再通过框架训练提升学生网络的分割效果。</td>   <td>G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈鹏飞;              陈楠栖;                   郑子彬       </td>   <td>中山大学</td>   <td>时间序列因果关系图的构建方法</td>   <td>广东省</td>   <td>CN114266322A</td>   <td>2022-04-01</td>   <td>本申请公开一种时间序列因果关系图的构建方法,基于若干条时间序列,计算每条时间序列的第一时间滞后值和每两条时间序列之间的第二时间滞后值。确定每条时间序列的直接滞后因变量和初始连接图。利用条件独立性准则判断初始连接图中每两个相互连接的节点所对应的时间序列之间是否存在因果关系,由此得到中间连接图。然后确定中间连接图中的具有因果滞后关系的时间序列之间的无向边的方向后,再次利用条件独立性准则检查每两条当前时刻的时间序列之间的无向边是否真实存在,得到最终的时间序列因果关系图。该方案通过第一时间滞后值对每两条时间序列进行拟合得到残差序列,并利用残差序列去计算第二时间滞后值,可以提高对因果关系判断的准确度。</td>   <td>1.一种时间序列因果关系图的构建方法,其特征在于,包括：获取时间序列数据集,所述时间序列数据集中包含若干条时间序列；计算每条所述时间序列的第一时间滞后值和每两条所述时间序列之间的第二时间滞后值,其中,所述第一时间滞后值为所述时间序列由于自相关性导致的自身与自身之间的时间滞后值,所述第二时间滞后值为每两条所述时间序列之间因果关系的时间滞后值；根据所述第一时间滞后值和第二时间滞后值确定每条时间序列的直接滞后因变量,基于各时间序列的直接滞后因变量,确定所述时间序列数据集的初始连接图；其中,所述初始连接图包含节点和无向边,一个节点代表所述时间序列数据集中的一条时间序列,每条时间序列的直接滞后因变量所对应的节点与时间序列所对应的节点通过一条无向边连接,当前时刻的每两条所述时间序列所对应的节点通过一条无向边连接；利用第一条件集按照条件独立性准则判断所述初始连接图中的每两个相互连接的节点所对应的时间序列之间是否存在因果关系,若是,则保留节点之间的无向边,若否,则删去节点之间的无向边,得到中间连接图；根据各条时间序列的直接滞后因变量确定所述中间连接图中,时间序列的直接滞后因变量所对应的节点与时间序列所对应的节点之间的无向边的方向,得到有向边；利用第二条件集按照条件独立性准则检查每两条当前时刻的时间序列所对应的节点之间的无向边是否真实存在,若是,则确定无向边的方向,得到有向边；若否,则删去时间序列之间的无向边,由此得到最终的时间序列因果关系图；其中,所述第二条件集不同于所述第一条件集。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              吴志颖;              刘洁利;                   郑子彬       </td>   <td>中山大学</td>   <td>一种区块链交易追踪方法及装置</td>   <td>广东省</td>   <td>CN114266323A</td>   <td>2022-04-01</td>   <td>本申请公开了一种区块链交易追踪方法及装置,所述方法包括：基于源节点,初始化见证网络,其中,所述见证网络包括节点集合、连边集合和各节点的优先级,所述源节点为交易网络中感兴趣的节点,所述交易网络为基于区块链网络的交易信息所构建的交易网络；根据个性化网页排名算法、所述见证网络及所述交易网络,确定目标见证网络,所述目标见证网络中的任意节点的重要性残差小于预设残差值；基于所述目标见证网络,根据局部社区发现算法,确定源节点的局部追踪网络。其中,所述局部追踪网络为所述目标见证网络的子网络,其能够捕获源节点与其他各节点之间的路径,从而实现对源节点的交易追踪。</td>   <td>1.一种区块链交易追踪方法,其特征在于,包括：基于源节点,初始化见证网络,其中,所述见证网络包括节点集合、连边集合和各节点的优先级,所述源节点为交易网络中感兴趣的节点,所述交易网络为基于区块链网络的交易信息所构建的交易网络；根据个性化网页排名算法、所述见证网络及所述交易网络,确定目标见证网络,所述目标见证网络中的任意节点的重要性残差小于预设残差值；基于所述目标见证网络,根据局部社区发现算法,确定源节点的局部追踪网络,所述局部追踪网络为所述目标见证网络的子网络。</td>   <td>G06K9/62;G06F16/951;G06F16/958;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余超;                   刘恒       </td>   <td>中山大学</td>   <td>用于虚拟自博弈智能体的重放经验池偏置更新方法及装置</td>   <td>广东省</td>   <td>CN114266325A</td>   <td>2022-04-01</td>   <td>本发明公开了一种用于虚拟自博弈智能体的重放经验池偏置更新方法及装置,建立一个对在不同时刻进入经验池的样本能够依照其进入时刻赋予权重并依照该权重进行采样的先入先出队列偏置重放经验池,并利用各智能体距离优化目标差距的博弈动态信息对偏置重放经验池中数据进行赋权。采用本发明实施例,动态地对新数据赋予较高权重,使得深度Q学习网络进行更有效地学习,弱化深度Q学习网络更新时的延迟和偏差带来的负面效益。</td>   <td>1.一种用于虚拟自博弈智能体的重放经验池偏置更新方法,其特征在于,包括：初始化动态预测参数、阶梯层数、层偏置系数、基础采样偏置系数、采样偏置系数限位比、先后手优势比例和变动烈度系数；根据所述阶梯层数、所述层偏置系数和属于不同队列的多个重放经验池,初始化偏置重放经验池；根据所述动态预测参数,设置策略源为深度Q值神经网络或平均策略神经网络；所述深度Q值神经网络包括动作Q值神经网络和目标Q值神经网络；根据强化学习智能体损失函数和对手强化学习智能体损失函数乘以所述先后手优势比例后的差值、所述基础采样偏置系数和所述采样偏置系数限位比和所述变动烈度系数,更新采样偏置系数；根据所述采样偏置系数,对所述偏置重放经验池进行偏置采样,并对偏置采样结果进行随机梯度下降,更新所述动作Q值神经网络；根据所述动作Q值神经网络周期性地更新所述目标Q值神经网络；在监督学习经验池进行采样,并对所述监督学习经验池的采样结果进行随机梯度下降,更新所述平均策略神经网络；调用目前所述策略源,采样一个当前动作并执行,获得下一个状态的状态值及下一个状态的奖励值,并将含有当前状态的状态值、所述当前动作、所述下一个状态的状态值、所述下一个状态的奖励值的元组存入所述偏置重放经验池。</td>   <td>G06K9/62;G06F16/2457;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王小青;                   陈嘉俊       </td>   <td>中山大学</td>   <td>一种基于时间衰减降水算法的森林火灾预警模型构建方法</td>   <td>广东省</td>   <td>CN114266392A</td>   <td>2022-04-01</td>   <td>本发明公开了一种基于时间衰减降水算法的森林火灾预警模型构建方法,包括：获取降水数据并基于时间衰减算法计算综合降水值；获取历史火灾数据并基于二维高斯卷积函数将森林火点转化为森林火点密度；获取气象数据、遥感数据和高程数据并数据进行预处理,得到预处理后的数据；将综合降水值、森林火点密度和预处理后的数据作为训练集,对SVM回归模型进行训练,得到训练完成的SVM回归模型；基于训练完成的SVM回归模型预测森林火灾密度数据；根据森林火灾密度数据划分火灾等级,结合训练完成的SVM回归模型得到森林火灾预警模型。通过使用本发明,能够提高森林火灾预警的准确率。本发明可广泛应用于火险预测领域。</td>   <td>1.一种基于时间衰减降水算法的森林火灾预警模型构建方法,其特征在于,包括以下步骤：S1、获取降水数据并基于时间衰减算法计算综合降水值；S2、获取历史火灾数据并基于二维高斯卷积函数将森林火点转化为森林火点密度；S3、获取气象数据、遥感数据和高程数据并数据进行预处理,得到预处理后的数据；S4、将综合降水值、森林火点密度和预处理后的数据作为训练集,对SVM回归模型进行训练,得到训练完成的SVM回归模型；S5、基于训练完成的SVM回归模型预测森林火灾密度数据；S6、根据森林火灾密度数据划分火灾等级,结合训练完成的SVM回归模型得到森林火灾预警模型。</td>   <td>G06Q10/04;G06Q50/26;G06N20/10;G08B17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余超;              张家鑫;              骆伟祺;                   周颖       </td>   <td>中山大学</td>   <td>一种数据分配权重的预测方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN114266418A</td>   <td>2022-04-01</td>   <td>本发明公开了一种数据分配权重的预测方法、装置、设备及存储介质,通过获取历史市场信息数据,对历史市场信息数据进行预处理,生成专家经验数据,并将专家经验数据存储到第一缓存表中；设置第一网络模型,通过获取当前市场信息数据,以使第一网络模型输出当前市场信息数据的资产分配权重,得到当前经验数据,将当前经验数据存储到第二缓存表中；按照预设的权重比例,分别采集第一缓存表和第二缓存表对应的经验数据,并根据经验数据,对第一网络模型进行更新,获取最优第一网络模型,以使最优第一网络模型输出最优资产分配权重。与现有技术相比,本发明通过设置两个经验数据缓存表,实现对网络模型进行更新训练,提高对数据预测的准确性。</td>   <td>1.一种数据分配权重的预测方法,其特征在于,包括：获取历史市场信息数据,对所述历史市场信息数据进行预处理,生成专家经验数据,并将所述专家经验数据存储到第一缓存表中；设置第一网络模型,通过获取当前市场信息数据,以使所述第一网络模型输出所述当前市场信息数据的资产分配权重,并根据所述资产分配权重,得到当前经验数据,将所述当前经验数据存储到第二缓存表中；按照预设的权重比例,分别采集所述第一缓存表和所述第二缓存表对应的经验数据,并根据所述经验数据,对所述第一网络模型进行更新,获取最优第一网络模型,以使所述最优第一网络模型输出最优资产分配权重。</td>   <td>G06Q10/04;G06Q10/06;G06Q40/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚和瑞;              杨雅平;              钟颖;              李俊微;              冯嘉豪;              汪进;                   陈睿       </td>   <td>中山大学孙逸仙纪念医院;赛维森(广州)医疗科技服务有限公司</td>   <td>基于深度学习的致密性乳腺图像分类评估方法和装置</td>   <td>广东省</td>   <td>CN114266754A</td>   <td>2022-04-01</td>   <td>本发明公开了基于深度学习的致密性乳腺图像分类评估方法和装置。该方法通过建立致密性乳腺图像分类评估模型,致密性乳腺图像分类评估模型包括多个模态模型,致密性乳腺图像分类评估模型为卷积神经网络模型；用第三样本数据集训练所述多个模态模型后,拼接各个模态模型的输出结果,并将拼接后的所述输出结果输入至所述致密性乳腺图像分类评估模型,根据第四图像样本集训练所述致密性乳腺图像分类评估模型至收敛；将预测样本集输入至所述致密性乳腺图像分类评估模型,得到致密性乳腺图像对应分类的综合置信度；预测样本集为致密性乳腺BI-RADS 4A的影像图像。本发明技术方案实现了对乳腺类型为致密性乳腺BI-RADS 4A的乳腺图像的高效且准确的分类评估。</td>   <td>1.一种基于深度学习的致密性乳腺图像分类评估方法,其特征在于,包括以下步骤：根据预设的第一条件从多个系统中获取乳腺超声影像图像和乳腺钼靶影像图像,作为第一样本数据集；所述乳腺超声影像图像和乳腺钼靶影像图像包括乳腺类型为致密性乳腺BI-RADS 4A和致密性乳腺BI-RADS 4B的影像图像；针对所述第一样本数据集中同一样本主体的样本数据进行一致性检查,将不符合一致性检查标准的样本主体的样本数据从所述第一样本数据集中删除,得到第二样本数据集；删除所述第二样本数据集中符合预设的第二条件的样本数据,得到第三样本数据集；选择所述第三样本数据集中图像对应的乳腺类型为致密性乳腺BI-RADS 4A的图像数据作为第四图像样本集；建立致密性乳腺图像分类评估模型,所述致密性乳腺图像分类评估模型包括多个模态模型,所述致密性乳腺图像分类评估模型为卷积神经网络模型；用所述第三样本数据集训练所述多个模态模型后,拼接各个模态模型的输出结果,并将拼接后的所述输出结果输入至所述致密性乳腺图像分类评估模型,根据第四图像样本集训练所述致密性乳腺图像分类评估模型至收敛；将预测样本集输入至所述致密性乳腺图像分类评估模型,得到所述预测样本集的致密性乳腺图像的对应分类；所述预测样本集为致密性乳腺BI-RADS 4A的影像图像。</td>   <td>G06T7/00;G06K9/62;G06V10/774;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              叶梓豪;                   刘坤华       </td>   <td>中山大学</td>   <td>一种多激光雷达协同的地图构建方法及其系统</td>   <td>广东省</td>   <td>CN114255324A</td>   <td>2022-03-29</td>   <td>本发明属于地图构建技术领域,更具体地,涉及一种多激光雷达协同的地图构建方法及其系统,方法包括以下步骤：多个激光雷达分别获取同一建图区域的原始点云数据,并根据原始点云数据求解得到多个激光雷达之间的外参初始值；对原始点云数据进行特征提取,得到特征g′；根据特征g′对原始点云数据进行特征匹配,得到初始化的前端位姿；对前端位姿进行优化,得到全局优化位姿以及全局优化地图；根据全局优化位姿与外参初始值对多个激光雷达的外参进行优化标定输出优化外参；根据优化外参更新外参初始值。本发明提高了多激光雷达协同建图的外参标定精准度,同时还降低了系统的成本。</td>   <td>1.一种多激光雷达协同的地图构建方法,其特征在于,包括以下步骤：S1：多个激光雷达分别获取同一建图区域的原始点云数据,对原始点云数据进行预处理,基于预处理后的点云数据求解得到多个激光雷达之间的外参初始值；S2：对预处理后的点云数据进行特征提取,得到边缘特征、平面特征,并对平面特征进行二次提取得到点面特征S3：基于关键帧和滑动窗口,利用所述点面特征对预处理后的点云数据进行特征匹配,得到初始化的前端位姿；S4：基于集束调整对前端位姿进行局部优化,得到局部优化位姿；对全局位姿进行优化得到全局优化位姿及全局优化地图；根据全局优化位姿与外参初始值对多个激光雷达的外参进行优化标定,输出优化外参,并将优化外参返回至步骤S1中更新外参初始值；S5：重复执行步骤S1至步骤S4,持续输出多个全局优化地图,根据多个全局优化地图构建SLAM地图。</td>   <td>G06T17/05;G06T7/80;G06T7/187</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青;              赵惠;              陈添水;                   林倞       </td>   <td>中山大学</td>   <td>一种基于图片蒸馏的通用物体检测系统及其实现方法</td>   <td>广东省</td>   <td>CN109344897B</td>   <td>2022-03-25</td>   <td>本发明公开了一种基于图片蒸馏的通用物体检测系统及其实现方法,该系统包括：Faster RCNN模型,构建Faster RCNN的网络结构,并进行训练,得到训练好的Faster RCNN模型；Wae Faster RCNN检测模型,将输入图像分解成两个分辨率只有原图一半的子图,构建并利用Wae Faster RCNN网络结构分别对低频和高频子图进行物体检测,将两个子图的检测结果进行融合得到最终检测结果；训练指导单元,对Wae Faster RCNN检测模型进行训练,并在训练时引入知识蒸馏机制,利用已训练好的Faster RCNN模型的输出作为软目标来指导Wae Faster RCNN模型的训练。</td>   <td>1.一种基于图片蒸馏的通用物体检测系统,包括：Faster RCNN模型,用于构建Faster RCNN的网络结构,并进行训练,得到训练好的Faster RCNN模型；Wae Faster RCNN检测模型,用于将输入图像分解成两个分辨率只有原图一半的子图,构建Wae Faster RCNN网络结构,利用Wae Faster RCNN网络结构分别对低频子图和高频子图进行物体检测,然后将两个子图的检测结果进行融合得到最终检测结果；训练指导单元,用于对所述Wae Faster RCNN检测模型进行训练,并在所述Wae FasterRCNN检测模型训练时引入知识蒸馏机制,利用训练好的Faster RCNN模型的输出作为软目标来指导所述Wae Faster RCNN检测模型的训练；所述Wae Faster RCNN检测模型包括：图像分解单元,用于利用训练好的Anto-Encoder模型将输入图像分解成两个分辨率只有原图一半的子图,分别为低频子图和高频子图；检测单元,用于构建所述Wae Faster RCNN网络结构,利用所述Wae Faster RCNN网络结构分别对低频子图和高频子图进行物体检测；融合处理单元,用于对低频子图与高频子图的检测结果进行融合,得到融合后的检测结果；所述图像分解单元采用类小波自动编码器WAE进行图像分解,以将输入图像分解成分辨率只有原图一半的低频子图和高频子图,两个子图分别包含原图的低频信息和高频信息；对于低频子图与高频子图,所述检测单元分别构建所述Wae Faster RCNN网络结构的低频子网络和高频子网络,该低频子网络的RPN和Fast RCNN,采用完整版Faster RCNN的RPN和Fast RCNN,该高频子网络的RPN和Fast RCNN,采用轻量版Faster RCNN的RPN和FastRCNN。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              梁曦文;                   周凡       </td>   <td>中山大学</td>   <td>一种基于深度语义分割的图像去雾方法</td>   <td>广东省</td>   <td>CN110766640B</td>   <td>2022-03-25</td>   <td>本发明公开了一种基于深度语义分割的图像去雾方法。本发明收集清晰无雾图和相应深度图的数据集,采用PSPNet网络模型构建语义分割模块,采用自动编码器构建去雾模块,并嵌入语义分割模块作为图像去雾模型；制定去雾模型训练策略进行模型训练；取有雾图及对应清晰图片所组成的测试集,对完整的去雾模型进行测试,将有雾图输入到语义分割模块中获得该有雾图的语义分割特征图,再将有雾图和对应语义分割特征图输入到去雾模块中,最后输出清晰无雾图。本发明方法能在较快时间内完成精度高的图像去雾任务,同时基于语义分割信息,能有效避免产生色差和光晕伪影现象,且在PSNR和SSIM指标上能比大部分现有图像去雾方法更好。</td>   <td>1.一种基于深度语义分割的图像去雾方法,其特征在于,所述方法包括：收集清晰无雾图和相应的深度图的数据集,室内图采用NYU-Depth v2数据集,室外图则采用RESIDE数据集；采用在ADE20K数据集下训练的PSPNet网络模型,并对该模型进行微调来构建语义分割模块；采用自动编码器来构建去雾模块,并嵌入语义分割模块作为完整的单张图像去雾模型；制定去雾模型训练策略,并进行模型训练,经设定的迭代次数修正网络参数得到最终的模型结果,即先设计损失函数,计算损失函数得到当前误差,通过反向传播修改网络参数；取有雾图及对应的清晰图片所组成的测试集,对完整的去雾模型进行测试,该最终模型接收一张输入的有雾图,经过语义分割模块后得到相应的语义分割标签图,将有雾图和得到的标签图连接起来并输入到去雾模块中得到对应的清晰结果图。</td>   <td>G06T5/00;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱杰友;                   周炳朋       </td>   <td>中山大学</td>   <td>一种基于多分支残差卷积网络的可见光室内定位方法</td>   <td>广东省</td>   <td>CN114239701A</td>   <td>2022-03-25</td>   <td>本发明公开了一种基于多分支残差卷积网络的可见光室内定位方法,该方法包括：获取可见光RSS数据图并构建训练集；基于训练集对预设的定位模型进行训练,得到训练完成的定位模型；所述预设的定位模型包括残差卷积网络和多分支特征融合网络；获取待测RSS数据图,输入至训练完成的网络模型中得到对应位置信息。通过使用本发明,解决方向未知情况与环境动态变化带来的定位影响,达到鲁棒的定位解决方法。本发明作为一种基于多分支残差卷积网络的可见光室内定位方法,可广泛应用于可见光室内定位领域。</td>   <td>1.一种基于多分支残差卷积网络的可见光室内定位方法,其特征在于,包括以下步骤：获取可见光RSS数据图并构建训练集；基于训练集对预设的定位模型进行训练,得到训练完成的定位模型；所述预设的定位模型包括残差卷积网络和多分支特征融合网络；获取待测RSS数据图,输入至训练完成的网络模型中得到对应位置信息。</td>   <td>G06K9/62;G06K9/00;G06V10/80;G06V10/774;G06V10/82;G06V10/44;G06V10/54;G06N3/04;G06N3/08;G01S5/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨钦泰;              李涵生;              罗新;              邵春奎;              陈健宁;              刘子锋;              吴晓琦;              杨林;              黄雪琨;              张雅娜;              郑瑞;              吴庆武;              吴硕;              邱惠军;              王心悦;              林明珍;                   屠佳杰       </td>   <td>杭州迪英加科技有限公司;中山大学附属第三医院(中山大学肝脏病医院)</td>   <td>一种鼻息肉病理切片分析方法、系统和可读存储介质</td>   <td>浙江省</td>   <td>CN114240836A</td>   <td>2022-03-25</td>   <td>本发明公开了一种鼻息肉病理切片分析方法、系统和可读存储介质,通过图像采集器实时采集实体切片的显微镜下的病理图像信息,并发送给处理器。处理器接对所述鼻息肉病理图像上所有细胞进行有效区域检测,去除当前视野中上皮区域、血管区域、腺体区域后再统计当前视野下的浆细胞、中性粒细胞、嗜酸性粒细胞和淋巴细胞数量；并统计上述四类炎症细胞总和作为当前视野下总体炎症细胞数目；然后计算浆细胞、中性粒细胞、嗜酸性粒细胞和淋巴细胞的百分比,通过当前玻片中随机10个高倍镜视野及热点视野下上述四类炎症细胞的数目及比例,最终判断当前切片患者鼻息肉炎症类别,最后将统计结果进行存储。本发明有助于鼻窦炎患者个体化诊疗及预后改善。</td>   <td>1.一种鼻息肉病理切片分析方法,其特征在于,所述方法包括以下步骤：采集鼻息病理切片图像,对鼻息病理切片图像进行预处理,使鼻息肉病理切片图像各参数符合数字病理切片图像各参数的要求；将预处理后的鼻息病理切片图像切分成若干个小图,再输入训练好的特征校正检测模型进行处理,去除当前视野中上皮区域、血管区域、腺体区域后再统计当前视野下的浆细胞、中性粒细胞、嗜酸性粒细胞和淋巴细胞数量；并统计上述四类炎症细胞总和作为当前视野下总体炎症细胞数目；然后计算浆细胞、中性粒细胞、嗜酸性粒细胞和淋巴细胞的百分比；通过当前玻片中随机10个高倍镜视野及热点视野下上述四类炎症细胞的数目及比例,最终判断当前切片患者鼻息肉炎症类别。</td>   <td>G06T7/00;G06T7/11;G06V20/69;G16H30/20;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         熊会元;              刘建勋;              刘羽;                   李同同       </td>   <td>中广核工程有限公司;中山大学</td>   <td>一种放射性废物包识别定位方法与装置</td>   <td>广东省</td>   <td>CN112581519B</td>   <td>2022-03-22</td>   <td>本发明公开一种放射性废物包识别定位方法与装置,方法包括：制作废物包点云模板及屏蔽容器点云模板,通过利用环境约束特征向量的两阶段匹配方法识别出屏蔽容器的位姿及废物包的位姿,以此进行识别定位,根据识别定位的结果对废物包进行装载或卸载。本发明实现对屏蔽容器姿态与内部状态识别与精确定位,实现了屏蔽外箱内货包的精确识别与定位,解决了对环境光照、遮挡等敏感的传统技术无法解决的箱内货包识别定位问题。</td>   <td>1.一种放射性废物包识别定位方法,其特征在于,制作废物包点云模板及屏蔽容器点云模板,通过两阶段匹配算法识别出屏蔽容器的位姿及废物包的位姿,以此进行识别定位,根据识别定位的结果对废物包进行装载或卸载,具体步骤如下：S1、通过激光扫描传感器采集场景点云,提取标定好的车道有效区域点云,进行降噪滤波去除杂乱随机离群点,并提取地面点云；S2、去除地面点云,并对场景内物体点云进行聚类,获得各个物体点云,并通过筛选获取聚类的车辆点云及屏蔽容器点云；S3、应用屏蔽容器点云模板对获取的屏蔽容器点云进行两阶段位姿匹配,识别得到屏蔽容器的位姿,如位姿正常,则根据位姿指导装卸装置卸载屏蔽容器的顶盖,如位姿异常,则重新识别屏蔽容器的位姿；S4、根据识别得到的屏蔽容器位姿,对屏蔽容器内点云进行分析,设定点云垂向密度最小阈值和最大阈值,检测屏蔽容器内是否装载废物包及屏蔽容器内部状态是否正常；S41、如点云垂向密度大于最大阈值,则屏蔽容器内装载有废物包,当屏蔽容器内装载有废物包时,要进行卸载,卸载过程如下：S411、提取屏蔽容器内的废物包点云并提取边界；S412、应用废物包点云模板对提取的废物包点云进行两阶段位姿匹配,获得废物包的位姿并传输给卸载系统,卸载系统发送操作指令给装卸装置抓取废物包进行卸载；S413、在卸载过程中实时监测废物包的位姿并反馈给卸载系统；S42、如点云垂向密度小于最小阈值,则屏蔽容器内为空,当屏蔽容器内为空时,要进行装载,装载过程如下：S421、直接将屏蔽容器的内部空间位姿传输给装载系统,装载系统发送操作指令给装卸装置抓取废物包进行装载；S422、在装载完成后检测废物包的位姿并反馈给装载系统；S43、其他状态则表明容器内存在异物,当屏蔽容器内存在异物时,则上报中控系统,在中控系统进行检查排除异常之后重新识别屏蔽容器的位姿。</td>   <td>G06T7/521;G06T7/73;G06V10/762;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金牧;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于符号选项和动作模型自学习的任务规划方法</td>   <td>广东省</td>   <td>CN114219099A</td>   <td>2022-03-22</td>   <td>本发明公开了一种基于符号选项和动作模型自学习的任务规划方法,该方法包括：基于符号状态映射模块,根据先验知识和数字图像处理将高维图像数据映射为符号状态；基于选项集合模块,根据随机动作和符号状态构建选项集合；基于动作模型学习模块,根据符号状态的变化学习动作模型和更新选项集合,得到新动作模型和规划目标基于规划器模块,根据新动作模型和规划目标求解规划路径,并根据规划结果探索是否存在新的动作模型。通过使用本发明,能够自动学习动作模型和符号选项以及它们之间的对应关系,进行规划和训练探索,以获得解决问题的动作策略。本发明作为一种基于符号选项和动作模型自学习的任务规划方法,可广泛应用于符号规划领域。</td>   <td>1.一种基于符号选项和动作模型自学习的任务规划方法,其特征在于,包括以下步骤：基于符号状态映射模块,根据先验知识和数字图像处理将高维图像数据映射为符号状态；基于选项集合模块,根据随机动作和符号状态构建选项集合；基于动作模型学习模块,根据符号状态的变化学习动作模型和更新选项集合,得到新动作模型和规划目标；基于规划器模块,根据新动作模型和规划目标求解规划路径,并根据规划结果探索是否存在新的动作模型。</td>   <td>G06N20/00;G06V10/77;G06K9/62;A63F13/67</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈亮;              王源盛;              谢芬方;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于情感分析的解释推荐方法、装置和设备</td>   <td>广东省</td>   <td>CN114219530A</td>   <td>2022-03-22</td>   <td>本发明公开了一种基于情感分析的解释推荐方法、装置和设备,方法包括：响应于用户输入的物品选取指令,确定用户选定的目标物品；根据针对目标物品的多条物品评论信息,生成对应的物品特征向量；根据用户关联的多条用户评论信息,生成对应的用户特征向量；将物品特征向量和用户特征向量投影至共享空间,确定目标物品对应的共享隐藏向量；根据物品评论信息和用户评论信息,分别确定物品评论偏好分数和用户评论偏好分数；基于物品评论偏好分数、用户评论偏好分数和共享隐藏向量,确定目标物品对应的推荐信息。以采用其涉及到的情感信息融合到推荐信息的生成过程中,从而更为有效提高解释推荐的生成质量,提高物品推荐的准确度。</td>   <td>1.一种基于情感分析的解释推荐方法,其特征在于,包括：响应于用户输入的物品选取指令,确定所述用户选定的目标物品；根据针对所述目标物品的多条物品评论信息,生成对应的物品特征向量；根据所述用户关联的多条用户评论信息,生成对应的用户特征向量；将所述物品特征向量和所述用户特征向量投影至共享空间,确定所述目标物品对应的共享隐藏向量；根据所述物品评论信息和所述用户评论信息,分别确定物品评论偏好分数和用户评论偏好分数；基于所述物品评论偏好分数、所述用户评论偏好分数和所述共享隐藏向量,确定所述目标物品对应的推荐信息。</td>   <td>G06Q30/02;G06F40/30;G06F40/284;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张冬雨;              陈炫坤;                   陈俊宏       </td>   <td>中山大学</td>   <td>将超分辨与退化联合学习的真实世界图片超分系统及方法</td>   <td>广东省</td>   <td>CN114219712A</td>   <td>2022-03-22</td>   <td>本发明提供一种将超分辨与退化联合学习的真实世界图片超分系统及方法,系统通过训练退化子网络,可以生成真实的训练对,从而避免双三次下采样造成的伪影,还引入了信息损失以避免颜色变化,并引入了感知损失以去除非真实的伪影；本发明相比于其他方法具有良好的性能,得到的高分辨率图片有更少的噪声和更好的视觉质量；解决现有超有超分辨方法不能适用于真实世界图片超分的问题,同时提出一个联合训练框架,既可以实现真实世界图片超分,也可以构建真实世界的高低分辨率图片对,方便应用于其他超分网络中。</td>   <td>1.一种将超分辨与退化联合学习的真实世界图片超分系统,其特征在于,包括：超分网络模块,将输入的低分辨率图像通过网络生成得到高分辨率图像；退化网络模块,将超分网络模块得到的高分辨率图像退化为具有真实世界特征的模糊图像；判别模块,对退化网络模块输入的图像进行判别是来自真实图像分布还是来自生成的图像的分布；损失函数模块,使超分网络模块和退化网络模块都受到损失函数模块的约束,以确保输出图像的分布并保留内容信息,损失函数模块包括对抗损失模块、循环一致损失模块、信息损失模块和感知损失模块,将它们加权求和得到总的损失函数模块。</td>   <td>G06T3/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢晓华;              郑钊;              余阳;                   赖剑煌       </td>   <td>中山大学</td>   <td>基于Ray-pixel相机标定模型的畸变矫正方法</td>   <td>广东省</td>   <td>CN114219726A</td>   <td>2022-03-22</td>   <td>本发明公开了基于Ray-pixel相机标定模型的畸变矫正方法,包括使用Ray-pixel模型对相机进行标定,得到相机的内参Intrinsics；参考镜头的焦距(f-x,f-y)、主点坐标(c-x,c-y),选定一个透视变换模型；利用选定的所述透视变换模型,将像素(u,v)进行反投影,得到该像素对应的入射光线方向利用Raxel-pixel模型对反投影后的方向进行重投影,得到p′＝(u′,u′)；在有畸变的原始图像上对p’进行双线性插值,得到p’的颜色,将该颜色赋予像素p,最后得到矫正后的去畸变图像。本发明去畸变后的图像内容更能真实反映物体的外观,也更适合进一步应用图像处理、目标检测、图像分割等算法。</td>   <td>1.基于Ray-pixel相机标定模型的畸变矫正方法,其特征在于,包括以下步骤：步骤1、使用Ray-pixel模型对相机进行标定,得到相机的内参Intrinsics；步骤2、参考镜头的焦距(f-x,f-y)、主点坐标(c-x,c-y),选定一个透视变换模型；步骤3、利用步骤2中选定的所述透视变换模型,将像素(u,v)进行反投影,得到该像素对应的入射光线方向步骤4、利用Raxel-pixel模型对反投影后的方向进行重投影,得到p′＝(u′,u′)；步骤5、在有畸变的原始图像上对p’进行双线性插值,得到p’的颜色,将该颜色赋予像素p,最后得到矫正后的去畸变图像。</td>   <td>G06T5/00;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宫凯凤;              陈振东;              彭勃;                   谢晓华       </td>   <td>中山大学</td>   <td>基于动态加权稳态主成分分析的医学图像去噪的方法</td>   <td>广东省</td>   <td>CN114219727A</td>   <td>2022-03-22</td>   <td>本发明公开了基于动态加权稳态主成分分析的医学图像去噪的方法。在原始3DPI图像数据基础上,基于稳态主成分分析进行动态加权扩展,并经动态加权后得到低秩矩阵L和稀疏矩阵S,以达到对3DPI图像去噪的目的。本发明有益效果在于,所提出的DWRPCA的性能优于RPCA和WRPCA。具体来说,在单周期和多周期的数据分析中,对于时间相似性指标EGM和SPEGM,DWRPCA和WRPCA具有相同的实验结果；对于无偏差性能指标TAE和ARE,DWRPCA均显著优于WRPCA；对于空间相似度指标SSI和SGSI,DWRPCA能获得更好的空间波形。</td>   <td>1.基于动态加权稳态主成分分析的医学图像去噪的方法,其特征在于,在原始3DPI图像数据基础上,基于稳态主成分分析进行动态加权扩展,并经动态加权后得到低秩矩阵L和稀疏矩阵S,以达到对3DPI图像去噪的目的。</td>   <td>G06T5/00;G06V10/77;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              刘奕志       </td>   <td>中山大学中山眼科中心</td>   <td>基于眼底影像的图像处理方法</td>   <td>广东省</td>   <td>CN114219761A</td>   <td>2022-03-22</td>   <td>本发明涉及一种基于眼底影像的图像处理方法,尤其涉及图像处理技术领域,包括,步骤S1,采集获取目标的眼底图像；步骤S2,根据所述眼底图像建立眼底图像模型；在建立眼底图像模型时,获取所述眼底图像的轮廓形状,建立与所述轮廓形状形状相同的眼底图像模型；步骤S3,对所述眼底图像进行图像分析；步骤S4,根据分析结果对所述眼底图像模型进行标记；步骤S5,对标记完成后的眼底图像模型进行着色；所述步骤S3-S4中,在进行图像分析时,将所述眼底图像按照灰度值进行区域划分,划分后形成若干目标区域。本发明通过建立眼底图像模型,并对眼底图像模型进行精确标记,有效提高了识别眼底图像的精确度。</td>   <td>1.一种基于眼底影像的图像处理方法,其特征在于,包括,步骤S1,采集获取目标的眼底图像；步骤S2,根据所述眼底图像建立眼底图像模型；在建立眼底图像模型时,获取所述眼底图像的轮廓形状,建立与所述轮廓形状形状相同的眼底图像模型；步骤S3,对所述眼底图像进行图像分析；步骤S4,根据分析结果对所述眼底图像模型进行标记；步骤S5,对标记完成后的眼底图像模型进行着色；所述步骤S3-S4中,在进行图像分析时,将所述眼底图像按照灰度值进行区域划分,划分后形成若干目标区域,再根据目标区域中曲线形状区域的宽度A判定该曲线形状区域是否为血管区域,在确定所述眼底图像中的全部血管区域后,按照宽度由大到小的顺序对各血管区域进行排序并编号,当血管区域宽度相同时,按照长度由大到小的顺序进行排序并编号,并将宽度、长度均相同的血管区域随机排序编号,编号完成后,按照编号顺序逐个将血管区域绘制在所述眼底图像模型上,在进行绘制时,对各血管区域进行重要等级划分,并对重要血管区域进行标记；在对所述眼底图像模型血管区域绘制完成后,根据眼底图像中的视盘区域中心点在所述眼底图像模型中绘制视盘区域轮廓,以对视盘区域进行标记；在对所述眼底图像模型视盘区域标记完成后,根据眼底图像中的黄斑区域圆心在所述眼底图像模型中绘制黄斑区域轮廓,以对黄斑区域进行标记。</td>   <td>G06T7/00;G06T7/11;G06T7/90;G06T7/62;G06T7/187;G06T11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              杜子纯;                   刘镇       </td>   <td>中山大学</td>   <td>一种三维地层模型内部自由漫游方法</td>   <td>广东省</td>   <td>CN109410326B</td>   <td>2022-03-18</td>   <td>本发明涉及一种三维地层模型内部自由漫游方法,属于地质与工程信息技术领域。其特征是：不直接绘制地层模型中的各个面,而是通过建立一组平板,计算平板与各地层的相互位置关系,在平板的对应位置绘制岩性花纹,来等效地展示视角附近的地层分布；此方法可以排除地层模型内部杂乱的面对视点绘制区域的遮挡等影响,使漫游过程直观简洁,因此也可满足在模型内部自由漫游的需求。</td>   <td>1.一种三维地层模型内部自由漫游方法,包括以下步骤：(1)隐去所有地层图像,使其只能参与计算,但不绘制图像；(2)根据视点位置,在视点前方、左侧、右侧、上方、下方的一定距离建立出5个平板,这5个平板的位置形成缺一个面的长方体形状,视点在长方体的缺面处的中心位置；(3)在各平板上确定若干条间距相等的线段,线段间距越小,漫游精度越高,同时漫游过程对计算机计算能力的要求越高；(4)计算每条线段的端点所在的地层,以及线段与各地层分界面的交点位置,线段与各地层分界面的交点和线段端点统称为关键节点,建立关键节点和所在地层的对应关系,将关键节点根据其在线段中的位置进行排序,相邻两点间的范围即为该线段上对应地层的范围；(5)在同一平板上,把各相邻的线段上相同的地层连接起来,即为平板与各地层的相交范围,在相交范围内,绘制与各相邻的线段相交地层对应的岩性花纹；(6)当视角移动或旋转后,删除原有平板,重复步骤(2)到(5)。</td>   <td>G06T17/05</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沙煜;              谢震宇;                   梁小丹       </td>   <td>中山大学;中山大学·深圳</td>   <td>一种基于神经网络搜索的虚拟试穿方法和系统</td>   <td>广东省</td>   <td>CN114202637A</td>   <td>2022-03-18</td>   <td>本发明提供了一种基于神经网络搜索的虚拟试穿方法和系统,所述方法包括：获取人体形状图和目标衣物图片,通过语义预测网络和Openpose网络获得人体关键点图、人体语义分割图和部分语义分割图；构造变形网络搜索空间,将原衣物掩模和目标衣物图片掩模联接,搜索出衣物变形场；通过衣物变形场将目标衣物变形至目标形态；构造融合网络搜索空间,结合人体形状图、人体关键点图、目标衣物图片和人体语义分割图得到试穿结果。本发明通过神经网络搜索以及双层层次搜索空间,针对不同的衣物种类自动搜索出的衣物变形场,提供了一种成功率高、自由度高的虚拟试穿方法和系统,能够解决不同服装的变形差异引起的空间错位,具有较高的效率和灵活性。</td>   <td>1.一种基于神经网络搜索的虚拟试穿方法,其特征在于,包括：获取人体形状图和目标衣物图片,通过语义预测网络和Openpose网络,获得人体关键点图、人体语义分割图和部分语义分割图；构造变形网络搜索空间,将原衣物对应的掩模和目标衣物图片对应的掩模联接,在所述变形网络搜索空间中搜索出与衣物种类对应的衣物变形场；通过所述衣物变形场将目标衣物图片变形至目标形态；构造融合网络搜索空间,通过所述融合网络搜索空间,结合所述人体形状图、所述人体关键点图、目标形态下的目标衣物图片和所述人体语义分割图,得到试穿结果。</td>   <td>G06T19/00;G06V40/10;G06V10/26;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              丁湲珺;                   陈伟利       </td>   <td>中山大学</td>   <td>一种洗钱团伙检测方法及其相关装置</td>   <td>广东省</td>   <td>CN114202421A</td>   <td>2022-03-18</td>   <td>本申请公开了一种洗钱团伙检测方法及其相关装置,方法包括：获取去中心化交易所的交易数据；根据交易数据构建交易有向图,交易图中的节点为去中心化交易所中的用户,节点之间的边为用户之间发生的交易,边的方向为资金的流动方向,节点的度为交易的个数；对交易有向图迭代进行多轮边缘弱化,并记录每一轮边缘弱化后的交易有向图中的最大连通团伙和整个迭代过程中最大连通团伙的出现次数；选择出现次数高于次数阈值的最大连通团伙作为强连接团伙；根据各强连接团伙中各用户的持仓变化量及收益检测各强连接团伙是否为洗钱团伙,改善了现有技术采用对单个洗钱用户进行检测的方式,操作检测准确率不高的技术问题。</td>   <td>1.一种洗钱团伙检测方法,其特征在于,包括：获取去中心化交易所的交易数据；根据所述交易数据构建交易有向图,所述交易图中的节点为所述去中心化交易所中的用户,所述节点之间的边为用户之间发生的交易,所述边的方向为资金的流动方向,所述节点的度为交易的个数；对所述交易有向图迭代进行多轮边缘弱化,并记录每一轮边缘弱化后的交易有向图中的最大连通团伙和整个迭代过程中最大连通团伙的出现次数；选择出现次数高于次数阈值的最大连通团伙作为强连接团伙；根据各所述强连接团伙中各用户的持仓变化量及收益检测各所述强连接团伙是否为洗钱团伙。</td>   <td>G06Q40/04;G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄华威;              张深扬;                   郑子彬       </td>   <td>中山大学</td>   <td>一种区块链分片方法、区块链系统及跨分片交易处理方法</td>   <td>广东省</td>   <td>CN114202422A</td>   <td>2022-03-18</td>   <td>本申请公开了一种区块链分片方法、区块链系统及跨分片交易处理方法,包括：根据当前分区周期新生成的交易区块,生成区块链的状态图；并将所述状态图划分成至少两个互不重叠的子状态图,得到状态图划分结果,所述子状态图之间的交易次数小于预设的第一阈值,各子状态图内部的总交易次数的方差小于预设的第二阈值；对所述状态图划分结果在区块链内进行共识,生成新的状态区块；根据所述新的状态区块,对各账户的状态进行重构。本申请可以使得子状态图之间的交易次数尽量少,达到了减少分片之间的交易次数的效果；同时,可以使得各子状态图的交易次数尽量接近,达到了各分片之间工作负载尽量均衡的效果。</td>   <td>1.一种区块链分片方法,其特征在于,包括：根据当前分区周期新生成的交易区块,生成区块链的状态图,所述状态图包括各账户/子账户在当前分区周期的交易关系,所述交易关系包括交易账户/子账户之间的交易次数；当新生成的交易区块达到预设数目后,将所述状态图划分成至少两个互不重叠的子状态图,得到状态图划分结果,所述子状态图之间的交易次数小于预设的第一阈值,各子状态图内部的总交易次数的方差小于预设的第二阈值；对所述状态图划分结果在区块链内进行共识,生成新的状态区块；根据所述新的状态区块,对各账户的状态进行重构。</td>   <td>G06Q40/04;G06F21/60;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;                   叶婉       </td>   <td>中山大学</td>   <td>一种数字资产兑换的风险防范方法</td>   <td>广东省</td>   <td>CN114202335A</td>   <td>2022-03-18</td>   <td>本发明涉及信息安全技术领域,更具体地,涉及一种数字资产兑换的风险防范方法,支持当前区块链背景下的跨链资产兑换,能够识别汇率波动,并通过延迟兑换请求降低资产兑换节点可能遭受的损失。</td>   <td>1.一种数字资产兑换的风险防范方法,其特征在于,包括用户节点U-X和服务器节点S-Y,其中X和Y表示节点可以访问的数字资产集合；服务器节点S-Y支持数字资产兑换,提供数字资产兑换服务；当拥有数字资产A的用户提出将A资产兑换成其他资产时,服务器节点S-Y执行风险防范方法,其中A∈Y,包括以下步骤：S1.服务器节点S-Y设置汇率的最低阈值λ-(rate)和汇率波动的最高阈值λ-(flu),检测汇率的波动情况,并根据设定时间内检测的汇率r-1,r-2,...,r-n,计算该汇率的波动值s；S2.当汇率较稳定即s＜λ-(flu)且r-k＞λ-(rate),1≤k≤n时,服务器节点S-Y设置延迟期为0,提供资产兑换服务；S3.当某个资产突然贬值时,汇率波动过大,即s＞λ-(flu),S-Y设置延迟期Δ-(delay)′,Δ-(delay)′大于0；S4.在延迟期Δ-(delay)′之后根据步骤S1重新计算汇率波动值,并根据步骤S2或步骤S3提供资产兑换服务或者继续延期。</td>   <td>G06Q20/40;G06Q20/38;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              杨杰宇;                   郑沛霖       </td>   <td>中山大学</td>   <td>智能合约交易异常维护方法、装置、设备及可读存储介质</td>   <td>广东省</td>   <td>CN114202215A</td>   <td>2022-03-18</td>   <td>本申请公开了智能合约交易异常维护方法、装置、设备及可读存储介质,方法包括：记录以太坊虚拟机当前的堆栈状态；追踪以太坊虚拟机上的智能合约的交易过程,得到交易的交易信息；当交易结束后,判断交易是否执行异常；若是,则根据预设的程序计数器的值与智能合约的源码的对应关系,确定交易信息中包含的异常的程序计数器的值对应的异常源码；根据异常源码修改交易的相关参数；在与堆栈状态相同的以太坊虚拟机上执行修改后的交易。显然,本申请可以根据预设的对应关系,确定引发智能合约交易的异常源码,并可以根据异常源码对交易作修改,进而在与交易修改前相同的以太坊虚拟机上执行修改后的交易,以供验证修改后的交易是否能执行成功。</td>   <td>1.一种智能合约交易异常维护方法,其特征在于,包括：记录以太坊虚拟机当前的堆栈状态；追踪所述以太坊虚拟机上的智能合约的交易过程,得到所述交易的交易信息；当所述交易结束后,判断所述交易是否执行异常；若是,则根据预设的程序计数器的值与所述智能合约的源码的对应关系,确定所述交易信息中包含的异常的程序计数器的值对应的异常源码；根据所述异常源码修改所述交易的相关参数；在与所述堆栈状态相同的以太坊虚拟机上执行修改后的所述交易。</td>   <td>G06Q10/06;G06Q10/00;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   梁泳恒       </td>   <td>中山大学</td>   <td>一种基于多智能体强化学习的协同充电方法</td>   <td>广东省</td>   <td>CN114202168A</td>   <td>2022-03-18</td>   <td>本发明提供一种基于多智能体强化学习的协同充电方法,该方法通过支持异步决策的轨迹采集机制,使得ASM-PPO能够在如无线可充电传感器网络等异步决策环境中采集更为精简有用的信息,加速了算法的训练速度；本发明通过由异形卷积核以及GRU单元构成的特征提取模块来处理全局信息,使得ASM-PPO在充电车数量增加的情况下仍能保持需要学习的参数数量不变,增加了算法的稳定性。</td>   <td>1.一种基于多智能体强化学习的协同充电方法,其特征在于,包括以下步骤：S1：建立无线可充电传感器网络仿真环境；S2：构建具有可扩展性的多智能体深度强化学习模型ASM-PPO；S3：在仿真环境中使用支持异步决策的轨迹采集机制采集数据,并训练ASM-PPO；S4：利用训练好的ASM-PPO模型用于真实环境中进行协同充电。</td>   <td>G06Q10/06;G06Q10/10;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   刘渤       </td>   <td>中山大学</td>   <td>一种区块链网络的分布式压力测试系统及方法</td>   <td>广东省</td>   <td>CN114201403A</td>   <td>2022-03-18</td>   <td>本发明提供了一种区块链网络的分布式压力测试系统及方法,其中系统包括：区块链客户端,用于创建多个用户之间具有先后顺序的多个交易数据,对多个交易数据进行预处理,得到可并行工作且互不冲突的多个交易工作流,将多个交易工作流分发给相应数量的区块链客户端,多个区块链客户端将多个交易工作流提交给区块链网络以便进行压力测试；其中,交易数据包括区块链交易以及其执行次数；区块链网络,用于通过所述区块链网络的节点执行多个交易工作流进行压力测试,获取区块链网络的压力测试性能数据。本发明同时考虑区块链客户端和区块链网络节点的网络场景情况,保证区块链网络压力测试的高可用性以及充分测试,提高了压力测试的测试结果准确程度。</td>   <td>1.一种区块链网络的分布式压力测试系统,其特征在于,包括：区块链客户端,用于创建多个用户之间具有先后顺序的多个交易数据,对多个所述交易数据进行预处理,得到可并行工作且互不冲突的多个交易工作流,将多个所述交易工作流分发给相应数量的区块链客户端,多个所述区块链客户端将多个所述交易工作流提交给区块链网络以便对区块链网络进行压力测试；其中,所述交易数据包括区块链交易以及对所述区块链交易的执行次数；区块链网络,用于通过所述区块链网络的节点执行多个所述交易工作流进行压力测试,获取所述区块链网络的压力测试性能数据。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   刘渤       </td>   <td>中山大学</td>   <td>一种区块链网络的压力测试系统及方法</td>   <td>广东省</td>   <td>CN114201404A</td>   <td>2022-03-18</td>   <td>本发明提供了一种区块链网络的压力测试系统及方法,其中系统包括：区块链客户端,用于创建多个用户之间具有先后顺序的多个交易数据,对多个所述交易数据进行预处理,得到可并行工作且互不冲突的多个交易工作流,将多个所述交易工作流提交给区块链网络以便进行压力测试；其中,所述交易数据包括区块链交易以及对所述区块链交易的执行次数；区块链网络,用于通过所述区块链网络的节点执行多个所述交易工作流进行压力测试,获取所述区块链网络的压力测试性能数据。本发明通过多个并行的交易工作流能最大限度地利用区块链网络的资源性能,能提高区块链网络对多个区块链交易的执行速度,并提高区块链网络压力测试的测试结果准确程度。</td>   <td>1.一种区块链网络的压力测试系统,其特征在于,包括：区块链客户端,用于创建多个用户之间具有先后顺序的多个交易数据,对多个所述交易数据进行预处理,得到可并行工作且互不冲突的多个交易工作流,将多个所述交易工作流提交给区块链网络以便进行压力测试；其中,所述交易数据包括区块链交易以及对所述区块链交易的执行次数；区块链网络,用于通过所述区块链网络的节点执行多个所述交易工作流进行压力测试,获取所述区块链网络的压力测试性能数据。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余建兴;              林妙培;              王世祺;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于多任务时序学习的工业原料消耗量预测方法</td>   <td>广东省</td>   <td>CN114186711A</td>   <td>2022-03-15</td>   <td>本发明提供一种基于多任务时序学习的工业原料消耗量预测方法,该方法首先获取所有原料的历史消耗量时间序列集合作为模型的输入,并对原始单时序集合进行聚类,进一步将原料分为具正相关或负相关关系的不同组,作为预测模型的先验约束。然后,本专利基于多任务学习思想,构建预测远期和近期未来发展趋势的辅助任务,基于神经网络的预测模型针对所有任务充分提取时间序列的空间和时间维度特征,在此过程中共享不同任务之间学习到的数据特征,以帮助主任务融合更多的时序信息,并基于组合模型思想结合自回归模型预测各种原料在未来一段时间内的消耗量。</td>   <td>1.一种基于多任务时序学习的工业原料消耗量预测方法,其特征在于,包括以下步骤：S1：对原料的历史消耗量时间单序列进行聚类得到多元时间序列集；S2：对步骤S1得到的多元时间序列集构建对应的预测任务；S3：针对步骤S2得到的预测任务进行工业原料消耗量预测得到最终的工业原料消耗量预测值。</td>   <td>G06Q10/04;G06Q10/08;G06Q50/04;G06N3/04;G06N3/08;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              褚燕燕       </td>   <td>中山大学</td>   <td>一种多灾种耦合作用下的燃气泄露风险预测方法</td>   <td>广东省</td>   <td>CN114186772A</td>   <td>2022-03-15</td>   <td>本发明公开了一种多灾种耦合作用下的燃气泄露风险预测方法,包括以下步骤：S1、细化暴雨-地面沉降-燃气管网泄漏多灾种耦合事件的因子粒度,确定五级结构的暴雨事件、地面降沉事件、燃气管道断裂事件与燃气管网泄露事件的事件因子及事件因子谱图；S2、计算多灾种险兆因子的耦合关系；S3、根据多灾种险兆因子的耦合关系构建暴雨-地面沉降-燃气管网泄露多灾种耦合事件链的顶上事件风险度函数,实现对燃气泄露风险预测；本发明能够计算各个灾害时间在空间以及时间上的相关性,辨识灾害在空间中的行为模式,从而对灾害进行有效的测量,不仅能够完成对单灾种灾害后果的估算,同时能够进行多灾种耦合度的匹配,进而实现对燃气泄露风险预测。</td>   <td>1.一种多灾种耦合作用下的燃气泄露风险预测方法,其特征在于,包括以下步骤：S1、获取暴雨事件、地面降沉事件、燃气管道断裂事件与燃气管网泄露事件,并将上述五类事件进行粒度分解,确定五级结构的暴雨事件、地面降沉事件、燃气管道断裂事件与燃气管网泄露事件的事件因子及事件因子谱图；S2、根据步骤S1所述的各个事件的事件因子,确定暴雨事件与地面沉降事件的耦合险兆因子、耦合作用力以及时间和空间相关性,确定地面沉降事件与燃气管网泄露事件的耦合险兆因子、耦合作用力以及时间和空间相关性以及确定燃气管道断裂事件与燃气管网泄露事件的耦合险兆因子、耦合作用力以及时间和空间相关性；S3、基于和构建暴雨-地面沉降-燃气管网泄露多灾种耦合事件链的事件风险度函数,最终预测暴雨事件、地面沉降事件和燃气管道断裂事件耦合作用下的燃气泄露风险。</td>   <td>G06Q10/06;G06Q50/06;G06F30/18;G06F30/28;G08B21/10;G08B21/16;G06F111/02;G06F113/08;G06F113/14;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;              叶婉;              李茂楠;                   郑海彬       </td>   <td>北京航空航天大学杭州创新研究院;中山大学</td>   <td>跨链节点的风险管理方法</td>   <td>浙江省</td>   <td>CN114187001A</td>   <td>2022-03-15</td>   <td>本发明涉及一种跨链节点的风险管理方法,其中服务器节点通过跨链技术支持2种及以上的资产交换,提供跨链资产交换服务,用户节点向服务器节点发出跨链资产交换请求后,服务器节点查询策略实施模块PIM,策略实施模块PIM执行风险管理方案,检测点异常、群体异常和条件异常,并返回风险评估结果,服务器节点根据该结果判断是否应该完成此次服务,降低了跨链风险。</td>   <td>1.一种跨链节点的风险管理方法,其特征在于,包括以下步骤：S1.服务器节点通过跨链技术支持2种及以上的资产交换,提供跨链资产交换服务；S2.当用户节点向服务器节点发出跨链资产交换请求后,服务器节点查询策略实施模块PIM,策略实施模块PIM执行风险管理方案,返回风险评估结果,服务器节点根据该结果判断是否应该完成此次服务,从而拒绝该资产交换请求或者提供资产交换服务；所述的风险管理方案包括点异常管理、群体异常管理、条件异常管理。</td>   <td>G06Q20/38;G06Q20/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         虞志益;              赵贵华;              刘显平;                   彭雅婷       </td>   <td>中山大学</td>   <td>传感器感应图像降噪处理方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN114187194A</td>   <td>2022-03-15</td>   <td>本发明公开了一种传感器感应图像降噪处理方法、系统、装置及存储介质,方法包括：获取传感器感应图像的第一阵列数据,对第一阵列数据添加高斯噪声得到第二阵列数据；对第二阵列数据进行函数关系转换,得到像素电容阵列,将像素电容阵列输入到预先训练好的卷积神经网络中；通过卷积层对像素电容阵列进行卷积计算,得到传感器电荷量阵列；对传感器电荷量阵列进行数据缩放得到第三阵列数据,通过激活函数对第三阵列数据进行非线性变换得到第四阵列数据,对第四阵列数据进行归一化处理得到第五阵列数据；通过解码层对第五阵列数据进行解码处理得到降噪后的传感器感应图像。本发明提高了传感器感应图像的降噪处理效率,可广泛应用于人工智能技术领域。</td>   <td>1.一种传感器感应图像降噪处理方法,其特征在于,包括以下步骤：获取传感器感应图像的第一阵列数据,对所述第一阵列数据添加高斯噪声得到第二阵列数据；对所述第二阵列数据进行函数关系转换,得到像素电容阵列,进而将所述像素电容阵列输入到预先训练好的卷积神经网络中；通过所述卷积神经网络的卷积层对所述像素电容阵列进行卷积计算,得到传感器电荷量阵列；对所述传感器电荷量阵列进行数据缩放得到第三阵列数据,并通过所述卷积神经网络的激活函数对所述第三阵列数据进行非线性变换得到第四阵列数据,进而对所述第四阵列数据进行归一化处理得到第五阵列数据；通过所述卷积神经网络的解码层对所述第五阵列数据进行解码处理得到降噪后的传感器感应图像。</td>   <td>G06T5/00;G06N3/04;G06N3/08;G06V10/30;G06V10/82;G06V40/12;G06V40/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王兴;                   王路倩       </td>   <td>中山大学</td>   <td>一种基于光流法的结构微幅振动工作模态分析方法</td>   <td>广东省</td>   <td>CN114187330A</td>   <td>2022-03-15</td>   <td>本发明公开一种基于光流法的结构微幅振动工作模态分析方法,属于结构振动测量领域。该方法包括以下步骤：第一：采集振动过程视频；第二：利用视频选择感兴趣的区域,并提取该区域的结构轮廓点；第三：提取结构轮廓点的表观运动响应；第四：将结构轮廓点的位移时域数据转换为频域数据,并分析得出结构的模态频率的近似值；第五：放大轮廓点的振动响应；第六：辨识结构的模态频率和阻尼比。与现有技术相比,本发明的优点为：本发明的分析方法实现非接触式测量,高精度、低成本地得到结构的模态参数,同时提取结构的轮廓点作为结构的特征点,得到的振动响应数据具有代表性。</td>   <td>1.一种基于光流法的结构微幅振动工作模态分析方法,其特征在于：包括以下步骤：S1.利用录像设备对结构的振动过程进行采集,获取振动过程的视频；S2.利用图像处理程序在所述视频的第一帧上选择感兴趣的区域,并提取该感兴趣区域的结构轮廓点；S3.通过视觉方法提取结构轮廓点的表观运动响应；S4.利用快速傅里叶变换将结构轮廓点的位移时域数据转换为频域数据,分析频域数据的峰值得出结构的模态频率的近似值；S5.根据所述模态频率的近似值对轮廓点位移信号进行带通滤波,并将滤波后的信号映射到原视频中,放大轮廓点的振动响应；S6.利用结构模态参数辨识方法和滤波后的位移时域数据辨识结构的模态频率和阻尼比。</td>   <td>G06T7/269;G06T7/262;G06T7/246;G06T7/13;G06V10/25;G06V10/62;G06V20/40;G01H9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         程德斌;              刘学奎;              詹羽荣;              赵常均;              吴迪;              赵政;                   李茵       </td>   <td>中山大学肿瘤防治中心;广州智能装备研究院有限公司</td>   <td>一种基于唇语识别的人工智能发声系统及发声方法</td>   <td>广东省</td>   <td>CN108831472B</td>   <td>2022-03-11</td>   <td>本发明公开了一种基于唇语识别的人工智能发声系统及发声方法,系统包括：视频采集模块、无线发射模块、中央信号处理模块、无线接收模块、电子发声模块；首先,视频采集模块采集人体对象嘴唇区域的视频；然后,中央信号处理模块对视频信息进行处理,利用人工智能技术分析每段视频所代表的语言信息；最后,电子发声模块根据分析结果信息进行发声。本发明可应用于无喉患者的发声,与现有的电子喉相比有两个显著优点：一是系统采用基于唇语识别的发声方法,使用时不需要手握装置,给用户带来更加舒适的发声体验；二是系统采用电子发声方式进行发声,让声音听起来更加自然。</td>   <td>1.一种基于唇语识别的人工智能发声系统,其特征在于,包括：视频采集模块、无线发射模块、中央信号处理模块、无线接收模块、电子发声模块；视频采集模块,用于采集人体对象嘴唇区域的视频,其中,采用眼镜镜框上的网络摄像头,采集嘴唇区域的视频；无线发射模块,用于视频信息传输至中央信号处理模块；中央信号处理模块,利用训练好的深度神经网络模型对视频信息进行语言类别的预测,并输出分析结果；无线接收模块,用于接收中央信号处理模块的分析结果信息；电子发声器,用于将分析结果转换成声音,固定在眼镜末端；所述深度神经网络模型包括卷积模块、双向长短时记忆模块和全连接分类器,卷积模块对所述人体对象嘴唇区域的视频进行二维卷积处理,获得视频中唇部的图像特征；图像特征输入双向长短时记忆模块,获得输出结果；输出结果输入全连接分类器,获得视频所代表的语言信息分类；所述深度神经网络模型是通过如下方法训练得到的：采集人体对象嘴唇区域的视频,并对视频进行语言信息标记,形成语言标签,用Y＝{y-1,y-2,...,y-m,...,yi}来记录每个语言标签样本,每个语言标签样本对应一个或者多个语言单元,其中y-m是一个i维的One-Hot编码向量；对视频进行数据预处理,形成输入数据；将输入数据和语音标签输入深度神经网络进行训练,生成网络模型。</td>   <td>G10L15/25;G10L15/16;G10L13/02;G10L13/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张冬雨;              陈俊宏;                   陈炫坤       </td>   <td>中山大学</td>   <td>一种基于图结构数据的关系型强化学习系统及方法</td>   <td>广东省</td>   <td>CN114170088A</td>   <td>2022-03-11</td>   <td>本发明提供一种基于图结构数据的关系型强化学习系统及方法,系统将真实世界图像和不匹配的高分辨率图像编码为退化表征,随后利用对比学习处理表征间正负样本关系,得到一个能够正确提取图像退化特征的编码器,供后续的下采样网络使用。高分辨率图像经过线性下采样网络得到的低分辨率图像将带有真实世界的退化特征,最后生成的数据集输入重建网络训练完成图像超分任务。与目前基于模糊核估计的超分算法相比,本发明能够学习图像间的隐式表达不需要引入额外的退化模型和先验知识,在达到和有监督方法同样的性能时具有更好地泛化性。</td>   <td>1.一种基于图结构数据的关系型强化学习系统,其特征在于,包括：退化特征提取模块,将低分辨图像和高分辨图像输入到退化特征提取模块进行训练,得到图像退化特征编码器；下采样模块,将高分辨率图像输入到线性下采样网络,生成的低分辨率图像再和真实世界图像一同输入到图像退化特征编码器中,使得二者能够得到相同的退化特征,同时用颜色损失和像素损失函数保证下采样图像原有的基础结构信息保持不变；超分重建模块,将下采样模块生成的低分辨率-高分辨率图像数据输入超分重建网络训练,得到一个真实世界图像超分模型。</td>   <td>G06T3/40;G06K9/62;G06N3/04;G06N3/08;G06V10/774;G06V10/74;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              张云青;                   刘坤华       </td>   <td>中山大学</td>   <td>一种带雾图像修复方法</td>   <td>广东省</td>   <td>CN114170098A</td>   <td>2022-03-11</td>   <td>本发明属于计算机视觉技术领域,更具体地,涉及一种带雾图像修复方法,包括：提取带雾图像的边缘图,利用掩膜将带雾图像转换为部分信息缺失图像；将部分信息缺失的图像、边缘图以及掩膜输入边缘修复网络,输出部分信息缺失图像的修复边缘；将修复边缘与部分信息缺失图像输入图像修复网络,输出修复图像。本发明通过掩膜将带雾图像转换为部分信息缺失的图像,进而提高图像的可利用信息,再图像的边缘信息对部分缺失信息的图像进行修复,提高了带雾图像修复的鲁棒性以及修复效果。</td>   <td>1.一种带雾图像修复方法,其特征在于,包括以下步骤：S1：提取带雾图像的边缘图,利用掩膜将带雾图像转换为部分信息缺失图像；S2：将部分信息缺失的图像、边缘图以及掩膜输入边缘修复网络,输出所述部分信息缺失图像的修复边缘；S3：将所述修复边缘与所述部分信息缺失图像输入图像修复网络,输出修复图像。</td>   <td>G06T5/00;G06T7/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              郭浩文;              张晓彤;              朱裕昌;                   刘坤华       </td>   <td>中山大学</td>   <td>一种点云加速配准方法</td>   <td>广东省</td>   <td>CN114170283A</td>   <td>2022-03-11</td>   <td>本发明属于图像处理领域,更具体地,涉及一种点云加速配准方法,包括对原始点云数据进行下采样,并提取出点的第一邻域点集；利用正二十面体群对第一邻域点集进行特征提取,得到具有旋转等变性的描述子；根据旋转等变性描述子对原始点云数据中的源点云与目标点云进行配准,得到块配准关系；对块配准关系进行局部优化配准,完成源点云与目标点云的配准工作。本发明可以兼顾点云配准的速度与精确性。</td>   <td>1.一种点云加速配准方法,其特征在于,包括以下步骤：S1：对原始点云数据进行下采样,并提取出点的第一邻域点集；S2：对第一邻域点集进行特征提取,得到具有旋转等变性的描述子；S3：根据旋转等变性的描述子对原始点云数据中的源点云与原始点云数据中的目标点云进行配准,得到块配准关系；S4：对块配准关系进行局部优化配准,完成源点云与目标点云的配准工作。</td>   <td>G06T7/33;G06T7/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任传贤;                   许耿鑫       </td>   <td>中山大学</td>   <td>基于共享解码器和残差塔式结构的眼底图像血管分割方法</td>   <td>广东省</td>   <td>CN112669285B</td>   <td>2022-03-08</td>   <td>本发明公开了一种基于共享解码器和残差塔式结构的眼底图像血管分割方法,所述方法包括以下步骤：通过数据输入模块得到训练数据集图像块、测试数据集图像块；通过残差塔式模块,得到残差塔式序列；通过编码模块得到多等级语义特征；通过共享解码模块,得到多等级概率图；将多尺度标签、残差塔式序列、共享解码器得到的概率图构造成模型总损失,并利用PyTorch进行梯度优化,训练编码模块、共享解码模块中的参数；将测试数据集图像块依次输入到训练后的编码模块和共享解码模块以得到概率图,对所得概率图并进行拼接、二值化处理得到最终的分割结果。本发明解决了血管口径分布不均、眼底图像对比度较弱问题。</td>   <td>1.基于共享解码器和残差塔式结构的眼底图像血管分割方法,其特征在于,所述方法利用处理模块实现,所述处理模块包括：数据输入模块、残差塔式模块、编码模块、共享解码模块、损失模块、数据输出模块,所述方法包括以下步骤：S1：数据输入模块接收带标签的训练数据集和待分割的测试数据集,并分别进行切片预处理得到训练数据集图像块、测试数据集图像块；S2：将训练数据集图像块的标签输入残差塔式模块,并将其进行多尺度下采样,构造多尺度标签,将多尺度标签上采样到与训练数据集图像块相同的分辨率,对上采样后的多尺度标签利用异或运算生成相邻尺度标签的残差,对残差下采样输出残差塔式序列；S3：将训练数据集图像块输入至编码模块,所述编码模块利用交替串联的L个双重卷积层和(L-1)个下采样对训练数据集图像块处理,得到多等级语义特征；S4：将多等级语义特征输入至共享解码模块进行共享解码,输出(L-1)个概率图；S5：将多尺度标签、残差塔式序列、共享解码器得到的概率图构造成模型总损失,并利用PyTorch进行梯度优化,训练编码模块、共享解码模块中的参数；S6：将测试数据集图像块利用训练后的编码模块、共享解码模块进行处理得到测试数据集图像块的概率图,数据输出模块对测试数据集图像块的概率图进行拼接,拼接后的概率图进行二值化处理得到最终的分割结果。</td>   <td>G06T7/00;G06T7/10;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王梓曼;              印鉴;              刘威;              陈仲;              朱怀杰;                   邱爽       </td>   <td>中山大学</td>   <td>一种基于深度学习的多元时间序列分类方法</td>   <td>广东省</td>   <td>CN114154551A</td>   <td>2022-03-08</td>   <td>本发明提供一种基于深度学习的多元时间序列分类方法,该方法在使用BaseCNN捕获变量间交互的同时,还使用具有长距离依赖能力的LSTM来构建了一个子网络,利用其长期记忆特性,强化模型的全局时序特性,帮助模型更好的捕获全局时序特征。此外,巧妙的设计了三步训练模式,有效发挥CenterLoss、TripletLoss的作用,来处理该数据集波动性和特异性的特征,为最终的分类网络提供了良好的特征嵌入。本发明大力推动现有人工智能前交叉韧带辅助诊断的研究,具有重大临床意义与实际应用价值。</td>   <td>1.一种基于深度学习的多元时间序列分类方法,其特征在于,包括以下步骤：S1：对变量进行特征转换；S2：对进行特征转换后的变量进行全局特征提取和局部特征提取；S3：搭建分类网络；S4：对搭建分类网络进行多目标学习训练,将步骤S2中得到的特征输入训练好的分类网络,最终使得同类样本特征距离拉近,异类样本距离拉远。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄华威;              黄振毅;              彭肖文;              郑子彬;                   郭嵩       </td>   <td>中山大学</td>   <td>一种区块链分片委员会调度方法、装置、终端及存储介质</td>   <td>广东省</td>   <td>CN114154893A</td>   <td>2022-03-08</td>   <td>本申请公开了一种区块链分片委员会调度方法、装置、终端及存储介质,本申请提供的区块链分片委员会调度方法,基于马尔科夫渐进优化算法关联的调度方案,通过在预设的计时周期内,基于预设的调度目标函数,计算调度方案的效用系数,可以为最终委员会安排效用价值更优的委员会。实现最终委员会的允许交易总量最大化以及委员会内部交易的等待时延最小化从而提高了区块链吞吐量,减少了不必要的等待时延,解决了现有的基于分片技术的区块链交易存在交易效益低的技术问题。</td>   <td>1.一种区块链分片委员会调度方法,其特征在于,包括：响应于委员会调度条件的触发,开始监听委员会的动态事件。基于到达的委员会分片的数量,初始化若干个委员会分片的调度方案,并且为各个所述调度方案分别设置一个计时器,其中,每个所述调度方案以马尔科夫链的节点的形式关联；在所述计时器的计时周期内,基于预设的调度目标函数,计算当前的基准方案的效用系数,再按照所述马尔科夫链的节点组成以及状态转移概率,将所述基准方案的下一个调度方案设为新的基准方案,以便基于新的基准方案,计算所述基准方案的效用系数,其中,所述调度目标函数为将所述基准方案的允许交易总量与交易累积时间量化成效用系数的函数,所述基准方案为所述若干个调度方案中的任意一个,所述状态转移概率为根据所述新的基准方案的效用系数估计值与所述当前的基准方案的效用系数之差计算得到的；当任意一个计时器计时结束时,触发所述马尔科夫链的状态转移并广播重置信号给其它调度方案,使得所述其它调度方案均响应于所述重置信号,基于第一效用系数对各自的计时器进行刷新,以便当效用系数的计算结果未满足收敛条件时,基于刷新后的计时器重新计算各个调度方案的效用系数,其中,所述第一效用系数为根据计时结束的计时器对应的调度方案计算得到的效用系数；当效用系数的计算结果满足收敛条件时,终止监听并且不再接受新到来的委员会分片提交的区块,再根据当前的效用系数,确定最大效用系数对应的目标调度方案,以便按照目标委员会调度方案确定加入最终委员会的各个委员会分片。</td>   <td>G06Q10/06;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓一术;              李超峰;              经秉中;              李彬;                   陈浩华       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于MR图像的鼻咽癌识别及肿瘤分割方法及系统</td>   <td>广东省</td>   <td>CN114155215A</td>   <td>2022-03-08</td>   <td>本发明公开了一种基于MR图像的鼻咽癌识别及肿瘤分割方法及系统,包括：接收第一用户上传的第一图像；其中,第一图像包括MR平扫序列图像或MR增强序列图像；对第一图像进行预处理,得到第一图像对应的第二图像；将第二图像输入至肿瘤分割模型,以使肿瘤分割模型对第二图像进行区域划分,输出第二图像对应的肿瘤分割图；其中,肿瘤分割模型是根据多个第一鼻咽良恶性MR影像数据以及对应的多个带有肿瘤标记的第二鼻咽良恶性MR影像数据,对三维卷积神经网络模型训练而获得。本发明采用适用于MR平扫序列和MR增强序列的肿瘤分割模型,实现对MR图像的鼻咽癌识别及肿瘤分割,并通过分割错漏的数据对模型进行优化,提升图像的分割效果。</td>   <td>1.一种基于MR图像的鼻咽癌识别及肿瘤分割方法,其特征在于,包括：接收第一用户上传的第一图像；其中,所述第一图像包括MR平扫序列图像或MR增强序列图像；对所述第一图像进行预处理,得到所述第一图像对应的第二图像；将所述第二图像输入至肿瘤分割模型,以使所述肿瘤分割模型对所述第二图像进行区域划分,输出所述第二图像对应的肿瘤分割图；其中,所述肿瘤分割模型是根据多个第一鼻咽良恶性MR影像数据以及对应的多个带有肿瘤标记的第二鼻咽良恶性MR影像数据,对三维卷积神经网络模型训练而获得。</td>   <td>G06T7/00;G06T7/11;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈清林;              邹玥;              张冰剑;              何畅;                   舒逸聃       </td>   <td>中山大学</td>   <td>一种评价热泵节能、经济与控碳效益的方法及装置</td>   <td>广东省</td>   <td>CN114140008A</td>   <td>2022-03-04</td>   <td>本发明涉及热泵技术领域,更具体地,涉及一种评价热泵节能、经济与控碳效益的方法及装置,其中一种评价热泵节能、经济与控碳效益的方法,具体步骤如下：确定热泵的种类及热泵的工作参数；利用热泵的工作参数计算可用于驱动热泵的不同种类能源的等效电量；根据等效电量建立热泵经济学模型计算各项费用；结合各项费用建立热泵评价指标体系；根据热泵评价指标体系分别计算热泵各评价指标,综合评价热泵并选择最节能、最经济及控碳效益最优的热泵驱动方式。本发明在进行多维度地对热泵进行评价的同时,可挑选出最节能、最经济及控碳效益最优的热泵驱动方式以作为对热泵的改进方案,进而可优化资源配置,实现效益最大化。</td>   <td>1.一种评价热泵节能、经济与控碳效益的方法,其特征在于,具体步骤如下：S1：确定热泵的种类及热泵工作参数；S2：利用热泵的工作参数计算可用于驱动热泵的不同种类能源的等效电量；S3：根据等效电量建立热泵经济学模型计算各项费用；S4：结合各项费用建立热泵评价指标体系；S5：根据热泵评价指标体系分别计算热泵各评价指标,综合评价热泵并选择最节能、最经济及控碳效益最优的热泵驱动方式。</td>   <td>G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              林洪权;                   苗建明       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种基于激光雷达的高鲁棒性无人船提取水面可通行区域的方法</td>   <td>广东省</td>   <td>CN114140412A</td>   <td>2022-03-04</td>   <td>本发明涉及激光雷达传感器及无人船自动驾驶技术领域,更具体地,涉及一种基于激光雷达的高鲁棒性无人船提取水面可通行区域的方法。本发明使用激光雷达传感器获取实验环境数据,通过神经网络对点云数据进行语义分割,再对连续多帧的河岸点云数据进行融合,然后通过平滑滤波,采用图像腐蚀的方法来细化河岸点云,从而提取出特征点,后续经过排序作为控制点。接着为了减缓河岸急剧变化的情况,通过无迹卡尔曼滤波来平滑控制点。利用B样条曲线拟合平滑后的控制点,最后基于粒子滤波对提取出的水面区域进行滤噪。有效提高了提高提取水面可通行区域的鲁棒性和精度。</td>   <td>1.一种基于激光雷达的高鲁棒性无人船提取水面可通行区域的方法,其特征在于,包括以下步骤：S1.引用SqueezeSeg的深度学习网络对激光雷达采集的点云数据进行语义分割,将点云数据分为河岸、植被和桥三大类；S2.对步骤S1提取出的河岸点进行平滑滤波操作,接着通过图像处理的方式得到控制点；首先对连续多帧的河岸点云数据进行融合,然后进行平滑滤波,接着通过图像腐蚀的方法,来对河岸点进行细化,得到河岸的特征点；S3.对河岸的特征点进行排序,作为B样条拟合的控制点；S4.对排完序的控制点进行无迹卡尔曼滤波UKF平滑；S5.采用B样条拟合控制点,描绘出河岸形状的曲线；S6.通过步骤5可得到河面区域,对河面区域中的障碍物占据的区域进行标识,进行粒子滤波。</td>   <td>G06T7/00;G06T7/11;G06T5/00;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              张子权;              单云霄;                   苗建明       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种基于光电传感器的高鲁棒性海天线提取方法</td>   <td>广东省</td>   <td>CN114140484A</td>   <td>2022-03-04</td>   <td>本发明涉及一种基于光电传感器的高鲁棒性海天线提取方法。通过对垂直梯度下的图像边缘增强,过滤一些无关的竖直线段,接着对直线进行抽样取点,得到边界的候选点,同时保留了直线的方向信息,根据边界的候选点提取出候选点周围的图像区块,通过对边界点周围的图像特征信息来判断该边界为海天线或是其他对象的边缘。利用含有海天线的图像块以及只有背景信息的图像块对卷积神经网络进行训练,使得该网络能够学习到海天线特征,在对边界候选点过滤的操作中有效区分海天线图像块与背景信息图像块,在RANSAC直线拟合中,考虑了拟合直线与拟合点的欧氏距离以及直线方向与拟合点从直线中抽样所保留的方向信息,使得最终拟合的海天线精度更高,更具鲁棒性。</td>   <td>1.一种基于光电传感器的高鲁棒性海天线提取方法,其特征在于,包括以下步骤：S1.通过光电传感器提取视觉图像信息,通过Sobel算子,对图像的Sobel垂直梯度进行计算,根据梯度对图像中的场景边缘进行边缘锐化；S2.对边缘增强后的图像数据通过LSD直线检测操作,寻找图像中梯度变化较大的像素,合并相似像素,得到一系列的直线段；S3.在所提取的直线中,过滤短直线,进行抽样取候选点,同时保存的候选点具有所在直线的方向信息；S4.对图像按所设定的大小区块进行划分,得到不同区块上候选点的分布及数量,将包含候选点超过所设定数量的区块记为感兴趣区域ROI；S5.卷积神经网络作二分类任务对图像上所有感兴趣区域划分为海天线区域与背景区域,从而对存在于背景区域中的候选点进行过滤；S6.通过步骤S5得到分布在海天线附近的控制点,用RANSAC采用随机抽样验证的方法,拟合出的直线即为海天线。</td>   <td>G06T7/13;G06T7/194;G06T5/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘德昭;              邓欢;              梁雁秋;              黑子清;              李响;              陈素芳;                   李晓芸       </td>   <td>中山大学附属第三医院</td>   <td>一种安全高效的智能麻醉科药物配送收费方法及系统</td>   <td>广东省</td>   <td>CN112258109B</td>   <td>2022-03-01</td>   <td>本发明公开了一种安全高效的智能麻醉科药物配送收费方法及系统。方法包括：输入第一数据信息并进行预验证；对第一数据信息进行查找验证；在预先设置的选择调查表内选择所需要的麻醉药物名称、数量及用法并将该信息打包成第二数据信息；按照预先设置的验证模型对第二数据信息进行验证并生成一药物使用风险概率,若在设定阈值范围内则验证通过并返回带有防伪标签的流水号；根据流水号得出驱动信号；根据驱动信号控制输送机构将药物自动送出,将扣费信息发送至医院收费系统中进行费用扣除,在扣费完成后反馈扣费成功信息至打印模块；在成功将药物自动送出的同时第一数据信息和第二数据信息同步到麻醉记录系统中。本发明有利于麻醉药物的管理和收费。</td>   <td>1.一种安全高效的智能麻醉科药物配送收费方法,其特征在于,该方法包括以下步骤：通过输入模块输入第一数据信息并对第一数据信息进行预验证,在预验证通过后将该第一数据信息发送至第一验证模块,所述第一数据信息至少包括麻醉科医生的工号、密码、病人姓名和住院号；第一验证模块在验证数据库中对第一数据信息进行查找验证,若验证通过则返回验证通过信息,若验证不通过则返回验证错误信息,并将验证错误信息以信息反馈表的形式存储在反馈数据库中；通过选择模块在预先设置的选择调查表内选择所需要的麻醉药物名称、数量及用法并将该信息打包成第二数据信息,并将第二数据信息发送至第二验证模块；第二验证模块按照预先设置的验证模型对第二数据信息进行验证,生成一药物使用风险概率,若该药物使用风险概率在设定阈值范围内则验证通过并返回带有防伪标签的流水号,否则验证不通过提示存在错误；将带有防伪标签的流水号输入至预先设置的驱动模型中进行比对以得出驱动信号；通过驱动信号控制输送机构将对应数量的药物自动送出,同时通过扣费模块将扣费信息发送至医院收费系统中进行费用扣除,在扣费完成后反馈扣费成功信息至打印模块,所述扣费信息包括药物扣费金额和病人住院号；在输送机构成功将药物自动送出的同时第一数据信息和第二数据信息同步到麻醉记录系统中；所述第一验证模块在验证数据库中对第一数据信息进行查找验证的具体步骤为：对麻醉科医生的工号密码进行验证,若通过则继续执行,否则返回工号密码错误的反馈信息,并将该验证失败的工号密码存储在数据库中；对病人姓名和住院号是否存在于医院的病历系统中进行验证,若通过则对第一数据信息的验证通过并继续执行,否则返回病人姓名或住院号不存在的反馈信息,并将该验证失败的病人姓名或住院号存储在数据库中；所述预先设置的验证模型的建立步骤为：建立每一种药物名称与适用疾病种类、药物数量与病人限制用量以及用法与标准用法之间的对应关系,形成预模型；将与病人姓名和住院号对应的病人患病情况导入该预模型中以形成验证模型；在验证模型建立后,将第二数据信息中的麻醉药物名称、数量及用法导入到该验证模型中进行比对,根据该验证模型内的风险评估算法计算出该麻醉药物的药物使用风险概率。</td>   <td>G06Q10/08;G16H20/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢震宇;              梁小丹;              黄载裕;                   赵富威       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于衣服块指引及空间自适应网络的虚拟试穿方法及系统</td>   <td>广东省</td>   <td>CN114119350A</td>   <td>2022-03-01</td>   <td>本发明提供一种基于衣服块指引及空间自适应网络的虚拟试穿方法及系统,该方法基于原始人体姿态,将衣服进行分块、标准化得到标准化表示下的衣服块,再根据目标人体姿态得到变形衣服,通过条件StyleGAN2生成网络的风格生成分支预测出目标衣服掩膜,并使用该掩膜对粗糙的变形衣服进行修正,最后通过条件StyleGAN2生成网络的纹理生成分支生成准确的虚拟试穿结果,实现一种在训练阶段无需匹配数据、测试阶段无需在线优化、在保留衣服纹理等细节的基础上实现不同类别衣服互换的虚拟试穿方法。</td>   <td>1.一种基于衣服块指引及空间自适应网络的虚拟试穿方法,其特征在于,包括以下步骤：S1：对于一张原始人体图像I-s,基于其2D姿态关键点J-s,将人体图像中的衣服G-s划分为不同衣服块P-s,并对所有衣服块进行标准化处理得到标准化衣服块P-n；S2：将步骤S1得到的标准化衣服块P-n,根据目标人体图像的2D姿态关键点J-t进行变形,随后将所有变形衣服块P-t拼接在一起,得到能和目标人体姿态、体型相适应的变形衣服G-t；S3：将步骤S1得到的标准化衣服块P-n经过特征提取网络得到条件StyleGAN2生成网络的隐向量将目标人物的头部RGB图像H-t及目标人体图像的2D姿态关键点J-t作为条件StyleGAN2生成网络的输入,随后使用其风格生成分支,生成粗糙的虚拟试穿结果以及预测出目标衣服掩膜M-g；S4：将步骤S2得到的变形衣服G-t和步骤S3得到的目标衣服掩膜M-g作为空间自适应残差模块的输入,使用条件StyleGAN2生成网络的纹理生成分支,生成精确的虚拟试穿结果I′-t。</td>   <td>G06T3/00;G06T7/10;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨世鑫;              黎浩江;              陈洪波;              黄文捷;              黄乾洋;              阮广英;                   刘立志       </td>   <td>桂林电子科技大学;中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种自动生成鼻咽癌影像诊断结构化报告方法</td>   <td>广西壮族自治区</td>   <td>CN114119558A</td>   <td>2022-03-01</td>   <td>本发明公开了一种自动生成鼻咽癌影像诊断结构化报告方法,首先建立基于卷积神经网络的鼻咽癌非刚性配准模型,选取一组健康人头部MRI图像和多组含有鼻咽癌的MRI图像,预处理后,作为学习样本输入网络进行迭代训练,得到一个配准模型；预测配准到模板MRI图像的变形场,将病人的MRI图像和模板MRI图像输入训练好的配准模型,获得模型预测的变形场；将鼻咽癌ROI图像配准到模板MRI图像,用得到的变形场对相应病人的鼻咽癌ROI图像进行配准,得到以模板图像为目标的配准后鼻咽癌ROI图像；生成结构化报告,计算得到的配准后鼻咽癌ROI图像和模板MRI图像中的医学解剖结构的体素侵犯率,生成结构化报告。该方法模型精简,生成快速,准确率高,完整性好。</td>   <td>1.一种自动生成鼻咽癌影像诊断结构化报告方法,其特征在于,包括如下步骤：1)建立基于卷积神经网络的鼻咽癌非刚性配准模型,选取一组健康人头部MRI图像和多组含有鼻咽癌的MRI图像,预处理后,作为学习样本输入由卷积神经网络和空间转换模块构建的鼻咽癌非刚性配准模型中进行迭代训练,得到一个训练完成的配准模型；2)预测配准到模板MRI图像的变形场：将病人的MRI图像和模板MRI图像输入步骤1)中训练好的配准模型,进行一次非刚体图像的配准,预测出尺寸和输入相同,每个点对应像素x、y、z位移分量的变形场,获得模型预测的变形场；3)将鼻咽癌ROI图像配准到模板MRI图像,用步骤2)得到的变形场对相应病人的鼻咽癌ROI图像进行进行变形场重采样,将病人的鼻咽癌ROI图像配准到以正常人模板图像为公共域的空间,得到以模板图像为目标的配准后鼻咽癌ROI图像；4)生成结构化报告：采用图像处理的方式,分别计算步骤3)得到的配准后鼻咽癌ROI和32个特定医学解剖结构的重叠体素,再除以每个解剖结构的总体素,得到相应解剖结构的体素侵犯率,统计被侵犯解剖结构,生成结构化报告。</td>   <td>G06T7/00;G06T7/32;G06K9/62;G06N3/04;G06N3/08;G06V10/25;G06V10/774;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡杜荣;                   张鹏       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于前景超分的遥感影像目标检测方法、装置及介质</td>   <td>广东省</td>   <td>CN114119646A</td>   <td>2022-03-01</td>   <td>本发明公开了一种基于前景超分的遥感影像目标检测方法、装置及介质,本发明通过对两路不同分辨率的第一图像块集合以及第三图像块集合进行目标检测处理,能够适用于不同大小的目标的识别,大目标和小目标都能够识别,提高了实用性；而进行超分辨率重构处理的第二图像块集合事先经过前景切分处理,能够剔除遥感影像的无效背景,提取包含目标的区域,从而使得后续超分辨率重构处理时能够集中在需要关注的前景中,避免计算成本浪费在无效的背景当中,从而提高超分辨率重构处理的效率,进而提高目标检测性能,实用性高且效率高,本发明作为一种基于前景超分的遥感影像目标检测方法、装置及介质,可广泛应用于图像处理技术领域。</td>   <td>1.基于前景超分的遥感影像目标检测方法,其特征在于,包括：获取遥感影像；对所述遥感影像进行图像分块处理,得到第一图像块集合；对所述第一图像块集合进行前景切分处理,得到第二图像块集合；所述第二图像块集合包括多个包含目标的前景小切块；对所述第二图像块集合进行超分辨率重构处理,得到第三图像块集合；对所述第一图像块集合进行第一目标检测处理,以及对所述第三图像块集合进行第二目标检测处理；所述第一目标检测处理与所述第二目标检测处理用于检测不同尺寸的目标；根据第一目标检测处理结果以及第二目标检测处理结果,进行非极大值抑制,确定目标检测结果。</td>   <td>G06T7/194;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王亮;              徐秋实;              丘昌镇;              谢洪途;              张志勇;              王鲁平;                   江伟弘       </td>   <td>中山大学</td>   <td>一种无人机检测方法及装置</td>   <td>广东省</td>   <td>CN114093385A</td>   <td>2022-02-25</td>   <td>本发明公开了一种无人机检测方法及装置,其中,方法包括：实时采集待检测区域的声音信号；对所述声音信号进行预加重和短时傅里叶变化,得到频谱信号；对所述频谱信号进行梅尔倒谱分析,获取多维特征参数MFCC；将所述多维特征参数MFCC输入至预先设置的神经网络模型,以使所述神经网络模型判断所述待检测区域是否存在无人机,并输出检测结果。其中,所述神经网络模型是根据多个样本声音信号以及各样本声音信号对应的无人机检测结果,结合卷积神经网络训练得到的；所述多个样本声音信号包括多个不同类型的无人机声音信号,以此提高无人机检测的精准度。</td>   <td>1.一种无人机检测方法,其特征在于,包括：实时采集待检测区域的声音信号；依次对所述声音信号进行预加重和短时傅里叶变化,得到频谱信号；对所述频谱信号进行梅尔倒谱分析,获取多维特征参数MFCC；将所述多维特征参数MFCC输入至预先设置的神经网络模型,以使所述神经网络模型判断所述待检测区域是否存在无人机,并输出检测结果；其中,所述神经网络模型是根据多个样本声音信号以及各样本声音信号对应的无人机检测结果,结合卷积神经网络训练得到的；所述多个样本声音信号包括多个不同类型的无人机声音信号。</td>   <td>G10L25/24;G10L25/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘刚;                   陈志广       </td>   <td>中山大学</td>   <td>基于生成对抗网络的复数域语音增强方法、系统及介质</td>   <td>广东省</td>   <td>CN110739002B</td>   <td>2022-02-22</td>   <td>本发明公开了一种基于生成对抗网络的复数域语音增强方法、系统及介质,本发明复数域语音增强方法的实施步骤包括：获取带噪声的语音；将语音采用傅里叶变换后再采用笛卡尔坐标表示得到带噪声的实数谱和虚数谱；将带噪声的实数谱和虚数谱输入预先完成训练的生成对抗网络的生成器,得到去除噪声后的纯净语音的实数谱和虚数谱；将纯净语音的实数谱和虚数谱基于逆傅里叶变换生成干净的语音。本发明能够从语音信号中更好地剔除噪声、生成干净的语音,有效解决相位难以预测的问题,能够有效提高增强后语音的听觉效果,可有效提高语音识别系统在噪声环境下的语音识别准确率。</td>   <td>1.一种基于生成对抗网络的复数域语音增强方法,其特征在于实施步骤包括：1)获取带噪声的语音；2)将语音采用傅里叶变换后再采用笛卡尔坐标表示得到带噪声的实数谱R和虚数谱I；3)将带噪声的实数谱R和虚数谱I输入预先完成训练的生成对抗网络的生成器,通过生成器的编码器Encoder将实数谱R和虚数谱I组成的输入IR编码为高语义特征Encoder-(IR)；高语义特征Encoder-(IR)经过生成器的自注意力机制层self-attention输出具有全局信息的特征S-(IR)；通过生成器的解码器Decoder将特征S-(IR)解码得到增强后纯净语音的实数谱和虚数谱IR′；4)将增强后纯净语音的实数谱和虚数谱IR′基于逆傅里叶变换生成干净的语音；所述生成对抗网络的生成器为由编码器Encoder、用于提取时序特征的长短时记忆网络LSTM、用于获取全局信息的自注意力机制层self-attention和解码器Decoder构成的U型网络,所述编码器Encoder包括依次相连的用于提取局部和空间上的特征的特征提取主干网络,所述长短时记忆网络LSTM将特征提取主干网络输出的特征图提取时序特征并输出至自注意力机制层self-attention,所述自注意力机制层self-attention输出具有全局信息的特征至解码器Decoder,所述解码器Decoder由多层反卷积网络层构成；步骤3)之前还包括训练生成对抗网络的步骤,详细步骤包括：S1)获取带噪声的语音样本,并将语音采用傅里叶变换后再采用笛卡尔坐标表示得到带噪声的实数谱R和虚数谱I构成训练集；S2)从训练集中选取一个语音样本的实数谱R和虚数谱I,通过生成器的编码器Encoder将实数谱R和虚数谱I组成的输入IR编码为高语义特征Encoder-(IR)；S3)高语义特征Encoder-(IR)经过自注意力机制层self-attention输出具有全局信息的特征S-(IR)；S4)通过解码器Decoder将特征S-(IR)解码得到增强后语音的实数谱和虚数谱IR′；S5)将纯净语音的实数谱虚数谱IR～C和IR′分别划分由大到小的指定的三个粒度的实数谱和虚数谱：和IR′-0,和IR′-1,和IR′-2；S6)通过多粒度的判别器D-0,D-1,D-2将每个粒度的判定为真,IR′-i为假,其中i＝0,1,2；S7)计算总的损失函数的值,依据反向传播跟新模型所有需要训练的参数；S8)判断是否满足预设的结束训练条件,如果满足预设的结束训练条件则判定训练结束并退出；否则,跳转执行步骤S2)继续进行训练。</td>   <td>G10L21/0208;G10L25/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         巫海维;                   张东       </td>   <td>中山大学</td>   <td>一种基于深度学习的鲸鱼活动音频分类方法</td>   <td>广东省</td>   <td>CN110827837B</td>   <td>2022-02-22</td>   <td>本发明涉及一种基于深度学习的鲸鱼活动音频分类方法。包括,1.采集水底语音数据；2.对采集的语音数据进行数据扩充；3.对训练数据进行声学特征提取,将一维的语音序列转换成二维的声学特征序列；4.利用声学特征,分别训练两组神经网络模型：基于帧的神经网络系统和基于语音片段的卷积神经网络系统；5.训练完基于帧的神经网络系统之后,提取基于帧的得分输出并做平均值处理,得到得分A；对于基于语音片段的卷积神经网络系统,利用该模型提取深度特征,用深度特征训练后端分类器,由后端分类器输出得分B；6.将得分A与得分B进行融合,得出最终的判断结果。本发明使用深度学习算法,能够得到更高的识别准确率,在具体应用中能够更加鲁棒,稳定。</td>   <td>1.一种基于深度学习的鲸鱼活动音频分类方法,其特征在于,包括以下步骤：S1.采集水底语音数据；S2.对采集的语音数据进行数据扩充,增加训练数据量；S3.对扩充后的训练数据进行声学特征提取,将一维的语音序列转换成二维的声学特征序列；S4.利用S3步骤的声学特征,分别训练两组神经网络模型,分别是基于帧的神经网络系统和基于语音片段的卷积神经网络系统；S5.训练完基于帧的神经网络系统之后,判断出音频信号是否为鲸鱼叫声,提取基于帧的得分输出并做平均值处理,得到一组得分A；对于基于语音片段的卷积神经网络系统,训练卷积神经网络之后,利用该模型提取深度特征,用深度特征训练后端分类器,判断出音频信号是否为鲸鱼叫声,由后端分类器输出得分B；S6.将得分A与得分B进行融合,得出最终的判断结果；对于基于帧的神经网络系统的训练,在训练之前,对提取的声学特征进行前后若干帧的拼接,从而增加上下文信息；之后,将生成的新的帧级别特征输入到网络中,采用时延神经网络结构作为帧级别网络模型；其中,所述的帧级别网络模型的计算流程包括：S511.输入的声学特征序列首先会被依次送入全连接神经网络当中,输出一个新的序列特征；S512.在新的特征上,按照设定的间隔,选取前后帧,与当前的帧的特征进行拼接；S513.将新生成的特征输入下一层全连接网络当中,输出新的序列特征；S514.逐渐扩大跳帧的间隔,从1扩大到3,再扩大到5,重复步骤S512和S513；S515.在最后一层全连接中,输出二维的得分结果,分别代表是否存在鲸鱼叫声；所述的基于语音片段的卷积神经网络系统,流程主要包括训练阶段和测试阶段；其中,训练阶段包括：S5211.进行数据扩充,提取语音声学特征；S5212.训练深度卷积神经网络；网络由三部分构成,第一部分是深度卷积结构,第二部分是编码层模块,第三部分是全连接层分类模块；S5213.训练完神经网络之后,使用神经网络提取深度特征,对每一个通道的语音数据都提取深度卷积特征,然后对特征做平均融合,作为一整个信号的表示；融合的方法可以用在特征层面上,或者后端分类器得分上；S5214.使用深度特征训练后端分类器；测试阶段包括：S5221.提取测试语音的声学特征；S5222.使用训练阶段S5212步骤中得到的网络提取深度特征；S5223.使用训练阶段S5214步骤中得到的后端分类器获取得分。</td>   <td>G10L17/26;G10L25/18;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              李翔;              吴岸聪;              曹玫;                   游瑾洁       </td>   <td>中山大学</td>   <td>基于多尺度联合学习的无交叠视域摄像头之间的低分辨率行人匹配方法</td>   <td>广东省</td>   <td>CN105404871B</td>   <td>2019-01-11</td>   <td>本发明公开了一种基于多尺度联合学习的无交叠视域摄像头之间的低分辨率行人匹配方法,包括以下步骤：(1)从原始的行人训练数据中分别生成多个不同尺度的行人训练数据；(2)提出不同尺度上同一行人差异最小化准则；(3)建立多尺度联合学习模型；(4)实现不同摄像头间低分辨率行人的匹配。本发明采用多个不同的图像尺度来有效地保持低分辨率行人的表观信息,进一步利用不同尺度上同一行人差异最小化准则来传递行人在不同分辨率下的判别信息,在此基础上建立多尺度联合学习模型,学习每个尺度的最优距离度量。本发明的方法相比于直接将行人图像缩放到单一尺度建模的现有行人匹配方法,能够获得更高的不同摄像头之间低分辨行人的匹配准确率。</td>   <td>1.一种基于多尺度联合学习的无交叠视域摄像头之间的低分辨率行人匹配方法,其特征在于包括以下步骤：(1)生成多个不同图像尺度的行人训练数据；(2)提出不同尺度上同一行人差异最小化准则；(3)建立多尺度联合学习模型；(4)实现不同摄像头间低分辨率行人的匹配；所述步骤(1)中,不同尺度的行人训练数据是通过将原始分辨率各异的行人训练图像同时缩放到多个不同的尺度得到的；步骤(1)具体为：行人训练图像被缩放到两个尺度,即一个标准尺度和一个其他的小尺度,对于一个行人训练集,通过缩放图像可以分别得到一个标准尺度的行人训练集和一个小尺度的行人训练集其中和分别表示同一张行人图像调整到标准尺度和小尺度后提取的特征向量,其所属的行人/类别记为y-i,N是训练集的行人图像样本总数,和分别表示行人图像调整到标准尺度和小尺度提取的特征向量空间,d-h和d-s分别表示行人图像调整到标准尺度和小尺度后提取的特征向量维度。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              吕硕;              江倩殷;              罗东华;              袁敏贤;                   余志       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种基于选择性搜索算法的车标检测识别方法及系统</td>   <td>广东省</td>   <td>CN106529424B</td>   <td>2019-01-04</td>   <td>本发明公开了一种基于选择性搜索算法的车标检测识别方法及系统,方法包括：对原始车辆图像进行车牌定位,获取车牌位置；根据车牌位置、车牌与车标空间位置关系和车窗边缘信息在原始车辆图像中对车标进行粗定位,得到车标粗定位图像；基于车辆中轴线在车标粗定位图像中选取车标候选区；采用选择性搜索算法对车标候选区进行目标定位,得到定位目标集；采用线性约束编码算法训练车标判断分类器来对定位目标集进行车标的判别,得到车标的位置；采用线性约束编码算法训练多类车标识别分类器来对车标进行具体的类型识别,得到车标识别结果。本发明具有适用性广、鲁棒性强和检测速度快的优点,可广泛应用于图像处理领域。</td>   <td>1.一种基于选择性搜索算法的车标检测识别方法,其特征在于：包括以下步骤：对原始车辆图像进行车牌定位,获取车牌位置；根据车牌位置、车牌与车标空间位置关系和车窗边缘信息在原始车辆图像中对车标进行粗定位,得到车标粗定位图像；基于车辆中轴线在车标粗定位图像中选取车标候选区；采用选择性搜索算法对车标候选区进行目标定位,得到定位目标集,所述选择性搜索算法综合根据颜色相似度、纹理相似度、大小相似度和吻合度相似度来进行区域合并；采用线性约束编码算法训练车标判断分类器来对定位目标集进行车标的判别,得到车标的位置；采用线性约束编码算法训练多类车标识别分类器来对车标进行具体的类型识别,得到车标识别结果；所述采用线性约束编码算法训练车标判断分类器来对定位目标集进行车标的判别,得到车标的位置这一步骤,其包括：将样本集的样本划分为正样本和负样本,其中,正样本包括单个字符样本、样本集中的小型车样本和样本集中的大型车标样本,负样本为样本集中大小随机选取的且与车标重合度小于20％的样本；以正样本作为训练样本,采用线性约束编码分类器进行迭代训练直至收敛,最终训练出车标判断分类器,其中,迭代训练过程在每次完成训练后会将车标判断分类器中错分为负样本的样本加入训练样本中形成新训练样本集,然后再以新训练样本集重新进行训练；根据训练出的车标判断分类器对定位目标集进行车标的判别,得到车标的位置。</td>   <td>G06K9/00;G06K9/32;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   陈春迎       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种多特征融合的人群密度估计方法</td>   <td>广东省</td>   <td>CN105184245B</td>   <td>2018-12-21</td>   <td>本发明公开一种多特征融合的人群密度估计方法,包括：提取基于KLT跟踪的轨迹段数目特征；对现存的人群密度估计算法的特征,包括GLCM纹理分析特征、像素统计特征,再和轨迹段数目特征在不同场景下进行实验对比,找到对人群密度估计最适合的特征组合：GLCM纹理特征+像素统计特征+轨迹段数目特征。提取出训练集视频帧的轨迹段数目特征、像素统计特征和纹理特征,送入线性回归模型中训练,得到的模型,计算出测试视频帧中行人的数目。本发明将基于KLT跟踪的轨迹段数目作为人群密度估计的特征,并将其应用到线性回归模型,和现有的基于个体目标的人群密度估计算法相比,复杂度低,准确率高。</td>   <td>1.一种多特征融合的人群密度估计方法,其特征在于,包括以下步骤：(1)视频采集；(2)特征的提取；采用KLT跟踪法对采集的视频中的个体目标进行跟踪,计算出基于KLT跟踪的轨迹段数目特征；对采集的视频进行运动信息前景的检测,提取边缘信息,计算出视频帧的前景分割区域特征、GLCM纹理分析特征、LBP纹理特征、像素统计特征,其中所述的KLT跟踪法,是用仿射运动建立个体目标运动模型,即J(AX+d)＝I(X),其中A是变形矩阵,d是偏移向量,且A＝I+D,I是单位矩阵,D为零矩阵,即A＝I,J(X+d)＝I(X)；将X视为二维空间的像素点的坐标,I(X)是像素点X的像素值,若干个像素点的像素值组成一幅图像；J(●X)是I(X)通过AX+d变换后像素点X的像素值,再最小化式子ε＝∫∫-W[J(AX+d)-I(X)]～2ω(X)dX,得到提取轨迹段所用模型Zd＝e,W是特征窗口,ω(X)是加权函数,其中：                                                      e为原图像I(X)和变换后图像J(X)在窗口W范围内像素值的加权误差,g(X)为均图像的梯度向量,g-x为均图像对x的偏导数,g-y为均图像对y的偏导数,Z为均图像的梯度矩阵,采用模型Zd＝e计算出了每一个特征窗口中心点的位移d,得到了一系列的轨迹段,计算出轨迹段的数目,所述像素点坐标；(3)将轨迹段数目特征、像素统计特征和GLCM纹理分析特征融合,应用到线性回归模型中进行训练得到训练模型；(4)根据训练模型,检测出待测视频帧中行人的数目。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林谋广;              吴育滨;              郑万山;              黄钊鹏;              刘锦龙;                   刘洋       </td>   <td>中山大学</td>   <td>一种基于可穿戴设备的唇语识别方法及系统</td>   <td>广东省</td>   <td>CN105488524B</td>   <td>2018-12-21</td>   <td>本发明公开了一种基于可穿戴设备的唇语识别方法及系统,其中,该方法包括：向用户面部投射结构光,通过结构光接收器获取面部反射的结构光信息；对所述面部反射的结构信息进行过滤处理,获取所述用户嘴部运动时的嘴部反射的结构光信息；对所述嘴部反射的结构光信息进行分段,获取分段结构光信息,并根据分段结构光信息,提取所述分段结构光信息的三维模型特征；比较所述分段结构光信息的三维模型特征与样本三维模型特征的相似度,获取相似度最高的三维模型特征所对应的文字信息或语音信息。采用本发明实施例,可快捷、准确的获取到用户唇语的文字信息或语音信息。</td>   <td>1.一种基于可穿戴设备的唇语识别方法,其特征在于,所述方法包括：向用户面部投射结构光,通过结构光接收器获取面部反射的结构光信息；对面部反射的结构信息进行过滤处理,获取所述用户嘴部运动时的嘴部反射的结构光信息；对所述嘴部反射的结构光信息进行分段,获取分段结构光信息,并根据分段结构光信息,提取所述分段结构光信息的三维模型特征；比较所述分段结构光信息的三维模型特征与样本三维模型特征的相似度,获取相似度最高的三维模型特征所对应的文字信息或语音信息。</td>   <td>G06K9/62;G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张木水;                   简钱华       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于粒子群的系统级封装BGA电源地引脚分布优化方法</td>   <td>广东省</td>   <td>CN105574237B</td>   <td>2018-12-21</td>   <td>本发明涉及一种基于粒子群的系统级封装BGA电源地引脚分布优化方法,包括以下步骤：S1.对电源引脚、地引脚、信号引脚进行编码处理,分别使1、2、0表示电源引脚、地引脚、信号引脚,然后使用矩阵来表示BGA中电源引脚、地引脚、信号引脚的分布；S2.对粒子群算法进行种群随机初始化处理；S3.设定粒子数、适应度函数,并令迭代次数t=0；S4.初始化每个粒子的速度和位置；S5.使用适应度函数计算每个粒子的适应度值；S6.求出每个粒子的个体最优和该次迭代的全局最优；S7.对每个粒子进行速度更新和位置更新；S8.判断t是否大于k,若是则执行步骤S9,否则执行步骤S5；S9.将全局最优作为最优解进行输出。</td>   <td>1.一种基于粒子群的系统级封装BGA电源地引脚分布优化方法,其特征在于：包括以下步骤：S1.对电源引脚、地引脚、信号引脚进行编码处理,分别使1、2、0表示电源引脚、地引脚、信号引脚,然后使用矩阵来表示BGA中电源引脚、地引脚、信号引脚的分布；S2.对粒子群算法进行种群随机初始化处理；S3.设定粒子数、适应度函数,设定最大迭代次数为k,并令迭代次数t＝0,其中所述粒子为电源引脚、地引脚或信号引脚,粒子数与BGA的电源引脚、地引脚、信号引脚的总数相等；S4.初始化每个粒子的速度和位置；S5.使用适应度函数计算每个粒子的适应度值；S6.求出每个粒子的个体最优和该次迭代的全局最优；S7.对每个粒子按照个体最优和全局最优进行速度更新和位置更新；S8.判断t是否大于k,若是则执行步骤S9,否则执行步骤S5；S9.将全局最优作为最优解进行输出。</td>   <td>G06F17/50;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张木水;                   谭天琪       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于遗传算法的大规模BGA封装最优引脚分布生成方法</td>   <td>广东省</td>   <td>CN105608257B</td>   <td>2018-12-21</td>   <td>本发明涉及一种基于遗传算法的大规模BGA封装最优引脚分布生成方法,该方法不仅有效地解决随着更多的功能函数被整合到信号分装中,大量的I/O引脚,P/G引脚必须容纳在信号封装甚至更小的体积内这一问题,而且还能大规模自动生出最优的引脚分布,以减少信号完整性的问题。</td>   <td>1.一种基于遗传算法的大规模BGA封装最优引脚分布生成方法,其特征在于：包括以下步骤：S1.对于引脚数目为M*N的BGA封装,其引脚分布使用M*N的矩阵D来表示,其中使用1、2、0分别来表示电源信号引脚、地信号引脚和空信号引脚；S2.选定K个封装方案,并使用M*N的矩阵分别来表示其引脚分布,K个封装方案构成种群Chrom,封装方案作为种群Chrom中的个体,此时令迭代次数t＝0；S3.将含有K个个体的种群Chrom随机排列；S4.将种群Chrom的个体的适应度值进行评价检测；S5.将种群Chrom中的个体根据其适应度值进行两两比较,将两两比较中适应度较好的个体放入WinChrom的容器中,WinChrom的容器共有N个；S6.使WinChrom中的个体进行匹配交叉,匹配交叉的位置由随机数m1、m2、n1、n2确定,若m1小于m2,则个体矩阵的交叉区域的行位于m1+1到m2之间,若m1大于m2,则个体矩阵的交叉区域的行位于1到m2或是m1+1到K之间,n1、n2用于确定交叉区域的列,其原理同m1、m2；由此可确认匹配交叉区域；S7.判断交叉后的个体相对应的电源信号引脚、地信号引脚数目是否发生了改变,若否则继续执行步骤S8；S8.使WinChrom中的个体进行变异,首先计算变异概率p-m：                  其中f-(Max)、为分别种群WinChrom中最适应个体的适应值、种群平均P应值、变异个体的适应值；S9.在变异概率内,判断变异个体的电源信号引脚、地信号引脚是否等于变异个体的总引脚数,若是则将某个电源信号引脚与地信号引脚互换位置,若否,则利用rand函数在(0,1)之间随机产生一个数,若此数大于Pm,则将个体中某个电源信号引脚与地信号引脚互换位置,否则将个体中某个电源信号引脚或者地信号引脚与空信号引脚交换位置；S10.N个WinChrom中的个体进行交叉匹配、变异后产生(K-N)个WinChrom后代,将N个WinChrom中的个体和(K-N)个WinChrom后代组合,形成新一代种群NewChrom；S11.计算种群NewChrom中各个个体的适应值,选择适应值最好的个体为BestInd；S12.令t＝t+1,将种群NewChrom作为初始种群重复执行步骤S3～S11直至t&gt;k；S13.保存每次迭代的最优个体BestInd到容器BestInd-Temp中,通过比较分析BestInd-Temp中每个BestInd的适应值得到最理想的引脚分配。</td>   <td>G06F17/50;G06N3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孟思明;                   罗笑南       </td>   <td>中山大学</td>   <td>一种基于LCV模型的图像轮廓编码方法及系统</td>   <td>广东省</td>   <td>CN105787972B</td>   <td>2018-12-21</td>   <td>本发明公开了一种基于LCV模型的图像轮廓编码方法及系统,其中所述方法包括：采用LCV模型对目标图像进行轮廓分割处理,获取所述目标图像的轮廓坐标信息；根据所述轮廓坐标信息进行轮廓矩阵构建处理,获取所述目标图像的轮廓矩阵；对所述轮廓矩阵进行编码处理,获取所述目标图像的轮廓编码矩阵；对所述轮廓编码矩阵进行二值化处理,获取二值化轮廓编码矩阵；对所述二值化轮廓编码矩阵进行排列编码,获取所述轮廓对应的编码链；在本发明实施例中,通过轮廓坐标提取、轮廓矩阵构建、编码、二值化和排列编码处理,从多角度的提取挖掘出图像边界轮廓的信息,得到的图像特征信息较强,在外界存在一定的干扰下也能保持着原图像特定的特征信息。</td>   <td>1.一种基于LCV模型的图像轮廓编码方法,其特征在于,所述方法包括：采用LCV模型对目标图像进行轮廓分割处理,获取所述目标图像的轮廓坐标信息；根据所述轮廓坐标信息进行轮廓矩阵构建处理,获取所述目标图像的轮廓矩阵；对所述轮廓矩阵进行编码处理,获取所述目标图像的轮廓编码矩阵；对所述轮廓编码矩阵进行二值化处理,获取二值化轮廓编码矩阵；对所述二值化轮廓编码矩阵进行排列编码,获取所述轮廓对应的编码链。</td>   <td>G06T9/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄敏;              钮中铭;              张学强;                   郑健       </td>   <td>中山大学</td>   <td>一种基于树结构的仿真路网数据管理方法</td>   <td>广东省</td>   <td>CN105205247B</td>   <td>2018-12-18</td>   <td>本发明涉及一种基于树结构的仿真路网数据管理方法,包括提供一种时空路网的数据模型：构建交通仿真中的路网数据模型,从仿真路网编辑过程中抽象出路网编辑操作；由一系列编辑操作形成路网阶段节点,构建一个以基态路网为根结点的路网阶段树,提供构建用户指定版本路网数据方法；定义用于组织同一个路网衍生出的不同基态路网的路网树,路网树上的每一个路网结点唯一对应一棵路网阶段树,并提供路网阶段树上的阶段分支到路网树节点的压缩方法,以降低由于路网阶段树的深度过大带来效率损失。本方法能够给用户快速、准确的提供指定版本的数据,使得路网数据得到系统的、有序的管理。</td>   <td>1.一种基于树结构的仿真路网数据管理方法,其特征在于,包括：1)构建时空路网数据模型；2)基于时空路网数据模型对路网进行路网编辑,为用户的每个路网构建一个路网阶段树,提供构建用户指定版本路网方法；3)压缩阶段树上一条路径到基态,构建路网的子路网,建立路网树,用路网树组织路网间的父子关系；其中,所述步骤1)构建时空网数据模型,并定义时空中的路网元素；所述时空路网数据模型用N(G-p,G-l)表示,其中G-p表示路网的物理拓扑,G-l表示路网的逻辑拓扑；路网的物理拓扑用有向图G-p＝(V,L)表示,其中V＝{v-i}为子路段节点集,v-i是子路段节点,表示交通组织中断处；L＝{l-(ij)|l-(ij)＝(v-i,v-j)}为子路段集,l-(ij)是子路段节点v-i和v-j之间的子路段；路网的逻辑拓扑用G-l＝(A,La,C-(La))表示,其中A＝{a-(ij)＝&lt;v-i,v-j&gt;|v-i,v-j∈V}为有向子路段集,a-(ij)为有向子路段,方向代表从子路段节点v-i到v-j的交通流向；La＝{lane}为车道集,lane表示车道,车道是位于有向子路段中,规定车辆运行行为的最小道路单元；C-(La)＝{c-i＝(lane-f,lane-t)|lane-f,lane-t∈La}表示车道连接器,c-i表示车辆从车道lane-f到lane-t的通行是允许的；所述路网元素是指交通路网N中某个道路单元(V,L,A,La,C-(La))的一个具体的要素(v-i,l-(ij),a-(ij),lane,c-i),elmt-h(t-c,t-d)描述时空中的路网元素h在时间区间&lt;t-c,t-d&gt;内的状态,其中h为元素在所属的道路单元中的编号；t-c为elmt-h状态创建时刻,t-d为状态消失时刻,在&lt;t-c,t-d&gt;时间内elmt-h几何状态和物理属性保持不变；各时刻的路网是路网元素按物理、逻辑拓扑有机组织起来的；其中,所述步骤2)基于时空路网数据模型对路网进行路网编辑,其中路网编辑是指在某时刻由于绘制仿真路网的操作引起的路网元素变化,该变化包括新建元素,删除元素以及更新元素,一个路网操作记为O(t)＝(add(t),dlt(t),mdf(t)),其中add(t)＝{elmt-h(t-c,t-d)|t-c＝t}表示在t时刻由操作创建的路网元素集；dlt(t)＝{elmt-h(t-c,t-d)|t-d＝t}表示在t时刻由操作删除的路网元素集；mdf(t)＝{elmt-h(t-c,t-d)|t-c＝t}∪{elmt-h(t-c,t-d)|t-d＝t}表示在t时刻由操作更新的路网元素集,分解为t时刻的删除要素集和创建要素集。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘荻;              刘冶;              王砚文;              陈宇恒;              印鉴;                   马朔       </td>   <td>中山大学;火烈鸟网络(广州)股份有限公司</td>   <td>一种消息过滤的方法及装置</td>   <td>广东省</td>   <td>CN105955951B</td>   <td>2018-12-11</td>   <td>本发明涉及一种消息过滤的方法,利用贝叶斯分类器模型计算消息为不良消息的概率,根据所述不良消息的概率判断消息的性质,该消息的性质包括正常消息、不良消息和可疑消息,直接过滤掉不良消息,保留正常消息和可疑消息,再利用基于语义的深度学习模型进一步分类,确定消息为正常消息或者不良消息。相对于现有技能,本发明能够自动学习,定时更新训练集并且识别近义词,节省大量人工标注的成本,具有更好的准确率、健壮性和稳定性。另外,本发明还提供了一种消息过滤的实现装置。</td>   <td>1.一种消息过滤的方法,其特征在于：包括步骤：S1：利用贝叶斯分类器模型计算消息为不良消息的概率；S2：根据所述不良消息的概率判断消息的性质,该消息的性质包括正常消息、不良消息和可疑消息,直接过滤掉不良消息,保留正常消息和可疑消息；S3：对所述性质为正常的和可疑的消息,利用基于语义的深度学习模型进一步分类,确定消息为正常消息或者不良消息；所述步骤S3进一步包括：S31：对训练集中的消息进行语义聚类,获得语料库中所有词的词向量；S32：使用聚类方法,根据步骤S31所得的词向量将语料库中的所有词分成k类；S33：根据步骤S32所得的词的类别,获得k维消息向量,并训练出消息分类模型；S34：将所述正常消息和可疑消息映射产生对应的k维消息向量,并将该消息向量输入步骤S33训练出的消息回归模型,根据回归分数得出正常消息或者不良消息的分类结果。</td>   <td>G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              王新文;              严聪;                   印鉴       </td>   <td>中山大学;广州智海纵横信息科技有限公司;广州中大南沙科技创新产业园有限公司</td>   <td>一种基于网格多级精确度递进式比划识别方法</td>   <td>广东省</td>   <td>CN104537343B</td>   <td>2018-11-16</td>   <td>本发明提供了一种基于网格多级精确度递进式比划识别方法,该方法采集若干个不同的比划并分别对其依次进行重采样规范化、旋转规范化、缩放规范化、平移规范化处理,对处理后的比划进行若干级精确度下拓扑特征向量的提取,最后将原始采集的比划和其特征向量作为一个比划模板存入模板库；用户输入比划A,对比划A依次进行重采样规范化、旋转规范化、缩放规范化、平移规范化处理得到比划A*,对比划A*进行若干级精确度下拓扑特征向量的提取；计算模板库中与提取出的比划A的拓扑特征向量差距最小的比划模板,并将其作为输出识别结果。</td>   <td>1.一种基于网格多级精确度递进式比划识别方法,其特征在于,包括以下步骤:S1：建立比划模板库：采集若干个不同的比划并分别对其依次进行重采样规范化、旋转规范化、缩放规范化、平移规范化处理,分别在若干级精确度下对处理后的比划进行拓扑特征向量的提取,最后将原始采集的比划和其特征向量作为一个比划模板来建立比划模板库,其中采集的比划经缩放规范化后被一标准包围框所包围,将该标准包围框分割为若干子网格,标准包围框被分割为不同的子网格数即表示该识别方法的不同级别的精确度,子网格数越多该方法的精确度级别越高；S2：提取待识别的比划特征向量:对用户输入的比划A依次进行重采样规范化、旋转规范化、缩放规范化、平移规范化处理得到比划A*,对比划A*进行若干级精确度下拓扑特征向量的提取,其中提取比划的特征向量的过程如下：S21：令最高精确度下标准包围框被细分为m～2个紧密的子网格,Grid[i]口]代表在行优先顺序下的第(i-1)*m+j个子网格,0≤i≤m,0≤j≤m,将任一网格Gridl[i][j]细分为左上、左下、右上、右下四个区域,同时将比划A*进入该网格的点记为入点a,将比划A*离开该网格的点记为出点b,设置比划A*在该子网格处特征值flag-(ij)如下：S211：入点a和出点b均不在该网格中,则A*在该网格的特征值为0x00；S212：入点a和出点b中一点位于左上,一点位于右上,则A*在该网格的特征值为0x0l；S213：入点a和出点b中一点位于左下,一点位于右下,则A*在该网格的特征值为0x02；S214：入点a和出点b中一点位于左上,一点位于左下,则A*在该网格的特征值为0x04；S215：入点a和出点b中一点位于右上,一点位于右下,则A*在该网格的特征值为0x08；S216：入点a和出点b中一点位于左上,一点位于右下,则A*在该网格的特征值为0x10；S217：入点a和出点b中一点位于左下,一点位于右上,则A*在该网格的特征值为0x20；S218：入点a和出点b中一点位于左上,另一点不存在或也位于左上,则A*在该网格的特征值为0x40；S219：入点a和出点b中一点位于左下,另一点不存在或也位于左下,则A*在该网格的特征值为0x80；S220：入点a和出点b中一点位于右上,另一点不存在或也位于右上,则A*在该网格的特征值为0xl00；S221：入点a和出点b中一点位于右下,另一点不存在或也位于右下,则A*在该网格的特征值为0x200；若比划A*的轨迹不止一次跨越一网格,则该格的最后特征值flag-(ij)为对多次跨越特征值间取逻辑或操作所得值：flag-(ij)＝特征值1|特征值2|特征值3……特征值n,其中n为比划轨迹跨越此网格的次数；因此比划A*在最高精度下的特征向量β-1,为β-1＝(flag-(00),……,flag-(0(m-1)),flag-((m-1)0),flag-((m-1)(m-1)))；S22：将网格精确度重复降低数次并分别提取出此精度下比划A*的拓扑特征向量,此操作迭代n次,最后该比划A的特征向量为:β-A＝β-(A*)＝(β-1,…,β-i,…,β-n)；S3：计算得到模板库中与提取出的比划A的拓扑特征向量差距最小的比划模板,并将其作为输出识别结果。</td>   <td>G06K9/00;G06K9/68</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杜晓荣;              徐泳钧;              平淑文;              张永;                   武汇岳       </td>   <td>中山大学</td>   <td>一种卡通肖像自动生成方法</td>   <td>广东省</td>   <td>CN104933742B</td>   <td>2018-10-23</td>   <td>本发明的卡通肖像自动生成方法,将人脸五官描述向量与各向量对应的特征向量于卡通素材库中相应的向量进行匹配,取相似度高的卡通素材作为匹配结果,将其正确组合得到卡通肖像,人脸的卡通效果逼真,生动；该方法计算简单,便于推广应用。</td>   <td>1.一种卡通肖像自动生成方法,其特征在于:首先直接使用FACE++开源库识别人脸特征点,将该人脸特征点集旋转并归一化后,结合各五官形状特性,为每个五官定义了多个特征变量,将其正确组织为五官描述向量然后利用该五官描述向量与卡通五官素材库中的各素材的描述向量进行相似度计算,选择差异最小的素材图片,将获取到的各卡通五官图片绘制在正确位置,即可自动生成卡通肖像；其中,人脸五官描述向量包括多个人脸五官特征变量,即：                  人脸五官特征变量eye-end-direction为两眼睛之间的角度,即为经过左眼睛的左眼角特征点和右眼角特征点的直线与右眼睛的左眼角特征点和右眼角特征点的直线之间的角度；人脸五官特征变量eye-top-angle为眼睛上眼睑角度,即为经过左眼睛的上眼睑顶端特征点及左眼睛的左眼角特征点的直线和经过左眼晴的上眼睑顶端特征点及左眼睛的右眼角特征点眼睛上眼睑角度的直线之间的角度；人脸五官特征变量eye-bottom-angle为眼睛下眼睑角度,即为经过左眼睛的下眼睑底端特征点及左眼睛的左眼角特征点的直线和经过左眼睛的下眼睑底端特征点及左眼睛的右眼角特征点眼睛上眼睑角度的直线之间的角度；人脸五官特征变量eye-size-width为眼睛的宽度,即为左眼睛的左眼角特征点、右眼睛的右眼角特征点间的距离减去右眼睛的左眼角特征点、左眼睛的右眼角特征点间的距离；人脸五官特征变量eye-size-height为眼睛的高度,即为左眼睛和右眼睛的上眼睑顶端特征点连线的中间点P到左眼睛和右眼睛的下眼睑底端特征点连线的距离；人脸五官特征变量eye-corner-distance为两眼之间内眼角之间的距离,即为左眼睛的右眼角特征点和右眼睛的左眼角特征点间的距离；人脸五官特征变量nose-size-length为鼻子的高度,即为鼻尖控制点到鼻梁左右最高点连线的距离；人脸五官特征变量nose-size-width为鼻子的宽度,即为鼻子轮廓左右最宽控制点间的距离；人脸五官特征变量nose-tip-angle为鼻尖角度,即为经过鼻子轮廓左最宽控制点和鼻尖控制点的直线与经过鼻子轮廓右最宽控制点和鼻尖控制点的直线之间的角度；人脸五官特征变量nose-contour-angle为鼻子下轮廓的角度,即为经过鼻子下轮廓最左控制点和鼻尖控制点的直线与经过鼻子下轮廓最右控制点和鼻尖控制点的直线之间的角度；人脸五官特征变量mouth-smile-direction为嘴巴微笑方向,即为嘴巴左嘴角控制点与嘴巴底端控制点的连线与经过嘴巴底端控制点的垂直直线间的夹角与嘴巴右嘴角控制点与嘴巴底端控制点的连线与经过嘴巴底端控制点的垂直直线间的夹角之间的差值；人脸五官特征变量mouth-size-width为嘴巴宽度,即为嘴巴左嘴角控制点与嘴巴右嘴角控制点间的距离；人脸五官特征变量mouth-smile-angle为嘴巴微笑角度,即为经过嘴巴左嘴角控制点和嘴巴下嘴唇顶端控制点的直线与经过嘴巴右嘴角控制点和嘴巴下嘴唇顶端控制点的直线之间的夹角；人脸五官特征变量eyebrow-size-width为眉毛长度,即为左右眉毛眉尾控制点、间的距离减去眉心控制点、间的距离的差值；人脸五官特征变量eyebrow-size-height为眉毛粗细,即为左右眉毛顶端控制点、连线中点P到左右眉毛底端控制点、连线的距离；人脸五官特征变量eyebrow-upper-angle-a为左眉毛上轮廓弧度,即为左眉毛上轮廓左侧控制点与左侧控制点的连线和上轮廓左侧控制点与右侧控制点的连线间的夹角；人脸五官特征变量eyebrow-upper-angle-b为右眉毛上轮廓弧度,即为右眉毛上轮廓居中控制点与左侧控制点的连线和上轮廓居中控制点与右侧控制点的连线间的夹角；人脸五官特征变量eyebrow-lower-angle-a为左眉毛下轮廓弧度,即为左眉毛下轮廓左侧控制点与左侧控制点的连线和下轮廓左侧控制点与右侧控制点的连线间的夹角；人脸五官特征变量eyebrow-lower-angle-b为右眉毛下轮廓弧度,即为右眉毛下轮廓居中控制点与左侧控制点的连线和下轮廓居中控制点与右侧控制点的连线间的夹角；人脸五官特征变量face-chin-angle为脸型下巴角度,即为经过脸型轮廓左第六个控制点和脸型下巴控制点的直线与经过脸型轮廓右第六个控制点和脸型下巴控制点的直线之间的角度；人脸五官特征变量face-cheek-angle为脸型脸颊角度,即为经过脸型轮廓左侧第一个控制点和脸型轮廓左侧第五个控制点的直线与经过脸型轮廓左侧第九个控制点及脸型轮廓左侧第五个控制点的直线之间的角度；人脸五官特征变量face-size-angle为脸型尺寸角度,即为经过脸型轮廓左第一个控制点和脸型下巴控制点的直线与经过脸型轮廓右第一个控制点和脸型下巴控制点的直线之间的角度。</td>   <td>G06T11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         雷浩鹏;              徐驰;              康洋;                   林淑金       </td>   <td>中山大学</td>   <td>一种基于手绘草图部件分割的三维模型检索系统及方法</td>   <td>广东省</td>   <td>CN104850633B</td>   <td>2018-10-12</td>   <td>本发明实施例公开了一种基于手绘草图部件分割的三维模型检索系统及方法,其中,该系统包括：预处理模块,用于对手绘查询草图进行去噪处理获得灰度图,并对所述灰度图进行二值化处理、边界扩展处理、图像孔洞填充处理,获得处理后的图像；部件标记模块,用于对处理后的图像进行等间隔采样,并对采样点添加部件标签；采样点特征提取模块,用于提取采样点的各种特征向量；部件分割模块,用于根据添加部件标签后的采样点的各种特征向量进行分割模型训练；相似度计算与总评分排序模块,用于进行部件局部相似度计算,按照总评分进行排序,并将排序结果返回给客户端。实施本发明实施例,可以使得基于手绘草图的三维模型检索更加精准有效。</td>   <td>1.一种基于手绘草图部件分割的三维模型检索系统,包括预处理模块、部件标记模块、采样点特征提取模块、部件分割模块、和相似度计算与总评分排序模块,其特征在于,所述预处理模块,用于接收手绘查询草图,对所述手绘查询草图进行去噪处理获得灰度图,并对所述灰度图进行二值化处理、边界扩展处理、图像孔洞填充处理,获得处理后的图像；所述预处理模块包括：草图去噪处理单元,用于对所述手绘查询草图进行去噪处理获得灰度图；和二值化处理单元,用于对所述灰度图进行二值化处理；和边界扩展处理单元,用于对二值化处理后的图像四周进行空白填充处理；和图像孔洞填充处理单元,用于对空白填充处理后的图像进行图像孔洞填充处理；所述部件标记模块,用于对所述处理后的图像进行等间隔采样,获得采样点,并对所述采样点添加部件标签；所述采样点特征提取模块,用于提取所述采样点的各种特征向量；所述部件分割模块包括：分割模型训练单元,用于根据添加部件标签后的采样点的各种特征向量进行分割模型训练；和部件分割单元,用于根据分割模型对添加部件标签后的采样点进行部件分割；所述相似度计算与总评分排序模块,用于基于分割模型进行部件局部特征提取以及部件局部相似度计算,并对所述处理后的图像进行视图全局特征提取及视图全局相似度计算,按照总评分进行排序,并将排序结果返回给客户端。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁喜冬;              蔡光亚;              陈弟虎;              罗永震;              郭建平;                   张曰理       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于三维实体模型的三角形表面网格生成方法</td>   <td>广东省</td>   <td>CN105184868B</td>   <td>2018-10-12</td>   <td>本发明公开一种基于三维实体模型的三角形表面网格生成方法,包括：读取三维实体模型中的一个面；读取该面的一条边界；判断该边界是否已经经过处理,若是,直接读取处理结果,若否,对该边界进行处理；判断该面的边界是否全部已处理完成；将该面的边界和顶点变换到二维参数空间,在二维参数空间中生成二维网格；将生成的二维网格变换为三维参数空间；判断该三维实体模型中是否所有面都已生成网格,若是则输出网格生成结果,生成STL文件。本发明直接逐面进行网格生成,对每个面的边界逐个进行处理,每个面或边界均只需处理一遍,并在进行边界和面的处理时设置与最终生成的网格的精度有关的调控参数,实现高效率和高精度地生成网格。</td>   <td>1.一种基于三维实体模型的三角形表面网格生成方法,其特征在于,包括：S1、读取三维实体模型中的一个面；S2、读取该面的一条边界；S3、判断该边界是否已经经过处理,若是,直接读取处理结果,若否,对该边界进行处理；S4、判断该面的边界是否全部已处理完成,若是,转到S5,若否,返回S2；S5、将该面的边界和顶点变换到二维参数空间,在二维参数空间中生成二维网格；S6、将生成的二维网格变换为三维参数空间；S7、判断该三维实体模型中是否所有面都已生成网格,若是则输出网格生成结果,生成STL文件,若否,则返回S1；所述步骤S5中,在二维参数空间生成二维网格时,采用在Constrained Delaunay三角剖分的基础上的小角度输入修正算法,并将线性单元构成的分片线性复形作为输入,在输入的分片线性复形的空间中生成二维参数空间中的三角形网格,且三角形网格满足A-τ≤θ,其中K～*为在二维参数空间生成的三角形网格,A-τ为三角形τ的面积,θ为三角形τ的面积的上限,τ为三角形。</td>   <td>G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              黄秋筱;              江倩殷;              李国鸣;                   卢林       </td>   <td>中山大学</td>   <td>一种基于视频监控的客运站非出入口区域的客流统计方法</td>   <td>广东省</td>   <td>CN106127812B</td>   <td>2018-10-12</td>   <td>本发明提供的客流统计方法针对于客运站非出入口区域拍摄的图像容易出现遮挡的特点,提出使用行人的不易被遮挡、且形态基本不变的头肩部haar-like特征来对行人进行检测,其检测判别是否为行人的准确率较高,适用于行人图像出现遮挡的应用场景；而在完成检测后,通过Kalman滤波器和以上检测行人的方法来对行人在每帧图像的位置进行双重追踪,以保证追踪的准确率；实验证明,该方法能够针对客运站非出入口区域行人姿态多变、行为复杂、行走方向难预测的特点,达到很好的追踪效果。通过对行人的准确检测和追踪,本发明提供的方法能够有效地记录下行人的运动轨迹,保证了行人目标的匹配,减少误检和遗漏,提高人数统计精度。</td>   <td>1.一种基于视频监控的客运站非出入口区域的客流统计方法,该方法预先划定好人数统计区域,并对该区域内的行人目标进行检测和跟踪,从而统计进入和离开统计区域的人数,其特征在于：其中对行人目标进行检测和跟踪的具体过程如下：S1.人工提取监控图像里的行人的头肩部图像的haar-like特征作为正样本对AdBoost分类器进行训练,得到训练好的AdBoost分类器；S2.对于当前帧图像,采用背景差分法在当前帧图像的统计区域内获取运动目标；S3.提取运动目标的头肩部haar-like特征,并将其输入训练好的AdBoost分类器内,AdBoost分类器判别运动目标是否为行人,若是则执行步骤S4；S4.计算判别为行人的运动目标的头肩部中心点位置,并使用四维向量X-k＝(p-x,p-y,v-x,v-y)来表示其在当前帧的系统状态,其中(p-x,p-y)表示头肩部中心点的位置,(v-x,v-y)表示中心点的速度；S5.将X-k输入Kalman滤波器,并对Kalman滤波器的四个参数进行初始化：A-k、H-k、w-k、v-k；其中A-k表示状态由当前帧到下一帧的转移矩阵,H-k当前帧的观测矩阵,w-k和v-k分别表示当前帧的系统噪声向量和观测噪声向量；令A-k、H-k在各帧的系统状态变换过程中为已知且具有唯一值的矩阵,另外,设w-k、v-k的概率密度函数是均值为零的高斯函数且相互独立；S6.Kalman滤波器对运动目标的头肩部中心点在下一帧的系统状态进行预报,具体如下：                  其中A-k表示状态转移矩阵,表示预报的下一帧的系统状态；表示当前帧的系统状态；由(1)式,可得系统状态协方差的预报方程：                  其中,P'-(k+1)和P-k分别是和对应的协方差,表示A-k的转置矩阵,Q-k表示当前帧的系统噪声向量w-k的协方差矩阵；S7.根据步骤S6求取的内容对Kalman加权矩阵进行求取：                  其中K-(k+1)表示下一帧的Kalman加权矩阵,H-k、表示观测矩阵以及其转置,R-k表示观测噪声向量v-k的协方差矩阵；S8.根据求取的Kalman加权矩阵对运动目标的头肩部中心点在下一帧的系统状态和状态向量协方差P-(k+1)进行更新：                  P-(k+1)＝(I-K-(k+1)H-k)P'-(k+1)其中Z-(k+1)为下一帧的观测值,I表示单位矩阵；S9.对下一帧图像按照步骤S2～S4的方法获取运动目标的头肩部中心点位置的系统状态,然后将获取的系统状态与步骤S5～S9预测得到的运动目标的系统状态进行匹配关联,若两者匹配,则将匹配的结果确定为运动目标在下一帧的位置,否则利用步骤S5～S9预测得到的系统状态确定运动目标在下一帧的位置；S10.S5～S9重复执行直至完成整个的统计过程。</td>   <td>G06T7/254;G06T7/277;G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   黎杰       </td>   <td>中山大学</td>   <td>一种基于L0正则化的自然图像盲去运动模糊的方法</td>   <td>广东省</td>   <td>CN105809642B</td>   <td>2018-10-09</td>   <td>本发明提供一种基于L0正则化的自然图像盲去运动模糊的方法,利用自然图像的梯度信息以及运动模糊核的稀疏特性,在模糊核的求解模型中分别引入相应L0正则项。模型求解时,首先利用基于半二次分裂方法分别对中间复原图像以及模糊核进行求解,为增加鲁棒性,求解过程中采用金字塔模型逐层求解,并且模糊核的估计只用到图像的梯度信息,通过傅里叶变换,将求解过程转换到频率域上进行,避免了直接在空域上进行反卷积运算,从而达到快速求解目的。然后利用求得的模糊核,采用基于全变差分的非盲去卷积方法求得最终的复原图像。本发明提供的方法求解快速,鲁棒性高,且最终的复原图像具有很好的视觉效果。</td>   <td>1.一种基于L0正则化的自然图像盲去运动模糊的方法,其特征在于,包括以下步骤：S1：对于输入的原始模糊图像转换成单通道的灰度图像；S2：求解模糊核时,引入L0正则项,构造求解模型如公式(1)所示：                  据此求解模型再结合金字塔模型,采用基于半二次分裂方法对公式(1)中模型进行求解得到模糊核k；其中及γ为权重参数,y是模糊图像,x是清晰图像,k是模糊核,表示x的一阶偏导；S3：根据步骤S2求解得到的模糊核k,对原始模糊图像中每个通道的图像均采用基于全变差分的非盲去卷积方法进行复原,再将每个通道复原后的图像合并即求得最终复原图像；所述步骤S2的处理过程如下：S201：根据人工输入的模糊核大小k-size,下采样因子及规定的最小核尺寸k-min-size确定金字塔模型的层级数目；S202：根据公式(1),采用基于半二次分裂方法求复原图像x,如公式(2)：                  引入辅助变量β及u,其中β初始化为γ,u初始化为0,将公式(2)写成如下公式(3)：                  当β接近于无穷时,公式(2)与公式(3)求解得到的x一致,而公式(3)能够通过交替的计算x和u来求解；S203：通过公式(4)求u：                  由于公式(4)是逐个像素的最小化问题,因此u能够通过公式(5)求解得：                  S204：根据S203求出u后,x能够通过解最小二乘问题(6)来求得：                  因此有：其中F(.)和F～(-1)(.)分别代表傅里叶变换和反傅里叶变换,是F(.)的复共轭形式,和分别代表垂直以及水平差分,S205：调整β＝2β,若β未超过限定的最大值,则根据S204求得的x作为输入,执行S203,否则,执行S206；S206：根据公式(1),采用基于半二次分裂方法求解k,在公式(8)：                  引入辅助变量θ及g,θ初始为g初始化为0,将公式(8)写成如下公式(9)：                  当θ接近于无穷时,公式(8)与公式(9)求解得到的k一致,而(9)式能够通过交替的计算k和g来求解；S207：通过公式(10)求g：                  由于公式(10)是逐个像素的最小化问题,因此g能够通过公式(11)求解得：                  S208：根据S207求出g后,k能够通过解最小二乘问题(12)来求得：                  因此有                  其中对k中小于规定阈值k-threshold的值赋0,并对求得的k归一化；S209：调整θ＝2θ,若θ未超过限定的最大值,则根据S208求得的k作为输入,执行S207,否则,执行S210；S210：若金字塔模型中所有层次求解完成,则保留k,执行S3,否则,调整γ：γ＝max{γ/1.1,1e～(-4)},若金字塔模型中当前层次求解尚未完成,则执行S202,否则将k,x上采样到金字塔模型中下一层级的对应尺寸,执行S202。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   向航       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种健康检测方法及系统</td>   <td>广东省</td>   <td>CN104915413B</td>   <td>2018-09-07</td>   <td>本发明提供一种健康监测方法及系统,其中方法包括以下步骤：移动终端向服务器发送浏览请求、搜索请求或健康报告请求；服务器接收移动终端的浏览请求,根据浏览请求向数据库发送查询指令；服务器接收移动终端的搜索请求,根据搜索请求向数据库发送搜索指令；服务器接收健康报告请求,根据健康报告请求的关键词组,利用朴素贝叶斯算法计算所述关键词组的最相关疾病,向数据库请求所述最相关疾病的信息；数据库根据接收到的指令,利用网络爬虫从互联网获取与该指令相关的数据；服务器将数据库返回的数据按照标准格式发送至所述移动终端。本发明提供的一种健康监测方法及系统提供了查询及健康报告功能,方便用户随时查询。</td>   <td>1.一种健康监测方法,其特征在于,适用于包括移动终端、服务器和数据库的系统,包括以下步骤：移动终端向服务器发送浏览请求、搜索请求或健康报告请求；服务器接收移动终端的浏览请求,根据浏览请求向数据库发送查询指令；服务器接收移动终端的搜索请求,根据搜索请求向数据库发送搜索指令；服务器接收健康报告请求,根据健康报告请求的关键词组,利用朴素贝叶斯算法计算所述关键词组的最相关疾病,向数据库请求所述最相关疾病的信息；数据库根据接收到的指令,利用网络爬虫从互联网获取与该指令相关的数据；服务器将数据库返回的数据按照标准格式发送至所述移动终端；其中,服务器执行搜索请求的步骤包括：服务器接收移动终端发送的移动设备ID；服务器向数据库发送搜索指令,获得该移动设备ID的历史搜索记录,选出搜索记录中被搜索次数最多的至少5个搜索关键字,作为查询热词；服务器向移动终端发送该移动设备ID的查询热词；服务器接收来自该移动终端发送的搜索请求,该请求包括：搜索关键字、移动设备ID、页号；服务器添加搜索记录到数据库,并根据搜索关键字对数据库进行检索；服务器接收数据库发送的检索结果；服务器将结果按页号发送给移动终端。</td>   <td>G06F17/30;G16H50/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张雨浓;              丁亚琼;              晏小刚;              李晓东;                   谭洪舟       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种硬件电路搭建方法和装置</td>   <td>广东省</td>   <td>CN105389429B</td>   <td>2018-09-04</td>   <td>本发明实施例公开了一种硬件电路搭建方法,用于解决现有张动力学方法搭建的硬件电路没有考虑非线性因素,使得硬件电路系统存在较大误差,降低硬件电路系统可靠性的问题。本发明实施例方法包括：首先,获取当前硬件电路的实际输出值；以及,获取需要搭建的硬件电路的期望输出值；然后,根据所述实际输出值和所述期望输出值获得所述需要搭建的硬件电路的偏差函数；接着,根据所述偏差函数设置搭建函数的收敛系数,使得所述搭建函数的输出结果在预设的时间内收敛；最后,根据所述搭建函数搭建出需要搭建的硬件电路。本发明实施例还提供一种硬件电路搭建装置。</td>   <td>1.一种硬件电路搭建方法,其特征在于,包括：获取当前硬件电路的实际输出值；获取需要搭建的硬件电路的期望输出值；根据所述实际输出值和所述期望输出值获得所述需要搭建的硬件电路的偏差函数；根据所述偏差函数设置搭建函数的收敛系数,使得所述搭建函数的输出结果在预设的时间内收敛；所述搭建函数的表达式为：其中,γ为所述收敛系数,e为所述偏差函数,SGN(e)为预设的符号函数激励电路模型,所述符号函数激励电路模型的表达式为：          e-i为e的第i个分量；根据所述搭建函数搭建出需要搭建的硬件电路。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘小平;              梁迅;              黎夏;              陈逸敏;              姚尧;              许晓聪;                   李丹       </td>   <td>中山大学</td>   <td>一种土地未来利用情景动态模拟方法</td>   <td>广东省</td>   <td>CN105447235B</td>   <td>2018-09-04</td>   <td>本发明提出并公开了一种土地未来利用情景动态模拟方法,该方法集成了元胞自动机(CA)模拟复杂系统时空演化过程的能力和CLUE-S模型模拟多类别土地利用类型竞争的优势,通过优势整合克服了传统元胞自动机或单纯CLUE-S模型的一些固有缺陷；另外采用了神经网络(ANN)算法实现了分布概率的智能计算,引入轮盘赌的竞争机制实现多种土地利用变化的同步模拟,使得新方法更适合多种类别的土地利用数据；并且相对于传统模型具有精度更高、适合多尺度、数据需求低、参数少、操作简便、速度快等实用优点；该方法有效的将智能算法(ANN)和不确定性模型(赌轮)结合,同时应用于未来土地利用情景预测中。</td>   <td>1.一种土地未来利用情景动态模拟方法,在于构建动态模拟模型对土地未来利用情景进行模拟,所述动态模拟模型包括分布概率计算模块和迭代模拟模块,其特征在于：所述动态模拟方法包括以下步骤：分布概率计算模块计算分布概率阶段：S1.对初始土地利用分类影像进行解译,获取初始土地利用数据；然后选取若干影响土地利用/土地覆盖变化的驱动力因子,组成驱动力数据；S2.使用初始土地利用分类影像规定好模拟区域的范围与标准栅格影像大小,然后计算模拟区域内空间栅格到各个驱动力因子的距离；生成与标准栅格影像图幅大小一致的栅格距离数据；S3.在驱动力数据与初始土地利用数据上进行随机点采样,获得采样数据；S4.使用采样数据对参数自适应神经网络算法进行训练；S5.将全体驱动力数据输入训练好的神经网络,通过神经网络计算获得每种土地利用类型在模拟区域内的分布概率；迭代模拟模块迭代输出阶段：S6.将S5输出的分布概率与S1中的初始土地利用数据输入迭代模拟模块；迭代前设定好邻域大小、每种土地利用类型的像元个数与转换限制矩阵；S7.迭代扫描初始土地利用数据的像元,计算该像元在邻域内包含的土地利用类型和在邻域内所占的比例,与S5输出的分布概率、S6设定的转换限制矩阵共同合成该像元上各类土地利用类型的总分布概率；S8.该像元上的各类土地利用类型的总分布概率构成轮盘,通过采用轮盘赌的方法,使区域内各种土地利用类型在像元上竞争,竞争获胜的土地利用类型占据该像元；S9.转到S7,直至迭代完一幅影像的全部有效像元,然后返回S6刷新初始影像进入下一次迭代,计算到目标数目的距离；到达迭代次数R或者达到目标像元后,停止迭代输出结果。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              刘丙军;              涂新军;              林凯荣;                   张强       </td>   <td>中山大学</td>   <td>南方感潮河网区水流水质耦合模拟系统</td>   <td>广东省</td>   <td>CN105893763B</td>   <td>2018-08-28</td>   <td>本发明提供一种南方感潮河网区水流水质耦合模拟系统,分为数据输入、模型库和数据输出三大模块,模型库包括水流数学模型和水质数学模型。水流数学模型可以作为单独的模块使用,对输入的地形、取水工程数据与水文数据等进行分析计算,采用灵活的用户界面使得数据可以方便地进行用户需要的二次处理,并为水质数学模型提供了基础数据支撑。水质数学模型与水流数学模型有机结合,实现了在水流数学模型的基础上对大范围网河区河流水质的模拟,并能够对闸坝、取排水等进行灵活设置,加强了系统的实用性及适用性。</td>   <td>1.南方感潮河网区水流水质耦合模拟系统,其特征在于,所述系统包括：数据输入模块：用于输入数据,输入数据由水流模拟、水质模拟和水流水质模型耦合关系三部分所需数据文件组成,其中水流模拟所需文件包括河道流场边界文件,流场边界类型及流场河道节点文件,河道地形数据文件,取水位置和取水量文件；水质模拟所需文件包括浓度场河道首末节点文件,浓度场污染源文件,浓度场外河道地形走向判断因子文件；水流水质耦合关系所需文件为浓度场与流场的河道、节点对应关系文件；模型库：包括水流数学模型和水质数学模型两大模块,且两者相互连接,有机结合；所述水流数学模型导入和存储河道地形数据、模型边界水文数据、取用水数据和模型河道糙率参数初始值,然后根据输入数据自动进行模型参数率定,最后使用率定后的模型进行工程取水论证,以期达到水资源的可持续开发和利用,并得到水质数学模型所需的基础数据；所述水质数学模型在水流水质模型耦合关系下通过水流数学模型提供的基础数据,结合输入的污染源位置及排污量数据、模型边界水质浓度数据和污染物降解系数进行河道水质模拟演算,制定合理的排污方案；数据输出模块：用于输出数据,数据输出文件由水流数学模型及水质模型两部分的输出结果组成,其中潮位和流量结果由水流数学模型输出,污染物浓度结果由水质数学模型输出。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈湘萍;              陈小燕;                   林谋广       </td>   <td>中山大学</td>   <td>一种基于APP质量的APP排名预测方法及系统</td>   <td>广东省</td>   <td>CN105095411B</td>   <td>2018-08-24</td>   <td>本发明实施例公开了一种基于APP质量的APP排名预测方法及系统,其中,该方法包括：根据APP的类型设置不同的排行榜,并对排行榜进行区间划分；通过ISO的质量模型和用户的使用反馈评估APP的质量,获得APP的评估质量；根据评估质量判断APP接近哪一个区间,并根据区间预测APP的排名；结合该APP的留存率来预测APP的最终排名。在本发明实施例中,根据APP的类型设置不同的排行榜,并在排行榜中设定不同的区间,通过ISO的质量模型和用户的使用反馈来评估APP的质量,判断APP接近哪一个区间,并根据区间预测APP的排名,再结合最近一周的用户对该APP的留存率来预测APP的最终排名,这样可以基于APP质量评估对APP商店的APP进行预测排名,提高APP排名的准确性,促进APP质量的提升。</td>   <td>1.一种基于APP质量的APP排名预测方法,其特征在于,所述方法包括：根据APP的类型设置不同的排行榜,并对所述排行榜进行区间划分；通过ISO的质量模型和用户的使用反馈评估APP的质量,获得APP的评估质量；根据所述评估质量判断APP接近哪一个区间,对待测APP进行判断APP的类型；根据待测APP的类型找到对应的排行榜；计算出待测APP的质量评估基础分；计算出待测APP的用户反馈基础分；计算出待测APP的基础分加权和；判断待测APP的基础分加权和接近排行榜哪个区间的分数；根据此区间预测待测APP的预排名在哪个区间,得出预排名；结合最近一周的用户对该APP的留存率来预测APP的最终排名。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林淑金;              李玉三;                   罗笑南       </td>   <td>中山大学</td>   <td>一种保周长的曲线细分方法及系统</td>   <td>广东省</td>   <td>CN105243234B</td>   <td>2018-08-24</td>   <td>本发明公开了一种保周长的曲线细分方法及系统,其中,该方法包括：获取未细分曲线的信息；对所述未细分的曲线进行融合逼近和插值的四点三重细分处理,获取曲线细分模式；对所述曲线细分模式的参数进行修改,使所述曲线细分模式下的曲线二阶导连续；在所述曲线二阶导连续的参数范围内调整参数,确定细分前后的曲线周长误差在阈值范围内；输出融合逼近和插值的保周长的细分曲线。在本发明实施例中,采用融合逼近和插值的细分方法能够实现细分前后的周长不变,又能提高曲线的光滑度,提高用户的使用体验感。</td>   <td>1.一种保周长的曲线细分方法,其特征在于,所述方法包括：获取未细分曲线的形状、未细分曲线的周长、未细分曲线的控制顶点和未细分曲线细分前后允许的周长误差的阈值未细分曲线的信息；对所述未细分的曲线进行融合逼近和插值的四点三重细分处理,获取曲线细分模式；对所述曲线细分模式的参数进行修改,使所述曲线细分模式下的曲线二阶导连续；获取所述二阶导连续的曲线模型的曲线周长,将所述未细分曲线的周长与所述曲线周长相减,获取相减结果,将所述相减结果与所述未细分曲线细分前后允许的周长误差的阈值相比较,获取比较结果,根据所述比较结果对所述二阶导连续的曲线的参数进行调整；输出融合逼近和插值的保周长的细分曲线。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              陈小燕;                   郑贵锋       </td>   <td>中山大学</td>   <td>一种基于空间定位和聚类的动作预测方法及系统</td>   <td>广东省</td>   <td>CN105488794B</td>   <td>2018-08-24</td>   <td>本发明公开了一种基于空间定位和聚类的动作预测方法及系统,其中,所述方法包括：对目标点进行空间定位,获取所述目标点每一帧的位置信息和运动状态信息；根据至少两帧连续的所述目标点的位置信息和运动状态信进行信息编码,建立至少两帧连续信息的模型；对所述至少两帧连续信息的模型进行聚类,获取聚类结果；根据所述聚类结果建立训练数据集,并根据所述训练数据集获取工作模式；根据所述工作模式对动作进行预测。实施本发明实施例,对目标点进行空间定位和基于外部输入的庞大数据下,通过聚类技术进行有效的预测来减少因信号传输过程中产生的时延,从而有效减少主观延时,提高用户的使用体验感。</td>   <td>1.一种基于空间定位和聚类的动作预测方法,其特征在于,所述方法包括：对目标点进行空间定位,获取所述目标点每一帧的位置信息和运动状态信息；在每一帧中记录所述目标点的位置信息和运动状态信息；记录连续至少两帧的所述目标点的位置信息和运动状态信息并进行信息编码,获取信息编码结果；根据所述信息编码结果构建至少两维的信息向量；根据所述至少两维的信息向量,获取至少两帧连续信息的模型；对所述至少两帧连续信息的模型进行聚类,获取聚类结果；根据所述聚类结果建立训练数据集,并根据所述训练数据集获取工作模式；根据所述工作模式对动作进行预测。</td>   <td>G06T7/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              粟涛;                   杨茵       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于ANSYS有限元热分析的芯片温度预测方法</td>   <td>广东省</td>   <td>CN104182568B</td>   <td>2018-08-21</td>   <td>本发明公开了一种基于ANSYS有限元热分析的芯片温度预测方法,包括：根据获取的芯片模型参数采用ANSYS构建芯片内部结构实体模型；对芯片内部结构实体模型进行有限元网格划分；加载生热率和边界条件,然后对有限元网格划分后的芯片内部结构实体模型进行稳态热分析,从而获得芯片最高温度；改变芯片的生热率,然后通过稳态热分析获得不同生热率下的芯片最高温度；对生热率与芯片温度的关系曲线进行拟合,从而得到生热率与芯片温度的关系函数；将实际的生热率代人生热率与芯片温度的关系函数,从而求出芯片的实际温度。本发明将温度的预测放到芯片的物理设计阶段,降低了花费的成本,操作简单和方便。本发明可广泛应用于半导体技术领域。</td>   <td>1.一种基于ANSYS有限元热分析的芯片温度预测方法,其特征在于：包括：步骤A、根据获取的芯片模型参数采用ANSYS构建芯片内部结构实体模型；步骤B、对芯片内部结构实体模型进行有限元网格划分；步骤C、加载生热率和边界条件,然后对有限元网格划分后的芯片内部结构实体模型进行稳态热分析,从而获得芯片最高温度；步骤D、改变芯片的生热率,然后通过稳态热分析获得不同生热率下的芯片最高温度；步骤E、对生热率与芯片温度的关系曲线进行拟合,从而得到生热率与芯片温度的关系函数；步骤F、将实际的生热率代入生热率与芯片温度的关系函数,从而求出芯片的实际温度；所述生热率为芯片的总功耗与面积的比值；所述芯片内部结构实体模型包括芯片内部层级结构,所述芯片内部层级结构为自下而上分布的衬底、器件层、电源网络结构、绝缘层以及钝化层；所述步骤A,其包括：步骤A1、根据选用的工艺库文件获取芯片内部各层级结构以及各层级结构材料的几何参数和热属性参数；步骤A2、根据获取的参数采用布尔操作构建芯片内部结构实体模型。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨锐;              王刚;                   刘红梅       </td>   <td>中山大学;深圳大学</td>   <td>一种鉴别数字音频AAC格式多次压缩的方法</td>   <td>广东省</td>   <td>CN105205102B</td>   <td>2018-08-14</td>   <td>本发明公开一种鉴别数字音频AAC格式多次压缩的方法,是根据音频压缩的特点而提出的统计判别方法,属于多媒体信号处理领域。本发明方法依据数字音频在压缩时MDCT系数会发生变化,进而导致Huffman编码的不同。随着压缩次数的增多,这种差异将越来越小。本发明方法正是将不同的压缩次数之间Huffman编码小值的差异组成特征值,再利用SVM分类器分类,对鉴别AAC格式的数字音频是否被多次压缩有很好的效果。本发明可以作为鉴别AAC格式的文件是否被多次压缩的一种有效手段,可以广泛应用在数字音频的鉴别和过滤假音质音乐方面。</td>   <td>1.一种鉴别数字音频AAC格式多次压缩的方法,其特征在于,包括以下步骤：1)数字音频集的构造：11)压缩一次音频集的构造：首先选取无损的WAV格式文件,裁剪成若干t秒钟长度的音频片段,然后以若干种不同的码率压缩成AAC格式的音频；12)压缩两次音频集的构造：对步骤11)中生成的AAC文件进行解码得到WAV格式文件,再将它们分别以其对应的码率再次压缩成AAC文件,得到压缩两次的音频集；13)压缩三次音频集的构造：对步骤12)中生成的AAC文件按照同样的方法进行解码,然后,再分别以其对应码率再压缩,得到压缩三次的AAC格式的音频集；2)音频集特征提取：对上述得到的三种音频集,按以下方法提取特征：21)根据AAC标准,每帧提取1024个Huffman编码值；22)统计每个音频片段中所有帧的Huffman编码值为0的个数,±1的个数和以及±2的个数和,然后除以帧数,得到平均每帧中0,±1,±2的个数,将平均每帧中0,±1,±2的个数称作Huffman小值；23)依据步骤22)中的方法,用压缩一次音频片段的Huffman小值减去压缩两次音频片段的Huffman小值,得到第一组特征值；采取相同的方法,用压缩两次音频片段的Huffman小值减去压缩三次音频片段的Huffman小值,得到第二组特征值；3)分类器的构造：将步骤2)中得到的两组特征值利用SVM 分类器进行训练,得到一个能鉴别AAC格式音频信号是否被多次压缩的分类器模型Model；用于判断待测音频特征值属于第一组特征值还是第二组特征值,如果待测音频特征值属于第一组特征值的类别则该待测音频是压缩一次的数字音频,否则是压缩两次或两次以上的数字音频；4)鉴别待测音频:首先,将待测音频解码,得到Huffman小值；然后,将解码的文件再次压缩成AAC文件,再解码,得到另一组Huffman小值；将这两组Huffman小值相减,组成待测音频特征值；最后,利用步骤3)中训练出来的Model进行鉴别；如果待测音频特征值属于第一组特征值的类别则该待测音频是压缩一次的数字音频,否则是压缩两次或两次以上的数字音频。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         许跃生;              陈颖;                   叶纬材       </td>   <td>中山大学</td>   <td>基于FMD索引和快表的跨越式种子查找算法</td>   <td>广东省</td>   <td>CN105138534B</td>   <td>2018-08-03</td>   <td>本发明公开了一种基于FMD索引和快表的跨越式种子查找算法,包括下述步骤：S0、构建数据库的FMD索引以及快表；S1、从快表中取出查询序列中长度为k的子序列的双区间；S2、这个步骤通过向后搜索算法,逐步找出k种子左边的匹配区域；S3、对步骤S2中缩小前的区间执行向前搜索算法,以找出k种子右边的匹配区域；S4、检查当前检测位置是否位于查询序列的尾部,如果是,则算法终止,否则,执行步骤S5；S5、将当前检测位置向前跳跃w-k+1个位置,重复执行步骤S2-S5,其中w是要查找的种子的长度。本发明提出的快表具有占用空间少、访问效率高的特点；在快表和FMD索引的基础上,本发明提出的种子查找算法能够快速地找出所有w种子的双区间。</td>   <td>1.基于FMD索引和快表的跨越式种子查找方法,包括下述步骤：S0、构建数据库FMD索引的快表,这个快表是一个Hash表,每一个表项对应一个长度为k的子序列,保存的是在FMD索引中搜索这个子序列所得到的双区间；FMD索引具体为：核酸序列的一个长度为k的子序列称为k子序列,查询序列与数据库序列之间的一段长度为w的完全匹配区段称为w种子,在数据库的FMD索引中搜索序列P,其搜索结果以双区间的形式表示,而双区间则由三个整数表示,给定核酸序列P的双区间和字符a,a为A、C、G、T中的其中一个,由向后搜索算法,可以得到aP的双区间；由向前搜索算法,可以得到Pa的双区间,双区间中元素的个数称为该区间的大小,它表示P在数据库中出现的次数,如果P的双区间为空区间,则表示P没有在数据库中出现；S1、计算查询序列中k子序列的Hash值,并从快表中取出其相应的长度为k的种子的双区间；S2、这个步骤通过向后搜索算法,逐步扩大k种子左边的匹配区域；S3、对步骤S2中缩小前的区间执行向前搜索算法,以找出k种子右边的匹配区域；S4、检查当前检测位置是否位于查询序列的尾部,如果是,则算法终止,否则,执行步骤S5；S5、将当前检测位置向前跳跃w-k+1个位置,重复执行步骤S2-S5,其中w是要查找的种子的长度。</td>   <td>G06F17/30;G06F19/28</td>  </tr>        <tr>   <td>中国专利</td>   <td>         冯健文;                   常会友       </td>   <td>中山大学</td>   <td>一种基于等价类的重复任务过程发现方法</td>   <td>广东省</td>   <td>CN105117430B</td>   <td>2018-07-31</td>   <td>本发明公开一种基于等价类的重复任务过程发现方法,通过扩展事件次序关系定义,提出等价类划分同一任务子集的判定定理,在预处理阶段,通过把具有正确依赖次序关系的同名事件划分为同一任务等价类子集,在处理中阶段采用短循环过程发现算法生成WF-net模型,在处理后阶段对不同的同一任务子集重命名,以达到消除重复任务的目标。其首先读取标准的业务过程XES文件,采用次序依赖关系定义和判定定理检测重复任务,输出采用WF-net表示的业务过程模型。该方法具有解决较高的处理包含短循环结构、多前驱后继和重复任务过程发现问题的能力,且该方法能保证挖掘结果是正确合理的。</td>   <td>1.一种基于等价类的重复任务过程发现方法,其特征在于,读取标准的业务过程XES文件,采用次序依赖关系定义和判定定理检测重复任务,输出采用WF-net表示的业务过程模型；采用次序依赖关系定义和判定定理检测重复任务的具体过程如下：(1)从XES日志W中提取初始任务集合T-W；(2)从XES日志W中提取首任务集合T-I和末任务集合T-O；(3)根据次序依赖关系定义从T-W、T-I和T-O提取任务间的次序依赖关系；(4)初始化多次任务集合T-M和T-C；(5)初始化重复任务日志W-D和任务集合T-D；(6)根据次序依赖关系定义建立同结构任务集合ST-D；(7)根据同一任务子集判定定理检测和更名重复任务,运行方法Discovery；(8)采用第三方过程发现方法构建WF-net模型；(9)对WF-net模型恢复重复任务名称；(10)结束；所述步骤(7)中方法Discovery的具体步骤如下：(7.1)读入重复任务日志W-D、任务集合T-D、多次任务集合T-M和同结构任务集合ST-D；(7.2)T-M中是否还有未检测任务t；(7.2.1) 没有未检测任务t,跳转至步骤(7.3)；(7.2.2) 有未检测任务t,则建立未检测任务t的同名事件集合,并对每个同名事件构建前驱/后继表,即P/S表；把P/S表的每个元素初始化为集合,选取任意两个集合,采用同一任务集合判定定理进行比较,如果两个集合为同一任务集合则合并,直到不能合并为止,结果保存至同一任务集合X；如果X中的元素个数大于1个,说明存在重复任务,就对W-D中,未检测任务t的同名事件进行更名操作；跳转至步骤(7.2.1)；(7.3)输出新的日志N-D和任务集合T-D。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   杨文来       </td>   <td>中山大学</td>   <td>面向广域分布云系统公平的多任务虚拟机分配方法</td>   <td>广东省</td>   <td>CN105138391B</td>   <td>2018-07-31</td>   <td>本发明公开了一种面向广域分布云系统公平的多任务虚拟机分配方法,包括：S1：计算任务提交到云系统,云系统估算它们的虚拟机需求；S2：将所有任务降序排序并加入队列；S3：选择队列中估值大的任务,估算每一节点若作为该任务的初始节点可能产生最终的通讯消耗；S4：将该任务分配给估值最小的节点,并将该任务移出队列；S5：判断是否所有任务都分配了一个初始节点,是则执行S6否则返回S3；S6：对于每一个未满足虚拟机需求的任务遍历系统中可用节点,计算直径虚拟机比；S7：将比值最小的任务分配到对应的节点上；S8：判断是否完成所有任务的分配,是则结束分配否则返回执行S7。本发明不仅能获得更低的系统通讯消耗,还能保证云系统的高公平性。</td>   <td>1.面向广域分布云系统公平的多任务虚拟机分配方法,其特征在于,包括下述步骤：S1：计算任务提交到云系统,云系统估算它们的虚拟机需求；S2：按照估算好的虚拟机需求将所有任务降序排序并加入队列；S3：选择队列中估值大的任务,对每个节点估算该任务若以该节点作为初始节点可能产生最终的通讯消耗；S4：将该任务分配给估值最小的节点,并将该任务移出队列；S5：判断是否所有任务都分配了一个初始节点,是则执行步骤S6否则返回步骤S3；S6：对于每一个未满足虚拟机需求的任务遍历系统中可用节点,计算对应的直径虚拟机比,计算对应的直径虚拟机比的方法如下：计算若将该节点分配给该任务会造成的通讯消耗增量,并将该增量除以该节点可以提供的虚拟机数量,便得到了该任务对应节点的直径虚拟机比；S7：将比值最小的任务分配到对应的节点上；S8：判断是否完成所有任务的分配,是则结束分配否则返回执行步骤S6。</td>   <td>G06F9/455;G06F9/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;                   王超       </td>   <td>中山大学</td>   <td>基于XML路网数据的Paramics路网构建方法</td>   <td>广东省</td>   <td>CN104679949B</td>   <td>2018-07-10</td>   <td>本发明涉及一种基于XML路网数据的Paramics路网构建方法,包括以下步骤：S1.将XML路网数据进行解析处理,生成路段链表,遍历路段链表,获得各个路段的起点坐标、终点坐标和相应的属性值；S2.建立路网节点链表,将各个路段的起点坐标、终点坐标作为节点元素按编号顺序存储在路网节点链表中；S3.对路网节点链表中的各个节点元素在路段链表中搜索其关联路段,并根据搜索得到的关联路段的起点坐标、终点坐标,生成新的路段链表,S4.根据路网节点链表和新的路段链表,分别生成“nodes”文件和“links”文件；S5.应用生成的“nodes”文件、“links”文件,生成路网。上述方法实现对大区域复杂路网进行构建的同时,不会出现读取错误导致路网拓扑出现混乱。</td>   <td>1.一种基于XML路网数据的Paramics路网构建方法,其特征在于：包括以下步骤：S1.将XML路网数据进行解析处理,生成路段链表,遍历路段链表中的所有路段,获得各个路段的起点坐标、终点坐标和相应的属性值,并根据遍历路段的顺序,分别对各个路段以及路段的起点坐标、终点坐标进行编号；S2.建立路网节点链表,将各个路段的起点坐标、终点坐标作为节点元素按编号顺序存储在路网节点链表中；S3.对路网节点链表中的各个节点元素在路段链表中搜索其关联路段,并根据搜索得到的关联路段的起点坐标、终点坐标,生成新的路段链表,各个节点的关联路段的起点坐标、终点坐标作为路段元素按照搜索顺序依次存储在新的路段链表中；S4.遍历路网节点链表中的节点元素,将各个节点元素对应的ID属性值及其x、y坐标值依次写入文本文件中生成“nodes”文件；遍历新的路段链表中的路段元素,将各个路段元素对应的关联路段的起点坐标、终点坐标和相应的属性值依次写入文本文件中生成“links”文件；S5.根据生成的“nodes”文件、“links”文件,应用Paramics软件,生成路网。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁政豪;                   吕中荣       </td>   <td>中山大学</td>   <td>一种基于人工蜂群算法的结构损伤识别方法</td>   <td>广东省</td>   <td>CN105183933B</td>   <td>2018-07-10</td>   <td>本发明公开一种基于人工蜂群算法的结构损伤识别方法,是人工蜂群算法在结构损伤识别这一领域的工程应用,主要步骤如下：S1.通过有限单元法建立损伤结构的有限元模型,提取结构的固有频率、振型等模态参数。S2.利用损伤结构和计算结构的固有频率残差和模态确保准则构建目标函数(MAC)构建目标函数。S3.采用人工蜂群算法优化这一目标函数,直到满足循环结束条件为止。S4.最后得到的最优解即为损伤识别结果。该方法相较于传统的灵敏度方法而言,无需借助梯度信息,利用少量的模态参数即可得到精度较高的识别结果。</td>   <td>1.一种基于人工蜂群算法的结构损伤识别方法,其特征在于,包括：步骤一：将结构划分为nel个单元,利用有限单元法得到系统刚度和质量矩阵,再提取前N阶固有频率和模态；步骤二：构建损伤结构的目标函数,即待优化的目标函数；步骤三：利用人工蜂群算法不断优化目标函数,直到满足终止条件；上述步骤二中目标函数如下：                                                      其中：f为目标函数,NF为提取的频率模态阶数,Δω-j为第j阶频率残差,分别为第j阶频率和模态的权重系数,为第j阶计算有限元模型的频率,为第j阶损伤结构的频率,MAC-j为第j阶模态确保准则,为第j阶计算有限元模型的振型,为第j阶损伤结构的振型,j为任意一阶参与计算的模态参数的编号；上述步骤三中利用人工蜂群算法对目标函数进行优化的具体过程如下：1)初始化参数,包括初始种群数量、最大迭代次数、算法中的雇佣蜂机制在同一位置的最大搜索次数；蜂群初始化生成任一可行解x-m,可行解的任一维变量生成方式如下所示：x-(m,i)＝l-i+rand(0,1)*(u-i-l-i)其中,x-(m,i)表示搜索空间中的任一可行解的任意一维变量,u-i和l-i代表变量x-(m,i)的上限和下限,rand(0,1)表示介于0和1之间的随机数；2)计算种群的函数适应度值,并评价种群；在损伤识别问题中,适应度的计算公式如下：fit(x-m)＝1/(1+f(x-m))其中fit(x-m)表示任一可行解x-m的适应度函数,来衡量解的质量好坏的,在损伤识别问题中,适应度函数值越小,说明计算有限元模型和损伤结构之间的差异越小,则计算有限元模型越能反映受损结构的损伤状况；3)引领蜂阶段：种群中的一半蜜蜂成为引领蜂x-m在食物源附近进行食物探索,利用式(1)生成新解v-m,新解和原始解的差异在于有一维变量不同,假定第t维变量为v-(m,t),其计算公式如下所示；v-(m,t)＝x-(m,t)+rand(0,1)*(x-(m,t)-x-(k,t))  (1)x-(k,t)是除x-m之外随机选取的一个解x-k的第t维变量,应用“贪婪原则”决定选取适应度更好的可行解；即如果新解v-m的适应度更好,则用v-m替换原来的x-m,反之,则保留原始解x-m；4)观察蜂阶段：根据适应度值的大小计算解x-m被选择的概率,公式如下：                  p-m则表示解x-m被选择的概率,SN表示雇佣蜂的数量,雇佣蜂们将蜜源信息传递给观察蜂；5)观察蜂参考这个概率,选择一个食物源进行二次探索,探索公式与引领蜂阶段的相同,应用“贪婪原则”,即选取适应度更好的解；6)侦查蜂阶段：对于某一个解,如果在最大次搜索后,仍未改善,则随机生成新解替换；7)记忆目前最好的解,直到算法结束为止。</td>   <td>G06F17/50;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              许伟亮;                   粟涛       </td>   <td>中山大学</td>   <td>一种基于集成电路层次化设计的时序后仿真方法</td>   <td>广东省</td>   <td>CN105138774B</td>   <td>2018-07-06</td>   <td>本发明公开了一种基于集成电路层次化设计的时序后仿真方法,通过调用已完成设计和时序仿真验证的模块A完成设计B,所述设计B为顶层设计或模块A的上一层设计；包括以下步骤：S1.导出设计B中模块A内部输入输出端口路径的延时信息；S2.在模块A的寄存器传输级电路源码设计的输入输出端口处添加所述设计B中模块A内部输入输出端口路径的延时信息；S3.读入设计B的网表和延时反标文件,将网表中的模块A用添加了设计B中模块A内部输入输出端口路径的延时信息的寄存器传输级电路源码设计表征,编译并启动设计B的时序后仿真测试。该方法可以有效地减少时序后仿真的资源占用和仿真时间,从而提高了仿真效率和节约设计成本。</td>   <td>1.一种基于集成电路层次化设计的时序后仿真方法,通过调用已经完成设计和时序仿真验证的模块A,以完成设计B,所述设计B为顶层设计或模块A的上一层设计；其特征在于：包括以下步骤：S1.导出设计B中模块A内部输入输出端口路径的延时信息；S2.在模块A的寄存器传输级电路源码设计的输入输出端口处添加所述设计B中模块A内部输入输出端口路径的延时信息；S3.读入设计B的网表和延时反标文件,将网表中的模块A用添加了设计B中模块A内部输入输出端口路径的延时信息的寄存器传输级电路源码设计表征,编译并启动设计B的时序后仿真测试。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王凯;              李明;              李昕;                   杰弗里·瓦尔顿       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种触控显示屏驱动及指纹图像采集方法</td>   <td>广东省</td>   <td>CN104573648B</td>   <td>2018-06-26</td>   <td>本发明涉及一种触控显示屏驱动及指纹图像采集方法,该方法使用双栅极光电薄膜晶体管对显示单元进行驱动和指纹图像进行采集；其中对显示单元进行驱动的过程具体如下：向双栅极光电薄膜晶体管的光栅极施加零电压或正偏压,暗栅极施加正电压,此时显示信号通过双栅极光电薄膜晶体管的漏极、源极输送至显示单元,显示信号对显示单元进行驱动；对显示单元进行指纹图像采集的过程如下：向双栅极光电薄膜晶体管的光栅极(透明导电材料)施加负偏压,暗栅极施加正偏压,则双栅极光电薄膜晶体管采集的指纹图像可通过源极输出。由于该方法不依靠于分离器件,具有生产成本低、功耗低的优点,同时采集的指纹图像信噪比高、分辨率高。</td>   <td>1.一种触控显示屏驱动及指纹图像采集方法,其特征在于：使用双栅极光电薄膜晶体管对显示单元进行驱动和指纹图像采集；其中对显示单元进行驱动的过程如下：向双栅极光电薄膜晶体管的光栅极施加零电压或正偏压,暗栅极施加正电压,此时显示信号通过双栅极光电薄膜晶体管的漏极、源极输送至显示单元,显示信号对显示单元进行驱动；对显示单元进行指纹图像采集的过程如下：向双栅极光电薄膜晶体管的光栅极施加负偏压,暗栅极施加正偏压,则双栅极光电薄膜晶体管采集的指纹图像通过源极输出。</td>   <td>G06K9/00;G06F3/041</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭建平;              王自鑫;              陈弟虎;              罗新潮;              黄侃;                   涂玏       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于线性延时模型的高层次综合调度方法</td>   <td>广东省</td>   <td>CN105005638B</td>   <td>2018-06-26</td>   <td>本发明公开一种基于线性延时模型的高层次综合调度方法,包括：获取输入的电路描述后构建对应的控制数据流图；对控制数据流图中的操作运算进行分类,为每一类操作运算建立对应的延时模型；基于延时模型对操作运算进行延时估算；计算控制数据流图中任意数据路径的延时信息；将计算出的延时信息标注至控制数据流图中,并根据带有延时信息的控制数据流图构建调度图；采用差分约束系统调度算法对调度图进行调度得到调度结果。本发明所使用的线性延时模型在保证估算的准确性同时降低算法时间复杂度为多项式时间复杂度,可以快速、准确的求解调度目标函数得到一个准确的结果,使得整体的调度结果更优,从而能够更加快速准确地生成硬件电路结构。</td>   <td>1.一种基于线性延时模型的高层次综合调度方法,其特征在于,包括以下步骤：S1、获取输入的电路描述后构建对应的控制数据流图；S2、对控制数据流图中的操作运算进行分类,为每一类操作运算建立对应的延时模型；S3、基于延时模型对操作运算进行延时估算；S4、计算控制数据流图中任意数据路径的延时信息；S5、将计算出的延时信息标注至控制数据流图中,并根据带有延时信息的控制数据流图构建调度图；S6、采用差分约束系统调度算法对调度图进行调度得到调度结果；所述操作运算包括逻辑操作运算、数学计算操作运算和比较大小的操作运算,所述步骤S2包括：将逻辑操作运算划分为一类并建立位级并行延时模型：式中d(i,j)表示操作运算从任意第i输入位至任意第j输出位的延时,D即为该操作运算的关键路径延时,为常数；将数学计算操作运算划分为一类并建立位级线性增量延时模型：                  式中D-b为模型中的每位延时增量,D-l为第0输入位至第0输出位的延时；将比较大小的操作运算划分为一类并建立位级线性减量延时模型：d(i,j)＝-D-d×(N-i)+D-m,j＝1,式中D-d为线性模型中的每位延时减量,D-m为最高输入位至最高输出位的延时,N为输入位宽；将逻辑操作运算、数学计算操作运算和比较大小的操作运算之外的操作运算划分为一类并建立黑盒模型：d(i,j)＝D。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              袁大龙;              韩非凡;              杜景洪;                   印鉴       </td>   <td>中山大学;广州智海纵横信息科技有限公司;广州中大南沙科技创新产业园有限公司</td>   <td>一种基于超像素的协同跟踪算法和系统</td>   <td>广东省</td>   <td>CN105654505B</td>   <td>2018-06-26</td>   <td>本发明涉及一种基于超像素的协同跟踪算法和系统。本发明提供的方法将结合全局判断和局部判断来确定候选图像内是否包含有目标区域,因此能解决目标区域被遮挡的跟踪问题,同时,通过引入更新策略,使得该方法可以适应目标区域在跟踪过程中各种外观变化,其准确性、适用性大大提高。</td>   <td>1.一种基于超像素分割的协同跟踪算法,用于解决单摄像头单目标的跟踪问题,其特征在于：包括以下步骤：一、训练阶段S1.构建全局判别模型,所述全局判别模型用于提取目标区域的Haar-Like特征,然后根据提取的Haar-Like特征构建全局分类器GC,并确定全局分类器GC的参数；S2.使用基于重叠滑动窗口的分片方法对目标区域进行分片,获得N个子区域,然后构建出N个局部判别模型,所述N个局部判别模型用于对N个子区域分别提取Haar-Like特征,然后根据提取的Haar-Like特征分别构建局部分类器,并确定局部分类器的参数；S3.构建适应生成模型,并确认适应生成模型的模型参数,其具体步骤如下：对目标区域进行超像素分割,并分别提取每个超像素的特征向量,然后使用K-means算法对目标区域的所有超像素进行聚类,从而确定适应生成模型的模型参数；二、跟踪阶段S4.将候选图像p-i输入至全局判别模型,全局判别模型对候选图像p-i的Haar-Like特征进行提取,然后使用全局分类器GC对候选图像p-i的Haar-Like特征进行分类,GC(p-i)表示候选图像p-i的分类结果；S5.使用步骤S2的方法将候选图像p-i划分N个子区域,然后使N个局部判别模型对N个子区域分别提取Haar-Like特征,然后使用N个局部分类器分别对N个子区域的Haar-Like特征进行分类,LC-j(p-i)表示第j个局部分类器对子区域的分类结果；S6.结合全局分类模型、局部分类模型的分类结果,对候选图像是否包含目标区域进行判断：                  thr-(GC)、thr-(LC)分别表示全局分类、局部分类的两个阈值,当y(p-i)＝1时,表示候选图像p-i包含有目标区域；S7.将所有的候选图像进行步骤S4～S6的操作从而判断其内是否包含有目标区域,然后将所有判定其内包含有目标区域的候选图像输入至适应生成模型；S8.对于每一张候选图像,适应生成模型对其进行超像素分割,然后提取每个超像素的特征向量,然后使用K-means算法对所有超像素的特征向量进行聚类,并计算候选图像的聚类置信度；然后选取置信度最高的候选图像作为跟踪结果进行输出,输出数据包括当前跟踪结果的置信度conf-T与目标区域的匹配面积area-T,其中其中A-i为每个超像素的面积,N表示候选图像片中包含超像素的个数,                  其中g′-i表示候选图像片包含的超像素,k′-i表示超像素所属聚类,S′-i表示超像素所属聚类的距离,表示k′-i的目标/背景置信度,R′-j表示聚类半径,conf-i′表示g′-i的置信度,L-i表示候选图像片中每个超像素与所属聚类中的模板超像素间的最小空间距离,a-s是控制空间距离权重的权重因子,a-s∈(0,1),表示g′-i与所属聚类的模板超像素在目标区域中的空间距离,表示以a-s为底,以为指数的幂运算；其中A′-j表示当前跟踪结果中每个超像素的像素点个数,表示每个超像素聚类包含的目标区域像素点个数,M表示超像素的总数；三、检测阶段S9.构建模板库生成模型,并使模板库生成模型在当前帧内检测目标区域,返回检测结果的置信度conf-D,然后根据适应生成模型和模板库生成模型的输出结果估计目标区域的当前位置：1)当area-T≥thr-(PL)且conf-T≥thr-(TH)时其中thr-(TH)、thr-(PL)分别表示置信度阈值和匹配面积阈值,此时适应生成模型的跟踪结果具有较高的置信度和匹配面积,适应生成模型正常工作而且适应了目标区域外观,所以把适应生成模型的输出结果作为目标位置输出；然后按照更新策略根据area-T、conf-T对全局分类器GC、局部分类器、适应生成模型的参数进行更新；2)当area-T&lt;thr-(PL)且conf-T≥thr-(TH)时此时适应生成模型的跟踪结果的匹配面积较低,但跟踪结果的置信度仍然高于阈值,所以仍把适应生成模型的输出结果作为目标位置输出；然后按照更新策略根据area-T、conf-T对全局分类器GC、局部分类器、适应生成模型的参数进行更新；3)当area-T≥thr-(PL)且conf-T&lt;thr-(TH)时此时适应生成模型的跟踪结果具有较低的置信度,但具有较高的匹配面积,所以仍把适应生成模型的输出结果作为目标位置输出；然后按照更新策略根据area-T、conf-T对全局分类器GC、局部分类器、适应生成模型的参数进行更新；4)当area-T&lt;thr-(PL),conf-T≥thr-(TH)且conf-D≥thr-(DH)时thr-(DH)表示检测结果置信度的阈值,此时适应生成模型的跟踪结果的置信度和匹配面积都低于预设的阈值,而模板库生成模型检测到一个置信度较高的目标位置,则把模板库生成模型的检测结果当作目标位置输出,然后对全局分类器GC、局部分类器、适应生成模型进行重初始化。</td>   <td>G06T7/246;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   杨帆       </td>   <td>中山大学</td>   <td>一种基于MSCR区域特征的图像复制检测方法</td>   <td>广东省</td>   <td>CN105825504B</td>   <td>2018-06-26</td>   <td>本发明提供了一种基于MSCR区域特征的图像区域复制检测方法。首先对彩色图像提取MSCR特征,然后将这些特征区域归一化为圆形区域。接下来计算每个圆形特征区域的Zernike矩,作为该区域的特征向量。然后计算这些特征向量的欧式距离,找出候选的特征向量匹配对,及对应的特征区域对。通过这些特征区域对在图像当中的位置关系,估计区域复制过程当中的仿射变换矩阵。最后根据仿射矩阵来确定图像是否经过区域复制,并且定位复制区域的位置。本发明使用了一种新的彩色图像特征,并且优化了区域定位方法,具有很好的检测准确性和定位精确度。</td>   <td>1.一种基于MSCR区域特征的图像复制检测方法,其特征在于,包括以下步骤：S1：提取MSCR图像特征：对彩色图像中的每个像素点,计算它与周围像素点之间的颜色差,色差小于给定阈值d时,这些点被聚为一类；重复这个过程,直到所有的点都完成计算；每个类中的所有像素点构成一个MSCR区域；S2：描述特征区域：将每个MSCR不规则区域采用构造仿射不变的方法表示成椭圆,然后将椭圆区域归一化为圆形区域；对每个圆形区域,计算其Zernike矩,生成一个12维特征向量；S3：匹配特征：对于每个特征区域,计算其与其它所有特征区域之间特征向量的欧式距离；比较这些距离中的最小值d-0与次最小值d-1之间的比值d-0/d-1,如果比值小于0.5,则认为距离为d-0的两个特征匹配；S4：聚类并过滤特征区域：如果没有达到设定的匹配的特征对,则检测结束；否则,对于所有匹配的特征,记录所有特征区域的中心点；对于所有的中心点,采用k-means聚类算法,设定k＝2,将这些点聚为两类；删除掉无法被聚类的点；如果一类中少于3个点,则删除所有点,检测结束；S5：估计仿射矩阵：任意三个不共线的特征点对,可计算得到一个仿射矩阵T-i；对于每个矩阵T-i,计算所有特征点对之间的误差,如果误差值小于阈值β,则这个矩阵T-i获得一票；最终得票数最多的矩阵即为所得仿射矩阵；S6：定位复制区域：对于原始图像,使用所得的仿射矩阵进行坐标变换得到变换后的图像；计算原始图像与变换后的图像之间对应位置的相似度,生成一副表示相似度的图像；相似度的值在[0,1]之间,值越大表示相似度越高；如果相似度大于0.5,则认为该位置为复制区域；将生成的相似度图像经过简单的滤波处理,生成最终检测结果图。</td>   <td>G06T7/11;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              陈世哲;                   郭春超       </td>   <td>中山大学</td>   <td>一种基于深度学习的行人再标识方法</td>   <td>广东省</td>   <td>CN104915643B</td>   <td>2018-06-22</td>   <td>本发明公开了一种基于深度学习的行人再标识方法,包括下述步骤：S1、提出一个适用于行人再标识的深度网络结构,从原始图像的裸像素获得他们的相似度得分；S2、提出一个学习排序算法,用于引导深度网络的学习；S3、对训练样本进行排序单元的采样,训练深度网络使用随机梯度下降算法；S4、深度网络训练完成后,对于一个镜头下的行人,网络直接计算它与另一个镜头下的候选人图像的相似度得分,获得匹配结果。本发明通过深度卷积神经网络的方法来建立原始图像对到对应相似度得分的映射,网络的输入是原始图像的像素值,不需要任何预处理和设计手工特征,并能够利用大规模的数据学习出更具判别性和表达性的特征,大大改善了行人再标识的效果。</td>   <td>1.一种基于深度学习的行人再标识方法,其特征在于,包括下述步骤：S1、提出一个适用于行人再标识的深度网络结构,所述深度网络结构采用八层的结构,包含五层卷积层和三层全连接层,深度网络以一对行人的图像为输入,直接从原始图像的裸像素获得所述一对行人的图像相似度得分；S2、提出一个学习排序算法,用于引导深度网络的学习,所述学习排序算法不依赖于任何假设,从排序的本质出发,直接惩罚排序的错乱,使得深度网络经过学习后趋于给正确匹配的样本对分配最高的相似度得分；S3、对训练样本进行排序单元的采样,训练深度网络使用随机梯度下降算法,所述深度网络的训练方法为：随机初始化网络参数,每次迭代随机选取多个排序单元,输入网络中,采用反向传播算法更新网络的参数；所述排序单元包含行人图像x、所述行人图像x的正确匹配x～+和G～-的子集R-x；对于行人图像x,在另一个摄像机中存在一个正确的匹配x～+,其余的样本都被视为负样本,记为G～-,学习排序算法引导深度网络的学习,迭代直到网络在验证集上收敛；S4、深度网络训练完成后,对于一个镜头下的行人,直接将一个镜头下的行人与另一个镜头下的候选人图像输入网络,得到对应的相似度得分,根据获得的得分由大到小排列,返回本次查询的排序结果。</td>   <td>G06K9/00;G06K9/62;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   洪福强       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于传感信息及目标追踪的多模信息系统及其融合方法</td>   <td>广东省</td>   <td>CN104881637B</td>   <td>2018-06-19</td>   <td>本发明公开了一种基于传感信息及目标追踪的多模信息系统,其特征在于,包括视觉信息收集模块,非视觉信息收集模块以及信息匹配模块,所述视觉信息收集模块建立在分布式多摄像头网络,它包括摄像头系统节点和检查点摄像头组,所述非视觉信息收集模块包括传感器信息收集,信息匹配模块包括基于跨摄像头人体目标重识别结果模块和多横数据配模块；本发明具有适用范围广泛,可降低后台图像识别处理压力,提供长效历史数据等优点,并可广泛应用于人物追踪,行为挖掘,公共安全等领域。</td>   <td>1.一种基于传感信息及目标追踪的多模信息系统的融合方法,其特征在于,包括如下步骤：(a)视觉信息收集模块：基于分布式多摄像头网络,对具有非重叠区域设置的独立摄像头中获取的视频数据利用码本codebook的前景提取方法,基于HOG的行人辨认,基于粒子滤波及匈牙利算法进行多目标追踪并分割,基于短时间序列的目标轨迹获取每个目标的角度信息并提取出追踪目标的多维特征信息,提取后的多维特征信息通过组合,获得对特征向量距离；(b)视觉信息收集模块：在检查点,利用检查点摄像头组,获取目标并追踪目标的多维特征,利用不同目标的多维特征信息组合成对特征向量距离,利用对特征向量距离作为新特征,包含了角度信息,该目标追踪信息与身份信息具有与时间约束；(c)非视觉信息收集模块：在检查点,利用传感器信息收集,获取非视觉个人身份信息,包括RFID信息,和/或小区门禁系统信息,和/或身份证信息,将该非视觉个人身份信息与目标追踪信息具有时间约束；(d)信息匹配模块：通过网络通信模块将分布式摄像头网络中每个摄像头节点提取的多维特征信息,角度信息以及摄像头节点信息和时间信息传输到后台的处理模块中,将多维特征信息及角度信息利用训练的分类器进行人物目标重识别；(e) 信息匹配模块：对人物目标重识别获得的目标关联,结合时间约束及与个人身份信息,建立具有多模态信息记录系统。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              朱倩茹;              李丽;                   丁卉       </td>   <td>中山大学</td>   <td>一种组合式空气质量预报模型的构建方法</td>   <td>广东省</td>   <td>CN105069537B</td>   <td>2018-06-19</td>   <td>本发明提出一种基于BP神经网络和多元逐步回归的组合式空气质量预报模型的构建方法,包括以下步骤：(1)基于训练样本集,建立BP神经网络预报模型；(2)基于BP神经网络预报结果,进行高污染情景判定,其具体是：(21)高污染情景的定义；(22)判别方程式的建立；(23)采用神经网络预报值判定法进行判定；(24)基于神经网络预报值判定结果,进行判别方程式的判定；(3)基于高污染情景判定结果,建立高污染的多元逐步回归预报模型。(4)综合以上预报判别过程,输出预报结果。本发明全面提高了城市空气质量预报精度,尤其是高污染情景的预警预报,实现了不同污染程度下稳定的空气质量精准预报。</td>   <td>1.一种组合式空气质量预报方法,其特征是,包括以下步骤：(1)基于训练样本集,建立基于BP神经网络预报模型,所述预报模型的输入层神经元包括选取的多个气象因子；(2)基于BP神经网络预报结果,进行高污染情景判定,其具体是：(21)高污染情景的定义；根据神经网络模型预报结果,确定一般污染情景与高污染情景的浓度限值,低于该限值的,认为属于一般污染情景,标记为组1；高于该浓度限值的,认为属于高污染情景,标记为组2。(22)判别方程式的建立；根据步骤(21)高污染情景设定的浓度限值,将样本数据分为两组,即一般污染情景组1和高污染情景组2,针对不同污染情景建立判别方程式,其具体为：(221)根据步骤(1)选取的气象因子确定输入变量,输入变量为第g个分组中第i个变量的第k个观测值；其中g＝1,2,即有两个分组；i＝1,2,...,n,即每个分组共有i个变量；k＝1,2,...,m-g,即第g组中共有m-g个观测值；计算输入变量的总均值第g组的组内均值总离差w～(ij)、第g组的组内离差(222)采用逐步判别方法,进行变量的引进和剔除；利用Wilks’lambda判别,Wilk统计量最小化的方法,判断依据利用F值,根据组均值的均等性检验结果,设F-(entry)＝2,F-(removal)＝1,即当被加入的变量F值&gt;＝2时才把变量加入到模型,否则变量不能进入模型,当F&lt;＝1时从模型中移出变量,否则模型中的变量不会移出；(223)最终选入d个变量,建立组1和组2的判别方程式：                  其中,x-i指代第i个变量；q-g＝m-g/M,M为样本容量,M＝m-1+m-2；C-(og)、为判别系数,(23)采用神经网络预报值判定法进行判定；依据BP神经网络预报结果,以所述浓度限值为判定标准,判定预测日是高污染情景或一般污染情景；(24)基于BP神经网络预报值判定结果,进行判别方程式的判定；(241)如果BP神经网络预报值判定预测日为一般污染情景,则不需要进行判别方程式的判定,直接判定为组1；(242)如果BP神经网络预报值判定预测日为高污染情景,则将预测日的待判别样本代入判别方程式计算值f-1(x)和f-2(x),如果值f-1(x)大于f-2(x),则判定为1组,否则判定为2组；(3)基于高污染情景判定结果,建立高污染的多元逐步回归预报模型；(4)综合以上预报判别过程,输出预报结果。</td>   <td>G06Q10/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              李发文;              江倩殷;              罗东华;                   袁敏贤       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种基于图分割的车窗提取方法及系统</td>   <td>广东省</td>   <td>CN105809699B</td>   <td>2018-06-19</td>   <td>本发明公开了一种基于图分割的车窗提取方法及系统,方法包括：对获取的车辆图像进行归一化,得到归一化图像；对归一化图像进行基于无向图的图像分割处理；根据各区域质心与质心参考点间的距离对分割后的图像上半部中的各区域进行排序,然后根据排序的结果依次将各区域依次加入到缓存图像中,再采用Freeman链码的一阶差分来实时计算缓存图像的区域边界流畅度,并根据缓存图像的区域边界流畅度提取出候选车窗区域；根据设定的车窗区域判断依据从候选车窗区域中筛选出最终的车窗区域。本发明采用了基于无向图的图像分割方法,抗干扰能力好且鲁棒性强；同时,保证了车窗区域的提取效果和准确性。本发明可广泛应用于图像处理领域。</td>   <td>1.一种基于图分割的车窗提取方法,其特征在于：包括以下步骤：S1、对获取的车辆图像进行归一化,得到归一化图像；S2、根据设定的高斯滤波参数、预分割参数以及区域面积阈值对归一化图像进行基于无向图的图像分割处理,得到分割后的图像；S3、根据各区域质心与质心参考点间的距离对分割后的图像上半部中的各区域进行排序,然后根据排序的结果依次将各区域依次加入到缓存图像中,再采用Freeman链码的一阶差分来实时计算缓存图像的区域边界流畅度,并根据缓存图像的区域边界流畅度提取出候选车窗区域；S4、根据设定的车窗区域判断依据从候选车窗区域中筛选出最终的车窗区域。</td>   <td>G06T7/00;G06T7/136;G06T7/11;G06T5/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张永东;              许跃生;                   谭利       </td>   <td>中山大学</td>   <td>一种基于评估反馈系统的车牌图像光照处理方法</td>   <td>广东省</td>   <td>CN104463130B</td>   <td>2018-06-12</td>   <td>本发明公开了一种基于评估反馈系统的车牌图像光照处理方法,包括下述步骤：(1)将输入的车牌图像由RGB模型转换为HSV模型；(2)对V分量进行一系列光照处理；(3)对增强后的车牌图像进行局部自适应阈值处理得到车牌二值图像；(4)评估车牌二值图像中车牌字符情况；(5)判断是否满足停止反馈的条件；(6)判断是否需要人眼观察的选择,若需要则对车牌二值图像骨架化,然后作为种子点在车牌增强图像上进行区域生长法,并对生长区域进行像素值的提升；若不需要则直接进行车牌字符识别并输出计算机识别结果。本发明有效地解决了车牌号码在复杂光照环境下难以被人眼和计算机识别的问题,从而提高了车牌号码的识别率。</td>   <td>1.一种基于评估反馈系统的车牌图像光照处理方法,其特征在于,包括下述步骤：(1)将输入的车牌图像由RGB模型转换为HSV模型；(2)对V分量进行一系列光照处理,首先用Gamma校正增强图像亮度,再进行高斯差分滤波去除光照中的高频分量,然后根据掩膜函数提取需要进一步处理的区域,最后采用对比度均衡化增强图像光照的对比度,从而达到去除光照中不均匀同时最大程度保留图像有用细节并增强图像对比度；(3)对增强后的车牌图像进行局部自适应阈值处理得到车牌二值图像,具体为：(3-1)将图像分成m*n个等大的小区域,其中n&gt;m&gt;0；(3-2)每个小区域内进行OTSU处理,将所有阈值组成的二维矩阵记作Mat-T-0；进行OTSU处理的具体方法为：(3-2-1)设定一个初始阈值T,其中T的计算公式如下所示：T＝wp-1+(1-w)p-2式中,p-1和p-2为图像中任意像素值；w为权重值；(3-2-2)利用T分割图像,产生两组相像素：亮度值大于等于T的所有像素组成G-1,亮度值小于T的所有像素组成G-2；(3-2-3)计算G-1和G-2范围内的像素的平均亮度值μ-1和μ-2；(3-2-4)计算新的T,如下式所示：T＝wμ-1+(1-w)μ-2(3-2-5)重复步骤(3-2-2)至(3-2-4),直到T的变化小于一个预定值T-0为止；(3-3)对所有Mat-T-0进行3*3的高斯滤波输出Mat-T-1,然后根据Mat-T-1进行每个区域的图像二值化(4)评估车牌二值图像中车牌字符情况,即进行基于八邻域的连通域标记并计算每个连通域的面积、位置、长宽比和域间间距参数；(5)判断是否停止反馈,即首先判断是否满足车牌字符标准,即将连通域参数与经验阈值相比较,若满足则输出该二值图像并退出评估反馈系统,若不满足则对比历史情况并缓存最好结果及对应二值图像；然后判断是否达到设定的循环上限的次数,若达到则输出缓存中二值图像并退出评估反馈系统,若未达到则输出调整后的新光照处理参数并重新进行光照处理；(6)判断是否需要人眼观察的选择,若需要则将步骤(4)中车牌二值图像与车牌增强图像进行图像融合输出视觉增强结果,即对车牌二值图像骨架化,然后作为种子点在车牌增强图像上进行区域生长法,并对生长区域进行像素值的提升；若不需要则直接进行车牌字符识别并输出计算机识别结果。</td>   <td>G06K9/00;G06K9/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              梅岭;                   冯展祥       </td>   <td>中山大学</td>   <td>一种基于WLD-TOP的活体人脸检测方法</td>   <td>广东省</td>   <td>CN104933414B</td>   <td>2018-06-05</td>   <td>本发明公开了一种基于WLD-TOP的活体人脸检测方法,包括以下步骤：(1)训练阶段：读取训练集视频,对每一帧进行人脸区域检测,并转换成灰度人脸图像帧序列,构造三维图像矩阵,然后构造滤波模板并计算WLD特征,再生成WLD-TOP特征向量,最后将特征向量输入SVM分类器进行训练,从而建立SVM模型；(2)测试阶段：对于测试的图像序列,对每一帧进行人脸检测并转换为灰度人脸图像序列,然后构造三维图像矩阵及滤波模板,计算WLD特征,生成WLD-TOP特征向量,最后送入训练好的SVM模型,得出活体人脸检测结果。本发明利用韦伯定理,在LBP-TOP基础上,不仅体现了邻域像素和中心像素的大小关系,还量化了邻域像素和中心像素的差异,使得描述子的特征更加全面。</td>   <td>1.一种基于WLD-TOP描述子的活体人脸检测方法,其特征在于,包括下述步骤：S1、训练阶段：读取训练集视频,对每一帧进行人脸区域检测,并转换成灰度人脸图像帧序列,构造三维图像矩阵,然后构造滤波模板并计算WLD特征,再生成WLD-TOP特征向量,最后将特征向量输入SVM分类器进行训练,从而建立SVM模型；S2、测试阶段：对于测试的图像序列,对每一帧进行人脸区域检测并转换为灰度人脸图像帧序列,然后构造三维图像矩阵及滤波模板,计算WLD特征,生成WLD-TOP特征向量,最后送入训练好的SVM模型,得出活体人脸检测结果；步骤S1中,构造滤波模板并计算WLD特征的方法为：分别选取X、Y坐标边界阈值L-X、L-Y,确定WLD描述子的滑动滤波模板长度p,构成p*p的滤波模板对三维图像矩阵I的三个正交平面XY、XT和YT,分别利用WLD方法的p*p滤波模板计算除去边界阈值后的各中心像素点的差分激励ξ和方向梯度Φ-t,计算方法如下:首先假设计算的中心点是x-c,它的八个相邻点分别是x-i,i＝0,...,p～2-1,定义令v-1＝x-5-x-1,v-2＝x-7-x-3,取定义令其中θ'∈[0,2π),S是方向梯度特征的维数,则Φ-t＝0,1,...,S-1,由上述步骤得到WLD的描述子{ξ'(x-c),Φ-t}；步骤S1中,WLD-TOP计算过程为：首先对ξ'(x-c)作如下归一化：故ξ(x-c)取值为0到N-1这N个整数值；Φ-t归一化到用整数0到S-1表示的S个方向,以XY平面为例,对WLD{ξ(x-c),Φ-t}二维直方图进行降维,固定Φ-t,求对应的ξ(x-c)子直方图,根据S维的Φ-t分为S组子直方图,按照Φ-t从小到大的顺序依次连接这S个子直方图,定义f(x,y)＝N×Φ-t+ξ(x-c),则XY平面的直方图h-(i,XY)＝∑-(x,y)M{f(x,y)＝i},i＝0,1,...,NΦ-t-1,其中从而构成NΦ-t维的WLD直方图H-(XY),再用此法得到三个正交平面(n＝0:XY,n＝1:XT,n＝2:YT)的直方图h-(i,n)＝∑-(x,y,t)M{f(x,y,t)＝i},i＝0,1,...,NΦ-t-1,将它们转为NΦ-t维的行向量H-n,依次前后连接,生成3NΦ-t维的WLD-TOP特征行向量H-(WT)＝[H-0 H-1 H-2]。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              杨斯媚;              艾博雅;                   粟涛       </td>   <td>中山大学</td>   <td>一种多宏单元多时钟芯片的时钟树综合方法</td>   <td>广东省</td>   <td>CN105138735B</td>   <td>2018-05-25</td>   <td>本发明公开了一种多宏单元多时钟芯片的时钟树综合方法,包括以下步骤：S1.按照一定的相邻缓冲器的连线距离范围,在各个宏单元之间手动插入多个缓冲器,构建多个H型时钟树；S2.将H型时钟树的缓冲器全部替换成反相器对；S3.划分芯片的所有时钟的重要等级；S4.按照时钟的重要等级从高到低的顺序,依次对每个时钟做RC平衡时钟树。该方法适用于宏单元和时钟都特别多的芯片,有着良好的时钟偏移和时钟延迟,并且所用器件少,功耗小。</td>   <td>1.一种多宏单元多时钟芯片的时钟树综合方法,其特征在于,包括以下步骤：S1.按照相邻缓冲器的连线距离范围,在各个宏单元之间手动插入多个缓冲器,构建多个H型时钟树；S2.将H型时钟树的缓冲器全部替换成反相器对；S3.划分芯片的所有时钟的重要等级；S4.按照时钟的重要等级从高到低的顺序,依次对每个时钟做RC平衡时钟树。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;                   李高翔       </td>   <td>中山大学</td>   <td>一种应用于智能微电网的异质载荷调度和能量管理方法</td>   <td>广东省</td>   <td>CN104484757B</td>   <td>2018-05-04</td>   <td>本发明公开了一种应用于智能微电网的异质载荷调度和能量管理方法,是基于用户延迟容忍用电请求模型和智能微电网总开销模型的异质载荷调度和能量管理方法,具体包括：将智能微电网运行周期切割成T个时间段；在每一个时间段内,获取各用户的延迟容忍和延迟敏感用电请求信息；根据系统状态信息以及用户请求信息决策出用户延迟容忍用电请求调度策略与能量管理策略,决策的约束条件为：满足用户延迟容忍用电请求QoE的同时最小化智能微电网系统的总开销；储能设备的能量水平始终处于其上下界之内。该方法利用了用户延迟容忍用电请求和电价的波动,能有效节省智能微电网的运营成本。</td>   <td>1.一种应用于智能微电网的异质载荷调度和能量管理方法,其特征在于,该方法是基于用户延迟容忍用电请求模型和智能微电网总开销模型的异质载荷调度和能量管理方法,具体包括以下步骤：S1：将智能微电网运行周期切割成T个时间段；S2：在每一个时间段内,获取各用户的延迟容忍和延迟敏感用电请求信息；S3：根据系统状态信息以及用户请求信息决策出用户延迟容忍载荷调度策略与能量管理策略,决策的约束条件为：满足用户延迟容忍用电请求的QoE的同时能最小化智能微电网系统的总开销；S4：根据决策策略对用户延迟容忍用电请求进行调度并执行储能设备充放电操作；用户延迟容忍用电请求模型具体为：设智能微电网服务的用户数量为N,定义所有用户在时刻t产生的延迟容忍请求为Γ(t)：Γ(t)＝Γ-0(t)+Γ-1(t)+…+Γ-i(t)+…+Γ-(N-1)(t)其中Γ-i(t)是一个多元组i表示用户索引,t表示当前时刻, 表示单位时刻智能微电网为一个用户延迟容忍用电请求供给的最大电能,E-i(t)表示用户i在时刻t提出的延迟容忍用电请求,E-i(t)可进一步表示为：                  其中表示智能微电网在t+j时刻为用户i在时刻t提出的延迟容忍用电请求分配的电能,D-(max)表示智能微电网对延迟容忍用电请求支持的最大延时；即在时刻t智能微电网为所有用户的延迟容忍用电请求提供的电能E-(dt)(t)为：所述步骤S3中将最小化智能微电网总开销的优化问题转化为Lyapunov优化问题,将用户请求信息和系统状态信息作为该优化问题的已知条件,将用户 延迟容忍请求的QoE值、储能设备的容量以及单位时刻智能微电网可为一个用户供给的最大电能作为约束条件,并同时设置一个可容忍QoE的下界来保证用户体验质量,然后解出最优解作为决策结果；将对于储能设备的约束条件转化为基于队列稳定性的条件,在该优化问题中定义一个虚拟队列B(t)：                  其中E-(rb)(t)表示时刻t储能设备的储能水平,表示任意单位时刻最多放电的能量,表示储能设备的最低能量水平,表示电价的最大值,V是一个调整参数；根据Lyapunov优化框架,定义L(B(t))和Δ(B(t))如下：                  Δ(B(t))＝E{(L(B(t+1))-L(B(t)))|B(t)}L(B(t))用于衡量队列的大小,Δ(B(t))表示相邻两个时间段队列的变化量；根据Lyapunov优化框架,依据用户用电请求信息和系统状态信息在每一个时间段内计算出满足min(Δ(B(t))+V(C-g(t)+C-b(t)+C-h(t)+C-e(t)))的用户延迟容忍载荷调度策略和能量管理策略,完成本时刻的决策。</td>   <td>G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;              陈湘萍;              马超;                   訾飞       </td>   <td>中山大学</td>   <td>一种最佳学习方案推送方法及系统</td>   <td>广东省</td>   <td>CN104765842B</td>   <td>2018-05-01</td>   <td>本发明实施例公开了一种最佳学习方案推送方法及系统,其中,该方法包括：构建学科知识技能图；根据知识点评分方法对学科知识技能图中所有知识点进行评分,获得每个知识点的评分；根据每个知识点的评分获取最佳知识点；从题库中获取最佳知识点所对应的题目,形成最佳学习方案,并将最佳学习方案推送给用户。在本发明实施例中,通过构建知识技能图,解决知识点的标准化、可视化和优先级问题,通过对知识技能图中各知识点的重要性进行评估形成最佳学习方案；将所形成的最佳学习方案推送给学生,用于解决不能根据学生实际学习状态的缺陷,解决了传统计算机辅助教育中存在的学生学习缺乏针对性的问题,使学生在限定时间中产生最大学习效益。</td>   <td>1.一种最佳学习方案推送方法,其特征在于,所述方法包括：提取每个知识点文件中的知识点名称、知识点描述、先修知识点名称、知识点对应的题目,并写入知识点优先级次序文件G中,读取所述知识点优先级次序文件G中的每条记录,存入知识库的知识表中；构建知识点的有向无环图DAG,读取知识表中的每条记录,生成当前知识点和先修知识点集合在DAG中对应的节点集合,设置当前知识点为先修知识点的子节点,设置先修知识点的孩子节点为当前知识点；利用图形化的界面语言生成图形化的知识技能图；获取用户设定学科的总学习时间,获取用户输入的在图形化的知识技能图中各知识点的个人偏好值；根据所述总学习时间和各知识点的个人偏好值,更新知识技能图中知识点中个人偏好值,构建学科知识技能图；根据知识点评分方法对所述学科知识技能图中所有知识点进行评分,获得每个知识点的评分；根据所述每个知识点的评分获取最佳知识点；从题库中获取最佳知识点所对应的题目,形成最佳学习方案,并将所述最佳学习方案推送给用户。</td>   <td>G06F17/30;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈荣军;              谭洪舟;              钟秀媚;              朱雄泳;              谢舜道;                   刘松劲       </td>   <td>中山大学;中山大学花都产业科技研究院</td>   <td>一种QR码检测与校正提取方法及IP核</td>   <td>广东省</td>   <td>CN104346597B</td>   <td>2018-04-27</td>   <td>本发明涉及一种QR码检测与校正提取方法及IP核,是通过硬件电路直接对摄像头逐行、逐个像素输出的图像数据流进行QR码实时定位检测与QR码校正提取,而不需要拍照存储后才进行处理,可以极大地提高检测速度和识别率。该检测方法在QR码实时定位检测阶段是基于摄像头获取的相邻两帧图像中的二维码位置、形状等变化不大的基础上的,即在图像采集过程中二维码没有快速移动或形变的情况,处理一帧图像时依据的是前一帧图像得到的参数,在处理当前图像的同时更新相应的参数,为后一帧图像的处理提供依据。在QR码旋转校正与提取阶段,采用改进型CORDIC算法对QR码进行旋转校正和提取,用移位和加法代替乘除法,可以大大节省硬件资源。</td>   <td>1.一种QR码检测与校正提取方法,其特征在于,通过硬件电路直接对摄像头逐行、逐个像素输出的图像数据流进行QR码实时定位检测,并采用改进型CORDIC算法对QR码进行旋转校正与提取,实现QR码的检测与校正提取；所述采用改进型CORDIC算法对QR码进行旋转校正与提取的具体实现方式为：在前级获得QR码的位置信息后,通过同一条改进型CORDIC算法流水线的不同模式分别计算QR码的旋转角度和对QR码进行校正提取；首先采用矢量模式下的CORDIC改进算法模块计算出QR码的旋转角度,是在初始的流水线前端增加一级迭代角度为α-(-3)＝arctan(2～3)的流水级,使其能逼近0-360°内的任意旋转角度；然后采用旋转模式下的CORDIC改进算法模块提取出旋转校正后的QR码图像。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;              赵有婷;              江倩殷;              张格格;                   何兆成       </td>   <td>中山大学</td>   <td>一种车牌图像去隐私的方法</td>   <td>广东省</td>   <td>CN105243668B</td>   <td>2018-04-27</td>   <td>本发明公开一种车牌图像去隐私的方法,采用方式1、方式2和方式3中的任一种或组合来实现车牌图像去隐私；方式1包括：获取卡口车辆图像；提取车辆的车牌图像；采用标准矩形框分割出车牌中的字符图像；重新排列标准矩形框中的字符图像,得到新的车牌图像；方式2包括：获取卡口车辆图像；提取车辆的车牌图像；采用标准矩形框分割出车牌中的字符图像；将车牌中的数字“6”或“9”的外接矩形框旋转180°,得到新的车牌图像；方式3包括：获取卡口车辆A和车辆B的图像；提取车辆A和车辆B的车牌图像；修改车辆A的车牌大小和倾斜角,使其和车辆B的车牌一致；车辆B采用用修改后车辆A的车牌图像,得到新的C车车牌图像。</td>   <td>1.一种车牌图像去隐私的方法,其特征在于,采用方式1、方式2和方式3中的任一种或组合；所述方式1包括以下步骤：S11.获取卡口车辆图像；S12.提取车辆的车牌图像；S13.采用标准矩形框分割出车牌中的字符图像；S14.重新排列标准矩形框中的字符图像,得到新的车牌图像；所述方式2包括以下步骤：S21.获取卡口车辆图像；S22.提取车辆的车牌图像；S23.采用标准矩形框分割出车牌中的字符图像；S24.将车牌中的数字“6”或“9”的外接矩形框旋转180°,得到新的车牌图像；所述方式3包括以下步骤：S31.获取卡口车辆A和车辆B的图像；S32.提取车辆A和车辆B的车牌图像；S33.修改车辆A的车牌大小和倾斜角,使其和车辆B的车牌一致；S34.车辆B采用修改后车辆A的车牌图像,得到新的C车车牌图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         庞志勇;              陈弟虎;                   朱冬梅       </td>   <td>中山大学</td>   <td>一种基于乳腺磁共振图像的计算机辅助肿块检测方法</td>   <td>广东省</td>   <td>CN104732213B</td>   <td>2018-04-20</td>   <td>本发明涉及医学图像处理与模式识别领域,为解决现有技术下肿块的分割效果不佳,以及分类实验中准确率、灵敏度跟特异度不高的问题,本发明提供了一种基于乳腺磁共振图像的计算机辅助肿块检测方法,包括以下步骤：S1、对乳腺磁共振图像进行感兴趣区域提取；S2、在所述感兴趣区域中提取分割出初始肿块区域,并确定所述初始肿块区域轮廓线；S3、计算所述初始肿块区域特征参数的权重分布；S4、选取权重系数大于基准权重系数的所述初始肿块区域特征参数进行训练分类以获取优化特征参数；S5、将所述优化特征参数输入分类器中,利用支持向量机分类方法对其进行分析,确定最终肿块区域并显示给用户。该检测方法对肿块有良好的分割效果,有效提高了分类实验中准确率、灵敏度跟特异度,将检测结果作为“第二意见”提供给放射科医生,可有效降低医生的误诊率和漏诊率。</td>   <td>1.一种基于乳腺磁共振图像的计算机辅助肿块检测方法,其特征在于,包括以下步骤：S1、对乳腺磁共振图像进行感兴趣区域提取；S2、在所述感兴趣区域中提取分割出初始肿块区域,并确定所述初始肿块区域轮廓线；所述S2中利用基于Chan-Vese的水平集分割方法提取所述初始肿块区域轮廓线,所述基于Chan-Vese的水平集分割方法的具体步骤是：S2a、输入所述感兴趣区域；S2b、进行邻域抑制操作；S2c、进行高斯去噪滤波操作；S2d、进行直方图均衡化操作；S2e、输出优化感兴趣区域；S2f、利用所述优化感兴趣区域进行Chan-Vese水平集求解以获取目标肿块区域轮廓线；所述步骤S2f中获取目标肿块区域轮廓线的具体步骤是：S2f1、对所述步骤S2e中的优化感兴趣区域建立Mumford-Shah的图像分割模型获取肿块边界曲线C-0,将所述优化感兴趣区域划分为若干个平滑区域；所述优化感兴趣区域I(x,y)的定义域为Ω,对于由所述肿块边界曲线C-0分割出的平滑区域I～(MS)(x,y)有以下方程式：                                                      (                              C                0                            ,                                                I                  0                                                  M                  S                                            )              =                              argminF                                  M                  S                                            (                              I                0                            ,              C              )                                                                                          F                                  M                  S                                                            (                                  I                  0                                ,                C                )                            =              &amp;mu;              L              e              n              g              t              h                              (                C                )                            +              &amp;lambda;                              &amp;Integral;                &amp;Omega;                            |                              I                -                                                      I                    0                                    2                                            |              d              x              d              y              +                              &amp;Integral;                                  &amp;Omega;                  /                  C                                            |                                                                    I                    0                                    2                                            |              d              x              d              y                                            ;  ]]>其中下式右边第一项为肿块轮廓曲线的长度项,第二项为肿块图像的方差项,第三项为肿块图像的边界项,当F～(MS)(I-0,C)取最小值,arg min F有极小值,所述优化感兴趣区域被肿块边界曲线C-0划分为若干个平滑区域,同时得到肿块边界曲线C-0；S2f2、通过建立能量泛函以获取全局最优的图像分割效果；定义闭合轮廓曲线C为子集的边界,设所述图像I-(最优)被任意闭合肿块边界曲线C-0划分为两个同质区域,C-0内和C-0外的灰度分别为：I-(最优)的灰度为：对于被任意闭合活动轮廓线C划分为内部ω-1和外部ω-2的所述优化感兴趣区域I,可得到以下方程式：    F          (      C      )        =          F      1              (      C      )        +          F      2              (      C      )        =          &amp;Integral;              i        n        s        i        d        e                            |        I                  (          x          ,          y          )                -                  C          1                |            2        d    x    d    y    +          &amp;Integral;              o        u        t        s        i        d        e                            |        I                  (          x          ,          y          )                -                  C          2                |            2        d    x    d    y  ]]>上式中,C-1、C-2是常数,分别为曲线内外部的拟合中心,也即平均灰度；当C＝C-0时,上式取得最小值；以上式为基础,添加长度平滑项μ·length(C)和面积平滑项v·Area(inside(C))得到以下能量泛函方程式：F(c-1,c-2,C)＝F-1(C)+F-2(C)＝μ·length(C)+ν·Area(inside(C))+λ-1∫-(inside)|I(x,y)-c-1|～2dxdy+λ-2∫-(outside)|I(x,y)-c-2|～2dxdy其中参数c-1、c-2如下所示：          inf              c        ,                  c          1                ,                  c          2                      F          (              c        1            ,              c        2            ,      C      )        ;  ]]>μ,ν≥0,λ-1,λ-2＞0是权重系数,设置为ν＝0,λ-1＝λ-2＝1,使上述能量泛函最小化,得到全局最优的图像分割效果；S2f3、对上述Chan-Vese模型进行水平集求解以获取所述目标肿块区域轮廓线；所述目标肿块区域轮廓线以水平集形式的数值解表示为：                  &amp;part;        &amp;phi;                    &amp;part;        t              =          &amp;delta;      &amp;epsiv;              (      &amp;phi;      )        &amp;lsqb;    &amp;mu;    &amp;dtri;    &amp;CenterDot;                  &amp;dtri;        &amp;phi;                    |                  &amp;dtri;          &amp;phi;                |              -    v    -          &amp;lambda;      1                      (        I        (                  x          ,          y                )        -                  c          1                )            2        +          &amp;lambda;      2                      (        I        (                  x          ,          y                )        -                  c          2                )            2        &amp;rsqb;  ]]>φ(0,x,y)＝φ-0(x,y)其中零水平集φ来表示所述目标肿块区域轮廓线；S2h、判断所述目标肿块区域轮廓线是否收敛；如果判断结果为否,回到步骤S2f继续执行；如果判断结果为是,停止迭代,输出所述目标区域轮廓线即为所述初始肿块区域轮廓线；S3、计算所述初始肿块区域特征参数的权重分布；S4、选取权重系数大于基准权重系数的所述初始肿块区域特征参数进行分类训练以获取优化特征参数；S5、将所述优化特征参数输入分类器中,利用支持向量机分类方法对其进行分析,确定最终肿块区域并显示给用户。</td>   <td>G06K9/00;G06K9/54;G06K9/62;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何李域;                   刘红梅       </td>   <td>中山大学</td>   <td>一种基于Otsu的花朵图像分割方法</td>   <td>广东省</td>   <td>CN105719304B</td>   <td>2018-04-13</td>   <td>本发明提出一种基于Otsu的花朵图像的分割方法,属于图像处理方面的领域。本方法利用Otsu自动阈值分割方法对目标花朵图像进行处理,得出花朵图像的前景部分(花朵)和背景部分(其他非花朵部分),本发明主要是提出一种方法,通过预处理选择算法,电脑能对花朵图像进行筛选,再根据不同的情况自动选择根据花朵图像的不同颜色分量R值、H值还是S值来对花朵图像进行阈值分割,最终对任一花朵图像能够得出一个较好的分割结果。本发明可用于图像识别特别是花朵图像识别方面,也可用于各种植物搜索引擎对植物图像进行识别和搜索。</td>   <td>1.一种基于Otsu的花朵图像的分割方法,其特征在于,该方法对花朵图像进行了选择和判定,根据输入花朵图像的特征,自动选择采用根据R值、H值或者S值对输入图像进行阈值分割；对花朵图像进行分割的具体过程步骤如下：11)遍历图像所有像素点,根据R、G、B三个值的相对大小,除去花朵中的绿色部分；12)划分花朵图像,将花朵图像四个边角部分的小区域划分为背景部分,且设中间部分的大区域内至少存在一部分的目标部分；13)对花朵图像进行判定,选择适应的值作为计算该花朵图像阈值的标准,再对该花朵图像进行Otsu自动阈值分割；根据输入花朵图像的特征,自动选择采用根据R值、H值或者S值对输入图像进行阈值分割的实现方式为：21)判断花朵图像中间部分的大区域,若存在白色像素点,则该花朵是存在白色,此时采用R值作为计算阈值的标准,即根据R值进行阈值分割；22)判断花朵图像四个边角部分的小区域,若这四个小区域内有至少一个区域,R值最大的点占了这个区域中的50%以上,则采用H值作为计算阈值的标准,即根据H值对花朵图像进行阈值分割；23)判断花朵图像四个边角部分的小区域,若这四个小区域内至少有一个区域,R、G、B三个值之间相差不大于15,则采用S值作为计算阈值的标准,即根据S值对花朵图像进行阈值分割；24)对背景单调的绿色花朵进行阈值分割,首先对花朵图像根据R值进行阈值分割,之后遍历花朵图像的所有像素点,逐点取反；通过以上步骤,最终得到合适的R值、H值或者S值来对花朵图像进行阈值分割。</td>   <td>G06T7/11;G06T7/136;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何兆成;                   周亚强       </td>   <td>中山大学</td>   <td>一种基于鸟类物种进化机制的路径优化方法</td>   <td>广东省</td>   <td>CN104504477B</td>   <td>2018-01-09</td>   <td>本发明公开一种基于鸟类物种进化机制的路径优化方法,包括：随机生成若干条可行路径,每一条路径对应一只鸟类的染色体,每一个节点对应染色体上的一个基因,基因长度为路径长度,基因顺序为路径节点顺序；确定经过可行路径所需的花费作为适应性函数；根据经过每条可行路径花费的多少对可行路径进行排序,并对其进行分类；计算利用多夫多妻制类的可行路径的数目,并重新随机生成一定比例的新可行路径,替代属于多夫多妻制类的可行路径；各条可行路径按照其所属鸟类物种进化方式进行繁殖重构,完成繁殖重构后,比较父代个体与子代个体的路径长度,保留花费少的可行路径；重复迭代到达设定的迭代次数阈值,获取若干条可行路径；对获取的可行路径中选取花费最少的路径作为优选路径。</td>   <td>1.一种基于鸟类物种进化机制的路径优化方法,其特征在于,是应用于交通领域,用于解决交通路径的路径优化,其过程包括：S1.随机生成若干条可行路径,每一条路径对应一只鸟类的染色体,每一个节点对应染色体上的一个基因,基因长度为路径长度,基因顺序为路径节点顺序；S2.确定经过可行路径所需的花费作为适应性函数；S3.根据经过每条可行路径花费的多少对可行路径进行排序,并对其进行分类,其具体分类方式如下：1)根据花费的多少将可行路径分为雌性类和雄性类,其中,花费小于等于阈值A时,则对应的可行路径属于雌性类,否则属于雄性类；2)对属于雌性类的可行路径进行分类,根据花费将其分为单性生殖类和一妻多夫制类,其中,花费小于等于阈值B时,则对应的可行路径属于单性生殖类,否则属于一妻多夫制类；对属于雄性类的可行路径进行分类,根据花费将其分为单配制类、一夫多妻制类和多夫多妻制类,其中,花费小于等于阈值C时,则对应的可行路径属于单配制类,花费大于阈值C且小于等于阈值D时,则属于一夫多妻制类,花费大于阈值D时,则属于多夫多妻制类；其中A&gt;B,D&gt;C&gt;A；S4.计算属于多夫多妻制类的可行路径的数目为E,并重新随机生成αE个新可行路径,0&lt;α&lt;1,替代属于多夫多妻制类的αE个可行路径；S5.对各条可行路径按照其所属鸟类物种进化方式进行繁殖重构,完成繁殖重构后,比较父代个体与子代个体的路径长度,保留花费少的可行路径；S6.重复步骤S3到S5直到到达设定的迭代次数阈值,获取若干条可行路径；S7.对步骤S6获取的可行路径中选取花费最少的路径作为优选路径。</td>   <td>G06Q10/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张永东;              谭利;                   许跃生       </td>   <td>中山大学</td>   <td>一种基于清晰度和亮度评估的车牌快速定位方法</td>   <td>广东省</td>   <td>CN104732227B</td>   <td>2017-12-26</td>   <td>本发明公开了一种基于清晰度和亮度评估的车牌快速定位方法,包括下述步骤：(1)对输入图像进行基于噪声和锐度的清晰度评估；(2)若清晰度不足则进行梯度锐化处理,若清晰度过高则进行高斯模糊处理；(3)由RGB图转换为灰度图；(4)对灰度图进行亮度评估；(5)若亮度异常则进行光照归一处理；(6)通过Scharr算子提取图像中垂直边缘；(7)进行局部自适应阈值处理；(8)通过形态学处理过滤噪声,以及使垂直边缘融合成连通区域；(9)对连通区域进行区域标记,根据中国车牌的特征进行筛选并得到车牌区域。</td>   <td>1.一种基于清晰度和亮度评估的车牌快速定位方法,其特征在于,包括下述步骤：(1)对输入图像进行基于噪声和锐度的清晰度评估；所述清晰度评估由噪声评估和锐度评估组成,在得到图像的噪声评估值和锐度评估值后,通过加权关系得到图像的清晰度评估值,计算清晰度评估值的公式如下：Quality＝wNoise+(1-w)Sharpness其中,w为权重值,取值范围在0和1之间；所述噪声评估是通过先对图像进行OTSU阈值处理得到二值图,然后计算连通区域中面积小于给定阈值的占比,最后通过线性变换得到噪声评估值,计算噪声评估值的公式如下：    N    o    i    s    e    =          L      1              &amp;Sigma;                        Area          i                =        0                    T                  a          r          e          a                            Comp      i        /          &amp;Sigma;                        Area          i                =        0            &amp;infin;              Comp      i        +          L      2      ]]>其中,Comp-i是第i个区域,Area-i是第i个区域的面积,T-(area)是判断面积是否过小的给定阈值,L-1和L-2是线性变换的参数；所述锐度评估采用的是点锐度算法,对图像的每点取8邻域点与之相减,先求8个差值的加权和,再将所有点所得值相加除以像素总个数,计算锐度评估值的公式如下：    S    h    a    r    p    n    e    s    s    =          &amp;Sigma;              i        =        1                    m        &amp;times;        n                    &amp;Sigma;              k        =        1            8        |                  d        f                    d        x              |    /          (      m      &amp;times;      n      )      ]]>其中,k是第k个邻域像素,m和n为图像的长和宽,df为灰度的变化幅值,dx为像素点间的距离增量；(2)对清晰度不足的图像进行梯度锐化处理,清晰度过高的图像进行高斯模糊处理；(3)对步骤(2)处理后的图像由RGB图转换为灰度图；(4)对灰度图进行亮度评估,即对灰度图像进行亮度过高或亮度不足两种情况进行评估；(5)若亮度异常则进行光照归一处理；(6)通过Scharr算子提取图像中垂直边缘；(7)进行局部自适应阈值处理；(8)通过形态学处理过滤噪声,以及使垂直边缘融合成连通区域；(9)对连通区域进行区域标记,根据中国车牌的特征进行筛选并得到车牌区域。</td>   <td>G06K9/32;G06K9/54</td>  </tr>        <tr>   <td>中国专利</td>   <td>         秦雁;              韦小波;              邓孺孺;              梁业恒;              熊龙海;              刘旭拢;              刘英飞;              卢世军;              刘永明;                   林梨       </td>   <td>中山大学</td>   <td>一种消除水域遥感数据镜面反射影响的方法</td>   <td>广东省</td>   <td>CN105205789B</td>   <td>2017-12-26</td>   <td>本发明公开了一种消除水域遥感数据镜面反射影响的方法,其特征在于,包括以下步骤：(A)从图像上提取暗像元,迭代计算大气散射系数、大气透过率、和天空光辐照度；(B)对整幅图像进行大气纠正；(C)消除天空光镜面反射光；(D)消除太阳直射光镜面反射光。该方法有效地消除了光学波段遥感数据中每个水域像元中的水面镜面反射光的影响,为精确的水质遥感、水下地或形地物遥感提供了必要的前提基础。</td>   <td>1.一种消除水域遥感数据镜面反射影响的方法,其特征在于,包括以下步骤：(A)从图像上提取山区植被阴影像元或清深水体像元,迭代计算大气散射系数、大气透过率和天空光辐照度；(B)对图像中所有像元进行大气纠正；(C)消除天空光镜面反射光；(D)消除太阳直射光镜面反射光；其中,所述步骤(A)中迭代计算大气散射系数、大气透过率和天空光辐照度的步骤包括：(A1)读取山区植被阴影像元或清深水体像元的表观反射率R-(vd),根据山区植被阴影像元或清深水体像元的表观反射率R-(vd)的计算公式：式中：ω为大气散射系数,T为大气透过率,R-v为地物反射率,P(θ)为大气散射相函数,θ为散射角,首先忽略等式(1)右边第一项的值,计算得到大气散射系数的初值(A2)：根据大气透过率的初值的计算公式：T′＝e～(-ω′),计算出大气透过率的初值T′,将大气透过率的初值T′代入等式(1)右边第一项中的T,将大气散射系数的初值ω′代入等式(1)右边第一项中的ω,计算得到大气散射系数(A3)：计算天空光辐照度：将步骤(A2)中计算得到的大气散射系数ω-1代入天空光辐照度计算公式计算天空光辐照度E-(sky1),式中：c为大气纠正前后的大气散射系数比,为测量值；(A4)：将步骤(A2)中计算得到的大气散射系数ω-1代入大气透过率的计算公式T＝e～(-ω),计算出大气透过率T-1；(A5)：将步骤(A2)中计算得到的大气散射系数ω-1代入等式(1)右边第一项中的ω、将步骤(A4)中计算得到的大气透过率T-1代入等式(1)右边第一项中的T,计算出精度高于大气散射系数ω-1的大气散射系数ω-2；根据步骤(A3)计算出精度更高的天空光辐照度E-(sky2)；根据步骤(A4)计算出精度高于大气透过率T-1的大气透过率T-2；依此办法,迭代计算出精度高于大气散射系数ω-2的大气散射系数ω-k、精度高于大气透过率T-2的大气透过率T-k和精度高于天空光辐照度E-(sky2)的天空光辐照度E-(skyk)；其中,k&gt;2。</td>   <td>G06T5/00;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;              林许;                   孙伟       </td>   <td>中山大学</td>   <td>一种基于九宫格的灰度图像空域隐写方法</td>   <td>广东省</td>   <td>CN104537601B</td>   <td>2017-12-08</td>   <td>本发明提供一种基于九宫格的灰度图像空域隐写方法,该方法构造九宫像素点块模板,根据九宫格像素点块模板得到待处理图像每一像素点对应数值序列,计算图像每一像素点数值序列的标准差并排序,根据秘钥选择N个由大到小排列的标准差值所对应的像素点在图像中的位置进行LSB匹配嵌入得到隐写图像。该方法本发明选取了图像中高频区域如边缘、纹理位置进行秘密信息的嵌入,具有很强的抗攻击能力。</td>   <td>1.一种基于九宫格的灰度图像空域隐写方法,其特征在于,包括以下步骤：S1：构造一个3×3大小的九宫格像素点块模板,其中每一宫格是一个小的正方形,表示一个像素,九个宫格构成一个大正方形,令构成该大正方形每一条边的三个宫格的像素值的和为15,分别对该大正方形旋转90°,180°,270°得到包括该大正方形在内的四个方向的九宫格像素点块模板(M0,M1,M2,M3)；S2：对于需要隐写的任一图像H,遍历图像H中的每一个像素点,取得由其8邻域像素以及本身构成的3×3大小的九宫格像素块,将该九宫格像素块构成的正方形的四条边上的三个宫格对应的像素值分别与模板(M0,M1,M2,M3)对应位置宫格的像素值进行点乘相加得到16个数值,将该九宫格像素块构成的正方形的两条对角线上的三个宫格对应的像素值分别与模板(M0,M1,M2,M3)对应位置宫格的像素值进行点乘相加得到8个数值,将该九宫格像素块构成的正方形的两条中线上的三个宫格对应的像素值分别与模板(M0,M1,M2,M3)对应位置宫格的像素值进行点乘相加得到8个数值,图像H中每一像素点对应得到32个数值；S3：根据S2的方法,计算图像H中每一个像素点对应的32个的数值的标准差,并将计算得到的标准差按从大到小的方式排序得到标准差序列A；S4：根据待隐写的信息嵌入率计算图像H中需要修改的像素个数N,在序列A中选择N个由大到小排列的标准差值所对应的像素位置值作为图像中待嵌入隐秘信息的位置序列P；S5：遍历P中所有的像素位置,根据隐秘信息进行LSB匹配嵌入获得图像H的隐写图像。</td>   <td>G06T1/00;G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         粟涛;              陈弟虎;                   王政集       </td>   <td>中山大学</td>   <td>一种提取电路寄生参数的方法</td>   <td>广东省</td>   <td>CN104133955B</td>   <td>2017-12-05</td>   <td>本发明涉及一种提取电路寄生参数的方法,其包括：建立芯片级集成电路的三维模型；对该三维模型进行逻辑操作并设置该三维模型中的层参量；设置电流流入/流出位置,编辑运行条件和监视进度,使得三维模型建立和芯片电路寄生参数提取自动化；开始仿真该芯片电路,并提取相应的芯片电路寄生参数。将计算所得的寄生参数,反馈到集成电路设计过程,可以更加准确地估计该芯片电路的延时,从而避免实际延时与预计延时相差较大的情况。确保芯片的工作频率能够达到额定运行状态,并且该芯片能够正常工作。</td>   <td>1.一种提取电路寄生参数的方法,具体包括以下步骤：(1)根据芯片电路的物理设计,读取所述芯片电路的GDS二维版图；GDS文件作为标准单元模型而被读取,在设计芯片级集成电路的版图时,通过合理组合标准单元的GDS,得到所需的芯片电路二维版图GDS文件；(2)根据所述GDS二维版图以及所述电路的高度和/或厚度信息,将二维GDS版图添加高度和厚度信息,建立相对应的芯片电路的三维模型,其中所述芯片电路的各元器件在所述三维模型中表示为若干不同的层；(3)对所述三维模型按照实际工艺情况执行逻辑操作并赋予属性参量,得到一个能体现并与实际多层复杂的芯片电路相吻合的三维模型；将芯片电路的高度和/或厚度信息制作成Layer mapping.tech文件,其中该高度和/或厚度信息在该Layer mapping.tech文件中表示为相对应的层高度和/或厚度,然后Layer mapping.tech文件与GDS文件一起导入场求解器中,即可得到芯片电路的初步三维模型；(4)选用Q3D Extractor作为有限元场求解器,对上述三维模型进行电流流入/流出设置,仿真并提取该模型的寄生参数,并巧妙利用脚本接口,使该求解过程脚本化；对Maxwell方程组进行简化处理；所述Q3D的适用频率上限为5GHz；当一并导入GDS文件和Layer mapping.tech文件时,首先导入GDS文件,然后根据Layermapping.tech文件的文本信息,将关联变量从Layer mapping.tech文件传递到GDS文件,得到芯片电路的初步三维模型；(5)根据该芯片电路的物理设计,定义电流流入位置和电流流出位置；所述芯片电路包括一个或多个输入/输出引线；启动场求解器Q3D为导体层设置材质参量,仿真所述芯片电路的运行情况,并提取所述芯片电路的寄生参数；利用Q3D建立芯片电路的三维模型时,对该三维模型中的各个层赋值,为各个层设置相对应的导体材质。</td>   <td>G06F17/50;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              王自鑫;              袁悦来;              涂玏;                   郑洪滨       </td>   <td>中山大学</td>   <td>一种高层次综合中的组合逻辑优化方法及系统</td>   <td>广东省</td>   <td>CN104408232B</td>   <td>2017-12-05</td>   <td>本发明公开了一种高层次综合中的组合逻辑优化方法及系统,该系统包括获取单元、组合逻辑优化映射单元及重构单元。该方法包括：得到该电路设计的各个操作及各个操作之间的数据依赖关系；对具有数据依赖关系的组合逻辑操作进行优化,根据优化后的结果进行查找表映射,进而构建查找表操作网络；采用查找表操作网络来替换所述具有数据依赖关系的组合逻辑操作。本发明能在高层次综合阶段优化设计中的组合逻辑,去除冗余的组合逻辑运算,并通过添加查找表操作在高层次综合中引入底层硬件信息,为后续高层次综合步骤提供了更为准确的组合逻辑时延和资源开销信息,有利提升高层次综合工具的性能。本发明可广泛应用于硬件设计领域中。</td>   <td>1.一种高层次综合中的组合逻辑优化方法,其特征在于：该方法包括以下步骤：A、获取电路设计的高层次功能描述,进而得到该电路设计所包含的各个操作以及各个操作之间的数据依赖关系；C、对具有数据依赖关系的组合逻辑操作进行优化,根据优化后的结果进行查找表映射,进而构建查找表操作网络；D、删除所述的具有数据依赖关系的组合逻辑操作,然后,对该电路设计中剩余的操作以及查找表操作网络中的查找表操作进行拓扑排序,接着,根据得到的拓扑排序结果,从而对剩余的操作以及查找表操作网络中的查找表操作进行存储。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              袁洋;                   冯展祥       </td>   <td>中山大学</td>   <td>基于相位编码特征和多度量学习的模糊人脸图像验证方法</td>   <td>广东省</td>   <td>CN104123560B</td>   <td>2017-12-01</td>   <td>本发明公开了一种基于相位编码特征和多度量学习的模糊人脸图像验证方法,包括：(1)训练阶段：对样本图像进行分块,对每一图像块提取多尺度初级特征；用上述特征进行fisher kernel词典学习,生成分块fisher kernel编码特征；对上述编码特征进行多度量矩阵学习以产生多个度量矩阵,并得到训练样本经过多度量矩阵投影后的度量距离,计算出正样本、负样本分别对集合的平均度量距离及方差,并通过高斯分布的概率计算公式确定最终的分类阈值；(2)验证阶段：对于输入的人脸图像,对图像分块并提取多尺度初级特征,然后产生分块fisher kernel编码特征,再通过多度量矩阵得到最终的度量距离,将此距离与阈值相比得出人脸验证结果。本发明具有识别率高、通用性强的优点。</td>   <td>1.基于相位编码特征和多度量学习的模糊人脸图像验证方法,其特征在于,包括步骤：(1)训练阶段：(1-1)对输入样本图像进行分块并对每一图像块提取多尺度初级特征；多尺度初级特征为目标像素与邻域像素在频域的相位差向量；(1-2)fisher kernel词典学习：对于训练样本,用步骤(1-1)提取的多尺度初级特征进行fisher kernel词典学习,并生成对应的分块fisher kernel编码特征；(1-3)多度量矩阵学习：对训练样本的分块fisher kernel编码特征进行多度量矩阵学习以产生多个度量矩阵,并得到训练样本经过多度量矩阵投影后的度量距离,计算出正样本对集合的平均度量距离及方差和负样本对集合的平均度量距离及方差,并通过高斯分布的概率计算公式确定最终的分类阈值；(2)测试人脸验证阶段：对于输入的人脸图像,首先对图像分块并提取多尺度初级特征,然后通过fisher kernel词典产生分块fisher kernel编码特征,再通过多度量矩阵得到最终的度量距离,将此距离与阈值相比得出人脸验证结果。</td>   <td>G06K9/62;G06K9/66</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐颂华;              林谋广;              姜涛;              薛凯军;                   肖剑       </td>   <td>东莞中山大学研究院;中山大学</td>   <td>一种基于LDA的生物医疗图像的标注系统及方法</td>   <td>广东省</td>   <td>CN103942274B</td>   <td>2017-11-14</td>   <td>本发明公开了一种基于LDA的生物医疗图像的标注系统,包括LDA训练模块、主题词抽取模块、主题词精炼模块、索引上下文句子模块、上下文生成模块、标注产生模块,LDA训练模块对LDA模型进行训练；主题词抽取模块对图像的说明文字进行LDA建模并抽取主题词；主题词精炼模块对主题词集合进行优化；索引上下文句子模块索引出与主题词关联的句子集；上下文生成模块选取最密切的句子构成图像的上下文；标注产生模块对图像的上下文进行建模,通过计算选取前几个单词作为生物医疗图像的标注词。本发明同时公开了一种基于LDA的生物医疗图像的标注方法。本发明一次能生成多个标注词语,准确性高,使用关键词索引来查找相关图像,方便快捷,更符合人们文本检索习惯。</td>   <td>1.一种基于LDA的生物医疗图像的标注系统,其特征在于,包括LDA训练模块、主题词抽取模块、主题词精炼模块、索引上下文句子模块、上下文生成模块、标注产生模块,所述LDA训练模块用于对LDA模型进行训练；所述主题词抽取模块用于对每幅生物医疗图像的说明文字进行LDA建模,然后从所建模型中抽取所有的主题词；所述主题词精炼模块对所述主题词抽取模块所产生的主题词集合进行优化；所述索引上下文句子模块用于从生物医疗图像的文本文件中索引出与主题词关联的句子集；所述上下文生成模块从每个主题词所对应的句子集中选取一个最密切的句子,然后集合所有最密切的句子,构成生物医疗图像的上下文；所述标注产生模块通过LDA训练模块得到的LDA模型对生物医疗图像的上下文进行建模,得到生物医疗图像的主题分布和单词分布,然后将主题-单词分布中每个单词的概率乘以对应主题的概率,所得结果作为这个单词的权值,再按照权值从大到小的顺序将所有单词排序,选取前几个单词作为生物医疗图像的标注词；其中,所述LDA模型的数据集是所有生物医疗图像的说明文字,从每幅生物医疗图像所对应的文本文件中抽取节点的说明文字,将所有图像的说明文字集合构成了LDA模型的训练数据集。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              李小莲;                   陈青辉       </td>   <td>中山大学</td>   <td>一种采用单类序列化模型的人群异常行为检测方法</td>   <td>广东省</td>   <td>CN104077571B</td>   <td>2017-11-14</td>   <td>本发明公开一种基于单类序列化模型的人群异常行为检测方法,该方法包括区域社会力特征的提取、支持向量描述模型(SVDD)监测、异常定位等主要部分。该方法在区域社会力特征提取前采用统计的方法除去背景,排除背景区域位置的光流场；采用在线更新的SVDD模型对视频中人群的异常行为进行实时的检测；并根据视频数据的序列性特征,对检测结果采取连续密度的隐马尔可夫模型来平滑处理。本方法具有良好的实时性,较好的准确度。可用于安防监控等领域。</td>   <td>1.一种采用单类序列化模型的人群异常行为检测方法,获取人群视频图像,将每一帧图像用同一组均匀的横向以及纵向的网格线分隔成多个区域单元,其特征在于,采用基于区域社会力ASF的特征来表示图像,在训练过程中,结合区域社会力特征训练得到支持向量数据描述SVDD模型；在测试过程中,结合支持向量数据描述的SVDD模型来检测人群异常,基于视频数据的序列性特征,采取连续密度的隐马尔可夫模型CDHMM来平滑处理异常检测结果,得到基于区域社会力的单类序列化模型的ASF+SVDD人群异常检测,实现异常定位；在采用基于区域社会力ASF的特征来表示图像前,采用统计的方法,去除所有场景图像的干扰,剔除场景图像的粒子光流,具体流程：1)对图像中所有的帧计算任意两帧之间的灰度差,将灰度差小于阈值τ的点标记为背景点；2)统计所有帧中各个位置被标记为背景点的次数,得到整个视频的区域活动图；3)若该位置被标记为背景点的次数与总次数的比值大于预设的η,则将其标记为整个视频的背景点,得到新的活动图；4)将步骤3)得到的活动图作为掩码图,与样本进行“与”操作,即可将样本的背景区域去除。</td>   <td>G06K9/00;G06K9/46</td>  </tr> </table></body></html>