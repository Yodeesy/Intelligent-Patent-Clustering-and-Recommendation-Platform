<html xmlns:o='urn:schemas-microsoft-com:office:office' xmlns:x='urn:schemas-microsoft-com:office:excel' xmlns='http://www.w3.org/TR/REC-html40'><head><style>table td,th{vnd.ms-excel.numberformat:@;text-align: center;} table th{color:red}</style><title></title><meta http-equiv='Content-Type' content="text/html; charset=utf-8"></head><body><table cellspacing='0' border='1'>     <tr>   <td style='vnd.ms-excel.numberformat:@'>SrcDatabase-来源库</td>   <td style='vnd.ms-excel.numberformat:@'>Author-作者</td>   <td style='vnd.ms-excel.numberformat:@'>Applicant-申请人</td>   <td style='vnd.ms-excel.numberformat:@'>Title-题名</td>   <td style='vnd.ms-excel.numberformat:@'>CountryName-国省名称</td>   <td style='vnd.ms-excel.numberformat:@'>PubNo-公开号</td>   <td style='vnd.ms-excel.numberformat:@'>PubTime-公开日期</td>   <td style='vnd.ms-excel.numberformat:@'>Summary-摘要</td>   <td style='vnd.ms-excel.numberformat:@'>Claims-主权项</td>   <td style='vnd.ms-excel.numberformat:@'>CLC-中图分类号</td>  </tr>  <tr>   <td>中国专利</td>   <td>         蔡木炎;              张新科;              郑雪怡;              赵子晗;                   项志成       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于人机融合策略的肿瘤预测方法及系统</td>   <td>广东省</td>   <td>CN115910337A</td>   <td>2023-04-04</td>   <td>本发明公开了一种基于人机融合策略的肿瘤预测方法及系统,该方法包括：获取肿瘤患者病例的冰冻切片病理图像并对其进行预处理,得到预处理后的图像；将预处理后的图像输入到残差神经网络,并进行交叉验证,构建深度学习模型；将待测图像输入至深度学习模型进行预测,得到第一预测概率；基于病理医生对待测图像的确定度并对确定度进行线性映射,得到第二预测概率；基于融合策略将第一预测概率和第二预测概率进行融合,得到融合预测概率。该系统包括：预处理模块、第一预测模块、第二预测模块、输出模块和融合模块。通过使用本发明,能够快速且准确预测出原发性中枢神经系统淋巴瘤和胶质瘤。本发明可广泛应用于数据预测领域。</td>   <td>1.一种基于人机融合策略的肿瘤预测方法,其特征在于,包括以下步骤：获取肿瘤患者病例的冰冻切片病理图像并对其进行预处理,得到预处理后的图像；将预处理后的图像输入到残差神经网络,并进行交叉验证,构建深度学习模型；将待测图像输入至深度学习模型进行预测,得到第一预测概率；基于病理医生对待测图像的确定度并对确定度进行线性映射,得到第二预测概率；基于融合策略将第一预测概率和第二预测概率进行融合,得到融合预测概率。</td>   <td>G16H50/30;G16H50/20;G16H30/00;G06V10/764;G06V10/80;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖正首;              黄林冲;                   黄帅       </td>   <td>中山大学</td>   <td>钻孔布置方案的鲁棒性评估方法和装置</td>   <td>广东省</td>   <td>CN111080020B</td>   <td>2023-03-31</td>   <td>本发明实施例提供一种钻孔布置方案的鲁棒性评估方法和装置。方法包括：根据钻孔布置方案,获得目标场地中钻孔位置土体参数；根据贝叶斯和随机场理论,获得目标场地各点土体参数的概率分布函数；通过马尔科夫蒙特卡洛抽样,获得目标场地各点土体参数的样本；基于目标场地各点土体参数的样本,通过映射函数计算出评估钻孔布置方案的鲁棒性的表征参数,进而可以依据该参数判断勘察工程的钻孔布置方案是否需要进行优化。因此,本发明提供的钻孔布置方案的鲁棒性评估方法和装置,有助于优化勘察工程的钻孔布置方案,节约勘察工程施工成本,提升勘察工程执行速度。</td>   <td>1.一种钻孔布置方案的鲁棒性评估方法,其特征在于,包括：S1、根据钻孔布置方案,获得目标场地中钻孔位置土体参数；S2、根据贝叶斯和随机场理论,获得目标场地各点土体参数的概率分布函数,所述的根据贝叶斯和随机场理论,获得目标场地各点土体参数的概率分布函数,包括：S201、确定表征目标场地的随机场的统计参数θ的先验概率分布函数f(θ)；S202、根据随机场理论,获得目标场地中的钻孔位置土体参数s-p发生的条件概率f(s-p|θ)；S203、将目标场地离散成网格,目标场地中各未知点土体参数s-n表征为各网格对应的随机变量,根据随机场理论,获得目标场地各未知点土体参数s-n发生的条件概率f(s-n|θ)；S204、根据贝叶斯理论,获得目标场地各未知点土体参数s-n发生的后验概率kf(s-n|θ)f(s-p|θ)f(θ),其中,k为使得后验概率kf(s-n|θ)f(s-p|θ)f(θ)在s-n取值空间上的积分为1的参数；S3、通过马尔科夫蒙特卡洛抽样,获得目标场地各点土体参数的样本,且该样本服从所获取的概率分布函数,所述的通过马尔科夫蒙特卡洛抽样,获得目标场地各点土体参数的样本,包括：S301、设置目标场地的随机场的统计参数θ的初始值；S302、基于转移概率函数f(θ～*|θ),抽样得到目标场地的随机场的统计参数候选值θ～*；S303、计算f(s-n|θ～*)f(s-p|θ～*)f(θ～*)与f(s-n|θ)f(s-p|θ)f(θ)的比值；S304、在均匀分布U(0,1)中随机抽样,确定接受率α；S305、决定统计参数候选值θ～*是否可接受：若比值[f(s-n|θ～*)f(s-p|θ～*)f(θ～*)]/[f(s-n|θ)f(s-p|θ)f(θ)]≥α,接受统计参数候选值θ～*；否则,拒绝；S306、重复步骤S302～S305,直至抽样得到目标数量的统计参数θ样本；其中,f(θ)为目标场地的随机场的统计参数θ的先验概率分布函数,f(s-p|θ)为目标场地中钻孔位置土体参数s-p发生的条件概率,f(s-n|θ)为标场地各未知点土体参数s-n发生的条件概率；S4、基于目标场地各点土体参数的样本,通过映射函数计算出评估钻孔布置方案的鲁棒性的表征参数,所述的基于目标场地各点土体参数的样本,通过映射函数计算出评估钻孔布置方案的鲁棒性的表征参数,计算公式为：y＝F(s-n)                  式中,y为钻孔布置方案的鲁棒性表征参数,n为目标场地被离散成的网格的数量,s-n为目标场地各点的土体参数样本,F(s-n)为映射函数i为目标场地各点的序号,p-i为目标场地各点土体参数的样本所对应的土木工程的性能参数。</td>   <td>G06Q10/04;G06Q50/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗锦兴;                   叶海艺       </td>   <td>中山大学</td>   <td>一种基于GPU的心脏电生理模拟方法</td>   <td>广东省</td>   <td>CN111091912B</td>   <td>2023-03-31</td>   <td>本发明公开了一种基于GPU的心脏电生理模拟方法,GPU获取若干心脏细胞的细胞数据,并将所有细胞数据排列为二维数组；其中,各心脏细胞的细胞数据相同,且二维数组每一行中细胞数据的个数为32的整数倍；GPU将位于同一行的细胞数据设置相同电流刺激值,继而按行为主序根据每一细胞数据以及电流刺激值,通过预设的自适应时间步长方法对每一心脏细胞进行心脏电生理模拟计算；其中,在模拟计算时每一初始细胞数据由GPU通过一个线程进行处理。通过实施本发明实施例能解决自适应时间步长方法在GPU上执行时,心脏电生理模拟加速效果减弱的问题,进一步提高心脏电生理模拟时的加速效果。</td>   <td>1.一种基于GPU的心脏电生理模拟方法,其特征在于,包括：GPU获取若干心脏细胞的细胞数据,并将所有所述细胞数据排列为二维数组；其中,各所述心脏细胞的细胞数据相同,且所述二维数组每一行中细胞数据的个数为32的整数倍；所述GPU将位于同一行的细胞数据设置相同电流刺激值,继而按行为主序根据每一细胞数据以及所述电流刺激值,通过预设的自适应时间步长方法对每一心脏细胞进行心脏电生理模拟计算；其中,在模拟计算时每一初始细胞数据由所述GPU通过一个线程进行处理；其中,每一所述细胞数据包括：初始电位、离子浓度、离子通道门变量、温度、最大时间步长、最小时间步长、最大变化电位和最小变化电位；所述预设的自适应时间步长方法包括：THM或CCL；通过以下步骤根据THM对每一心脏细胞进行心脏电生理模拟计算：步骤A:根据所述离子浓度计算心脏细胞的总离子电流；步骤B:通过以下公式计算心脏细胞当前时刻的时间步长：                  其中,dt为心脏细胞当前时刻的时间步长,dv为电位变化率,且dv＝I-(ion)；I-(ion)为所述总离子电流；dv-(max)为所述最大变化电位；dv-(min)为所述最小变化电位；dt-(max)为所述最大时间步长；步骤C:判断心脏细胞各时刻的时间步长之和是否大于所述最大时间步长,若是则执行步骤D,若否则执行步骤E；步骤D:计算扩散电位,继而根据所述扩散电位更新所述心脏细胞当前时刻的细胞电位,并执行步骤F；步骤E:重新计算所述离子浓度,并根据更新后的离子浓度重复执行步骤A、B和C；步骤F:判断是否达到预设模拟时长,若是则结束模拟计算,若否则将心脏细胞各时刻的时间步长之和置零,重新计算所述离子浓度,并根据更新后的离子浓度重复执行步骤A、B和C；通过以下步骤根据CCL对每一心脏细胞进行心脏电生理模拟计算：步骤A1:根据所述离子浓度计算心脏细胞的总离子电流；步骤B1:通过以下公式计算心脏细胞当前时刻的时间步长：                  其中,dt为心脏细胞当前时刻的时间步长,dv为电位变化率,且dv＝I-(ion)；I-(ion)为所述总离子电流；步骤C1:判断心脏细胞各时刻的时间步长之和是否大于所述最大时间步长,若是则执行步骤D1,若否则执行步骤E1；步骤D1:计算扩散电位,继而根据所述扩散电位更新所述心脏细胞当前时刻的细胞电位,并执行步骤F1；步骤E1:重新计算所述离子浓度,并根据更新后的离子浓度重复执行步骤A1、B1和C1；步骤F1:判断是否达到预设模拟时长,若是则结束模拟计算,若否则将心脏细胞各时刻的时间步长之和置零,重新计算所述离子浓度,并根据更新后的离子浓度重复执行步骤A1、B1和C1。</td>   <td>G16H50/50;G06T1/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         龚林;              张磊;              徐世友;                   陈曾平       </td>   <td>中山大学</td>   <td>基于ISAR图像的目标尺寸提取方法</td>   <td>广东省</td>   <td>CN111161341B</td>   <td>2023-03-31</td>   <td>本发明公开了一种基于ISAR图像的目标尺寸提取方法。该方法通过作出二维ISAR图像的一维高分辨像,使用恒虚警率检测法对一维高分辨像进行检测,并根据检测结果得到待测目标的第一次CFAR检测区域；对二维ISAR图像进行区域重确定,得到区域重确定后的二维ISAR图像,根据区域重确定后的二维ISAR图像外的图像噪声水平,对检测阈值进行更新,并再次通过恒虚警率检测法对一维高分辨像进行检测,从而在二维ISAR图像得到目标检测区域,最终得到目标的尺寸数据。通过使用本发明中的方法,能够减少目标检测的处理用时,提高了检测效率；还能够有效减少目标边缘漏检,提高了目标检测的精度。本发明可广泛应用于雷达技术领域内。</td>   <td>1.基于ISAR图像的目标尺寸提取方法,其特征在于,包括以下步骤：获取含待测目标的二维ISAR图像,作出所述二维ISAR图像距离维和方位维的一维高分辨像；通过恒虚警率检测法对所述一维高分辨像进行检测,根据检测结果在二维ISAR图像得到待测目标的第一次CFAR检测区域；基于所述第一次CFAR检测区域,对所述二维ISAR图像进行区域重确定,得到区域重确定后的二维ISAR图像,所述区域重确定后的二维ISAR图像小于原二维ISAR图像；根据所述二维ISAR图像中区域重确定后的二维ISAR图像外的图像噪声水平,对恒虚警率检测法中的检测阈值进行更新；基于更新后的检测阈值,再次通过恒虚警率检测法对所述一维高分辨像进行检测,根据检测结果在二维ISAR图像得到目标检测区域；基于所述目标检测区域,获取目标的尺寸数据；所述通过恒虚警率检测法对所述一维高分辨像进行检测,根据检测结果在二维ISAR图像得到待测目标的第一次CFAR检测区域这一步骤,其具体包括：通过恒虚警率检测法对距离维的一维高分辨像进行检测,基于预设的第一前置检测阈值和第一后置检测阈值在距离维上检测出目标第一前端和目标第一后端；通过恒虚警率检测法对方位维的一维高分辨像进行检测,基于预设的第二前置检测阈值和第二后置检测阈值在方位维上检测出目标第二前端和目标第二后端；根据所述目标第一前端、目标第一后端、目标第二前端和目标第二后端,在二维ISAR图像得到待测目标的第一次CFAR检测区域；所述基于所述第一次CFAR检测区域,对所述二维ISAR图像进行区域重确定,得到区域重确定后的二维ISAR图像这一步骤,其具体为：在所述第一次CFAR检测区域和二维ISAR图像的边界线之间划定噪声去除边界线,以所述噪声去除边界线内的图像作为区域重确定后的二维ISAR图像。</td>   <td>G06T7/60;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         程晓;                   陈卓奇       </td>   <td>中山大学</td>   <td>一种极地可见光遥感自适应制图方法</td>   <td>广东省</td>   <td>CN111354054B</td>   <td>2023-03-31</td>   <td>本发明公开一种极地可见光遥感自适应制图方法,包括如下步骤：对卫星遥感影像进行太阳高度角订正；对太阳高度角订正后的卫星遥感影像进行非朗勃体订正,订正冰雪表面的非朗勃体效应；对经过太阳高度角订正、非朗勃体订正后的卫星遥感影像进行非线性彩色拉伸；对非线性彩色拉伸后的卫星遥感影像进行拼接,完成卫星遥感影像自适应制图。本发明提出了一套标准化、流程化的极地遥感影像自适应制图方法,通过对遥感图像进行太阳高度角订正、非朗勃体订正、非线性影像彩色拉伸、极地可见光遥感影像拼接,所获得的极地遥感影像亮度明显提高、无色差,且保留了原始影像中所有的细节信息,实现了对南北极环境的有效监测。</td>   <td>1.一种极地可见光遥感自适应制图方法,其特征在于,包括如下步骤：对卫星遥感影像进行太阳高度角订正；对太阳高度角订正后的卫星遥感影像进行非朗勃体订正,订正冰雪表面的非朗勃体效应；对经过太阳高度角订正、非朗勃体订正后的卫星遥感影像进行非线性彩色拉伸,包括：确定自适应非线性影像彩色拉伸函数,并基于自适应非线性拉伸函数对极地可见光卫星遥感影像进行非线性拉伸处理；对非线性彩色拉伸后的卫星遥感影像进行拼接,完成卫星遥感影像自适应制图；对卫星遥感影像进行太阳高度角订正的方法包括：卫星接收到的太阳辐射由式1计算获得：ρ-λ＝(M-λ×DN+A-λ)×sinθ……………………………………1其中,ρ-λ表示卫星接收到的太阳辐射值,DN表示卫星传感器电信号强度,M-λ和A-λ分别表示电信号转化为太阳辐射值的缩放系数和增益系数,Sinθ表示太阳高度角订正系数；太阳高度角订正系数Sinθ由日地关系计算获得,如式2所示：sinθ＝cosω×cosδ×cosφ+sinδ×sinφ………………………2其中,ω表示地方时角,δ表示太阳赤纬角,φ表示纬度；将式2代入式1,得到经太阳高度角订正后的太阳辐射。</td>   <td>G06T11/00;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;                   黎睿德       </td>   <td>中山大学</td>   <td>一种分布式云系统-云簇架构下的服务容器资源的分配方法与系统</td>   <td>广东省</td>   <td>CN111381936B</td>   <td>2023-03-31</td>   <td>本发明涉及云计算技术领域,具体为分布式云系统-云簇架构下的服务容器的资源分配方法及系统。分配方法包括步骤：本地微云系统根据终端用户提交的任务请求,估算完成任务需要构建的容器数量及相关的资源需求量,基于其本身运行的任务管理算法,决定终端用户的业务请求能否由本地微云系统服务。若本地微云系统有足够资源直接执行任务,则依据计算服务成本最低的策略创建虚拟机,并在新创建的虚拟机上创建容器提供服务；若无法服务,则基于双染色体遗传算法计算生成服务成本最低的跨微云容器资源分配方案,将部分或者全部任务转载到其它相邻微云系统上执行。本发明通过物理资源的跨微云调度,解决单个微云在业务高峰期资源不足的问题。</td>   <td>1.一种分布式云系统-云簇架构下的服务容器资源的分配方法,其特征在于,包括以下步骤：S1、本地微云系统收集其自身的资源情况、资源实际使用情况；云簇管理中心收集所有微云资源情况、实际资源使用情况；本地微云系统从云簇管理中心获取其相邻微云系统集的信息；S2、本地微云系统根据终端用户提交的任务请求,估算完成任务需要构建的容器数量及相关的资源需求量；S3、本地微云系统基于其本身运行的任务管理算法,决定一个终端用户的业务请求能否由本地微云系统服务；S4、若本地微云系统有足够资源直接执行任务,则依据计算服务成本最低的策略创建虚拟机,并在新创建的虚拟机上创建容器为用户提供服务；S5、若本地微云系统无法服务,则基于双染色体遗传算法计算生成服务成本最低的跨微云容器资源分配方案,将部分或者全部任务转载到其它相邻微云系统上执行；本地微云系统根据跨微云的容器资源分配方案,遵照跨微云服务请求流程请求相关邻居微云提供服务；相关邻居微云收到请求后,则确认请求并分配资源,创建虚拟机,并在新创建的虚拟机上创建容器为用户提供服务；步骤S5中基于双染色体遗传算法计算生成服务成本最低的跨微云容器资源分配方案,包括以下步骤：S51、本地微云系统获取自身系统固定预设规格的虚拟机类型数量t和对应的虚拟机规格,估算完成终端用户任务需要构建的容器的容器数量c和相关的资源需求量,使用最佳适应算法估算需要创建的虚拟机数量v,向云簇管理中心发送请求并获取邻居微云系统的数量m和对应的邻居微云的空闲资源信息；S52、设置种群个数n、交叉概率Pc、变异的概率Pv、终止迭代次数Step和个体适应度的变化量Δ；其中,0＜Pc＜1,0＜Pv＜1,Step&gt;1,表示从n个不同元素中取出n个元素的排列数,Δ＞0；S53、本地微云系统使用双染色体遗传算法对种群进行多次选择、交叉和变异；通过改变染色体中的序列,得到邻居微云系统中最优的虚拟机分配方案和容器分配方案,此即为服务成本最低的跨微云容器资源分配方案。</td>   <td>G06F9/455;G06F9/50;G06N3/126</td>  </tr>        <tr>   <td>中国专利</td>   <td>         洪思宇;              郭裕兰;              符智恒;                   黄小红       </td>   <td>中山大学</td>   <td>基于多任务网络的单目深度估计与表面法向量估计方法</td>   <td>广东省</td>   <td>CN111539922B</td>   <td>2023-03-31</td>   <td>本发明公开了基于多任务网络的单目深度估计与表面法向量估计方法,所述方法包括以下步骤：采用高分辨率网络作为骨干网络收集多尺度信息；通过高分辨率网络输出了不同分辨率的特征,并对特征分别进行独立上采样后获得与原分辨率相同的特征图；将获得的特征图串接得到一个多尺度表面特征,生成多尺度融合特征；将多尺度融合特征分为2个分支特征,并输入至互相关注意力机制交互模块,获得学习相关性的互相关矩阵；把输入到每个分支特征的1x1连续卷积层,再通过softmax操作得到两个互相关注意力图并利用注意力图上有利于交互的部分获得新的融合特征；重复步骤S5获得特定任务的特征信息后,最终得到单目深度估计和表面法向量估计结果。</td>   <td>1.基于多任务网络的单目深度估计与表面法向量估计方法,其特征在于,所述方法包括以下步骤：S1采用高分辨率网络作为骨干网络收集多尺度信息；S2通过高分辨率网络输出了不同分辨率的特征,并对特征分别进行独立上采样后获得与原分辨率相同的特征图；S3将获得的特征图串接得到一个多尺度表面特征,生成多尺度融合特征；S4将多尺度融合特征分为2个分支特征,并输入至互相关注意力机制交互模块,获得学习相关性的互相关矩阵；S5把输入到每个分支特征的连续卷积层,再通过softmax操作得到两个互相关注意力图并利用注意力图上有利于交互的部分获得新的融合特征；S6重复步骤S5获得特定任务的特征信息后,最终得到单目深度估计和表面法向量估计结果。</td>   <td>G06T7/00;G06T7/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         权小军;                   谢智贤       </td>   <td>中山大学</td>   <td>一种针对多人多轮对话场景的对话图重构方法及系统</td>   <td>广东省</td>   <td>CN112765978B</td>   <td>2023-03-31</td>   <td>本发明公开了一种针对多人多轮对话场景的对话图重构方法及系统,该方法包括：获取多人多轮对话数据并多人多轮对话数据输入到预构建的模型；对多人多轮对话数据行预处理,得到预处理后的对话；对预处理后的对话进行编码,得到句子向量和词向量；根据句子向量和词向量构建自适应图并与预构建的先验图相结合,得到重构的对话图。该系统包括：输入模块、预处理模块、编码模块和对话图重构模块。通过使用本发明,采用先验图和自适应图相结合的方式实现对话图重构。本发明作为一种针对多人多轮对话场景的对话图重构方法及系统,可广泛应用于自然语言处理领域。</td>   <td>1.一种针对多人多轮对话场景的对话图重构方法,其特征在于,包括以下步骤：获取多人多轮对话数据并将多人多轮对话数据输入到预构建的模型；对多人多轮对话数据进行预处理,得到预处理后的对话；对预处理后的对话进行编码,得到句子向量和词向量；根据说话者特征信息和预设规则构建先验图；基于预训练网络根据句子向量和词向量获取句子间的相关程度并构建自适应图；所述自适应图的构建公式如下；                  上式中,W-a为可学习参数,x-i表示句子向量,表示对句子向量x-j转置,i、j表示构建得到的自适应图中第i行第j列的值；将先验图和自适应图结合,得到重构的对话图；根据重构的对话图得到输出结果。</td>   <td>G06F40/289;G06F40/126;G06N3/049;G06F16/901</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;              王立华;              尹雪梅;                   黄梓生       </td>   <td>中山大学</td>   <td>一种可抗屏幕拍摄的图像水印方法</td>   <td>广东省</td>   <td>CN112767227B</td>   <td>2023-03-31</td>   <td>本发明提出一种可抗屏幕拍摄的图像水印方法,解决了现有图像水印方法不利于水印有效提取的问题,所述方法包括水印嵌入过程与水印提取过程,所述水印嵌入过程将水印嵌入宿主图像,水印提取过程基于所述水印嵌入过程,对已嵌入水印且经屏幕拍摄的宿主图像进行透视矫正后,进行水印提取操作,提取宿主图像已嵌入的水印信息,保证了水印提取信息的有效性。</td>   <td>1.一种可抗屏幕拍摄的图像水印方法,其特征在于,所述方法包括水印嵌入过程与水印提取过程,所述水印嵌入过程将水印嵌入宿主图像,水印提取过程基于所述水印嵌入过程,对已嵌入水印且经屏幕拍摄的宿主图像进行透视矫正后,进行水印提取操作,提取宿主图像已嵌入的水印信息；所述水印嵌入过程至少包括：S1.利用密钥生成伪随机序列和模板序列,结合水印比特信息生成待嵌入的二维水印矩阵；S2.确定宿主图像,对宿主图像做二维离散傅立叶变换,将变换后的直流成分平移到离散傅立叶幅度谱的中心,在傅立叶系数幅度谱的上半平面中嵌入水印,并将嵌入区域内点的坐标映射到对数极坐标上；S3.将对数极坐标作为二维水印矩阵的坐标,在具有相同对数极坐标的傅立叶系数中嵌入相同的水印比特信息；S4.由于傅立叶 幅度谱具有中心对称性,将上半平面的对应系数复制到下半平面,然后对嵌入水印比特信息后的傅立叶系数进行逆傅立叶变换,得到含水印的图像；所述水印提取过程至少包括：SA.对经屏幕拍摄且已嵌入水印的宿主图像进行透视矫正,裁剪出目标图像区域作为待测图像；步骤SA中所述对经屏幕拍摄且已嵌入水印的宿主图像进行透视矫正的过程为：SA01.设经屏幕拍摄且已嵌入水印的宿主图像为I-0,将I-0转换为灰度图像,对灰度图像进行高斯滤波得到图像I-1；SA02.采用Sobel算法检测图像I-1边缘,得到边缘点图像I-2；SA03.对图像I-2进行形态学闭运算,得到图像I-3,从图像I-3中删除小于P的连通分量,生成二值图像I-4,P表示一个被删除连通分量的像素评价阈值；SA04.设目标图像为I′,跟踪二值图像I-4中对象的外边界区域,将最大的连通区域作为目标图像I′的轮廓,计算包含图像I′轮廓的最小多边形凸包,得到多边形凸包的顶点集合points；SA05.计算目标图像I′的边缘直线:按逆时针顺序遍历多边形凸包的顶点集合points,每两个点确定一条直线,角度相近的两条线段中选取长度最大的计算其参数表达式,得到一系列直线；当直线数量大于4时,删除与相邻两条直线夹角过大的直线；SA06.计算目标图像I′的四个顶点：确认四条直线的交点,得到目标图像I′的顶点集合vecs；当顶点坐标超出宿主图像I-0的范围时,水印图像经屏幕拍摄的不完整,将宿主图像I-0范围外的内容进行补0填充；SA07.设目标图像I′的最小边长为L-m,根据顶点集合vecs和L-m对宿主图像I-0进行透视矫正,将变换后的目标图像裁剪出来,得到图像I-(new)；SB.对待测图像做二维离散傅立叶变换,将变换后的直流成分平移到离散傅立叶幅度谱中心,以离散傅立叶幅度谱中心作为直角坐标系的原点,在傅立叶系数幅度谱的上半平面中提取水印,将提取范围内幅度系数的直角坐标映射到对数极坐标上；SC.计算一个二维傅立叶系数幅度矩阵：对经过映射后拥有相同对数极坐标的幅度系数求均值,将其作为二维傅立叶系数幅度矩阵的一个元素；SD.根据相位相关原理,将原始模板与傅立叶系数幅度矩阵进行快速匹配计算,根据最大相关值的坐标位置,确定水印矩阵在二维傅立叶系数幅度矩阵中的位置,得到与嵌入水印同步的幅度矩阵；SE.利用伪随机序列对幅度矩阵进行解扩频调制,提取到水印信息。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         洪楷铎;                   郑伟诗       </td>   <td>中山大学</td>   <td>基于模型无关元学习的无监督少样本图像分类方法、系统及存储介质</td>   <td>广东省</td>   <td>CN112861995B</td>   <td>2023-03-31</td>   <td>本发明公开了一种基于模型无关元学习的无监督少样本图像分类方法、系统及存储介质,包括下述步骤：生成训练数据,得到元训练集和元测试集；构造卷积神经网络模型,在卷积神经网络模型中引入快权重和慢权重,所述快权重在内部循环中进行迭代,所述慢权重在外部循环进行优化求解；利用元训练集和元测试集对优化后的卷积神经网络模型进行训练,得到优化后的神经网络模型；引入无监督相关损失,提高卷积神经网络模型分类效果；将待分类的图像输入到训练好的卷积神经网络,得到分类结果。本发明结合数据采样、数据增强、和无监督图像分类中的方法,提升模型无关原学习方法的训练速度,解决少样本学习无监督样本生成和计算效率的问题。</td>   <td>1.基于模型无关元学习的无监督少样本图像分类方法,其特征在于,包括下述步骤：生成训练数据,得到元训练集和元测试集；构造卷积神经网络模型,在卷积神经网络模型中引入快权重和慢权重,所述快权重在内部循环中进行迭代,所述慢权重在外部循环进行优化求解,所述卷积神经网络包括三部分,具体为：第一部分为神经网络的前面几层卷积层,用来提升较为通用的特征,称为卷积层前部；第二部分为网络除卷积层前部外的卷积层,称为卷积层后部；第三部分为最后的全连接层线性操作参数记为w,w＝w-(bias)+w-(linear)；在所有卷积层后连接一个投影模块,用于旋转的预测,投影模块由两层线性层组成,再加上一个softmax分类器,在内部循环中,将元测试集每个图像x经过多次旋转,得到x-1,x-2,…,x-r,输入同一张图像的两张不同角度的图片x-i,x-j,经过投影模块经过softmax层,输出一个12维的向量,表示预测的两张图片的旋转角度差；利用元训练集和元测试集对优化后的卷积神经网络模型进行训练,得到优化后的神经网络模型；所述利用元训练集和元测试集对优化后的卷积神经网络模型进行训练,具体为：设x-spt为元训练集,x-qry为元测试集,卷积神经网络的损失函数为f,其参数为初始参数为w-0,内部学习率为α-(inner),w-k为第k次内部迭代得到的参数,则卷积神经网络模型的第一个训练目标就是：                                    其中的一些概念解释如下：任务：在少样本图像分类中,定义任务为给定少量几张图像X,再给定另外同类别的几张图像Y,判断Y中的每一张图像,分别和X中哪张图像属于同一类别；x-spt：元训练集,少样本图像分类任务中,每一个任务的少量训练样本；x-qry：元测试集,少样本图像分类任务中,每一个任务的少量测试样本；          指的是卷积神经网络中可训练的网络权重；α-(inner)：在模型无关元学习中,内层迭代使用的学习率；在训练过程中,内部循环固定卷积神经网络的前几层参数,将分为w-f和w-b,w-f和w-b分别表示卷积神经网络的前几层参数和后面几层的参数,则训练目标变成：                                    w-(b,0)＝w-b,还包括对全连接层参数进行分解的步骤,具体为：卷积神经网络最后一层全连接层参数包括w和b,其中w是线性操作参数,b是平移参数,w在小为fea-num×n,b大小为n,其中fea-num是卷积层的特征维度,n是少样本分类类别数,将w分为w＝w-(bias)+w-(linear),其中w-(bias)大小为fea-num×1,w-(linear)大小为fea-num×n,内部循环时,w-(bias)保持不变,w-(linear)初始化为0开始迭代,外部循环只对w-(bias)做优化,故训练目标为：                                                      w-(linear,0)＝w-(linear),w-(b,0)＝w-b,w＝[w-f,w-b,w-(bias)]；引入无监督相关损失,提高卷积神经网络模型分类效果；将待分类的图像输入到训练好的卷积神经网络,得到分类结果。</td>   <td>G06V10/774;G06V10/764;G06V10/82;G06N3/0464;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              陈钦德;              赵山河;              周克涌;              梁万山;                   李少华       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>资源转移提醒方式的确定方法、装置和计算机设备</td>   <td>广东省</td>   <td>CN115878796A</td>   <td>2023-03-31</td>   <td>本申请涉及一种资源转移提醒方式的确定方法、装置和存储介质。上述方法包括：确定目标对象在回答预设的提醒问题时的对话数据；通过预先训练好的目标画像模型,确定目标对象的用户数据；将对话数据和用户数据进行数据融合,得到多模态数据,并对多模态数据进行数据编码,得到隐空间数据；分别对对话数据和隐空间数据进行情感评估,得到各自对应的评估分数,并根据每个评估分数,确定目标对象的资源转移提醒方式。采用本方法能够提高资源转移提醒方式的确定的准确性。</td>   <td>1.一种资源转移提醒方式的确定方法,其特征在于,所述方法包括：确定目标对象在回答预设的提醒问题时的对话数据；通过预先训练好的目标画像模型,确定所述目标对象的用户数据；所述目标画像模型是综合历史用户数据和历史对话数据训练得到；将所述对话数据和所述用户数据进行数据融合,得到多模态数据,并对所述多模态数据进行数据编码,得到隐空间数据；分别对所述对话数据和所述隐空间数据进行情感评估,得到各自对应的评估分数,并根据每个所述评估分数,确定所述目标对象的资源转移提醒方式。</td>   <td>G06F16/35;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              李兆文;                   林淑金       </td>   <td>中山大学</td>   <td>基于手绘草图语义的外观专利图像检索方法与系统</td>   <td>广东省</td>   <td>CN115878833A</td>   <td>2023-03-31</td>   <td>本发明提出一种基于手绘草图语义的外观专利图像检索方法与系统,涉及深度学习与图像检索的技术领域,选取外观专利图像数据集后处理,形成图像-草图-简化草图配对的图像数据集,构建图像检索模型对图像、草图、简化草图分别进行特征提取,得到低层、中层和高层的特征图,并将低层、中层和高层的特征图按通道维相接,利用卷积和全连接层获得图像语义特征编码,从而实现图像或者草图的编码到的信息能够既观察到局部细节,也能观察到全局的特征,进一步提升了检索的精度；以对比损失函数来替代三元组损失,降低数据选取的随机性,从而避免了挖掘三元组的问题。利用对比学习在草图图像检索中应用,加快了训练收敛速度,提高了检索的精度。</td>   <td>1.一种基于手绘草图语义的外观专利图像检索方法,其特征在于,所述方法包括以下步骤：S1.选取外观专利图像数据集,对外观专利图像数据集中的图像数据进行处理,形成图像-草图-简化草图配对的图像数据集；S2.构建图像检索模型,图像检索模型对图像数据集中的图像、草图、简化草图分别进行特征提取,得到低层、中层和高层的特征图,并将低层、中层和高层的特征图按通道维相接,利用卷积和全连接层获得图像语义特征编码；S3.将图像数据集划分为训练集、验证集和测试集；S4.利用图像检索模型对训练集中的图像、草图、简化草图分别进行图像语义特征编码,得到图像编码、草图编码及简化草图编码；S5.分别构建图像-草图对比损失函数、草图-简化草图对比损失函数、图像-简化草图对比损失函数；S6.基于S5构建的三个对比损失函数计算最终的损失函数,利用优化器优化训练图像检索模型,并利用验证集验证,得到训练好的图像检索模型；S7.利用训练好的图像检索模型对数据库中的外观专利图像进行预编码,得到图像预编码数据库；S8.对测试集中手绘的外观专利图像草图进行预处理,利用训练好的图像检索模型对预处理后的草图进行语义特征编码,将编码结果与图像预编码数据库对比,返回图像检索结果。</td>   <td>G06F16/583;G06V10/44;G06V10/74;G06V10/774;G06V10/82;G06Q50/18;G06N3/0442;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈旭琳;              林天歆;              吴少旭;              洪桂斌;              林真;              汪进;                   陈睿       </td>   <td>中山大学孙逸仙纪念医院;赛维森(广州)医疗科技服务有限公司</td>   <td>膀胱癌淋巴结转移的病理图像识别方法、装置、介质</td>   <td>广东省</td>   <td>CN115880293A</td>   <td>2023-03-31</td>   <td>本申请公开了一种膀胱癌淋巴结转移的病理图像识别方法、装置、介质,包括将目标图像块输入目标分割网络,得到分割置信度图；对分割置信度图中所有像素点的值取平均值,得到分类置信度；将分类置信度的值排序,选取前N个目标图像块进行非均匀重采样处理,得到重采样图像块；将重采样置信度图进行映射处理,得到映射置信度图；将映射置信度图与目标图像块的分割置信度图融合,得到融合置信度图；将融合置信度图与目标图像块中未进行非均匀重采样处理的目标图像块的分割置信度图拼接,得到病理图像的识别结果。本申请对病理图像进行非均匀重采样处理,能够对淋巴结组织图像中的转移癌实现准确分割,提高病理图像的识别效率和准确率。</td>   <td>1.一种膀胱癌淋巴结转移的病理图像识别方法,其特征在于,包括：获取病理图像,按照预设分辨率大小对所述病理图像进行滑窗裁剪,得到M个目标图像块,其中M为大于1的自然数；分别将M个所述目标图像块输入目标分割网络,得到M个对应于所述目标图像块的分割置信度图,其中所述分割置信度图的像素点的值表征所述像素点属于癌这一类别的概率；对所述分割置信度图中所有像素点的值取平均值,得到所述目标图像块的分类置信度；将M个所述目标图像块按照对应的所述分类置信度的值从大到小进行排序,并从中选取前N个所述目标图像块分别进行非均匀重采样处理,得到N个对应于所述目标图像块的重采样图像块,其中N为大于0且小于M的自然数；分别将N个所述重采样图像块输入目标分割网络,得到N个对应于所述重采样图像块的重采样置信度图；将所述重采样置信度图进行映射处理,得到对应于所述目标图像块的映射置信度图；将所述映射置信度图与对应于所述目标图像块的分割置信度图进行融合,得到N个融合置信度图；将所述N个融合置信度图与M个所述目标图像块中未进行非均匀重采样处理的目标图像块的分割置信度图进行拼接,得到所述病理图像的识别结果。</td>   <td>G06T7/00;G06T3/40;G06T7/11;G06V10/26;G06V10/764;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              甄家杰;              刘凌波;                   李冠彬       </td>   <td>中山大学</td>   <td>一种基于深度学习的人群计数模型及其实现方法</td>   <td>广东省</td>   <td>CN110705344B</td>   <td>2023-03-28</td>   <td>本发明公开了一种基于深度学习的人群计数模型及其实现方法,所述方法包括：步骤S1,获取人群图像,对获取的人群图像进行预处理并利用标注信息产生对应的人群密度图；步骤S2,将输入的人群图像缩放成多个尺度版本,通过多个子网络提取各个尺度的特征,并利用特征增强模块增强各个尺度的特征；步骤S3,将多个子网络产生的特征结合,生成估计的人群密度图；步骤S4,利用估计的人群密度图与真实的人群密度图计算损失,更新模型参数；步骤S5,利用不同人群图像多次迭代式地进行步骤S1-S4的训练过程,直到符合停止的条件。</td>   <td>1.一种基于深度学习的人群计数模型,包括：预处理单元,用于获取人群图像,对获取的人群图像进行预处理后输出至特征提取单元,并利用标注信息产生对应的人群密度图；特征提取单元,用于将输入的人群图像缩放成多个尺度版本,通过多个子网络提取各个尺度的特征,并利用特征增强模块增强各个尺度的特征；估计人群密度图生成单元,用于将多个子网络产生的特征结合,生成估计的人群密度图；更新单元,用于根据所述估计人群密度图生成单元生成的估计的人群密度图与所述预处理单元生成的真实人群密度图计算损失,更新模型参数；迭代训练单元,用于多次迭代式地对不同人群图像进行所述预处理单元、特征提取单元、估计人群密度图生成单元以及更新单元的训练过程,直到满足设定的停止条件时停止训练；所述预处理单元进一步包括：图像裁剪模块,用于对获取的人群图像随机裁剪成固定大小的图像；人群密度图生成模块,用于利用标注的人头位置信息通过高斯核生成对应的人群密度图,将其作为标签图像；所述人群密度图生成模块通过如下公式生成人群密度图：                  其中,M代表所述人群图像中的人数,x代表图像中每个像素的位置,x-i代表第i个人的标注位置,δ(x-x-i)表示激活函数,表示标准差为σ-i的高斯核,β为一常数,/&gt;代表第i个人的标注位置与其周边的m个人的标注位置的平均距离,/&gt;所述特征提取单元进一步包括：子网络构建模块,用于构建多个并行的子网络,对输入的人群图像提取多个尺度的图像的特征；特征增强模块,用于在子网络各个下采样层前结合不同尺度的特征,增强各个尺度的特征；所述并行的子网络使用相同的网络结构并共享参数,由预训练的VGG-16模型的前十个卷积层组成,前十个卷积层分成四组,每一组卷积层之间都有一个下采样层,用于扩大感受野；所述特征增强模块设置在每一组卷积层后下采样层前,基于条件随机场对各个子网络中相同大小的特征进行互补增强。</td>   <td>G06V20/52;G06V20/40;G06V10/774;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周晨星;              赖韩江;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于数据增强的深度学习主题情感分类方法</td>   <td>广东省</td>   <td>CN110245229B</td>   <td>2023-03-28</td>   <td>本发明提供一种基于数据增强的深度学习主题情感分类方法,该方法通过bert预训练语言模型能够让词先获取到一个初步的语义信息,然后经过双向GRU网络学习词与词之间的上下文语义特征,同时提出一种增强数据的方法,通过剔除每个句子中影响情感极性最大的词,迫使模型去学习更难句子的情感极性的判定,同时扩充数据集又使得模型能够从更多的数据集捕获特征。通过在相应数据集上的实验表明,本发明对比之前的情感分类方法,有较大提升。</td>   <td>1.一种基于数据增强的深度学习主题情感分类方法,其特征在于,包括以下步骤：S1：建立用于生成句子的语义信息,特征表示以及分类器的深度学习网络模型G；具体过程为：S11：利用bert预训练语言模型,将预训练处理后的句子中的每个单词用一个低维,稠密的实数向量进行表示,并且由于bert预训练语言模型本身已经包含了对每个单词的语义建模,因此,经过bert输出的每个词都具有语义信息,于是将整个句子表示成X＝[x-1,…,x-t,…,x-n],其中n是句子的长度,向量矩阵X的维度为768维；S12：根据经过bert层的词向量表示已经具备一定的语义信息,还需要让模型学习句子的每个词的上下文信息,用一个双向GRU网络去学习句子的上下文信息；设每一个词代表一个时间步t,每个GRU细胞单元的输入为当前t时刻的词向量x-t以及t-1时刻的GRU细胞隐层输出h-(ft-1),得到前向GRU的表示为H-f＝[h-(f1),…,h-(ft),…h-(fn)],同理,后向GRU的表示为H-b＝[h-(b1),…,h-(bt),…h-(bn)]S13：为了学习句子的每个词与主题词的关系,构建一层Attention层,用来计算每个词关于主题词的权重,权重越大代表该词在影响句子关于当前主题的情感极性越大,首先每个词由S12表示为H＝H-f+H-b,当前主题词的词向量表示为e-N,然后将两个向量进行拼接并使用tanh激活函数,得到的向量表示为M＝tanh([H；e-N]),然后学习一个参数W去计算每个词关于主题词的权重大小再乘上对应位置每个词的GRU输出得到句子关于主题词的整体表示r,其中r＝H·softmax(W～TM)；S14：建立最后一层输出层,将S13得到的句子表示r通过两层全连接层以及一层softmax映射到三个分类类别上,分别对应当前句子的情感极性是积极,消极和中性的概率,然后根据概率大小情况输出最大概率的情感极性,输出结果；S15：将数据集中的训练数据按照上述步骤S1-S14进行一遍训练,训练过程中采用交叉熵作为损失函数,使用ADAM优化器进行优化,采用L2正则化防止出现过拟合,最后将网络的参数保存下来；S2：根据深度学习网络模型G挑选出训练集中影响情感分析最重要的词构成新的训练集；S3：根据原始训练集和新训练集对深度学习网络模型G再次进行训练,然后进行测试。</td>   <td>G06F16/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈旭;              周知;                   刘德银       </td>   <td>中山大学</td>   <td>基于端边云协同的深度学习模型训练加速方法</td>   <td>广东省</td>   <td>CN111242282B</td>   <td>2023-03-28</td>   <td>本发明公开了一种基于端边云协同的深度学习模型训练加速方法,提出结合模型分割与训练数据切分的分布式训练深度模型的方法,通过对整个训练过程中的计算时延和数据传输时延进行理论建模得到总训练时延作为目标函数,通过求解最小化目标函数得到最优的模型分割的切割点和训练数据分配的策略,相较于传统的基于云数据中心的方法和基于边缘服务器部署的方法,本方法能有效的利用移动端设备、边缘服务器和云数据中心的计算资源来减少在利用移动端搜集的图像数据进行用于图像识别的深度学习模型训练场景下的训练所需时延。</td>   <td>1.一种基于端边云协同的深度学习模型训练加速方法,其特征在于,所述的深度学习模型训练加速方法包括：S1、离线测量步骤,测量所需训练的深度学习模型基于单个图像数据作为输入时各个网络层所输出的特征图像的数据量的大小；测量所需训练的用于图像识别的深度学习模型各个网络层基于单个图像数据作为输入时,在参与任务计算的各计算节点上执行计算所需的平均计算时延大小；S2、在线优化步骤,首先测量当前端边云各计算节点之间的网络带宽,再利用在离线测量步骤下得到的基于单个训练样本作为输入深度学习模型各个网络层所输出的数据量的大小和各网络层在各计算节点进行计算所需的平均计算时延、及测量所得网络带宽作为输入,通过对单次迭代训练过程的总训练时延进行理论建模,然后将总训练时延作为目标函数,加入约束条件构建一个最小化优化问题,通过求解优化问题得到最优的分割深度学习模型的切割点和参与任务计算的各计算节点进行深度学习模型训练时所需处理的图像数据的大小作为输出；S3、协同训练步骤,根据在线优化步骤输出的最优的模型分割的切割点和训练数据分配的策略,端边云各计算节点按照所得的策略,各计算节点基于一定数目的图像数据对深度学习模型进行协同训练；所述的在线优化步骤中,通过对单次迭代训练过程的总训练时延进行一个理论建模,然后将总训练时延作为目标函数,加入必要的约束条件构建一个最小化优化问题,得到最优的模型分割的切割点和用于训练的图像数据分配的策略的过程包括：S21、定义三种任务类型如下：TASK O：基于b-o个图像数据作为输入,执行原本的整个深度学习模型训练的计算任务；TASK S：基于b-s个图像数据作为输入,执行深度学习模型前m-s层训练的计算任务；TASK L：基于b-l个图像数据作为输入,执行深度学习模型前m-l层训练的计算任务；其中b-o,b-s,b-l均为整数,分别代表用于训练的图像数据分配的策略,m-s,m-l均为整数,分别代表模型分割的策略；再定义三个计算节点node-o、node-s、node-l,假定三种计算任务TASK O、TASK S、TASK L分别分配给计算节点node-o、node-s、node-l进行执行；将定义的三个计算节点与实际参与计算的端计算节点、边缘计算节点、云计算节点根据一一对应原则建立映射关系；S22、对于可能的映射策略找出基于该映射策略下最优的模型分割的切割点和用于训练的图像数据分配的策略,其中,整个训练的总训练时延包括计算时延和数据传输时延,过程如下：S221、对计算时延进行理论建模,使用T-(j,i,b,forward)和T-(j,i,b,backward)分别表示在计算节点j,j∈{o,s,l},o,s,l分别代表计算节点node-o、node-s、node-l上基于b个图像数据作为输入执行第i层深度学习模型的前向传播时延和后向传播时延,计算公式如下：                            /&gt;公式(1)中,表示在计算节点j上基于单个图像作为输入执行第j层深度学习模型前向传播所需的平均计算时延；公式(2)中,表示在计算节点j上基于单个图像作为输入执行第j层深度学习模型反向传播所需的平均计算时延；S222、求解深度学习模型更新过程中在各计算节点产生的计算时延,计算公式如下：                                                      公式(3)中,T-(o,update)表示在计算节点node-o更新其所包含的深度学习模型层的参数所需的计算时延,表示在计算节点node-o执行第i层深度学习模型参数更新所需的平均计算时延；公式(4)中,T-(s,update)表示在计算节点node-s更新其所包含的深度学习模型层的参数所需的计算时延,表示在计算节点node-s执行第i层深度学习模型参数更新所需的平均计算时延；公式(5)中,T-(l,update)表示在计算节点node-l更新其所包含的深度学习模型层的参数所需的计算时延,表示在计算节点node-l执行第i层深度学习模型参数更新所需的平均计算时延；S223、求解数据传输时延T-(communication),计算公式如下：                  公式(6)中,DataSize表示所需传输数据的大小,Bandwidth表示当前测量所得的带宽大小；S23、将整个分布式的深度学习模型训练按照以下原则进行划分：前m-s层深度学习模型在并行的三个计算节点上运行,m-(s+1)层至m-l层在并行的计算节点node-l和计算节点node-o上运行,m-(l+1)层至最后一层仅运行在计算节点node-o上,然后将总训练时延切分为三个阶段：阶段一：训练前m-s层深度学习模型所需的时延；阶段二：训练m-(s+1)层至m-l层深度学习模型所需的时延；阶段三：训练而m-(l+1)层至最后一层深度学习模型所需的时延；S231、对于阶段一,用和/&gt;分别表示阶段一中所需的前向传播和后向传播所需的时延,计算公式如下：          /&gt;                  公式(7)中,T-(o,input)、T-(s,input)、T-(l,input)分别代表计算节点node-o、node-s、node-l接收训练所需图像数据的数据传输时延,T-(s,output)代表从计算节点node-s将前向传播的输出数据给计算节点node-o的数据传输时延,代表计算节点node-o基于b-o个图像数据作为输入执行第i层深度学习模型的前向传播所需要的时延,/&gt;代表计算节点node-s基于b-s个图像数据作为输入执行第i层深度学习模型的前向传播所需要的时延,/&gt;代表计算节点node-l基于b-l个图像数据作为输入执行第i层深度学习模型的前向传播所需要的时延；公式(8)中,T-(s,grad)代表从计算节点node-o将反向传播的梯度数据发送给计算节点node-s的数据传输时延,代表计算节点node-o基于b-o个图像数据作为输入执行第i层深度学习模型的反向传播所需要的时延,/&gt;代表计算节点node-s基于b-s个图像数据作为输入执行第i层深度学习模型的反向传播所需要的时延,/&gt;代表计算节点node-l基于b-l个图像数据作为输入执行第i层深度学习模型的反向传播所需要的时延；S232、对于阶段二,用和/&gt;分别表示阶段二中所需的前向传播和后向传播所需的时延,计算公式如下：                                    公式(9)中,T-(l,output)代表计算节点node-l将前向传播的输出数据发送给计算节点node-o的数据传输时延,代表计算节点node-o基于b-o+b-s个图像数据作为输入执行第i层深度学习模型的前向传播所需要的时延；公式(10)中,T-(l,grad)代表计算节点node-o发送反向传播计算的梯度给计算节点node-l产生的数据传输时延,代表计算节点node-o基于b-o+b-s个图像数据作为输入执行第i层深度学习模型的反向传播所需要的时延；S233、对于阶段三,用和/&gt;分别表示阶段三中所需的前向传播和后向传播所需的时延,计算公式如下：/&gt;                                    公式(11)中,代表计算节点node-o基于b-o+b-s+b-l个图像数据作为输入执行第i层深度学习模型的前向传播所需要的时延,N代表所训练模型的总层数；公式(12)中,代表计算节点node-o基于b-o+b-s+b-l个图像数据作为输入执行第i层深度学习模型的反向传播所需要的时延；S24、当深度学习模型训练的反向传播计算完成,计算节点node-s和计算节点node-l将其计算的模型参数梯度发送给计算节点node-o,然后计算节点node-o对所得参数梯度进行一个汇总取平均得到处理后的参数梯度,最后再将汇总后的参数梯度分别发送给计算节点node-s和计算节点node-l,各计算节点基于所得汇总后的参数梯度更新模型的参数,求解模型更新所需的时延,公式计算如下：T-(update)＝max{T-(s,weightGrad),T-(l,weightGrad)}+max{T-(o,update),T-(s,update),T-(l,update)}(13)公式(13)中,T-(s,weightGrad)和T-(l,weightGrad)分别代表计算节点node-s和计算节点node-l与计算节点node-o进行参数梯度数据交换所产生的数据时延；S25、将深度学习模型训练的总训练时延用T-(total)表示,计算公式如下：                  S26、根据深度学习模型训练中每次迭代所用到的图像数据的数目为定值B,添加以下限制条件：b-o+b-s+b-l＝B根据变量m-s和m-l可能取值等于0,此时代表计算节点node-s和计算节点node-l不参与训练任务的计算,分配给计算节点node-s和计算节点node-l的样本数据为0,添加以下限制条件：0≤b-s≤m-sB,0≤b-l≤m-lB根据限制条件,将总训练时延作为目标函数进行最小化,将得到的一个最小化优化的问题表示如下：                  s.t.b-o+b-s+b-l＝B0≤b-s≤m-sB0≤b-l≤m-lB对于以上最小化优化问题,将变量m-s和m-l的值确定后,最小化优化问题则变成一个整数线性规划问题,采用优化求解器对该整数线性规划问题进行求解,通过对变量m-s和m-l的可能取值进行遍历,再求解出相应最优的b-o、b-s、b-l的解得到一个待选策略集合,最后比较待选策略集合内的策略选出最优的策略。</td>   <td>G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周素红;              李秋萍;              卢俊文;              郭昊南;              颜锌颖;                   胡靖元       </td>   <td>中山大学</td>   <td>一种GPS轨迹与活动日志数据融合的自动处理方法及系统</td>   <td>广东省</td>   <td>CN111198929B</td>   <td>2023-03-28</td>   <td>本发明公开了一种GPS轨迹与活动日志数据融合的自动处理方法及系统,其中,所述自动处理方法包括如下步骤：S1、获取GPS轨迹数据,识别得到GPS轨迹数据的停驻点和移动点；S2、获取活动日志数据并对其进行地理编码,得到包含地点列表的活动日志数据,所述地点列表包括地点、及对应地点的经纬度信息和时间信息；S3、将S2的活动日志数据与S1的GPS轨迹数据匹配,校正活动日志数据的经纬度信息；S4、将GPS轨迹数据与S3校正后的活动日志数据匹配,得到带日志属性的GPS轨迹数据。通过本自动处理方法及系统能模拟调查员对数据进行理解和判断的过程,可以代替人工对大样本的GPS轨迹数据与活动日志数据进行整理、匹配与相互补充,数据的处理效率更高。</td>   <td>1.一种GPS轨迹与活动日志数据融合的自动处理方法,其特征在于,包括如下步骤：S1、获取GPS轨迹数据,识别得到GPS轨迹数据的停驻点和移动点；S2、获取活动日志数据并对其进行地理编码,得到包含地点列表的活动日志数据,所述地点列表包括地点、及对应地点的经纬度信息和时间信息；S3、将S2的活动日志数据与S1的GPS轨迹数据匹配,校正活动日志数据的经纬度信息；S4、将GPS轨迹数据与S3校正后的活动日志数据匹配,得到带日志属性的GPS轨迹数据；其中,S3具体包括如下步骤：S31、根据运动状态划分活动日志数据,得到若干段的第一日志数据集；所述第一日志数据集包括起始时间、终止时间和活动地经纬度；S32、按时间和运动状态的对应关系,分别将若干段的第一日志数据集与GPS轨迹数据进行匹配；若时间和运动状态均一致则匹配成功,则计算对应的GPS轨迹数据的经纬度均值,并将其替换为该第一日志数据集的活动地经纬度；若匹配不成功,则执行S33；S33、判断第一日志数据集中符合匹配条件且前后连续的部分日志数据的时间长度,是否大于预设参数；若是,则计算符合匹配条件的部分日志数据所对应的GPS轨迹数据的经纬度均值,并将其替换为该第一日志数据集的活动地经纬度；若否,则不替换该第一日志数据集的活动地经纬度；其中,S4具体包括如下步骤：S41、根据停驻和移动的运动状态,对GPS轨迹数据进行划分,得到连续的若干子轨迹数据；S42、从若干子轨迹数据中识别得到空缺数据,S42具体包括：S421、将一空缺数据与其前后的空缺数据进行合并,得到若干时间连续的空缺数据集合；S422、将空缺数据集合与S3校正后的活动日志数据按时间的对应关系进行匹配,得到带日志属性的空缺数据集合；S423、识别每一非空缺数据的运动状态,将一非空缺数据与其前后运动状态相同的非空缺数据进行合并,得到若干时间连续的非空缺数据集合；S424、将非空缺数据集合与S3校正后的活动日志数据按时间的对应关系进行匹配,得到带日志属性的非空缺数据集合；S425、将S422的带日志属性的空缺数据集合与S424的带日志属性的非空缺数据集合,按时间顺序进行合并,得到带日志属性的GPS轨迹数据。</td>   <td>G06F16/29;G01S19/37</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              施煜锴;              陈崇雨;              王可泽;                   成慧       </td>   <td>中山大学</td>   <td>一种基于上下文相关多任务深度学习的图像超分辨算法</td>   <td>广东省</td>   <td>CN109389552B</td>   <td>2023-03-28</td>   <td>本发明提供一种基于上下文相关多任务深度学习的图像超分辨算法,该算法设计了三个深度神经网络,分别用于捕捉图像的基本信息、主要边缘信息和微小细节信息,然后在一个多任务学习的框架中对这些神经网络进行上下文相关连接与统一训练。给定输入的低分辨率图像,训练好的神经网络将分别输出基本图像、主要边缘图像和微小细节图像,最终的高分辨率图像由基本图像和微小细节图像融合而成；该算法可以仅用静态低分辨率(LR)图像为输入,恢复出高分辨率(HR)的图像。并且,所恢复出来的HR图像的结构得到了很好的保持,能尽可能多地恢复出理想HR图像中的结构信息。</td>   <td>1.一种基于上下文相关多任务深度学习的图像超分辨算法,其特征在于,包括以下步骤：S1：收集图像数据；步骤S1中收集的图像数据训练数据包括高分辨率的图像、该高分辨率的图像对应的边缘图像和其对应的静态低分辨率图像；其中,高分辨率的图像对应的边缘图像是二值图像,由边缘检测算法给出或由人工标记给出；边缘图像中值为0的像素表示非边缘,值为1的像素表示边缘；S2：建立神经网络模型；步骤S2的神经网络模型包括三个部分组成；第一个部分由4个卷积层组成,其滤波器数量逐层提高,用于提取图像的多尺度特征；第二部分由一个第一反卷积层和两个第一卷积层组成,其中第一反卷积层用于将特征图进行自适应的插值,第一卷积层用于输出期望的特征图和初步的高分辨率的图像；第三部分是由一个第二反卷积层和两个第二卷积层组成,其中第二反卷积层用于将特征图进行自适应的插值,第二卷积层用于输出残差图；S3：利用收集图像数据对所建立的神经网络模型进行训练；S4：将训练好的神经网络处理静态低分辨率图像即得到高分辨率的图像。</td>   <td>G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         万海;              欧佳玲;              曾娟;                   王宝亿       </td>   <td>中山大学</td>   <td>面向移动端虚拟现实与增强现实的场景图谱生成方法</td>   <td>广东省</td>   <td>CN111144492B</td>   <td>2023-03-28</td>   <td>本发明提供面向移动端虚拟现实和增强现实的场景图谱生成方法,涉及场景图谱领域。包括：利用场景图谱样本集,提取视觉关系组合、常识信息；通过目标检测模型检测出图像中物体的物体框及其物体类别；获取与物体对应的语义信息,根据常识信息进一步构造常识知识图,生成视觉关系f1；提取物体框区域的视觉信息,生成视觉关系f2；结合常识信息和视觉信息,通过注意力机制将f1、f2结合,生成场景图谱,获得并优化场景图谱生成模型。本发明在移动端运行场景图谱生成模型,能快速识别虚拟现实或增强现实画面中目标物体及物体之间的关系,相比服务器端检测具有更高的检测效率,为面向移动端虚拟现实和增强现实进行场景图谱生成提供技术可行性。</td>   <td>1.面向移动端虚拟现实和增强现实的场景图谱生成方法,其特征在于,包括以下步骤：S1、利用场景图谱样本集,提取并统计视觉关系组合,提取常识信息；S2、通过训练好的目标检测模型检测出输入场景图谱样本集图像中的物体,生成若干个物体框,并预测出物体框对应的物体类别；S3、根据步骤S2得到的物体类别获取与物体对应的语义信息,再根据步骤S1所提取的常识信息,进一步构造常识知识图,生成初步的视觉关系f1；S4、通过神经网络模型提取所述物体框的视觉信息,包括视觉特征、空间特征和语义特征,生成初步的视觉关系f2；S5、结合视觉信息和常识信息,通过注意力机制,将初步的视觉关系f1、初步的视觉关系f2的检测结果结合,进行场景图谱生成,并得到场景图谱生成模型；S6、虚拟现实与增强现实系统包括移动端、计算机显示终端,对得到的场景图谱生成模型进行常识知识图和模型参数的优化,从而获取能够嵌入移动端的模型,以现实场景图像作为输入,并传输给计算及显示终端；计算及显示终端接收到现实场景图像,进行场景图谱生成,抽取对应现实场景图的视觉关系,叠加在现实场景图像中,获得当前现实或虚拟场景的场景图谱；步骤S4包括：S41、将检测出来的一对物体s和o,分别表示主语物体和宾语物体,通过训练好的神经网络模型提取视觉特征,编码成视觉特征；S42、将检测出来的一对物体s和o,获取他们的位置信息,依次通过降采样、掩膜、卷积神经网络和全连接层,获取空间特征；S43、将预测出来的物体类别c,获取对应的词向量,从而获取语义特征；S44、将视觉特征、空间特征和语义特征融合为视觉信息,从而生成初步的视觉关系f2。</td>   <td>G06V20/20;G06V20/70;G06V10/82;G06T19/00;G06N3/045;G06N3/044;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         成慧;              杨凯;              吴华栋;                   张东       </td>   <td>中山大学</td>   <td>基于图像输入的多智能体跨模态深度确定性策略梯度训练方法</td>   <td>广东省</td>   <td>CN109948642B</td>   <td>2023-03-28</td>   <td>本发明涉及一种基于图像输入的多智能体跨模态深度确定性策略梯度训练方法；首先构建在仿真平台中的机械臂训练环境；之后构造两个利用不同模态输入的导师(teacher)和学徒(student)智能体；然后基于深度确定性策略梯度算法,训练导师的actor模块与critic模块和学徒的actor模块,最终实现基于图像输入的跨模态深度强化学习机械臂训练算法；在总体训练完成的时候,就能够只使用学徒的演员网络,接受高维度的图像输入,输出能够完成任务的动作,并且这样的方法很适合迁移到真实环境中,由于真实环境无法提供全状态模态的信息,但是图像模态的信息较为容易获得,所以当训练好学徒的演员网络之后,就可以抛弃全状态模态信息的需求,直接利用图像输入获得比较好的输出策略。</td>   <td>1.一种基于图像输入的多智能体跨模态深度确定性策略梯度训练方法,其特征在于,包括以下步骤：S1.搭建仿真器中的实验平台,定义交互物体与机械臂类型,定义机械臂控制任务的最终目标与奖惩规则,明确双智能体的状态空间和动作空间；S2.基于深度确定性策略梯度算法,为两组智能体：teacher和student建立决定行动的actor模块与评判反馈的critic模块,两种模块都基于深度神经网络搭建,并随机初始化网络参数；S3.利用仿真环境中容易直接读取的全状态信息结合深度确定性策略梯度预先训练导师智能体的actor和critic模块,该训练过程包括智能体对环境的探索和智能体利用探索收集到的数据对actor和critic模块进行更新；S4.利用训练好的导师智能体,指导学徒智能体actor模块的训练,该过程包括：学徒智能体对环境的单独探索和学徒智能体利用探索收集到的数据以及导师智能体给予的梯度指导耦合优化actor模块,同时利用学徒智能体的训练数据以极小学习率优化导师的actor与critic模块；具体包括：S41.学徒actor模块包含两个结构完全相同,参数更新时间不一致的网络模型,及时更新参数的网络模型μ为在线actor,其参数表示为θ～μ；延迟更新参数的网络模型μ′为目标actor,其参数表示为θ～(μ’)；对于目标actor,根据经验池中随机采样的样本[s-L,s-H,a,r,s-L’,s-H’],其中s-L和s-H分别为当前时刻下的全状态信息和图像信息,s′-L和s′-H分别为下一个时刻的全状态信息和图像信息；利用下述梯度下降公式优化学徒在线actor：                  公式中第一项利用导师智能体的在线critic模块根据采样样本中的全状态模态信息s-L与动作a计算状态-动作对的Q值,该Q值取负后作为损失函数的第一项参与梯度计算；上述公式的第二项描述了两个智能体的actor在接收同一时刻下同一场景的不同模态表现形式得到动作输出的相似程度；μ-t和μ-s分别为导师actor模块的网络和学徒actor模块的网络,r表示回报；目标actor是在线actor的延迟更新,目标actor的参数更新公式为：θ～(μ’)＝τθ～μ+(1-τ)θ～(μ’),其中τ为平衡因子；S42.利用步骤S41的更新公式更新学徒智能体的actor模块,并利用更新后的actor模块对环境进行探索得到新的探索样本[s-L,s-H,a,r,s-L’,s-H’],将新的探索样本加入到原本的经验池中,如果样本数量达到经验池的最大样本数量,则用最新的探索样本替换旧的样本；S43.利用样本[s-L,a,r,s-L’]以小步长更新导师的actor与critic模块,让导师智能体也能收益于学徒智能体的环境探索经验；S44.重复步骤S42与S43直至满足导师智能体的优化终止条件或达到最大迭代步数；S5.重复步骤S4,直到智能体的决策满足优化终止条件。</td>   <td>G06V10/774;G06V30/19;G06N3/006;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              刘妮;              郭叙森;                   程龙       </td>   <td>中山大学</td>   <td>一种针对动态视觉传感器事件流的新型去雨方法及系统</td>   <td>广东省</td>   <td>CN112184572B</td>   <td>2023-03-28</td>   <td>本发明涉及一种针对动态视觉传感器事件流的新型去雨方法。创新地提出基于雨水痕迹在时间方向和水平宽度方向上的稀疏性,将传统的H-W视角转换为W-T视角,通过这一转换将雨水从错综复杂的背景环境中提取出来,变成在W-T平面上近似均匀分布的噪声点,大幅降低了去除雨水的难度；使用中值滤波算法清除雨水痕迹,充分利用了图像中的冗余信息,在去噪的同时能最大程度地保持图像的细节特征。中值滤波的本质是把某点的像素值用该点的一个邻域中各点值的中值代替,让周围的像素值接近的真实值,从而消除孤立的噪声点。W-T空间内雨水表现为椒盐噪声,中值滤波可以简单高效的滤除这种噪声的同时保护了图像的尖锐边缘。</td>   <td>1.一种针对动态视觉传感器事件流的新型去雨方法,其特征在于,基于雨痕分布在时间方向和水平宽度方向上的稀疏性与不连续性,提出在宽度-时间即W-T空间对图像进行去雨操作,对图像的高度进行逐像素操作,即对于每一个高度值,检查其对应的W-T平面；具体包括以下步骤：S1.创建缓冲队列：创建一个存储DVS视频流的、深度为d的先入先出缓存队列Q,大小为h×w×d；当有新的事件帧/视频帧进入Q时,如果Q中已经存在d帧,则将其中最早进入的帧移出；S2.处理Q中的原始帧I-1,对其去噪,得到原始帧I-1对应的去雨后的帧具体包括：S21.备份：复制Q中的原始帧I-1；S22.空间域转换：将缓存队列Q中的所有帧I转换至W-T空间中,转换后变为h个大小为w×d的图像S23.基于中值滤波对W-T空间中图像逐帧去噪；将W-T平面中的未去雨帧逐帧进行中值滤波得到结果/&gt;通过搜索窗口中的中间像素值来替换掉目标像素值；将中值滤波结果/&gt;进行阈值滤波,得到/&gt;将/&gt;和/&gt;逐元素相乘,得到对应的/&gt;其中,/&gt;为W-T平面的/&gt;对应的中值滤波结果；/&gt;为W-T平面的/&gt;的阈值滤波结果；S24.空间域逆转换：将去噪后得到的h个从W-T空间逆转换回高度-宽度即H-W空间,得到原始帧I-1对应的去雨后的帧/&gt;其中,/&gt;为W-T平面的切片；为W-T平面的/&gt;对应的去噪结果；S3.基于原始帧I-1修复其去噪结果S4.输出流中推入结果S5.继续循环处理队列Q：从Q中弹出原始帧I-1,Q中不为空时回到步骤S2,Q中为空时等待输入；其中,DVS输出的事件流本质上是一系列H-W空间内二值图像的组合[I-1,I-2,...,I-t],是一个二维张量,为H-W平面的切片；三维张量/&gt;h为事件帧/视频帧的高；w为事件帧/视频帧的宽；Q为待去雨的图片的队列空间；/&gt;为H-W平面的I-i对应的去噪结果；/&gt;为H-W平面的/&gt;对应的边缘损失修复结果。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              苏博为;              周克涌;              赵山河;              张鹏;                   邓文强       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>产品推荐方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115858915A</td>   <td>2023-03-28</td>   <td>本申请涉及一种产品推荐方法、装置、计算机设备和存储介质。所述方法包括：获取相似用户集合中各个相似用户标识分别对应的已获得产品标识集合；对同一产品标识进行统计,得到各个产品标识对应的获得频率,基于所述获得频率得到产品标识序列；基于所述产品标识序列中产品标识之间的排列顺序,得到关联产品标识集合；将所述关联产品标识集合划分成推荐集合和参考集合,将所述推荐集合和参考集合组成候选关联关系,计算所述候选关联关系中推荐集合相对于参考集合的条件概率,基于所述条件概率确定所述相似用户集合对应的关联关系集合；基于所述关联关系集合,确定推送给所述相似用户标识对应的待推送产品标识。采用本方法能够提高产品推荐的准确率。</td>   <td>1.一种产品推荐方法,其特征在于,所述方法包括：获取相似用户集合中各个相似用户标识分别对应的已获得产品标识集合；对各个所述已获得产品标识集合中的同一产品标识进行统计,得到各个产品标识对应的获得频率,基于所述获得频率得到各个所述相似用户标识分别对应的产品标识序列；基于所述产品标识序列中产品标识之间的排列顺序,得到关联产品标识集合；将所述关联产品标识集合划分成推荐集合和参考集合,将所述推荐集合和参考集合组成候选关联关系,计算所述候选关联关系中推荐集合相对于参考集合的条件概率,基于所述条件概率确定所述相似用户集合对应的关联关系集合；基于所述关联关系集合,确定推送给所述相似用户标识对应的待推送产品标识。</td>   <td>G06F16/9535;G06Q30/0601;G06F18/22;G06F18/213</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱祥维;              刘阳;              徐波;              沈丹;              陈正坤;                   郑泽昊       </td>   <td>中山大学</td>   <td>一种基于LSTM神经网络的综合原子时计算方法及系统</td>   <td>广东省</td>   <td>CN115860050A</td>   <td>2023-03-28</td>   <td>本申请属于时间频率信号技术领域,公开了一种基于LSTM神经网络的综合原子时计算方法及系统。通过获取每台原子钟的测量钟差数据,对测量钟差数据进行预处理,得到预处理后的钟差数据,并按照预设比例将预处理后的钟差数据划分为训练钟差数据和测试钟差数据；利用训练钟差数据对LSTM神经网络进行训练,调整网络参数,得到训练好的LSTM神经网络；将测试钟差数据输入到训练好的LSTM神经网络中,得到每台所述原子钟的预报钟差序列,再计算得到预报钟差数据；计算每台原子钟的权重值,并基于其对应的权重值、预报钟差数据和测量钟差数据,通过加权平均算法的时间尺度基本方程计算得到综合原子时。提高了生成综合原子时的稳定性能。</td>   <td>1.一种基于LSTM神经网络的综合原子时计算方法,其特征在于,所述方法包括：获取每台原子钟的测量钟差数据,对所述测量钟差数据进行预处理,得到预处理后的钟差数据,并按照预设比例将所述预处理后的钟差数据划分为训练钟差数据和测试钟差数据；利用所述训练钟差数据对LSTM神经网络进行训练,调整网络参数,得到训练好的LSTM神经网络；将所述测试钟差数据输入到所述训练好的LSTM神经网络中,得到每台所述原子钟的预报钟差序列,基于所述预报钟差序列得到所述每台所述原子钟的预报钟差数据；计算每台所述原子钟的权重值,并基于所述权重值、所述预报钟差数据和所述测量钟差数据,通过加权平均算法的时间尺度基本方程计算得到综合原子时。</td>   <td>G06N3/0442;G06N3/049;G06N3/08;G06F18/214;G06F17/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;                   何宗耀       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于动态隐式图像函数的任意尺度图像表示方法及系统</td>   <td>广东省</td>   <td>CN115861343A</td>   <td>2023-03-28</td>   <td>本发明公开了基于动态隐式图像函数的任意尺度图像表示方法及系统,其中,方法包括获取待处理图像；通过预先训练的编码器对所述待处理图像进行隐式编码处理,得到二维特征图；将所述二维特征图输入动态隐式图像网络,对所述二维特征图进行动态坐标切片处理,并通过双阶段多层感知器进行像素值预测处理,得到图像像素值。本发明实施例能够减少图像连续表示的计算成本,提高了处理性能,可广泛应用于人工智能技术领域。</td>   <td>1.一种基于动态隐式图像函数的任意尺度图像表示方法,其特征在于,所述方法包括：获取待处理图像；通过预先训练的编码器对所述待处理图像进行隐式编码处理,得到二维特征图；将所述二维特征图输入动态隐式图像网络,对所述二维特征图进行动态坐标切片处理,并通过双阶段多层感知器进行像素值预测处理,得到图像像素值。</td>   <td>G06T7/11;G06N3/0455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘奕志;                   郑颖丰       </td>   <td>中山大学中山眼科中心</td>   <td>基于人工智能的对象检测设备及其方法</td>   <td>广东省</td>   <td>CN115861648A</td>   <td>2023-03-28</td>   <td>本发明涉及一种基于人工智能的对象检测设备及其方法,包括：图像采集模块,用于获取目标检测对象的数字图像并将数字图像传输至图像预处理模块；所述图像预处理模块,用于接收所述图像采集模块获取的数字图像,识别并提取数字图像中目标检测对象的边缘,在图像进行傅里叶变换对低频分量区中对应的像素点进行灰度调节以获得增强图像,并将所述增强图像传输至区域信息统计模块；所述区域信息统计模块,用于接收增强图像并设置掩码矩阵视野并截取ROI区域,进而获取ROI区域内的各区间信息数组；数据处理优化器,用于提高增强图像的数据处理速度；综合识别模块,用以综合ROI区域的特征信息,进而提取并检测目标检测对象。</td>   <td>1.一种基于人工智能的对象检测设备,其特征在于,包括：图像采集模块,用于获取目标检测对象当前场景下的数字图像并将数字图像传输至图像预处理模块；所述图像预处理模块,用于接收所述图像采集模块获取的数字图像,识别并提取数字图像中目标检测对象的边缘,图像预处理模块将位于目标检测对象边缘上各像素点u×u邻域内且位于目标检测对象边缘外的像素点集合设定为集合A1,将位于目标检测对象边缘内的像素点集合设定为集合A2,图像预处理模块根据图像中信号频率的离散程度将集合A1形成的图像区域和集合A2形成的图像区域的并集划分为高频分量区与低频分量区,并对低频分量区中不符合低频要求的像素点进行灰度调节以获得增强图像,所述增强图像为经过灰度调节后的集合A1形成的图像区域和经过灰度调节后的集合A2形成的图像区域的并集,图像预处理模块将所述增强图像传输至区域信息统计模块；所述区域信息统计模块,用于接收所述图像预处理模块传输的增强图像并获取所述增强图像的图像尺寸以及分别获取用于扫描增强图像的第一掩码矩阵沿第一掩码方向和第二掩码矩阵沿第二掩码方向的扫描视野,区域信息统计模块采用所述第一掩码矩阵沿第一掩码方向扫描增强图像内部像素点以获取第一区间信息数组并截取ROI区域,进而获取所述第一区间信息数组中的ROI区域的图像信息,区域信息统计模块采用所述第二掩码矩阵沿第二掩码方向扫描增强图像内部像素点以获取第二区间信息数组,进而获取所述ROI区域中在第二区间信息数组中的图像信息,其中,区域信息统计模块设定沿图像宽度方向为第一掩码方向,设定沿图像高度方向为第二掩码方向；数据处理优化器,用于在对所述第一掩码矩阵沿第一掩码方向和所述第二掩码矩阵沿第二掩码方向扫描增强图像内部像素点的过程中进行数据处理流程的优化,以提高增强图像的数据处理速度；综合识别模块,用以综合所述第一区间数组和所述第二区间数组中ROI区域的特征信息,进而从各干扰对象中提取并精确识别目标检测对象。</td>   <td>G06V10/44;G06V10/25;G06V10/764;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪瑞昕;              林浩添;              徐枫;              余新平;                   吕军锋       </td>   <td>中山大学中山眼科中心;清华大学</td>   <td>一种基于视线估计的视线差值测量方法及装置</td>   <td>广东省</td>   <td>CN115861899A</td>   <td>2023-03-28</td>   <td>本申请属于视线追踪技术领域,公开了一种基于视线估计的视线差值测量方法及装置。通过获取受试者注视视标的视频数据,从视频数据获取人脸图像序列；将该人脸图像序列输入到第一神经网络中进行关键帧提取,得到第一眼位人脸图像和第二眼位人脸图像,再输入到第二神经网络中进行人脸特征点提取,基于人脸特征点坐标进行剪裁,得到第一眼部区域图像和第二眼部区域图像；利用公开数据集中的眼部区域图像集对视线差分估计网络进行训练,得到训练好的视线差分估计网络；将第一眼部区域图像和第二眼部区域图像输入到训练好的视线差分估计网络中,得到第一眼部区域图像和第二眼部区域图像之间的预测视线差值。实现视线差值的降低测量成本,提高测量精度。</td>   <td>1.一种基于视线估计的视线差值测量方法,其特征在于,所述方法包括：获取受试者注视视标的视频数据,基于所述视频数据获取所述受试者的人脸图像序列；将所述人脸图像序列输入到第一神经网络中进行关键帧提取,得到第一眼位人脸图像和第二眼位人脸图像；将所述第一眼位人脸图像和所述第二眼位人脸图像分别输入到第二神经网络中进行人脸特征点提取,得到第一人脸特征点坐标和第二人脸特征点坐标,基于所述第一人脸特征点坐标和所述第二人脸特征点坐标进行剪裁,得到第一眼部区域图像和第二眼部区域图像；利用公开数据集中的眼部区域图像集对视线差分估计网络进行训练,得到训练好的视线差分估计网络；将所述第一眼部区域图像和所述第二眼部区域图像输入到训练好的视线差分估计网络中,得到所述第一眼部区域图像和所述第二眼部区域图像之间的预测视线差值。</td>   <td>G06V20/40;G06V40/16;G06V10/82;G06V10/46;G06V10/26;G06V10/774;G06N3/0464;G06N3/08;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张恺成;              陈泽林;                   郑伟诗       </td>   <td>中山大学</td>   <td>无监督的动作迁移和发现方法、系统、设备和介质</td>   <td>广东省</td>   <td>CN115861902A</td>   <td>2023-03-28</td>   <td>本发明公开了一种无监督的动作迁移和发现方法、系统、设备和介质,方法包括：获取无标签的目标数据集；构建分解动作流的卷积网络模型,对所有视频都做切片处理,用聚类算法计算出所有切片的聚类中心作为切片动作的伪标签,并以这些伪标签学习视频切片表达的分解动作；构建完整动作流的卷积网络模型,用聚类算法计算出所有完整视频的聚类中心作为视频动作的伪标签,并以这些伪标签学习完整视频表达的完整动作；分解动作流的卷积网络模型和完整动作流的卷积网络模型相互学习,使得模型能发现新的动作类型并学习到更精确的分解动作信息。本发明可以在无监督条件下完成动作识别任务,并利用迁移学习方法提高动作识别准确率和整体算法效率。</td>   <td>1.无监督的动作迁移和发现方法,其特征在于,包括下述步骤：获取无标签的目标数据集,对所述目标数据集为采集到的视频；构建分解动作与完整动作双向学习MUSIC模型,所述MUSIC模型包括分解动作流的卷积网络模型和完整动作流的卷积网络模型；所述分解动作流的卷积网络模型是对所有视频都做切片处理,用聚类算法计算出所有切片的聚类中心作为切片动作的伪标签,并以这些伪标签学习视频切片表达的分解动作；所述完整动作流的卷积网络模型是用聚类算法计算出所有完整视频的聚类中心作为视频动作的伪标签,并以这些伪标签学习完整视频表达的完整动作；分解动作流的卷积网络模型和完整动作流的卷积网络模型相互学习,得到训练好的MUSIC模型；在相互学习过程中,给分解动作流和完整动作流之间添加完整性约束,使得完整动作的表达是由已被学习到的分解动作构造而成,并采用相似完整动作区分策略对相似性完整动作进行区分,所述相似完整动作区分策略是如果分解动作不同,则其所属的完整动作被划分到不同的类别中,最后引入分解动作对齐策略,使得分解动作流的卷积网络模型和完整动作流的卷积网络模型都学习共享的分解动作；利用学习好的MUSIC模型在无监督条件下完成动作识别任务。</td>   <td>G06V20/40;G06V10/762;G06V10/82;G06N3/0464;G06N3/088;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>              齐志新       </td>   <td>中山大学</td>   <td>一种生产建设用地的高频次全自动遥感监测方法</td>   <td>广东省</td>   <td>CN114022413B</td>   <td>2023-03-24</td>   <td>本发明公开了一种生产建设用地的高频次全自动遥感监测方法,涉及遥感监测的技术领域,包括：按照三个不同获取时间的先后顺序将光学遥感影像依次设置为矫正影像、参考影像和检测影像；计算检测影像和参考影像、检测影像和矫正影像之间的土地平整强度,获得第一土地平整强度图像和第二土地平整强度图像；确定土地平整强度最佳阈值,利用阈值法分别提取出第一土地平整强度图像上的生产建设用地和第二土地平整强度图像上的生产建设用地,获得第一检测结果图像和第二检测结果图像,确定最终生产建设用地。本发明可以消除农作物、自然植被、山体及建筑阴影季节性变化导致的误差,实现生产建设用地高频次、全自动监测,显著提高监测精度。</td>   <td>1.一种生产建设用地的高频次全自动遥感监测方法,其特征在于,包括以下步骤：S1：获取待检测区域三个不同时间的光学遥感影像,按照三个不同获取时间的先后顺序依次设置为矫正影像、参考影像和检测影像；S2：计算检测影像和参考影像之间的土地平整强度,获得第一土地平整强度图像；计算检测影像和矫正影像之间的土地平整强度,获得第二土地平整强度图像；S3：确定土地平整强度最佳阈值；具体方法为：S3.1：获取多种遥感卫星拍摄的生产建设用地的参考图像和检测图像、非生产建设用地的参考图像和检测图像；S3.2：对多种遥感卫星拍摄的参考图像和检测图像进行组合,计算不同遥感卫星组合的土地平整强度；S3.3：利用决策树算法,根据不同遥感卫星组合的土地平整强度,获得土地平整强度阈值范围；S3.4：根据实际获取待检测区域的遥感卫星种类,在土地平整强度阈值范围内确定土地平整强度最佳阈值；S4：根据土地平整强度最佳阈值,利用阈值法分别提取出第一土地平整强度图像上的生产建设用地和第二土地平整强度图像上的生产建设用地,获得第一检测结果图像和第二检测结果图像；S5：根据第一检测结果图像和第二检测结果图像,获得最终生产建设用地的开发情况；具体方法为：对第一检测结果图像和第二检测结果图像取交集,即：C-(t12)＝(I-(t12)&gt;T)&amp;(I-(t02)&gt;T)式中,C-(t12)表示最终生产建设用地,I-(t12)表示检测影像和参考影像之间的土地平整强度,I-(t02)表示检测影像和矫正影像之间的土地平整强度,T表示土地平整强度最佳阈值,&amp;表示取交集操作。</td>   <td>G06T7/00;G06T7/136;G01C11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王家彪;              朱薇儒;              赵铜铁钢;                   李银林       </td>   <td>中山大学</td>   <td>一种基于预报不确定性的水库多阶段实时优化调度方法</td>   <td>广东省</td>   <td>CN114881481B</td>   <td>2023-03-24</td>   <td>本发明公开了一种基于预报不确定性的水库多阶段实时优化调度方法,包括S1、收集并整理水库实时调度所需的数据；S2、构建水库径流预报模型,实现水库径流预报；S3、水库多阶段径流预报不确定性分析；S4、构建水库实时优化调度模型,实现水库实时优化调度；S5、对水库实时优化调度方案进行收敛性分析；S6、实施水库实时优化调度方案,并进入下一调度阶段。优点是：能够综合多阶段预报信息,同时区分考虑多阶段预报的不确定性,既能充分利用预报信息,又能尽可能降低预报不确定性对实时调度方案的影响,从而显著提高水库调度效益,对于水库预报调度具有实践价值。</td>   <td>1.一种基于预报不确定性的水库多阶段实时优化调度方法,其特征在于：包括如下步骤,S1、收集并整理水库实时调度所需的数据；S2、构建水库径流预报模型,实现水库径流预报；步骤S2具体包括如下内容,S21、根据整理后的水库历史实测径流序列,采用自回归的方法,构建水库径流预报模型,如公式(1)；                  其中,t为预报时段；Q(t)为水库在t预报时段的径流量；Q(t+1)为水库在t+1预报时段的径流量；μ为水库历史实测径流序列的均值；ρ为自回归相关系数；σ为标准差,代表预报不确定性；V为满足标准正态分布的随机变量,V在每个预报时段完全独立,与其他时段无关,V满足公式(2)和(3),E(V)＝0                           (2)E(V～2)＝1                          (3)其中,水库历史实测径流序列的均值μ、自回归相关系数ρ和标准差σ由水库历史实测径流序列回归分析计算得出；S22、利用构建的水库径流预报模型进行水库径流预报；S3、水库多阶段径流预报不确定性分析；步骤S3具体为,水库当前径流预报时段的不确定性量化为σ-0,由观测精度确定；水库未来多个径流预报时段的不确定性量化由公式(4)确定,                  其中,i为径流预报时段编号；σ-i为水库第i个径流预报时段的不确定性量化；σ-(i-1)为水库第i-1个径流预报时段的不确定性量化；对于水库当前径流预报时段,i＝0；S4、构建水库实时优化调度模型,实现水库实时优化调度；步骤S4具体包括如下内容,S41、将每一预报时段划分为一个调度阶段；S42、根据水库调度任务,确定优化调度目标,进而构建水库实时优化调度模型,如公式(5),                  其中,B为效益函数；N为水库实时优化调度阶段总数,N＝1,2,3,……；K-i为考虑预报不确定影响下的不同预报时段的权重系数；R-i为第i个预报时段的水库出库流量,即优化调度方案,也是优化调度的决策变量；S43、根据水库取用水能力和水库库容,确定水库优化调度约束条件；S44、根据水库未来多个径流预报时段的不确定性量化,参照卡尔曼滤波方法中增益系数由方差倍比关系确定的思路计算权重系数K-i,如公式(6)和(7),                                    其中,β为权重惩罚因子；K-0为当前预报时段的权重系数；σ-1为水库第1个径流预报时段的不确定性量化；σ-t为水库径流预报时段t的不确定性量化；σ-(t+1)为水库径流预报时段t+1的不确定性量化；S45、采用遗传算法求解水库实时优化调度模型；S5、对水库实时优化调度方案进行收敛性分析；S6、实施水库实时优化调度方案,并进入下一调度阶段。</td>   <td>G06Q10/0631;G06Q50/06;G06N3/126</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邱建秀;              何晨曦;              辛秦川;                   唐国平       </td>   <td>中山大学</td>   <td>一种基于土壤水分的旱涝急转事件识别方法、装置及设备</td>   <td>广东省</td>   <td>CN115329610B</td>   <td>2023-03-24</td>   <td>本发明涉及自然灾害风险评估技术领域,公开了一种基于土壤水分的旱涝急转事件识别方法、装置及设备。本发明采用日尺度土壤水数据计算其实际分布的概率密度与均匀分布概率密度曲线,并基于该两曲线计算对应日的土壤水分集中指数；根据目标时间段的土壤水分集中指数序列确定可能发生旱涝急转的时间点,并结合土壤水分距平百分率,确定可能发生旱涝急转的时间点对应时间窗口内各日的旱涝状态,若偏旱状态与偏涝状态切换的时间间隔不大于第一天数阈值、切换前的旱涝状态持续时间大于第二天数阈值且切换后的旱涝状态持续时间大于第三天数阈值,判定对应时间点发生旱涝急转事件。本发明有效提高了旱涝急转事件识别的精度,应用效果更好。</td>   <td>1.一种基于土壤水分的旱涝急转事件识别方法,其特征在于,包括：获取目标时间段内各日在对应第一时间窗口内的土壤水分序列,对各土壤水分序列进行离差标准化处理,得到目标时间段内各日对应的标准化土壤水分序列；根据所述标准化土壤水分序列绘制对应日的实际累积土壤水分值与累积时间的第一概率密度曲线,以及绘制对应日的累积平均土壤水分值与累积时间的第二概率密度曲线,计算对应日的第一概率密度曲线和第二概率密度曲线在对应第一时间窗口内的积分之差,将所述积分之差除以相应第二概率密度曲线在对应第一时间窗口内的积分,得到对应日的土壤水分集中指数；将所述目标时间段内每日的土壤水分集中指数与预置的指数正常阈值范围进行比较,从超出所述指数正常阈值范围的土壤水分集中指数序列中选取极值点的对应日作为可能发生旱涝急转的时间点；以所述可能发生旱涝急转的时间点为时间窗口中心,计算对应第二时间窗口内各日的土壤水分距平百分率,根据计算得到的土壤水分距平百分率序列确定对应第二时间窗口内各日的旱涝状态,若对应第二时间窗口内偏旱状态与偏涝状态切换的时间间隔不大于第一天数阈值、切换前的旱涝状态持续时间大于第二天数阈值且切换后的旱涝状态持续时间大于第三天数阈值,判定在对应的可能发生旱涝急转的时间点发生旱涝急转事件；其中,绘制第一概率密度曲线和第二概率密度曲线时,分别根据所述标准化土壤水分序列计算累积土壤水分序列和累积平均土壤水分序列,根据所述累积土壤水分序列绘制得到第一概率密度曲线,根据所述累积平均土壤水分序列绘制得到第二概率密度曲线；所述第一时间窗口的时间长度为23天时,以对应日作为时间窗口中心,则取对应日前后11天进行土壤水分集中指数计算,相应的土壤水分集中指数的计算公式如下：                  式中,表示第日的土壤水分集中指数,为第一概率密度曲线,为第二概率密度曲线。</td>   <td>G06F30/20;G06F18/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈刚;              林文蔚;                   仲崇豪       </td>   <td>中山大学</td>   <td>基于扇形卷积神经网络的图像特征匹配方法</td>   <td>广东省</td>   <td>CN115439673B</td>   <td>2023-03-24</td>   <td>本发明公开了基于扇形卷积神经网络的图像特征匹配方法,通过构建扇形卷积神经网络,根据损失函数对扇形卷积神经网络进行训练优化,获得目标模型,使得本发明的实施例具有较强的泛化能力和鲁棒性；通过在图像中提取特征点,并以特征点为中心在图像中提取正方形图像块集；将图像块集输入扇形卷积神经网络中,得到旋转描述子；其中,旋转描述子是可旋转重编码描述子；对旋转描述子进行处理,能够在图像任意旋转变化的情况下,完成图像的高精度特征匹配。本发明的实施例可广泛应用于计算机图像处理技术领域。</td>   <td>1.基于扇形卷积神经网络的图像特征匹配方法,其特征在于,包括：构建扇形卷积神经网络,根据损失函数对所述扇形卷积神经网络进行训练优化,获得目标模型；其中,所述扇形卷积神经网络具有扇形卷积层和一维卷积层；在图像中提取特征点,并以所述特征点为中心在所述图像中提取正方形图像块集；将所述正方形图像块集输入所述目标模型中,得到旋转描述子；其中,所述旋转描述子为可旋转重编码描述子；对所述旋转描述子进行旋转重编码和特征匹配处理,完成图像的特征匹配；其中,所述将所述正方形图像块集输入所述目标模型中,得到旋转描述子,包括：通过扇形卷积核对图像块进行卷积,得到特征图；其中,所述图像块来源于所述正方形图像块集；对所述特征图进行循环填充,并将循环填充后的所述特征图输入一维卷积层进行卷积,得到可旋转重编码的旋转描述子。</td>   <td>G06V10/75;G06N3/04;G06N3/08;G06V10/46;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李劲嵘;              李根;              封檑;                   周榆松       </td>   <td>中山大学中山眼科中心</td>   <td>一种角膜缘定位方法及其系统</td>   <td>广东省</td>   <td>CN115496808B</td>   <td>2023-03-24</td>   <td>本发明提供了一种角膜缘定位方法及其系统,方法包括：构建多分辨率多尺寸多种形态的卷积核；对输入图像进行包括边缘提取在内的预处理；通过各个最低分辨率下的卷积核对最低分辨率下的去噪边缘图像进行卷积处理,得到定位样本；样本扩展,并筛选得到n个最优样本；进行基于最近点关联的迭代椭圆优化流程,得到包括角膜缘的圆心位置和角膜缘椭圆的几何参数在内的定位结果。本发明的方案具有鲁棒性、快速性和精确性,能够有效过滤眼睑特征对角膜缘定位识别的影响,准确、高效的实现角膜缘定位,且整体的计算量小,计算过程简单,计算效率高。</td>   <td>1.一种角膜缘定位方法,其特征在于,包括如下：基于角膜缘在眼球转动时的多种形态,构建多个分辨率、多个尺寸、多种眼球转动形态下的卷积核,并对多个卷积核进行编号；对输入图像进行包括边缘提取在内的预处理,得到仅涉及眼部区域的、多个分辨率下的去噪边缘图像；通过各个最低分辨率下的卷积核对最低分辨率下的去噪边缘图像进行卷积处理,得到n个定位样本；其中,每个定位样本中包括角膜缘的像素坐标、卷积核编号以及卷积核与去噪边缘图像的匹配程度；n为大于1的自然数；对所述定位样本进行样本扩展,并基于预设分辨率下的卷积核和去噪边缘图像对扩展的样本进行筛选,重新得到n个最优样本；以n个最优样本、各个卷积核以及最高分辨率下的去噪边缘图像为输入,进行基于最近点关联的迭代椭圆优化流程,得到包括角膜缘的圆心位置和角膜缘椭圆的几何参数在内的定位结果。</td>   <td>G06T7/73;G06T5/00;G06T7/00;G06T7/11;G06T7/13;G06V10/26;G06V10/30;G06V10/44;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              郑冶枫;              赵瑞辉;              刘亚飞;              林帅;              刘文阁;              唐鉴恒;                   王巨宏       </td>   <td>中山大学;腾讯科技(深圳)有限公司</td>   <td>一种信息推荐方法、装置、设备、系统及存储介质</td>   <td>广东省</td>   <td>CN115840809A</td>   <td>2023-03-24</td>   <td>本申请实施例公开了一种信息推荐方法、装置、设备、系统及存储介质。方法中首先获取目标对象的医疗文本素材。其后确定医疗文本素材中的症状实体。接着基于医疗文本素材,提取与症状实体对应的症状实体特征信息和上下文特征信息。然后将症状实体特征信息和上下文特征信息进行特征融合,得到症状实体对应的融合特征。最后基于医疗文本素材中各症状实体对应的融合特征进行信息推荐。通过从医疗文本素材提取症状实体对应的的症状特征信息和上下文特征信息,以更丰富的症状关联语义作为所推荐信息的依据。相比于已有技术,本申请技术方案丰富了所推荐信息的依据范畴,提升了医疗文本素材中信息的利用率,进而使推荐的信息更加准确。</td>   <td>1.一种信息推荐方法,其特征在于,包括：获取目标对象的医疗文本素材；确定所述医疗文本素材中的症状实体；基于所述医疗文本素材,提取与所述症状实体对应的症状实体特征信息和上下文特征信息；将所述症状实体特征信息和所述上下文特征信息进行特征融合,得到所述症状实体对应的融合特征；基于所述医疗文本素材中各症状实体对应的融合特征进行信息推荐。</td>   <td>G06F16/335;G06F16/33;G06F16/36;G16H50/20;G16H40/20;G16H70/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张贺晔;                   张卫卫       </td>   <td>中山大学</td>   <td>冠状动脉特异性钙化检测方法及装置</td>   <td>广东省</td>   <td>CN111612756B</td>   <td>2023-03-21</td>   <td>本申请提供了一种冠状动脉特异性钙化检测方法及装置,包括：利用人工智能模型的自学习能力,建立冠状动脉多视角医学图像的多视角图像特征与冠状动脉中的钙化分割结果和钙化量化结果之间的对应关系；获取患者的当前冠状动脉多视角医学图像的当前多视角图像特征；通过对应关系,确定与当前多视角图像特征对应的当前冠状动脉中的钙化分割结果和钙化量化结果；具体地,确定与多视角图像特征对应的当前冠状动脉中的钙化分割结果和钙化量化结果,包括：将对应关系中与当前多视角图像特征相同的多视角图像特征所对应的冠状动脉中的钙化分割结果和钙化量化结果,确定为当前冠状动脉中的钙化分割结果和钙化量化结果。同时实现分割和量化,节省冗余工作。</td>   <td>1.一种冠状动脉特异性钙化检测方法,其特征在于,包括：利用人工智能模型的自学习能力,建立冠状动脉多视角医学图像的多视角图像特征与冠状动脉中的钙化分割结果和钙化量化结果之间的对应关系；其中,所述多视角至少包括三个位置不同的视角；具体的,利用残差空洞网络提取轴视角特征；所述残差空洞网络包括依次设置的收缩路径、金字塔池化模块和扩张路径；所述收缩路径包括残差网络,所述残差网络共52层,包括4个卷积核大小为3x3的残差块,所述残差网络的最后两个残差块中使用扩张率为2的空洞卷积；所述金字塔池化模块共4层,池化核的大小分别为1x1、2x2、3x3和6x6,所述金字塔池化模块用于提取全局上下钙化信息；所述扩张路径包括3个特征融合模块,每个所述特征融合模块分别包括基于3x3反卷积核的上采样、基于通道的级联和2个3x3的卷积层,所述扩张路径用于将所述收缩路径提取的多尺度特征和所述金字塔池化模块提取的全局上下钙化信息进行融合,其中,所述多尺度特征由所述收缩路径中每个残差块提取到的特征经过一次扩张率为2、通道数为16的空洞卷积得到；获取患者的当前冠状动脉多视角医学图像的当前多视角图像特征；通过所述对应关系,确定与所述当前多视角图像特征对应的当前冠状动脉中的钙化分割结果和钙化量化结果；具体地,确定与所述多视角图像特征对应的当前冠状动脉中的钙化分割结果和钙化量化结果,包括：将所述对应关系中与所述当前多视角图像特征相同的多视角图像特征所对应的冠状动脉中的钙化分割结果和钙化量化结果,确定为所述当前冠状动脉中的钙化分割结果和钙化量化结果。</td>   <td>G06T7/00;G06T7/11;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾栋;              卢宇彤;              杜云飞;              钟康游;              李江;                   郭贵鑫       </td>   <td>中山大学</td>   <td>一种支持复杂工作流结构的工作流管理系统</td>   <td>广东省</td>   <td>CN110516000B</td>   <td>2023-03-21</td>   <td>本发明涉及一种支持复杂工作流结构的工作流管理系统,包括工作流定义模块用于接收用户定义的工作流；工作流包括至少一个任务以及各个任务之间的依赖关系,任务包括任务内容和任务类型,任务类型包括原子类型以及控制类型；数据库用于存储工作流定义模块接收的工作流；任务关口模块用于从数据库中获取需要执行的任务作为待执行任务；系统通过工作流定义模块接收用户的工作流定义后,提取任务定义存入数据库；任务关口模块从数据库中获取任务,当待执行任务的任务类型为原子类型时,将任务提交计算节点执行；当待执行任务的任务类型为控制类型时,添加新任务至数据库和/或设置任务的执行状态。该系统可支持复杂的控制结构,支持灵活的工作流模式。</td>   <td>1.一种支持复杂工作流结构的工作流管理系统,其特征在于,包括：工作流定义模块,用于接收用户定义的工作流和/或子工作流并上传至数据库；所述工作流包括至少一个任务以及各个所述任务之间的依赖关系,每个所述任务包括任务内容和任务类型,所述任务类型包括原子类型以及控制类型；所述子工作流包括与工作流之间的映射关系；数据库,用于存储所述工作流定义模块上传的所述工作流以及各个所述任务的执行状态任务关口模块,用于根据所述依赖关系从所述数据库中获取需要执行的所述任务作为待执行任务；当所述待执行任务的任务类型为原子类型时,将所述待执行任务提交执行；当所述待执行任务的任务类型为控制类型时,添加新任务至数据库和/或设置任务的执行状态；所述控制类型包括循环类型和/或分支类型和/或子工作流调用类型和/或返回类型；所述任务关口模块还用于当所述待执行任务的任务类型为原子类型的所述任务,且为父任务所调用时,或者当所述待执行任务的任务类型为返回类型的所述任务时,执行返回操作,所述父任务为任务类型为循环类型或分支类型或子工作流调用类型的所述任务：若所述父任务的所述任务类型为分支类型或子工作流调用类型,则标记所述父任务为已完成,继续查看该父任务是否有自身的父任务并进行处理；若所述父任务的所述任务类型为循环类型,则判断是否需要继续执行所述父任务,若是则标记所述父任务为就绪,结束返回操作,若否则标记所述父任务为已完成,继续返回操作；当所述任务的所述任务类型为子工作流调用类型时,所述任务的所述任务内容包括关键字-called-wf和关键字-sub-wf；若所述任务已被调用过,则所述关键字-called-wf指向已存储在数据库的工作流,若所述任务未被调用,则关键字-sub-wf指向已存储在数据库的子工作流；当所述任务的所述任务类型为返回类型时,所述任务的所述任务内容为调用该所述任务所属子工作流的调用者；所述任务关口模块,还用于当所述待执行任务的任务类型为子工作流调用类型时,执行以下子工作流调用步骤：若所述关键字-called-wf不为空,则将所述关键字-called-wf指向的工作流中没有依赖的任务的执行状态为待执行,以使所述没有依赖的任务作为待执行任务；若所述关键字-called-wf为空,则根据关键字-sub-wf从数据库中提取出子工作流的定义,在-sub-wf指向的子工作流中添加任务类型为返回类型的所述任务作为结束任务,所述结束任务的依赖关系为所述结束任务依赖于所述关键字-called-wf指向的工作流中所有没有被依赖的所述任务,同时将子工作流中的任务定义也写入数据库中,并将其中的没有依赖的任务执行状态设置为待执行；所述任务关口模块,还用于当所述待执行任务的所述任务类型为返回类型时,执行返回操作。</td>   <td>G06F16/25;G06F9/448</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              黄进波;              蔡倬;              林昊;              邬稳;                   梁毅       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>答案生成方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115827834A</td>   <td>2023-03-21</td>   <td>本申请涉及一种答案生成方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取目标问题,对目标问题进行实体识别,得到目标问题中的目标实体；获取目标实体对应的各个候选属性,将目标问题分别和各个候选属性进行拼接,得到多个候选文本；基于候选文本进行目标问题和候选属性的匹配,得到目标问题分别和各个候选属性之间的属性关联度；基于属性关联度,从各个候选属性中确定目标实体对应的目标属性；基于目标实体和目标属性对应的属性值,得到目标问题对应的目标答案。采用本方法能够提高答案生成的效率。</td>   <td>1.一种答案生成方法,其特征在于,所述方法包括：获取目标问题,对所述目标问题进行实体识别,得到所述目标问题中的目标实体；获取所述目标实体对应的各个候选属性,将所述目标问题分别和所述各个候选属性进行拼接,得到多个候选文本；基于所述候选文本进行目标问题和候选属性的匹配,得到所述目标问题分别和所述各个候选属性之间的属性关联度；基于所述属性关联度,从所述各个候选属性中确定所述目标实体对应的目标属性；基于所述目标实体和所述目标属性对应的属性值,得到所述目标问题对应的目标答案。</td>   <td>G06F16/332;G06F40/295</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘镇;              张松安;                   周翠英       </td>   <td>中山大学</td>   <td>一种基于互联网Web服务的工程数据智能管理系统</td>   <td>广东省</td>   <td>CN115828014A</td>   <td>2023-03-21</td>   <td>本发明涉及一种基于互联网Web服务的工程数据智能管理系统,属于网络信息技术与大型基建工程数字化管理技术交叉领域。其特征是：根据勘探报告、钻孔信息等原始资料对工程所在的区域进行机器学习确定地层分布数据模型,利用地层数据模型对地质体进行三维可视化,前后端分离开发B/S架构平台,工程分类编码以及编码复用,独立单元模型功能开发,监测数据二维、三维可视化,神经网络预测功能开发。</td>   <td>1.一种基于互联网Web服务的工程数据智能管理系统,主要包括了：根据勘探报告、钻孔信息等原始资料对建筑工程所在的区域进行机器学习确定地层分布数据模型,利用地层数据模型对地质体进行三维可视化,采用前后端分离开发B/S架构平台,工程分类编码以及编码复用,独立单元模型功能开发,监测数据二维、三维可视化,神经网络预测功能开发。</td>   <td>G06F16/958;G06F16/957</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              欧广盛;              周克涌;              林昊;              张鹏;                   纳颖泉       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>基于联盟链的资源处理方法、装置、电子设备和存储介质</td>   <td>广东省</td>   <td>CN115829721A</td>   <td>2023-03-21</td>   <td>本申请涉及一种基于联盟链的资源处理方法、装置、电子设备和存储介质。方法包括：获取联盟链中资源需求方提供的资源借调凭证,以及获取资源需求方请求借调的目标资源；从资源借调凭证中提取得到借调凭证属性和表征允许借调最大资源值的资源借调量；对借调凭证属性进行隐私化处理,得到原始属性值,并根据联盟链的借调属性池对原始属性值进行属性审查,得到审查结果；当审查结果表征审查通过时,根据资源借调量和目标资源进行比较,得到比较结果；当比较结果表征允许资源借调时,转移目标资源到资源需求方对应的需求方账户中,并将原始属性值存储至借调属性池中。采用本方法能够提高数据的安全性,且避免同一个资源借调凭证重复借调资源。</td>   <td>1.一种基于联盟链的资源处理方法,其特征在于,所述方法包括：获取联盟链中资源需求方提供的资源借调凭证,以及获取所述资源需求方请求借调的目标资源；从所述资源借调凭证中提取得到借调凭证属性和表征允许借调最大资源值的资源借调量；对所述借调凭证属性进行隐私化处理,得到原始属性值,并根据所述联盟链的借调属性池对所述原始属性值进行属性审查,得到审查结果；当所述审查结果表征审查通过时,根据所述资源借调量和所述目标资源进行比较,得到比较结果；当所述比较结果表征允许资源借调时,转移所述目标资源到所述资源需求方对应的需求方账户中,并将所述原始属性值存储至所述借调属性池中。</td>   <td>G06Q40/03;G06F16/27;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         石茜;                   周承乐       </td>   <td>中山大学</td>   <td>一种双时相高光谱遥感图像变化检测方法</td>   <td>广东省</td>   <td>CN115829933A</td>   <td>2023-03-21</td>   <td>本发明提供一种双时相高光谱遥感图像变化检测方法,包括以下步骤：光谱信息方面：首先进行图像融合,得到两期图像融合特征,然后获取初步界定值和综合权重,最后将初步界定值转换为参考界定值；空间信息方面：首先获取第一主成分差值图像,然后获取频域的幅度谱和相位谱,最后通过傅里叶逆变换得到频域显著性水平；信息融合：将频域显著性水平与参考界定值进行卷积运算,得到综合界定值,并结合预设的虚警阈值输出所述双时相高光谱遥感图像的变化检测结果。本发明提供一种双时相高光谱遥感图像变化检测方法,解决了目前双时相高光谱遥感图像变化检测技术容易产生较高虚警现象,从而导致检测精度不够高的问题。</td>   <td>1.一种双时相高光谱遥感图像变化检测方法,其特征在于,包括以下步骤：光谱信息方面：首先将一对双时相高光谱遥感图像进行图像融合,得到两期图像融合特征,然后根据图像融合特征获取初步界定值和综合权重,最后根据所述综合权重将初步界定值转换为参考界定值；空间信息方面：首先获取所述双时相高光谱遥感图像的第一主成分差值图像,然后获取所述第一主成分差值图像在频域的幅度谱和相位谱,并采用高斯滤波对幅度谱进行滤波以抑制非变化属性,最后通过傅里叶逆变换得到频域显著性水平；信息融合：将频域显著性水平与参考界定值进行卷积运算,得到综合界定值,并结合预设的虚警阈值输出所述双时相高光谱遥感图像的变化检测结果。</td>   <td>G06T7/00;G06F17/14;G06F17/15</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵玮;              古威丽;              谢楠;                   范晓蕾       </td>   <td>中山大学</td>   <td>一种口腔黏膜上皮的癌前病变、不典型增生图像检测系统</td>   <td>广东省</td>   <td>CN115829968A</td>   <td>2023-03-21</td>   <td>本发明公开了一种口腔黏膜上皮的癌前病变、不典型增生图像检测系统构建方法,图像数据来源将采集于已经被专家明确诊断的H&amp;E染色的切片进行数字化扫描处理,并以数据分类标签正确为训练模型发展的前提,为打造高专业度、高质量数据集,采集分类的过程将以口腔黏膜及其癌病灶的组织病理学特点与形态鉴别掌握为依据,尽可能接近临床与教学的实际应用；经此项系统识别后产生的具体数值对需了解该病理图像人员可提供高精度的参考数值。</td>   <td>1.一种口腔黏膜上皮的癌前病变、不典型增生图像检测系统构建方法,其特征在于,包括以下步骤：S1：采集并筛选临床被高等医疗机构病理医生诊断为“异常增生”、“原位癌”的口腔黏膜病理切片；S2：将获取的病理切片经病理切片扫描仪转化为数字化全景病理,使切片转化为计算机可读模式；S3：针对全景病理图像中口腔黏膜上皮区域进行标注,将图像上皮层包含基底层的部分与结缔组织进行标签区分,获得原始数据第一样本数据集；S4：将S3描述数据集经深度学习卷积神经网络模型进行图像训练,取得识别分割上皮层包含基底层的分类模型,并且将图像中上皮层包含基底层之区域分割提取；S5：将由全景病理图像分割后的上皮层包含基底层之图像进行裁切,分割为长宽1：1像素的小图片；获得大量图像样本；S6：将S5获得图像进行细胞核级别的标注,将小图片中所有完整细胞核标注构成第二样本数据集；S7：将S6描述数据集经深度学习卷积神经网络模型进行图像训练,识别出数字病理图像中的每个单个细胞核,并进行图像的分割标记,并与对应之病理诊断进行结果对比,形成一套口腔黏膜上皮数字病理图像快速初步判别异常增生与否和等级的分类器；S8：将识别结果所分割的每一个单细胞核的图像像素特征计算,并与对应的病理诊断结果进行归纳统计,将结果反馈给需要识别结果的人员及诊断医生,加强对于异常增生判别结果的验证。</td>   <td>G06T7/00;G06N3/0464;G06N3/08;G06T7/10;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>              李永宝       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种放疗计划三维剂量分布与通量的同步预测方法及装置</td>   <td>广东省</td>   <td>CN115829972A</td>   <td>2023-03-21</td>   <td>本申请属于放射治疗技术领域,公开了一种放疗计划三维剂量分布与通量的同步预测方法及装置,该方法包括：从患者的肿瘤医学影像中提取计划靶区轮廓图像、危及器官轮廓图像及CT图像；根据预先训练好的同步预测模型、提取得到的计划靶区轮廓图像、危及器官轮廓图像及CT图像,得到患者的放疗计划的预测三维剂量分布图和预测二维通量图；根据预测三维剂量分布图和预测二维通量图,反归一化得到患者的放疗计划的绝对剂量分布图和绝对通量图。本申请可以达到提高放疗计划质量一致性和计划设计效率的效果。</td>   <td>1.一种放疗计划三维剂量分布与通量的同步预测方法,其特征在于,所述方法包括：从患者的肿瘤医学影像中提取计划靶区轮廓图像、危及器官轮廓图像及CT图像；根据预先训练好的同步预测模型、提取得到的所述计划靶区轮廓图像、所述危及器官轮廓图像及所述CT图像,得到所述患者的放疗计划的预测三维剂量分布图和预测二维通量图；根据所述预测三维剂量分布图和所述预测二维通量图,反归一化得到所述患者的放疗计划的绝对剂量分布图和绝对通量图。</td>   <td>G06T7/00;G06V10/774;G06T7/13;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              廖泳贤;                   黄立峰       </td>   <td>中山大学</td>   <td>一种面向三维人脸重建系统的自适应参数对抗攻击方法</td>   <td>广东省</td>   <td>CN115830218A</td>   <td>2023-03-21</td>   <td>本发明公开了一种面向三维人脸重建系统的自适应参数对抗攻击方法,方法包括：根据三维人脸重建网络的输出参数种类对参数权重进行初始化操作；其中,所述输出参数种类包括形状参数、表情参数、位置参数、材质参数、光照参数和摄像机参数；根据所述参数权重,输入对抗样本对三维人脸重建模型进行攻击；利用自适应方法不断更新所述参数权重；利用梯度下降法不断更新所述对抗样本,并通过语义约束对所述对抗样本进行优化,直至达到预设条件,完成对目标图像的攻击任务。本发明的泛化能力高,对不同三维人脸重建系统都有很好的攻击效果,可广泛应用于计算机技术领域。</td>   <td>1.一种面向三维人脸重建系统的自适应参数对抗攻击方法,其特征在于,包括：根据三维人脸重建网络的输出参数种类对参数权重进行初始化操作；其中,所述输出参数种类包括形状参数、表情参数、位置参数、材质参数、光照参数和摄像机参数；根据所述参数权重,输入对抗样本对三维人脸重建模型进行攻击；利用自适应方法不断更新所述参数权重；利用梯度下降法不断更新所述对抗样本,并通过语义约束对所述对抗样本进行优化,直至达到预设条件,完成对目标图像的攻击任务。</td>   <td>G06T17/00;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王自鑫;              何国勤;              张博雯;              何晓曦;                   陈弟虎       </td>   <td>中山大学</td>   <td>基于高层次综合工具的数字识别优化方法、系统及介质</td>   <td>广东省</td>   <td>CN115830415A</td>   <td>2023-03-21</td>   <td>本发明公开了基于高层次综合工具的数字识别优化方法、系统及介质,方法包括：构建LeNet-5卷积神经网络,根据预设的训练数据集对其进行训练得到数字识别模型；通过高层次语言表示数字识别模型,并通过高层次综合工具对数字识别模型进行仿真验证；对数字识别模型中的各层循环体进行优化；将优化后的数字识别模型转化成RTL代码并导出为IP核；通过FPGA将IP核与摄像头模块建立连接。本发明利用高层次综合工具对高层次语言描述的数字识别模型的循环体进行优化,然后转化为RTL代码进而导出为IP核,使得数字识别算法可以在FPGA上快速实现,提高了数字识别算法的硬件开发效率和系统执行速度,可广泛应用于机器学习技术领域。</td>   <td>1.一种基于高层次综合工具的数字识别优化方法,其特征在于,包括以下步骤：构建LeNet-5卷积神经网络,根据预设的训练数据集对所述LeNet-5卷积神经网络进行训练得到数字识别模型；通过高层次语言表示所述数字识别模型,并通过高层次综合工具对所述数字识别模型进行仿真验证；通过所述高层次综合工具对所述数字识别模型中的各层循环体进行优化；将优化后的所述数字识别模型转化成RTL代码并导出为IP核；通过FPGA将所述IP核与摄像头模块建立连接,使得所述摄像头模块将采集到的图像数据输入到所述IP核进行数字识别。</td>   <td>G06V10/774;G06V10/82;G06N3/048;G06N3/084;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢舜道;                   谭洪舟       </td>   <td>中山大学</td>   <td>一种模糊可识别二维码及其生成、识别方法</td>   <td>广东省</td>   <td>CN112819120B</td>   <td>2023-03-17</td>   <td>本发明提供一种模糊可识别二维码,包括定位图案、格式信息和数据；所述定位图案由模糊不变形状组成；所述格式信息存储于由模糊不变形状组成的定位图案的模糊不变特征中；所述定位图案间设置有数据带,所述数据存储于所述数据带上。本发明还提供一种模糊可识别二维码的生成、识别方法,其生成的模糊可识别二维码可以在模糊图像中直接被识别,不需要去模糊等预处理操作,简化识别流程,加快在模糊图像中的识别速度且在模糊图像中,利用模糊不变图形可以被快速识别的特点,可以快速定位到该二维码；同时,由于格式信息的存储使用了模糊不变特征,模糊并不能破坏这些特征,因此即使在严重模糊的图像中,仍然可以正确识别该二维码。</td>   <td>1.一种模糊可识别二维码,其特征在于,包括定位图案、格式信息和数据；其中：所述定位图案由模糊不变形状组成；所述格式信息存储于由模糊不变形状组成的定位图案的模糊不变特征中；所述定位图案间设置有数据带,所述数据存储于所述数据带上；所述定位图案由两个同心圆环和五个实心圆盘组成模糊不变形状；其中：两个同心圆环的内侧半径成固定的比例关系；五个实心圆盘的半径相等,并与同心圆环内侧半径之间的比例关系也固定不变；五个实心圆盘的一个圆心设置在同心圆环的圆心上,其余四个的圆心设置在大的同心圆环的内侧圆周上；所述格式信息存储于所述定位图案的五个实心圆盘组成的两个等腰三角形中,所述等腰三角形顶角在所述同心圆环的圆心上,其腰为大的同心圆环的半径,底角分别处在四个实心圆盘的圆心上；所述等腰三角形内角大小是一种模糊不变特征,用于存储格式信息；所述的两个等腰三角形两条腰共线形成大的同心圆环的直径,另外两条腰处于被该直径分成两个半圆的同一半圆内；两个等腰三角形除顶点外不相交,并且其中一个的顶角固定为Δ,另外一个顶角的大小根据二维码容量的不同,为iΔ,并且有iΔ＜180°-2Δ。</td>   <td>G06K19/06;G06K7/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈定安;              肖航;              夏林元;              陈逸敏;              黄英;                   李倩霞       </td>   <td>中山大学</td>   <td>一种面向点云配准的标靶球位置优化方法</td>   <td>广东省</td>   <td>CN112884902B</td>   <td>2023-03-17</td>   <td>本发明公开了一种面向点云配准的标靶球位置优化方法,该方法包括：获取参数；根据参数生成点云并建立仿真模型；对仿真模型的方位进行调整并建立配准模型,得到源点云和目标点云；在配准模型上源点云和目标点云的伪随机位置上分别生成多组球面点云数据并得到仿真标靶球点云数据；对仿真标靶球点云数据执行球面拟合操作,得到球心坐标数据集；计算位移矢量和旋转矩阵；对源点云进行处理,完成与目标点云的配准；计算误差；循环步骤得到最优精度的数据。本发明方法以大量的内业计算弥补高昂的外业成本,获取标靶球的相对最优摆放位置,提高点云数据配准质量。本发明作为一种面向点云配准的标靶球位置优化方法,可广泛应用于点云数据可视化领域。</td>   <td>1.一种面向点云配准的标靶球位置优化方法,其特征在于,包括以下步骤：S1、获取七个基本点参数、一个限高参数和一个地面范围参数；所述七个基本点包括第一测站的中心坐标点A、第二测站相对于第一测站的相对坐标点B、扫描物体的最低处点C、扫描物体的最高处点D、扫描物体的最左侧点E和扫描物体的最右侧点F；S2、根据基本点参数、限高参数和地面范围参数生成三维模型立面点云、地面点云和标靶球的伪随机位置集并建立仿真模型；所述根据基本点参数、限高参数和地面范围参数生成三维模型立面点云、地面点云和标靶球的伪随机位置集并建立仿真模型这一步骤具体包括；连接点C和点D作为三维模型的高,并以等间距a生成多条垂线,连接点E和点D作为三维模型左侧墙宽,以等间距a生成多条垂线,以垂线相交形成的格网的交角为三维模型左侧立面点云；连接点C和点D作为三维模型的高,以等间距a生成多条垂线,连接点E和点F作为三维模型左侧墙宽,以等间距a生成多条垂线,以垂线相交形成的格网的交角为三维模型右侧立面点云；以点E和点F连线的中点Q指向点C作为方向,以点C作为起点,向前取地面范围参数代表的距离至点Q,经过P点做PQ的第一垂线,再分别经过E、F做第一垂线的垂线,垂足分别为G、H,多边形为摆放标靶球的地面范围,在多边形中生成多个最小间距为仿真标靶球直径的点,作为地面点云；基于限高参数和地面点云,以仿真标靶球直径作为间距,将限高参数除以间距,获得层数k,复制k层地面点云作为标靶球可能出现的伪随机位置,得到标靶球的伪随机位置集；根据三维模型左侧立面点云、三维模型右侧立面点云、地面点云和标靶球的伪随机位置集,建立仿真模型；S3、基于基本点的相对位置,调整仿真模型的方位并建立配准模型,得到源点云和目标点云；S4、在配准模型上源点云和目标点云对应标靶球的伪随机位置分别生成多组球面点云数据并得到仿真标靶球点云数据；S5、基于最小二乘法分别对仿真标靶球点云数据执行球面拟合操作,得到球心坐标数据集；S6、基于霍恩法对源点云与目标点云中的球心坐标数据集进行计算,得到位移矢量和旋转矩阵；S7、根据位移矢量和旋转矩阵对源点云进行处理,完成与目标点云的配准；S8、根据目标点云和源点云进行平面拟合,并计算均方根误差作为精度评价值；S9、返回步骤S1,直至达到预设循环次数,输出精度评价最优的10组位置数据。</td>   <td>G06T17/20;G06T7/33;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>              褚燕燕       </td>   <td>中山大学</td>   <td>一种基于在线火灾危险度评测的智能疏散方法及系统</td>   <td>广东省</td>   <td>CN115809750A</td>   <td>2023-03-17</td>   <td>本发明公开了一种基于在线火灾危险度评测的智能疏散方法及系统,包括以下步骤：收集火灾现场信息；基于小波变换原理进行火灾现场信息降噪；确定火源位置信息；火灾现场空间状态危险度评估；构建火灾疏散势函数；基于Dijkstra算法计算最优疏散方向和最优疏散路径；根据位置和时间更新最优疏散方向和最优疏散路径。本发明能够有效解决当前火灾疏散系统对火源信息收集处理程度不足,对火灾时建筑内部各区域实时危险性分析缺少和疏散路径无法依据火势发展更新的问题。</td>   <td>1.一种基于在线火灾危险度评测的智能疏散方法,其特征在于,包括以下步骤：S1、实时采集多种多源火灾现场信息,根据实时采集的多种多源火灾现场信息形成现场燃烧的时间序列的四维信息矢量样本；S2、基于小波变换原理对步骤S1获得的四维信息矢量样本进行火灾现场信息降噪,得到降噪后的有效多源监测信息；S3、对步骤S2降噪后的有效多源监测信息,采用最小二乘法进行火源参数推演,确定火源位置信息；S4、基于步骤S3获得的火源位置信息,并以ISO安全威胁为原则进行动态的火灾现场空间状态危险度评估；S5、根据火源位置信息、火灾现场空间状态危险度以及火灾现场的人员密度信息和人员位置信息,计算火灾现场各个疏散区域的疏散风险,根据各个疏散区域的疏散风险,构建火灾疏散势函数；S6、将火灾风险势函数作为行人运动的路径选择最优策略原则,基于Dijkstra算法计算最优疏散方向和最优疏散路径；S7、以疏散时的位置为起点,并依据间隔时间更新的位置,不断计算并更新最优疏散方向和最优疏散路径。</td>   <td>G06Q10/047;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   刘一晴       </td>   <td>中山大学</td>   <td>一种基于法向量的点云属性压缩方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113096200B</td>   <td>2023-03-14</td>   <td>本发明公开了一种基于法向量的点云属性压缩方法、装置、设备及介质,方法包括：计算待压缩点云数据的几何信息；根据所述点云数据的几何信息进行莫顿码排序,得到莫顿序；根据所述莫顿序遍历得到当前编码点的目标预测点,并确定所述目标预测点的预测权值；构建k-d树；根据所述k-d树搜索所述当前编码点和所述目标预测点的最邻近点；根据所述最邻近点进行平面拟合,得到所述平面的法向量；根据所述法向量对所述预测权值进行修正,得到目标权值；根据所述目标权值确定所述点云数据的编码结果。本发明能够降低点云属性压缩结果的误差,可广泛应用于点云数据处理技术领域。</td>   <td>1.一种基于法向量的点云属性压缩方法,其特征在于,包括：计算待压缩点云数据的几何信息；根据所述点云数据的几何信息进行莫顿码排序,得到莫顿序；根据所述莫顿序遍历得到当前编码点的目标预测点,并确定所述目标预测点的预测权值；构建k-d树；根据所述k-d树搜索所述当前编码点和所述目标预测点的最邻近点；根据所述最邻近点进行平面拟合,得到所述平面的法向量；根据所述法向量对所述预测权值进行修正,得到目标权值；根据所述目标权值确定所述点云数据的编码结果；其中,所述根据所述k-d树搜索所述当前编码点和所述目标预测点的最邻近点,包括：确定当前待预测编码点；根据曼哈顿距离选出与所述当前待预测编码点最近的3个已编码点；通过所述k-d树搜索所述待预测编码点和所述已编码点的4个最邻近点；从所述4个最邻近点中删除1个与所述待预测编码点最近的点,得到3个最邻近点；其中,所述k-d树中每个节点均为k维数值点；所述k-d树的每个节点代表一个超平面；所述超平面垂直于当前划分维度的坐标轴并在该当前划分维度上将空间划分为左子树和右子树。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              林奕全;                   王国倩       </td>   <td>中山大学</td>   <td>一种面向任务型对话的多域请求式意图识别方法</td>   <td>广东省</td>   <td>CN113076758B</td>   <td>2023-03-14</td>   <td>本发明提供一种面向任务型对话的多域请求式意图识别方法,该方法通过将请求式意图识别任务建模为配对排序任务,使用简单的双编码器框架及基于多层级相似度的困难负样本挖掘策略,有效提升了该场景下的识别效率及准确率。实验结果表明,本发明提出的方法相较基线(Baseline)检索模型于DSTC9-Track1测试集上,识别效率及可见域Top1/Top5准确率有较大提升。此外,该方法兼容基于语义空间的域自适应(Domain Adaption)技术,便于后续对小样本场景的扩展使用。</td>   <td>1.一种面向任务型对话的多域请求式意图识别方法,其特征在于,包括以下步骤：S1：获取对话数据,从对话数据中获取实体ID集合E＝{1,2,…,C}和对话历史U＝{u-1,u-2,…,u-t},并对对话历史进行分词；S2：随机采样一批步骤S1已分词的对话历史,与实体ID构成样本对,通过双编码器模型分别对对话历史及实体ID进行特征提取,得到正样本i对应的查询表征及实体ID的码本表征分别为q-i＝E(U-i)∈R～d和Z＝{z-1,z-2,…,z-C}∈R～(|E|×d)；S3：通过步骤S2得到的批样本对的高维表征,根据实体级层级标签计算样本对重要性,并进行实体级表征三元组的挖掘：Triples-(i,local)＝{(q-i,z-i,q-(i,1)～-),(q-i,z-i,q-(i,2)～-),…,(q-i,z-i,q-(i,M)～-)}其中,q-i为正样本i对应的查询表征,q-(,M)～-为样本i的第M个负样本对应的查询表征,z-i为正样本i锚定的码本表征,最后计算实体级局部损失函数S4：通过步骤S2得到的批样本对的高维表征,根据域级层级标签计算样本对重要性,并进行域级表征三元组的挖掘：Triples-(global)＝q-1,z-1,q-1～-,q-2,z-2,q-2～-,…,q-N,z-N,q-N～-}}其中,q-N～-为度量空间中与z-N相似度最高的异域样本表征,最后计算域级全局损失函数S5：计算总损失函数,                  其中,β、γ为可调参数,为码本损失函数,用于对码本嵌入进行更新,最后,通过总损失函数优化双编码器模型,重复步骤S2-S5直至达到设定的最大迭代次数；S6：停止迭代双编码器模型,并用于请求式意图识别。</td>   <td>G06F40/35;G06F40/284</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;                   赖昆锌       </td>   <td>中山大学</td>   <td>一种基于顶点相连列表的无向图索引方法</td>   <td>广东省</td>   <td>CN109558519B</td>   <td>2023-03-14</td>   <td>本发明涉及社交网络领域,更具体的,涉及一种基于顶点相连列表的无向图索引方法。本方法使用相连列表建立起了顶点与顶点的映射关系。在生成一条标签项(u-v,d)后,标签项对应的两个顶点u,v的相连列表nextList(u)和nextList(v)均得到了扩充,如果再次遍历到u或者v时,可以直接利用nextList(u)或者nextList(v)中的结果,并且无需考虑是否将该标签项进行剪枝。因此,相对已有方法,在一定程度上节省了运算时间,提高工作效率。</td>   <td>1.一种基于顶点相连列表的无向图索引方法,其特征在于,包括以下步骤：步骤S1：设在图G＝(V,E)中,V是G的顶点集,E是G的边集；设对于每个v∈V都有标签,则将标签记作L(v)；v的每个标签项表示成(u,d),u∈V,d表示u和v之间的最短距离dist-G(u,v)；步骤S2：输入图G＝(V,E),在G上求V中每一个顶点v的度数r(v)和v的相连列表nextList(v),nextList(v)初始化为v的邻接表；步骤S3：将G中的每一条边(u,v)∈E都转换成一个标签项；步骤S4：将在图G＝(V,E)中所有标签项的集合记作Y,并将步骤S3中生成的标签项放入总标签集Y中；步骤S5：依次遍历G中的每一点v,检查v的相连列表nextList(v)是否为空,如果为空,则遍历G的下一个顶点；如果nextList(v)不为空,则进入步骤S6；步骤S6：依次取得nextList(v)中的一点k,k∈V,存在标签项(v-k,d-1)∈Y,d-1表示顶点v和k之间的最短距离；再对nextList(k)进行遍历,依次取得nextList(k)的一点m,m∈V,存在标签项(k-m,d-2)∈Y,d-2表示顶点v和m之间的最短距离；步骤S7：判断Y中是否存在标签项,如果Y中不存在标签项(v-m,d),则利用(v-k,d-1)和(k-m,d-2)生成标签项(v-m,d-1+d-2),并将其加入Y,同时,将m加入nextList(v),将v加入nextList(m)；如果Y中存在标签项(v-m,d),且d&gt;d-1+d-2,则将该标签项更新为(v-m,d-1+d-2)；步骤S8：重复步骤S5～步骤S7,直至遍历完V中的每一个顶点；步骤S9：将标签集Y中的每一个标签项转换成对应顶点v的标签L(v)中的一个标签项,并在L(v)中加入标签项(v,0)；步骤S10：将所有顶点的标签输出,即为图G的一个2hop索引L-(2hop)G。</td>   <td>G06F16/901;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   高勇       </td>   <td>中山大学</td>   <td>一种基于语法结构的分层Attention的句子匹配方法及装置</td>   <td>广东省</td>   <td>CN109614485B</td>   <td>2023-03-14</td>   <td>本发明公开了一种基于语法结构的分层Attention的句子匹配方法,包括以下步骤：S1：将两句子按语言语法结构拆分,分别拆分为两个不同的分解层次深度的句子结构；S2：对两句子拆分后的句子结构进行词向量映射,并计算attention相似度矩阵；S3：分别对两句子的两个不同分解层次深度的句子结构进行门限注意力对齐,并对结果进行拼接；S4：分别计算两句子的两个不同分解层次深度下的句子结构拼接后结果的均值,经前馈神经网络分别映射为一个固定长度的向量,再分别经过MLP映射为固定维度的向量,并将该固定维度的向量一起经MLP层映射为预测值,所述预测值即为两句子的匹配程度。本发明结合实际句子语法结构的信息和注意力机制构造模型,提高模型适应性及性能。</td>   <td>1.一种基于语法结构的分层Attention的句子匹配方法,其特征在于,包括以下步骤：S1：将两句子按语言语法结构拆分,分别拆分为两个不同的分解层次深度的句子结构；S2：对两句子拆分后的句子结构进行词向量映射,并计算attention相似度矩阵；S3：分别对两句子的两个不同分解层次深度的句子结构进行门限注意力对齐,并对结果进行拼接；S4：分别计算两句子的两个不同分解层次深度下的句子结构拼接后结果的均值,经前馈神经网络分别映射为一个固定长度的向量,再分别经过MLP映射为固定维度的向量,并将该固定维度的向量一起经MLP层映射为预测值,所述预测值即为两句子的匹配程度；所述步骤S1中将两句子按语言语法结构拆分,利用JParser语义解析器进行拆分,分别拆分为两个不同的分解层次深度的句子结构；所述步骤S3中对不同分解层次深度的句子结构进行门限注意力对齐具体为：对齐的计算方式如下:                                    式中,α-j、β-i为对齐后的对齐向量,l-a、l-b为分解层次深度中分解单词个数,e-(ij)为对应的两个词向量的相似度权重,分别对应两句子中第j个分解单词的词向量,该公式为对权重进行归一化。</td>   <td>G06F16/35;G06F18/22;G06N3/0442;G06N3/045</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   李正仁       </td>   <td>中山大学</td>   <td>一种图像特征信息帧内快速划分方法、系统及存储介质</td>   <td>广东省</td>   <td>CN111259826B</td>   <td>2023-03-14</td>   <td>本发明公开了一种图像特征信息帧内快速划分方法、系统及存储介质,方法包括：获取训练视频序列,对视频序列提取特征获取训练数据；通过所述训练数据训练支持向量机得到分类器；通过已训练完成的分类器对模式列表进行过滤,获取过滤后的模式列表；根据过滤后的模式列表,跳过编码模式的尝试过程,进行编码流程。该方法提取图像特征信息后,训练得到分类器,并使用分类器对待处理图像进行判断,对耗时较长的编码模式的尝试过程进行跳过,从而缩短了在进行视频编码过程中所花费的时间。本发明可广泛应用于机器视觉和模式识别技术领域。</td>   <td>1.一种图像特征信息帧内快速划分方法,其特征在于,包括以下步骤：获取训练视频序列,对视频序列提取特征获取训练数据；通过所述训练数据训练支持向量机得到分类器；通过已训练完成的分类器对模式列表进行过滤,获取跳过模式列表；根据所述跳过模式列表,跳过编码模式的尝试过程,进行编码流程；所述获取训练视频序列,对视频序列提取特征获取训练数据这一步骤,包括以下步骤：获取特征数据的灰度共生矩阵；通过Sobel算子获取所述特征数据的梯度和绝对值；使用所述灰度共生矩阵,以及所述梯度和绝对值训练支持向量机,得到分类器；所述分类器包括四叉树结构分类器、垂直结构分类器、二叉树结构分类器和帧内模式分类器；所述通过所述训练数据训练支持向量机得到分类器这一步骤,还包括以下步骤：通过Sobel算子模板对像素矩阵进行卷积计算处理,获取图像的一阶水平梯度矩阵及一阶垂直梯度矩阵；获取垂直和水平灰度共生矩阵对应的垂直矩阵能量值和水平矩阵能量值,垂直矩阵对比度和水平矩阵对比度,垂直矩阵熵和水平矩阵熵,垂直矩阵逆差距和水平矩阵逆差距；获取当前待编码划分块的左方,上方及左上方编码完成块的四叉树划分深度；获取当前待编码划分块的左右区域的像素均值之差及上下区域的第一像素均值差；获取当前待编码划分块在三叉树划分情况下,不同划分区域的第二像素均值差；将所述垂直和水平灰度共生矩阵对应的垂直矩阵能量值和水平矩阵能量值,垂直矩阵对比度和水平矩阵对比度,垂直矩阵熵和水平矩阵熵,垂直矩阵逆差距和水平矩阵逆差距,四叉树划分深度,第一像素均值差,第二像素均值差,作为输入数据,训练所述支持向量机,得到分类器；所述通过已训练完成的分类器对模式列表进行过滤,获取跳过模式列表这一步骤,包括以下步骤：通过四叉树结构分类器获取划分为四叉树结构的第一概率值,若所述第一概率值大于四叉树第一预设概率阈值,则直接进行四叉树的划分；反之,所述第一概率值低于四叉树第二预设概率阈值,则禁止进行四叉树划分的尝试过程；通过垂直结构分类器获取划分为垂直结构的第二概率值,若所述第二概率值大于垂直结构第一预设概率阈值,则禁止水平划分的尝试过程；反之,所述第二概率值小于垂直结构第二预设概率阈值,则禁止垂直划分的尝试过程；通过二叉树结构分类器获取划分为二叉树的第三概率值,若所述第三概率值大于二叉树第一预设概率阈值,则禁止三叉树划分的尝试过程,反之,所述第三概率值小于二叉树第二预设概率阈值,则禁止二叉树划分的尝试过程。</td>   <td>G06V20/40;G06V10/764;G06T7/45;H04N19/11;H04N19/136;H04N19/96</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              刘小慧;              赵山河;              蔡倬;              邬稳;                   朱煜       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>文本分类方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115795030A</td>   <td>2023-03-14</td>   <td>本申请涉及一种文本分类方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取待分类文本,获取目标主题特征词汇表；计算所述待分类文本对应的待分类文本特征向量；获取所述各个候选主题对应的主题特征向量,所述主题特征向量是基于所述候选主题对应的特征词集合计算得到的；计算所述待分类文本特征向量与各个主题特征向量之间的相似度,基于相似度获取所述待分类文本对应的目标主题特征向量；获取所述目标主题特征向量对应的候选主题作为所述待分类文本对应的目标主题。采用本方法能够提高短文本分类的准确度。</td>   <td>1.一种文本分类方法,其特征在于,所述方法包括：获取待分类文本,获取目标主题特征词汇表,所述目标主题特征词汇表中存储了各个候选主题和候选主题对应的特征词集合,一个特征词集合中包括同一个候选主题对应的各个特征词,所述目标主题特征词汇表基于目标领域本体和主题特征词汇表得到,所述目标领域本体用于扩展主题特征词汇表的特征词,所述主题特征词汇表基于训练集得到,所述训练集从历史文本中划分得到；计算所述待分类文本对应的待分类文本特征向量；获取所述各个候选主题对应的主题特征向量,所述主题特征向量是基于所述候选主题对应的特征词集合计算得到的；计算所述待分类文本特征向量与各个主题特征向量之间的相似度,基于相似度获取所述待分类文本对应的目标主题特征向量；获取所述目标主题特征向量对应的候选主题作为所述待分类文本对应的目标主题。</td>   <td>G06F16/35;G06F40/237</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              吴志颖;              赵山河;              尹川学;              郭海旭;              郑子彬;                   张文锋       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>数据挖掘方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115795103A</td>   <td>2023-03-14</td>   <td>本申请涉及一种数据挖掘方法、装置、计算机设备和存储介质。所述方法包括：获取对象资源数据；根据所述对象资源数据构建对象特征图谱；获取所述对象特征图谱中的各个异常节点；分别计算所述各个异常节点与所述对象特征图谱中各个其他节点对应的影响因子；根据所述各个其他节点对应的影响因子确定所述其他节点中的各个目标节点,并根据所述各个目标节点的影响因子生成对应的关联因子；基于所述各个异常节点间的关联路径与所述关联因子融合生成目标信息关联数据,所述目标信息关联数据用于表征各个目标节点与各个异常节点之间的关联关系。采用本方法能够有效提高数据挖掘的准确性。</td>   <td>1.一种数据挖掘方法,其特征在于,所述方法包括：获取对象资源数据；根据所述对象资源数据构建对象特征图谱,所述对象特征图谱用于表征所述对象资源数据中各个节点的节点属性以及各个节点之间的关联路径；获取所述对象特征图谱中的各个异常节点；分别计算所述各个异常节点与所述对象特征图谱中各个其他节点对应的影响因子；根据所述各个其他节点对应的影响因子确定所述其他节点中的各个目标节点,并根据所述各个目标节点的影响因子生成对应的关联因子,所述关联因子用于表征目标节点与对应的异常节点在对应的关联路径下的关联程度；基于所述各个异常节点间的关联路径与所述关联因子融合生成目标信息关联数据,所述目标信息关联数据用于表征各个目标节点与各个异常节点之间的关联关系。</td>   <td>G06F16/901;G06F16/903</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄华威;              叶光;              彭肖文;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于中间人账户激励的区块链交易方法、装置及系统</td>   <td>广东省</td>   <td>CN115797070A</td>   <td>2023-03-14</td>   <td>本发明涉及区块链技术领域,公开了一种基于中间人账户激励的区块链交易方法、装置及系统。本发明的区块链由主链和基于分片机制的侧链构成,侧链通过智能合约与主链桥接,侧链上各分片中的节点仅存储所在分片内的账户状态信息；当需要从第一账户向第二账户转入通证且该两账户所属分片不同时,通过目标中间人账户执行相应跨分片交易,目标中间人账户在完成跨分片交易时得到相应的交易中转服务收益；该目标中间人账户同属于第一分片和所述第二分片,为由目标智能合约验证通过的用于提供交易中转服务的所述侧链上的账户,且转入目标智能合约的通证数量满足预置通证数量条件。本发明实现了侧链上的跨分片交易,能够有效提高区块链的可扩展性。</td>   <td>1.一种基于中间人账户激励的区块链交易方法,其特征在于,区块链由主链和基于分片机制的侧链构成,所述侧链通过智能合约与所述主链桥接,所述侧链上各分片中的节点仅存储所在分片内的账户状态信息,所述方法包括：接收从第一账户向第二账户转入第一目标通证数量的通证的转账指令；所述第一账户和第二账户均为所述侧链上的账户；确定所述第一账户所属的第一分片及所述第二账户所属的第二分片；若所述第一分片和所述第二分片属于不同分片,从各中间人账户中确定目标中间人账户；所述中间人账户为由目标智能合约验证通过的用于提供交易中转服务的所述侧链上的账户,且所述中间人账户转入所述目标智能合约的通证数量满足预置通证数量条件；所述目标中间人账户同属于所述第一分片和所述第二分片；向所述目标中间人账户发送与所述转账指令对应的交易请求,以通过所述目标中间人账户执行与所述交易请求相应的跨分片交易；所述目标中间人账户在完成所述跨分片交易时得到相应的交易中转服务收益。</td>   <td>G06Q40/04;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡茂川;              冯莹莹;              霍子文;              刘丙军;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种历史纸质地图的数字化处理方法及装置</td>   <td>广东省</td>   <td>CN115797415A</td>   <td>2023-03-14</td>   <td>本发明公开了一种历史纸质地图的数字化处理方法及装置,方法包括：对原始纸质地图的栅格图像进行配准处理,以将原始纸质地图匹配到目标投影坐标系中；根据河流主干、建筑物以及山峰顶点对配准处理的结果进行验证,确定配准处理的结果的准确性；将配准处理后的原始纸质地图与土地利用数字化地图进行比较,识别到发生土地利用类型变化的目标区域,得到目标区域的矢量多边形；根据历史资料对矢量多边形进行几何校准处理；对完成几何校准处理的矢量多边形进行格式转换处理；根据格式转换处理的结果,构建历史土地利用数字化地图；对历史土地利用数字化地图进行实时显示,提高了效率和精确度,可广泛应用于图形数字化技术领域。</td>   <td>1.一种历史纸质地图的数字化处理方法,其特征在于,包括：对原始纸质地图的栅格图像进行配准处理,以将所述原始纸质地图匹配到目标投影坐标系中；根据河流主干、建筑物以及山峰顶点对所述配准处理的结果进行验证,确定所述配准处理的结果的准确性；将所述配准处理后的原始纸质地图与土地利用数字化地图进行比较,识别到发生土地利用类型变化的目标区域,得到所述目标区域的矢量多边形；根据历史资料对所述矢量多边形进行几何校准处理；对完成几何校准处理的矢量多边形进行格式转换处理；根据所述格式转换处理的结果,构建历史土地利用数字化地图；对所述历史土地利用数字化地图进行实时显示。</td>   <td>G06T7/30;G06T3/00;G06F16/29;G06F16/56</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡楷欣;              任鹏真;                   梁小丹       </td>   <td>中山大学;中山大学·深圳</td>   <td>一种基于多视图一致性的文本监督语义分割算法</td>   <td>广东省</td>   <td>CN115797639A</td>   <td>2023-03-14</td>   <td>本发明公开了一种基于多视图一致性的文本监督语义分割算法,如下：构建文本监督语义分割模型,包括学生图像编码器、教师图像编码器、文本编码器；将多视图输入学生图像编码器、教师图像编码器进行多视图交叉一致性学习,得到交叉视图一致性损失值；利用学生图像编码器获取多视图的图像编码,结合利用文本编码器获得文本编码进行多视图-文本一致性学习,得到多视图-文本一致性损失值；将交叉视图一致性损失值与多视图-文本一致性损失值相加进行反向传播,训练优化文本监督语义分割模型；完成训练后,利用教师图像编码器和文本编码器进行语义分割,得到语义分割图。本发明克服以往方法存在图文对比歧义性、图文对比过于严格的问题。</td>   <td>1.一种基于多视图一致性的文本监督语义分割算法,其特征在于：所述的算法实现的步骤如下：构建基于多视图一致性的文本监督语义分割模型,所述的文本监督语义分割模型包括学生图像编码器、教师图像编码器以及文本编码器；将训练图像对应的多视图输入学生图像编码器、教师图像编码器进行多视图交叉一致性学习,得到交叉视图一致性损失值；利用学生图像编码器获取训练图像对应的多视图的图像编码,结合利用文本编码器获得文本的文本编码进行多视图-文本一致性学习,得到多视图-文本一致性损失值；将交叉视图一致性损失值与多视图-文本一致性损失值相加,并进行反向传播,从而训练优化文本监督语义分割模型；完成训练后,利用教师图像编码器和文本编码器进行语义分割,从而得到语义分割图。</td>   <td>G06V10/26;G06V10/82;G06V20/70;G06N3/0455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙颖;              冯晨阳;              李超峰;              何仲廉;              何荣;                   潘泽涛       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种生存状态的获取方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN115798737A</td>   <td>2023-03-14</td>   <td>本发明提供了一种生存状态的获取方法、装置、终端设备及存储介质,通过用户输入的患者的身份信息与医疗机构可获得院外公开数据进行比对,能够获得详细的患者的就诊信息,并根据这些就诊信息,进行入院状态查询,并分析查询反馈所得的数据,进行生存状态数据的获取。相比于现有技术,本发明能够避免绝大多数直接与患者或者患者家属沟通,并将常见的数据转化为优质可用的资源,从而进行生存状态数据的自动获取,不仅提高了患者生存状态数据获取的准确性,同时也提高了生存状态数据获取的效率,为医疗诊断相关的研究提供了重要的数据,有利于构建智慧医疗系统。</td>   <td>1.一种生存状态的获取方法,其特征在于,包括：根据用户输入的第一信息,通过院外数据,获得多个患者第一医疗数据；其中,所述第一信息包括所有患者的身份标识；以及每个所述患者第一医疗数据包括患者就诊医院数据以及患者身份信息；根据所述多个患者第一医疗数据,分别进行预设流程的查询操作,根据查询操作的结果,获得多个患者的查询数据；其中,每个所述查询数据包括第一查询数据或第二查询数据；根据所述多个患者的查询数据,当患者的查询数据为第一查询数据时,对每个第一数据进行第一预设值的识别,获得每个第一查询数据对应患者的第一生存状态数据；当患者的查询数据为第二查询数据时,对每个第二数据进行第二预设值的识别,获得每个第二查询数据对应患者的第二生存状态数据；其中,所述第一生存状态数据包括第一生存数据或第一不确定数据；以及所述第二生存状态数据包括第一死亡数据或第二不确定数据；汇总所有所述第一查询数据对应的患者的第一生存状态数据和所有所述第二查询数据对应的患者的第二生存状态数据,输出所述多个患者的院外生存状态数据。</td>   <td>G16H80/00;G16H50/20;G16H10/60;G06F16/2455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;                   陈禹亘       </td>   <td>中山大学</td>   <td>一种基于图卷积网络的偏瘫步态分类方法</td>   <td>广东省</td>   <td>CN111104902B</td>   <td>2023-03-10</td>   <td>本发明公开了一种基于图卷积网络的偏瘫步态分类方法,包括下述步骤：S1、获取待分析的步态数据,对该步态数据进行预处理；S2、基于图卷积网络构建检测网络模型,并训练该网络模型；S3、将步态数据按关节点结构输入训练好的模型中,得到最后一层的卷积结果；S4、获取最后一层的卷积结果,按特征权重比进行缩放；S5、根据得到的特征缩放结果,在全连接层中进行计算,分别得到该目标是健康人和是偏瘫患者的分。本发明利用图卷积神经网络自动提取关节点数据特征,增强了抗噪性能,使得分类速度和分类精度有大幅度提高。</td>   <td>1.一种基于图卷积网络的偏瘫步态分类方法,其特征在于,包括下述步骤：S1、获取待分析的步态数据,对该步态数据进行预处理；S2、基于图卷积网络构建检测网络模型,并训练该网络模型；建立图卷积网络包括：特征邻接矩阵,将输入图像中有联系的特征点连接起来；建立步态图,直接跟步态数据进行矩阵相乘；建立好步态图以后,对每一个节点初始化权重W,对于每一个输入的矩阵H,将矩阵H、图卷积网络G、初始化权重W进行相乘,即可得到每一个节点的特征,在这个过程中,图卷积利用了关节点间的连接信息,能够更好地提取特征,最后得到特征图；训练网络模型的步骤如下：将步态数据输入神经网络,获取分类结果后计算结果与真实值的差距,使用随机梯度下降和反向传播的方法调整网络参数,逐步缩小检测值与真实值的差距；S3、将步态数据按关节点结构输入训练好的模型中,得到最后一层的卷积结果；S4、获取最后一层的卷积结果,按特征权重比进行缩放；S5、根据得到的特征缩放结果,在全连接层中进行计算,分别得到目标是健康人和是偏瘫患者的得分。</td>   <td>G06V40/20;G06V10/774;G06V10/82;G06V10/764;G06N3/0455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              胡康;                   朱智慧       </td>   <td>中山大学</td>   <td>一种基于小样本学习的动作相似度评估方法</td>   <td>广东省</td>   <td>CN109522850B</td>   <td>2023-03-10</td>   <td>本发明公开了一种基于小样本学习的动作相似度评估方法,该方法步骤包括建立数据预处理模型、训练模型、测试模型,采用人体姿态估计模型提取人体整体骨架运动视频以及各关节点位置,排除了背景干扰,并且对人的动作按照关节点位置拆分,设定采样像素值和采样间隔,截取得到包括人体整体骨架运动视频和以各关节点为中心的关节动作的采样视频,采样视频结合了局部信息与全局信息,通过数据预处理后,再使用改写的三元组损失函数进行训练,最后将视频数据映射至余弦空间,计算余弦距离,输出视频中人的动作整体及各个关节相似程度结果。本发明仅用很少的样本就可以学习到一个很好的动作特征映射模型,进而得到一个很好的动作相似度结果。</td>   <td>1.一种基于小样本学习的动作相似度评估方法,其特征在于,包括下述步骤：建立数据预处理模型：采用人体姿态估计模型提取人体整体骨架运动视频以及各关节点位置；设定采样像素值和采样间隔,截取得到采样视频,采样视频包括人体整体骨架运动采样视频和以各关节点为中心的关节动作采样视频；所述采样步骤具体如下所述：将人体整体骨架运动视频缩放像素,采用软间隔采样,得到采样视频；截取以各关节点为中心的关节动作视频并且缩放像素,使用软间隔采样,视频帧数对采样间隔取模值小于1,则将视频帧加入目标视频,所述关节动作视频缩放的像素值与人体整体骨架运动视频相同；所述软间隔采样的采样间隔计算方式如下述公式所述：sample＝t/(fps/25)/36；其中sample为采样间隔,t为视频总帧数,fps为视频帧率；建立训练模型：选取训练数据,确定模板数据、正类数据、负类数据；将模板数据、正类数据、负类数据分别输入到三维卷积神经网络的特征提取器,得到特征图,再经过全连接层的计算分别得到模板特征向量,正类特征向量,负类特征向量；模板特征向量与正类特征向量对应计算出第一余弦距离；模板特征向量与负类特征向量对应计算出第二余弦距离；采用三元组损失函数训练,更新参数后输出训练好的特征提取器；所述第一余弦距离或第二余弦距离的计算公式如下所述：                  其中,cos为计算所得余弦值,取值范围为[0,1],余弦值越接近1,表明夹角越接近于0度,两个特征向量越相似,x-i为模板数据的第i个特征向量,y-i为 正类或负类数据的第i个特征向量；所述采用三元组损失函数计算公式如下所述：                  其中N-i为第i个模板数据动作与第i个负类数据动作计算余弦距离得到的余弦值,P-i为第i个模板数据动作与第i个正类数据动作计算余弦距离得到的余弦值,n＝13,m为两个余弦距离的最小间隔,m取0.9,+表示[]内的值大于零的时候,取该值进行损失计算,否则损失为零；建立测试模型：输入两段待测视频,经过数据预处理模型进行数据预处理；分别输入已经训练好的特征提取器,将得到的特征向量对应计算余弦距离；计算余弦距离的平均值,输出视频中人的动作整体动作的相似度分数。</td>   <td>G06V40/20;G06V10/74;G06V10/774;G06V10/77</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              林楚庭;                   林金城       </td>   <td>中山大学</td>   <td>基于M-CMSE场景识别与E-SFM结合的人群异常行为检测方法</td>   <td>广东省</td>   <td>CN112380936B</td>   <td>2023-03-10</td>   <td>本发明属于人群异常行为检测技术,为基于M-CMSE场景识别与E-SFM结合的人群异常行为检测方法,包括：用基于M-CMSE方法得到场景特征,匹配得出当前场景标签；做前景分割处理得到仅有前景像素点的帧图像；把图像切割成若干个小块,统计每个小块中前景像素点个数,并标记出关键目标块；计算每个关键目标块的速度和方向得到运动特征；根据行人速度、方向,通过E-SFM结合的分析方法,计算出行人的情绪值、社会力,输出帧图像中的异常区域；提取出异常区域中的局部特征,与场景特征、运动特征进行连接构成完整的特征向量I,分类得出异常的分类结果。本发明基于M-CMSE进行场景识别,配合E-SFM结合的异常检测方法,有效提高检测的准确率、稳定性和鲁棒性。</td>   <td>1.基于M-CMSE场景识别与E-SFM结合的人群异常行为检测方法,其特征在于,包括以下步骤：S1、采集视频帧序列前几帧,用基于多尺度空间包络与颜色矩结合的全局特征提取方法,得到场景特征,并匹配运算得出当前场景标签；S2、对输入的视频帧序列做前景分割处理,得到仅有前景像素点的帧图像；S3、输入前景分割处理后的仅有前景像素点的帧图像,设置网格大小,把图像切割成若干个小块,统计每个小块中前景像素点个数,当第i小块的前景像素点超过阈值时标记该块为关键目标块b-i,最终得到每一帧图像的运动目标块集；S4、计算帧图像中每个关键目标块b-i的速度v-i和方向u-i,得到运动特征；S5、根据帧图像中行人的速度、方向,通过情感分析与社会力模型结合分析方法,计算出行人的情绪值,然后计算出行人的社会力,最后输出帧图像中的异常区域；S6、根据帧图像中的异常区域,提取出异常区域中的局部特征,与场景特征、运动特征进行连接构成完整的特征向量I,输入到预先训练好的分类器中进行分类,得出异常的分类结果；步骤S5中情感分析与社会力模型结合分析方法,首先将监控画面划分成同样大小的方格,在方格内考虑行人与行人,行人与障碍物之间的交互关系；然后引入情绪值的计算分析来判断人群中是否发生异常,以行人速度的对数值作为情绪初值,再根据每个行人不同的传播因子,以及取决于性格分类模型的易感因子,从而获取到该行人的情绪值,并结合行人之间的受力分析,得出可能存在异常的区域；步骤S4利用Farneback光流法计算帧图像中每个关键目标块b-i的速度v-i和方向u-i：把每个像素点的邻域用多项式展开来表示,从而对帧图像中每个关键目标块b-i计算得出位移估计值d-i；再引入多尺度位移估计的方法,先从一个较粗的尺度开始,得到一个粗略但合理的位移估计,接着通过逐级细化尺度获得越来越精确的估计；在尺度变换之间对关键目标块进行二次采样,通过二次采样将关键目标块在尺寸和质量上进行压缩,最后通过多帧的运算,获得每个关键目标块的速度v-i和方向u-i；步骤S5将所有的行人划分为两种状态：感染状态和未感染状态；当行人情绪值大于预设阈值时,该行人由未感染状态转变为感染状态,处于感染状态的行人才能够向周围人传递情绪,每一个行人情绪值包括情绪初值以及情绪累计值；对于情绪累计值的计算,以划分的方格为界限,方格中的人互为邻居,处于感染状态的行人向其邻居传染情绪；每个人传播自己情绪的能力用传播因子α来表示,通过方格中的人群数量来计算传播因子α；每个人受到周围情绪的影响用易感因子τ来表示,依据OCEAN性格分类模型对性格进行区分,考虑其中的好奇、友好、消极三种性格因素,计算出行人的易感因子；最终每个人的情绪累计值由他所在方格内的邻居传递出的情绪值乘以易感因子再累加得到；计算每个方格中行人情绪的平均值,将这个平均值作为方格的情绪值；当情绪值大于预设阈值时,判断该方格中可能存在异常行为；最后通过社会力模型计算行人之间的受力情况,分析行人与行人之间的作用力、障碍物与行人之间的作用力都控制在同一个方格内计算,将行人与行人之间的作用力、行人与障碍物之间的作用力合并为交互力,即社会力；以方格中行人的最大社会力作为该方格的社会力,当社会力超过一定阈值时,判断该方格中可能发生异常。</td>   <td>G06V20/52;G06V40/20;G06V20/40;G06V10/26;G06V10/42;G06V10/44;G06V10/56;G06V10/46;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陆遥;              信闫奇;              朱庆堂;              吕璐璐;                   刘小林       </td>   <td>中山大学</td>   <td>一种基于单个深度相机的手部骨架高精度三维重建方法</td>   <td>广东省</td>   <td>CN111429499B</td>   <td>2023-03-10</td>   <td>本发明涉及计算机视觉和计算机图形学技术领域,更具体地,涉及一种基于单个深度相机的手部骨架高精度三维重建方法。一种基于单个深度相机的手部骨架高精度三维重建方法,利用单个深度相机多角度采集手部深度数据和RGB数据,提取RGB图像中的手部骨架关键点并映射到对应的深度数据点,将多角度采集到的精确关键点匹配,同时利用手部骨架拓扑结构校正,得到高精度的手部骨架三维模型。本发明可以解决基于视觉图像序列三维重建方法中受距离、光线以及手部自身遮挡等因素影响下精度不足的问题,能够重建出真实的高精度的手部骨架三维模型。</td>   <td>1.一种基于单个深度相机的手部骨架高精度三维重建方法,其特征在于,包括以下步骤：S1：标定单个深度相机的深度数据、RGB数据内部参数以及多角度的外部位置参数,利用单个深度相机多角度采集手部的深度数据和RGB数据；S2：对各个角度采集到的手部RGB数据分割出该角度下的手部骨架关键点二维图,将二维手部骨架关键点映射到对应的深度数据中,得到该角度下的手部骨架关键点三维结构；S3：利用步骤S1中的多角度外部位置参数,将步骤S2中的各角度下的手部骨架关键点三维结构配准到同一个三维坐标系下,得到初步手部骨架三维模型；S4：利用手部骨架拓扑结构,对步骤S3中得到的初步手部骨架三维模型进行手指中心线校正、手部整体拓扑结构校正,得到高精度的手部骨架三维模型；所述步骤S2具体包括以下步骤：s21：对步骤S1中得到的RGB手部图像数据使用双边滤波进行平滑去噪,得到低噪音并且保持特征的数据；s22：使用深度学习技术训练手部关键点提取模型,分割出步骤s21中RGB图像中的手部关键点二维坐标；s23：将步骤s22中获取手部关键点二维坐标与该RGB图像对应的深度数据对应,获得深度坐标,得到该角度下手部骨架关键点三维结构；所述步骤S3主要包括以下步骤：s31：分析对于各角度下提取的手部骨架关键点,选取2个或2个以上共同看到的关键点；s32：利用步骤S1中设定的相机外部位置参数,结合步骤s31中选取的关键点,固定一个角度,将其它角度下的关键点匹配到固定的角度下的三维坐标系下,得到初步手部骨架三维模型；所述步骤S4主要包括以下步骤：s41：对步骤s32中得到的初步手部骨架三维模型,利用手部拓扑结构,针对手指、手掌部分关键点,将从其他角度配准过来的关键点匹配到同一个手部拓扑结构上；s42：对步骤s41中校正后的手部骨架三维模型,利用手部拓扑结构,整体校正手部骨架三维模型,得到高精度手部骨架三维模型。</td>   <td>G06T7/55;G06T17/00;G06T5/00;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   王晶       </td>   <td>中山大学</td>   <td>基于移动社交网络的数据访问控制策略生成方法</td>   <td>广东省</td>   <td>CN110851852B</td>   <td>2023-03-07</td>   <td>本发明公开一种基于移动社交网络的数据访问控制策略生成方法和属性概率图模型,该属性概率图模型用于实现本方法,本方法包括定义属性概率图模型的数据属性集合、访问者属性集合及访问策略集合,明确数据访问权限,基于数据属性集合A到访问策略集合f(P)的映射关系构建属性概率图模型,其中属性概率图模型的目标函数为访问策略安全性的评估函数,通过属性概率图模型评估数据属性与访问策略间的关联性,求解在数据属性确定的情况下使评测函数F(A',f-k(P))达到最大的访问策略。本发明基于数据所有者及访问者之间的关联,实现MSN访问权限的智能化管理。</td>   <td>1.基于移动社交网络的数据访问控制策略生成方法,其特征在于,包括如下步骤：S10、假设A＝{a-i,0≤i≤n}为数据属性集合,n为数据属性数目,P＝{p-j,0≤j≤m}为访问者属性集合,m为访问者属性数目,f(P)＝{f-k(P)|1≤k≤N}为访问策略集合,f-k(P)为指定访问策略,N为访问策略的数目,明确数据访问权限；S20、基于数据属性集合A到访问策略集合f(P)的映射关系构建属性概率图模型,属性概率图模型的目标函数为访问策略安全性的评估函数其中得到一个子图G′＝G-A',G表示属性概率图,p-(P′,A')表示访问者属性子集在子图G′下的吉布斯分布,表示访问者属性子集P′为访问策略f-k(P)的一个可满足集；S30、通过属性概率图模型评估数据属性与访问策略间的关联性,求解在数据属性确定的情况下使评估函数F[A′,f-k(P)]达到最大的访问策略</td>   <td>G06F21/62;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              林泽炜;              周克涌;              蔡倬;              张鹏;                   林华春       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>信用信息共享方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115757310A</td>   <td>2023-03-07</td>   <td>本申请涉及一种信用信息共享方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取共享对象标识的信用等级变更申请对应的审核结果；所述信用等级变更申请中包括变更信息；基于所述审核结果,获取审核通过的信用等级变更申请对应的确认变更信息,将所述确认变更信息打包成目标区块,基于所述目标区块更新共享区块链得到目标区块链；所述目标区块链用于参与信用信息共享的共享节点验证共享对象标识的信用信息；基于所述确认变更信息,更新目标数据库中所述确认变更信息对应的共享对象标识的信用等级；所述目标数据库用于所述共享节点查询共享对象标识的信用信息。采用本方法能够提高共享信用信息的准确率。</td>   <td>1.一种信用信息共享方法,其特征在于,所述方法包括：获取共享对象标识的信用等级变更申请对应的审核结果；所述信用等级变更申请中包括变更信息；基于所述审核结果,获取审核通过的信用等级变更申请对应的确认变更信息,将所述确认变更信息打包成目标区块,基于所述目标区块更新共享区块链得到目标区块链；所述目标区块链用于参与信用信息共享的共享节点验证共享对象标识的信用信息；基于所述确认变更信息,更新目标数据库中所述确认变更信息对应的共享对象标识的信用等级；所述目标数据库用于所述共享节点查询共享对象标识的信用信息。</td>   <td>G06F16/176;G06F21/62;G06Q30/018;G06Q30/0601</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林瑞玉;              陈官正;                   梁上松       </td>   <td>中山大学</td>   <td>基于知识增强生成式语言模型的问答方法、系统及介质</td>   <td>广东省</td>   <td>CN115759254A</td>   <td>2023-03-07</td>   <td>本发明涉及自然语言处理技术领域,特别涉及一种基于知识增强生成式语言模型的问答方法、系统及介质。本发明的方法通过根据关系划分知识图谱,并针对关系训练知识图谱子模型,使得生成式语言模型能够更多地学习到知识图谱中的关系语义,提高了生成式语言模型的问答能力。同时,本发明的方法在训练掩码建模方法预测实体的过程中,结合了Bart模型的特性,利用对比学习构建损失函数,解决实体预测空间大和多个单词预测难度大的问题,提高了知识增强生成式语言模型的训练效率。</td>   <td>1.一种基于知识增强生成式语言模型的问答方法,其特征在于,包括以下步骤：获取数据,所述数据包括问答数据集和知识图谱数据集；根据关系属性将知识图谱数据集进行划分,并基于划分结果训练多个相互独立的子知识图谱模型,其中,每个子知识图谱模型以Bart模型为基础构建得到；使用Adapter技术将多个子知识图谱模型连接到Bart For Conditional Genration模型中,构建知识图谱增强的生成式语言模型；使用问答数据集训练知识图谱增强的生成式语言模型；将问题输入到训练好的模型,得到问题的答案；其中,在Bart模型的最后一层增加一个用于文本生成任务的语言建模头网络,得到Bart For Conditional Genration模型。</td>   <td>G06N5/022;G06F18/214;G06F18/2113;G06F18/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;                   张易东       </td>   <td>中山大学</td>   <td>一种基于AO算法的碳排放量预测方法、装置及设备</td>   <td>广东省</td>   <td>CN115759346A</td>   <td>2023-03-07</td>   <td>本发明涉及环境科学与机器学习技术领域,公开了一种基于AO算法的碳排放量预测方法、装置及设备。本发明从预置的多个碳排放影响因素中筛选目标影响因素；运用AO算法,优化分数阶灰色预测模型的阶数和支持向量回归预测模型的核心参数,分别训练得到碳排放影响因素预测模型和碳排放量预测模型,基于所述碳排放影响因素预测模型对所述目标影响因素进行预测,得到目标影响因素的预测值,将该预测值作为模型输入,利用所述碳排放量预测模型对碳排放量进行预测。本发明存在可解释性强、客观性强、预测精度高以及适用范围较大的优点,能够为不同地区和行业的碳排放量预测提供较精确的科学依据。</td>   <td>1.一种基于AO算法的碳排放量预测方法,其特征在于,包括：从预置的多个碳排放影响因素中筛选目标影响因素；获取目标影响因素数据,基于所述目标影响因素数据训练分数阶灰色预测模型并运用AO算法优化所述分数阶灰色预测模型的阶数,得到碳排放影响因素预测模型；基于所述碳排放影响因素预测模型对所述目标影响因素进行预测,得到目标影响因素的预测值；获取碳排放量及对应影响因素的历史数据,根据所述历史数据构建训练样本数据集,基于所述训练样本数据集训练支持向量回归预测模型并运用AO算法优化所述支持向量回归预测模型的参数,得到碳排放量预测模型,所述参数包括惩罚系数和/或核函数参数；将所述目标影响因素的预测值作为模型输入,利用所述碳排放量预测模型对碳排放量进行预测；其中,所述AO算法将安康鱼在深海中随机游走觅食的过程模拟为全局寻优的过程,基于莱维飞行进行全局寻优,并将搜索种群分为雌鱼和雄鱼两大群体,按照安康鱼觅食和交配行为进行局部寻优,以得到最优解。</td>   <td>G06Q10/04;G06Q50/26;G06N20/10;G06N3/006;G06F17/18;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              林凯欣;              吴志颖;              黄宝莹;              付齐双;              杨晗;                   郑子彬       </td>   <td>中山大学</td>   <td>交易数据的获取方法、装置、存储介质及计算机设备</td>   <td>广东省</td>   <td>CN115760413A</td>   <td>2023-03-07</td>   <td>本申请提供的交易数据的获取方法,包括：当接收到数据获取请求时,获取数据获取请求中包含的区块号范围；若区块号范围不为空,生成区块号范围内每个区块对应的交易数据获取请求；将交易数据获取请求添加至请求队列；根据预设排序策略,对请求队列的交易数据获取请求进行排序；基于排序后的请求队列,依次将请求队列的交易数据获取请求发送至处于空闲状态的工作线程；获取第一交易数据；根据第一交易数据的数据类型,确定与数据类型对应的目标管道；将第一交易数据存储到目标管道,对目标管道的第一交易数据进行排序,并将经过排序的第一交易数据存储到图数据库。应用本申请提供的方法,能够快速、有序地获取区块链交易数据,提高数据获取的效率。</td>   <td>1.一种交易数据的获取方法,其特征在于,所述方法应用于服务端,包括：当接收到数据获取请求时,获取所述数据获取请求中包含的区块号范围；其中,所述区块号范围包括起始区块号和结束区块号；若所述起始区块号和所述结束区块号均不为空,生成所述区块号范围内每个区块对应的各个交易数据获取请求；将各个所述交易数据获取请求添加至请求队列中；根据预设排序策略,对所述请求队列中的各个所述交易数据获取请求进行排序；基于经过排序后的请求队列,依次将所述请求队列中的所述交易数据获取请求发送至处于空闲状态的工作线程；获取第一交易数据；其中,所述第一交易数据为所述工作线程接收到所述交易数据获取请求时,调用接口获取的该交易数据获取请求对应区块中的对应数据；根据所述第一交易数据的数据类型,确定与所述数据类型对应的目标管道；将所述第一交易数据存储到所述目标管道中,对所述目标管道中的各个所述第一交易数据进行排序,并将经过排序的所述第一交易数据存储到图数据库中。</td>   <td>G06Q40/04;G06F16/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨炜俊;              毛庆国;              梁常德;              蔡铭;                   王理民       </td>   <td>中山大学;深圳市生态环境智能管控中心</td>   <td>基于兴趣点数据的声环境功能区噪声超标限值调整方法</td>   <td>广东省</td>   <td>CN115760515A</td>   <td>2023-03-07</td>   <td>本发明公开了一种基于兴趣点数据的声环境功能区噪声超标限值调整方法,包括：按城市声环境功能区的定义,对兴趣点数据进行类别划分,使兴趣点匹配到各类声环境功能区；以4a类和4b类声环境功能区为边界对城市区域进行划分,将城市区域划分成多个小区域,根据小区域内各类型兴趣点的数量比例,计算该区域的噪声超标限值偏移量；根据声环境功能区原有的噪声超标限值标准及噪声超标限值偏移量,计算修正后的声环境功能区噪声超标限值。本发明能够利用兴趣点数据反映当前城市的土地利用情况,并根据各个区域用地的不同对其环境噪声超标限值进行调整,有助于提升城市声环境质量的管理水平。本发明可广泛应用于环境噪声控制与治理领域。</td>   <td>1.一种基于兴趣点数据的声环境功能区噪声超标限值调整方法,其特征在于,包括以下步骤：按城市声环境功能区的定义,对兴趣点数据进行类别划分,使兴趣点匹配到各类声环境功能区；以4a类和4b类声环境功能区为边界对城市区域进行划分,将城市区域划分成多个小区域,根据小区域内各类型兴趣点的数量比例,计算该区域的噪声超标限值偏移量；根据声环境功能区原有的噪声超标限值标准及噪声超标限值偏移量,计算修正后的声环境功能区噪声超标限值。</td>   <td>G06Q50/26;G06F17/18;G06F16/9537;G06F16/29</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              詹丹丹;                   吴嘉豪       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种针对不规则孔洞的多模态人脸图像修复方法和系统</td>   <td>广东省</td>   <td>CN115760646A</td>   <td>2023-03-07</td>   <td>本发明公开了一种针对不规则孔洞的多模态人脸图像修复方法和系统,包括获取待修复人脸图像对应的隐藏表示信息,使用多个多尺度多级跳接融合模块依次接续对隐藏表示信息进行处理,获得图像特征信息,获取待修复人脸图像对应的文本特征信息,使用多模态特征融合模块根据文本特征信息对图像特征信息进行调整,获得多模态融合特征信息等步骤。本发明使用多模态特征融合模块来调整图像特征,获得多模态融合特征信息,使用多尺度多级跳接融合模块来提高对图像特征的利用率；受益于这两个模块,本发明能够在人脸图像的不规则受损区域内生成视觉上逼真、语义上合理的具有精细纹理的内容,减少伪影或者模糊等瑕疵。本发明广泛应用于图像处理技术领域。</td>   <td>1.一种针对不规则孔洞的多模态人脸图像修复方法,其特征在于,所述针对不规则孔洞的多模态人脸图像修复方法包括：获取待修复人脸图像；获取所述待修复人脸图像对应的隐藏表示信息；使用多个多尺度多级跳接融合模块,依次接续对所述隐藏表示信息进行处理,获得图像特征信息；获取所述待修复人脸图像对应的文本特征信息；使用多模态特征融合模块,根据所述文本特征信息对所述图像特征信息进行调整,获得多模态融合特征信息；对所述多模态融合特征信息依次进行反卷积和卷积处理,获得重建人脸图像。</td>   <td>G06T5/00;G06T5/50;G06N3/0442;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林俊忠;              周健;              彭健宏;              蔡培强;              谢传淼;                   潘志忠       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种用于结直肠癌肝转移瘤识别的小目标分割方法</td>   <td>广东省</td>   <td>CN115760781A</td>   <td>2023-03-07</td>   <td>本发明公开了一种用于结直肠癌肝转移瘤识别的小目标分割方法,方法包括：用卷积提取肝转移瘤医学图像的视觉特征表示,用最大池化对视觉特征进行下采样处理；进行深度特征编码处理；将深度特征编码处理的最后编码特征送入多尺度注意力模块处理后,将深度特征编码处理的中间编码特征送入层级信息交融模块处理,得到第一特征；将第一特征与对应的解码特征进行跳跃连接操作,得到第二特征；用转置卷积对第二特征进行上采样操作；进行连续解码,得到第三特征；用1×1卷积压缩通道用Sigmoid对第三特征激活得到预测图。本发明提高了分割预测的准确率,并提高了编码和解码之间的兼容性,可广泛应用于计算机技术领域。</td>   <td>1.一种用于结直肠癌肝转移瘤识别的小目标分割方法,其特征在于,包括：用卷积提取肝转移瘤医学图像的视觉特征表示,用最大池化对所述视觉特征进行下采样处理；重复进行所述卷积提取和所述下采样处理后,进行深度特征编码处理；将所述深度特征编码处理的最后编码特征送入多尺度注意力模块处理后,将所述深度特征编码处理的中间编码特征送入层级信息交融模块处理,得到第一特征；将所述第一特征与对应的解码特征进行跳跃连接操作,得到第二特征；用转置卷积对所述第二特征进行上采样操作；重复进行所述跳跃连接操作和所述上采样操作后,通过连续解码得到第三特征；用1×1卷积压缩通道用Sigmoid对所述第三特征激活得到预测图。</td>   <td>G06T7/00;G06T7/11;G06T5/30;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         古博;              林敏;              陈柔柔;              牛宁杰;              李倩欣;                   聂苏程       </td>   <td>中山大学</td>   <td>一种基于视触觉进行加工元件表面凹陷的定位方法</td>   <td>广东省</td>   <td>CN115760805A</td>   <td>2023-03-07</td>   <td>本发明公开了一种基于视触觉进行加工元件表面凹陷的定位方法、装置、电子设备及存储介质,方法具体包括：获取加工元件表面所在的工作面的区域图像对比度,根据区域图像对比度选择视触觉定位法或者触觉定位法,通过触觉传感器获取加工元件表面的特征量后进行定位计算,确定加工元件表面的凹陷信息。本发明解决了在光照条件不佳而无法获得元件表面图像的情况下的凹陷定位问题,通过触觉传感器,还能有效区分微弱信号,获得更精确的定位,降低检测的故障率；本发明的实施例采用机器检测也可以减少人力资源的消耗,检测结果也不会受个人主观因素影响,可广泛应用于表面缺陷定位技术领域。</td>   <td>1.一种基于视触觉进行加工元件表面凹陷的定位方法,其特征在于,包括：获取加工元件表面所在的工作面的光照信息,根据所述光照信息确定所述加工元件表面的区域图像对比度；根据所述加工元件表面的区域图像对比度,选择视触觉定位法或触觉定位法；通过触觉传感器获取所述加工元件表面的特征量,对所述特征量进行定位计算,确定所述加工元件表面的凹陷信息。</td>   <td>G06T7/00;G06T7/136;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴晓航;              林浩添;              谢佩辰;              刘少鹏;                   洪佳明       </td>   <td>中山大学中山眼科中心</td>   <td>一种裂隙灯图像质量检测方法</td>   <td>广东省</td>   <td>CN115760806A</td>   <td>2023-03-07</td>   <td>本发明公开了一种裂隙灯图像质量检测方法。该方法采用图像质量过滤器对实时拍摄的弥散光图像进行图像质量检测,当检测为不合格时,通过实时指导反馈系统对所述弥散光图像进行图像质量分析,并根据图像质量分析结果生成重新拍摄的操作指导；当所述弥散光图像的检测结果为合格时,检测所述弥散光图像是否满足裂隙光图像和红反光图像的拍摄条件；若满足则进行裂隙光图像拍摄和红反光图像拍摄,若不满足则结束拍摄并输出拍摄结果；通过所述实时指导反馈系统对不合格的裂隙光图像和红反光图像进行图像质量分析,并根据图像质量分析结果生成重新拍摄的操作指导。本发明技术方案提高了对临床裂隙灯图像的采集质量和效率。</td>   <td>1.一种裂隙灯图像质量检测方法,其特征在于,包括以下步骤：采用图像质量过滤器对实时拍摄的弥散光图像进行图像质量检测,当检测为不合格时,通过实时指导反馈系统对所述弥散光图像进行图像质量分析,并根据图像质量分析结果生成重新拍摄的操作指导；当所述弥散光图像的检测结果为合格时,检测所述弥散光图像是否满足裂隙光图像的拍摄条件；若满足则进行裂隙光图像拍摄,若不满足则结束拍摄并输出拍摄结果；当检测所述弥散光图像的检测结果为合格时,检测所述弥散光图像是否满足红反光图像的拍摄条件；若满足则进行红反光图像拍摄,若不满足则结束拍摄并输出拍摄结果；采用图像质量过滤器对拍摄的所述裂隙光图像和红反光图像进行图像质量检测,当检测为不合格时,通过所述实时指导反馈系统对所述裂隙光图像和红反光图像进行图像质量分析,并根据图像质量分析结果生成重新拍摄的操作指导。</td>   <td>G06T7/00;G06V10/764;G06V10/82;G06V10/774;G06N3/08;G06N3/0464;A61B3/135;A61B3/00;A61B3/15</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁北辰;              樊天慧;              黄庆庆;              冯国栋;                   陈超核       </td>   <td>中山大学;华南理工大学</td>   <td>一种水下机器人作业环境与状态的评估方法</td>   <td>广东省</td>   <td>CN115761464A</td>   <td>2023-03-07</td>   <td>本发明公开了一种水下机器人作业环境与状态的评估方法,方法包括：通过水下相机实时获取周围环境信息；对所述周围环境信息进行视频流分解,获取逐帧图像；对所述逐帧图像进行图像增强处理,确定每帧图像中的目标物；对所述目标物进行识别,确定每帧图像中的目标物的初步空间状态；获取任意相邻帧的图像中的目标物的初始空间状态,采用均值法对所述初步空间状态进行优化处理,得到每个目标物的最终空间状态。本发明能够提高图像对比度和清晰度,获取水下工作环境信息,可广泛应用于计算机技术领域。</td>   <td>1.一种水下机器人作业环境与状态的评估方法,其特征在于,包括：通过水下相机实时获取周围环境信息；对所述周围环境信息进行视频流分解,获取逐帧图像；对所述逐帧图像进行图像增强处理,确定每帧图像中的目标物；对所述目标物进行识别,确定每帧图像中的目标物的初步空间状态；获取任意相邻帧的图像中的目标物的初始空间状态,采用均值法对所述初步空间状态进行优化处理,得到每个目标物的最终空间状态。</td>   <td>G06V20/05;G06V20/40;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁北辰;              樊天慧;              刁琪;              冯国栋;                   陈超核       </td>   <td>中山大学;华南理工大学</td>   <td>一种基于压缩与激励网络的水下图像处理方法</td>   <td>广东省</td>   <td>CN115761469A</td>   <td>2023-03-07</td>   <td>本发明公开了一种基于压缩与激励网络的水下图像处理方法,方法包括：采集水下机器人周边的水下视觉图像；对所述水下视觉图像进行预处理,得到训练数据集；根据所述训练数据集,对基于压缩激励网络搭建的学习模型进行训练,得到目标模型；将水下机器人作业时采集到的目标水下图像输入到训练好的目标模型中,得到对所述目标水下图像的识别结果,确定所述水下机器人周边的水下环境状况。本发明提高了准确率和效率,可广泛应用于图像处理技术领域。</td>   <td>1.一种基于压缩与激励网络的水下图像处理方法,其特征在于,包括：采集水下机器人周边的水下视觉图像；对所述水下视觉图像进行预处理,得到训练数据集；根据所述训练数据集,对基于压缩激励网络搭建的学习模型进行训练,得到目标模型；将水下机器人作业时采集到的目标水下图像输入到训练好的目标模型中,得到对所述目标水下图像的识别结果,确定所述水下机器人周边的水下环境状况。</td>   <td>G06V20/05;G06V10/774;G06V10/82;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建芳;              林子杭;              谭超镭;              郑伟诗;                   王军       </td>   <td>之江实验室;中山大学</td>   <td>基于边框标注的弱监督视频目标分割方法及装置</td>   <td>浙江省</td>   <td>CN115761574A</td>   <td>2023-03-07</td>   <td>本发明公开了一种基于边框标注的弱监督视频目标分割方法及装置,方法包括下述步骤：在图像分割数据集上训练基于PReMVOS模型的伪标注生成模型；使用伪标注生成模型对视频数据和边框标注逐帧生成对应的伪掩模标注；利用生成的伪掩模标注,使用“合作教学”算法训练视频目标分割模型。本方法使用低代价的边框标注训练视频目标分割模型,从而降低视频目标分割模型迁移到实际应用场景时对新数据进行标注的代价,降低视频目标分割模型的落地难度；通过使用“合作教学”的训练算法,可以更充分地利用现有的大量视频目标跟踪数据集来训练视频目标分割模型,增强视频目标分割模型的性能和泛化能力。</td>   <td>1.基于边框标注的弱监督视频目标分割方法,其特征在于,包括下述步骤：在图像分割数据集上训练基于PReMVOS模型的伪标注生成模型,所述伪标注生成模型的输入为原始视频及对应的边框标注,输出为伪掩模标注；使用伪标注生成模型对视频数据和边框标注逐帧生成对应的伪掩模标注；利用生成的伪掩模标注,使用“合作教学”算法训练视频目标分割模型,利用训练好的视频目标分割模型对视频数据进行目标分割,得到目标分割结果；所述“合作教学”算法是将两个结构相同参数不同的网络在训练阶段的每次迭代中,分别为对方筛选出较干净的数据以供对方训练,缓解噪声标注的影响。</td>   <td>G06V20/40;G06V20/70;G06V10/82;G06N3/04;G06N3/0895;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              刘怡初;                   娄旭磊       </td>   <td>中山大学</td>   <td>基于车牌信息联合的车辆重识别方法</td>   <td>广东省</td>   <td>CN115761663A</td>   <td>2023-03-07</td>   <td>本发明提供的基于车牌信息联合的车辆重识别方法,方法包括以下步骤：获取目标图像；获取目标图像中的待识别车辆图像,进行全局特征提取得到外观特征信息；对目标图像中的待识别车辆进行车牌区域提取,将车牌区域进行对齐转换,得到车牌图像；根据车牌图像进行特征提取,得到车牌特征信息；对外观特征信息以及车牌特征信息进行加权融合,根据加权融合结果确定目标车辆；方法将车牌信息引入到车辆重识别网络中,以提高车辆的可辨别性；另外,方法对车辆外观特征和车牌特征并行提取,经过融合模块得到最后结果,避免渐进式搜索框架中由于车牌匹配失败带来的误差,对于开放场景下车牌模糊的情况也具有鲁棒性可广泛应用于计算机视觉技术领域。</td>   <td>1.基于车牌信息联合的车辆重识别方法,其特征在于,包括以下步骤：获取目标图像；获取所述目标图像中的待识别车辆图像,进行全局特征提取得到外观特征信息；对所述目标图像中的所述待识别车辆进行车牌区域提取,将所述车牌区域进行对齐转换,得到车牌图像；根据所述车牌图像进行特征提取,得到车牌特征信息；对所述外观特征信息以及所述车牌特征信息进行加权融合,根据加权融合结果确定目标车辆。</td>   <td>G06V20/56;G06V20/62;G06V10/82;G06V10/80;G06V10/42;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   张权       </td>   <td>中山大学</td>   <td>基于不确定性二阶自注意力结构模型的小股行人重识别方法</td>   <td>广东省</td>   <td>CN115761795A</td>   <td>2023-03-07</td>   <td>本发明针对现有技术的局限性,提出了一种基于不确定性二阶自注意力结构模型的小股行人重识别方法,基于有限样本,通过模拟成员和布局的变化来挖掘趋于无限的群组结构。成员不确定性将组内成员的数量作为一个截断的高斯分布,而不是一个固定的值,然后通过动态抽样来模拟成员的变化。布局不确定性构造了关于成员位置的随机仿射变换,以扩大训练集中的固定方案。本发明提出了二阶不确定性自注意力结构模型(UMSOT),它提取一阶token作为每个成员的特征,然后根据上述所有一阶token学习一个二阶token作为组特征。UMSOT利用自注意力模型的结构优势,实现了布局特征的显式建模和与外观建模的集成。在CSG、SYSUGroup、RoadGroup和iLIDS-MCTS 4个数据集上的综合实验充分证明了该方法的优越性。</td>   <td>1.一种基于不确定性二阶自注意力结构模型的小股行人重识别方法,其特征在于,包括以下步骤：S1,获取待识别图像；S2,获取所述待识别图像输入由不确定性二阶自注意力结构模型训练获得的小股行人重识别器中,获得识别结果；其中,所述不确定性二阶自注意力结构模型中的特征提取阶段包括成员特征提取以及群组特征提取；在成员特征提取的阶段,以视觉自注意力模型作为提取器,提取成员表观特征；在群组特征提取的阶段,通过进行不确定性建模,整体考虑关系建模与表观建模,从而提取完整的群组判别性特征；在训练过程中,同时对群体的身份类别和逐个成员的身份类别向所述不确定性二阶自注意力结构模型提供有监督训练约束,以交叉熵损失函数、困难三元组损失函数之和达到最小化为目标进行优化。</td>   <td>G06V40/10;G06V10/764;G06V10/77;G06V10/82;G06N3/0464;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁紫旭;              陈灿;              王辉;              李康顺;              曹务腾;              吴志杰;              蔡建;              王文祥;              蔡宗禄;              刘铎;              邝颖仪;              王盛宇;                   邵碧艳       </td>   <td>中山大学附属第六医院;华南农业大学</td>   <td>结直肠癌CRS根治程度预测模型的训练、使用方法及系统</td>   <td>广东省</td>   <td>CN115762748A</td>   <td>2023-03-07</td>   <td>本发明提供结直肠癌CRS根治程度预测模型的训练、使用方法及系统,包括：获取结直肠癌病例的病历数据；对每个结直肠癌病例的腹膜转移相关指标进行筛选,得到第一训练集；将第一训练集输入到第一深度学习模型进行训练；将每个结直肠癌病例的CT图像作为第二训练集输入第二深度学习模型进行训练；将每个结直肠癌病例对应的第一特征向量和第二特征向量进行拼接得到第三特征向量集；将第三特征向量集划分为训练集和验证集；将训练集输入第三深度学习模型训练,得到收敛的第三深度学习模型；将验证集输入收敛的第三深度学习模型进行验证,根据验证结果进行优化。本发明融合多模态特征预测,能有效地对结直肠癌CRS根治程度进行评分。</td>   <td>1.一种结直肠癌CRS根治程度预测模型的训练方法,其特征在于,包括：获取结直肠癌病例的病历数据,病历数据包括CT图像和腹膜转移相关指标；对每个结直肠癌病例的腹膜转移相关指标进行筛选,得到第一训练集；将第一训练集输入到第一深度学习模型进行训练,得到收敛的第一深度学习模型和输出的第一特征向量集；将每个结直肠癌病例的CT图像作为第二训练集输入第二深度学习模型进行训练,得到收敛的第二深度学习模型和输出的第二特征向量集；将每个结直肠癌病例对应的第一特征向量和第二特征向量进行拼接得到第三特征向量集；将第三特征向量集划分为训练集和验证集；将训练集输入第三深度学习模型训练,得到收敛的第三深度学习模型；将验证集输入收敛的第三深度学习模型进行验证,根据验证结果进行优化。</td>   <td>G16H50/20;G06N3/0464;G06N3/084;G06T7/00;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘子锋;              卢娅欣;              彭福华;              刘君宇;              杨钦泰;              银琳;                   凌翔       </td>   <td>中山大学附属第三医院</td>   <td>一种HIV阴性隐球菌脑膜炎治疗结局预测模型及其构建方法</td>   <td>广东省</td>   <td>CN115762764A</td>   <td>2023-03-07</td>   <td>本发明提供了一种HIV阴性隐球菌脑膜炎治疗结局预测模型及其构建方法,属于生物技术领域。本发明基于HIV阴性隐球菌脑膜炎患者的多维度数据所构建的治疗结局预测模型,故可以此建立精准预测HIV阴性隐球菌脑膜炎患者治疗效果的在线开放式平台,临床医生可通过输入患者当前的8个预测指标数值,迅速获取患者疗效好坏的预测概率及患者的高低风险分层,便于辅助临床决策,为患者及时提供个性化治疗方案。</td>   <td>1.一种HIV阴性隐球菌脑膜炎治疗结局预测模型的构建方法,其特征在于,包括以下步骤：S1、收集HIV阴性隐球菌脑膜炎患者临床数据作为候选特征数据变量；S2、以HIV阴性隐球菌脑膜炎患者抗真菌治疗后10周的治疗效果为隐球菌脑膜炎患者的治疗结局；S3、对候选特征数据进行数据分析处理；S4、使用最小绝对收缩选择算子筛选得到最优特征数据变量；S5、采用随机森林、极端梯度提升树、逻辑回归、高斯朴素贝叶斯、K邻近和多层感知机机器学习模型对训练集进行模型构建；S6、通过内部验证和综合评价筛选出最优模型。</td>   <td>G16H50/20;G06F18/24;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         覃海德;              阮红莲;              裴璐;              杨美华;                   黄龙       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种基于lncRNA的优化模型预测膀胱癌患者生存预后的方法</td>   <td>广东省</td>   <td>CN115762792A</td>   <td>2023-03-07</td>   <td>本发明涉及膀胱癌预测技术领域,且公开了一种基于lncRNA的优化模型预测膀胱癌患者生存预后的方法,包括以下步骤：S1：数据收集和预处理,使用FPKM数据分析来自TCGA的膀胱癌lncRNA数据,使用RSEM归一化计数类数据和进一步的log2转换表达矩阵分析来自TCGALevel3的mRNA数据,TCGA临床数据采用校正的表型数据,对数据进行预处理,通过质量控制、归一化和转换,以获得统一的表达矩阵。在研究中,数据不完整或数据缺失通常是限制模型应用的常见问题,本发明的模型在相对完整的数据基础之上构建,这使得能够在多个维度对生存进行预测,模型表现会更加稳定。</td>   <td>1.一种基于lncRNA的优化模型预测膀胱癌患者生存预后的方法,其特征在于,包括以下步骤：S1：数据收集和预处理使用FPKM数据分析来自TCGA的膀胱癌lncRNA数据,使用RSEM归一化计数类数据和进一步的log2转换表达矩阵,分析来自TCGA Level 3的mRNA数据,TCGA临床数据采用校正的表型数据,对数据进行预处理,通过质量控制、归一化和转换,以获得统一的表达矩阵；S2：统计分析将纳入分析的394例患者按7:3的比例随机分为训练集和验证集,首先使用训练集中的数据寻找独立预后因素,采用lasso回归与逐步法对变量进一步降维构建多变量Cox风险模型,然后将模型应用于验证队列以评估预测模型的特异性、敏感度及临床有效性。对于模型的优化,对给定的肿瘤微环境相关基因表达标签在mRNA数据集中构建模型,计算风险分值,用来优化融合模型,融合与优化之后的模型用列线图展示,模型预测价值及临床有效性的评估分别采用受试者工作特性曲线和决策曲线分析；S3：框架设计和数据预处理经过数据预处理及lasso降维筛选后,构建lncRNA预后预测模型,随后,把影响膀胱癌预后的临床风险因素纳入模型中,包括T分期、N分期及肿瘤分级这些具有临床意义的指标,以构建临床因素-lncRNA复合模型,然后再基于微环境中肿瘤相关成纤维细胞间质细胞(CAF)特异表达标签,连同免疫细胞亚群细胞信息,分别计算风险分值,作为优化变量对临床因素-lncRNA复合模型进行优化,再把这个优化的模型与已经发表的、肿瘤相关的lncRNA模型进行比较；S4：基于lncRNA预后预测模型的构建采用lasso算法和多元Cox回归分析相结合的方法,获得一个包含12个分子的lncRNA模型,ROC曲线表明,lncRNA模型在预测膀胱癌预后方面表现良好,训练数据集5年的生存预测的AUC为0.894,利用该模型计算的风险分值可把患者区分为显著差异的两类,高风险分值相比于低风险分值的患者,死亡风险增加了7.5倍,验证数据集5年生存预测的AUC为0.755,高风险分值患者死亡风险是低风险分值患者的2.7倍；S5：基于lncRNA模型与临床风险因素的整合整合入临床风险因素,包括膀胱癌T分期、N分期、肿瘤分级,构建临床风险因素-lncRNA复合模型,单独的临床风险因素模型和单独lncRNA模型,对膀胱癌的预后预测表现良好,但表现尚未达到优的级别,在验证集中临床风险因素模型5年生存预测的AUC为0.774,lncRNA模型的AUC为0.764,相比之下,lncRNA模型融合进入临床风险因素后(临床风险因素-lncRNA复合模型)在验证集中5年生存预测的AUC为0.882,模型表现达到优的级别,lncRNA与临床风险因素的结合构建的融合模型,可大大提高预测模型的性能；S6：肿瘤微环境间质细胞特征基因和免疫细胞亚群对膀胱癌预后预测作用我们对间质细胞的特征基因表达标签构建模型,计算风险分值并整合入lncRNA模型中。结果表明,间质细胞的特征基因表达风险分值可提高模型的性能。在验证数据集中,5年生存的预后预测AUC为0.789。采用CYBERSORT从mRNA数据经反卷积计算得到的免疫细胞组分的研究表明,单独的免疫细胞组分可以预测膀胱癌的预后,然后计算免疫细胞成分风险分值并整合入lncRNA-CAF复合模型中,结果表明,lncRNA-CAF-Immune复合模型的表现在训练集中的表现优异(5年生存预测的AUC＝0.924),复合模型在验证集中5年生存的预测价值同样优于单纯的lncRNA模型(AUC＝0.787)；S7：优化的lncRNA融合模型预测膀胱癌患者预后的表现结合多维生物学信息的预测模型可能会提高预测性能,由此建立了一个以lncRNA模型为骨架,融合入临床风险因素、肿瘤微环境的间质细胞/免疫细胞亚型基因表达信息的融合模型,结果表明,融合模型的ROC曲线在训练集与验证数据集中均表现优异,在验证数据集中,5年生存的预后预测AUC为0.913；S8：优化的lncRNA融合模型的临床应用探索基于构建的融合模型,绘制列线图。该列线图直观展示了优化的融合模型中可行性最高的lncRNA标记,CAF风险评分,Immune风险分值以及临床风险因素对生成预后的影响。另外,我们绘制的DCA曲线表明,我们构建的融合模型具有临床应用价值。</td>   <td>G16H50/30;G16H50/50;G16H50/70;G16H50/20;G16B5/00;G16B40/00;G06F18/214;G06F18/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              刘文阁;              林帅;              刘亚飞;              赵瑞辉;              郑冶枫;                   王巨宏       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>一种数据处理方法、设备以及可读存储介质</td>   <td>广东省</td>   <td>CN115730050A</td>   <td>2023-03-03</td>   <td>本申请公开了一种数据处理方法、设备以及可读存储介质,方法包括：获取目标对象对应的对象类别状态,以及目标对象在对象类别状态下所呈现的对象状态属性；在关系图的类别状态节点中确定对象类别状态所指示的目标类别状态节点,在与目标类别状态节点具有关联关系的状态属性节点中,确定对象状态属性所指示的目标状态属性节点；根据目标类别状态节点与目标状态属性节点分别对应的向量表达特征,对关系图进行更新,得到目标关系图；根据目标关系图中每个类别节点分别对应的更新向量表达特征,在目标关系图的类别节点中获取预测类别节点,将预测类别节点所指示的类别信息确定为目标对象的预测类别结果。采用本申请,可以提高对象类别的识别准确率。</td>   <td>1.一种数据处理方法,其特征在于,包括：获取目标对象对应的对象类别状态,以及所述目标对象在所述对象类别状态下所呈现的对象状态属性；获取关系图；所述关系图包含类别节点、类别状态节点、状态属性节点之间的关联关系；在所述类别状态节点中确定所述对象类别状态所指示的目标类别状态节点,在与所述目标类别状态节点具有关联关系的状态属性节点中,确定所述对象状态属性所指示的目标状态属性节点；根据所述目标类别状态节点与所述目标状态属性节点分别对应的向量表达特征,对所述关系图进行更新,得到目标关系图；根据所述目标关系图中每个类别节点分别对应的更新向量表达特征,在所述目标关系图的类别节点中获取预测类别节点,将所述预测类别节点所指示的类别信息确定为所述目标对象的预测类别结果。</td>   <td>G06F16/332;G06F16/33;G06F16/335;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘晔;              肖童;                   张弦       </td>   <td>中山大学</td>   <td>基于终端信令数据的工作日设施可达性计算方法及装置</td>   <td>广东省</td>   <td>CN115730763A</td>   <td>2023-03-03</td>   <td>本发明公开了一种基于终端信令数据的工作日设施可达性计算方法及装置,所述方法包括：在预设时长内获取信令数据集后,根据信令数据集将统计区域内在工作日期间使用设施的潜在用户划分为若干种通勤类型人口群体,通勤类型人口群体包括非通勤类型人口群体、流入通勤类型人口群体和流出通勤类型人口群体；分别计算每种通勤类型人口群体分别对应的设施可达性值,并依据若干个设施可达性值计算统计区域内用户对目标设施的总体可达性值。本发明基于终端信令数据划分用户的通勤类型,根据不同通勤类型分别计算设施可达性,最后集合不同类型的可达性计算设施的总体可达性,从而贴合用户的实际出行情况,减少计算误差,提高计算的准确率。</td>   <td>1.一种基于终端信令数据的工作日设施可达性计算方法,其特征在于,所述方法包括：在预设时长内获取信令数据集后,根据所述信令数据集将统计区域内在工作日期间使用设施的潜在用户划分为若干种通勤类型人口群体,所述通勤类型人口群体包括非通勤类型人口群体、流入通勤类型人口群体和流出通勤类型人口群体；分别计算统计区域内每种所述通勤类型人口群体分别对应的设施可达性值,并依据若干个所述设施可达性值计算目标设施的总体可达性值。</td>   <td>G06Q10/063;G06Q50/26;G06F16/2458;G06F16/29;G16Y10/65;G16Y20/10;G16Y20/40;G16Y40/10;G16Y40/20;G16Y40/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张晓飞;              谭晓军;              范正平;              陈泽松;                   安亚松       </td>   <td>中山大学</td>   <td>一种基于时空自适应注意力的3D多目标跟踪方法</td>   <td>广东省</td>   <td>CN115731267A</td>   <td>2023-03-03</td>   <td>本发明公开了一种基于时空自适应注意力的3D多目标跟踪方法,方法包括：获取目标场景下的2D多源数据和3D多源数据,对2D多源数据进行图像特征提取,获取图像特征,并对3D多源数据进行点云特征提取,获取点云特征；将所述图像特征和所述点云特征进行特征融合,得到融合特征；根据所述融合特征确定目标场景内每个对象的检测状态；根据所述检测状态,提取检测对象和预测对象之间的协作特征；根据所述协作特征对目标场景内的对象检测和跟踪状态进行实时更新。本发明能够有效地获得更好的跟踪性能并减少推理时间,可广泛应用于计算机技术领域。</td>   <td>1.一种基于时空自适应注意力的3D多目标跟踪方法,其特征在于,包括：获取目标场景下的2D多源数据和3D多源数据,对2D多源数据进行图像特征提取,获取图像特征,并对3D多源数据进行点云特征提取,获取点云特征；将所述图像特征和所述点云特征进行特征融合,得到融合特征；根据所述融合特征确定目标场景内每个对象的检测状态；根据所述检测状态,提取检测对象和预测对象之间的协作特征；根据所述协作特征对目标场景内的对象检测和跟踪状态进行实时更新。</td>   <td>G06T7/246;G06T7/40;G06N3/048;G06N3/047;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              王巨宏;              郑冶枫;              赵瑞辉;              王硕佳;              唐鉴恒;              刘文阁;              林帅;                   杨敏       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>一种数据查询方法、装置、电子设备和存储介质</td>   <td>广东省</td>   <td>CN115718812A</td>   <td>2023-02-28</td>   <td>本发明实施例公开了一种数据查询方法、装置、电子设备和存储介质；可以获取包括目标对象交互操作与交互关联对象之间的关联关系的对象交互数据和包括不同的特征提取网络的交互关系提取模型,交互关系提取模型的训练样本包括无标注的样本交互数据,通过各特征提取网络对对象交互数据进行特征提取,得到各特征提取网络对应的交互特征,对各交互特征进行特征融合,得到对象交互特征,基于对象交互特征和预设处理任务得到处理后交互特征,将处理后交互特征与参考特征进行相似度计算,得到处理后交互特征与各参考特征的相似度,进而得到处理结果；因此,可以降低模型训练对人工标注样本的需求,节约人力资源,有利于提升音乐、视频等数据查询的效率。</td>   <td>1.一种数据查询方法,其特征在于,包括：获取对象交互数据以及交互关系提取模型,所述对象交互数据包括目标对象交互操作与交互关联对象之间的关联关系,所述交互关系提取模型的训练样本包括无标注的样本交互数据,所述交互关系提取模型包括至少两个不同的特征提取网络；通过所述交互关系提取模型中的各所述特征提取网络,对所述对象交互数据进行特征提取,得到各所述特征提取网络对应的交互特征；对各所述特征提取网络对应的交互特征进行特征融合,得到所述对象交互数据对应的对象交互特征；基于所述对象交互特征以及预设处理任务,得到所述预设处理任务对应的处理后交互特征,所述预设处理任务与目标对象交互操作或交互关联对象相关；将所述处理后交互特征与所述预设处理任务对应的至少一个参考特征进行相似度计算,得到所述处理后交互特征与各参考特征的相似度；基于所述相似度得到所述预设处理任务的处理结果。</td>   <td>G06F16/53;G06F16/55;G06F16/583;G06V10/40;G06V10/74;G06V10/774;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄润辉;              龙衍鑫;                   梁小丹       </td>   <td>中山大学</td>   <td>一种跨模态检索方法和系统</td>   <td>广东省</td>   <td>CN115718815A</td>   <td>2023-02-28</td>   <td>本发明公开了一种跨模态检索方法和系统,涉及深度学习的技术领域,包括：获取图文对数据集,构建初始视觉-语言检索模型；利用视觉编码器获得掩码块图像编码和图像数据编码,设置图像重建损失函数；在视觉概念词汇库中搜索视觉概念词,利用文本编码器获得视觉概念增强的文本编码,设置图像描述损失函数；利用跨模态解码器生成纯文本数据编码和重建文本数据,计算图文对噪声概率,设置噪声自适应对比损失函数；并利用噪声概率和重建文本数据获得重建图文对数据；构建总损失函数并进行优化,获得优化后的视觉-语言检索模型,进行跨模态检索,获得检索结果；本发明提高了检索结果的准确性,还可以对文本数据不完整的图文对数据集进行补全。</td>   <td>1.一种跨模态检索方法,其特征在于,包括：S1：获取图文对数据集,包含相互对应的图像数据和文本数据；S2：构建初始视觉-语言检索模型,包括视觉编码器、文本编码器和跨模态解码器；S3：对图像数据上的像素块进行随机覆盖,获得掩码块图像；对文本数据进行随机掩码,获得掩码文本数据；S4：将掩码块图像与图像数据输入视觉编码器,获得掩码块图像编码和图像数据编码,并根据掩码块图像编码和图像数据设置图像重建损失函数；S5：将图像数据输入预设视觉概念词汇库,获得视觉概念词；并将视觉概念词和掩码文本数据输入文本编码器,获得视觉概念增强的文本编码；S6：根据文本数据、视觉概念增强的文本编码和图像数据编码设置图像描述损失函数；S7：将图像数据、文本数据和视觉概念增强的文本编码输入跨模态解码器,根据文本数据和视觉概念增强的文本编码生成纯文本数据编码,根据图像数据和视觉概念增强的文本编码生成重建文本数据；S8：根据图像数据编码和纯文本数据编码计算图文对噪声概率,设置噪声自适应对比损失函数；S9：将噪声概率作为替换概率,根据替换概率利用重建文本数据替换对应的文本数据,获得重建图文对数据；S10：根据图像重建损失函数、噪声自适应对比损失函数和图像描述损失函数构建总损失函数,利用重建图文对数据对总损失函数进行优化,获得优化后的视觉-语言检索模型；S11：将待检索的图像数据或文本数据输入训练好的跨模态检索模型中,进行跨模态检索,获得检索结果。</td>   <td>G06F16/58;G06F16/583;G06F40/30;G06F18/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              梁子仲;              刘劲;                   林倞       </td>   <td>中山大学</td>   <td>一种基于依赖树的深度学习视觉问答方法及系统</td>   <td>广东省</td>   <td>CN111222533B</td>   <td>2023-02-24</td>   <td>本发明公开了一种基于依赖树的深度学习视觉问答方法及系统,该方法包括：对问句-图像对输入进行预处理,提取图像的目标区域特征记为图像特征R,生成问句的词语特征记为问句特征E；使用自关注方法分别关注到图像以及问句的显著部分,更新图像及问句特征；通过协同关注方法,将图像和问句特征交替作为引导,更新图像及问句特征；将问句解析成依赖树,根据词语类型剪枝,将问句特征按词语分配到每个树结点；利用图像特征,从依赖树叶子结点往根结点流动,根据结点词语类型分为物体关注模块以及关系构建模块,将图像以及问句特征在模块流动过程中更新；将图像和问句特征进行融合,并通过全连接层分类得到问题的答案。</td>   <td>1.一种基于依赖树的深度学习视觉问答方法,包括如下步骤：步骤S1,对问句-图像对的输入进行预处理,提取图像I的目标区域特征,记为图像特征R,以及生成问句Q的问句词语特征,记为问句特征E；步骤S2,使用自关注的方法分别关注到图像以及问句的显著部分,从而更新图像特征以及问句特征；步骤S3,通过协同关注的方法,将步骤S2得到的图像和问句特征交替作为引导,更新图像特征及问句特征；步骤S4,将问句解析成依赖树,根据词语的类型进行剪枝,留下的结点词语属于关系与物体两种类型,将步骤S3得到的问句特征按照词语分配到每个树结点上步骤S5,利用步骤S3中得到的图像特征,从步骤S4得到的依赖树叶子结点开始往根结点流动,根据结点词语类型分为物体关注模块以及关系构建模块,将图像特征以及问句特征在模块流动过程中进行更新；步骤S6,利用步骤S5根据依赖树流动更新过后的图像和问句特征进行融合,并通过全连接神经网络分类得到问题的答案,即得到类别概率分布。</td>   <td>G06V10/80;G06V10/82;G06V10/44;G06F16/31;G06F16/36;G06F40/289;G06N3/0464;G06N3/0442;G06N3/045;G06N3/082</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              王子渊;                   冯展祥       </td>   <td>中山大学</td>   <td>基于度量学习的解决难分不平衡样本的表面缺陷检测方法</td>   <td>广东省</td>   <td>CN112862767B</td>   <td>2023-02-24</td>   <td>本发明公开了一种基于度量学习的解决难分不平衡样本的表面缺陷检测方法,所述方法包括以下步骤：对目标图像进行特征提取网络生成高维特征；将特征提取网络提取到的特征添加到自适应特征内存,根据特征偏移值调整特征内存大小并记录内存大小的改变历史,在每个迭代中,将特征内存大小的改变历史均值作为获取旧特征数量的参考值；在上一步获取到充分的对比样本对后,同时计算欧氏距离和余弦距离的双相似性度量来度量不同样本的特征相似性。使用前k难单中心聚类的三元组损失,每次迭代中充分挖掘训练批次中的困难样本,解决多分类任务的不平衡样本。提出的方法在不引入任何计算量的情况下,提高了模型的预测精度,并且优于最新方法。</td>   <td>1.基于度量学习的解决难分不平衡样本的表面缺陷检测方法,其特征在于,所述方法包括以下步骤：S1对目标图像进行特征提取网络生成高维特征；S2将特征提取网络提取到的特征添加到自适应特征内存,特征内存大小在训练过程中是动态变化的,自适应算法将特征偏移大小作为参考量,当其增大时增大特征内存,反之减小特征内存,记录特征内存大小变化的历史,在每个迭代中,计算该特征内存的历史大小的平均值,作为获取对比特征的窗口大小,在每个迭代中,将特征内存大小的改变历史均值作为获取旧特征数量的参考值；S3在上一步获取到充分的对比样本对后,同时计算欧氏距离和余弦距离的双相似性度量来度量不同样本的特征相似性；S4使用前k难单中心聚类的三元组损失,每次迭代中充分挖掘训练批次中的困难样本,解决多分类任务的不平衡样本,所述前k难单中心聚类的三元组损失的计算公式如下所示：                  其中,N表示批次的大小,函数d表示欧氏距离公式和余弦距离公式之和的双重相似度,A表示当前批次中与样本a类别相同的样本集合,N-A表示该集合大小,代表不同类别的样本,L-A是集合A中与样本a距离最大的k个样本集合,而表示集合中与样本a距离最小的k个样本集合。</td>   <td>G06T7/00;G06V10/764;G06V10/40;G06V10/762;G06V10/774;G06V10/82;G06V10/74;G06N3/04;G06N3/06;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         匡铭;              翁宗鹏;              许丽霞;              彭穗;              陈淑玲;              肖晗;                   陈峭峰       </td>   <td>中山大学附属第一医院</td>   <td>一种基于图像分析的肿瘤微血管侵犯检测装置</td>   <td>广东省</td>   <td>CN113077415B</td>   <td>2023-02-24</td>   <td>本发明公开了一种基于图像分析的肿瘤微血管侵犯检测装置,包括：输入模块,用于将病理图像分割成若干个预设尺寸大小的区域图像,并将若干个区域图像输入至血管侵犯模型中；标记模块,用于利用血管侵犯模型对区域图像进行图像检测得到肿瘤微血管侵犯结构,并采用矩形框标记每一肿瘤微血管侵犯结构；去重模块,用于根据矩形框的覆盖面积和置信度,对重叠的两个矩形框进行去重得到去重后的矩形框；分类模块,用于将每一矩形框裁剪成以每一矩形框的重心作为重心、以每一矩形框的长作为边长的正方形图像,采用分类模型对正方形图像进行分类,判断正方形图像是否为肿瘤微血管侵犯。本发明实施例能够有效提高肿瘤微血管侵犯检测的准确性和可靠性。</td>   <td>1.一种基于图像分析的肿瘤微血管侵犯检测装置,其特征在于,包括：输入模块,用于将病理图像分割成若干个预设尺寸大小的区域图像,并将若干个所述区域图像输入至血管侵犯模型中；标记模块,用于利用所述血管侵犯模型对所述区域图像进行图像检测得到肿瘤微血管侵犯结构,并采用矩形框标记每一所述肿瘤微血管侵犯结构,其中每一所述矩形框所标记的肿瘤微血管侵犯结构均对应一个置信度；去重模块,用于根据所述矩形框的覆盖面积和置信度,对重叠的两个所述矩形框进行目标去重处理,得到去重后的矩形框；分类模块,用于将每一矩形框裁剪成以每一所述矩形框的重心作为重心、以每一所述矩形框的长作为边长的正方形图像,采用分类模型对所述正方形图像进行分类,判断所述正方形图像是否为肿瘤微血管侵犯；所述将若干个所述区域图像输入至血管侵犯模型中,具体为：降低所述区域图像的分辨率,将降低分辨率后的区域图像输入至血管侵犯模型中；所述标记模块,具体用于：通过所述血管侵犯模型采用YOLO-v4网络结构对所述区域图像进行图像检测得到肿瘤微血管侵犯结构,并采用矩形框标记每一所述肿瘤微血管侵犯结构。</td>   <td>G06T7/00;G06T7/11;G06T7/66</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张荣辉;                   吴月颖       </td>   <td>中山大学</td>   <td>基于ResNeSt和自注意力蒸馏的智能车辆车道线检测方法</td>   <td>广东省</td>   <td>CN113158768B</td>   <td>2023-02-24</td>   <td>本发明公开ResNeSt和自注意力蒸馏的智能车辆车道线检测方法,该方法基于深度学习,以卷积神经网络和编码-解码框架为核心,设计了一个车道线检测网络；使用ResNeSt作为主干网络,并采用自注意力蒸馏技术,以增强网络的特征提取能力；利用传感器获取的图像作为输入,对输入图像进行预处理,以提高网络的速度和精度；网络设计了两个分支,利用二进制分支实现车道线的语义分割,利用嵌入分支实现车道线的实例分割,获取每一条车道线的实例。本发明的方法可在不同的因素影响下,提高车道线检测的准确性和鲁棒性,为驾驶员辅助系统和智能车辆系统提供更准确的感知信息。</td>   <td>1.基于ResNeSt和自注意力蒸馏的智能车辆车道线检测方法,其特征在于,包括以下步骤：S1、对训练图像进行预处理；S2、制作训练集：对每一张图像制作两个标签作为训练集的数据,其中一个作为训练二进制分支的真实标签,另一个作为训练嵌入分支的真实标签；S3、将训练集的图像输入多分支卷积神经网络进行训练：卷积神经网络设有编码-解码结构；编码器对训练数据进行编码,编码器中使用ResNeSt作为主干网络,并设有自注意力蒸馏路径；解码器对编码器输出的特征图进行反卷积,实现上采样和分类；解码器的最后一层,设有两个分支,分别为二进制分支和嵌入分支,利用二进制分支进行语义分割、嵌入分支进行实例分割,两个分支均使用卷积核为1×1的卷积层降低特征映射的维数,作为二进制分支和嵌入分支的输出；计算输出的特征图像与输入的真实标签之间的损失,然后使用梯度下降算法更新神经网络模型的参数,训练直至网络收敛；S4、训练完毕后,将实际的道路图片输入多分支卷积神经网络,得到两个输出,一个是通过二进制分支进行语义分割后的输出,另一个是通过嵌入分支进行实例分割后的输出,之后进行后处理,如下：得到语义分割的结果后,用语义分割的结果制作mask过滤掉嵌入分支输出中属于背景的部分,然后对其进行Meanshift聚类即得到属于不同车道线像素的聚类,获得真正的实例分割的结果；得到实例分割的结果后,在拟合车道过程中,采用如下算法：假设第i条车道的点集为A-i,而A-i中的点坐标为(x,y),则有一系列的x(x-1,x-2,x-3,……,x-n)对应于相同的y值,然后对这些x计算平均值得到：                  由此得到点的坐标为根据这一算法,得到每个车道的点集,最后通过三次样条插值得到最终的车道线检测结果输出；其中,步骤S3中,特征图像与输入的真实标签之间的损失主要分三个部分；包括语义分割时的损失、实例分割时的损失、以及进行自注意力蒸馏时的损失；对于语义分割时的损失,采用Dice Loss公式作为损失函数；对于实例分割时的损失,采用pixel embedding的方法实现实例分割：训练后,嵌入分支为每个像素输出一个3维向量,属于同一车道的向量之间的距离很小,不同车道线像素的向量之间的距离很大,所以使用修正后的损失函数,如下式：                                    式中,C表示聚类的个数,即车道线的条数；N-c为聚类C中的像素数量；μ-c为聚类C中的向量平均值；X-i为第i个像素的嵌入向量；δ-v为超参数,仅在向量与其聚类中心的距离大于δ-v时,才计算损失；δ-d为超参数,仅当聚类中心之间的距离小于δ-d时,才计算损失；[x]-+表示max(0,x)；下标A和B表示两个不同的车道线；方差损失L-(var)将属于同一条车道线的像素点的嵌入向量拉向这条车道线向量的平均值,即让同一条车道线的像素之间的嵌入向量距离更近,形成一个聚类中心；距离损失L-(dist)将聚类中心彼此推开,即让不同车道线的像素的向量之间的距离变大；对于进行自注意力蒸馏时的损失,过程如下：在通过自注意力蒸馏路径提取注意力图后,由于目标图比原始图小,所以要先对目标图进行上采样,然后对每个图执行softmax,然后计算两个注意力图之间的均方误差,自注意力蒸馏的损失函数公式如下：                  Ψ(A-m)表示对特征图A-m进行注意力图提取、上采样和softmax操作；m为第m个block输出的特征图,M为block的总数；所以总的损失函数由以下三项组成：L-(total)＝αL-(bin)+β(L-(var)+L-(dist))+γL-(SAD)L-(bin)是用Dice Loss公式计算的语义分割时的损失,参数α,β和γ平衡了各个损失的影响；其中,步骤S3中,编码器和解码器都由五个Block组成,每个Block内包含若干层卷积；对于编码器,使用ResNeSt作为主干网络,ResNeSt使用拆分注意力,将每个块的特征图沿通道维度分成若干组,每个组再拆分成若干个部分,再把每个部分经过不同的卷积,最后每个组的特征表达是其各个部分特征图的加权组合,权重根据全局信息选择。</td>   <td>G06V20/56;G06V10/26;G06V10/762;G06V10/774;G06V10/77;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;              黄靖雯;              许遵楠;              唐一琳;                   梁潇       </td>   <td>中山大学</td>   <td>一种可交互的基于编译的音乐生成方法和装置</td>   <td>广东省</td>   <td>CN115712729A</td>   <td>2023-02-24</td>   <td>本发明公开了一种可交互的基于编译的音乐生成方法和装置,其中,方法包括获取音乐描述语言文本和音乐风格描述文本；通过预先训练的配置分类模型对所述音乐风格描述文本进行音乐配置分类处理,得到配置文本；根据所述配置文本对所述音乐描述语言文本进行改编处理,得到待编译文本；对所述待编译文本进行音乐编译生成处理,得到可编译音乐文件。本发明实施例能够无需学习乐理知识即可创作音乐,能够广泛应用于人工智能技术领域。</td>   <td>1.一种可交互的基于编译的音乐生成方法,其特征在于,所述方法包括：获取音乐描述语言文本和音乐风格描述文本；通过预先训练的配置分类模型对所述音乐风格描述文本进行音乐配置分类处理,得到配置文本；根据所述配置文本对所述音乐描述语言文本进行改编处理,得到待编译文本；对所述待编译文本进行音乐编译生成处理,得到可编译音乐文件。</td>   <td>G06F16/35;G06F40/205;G06F40/253;G06F40/30;G06F18/214;G06F18/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺丰;              刘智斌;              江波;                   林倞       </td>   <td>中山大学</td>   <td>基于文本描述的跨领域人物搜索方法</td>   <td>广东省</td>   <td>CN115712751A</td>   <td>2023-02-24</td>   <td>本发明公开了一种基于文本描述的跨领域人物搜索方法,如下：构建基于文本描述的跨领域人物搜索网络模型,其包括图像特征提取器、文本特征提取器、第一梯度反转层、第二梯度反转层、图像域分类器、文本域分类器；图像特征提取器通过第一梯度反转层将提取到的图像特征输入图像域分类器；图像域分类器对图像特征处理得到图像域标签,并根据图像域标签计算图像域分类损失；文本特征提取器通过第二梯度反转层将提取到的文本特征输入文本域分类器；文本域分类器对文本特征处理得到文本域标签,并根据文本域标签计算文本域分类损失；利用训练好的跨领域人物搜索网络模型对目标域进行基于文本描述的人物搜索。本发明能在缺乏标签数据的情况下,具有跨领域人物搜索能力。</td>   <td>1.一种基于文本描述的跨领域人物搜索方法,其特征在于：所述的方法包括步骤如下：构建基于文本描述的跨领域人物搜索网络模型,所述的跨领域人物搜索网络模型包括用于提取图像特征的图像特征提取器、用于提取文本特征的文本特征提取器、用于梯度下降的第一梯度反转层、用于梯度下降的第二梯度反转层、图像域分类器、文本域分类器；所述的图像特征提取器通过第一梯度反转层将提取到的图像特征输入图像域分类器；所述的图像域分类器对图像特征处理得到图像域标签,并根据图像域标签计算图像域分类损失；所述的文本特征提取器通过第二梯度反转层将提取到的文本特征输入文本域分类器；所述的文本域分类器对文本特征处理得到文本域标签,并根据文本域标签计算文本域分类损失；利用训练好的跨领域人物搜索网络模型对目标域进行基于文本描述的人物搜索。</td>   <td>G06F16/583;G06N3/045;G06N3/084;G06F16/532;G06F16/35;G06V10/764;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         侯英威;              由林麟;              李浩源;              吴承瀚;              林俊龙;                   郭子晗       </td>   <td>中山大学</td>   <td>一种自适应聚合的联邦学习系统、方法、装置及存储介质</td>   <td>广东省</td>   <td>CN115713113A</td>   <td>2023-02-24</td>   <td>本发明公开了一种自适应聚合的联邦学习系统、方法、装置及存储介质,通过中央服务器下发全局模型至所有客户机,使得客户机基于本地数据训练本地模型后将更新后的本地模型返回至中央服务器,中央服务器根据客户机的数据特征及模型特征自适应地计算出各个客户机的归一化权重,然后采取不同的聚合模式进行全局模型的聚合更新,并预测不同聚合模式下的第一模型准确率、第一时间成本以及第一通信成本,再对这些预测信息进行推送便于根据用户需求选择合适的聚合模式,然后根据该聚合模式进行正式的联邦学习训练。本发明实施例可以自适应地计算聚合权重并选择合适的聚合模式进行联邦学习训练,提高了联邦学习的训练效率,可广泛应用于联邦学习技术领域。</td>   <td>1.一种自适应聚合的联邦学习系统,其特征在于,包括：本地训练层,用于客户机在接收到中央服务器发送的全局模型后,基于本地数据进行模型训练并将更新后的本地模型返回至所述中央服务器；特征感知层,用于获取各所述客户机的数据特征和所述本地模型的模型特征；权重分配层,用于根据所述数据特征和所述模型特征计算得到各所述客户机在全局模型加权聚合时的归一化权重；聚合更新层,用于根据所述归一化权重和预设的多个聚合模式对各所述客户机上传的所述本地模型进行加权聚合,计算当前聚合轮次所述全局模型的模型准确率,并将更新后的所述全局模型下发至参与聚合的各所述客户机；信息预测层,用于根据当前聚合轮次的所述模型准确率和前一聚合轮次的所述模型准确率进行预测,得到对应各所述聚合模式的预测信息,所述预测信息包括各所述聚合模式下在预设时间内可以达到的第一模型准确率,以及达到预设的第二模型准确率所需的第一时间成本和第一通信成本；策略选择层,用于根据所述中央服务器推送的所述预测信息和预先获取的用户需求从所述聚合模式中选取出第一聚合模式,并根据所述第一聚合模式进行正式的联邦学习训练。</td>   <td>G06N3/098;G06F9/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         万海;              夏勇涛;                   曾娟       </td>   <td>中山大学</td>   <td>一种基于图二阶相似性的知识图谱实体语义空间嵌入方法</td>   <td>广东省</td>   <td>CN109829057B</td>   <td>2023-02-21</td>   <td>本发明公开一种基于图二阶相似性的知识图谱实体语义空间嵌入方法,包括步骤：(1)输入知识图谱数据集、最大迭代次数；(2)通过一、二阶相似性特征嵌入处理,通过图注意力机制考虑实体之间联系,计算一、二阶相似性向量表示,得到一、二阶相似性语义空间嵌入表示；(3)对实体最终的一阶相似性向量和二阶相似性向量加权求和,得到实体最终的向量表示,输入翻译模型计算损失值,得到图注意力网络、图神经网络残差,并迭代网络模型；(4)对网络模型进行链接预测和分类测试。本发明首次提出运用图注意力机制挖掘实体之间的联系,专利在知识图谱的链接预测和分类等应用领域上都取得了较好的效果。</td>   <td>1.一种基于图二阶相似性的知识图谱实体语义空间嵌入方法,其特征在于,包括步骤：S1、输入知识图谱数据集、最大迭代次数,初始化；在所输入的知识图谱数据集中,每个知识图谱中的三元组记为(h,r,t),其中h表示头实体,t表示尾实体,r表示头实体h和尾实体t之间的关系,实体表示为e；S2、通过一阶相似性特征嵌入处理,通过图注意力机制考虑实体之间的联系,计算实体的一阶相似性向量表示,得到实体的一阶相似性语义空间嵌入表示；S3、通过二阶相似性特征嵌入处理,根据二阶相似性采样取得的特征实体,结合图注意力机制所考虑的实体之间的联系,计算实体的二阶相似性向量表示,得到实体的二阶相似性语义空间嵌入表示；S4、对实体e最终的一阶相似性向量和二阶相似性向量加权求和,得到实体最终的向量表示,输入翻译模型计算损失值,得到图注意力网络、图神经网络的残差,并迭代图注意力网络、图神经网络的模型；S5、对图注意力网络、图神经网络的模型,进行链接预测和分类测试；步骤S2包括：实体e的一阶相似性邻居实体集合为从一阶相似性邻居实体集合中取出邻居实体n并取出邻居实体n与实体e实体相连的关系r对应的关系语义矩阵A-r,将邻居实体n对应的向量v-n投影到关系语义矩阵A-r上让它在不同关系下有不同的表示,经过批标准化BN和激活函数ReLU之后得到邻居实体的向量表示；一阶相似性向量在关系语义矩阵下的投影表示如下：                  转换后的邻居实体向量集合记为设一共有K个一阶相似性邻居实体,将所有的邻居实体向量相加并求均值得到实体e初步的一阶相似性向量                  将实体e初步的一阶相似性向量和邻居实体向量集合放进图注意力网络计算权值,将实体e初步的一阶相似性向量与邻居实体向量集合中的K个向量逐个拼接,放入单层全连接神经网络相乘,相乘之后得到各个权重系数α-(ei),将所有权重系数做归一化处理得到图注意力网络所计算出的权重参数,其中一个单层全连接神经网络的注意力系数计算如下：                  其中W～1是单层全连接神经网络的参数,||表示两个向量的拼接；将计算出的权重参数逐个与邻居实体向量相乘,得到实体最终的一阶相似性向量表示：                  步骤S3包括：从实体e的二阶相似性邻居实体集合中取出邻居实体n,并取出邻居实体n与实体e相连的关系r对应的关系语义矩阵A-r,将邻居实体n对应的向量v-n投影到关系语义矩阵A-r上让它在不同关系下有不同的表示,经过批标准化BN和激活函数ReLU之后得到邻居实体的向量表示；二阶相似性向量在关系语义矩阵下的投影表示如下：                  假设有K个二阶相似性向量,将它们相加并求均值,得到该实体e初步的二阶相似性向量表示：                  将实体e初步的二阶相似性向量和邻居向量集合中的K个向量放进图注意力网络计算权重参数,计算公式如下：                  将计算出的权重参数逐个与邻居向量相乘得到实体e最终的二阶相似性向量表示：                  步骤S4包括：(1)实体e最终的一阶相似性向量、二阶相似性向量加权求和的公式为：                            为实体e最终的一阶相似性向量,为实体e最终的二阶相似性向量；(2)损失值的计算采用得分函数,得分函数的公式为：f(h,r,t)＝||v-h+v-r-v-t||其中Ve表示所有实体,v-h为头实体,v-t为尾实体；v-r为一个向量,维度与v-h、v-t的维度保持相同,根据不同的关系随机初始化再进行参数训练得到；(3)训练目标函数,目标函数的公式为：                  其中τ是一个超参数,用于分隔开正样本和负样本,(h-i,r-i,t-i)是训练集中的正样本,(h-i′,r-i,t-i′)是正样本随机替换掉头实体或尾实体产生的负样本。</td>   <td>G06F16/36;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁业恒;              邓孺孺;              秦雁;                   刘永明       </td>   <td>中山大学</td>   <td>一种水中重金属可遥感反演的下限浓度计算方法</td>   <td>广东省</td>   <td>CN109376424B</td>   <td>2023-02-17</td>   <td>本发明公开了一种水中重金属可遥感反演的下限浓度计算方法,其通过传感器对应的辐射定标公式确定遥感观测值和遥感反射率之间的关系,通过水质遥感模型确定重金属浓度和遥感反射率间的关系,并将关系式联立进行求解,推导出重金属在水中能被传感器观测到的可遥感反演的下限浓度计算公式,可建立起重金属可遥感反演下限浓度值与传感器辐射灵敏度、传感器类型、背景水体类型、重金属种类之间的函数关系,可用于方便快捷地计算得出不同水体情况下,各种重金属的可遥感反演的下限浓度,适用性强。</td>   <td>1.一种水中重金属可遥感反演的下限浓度计算方法,其特征在于,包括以下步骤：S1、通过传感器对应的辐射定标公式f-1标定：                  其中E-s为大气层外太阳辐照度；θ-z为太阳天顶角；d为日地平均距离因子；Gain为传感器定标斜率；Offset为传感器绝对定标系数偏移量；通过水质遥感模型f-2标定：R-n＝f-2(D-n)；其中,D-n为水体中的重金属浓度,DN-n为传感器对遥感观测值,R-n为重金属浓度为D-n的水体的遥感反射率；S2、通过所述传感器对应的辐射定标公式f-1标定：R-(n+1)＝f-1(DN-n-ε)；通过水质遥感模型f-2标定：R-(n+1)＝f-2(D-(n+1))；其中,D-(n+1)为水体中的变化后的重金属浓度,DN-n-ε为所述传感器对所述水体的遥感观测值,R-(n+1)为重金属浓度为D-(n+1)的水体的遥感反射率；ε为所述传感器的辐射分辨率；S3、将R-n和R-(n+1)作比,可得由此可推导出D-(n+1)和D-n之间的关系D-(n+1)＝g(D-n)；S4、取n＝0,有D-0＝0,此时D-1＝g(0)；其中,D-1为重金属在水中能被传感器观测到的可遥感反演的下限浓度。</td>   <td>G06F30/20;G01N21/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李茁;                   马宇       </td>   <td>中山大学</td>   <td>压水堆组件形状因子参数化方法</td>   <td>广东省</td>   <td>CN110427681B</td>   <td>2023-02-17</td>   <td>本发明是压水堆组件形状因子参数化方法。本发明组件形状因子参数化方法以本征正交分解为基础,在于将组件形状因子分解为具有空间特征的本征正交基及随组件状态参数变化的本征正交系数两部分,将本征正交系数作为一种组件均匀化少群常数进行少群常数参数化,以快速获取准确的组件形状因子为目的。本发明将组件形状因子的空间特性存储于本征正交基中,可以提高组件形状因子参数化的计算精度；将本征正交系数作为一种组件均匀化少群常数进行少群常数参数化,可以明显减少组件形状因子参数化的计算量提高计算速度；本征正交系数随组件状态参数的变化规律更单调,更易于进行参数化,进而可以提高组件形状因子参数化的计算精度。</td>   <td>1.一种压水堆组件形状因子参数化方法,其特征是：包括如下步骤：步骤一：确定压水堆组件工况点数,视压水堆组件形状因子为二维矩阵；步骤二：对多个二维矩阵进行本征正交分解,得到本征正交基,以及本征正交系数；步骤三：取前M个本征正交基以及对应的本征正交系数,将本征正交基与本征正交系数相乘,得到乘积；步骤四：比较本征正交基与本征正交系数的乘积与压水堆组件形状因子,计算压水堆组件形状因子误差；步骤五：判断组件形状因子误差是否满足要求,重复步骤三至步骤五,直至搜索到满足要求的本征正交基的最小数量,并存储最小数量的一组本征正交基；步骤六：对M个本征正交系数进行常规截面参数化,得到M个本征正交系数截面参数化结果,存储本征正交系数参数化的结果；步骤七：根据存储的本征正交系数参数化结果,对本征正交系数进行回代,回代后的本征正交系数与存储的本征正交基相乘,得到压水堆组件形状因子。</td>   <td>G06F30/20;G06F17/16;G21C13/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              朱聿莹;              刘凌波;                   林倞       </td>   <td>中山大学</td>   <td>一种地铁客流量分布预测方法以及设备</td>   <td>广东省</td>   <td>CN113077281B</td>   <td>2023-02-17</td>   <td>本发明公开了一种地铁客流量分布预测方法以及设备,本发明通过将OD客流量分布中未完成的订单信息作为输入的一部分,与已完成的订单信息一起输入OD客流量分布预测子模型进行预测,从而在对未来的客流量分布预测中考虑了未完成的订单信息。并且,本发明实施例通过将OD第一分布特征隐藏状态和DO第一分布特征隐藏状态进行融合后获得融合特征,从而充分发掘了OD客流量分布与DO客流量分布在预测中相互之间的指导作用,使得地铁客流量分布预测模型输出的预测结果能够准确完整地反映客流量的真实分布情况。</td>   <td>1.一种地铁客流量分布预测方法,其特征在于,包括以下步骤：获取地铁系统在Z个历史时刻的OD客流量分布以及Z个历史时刻的DO客流量分布；其中,所述OD客流量分布中包括已完成的订单信息以及未完成的订单信息,其中,Z∈N+；将所述Z个历史时刻的OD客流量分布以及所述Z个历史时刻的DO客流量分布输入到预先设置的地铁客流量分布预测模型中,以使所述地铁客流量分布预测模型根据所述Z个历史时刻的OD客流量分布以及所述Z个历史时刻的DO客流量分布,获得OD第一分布特征隐藏状态以及DO第一分布特征隐藏状态,并基于由所述OD第一分布特征隐藏状态和所述DO第一分布特征隐藏状态融合后获得的融合特征,获得OD第二分布特征隐藏状态和DO第二分布特征隐藏状态,基于所述OD第一分布特征隐藏状态、所述DO第一分布特征隐藏状态、所述OD第二分布特征隐藏状态以及所述DO第二分布特征隐藏状态,输出未来Z个时刻的OD客流量分布预测和未来Z个时刻的DO客流量分布预测；所述地铁客流量分布预测模型基于所述Z个历史时刻OD客流量分布以及所述Z个历史时刻DO客流量分布,得到OD第一分布特征隐藏状态以及DO第一分布特征隐藏状态的具体过程为：所述地铁客流量分布预测模型基于所述Z个历史时刻的OD客流量分布,得到Z个历史时刻中每个历史时刻所对应的OD第一分布特征隐藏状态；所述地铁客流量分布预测模型基于所述Z个历史时刻的DO客流量分布,得到Z个历史时刻中每个历史时刻所对应的DO第一分布特征隐藏状态；所述地铁客流量分布预测模型基于所述Z个历史时刻的OD客流量分布,得到Z个历史时刻中每个历史时刻所对应的OD第一分布特征隐藏状态的具体过程为：所述地铁客流量分布预测模型获取第q-1OD第一分布特征隐藏状态,从所述Z个历史时刻的OD客流量分布中获取第q历史时刻的OD客流量分布,其中,q∈Z,且当q＝1时,第q-1OD第一分布特征隐藏状态为0；所述地铁客流量分布预测模型执行第一分析步骤,其中,第一分析步骤的具体过程为：所述地铁客流量分布预测模型基于所述第q-1OD第一分布特征隐藏状态对所述第q历史时刻的OD客流量分布中已完成的订单信息进行时空表征学习,得到第q OD出站客流量特征隐藏状态；基于所述第q-1OD第一分布特征隐藏状态对所述第q历史时刻的OD客流量分布中未完成的订单信息进行时空表征学习,得到第q OD未出站客流量特征隐藏状态；基于所述第q OD出站客流量特征隐藏状态以及所述第q OD未出站客流量特征隐藏状态,得到第qOD第一分布特征隐藏状态；令q＝q+1,重新执行第一分析步骤,直至q＝Z,得到Z个历史时刻中每个历史时刻所对应的OD第一分布特征隐藏状态。</td>   <td>G06Q30/02;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马锦华;              高远;                   陈培鹏       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>视频处理方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115705706A</td>   <td>2023-02-17</td>   <td>本申请涉及一种视频处理方法、装置、计算机设备和存储介质。所述方法包括：通过待训练的识别模型,分别提取源域和目标域下的视频样本的深度特征；通过域适应训练器对深度特征进行多时间尺度特征提取,分别得到源域和目标域下的多时间尺度的视频特征；按照视频特征对应的时间节点和时间尺度权重,将源域和目标域下的视频特征分组对齐；时间尺度权重与相应视频特征所表达的信息量正相关；根据同组内的源域和目标域下的视频特征之间的对抗损失,以及源域下的视频样本的预测类别与相应样本标签之间的类别损失,调整识别模型的模型参数并继续进行对抗训练,直至满足训练停止条件时结束训练。采用本方法能够有效提高视频识别的准确率。</td>   <td>1.一种视频处理方法,其特征在于,所述方法包括：通过待训练的识别模型,分别提取源域和目标域下的视频样本的深度特征；所述源域下的视频样本携带样本标签；通过域适应训练器对所述深度特征进行多时间尺度特征提取,分别得到源域和目标域下的多时间尺度的视频特征；按照所述视频特征对应的时间节点和时间尺度权重,将源域和目标域下的视频特征分组对齐；所述时间尺度权重与相应视频特征所表达的信息量正相关；根据同组内的源域和目标域下的视频特征之间的差异,确定对抗损失；基于源域下的视频样本的预测类别与相应样本标签之间的差异,确定类别损失；所述预测类别,是基于所述源域下的视频样本的视频特征进行分类得到；根据所述对抗损失和所述类别损失,调整所述识别模型的模型参数并继续进行对抗训练,直至满足训练停止条件时结束训练。</td>   <td>G06V20/40;G06V10/62;G06V10/764;G06V10/82;G06N3/0464;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈定安;              彭雄;                   李名豪       </td>   <td>中山大学</td>   <td>一种基于单一立方体三维点云配准方法及系统</td>   <td>广东省</td>   <td>CN114882085B</td>   <td>2023-02-14</td>   <td>本发明公开了一种基于单一立方体三维点云配准方法及系统,该方法包括：获取原始点云并根据原始点云提取骰子点云；判断到骰子点云数据完整,对骰子点云进行平面分割、旋转和图像处理,得到预处理图像；对预处理图像进行圆边缘检测和圆拟合,并进行坐标变换,得到骰子平面点数圆中心三维坐标；根据骰子平面点数圆中心三维坐标构建同名点对；计算同名点对之间的旋转矩阵和平移矩阵,并基于旋转矩阵和平移矩完成配准。该系统包括：点云提取模块、图像处理模块、中心计算模块、同名点对构建模块和配准模块。通过使用本发明,能够将两个测站所扫描的点云数据准确进行配准,得到完整的三维点云数据。本发明可广泛应用于地理信息处理领域。</td>   <td>1.一种基于单一立方体三维点云配准方法,其特征在于,包括以下步骤：获取原始点云进行降噪预处理并根据预处理后的点云提取骰子点云；判断到骰子点云数据完整,对骰子点云进行平面分割、旋转和图像处理,得到预处理图像；对预处理图像进行圆边缘检测和圆拟合,并进行坐标变换,得到骰子平面点数圆中心三维坐标；根据骰子平面点数圆中心三维坐标构建同名点对；计算同名点对之间的旋转矩阵和平移矩阵,并基于旋转矩阵和平移矩完成粗配准。</td>   <td>G06T7/33;G06T7/13;G06T7/73;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢志;              何尧;              周昊;                   张昀       </td>   <td>中山大学中山眼科中心</td>   <td>一种适用多种视觉任务的领域自适应增强方法</td>   <td>广东省</td>   <td>CN115701868A</td>   <td>2023-02-14</td>   <td>本发明公开一种适用多种视觉任务的领域自适应增强方法,包括S01：针对基于深度学习算法的医学图像分析任务,从该任务中分析提取出该任务的业务模型；S02：根据业务模型,构建基于CycleGAN模型与辅助任务协同学习的域自适应框架,包括CycleGAN模块和辅助任务模块,其中,CycleGAN模块用于转换不同域的图像风格,所述辅助任务模块包括主辅助任务和次辅助任务；S03：使用未配对的目标域图像数据集和源域图像数据集训练所述基于CycleGAN模型与辅助任务协同学习的域自适应框架；S04：使用训练好的CycleGAN模型将目标域图像转换为源域图像风格,输入业务模型中,得到最终的结果。本发明改善由源域数据训练的业务模型对目标域图像的泛化性,不需要业务标签即可提高目标域图像上的业务性能。</td>   <td>1.一种适用多种视觉任务的领域自适应增强方法,其特征在于,包括以下步骤：S01：针对基于深度学习算法的医学图像分析任务,从该任务中分析提取出该任务的业务模型；S02：根据业务模型,构建基于CycleGAN模型与辅助任务协同学习的域自适应框架,包括CycleGAN模块和辅助任务模块,其中,CycleGAN模块用于转换不同域的图像风格,所述辅助任务模块包括主辅助任务与次辅助任务；S03：使用未配对的目标域图像数据集和源域图像数据集训练所述基于CycleGAN模型与辅助任务协同学习的域自适应框架；S04：使用训练好的CycleGAN模型将目标域图像转换为源域图像风格,输入业务模型中,得到最终的结果。</td>   <td>G06T5/00;G06T3/00;G06V10/26;G06V10/764;G06V10/774;G06V10/82;G06N3/0464;G06N3/092</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金舒原;                   张允义       </td>   <td>中山大学</td>   <td>一种基于主机关联性的DGA家族分类方法</td>   <td>广东省</td>   <td>CN111125700B</td>   <td>2023-02-07</td>   <td>本发明提供一种基于主机关联性的DGA家族分类方法,包括以下步骤：S1.利用现有的DGA域名检测技术将流量中所包含的所有DGA域名及其解析行为关系提取出来,形成DGA域名与解析主机的集合；S2.针对不同家族的特性提出新的描绘家族特性的特征,得到DGA家族的家族画像；S3.获得某个主机解析的全部域名的集合,然后遍历主机集合,当两个主机解析的域名出现重合的则将这两个主机关联在一起并归为一类；S4.将步骤S3所得的初步聚类的类别进行再次聚合,遍历所有类别,利用初步聚类的类别训练分类器,计算初步聚类的类别间相似度,实现类别融合,最终得到DGA家族的聚类结果；S5.使用S2所得的家族画像对聚类结果进行比较验证,对聚类结果进行纠正分析并进行评估判断。</td>   <td>1.一种基于主机关联性的DGA家族分类方法,其特征在于,包括以下步骤：S1.获取包含DGA域名数据的DNS流量数据,利用DGA域名检测技术将流量中所包含的所有DGA域名及其解析行为关系提取出来,形成DGA域名与解析主机的集合；S2.根据DGA域名与解析主机的集合进行DGA家族的详细分析,针对不同家族的特性提出描绘家族特性的特征,得到DGA家族的家族画像；S3.主机关联预分类阶段,利用S1所得的DGA域名与解析主机的集合获得每个主机解析的全部域名的集合,然后遍历主机集合,当两个主机解析的域名出现重合的则将这两个主机关联在一起并归为一类；S4.将步骤S3所得的初步聚类的类别进行再次聚合,遍历所有类别,利用初步聚类的类别训练分类器,计算每一类别与其他类别的元素相似度,实现类别融合,最终得到DGA家族的聚类结果；S5.使用S2所得的家族画像对聚类结果进行比较验证,对聚类结果进行纠正分析并进行评估判断。</td>   <td>G06F21/56</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓晓晴;                   骆伟祺       </td>   <td>中山大学</td>   <td>一种基于梯度网络架构搜索的空域隐写分析方法及系统</td>   <td>广东省</td>   <td>CN113034472B</td>   <td>2023-02-07</td>   <td>本发明提出一种基于梯度网络架构搜索的空域隐写分析方法及系统,解决了现有人工设计网络性能表现欠佳以及搜索网络耗时长的问题,首先定义一个隐写分析网络搜索架构,确定隐写分析网络搜索架构中每部分待搜索模块的搜索架构及候选操作,并使用Softmax函数融合搜索空间中的所有候选操作以构建一个超参数网络,然后利用梯度下降法对所构建的超参数网络进行训练优化,根据训练好的超参数网络中的架构参数选定相应的操作,完成隐写分析网络的搜索构建,本方案所提方法减少了网络设计中的人工干预,避免所构建隐写分析网络的性能受限的弊端,并且基于梯度更新的网络架构搜索方式使搜索耗时减少。</td>   <td>1.一种基于梯度网络架构搜索的空域隐写分析方法,其特征在于,至少包括：S1.构建包括若干部分的隐写分析网络搜索框架,确定每部分对应的搜索架构及搜索空间中的候选操作；S2.利用Softmax函数将搜索空间中的所有候选操作进行结合,构建包含候选操作的超参数网络；S3.利用梯度下降法对构建出的超参数网络进行训练优化；S4.根据训练好的超参数网络,完成隐写分析网络的搜索构建,确定搜索得到的隐写分析网络,用于隐写分析；所述隐写分析网络搜索框架包括依次相连的预处理部分、特征提取部分及分类部分,所述预处理部分包括一个预处理模块,所述预处理模块由SRM线性高通滤波核及TLU激活函数组成,预处理模块的搜索空间为F,候选操作为f-i,i＝1,2,...,n,n表示候选操作的个数；所述特征提取部分包括一般模块、第一缩减模块及第二缩减模块,一般模块、第一缩减模块及第二缩减模块的架构相同,搜索空间均为O,候选操作为o-k,k＝1,2,...,m,m表示候选操作的个数；一般模块的候选操作步长设置为1,第一缩减模块及第二缩减模块的候选操作步长均设置为2；所述分类部分包括全局协方差池化层、全连接层和Softmax激活函数,无待搜索模块,不存在搜索空间及候选操作；待隐写分析图像输入至预处理模块,经过SRM线性高通滤波核滤波处理后,输出经过TLU激活函数处理,处理公式为：                  其中,x表示输入图像,T为所设置的阈值,经过TLU激活函数处理后的输出被拼接在一起作为预处理模块的最后输出；步骤S2中利用Softmax函数将搜索空间中的所有候选操作进行结合,构建出包含候选操作的超参数网络的过程包括：在预处理模块中,输入图像经过所有候选SRM线性高通滤波核滤波操作处理后,输出经过TLU激活函数处理,加上经过Softmax函数计算后得到的超参数网络架构参数以作为权重,得到每个候选操作处理后相应的输出,计算公式为：                  其中,input表示输入,f-i表示第i个候选操作,参数表示每一个候选操作滤波前的权重,r-i表示为输入经过第i个候选操作处理后的输出结果,最后预处理模块的输出为所有r-i的拼接结合,i＝1,2,...,n；在一般模块、第一缩减模块及第二缩减模块中,为了减少搜索过程中所需要的计算资源,采用部分通道连接的计算方式,即仅输入的部分通道通过候选操作进行处理,其余通道直接作为模块的部分输出与经过候选操作后的另一部分输出进行结合作为模块的最后输出；在部分通道连接的情况下,对部分输入经过候选操作后的输出,加上Softmax函数计算后得到超参数网络架构参数以作为权重,计算公式为：                  其中,y～(PC)(x-j)表示输入节点x-j在部分通道连接的情况下通过所有候选操作后的输出结果,x-j表示一般模块、第一缩减模块或第二缩减模块的输入节点,为在先模块的输出,j＝0,1；S-j是一个长度与输入节点x-j通道数相同的向量,表示输入节点x-j的通道采样掩模,当输入节点x-j的某一通道被选取用于通过候选操作时,对应位置上的S-j元素被设为1,否则为0；o-i表示一般模块、第一缩减模块或第二缩减模块搜索空间中的第i个候选操作；参数表示第j个输入节点后第i个候选操作前所带的权重。</td>   <td>G06T7/00;G06N3/0464;G06N3/0985</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄淼鑫;                   潘嵘       </td>   <td>中山大学</td>   <td>一种嵌入外部词典信息的词向量改进方法</td>   <td>广东省</td>   <td>CN109271635B</td>   <td>2023-02-07</td>   <td>本发明涉及自然语言处理的技术领域,更具体地,涉及一种嵌入外部词典信息的词向量改进方法。本发明在普通词向量的基础上融合了相似词词典和相关词词典的信息,相比于普通词向量,本发明可以较好的分离共现词的影响,同时缩小词义相近的词的词向量距离,使得最终的词向量更接近词的客观词义；另一方面,因为词向量是很多自然语言处理任务的底层技术,更接近客观词义的词向量有助于下游任务的提升。外部预训练的高质量词向量在一些任务中还能缓解标注数据不足的问题。</td>   <td>1.一种嵌入外部词典信息的词向量改进方法,其特征在于,包括以下步骤：S1: 准备一个大型语料库和一个电子词典；S2: 相似词词典：电子词典的每个词可能会附带有近义词和同义词,利用脚本将其抽取出来并记录；S3: 相关词词典：在大型语料库中,使用统计方法寻找相关词对,按照两个相关词的联合概率远大于两个词的单独概率乘积的原则,将相关词对识别出来并记录；S4: 针对语料库,统计出现的所有词及其词频,构建一个词汇表；S5: 在语料库中设定一个滑动窗口,窗口大小为n,取窗口的中间词为中心词,将中心词和其他词构成正例pair；S6: 在词汇表中依据词频确定被采样概率,采样出若干个词,和中心词一起构成负例pair；S7: 如果S5的中心词出现在相似词词典中,则分别把中心词和相似词典记录的对应词构成pair,加入到正例pair中；S8: 如果S5的中心词出现在相关词词典中,则分别把中心词和相关词典记录的对应词构成pair,加入到负例pair中；S9: 搭建一个单层且无偏置参数的全连接神经网络,将正例pair和负例pair作为输入,利用sigmoid函数输出pair是正例或负例的概率；S10: 利用均方差计算输出loss,使用梯度下降法使loss下降；S11: 重复S5到S10,直到loss收敛；S12: 全连接网络的权重矩阵即是所有词语的词向量构成的矩阵。</td>   <td>G06F40/247</td>  </tr>        <tr>   <td>中国专利</td>   <td>              黄慧玲       </td>   <td>中山大学附属第一医院</td>   <td>一种基于运动方案的心脏风险等级评估方法、设备及介质</td>   <td>广东省</td>   <td>CN115440381B</td>   <td>2023-02-07</td>   <td>本申请公开了一种基于运动方案的心脏风险等级评估方法、设备及介质,方法包括：获取待测人员的身体指标；根据身体指标,生成待测人员的运动方案,以使待测人员执行所述运动方案；采集待测人员的测试数据；根据测试数据,确定所述待测人员的心脏风险等级。从多个方面对测试者的心血管系统进行更加整体性的分析,可以更及时地发现运动过程中的风险,提高测试的准确性,通过从不同方面对测试者产生的评估结果,得到尽可能准确的心脏风险等级评估结果。测试医师可以根据测试的评估结果,给出针对待测人员的运动建议。</td>   <td>1.一种基于运动方案的心脏风险等级评估方法,其特征在于,包括：获取待测人员的身体指标；根据所述身体指标,生成所述待测人员的运动方案,以使所述待测人员执行所述运动方案；采集所述待测人员的测试数据；根据所述测试数据,确定所述待测人员的心脏风险等级；所述获取待测人员的身体指标,具体包括：获取所述待测人员的当前身体数据,所述身体数据至少包括体重数据、年龄数据；获取所述待测人员内的家族遗传病史信息以及当前血压信息、心电图信息；所述根据所述身体指标,生成所述待测人员的运动方案,具体包括：根据所述体重数据以及所述年龄数据,确定所述待测人员的运动功率；根据所述运动功率,确定所述待测人员在不同评估模式下的目标运动时长；所述评估模式至少包括快速评估模式以及正常评估模式；根据所述待测人员的性别,确定所述待测人员在不同运动模式下的目标心率；所述根据所述体重数据以及所述年龄数据,确定所述待测人员的运动功率,具体包括：          ；其中,为所述待测人员的运动功率,为所述待测人员的体重数据,为所述待测人员的年龄数据；所述根据所述运动功率,确定所述待测人员在不同评估模式下的目标运动时长,具体包括：          ；其中,为目标运动时长,为不同评估模式对应的运动增量系数；所述根据所述待测人员的性别,确定所述待测人员在不同运动模式下的目标心率,具体包括：          ；其中,为目标心率,为与所述待测人员性别相关的性别系数；为与运动模式相关的运动量级系数。</td>   <td>G16H50/30;G16H10/60;G16H20/30;A61B5/0205;A61B5/329;A61B5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   肖小粤       </td>   <td>中山大学</td>   <td>一种基于区块链的多方安全选举系统</td>   <td>广东省</td>   <td>CN109558517B</td>   <td>2023-02-03</td>   <td>本发明公开一种基于区块链的多方安全选举系统,本系统选择了以太坊,提供了一个内置成熟的区块链,使用语言创建分布式对等互联选举协议来编码实现任意的状态转换功能或定制的逻辑,该方法采用分布式对等互联选举协议,分布式对等互联选举协议是基于安全多方求和协议的、去中心化的、自计票的选举协议,其能满足更高的安全性需求,并与区块链契合,其包括注册阶段、发送加数阶段、发送和阶段和计票阶段,为一种基于安全多方求和协议的、去中心化的、自计票的、安全可靠的协议。本发明的具备分布式对等互联选举协议的区块链可以为本选举系统提供去中心化、不可篡改、安全可靠、可编程性等特性。</td>   <td>1.一种基于区块链的多方安全选举方法,其特征在于,具体步骤为：S10设置阶段：在以太坊系统的服务层制定分布式对等互联选举协议,设置选举管理员和选民,选举管理员设制选举的初始化问题,其包括参与人白名单、选举问题、候选人选项；具体为：选取以太坊系统,生成公钥私钥x-i及电子选票a-j(j∈{1,...,m}),制定分布式对等互联选举协议,构建用于选举的以太坊区块链；以太坊系统的选取步骤包括：(1)假设所有选民承认一个事实(G,g),其中G表示素数阶q的一个有限循环群,g表示G的生成元；(2)假设现有n个选民(P-1,P-2,...,P-n)参与投票,共有m个候选人(C-1,C-2,...,C-m)；(3)设计电子选票结构：每列由k位构成,其中,前k-1位为0,最后1位a-j值取决于选民,若选民对候选人C-j投赞成票,则a-j＝1,否则a-j＝0,因此选票总位数为m*k；S20注册阶段：允许参与人白名单中的选民注册合法身份,且仅具有合法身份的选民获取选举的初始化问题；具体为：在以太坊区块链广播公钥,以供n个选民获取,分配私钥x-i给选民,选民根据私钥x-i计算出一个非交互式的零知识证明ZKP(x-i)发送以太坊区块链进行身份验证,若验证成功,选民为具有选民身份的选民P-i(i∈{1,...,n})；所述选民根据私钥x-i计算出一个非交互式的零知识证明ZKP(x-i)的方法为：所述以太坊系统将零知识证明实现为Schnorr证明,使用Fiat-Shamir启发式的方法保证其非交互性；S30发送加数阶段：选民将自己回复的选举的初始化问题以加密加数形式发送至以太坊区块链；具体为：具有选民身份的选民P-i在电子选票a-j上对m个候选人(C-1,C-2,...,C-m),若支持该候选人C-j(j∈{1,...,m}),则选票a-j＝1,反对,则a-j＝0,由此生成选票,采用椭圆曲线加密算法对选票进行加密获得加密加数a-(ki),且将其发送至以太坊区块链；S40发送和阶段：选民从区块链中取出所有的加密加数,把这些加密加数求和；S50计票阶段：选举管理员或具有合法身份的选民调用分布式对等互联选举协议进行票数统计；具体为：以太坊区块链将所有选民发送来的和的加密加数a-(ki)的值进行求和：                  以得到所有候选人C-j的得票数。</td>   <td>G06F16/901;G07C13/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              庄业广;                   周晓聪       </td>   <td>中山大学</td>   <td>基于文档嵌入的长文本案件罚金范围分类预测方法及装置</td>   <td>广东省</td>   <td>CN109614606B</td>   <td>2023-02-03</td>   <td>本发明公开一种基于文档嵌入的长文本案件罚金范围分类预测方法,包括：S1：对罚金金额进行离散化处理,并根据罚金金额标记不同的label；S2：进行分词并去停用词处理；S3：将同一label下的判决文书拼接组合成一个文档,计算每个词在不同文档中的TFIDF值,并按照每个词在不同文档中的TFIDF值的方差大小对词进行重要性排序；S4：取排序后top k个词作为关键词,保留是关键词的词；S5：利用过滤后判决文书训练一个doc2vec模型,对应的doc2vec中心向量；S6：计算待预测判决文书doc2vec向量及其与各label的doc2vec中心向量的距离,取距离最邻近的label作为预测的label,得到待预测判决文书的罚金范围。本发明利用机械学习与大数据自动给出案件中责任人所处罚金的范围,提高办案效率,较少人力资源。</td>   <td>1.一种基于文档嵌入的长文本案件罚金范围分类预测方法,其特征在于,包括以下步骤：S1：对已知罚金金额的判决文书的罚金金额进行离散化处理,并根据罚金金额对已知罚金金额的判决文书标记不同的label；S2：对已知罚金金额的判决文书进行分词并去停用词处理；S3：将同一label下的已知罚金金额的判决文书拼接组合成一个文档,计算每个词在不同label下的文档中的TFIDF值,并按照每个词在不同文档中的TFIDF值的方差大小对词进行重要性排序；S4：取排序后top k个词作为关键词,对已知罚金金额的判决文书的词进行过滤,只保留是关键词的词；S5：利用过滤后的已知罚金金额的判决文书训练一个doc2vec模型,按照label计算对应的doc2vec中心向量；S6：对待预测的判决文书,计算其doc2vec向量及其与各label的doc2vec中心向量的欧式距离,取欧式距离最邻近的label作为其预测的label值,得到待预测的判决文书的罚金范围；所述步骤S5具体步骤如下：S5.1：对每一过滤后的已知罚金金额的判决文书新增一paragraph id1,并将其映射成一个paragraph vector向量,在训练过程中,paragraph id1保持不变,共享着同一个paragraph vector；S5.2：将每一个词映射成一个word vector向量,paragraph vector与word vector的维数一样,来自于两个不同的向量空间；S5.3：将paragraph vector和word vector累加或连接起来,作为输入；S5.4：输出该过滤后的已知罚金金额的判决文书的paragraph vector；S5.5：对于每个label下的过滤后的已知罚金金额的判决文书,将该label下所有paragraph vector的平均向量作为该label的doc2vec中心向量。</td>   <td>G06F16/35;G06F40/216;G06F40/289;G06F40/30;G06Q50/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈景宇;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络模型的嵌入式人群密度估计方法</td>   <td>广东省</td>   <td>CN109614941B</td>   <td>2023-02-03</td>   <td>本发明公开一种基于卷积神经网络模型的嵌入式人群密度估计方法及嵌入式人群密度估计的卷积神经网络模型,本模型用于实现本方法,本方法包括通过3个具有生成人群密度图输出能力的卷积神经分支的结构嵌套,使得模型具有3个运行模式,对训练图像预处理后,训练卷积神经网络模型,输入图像至训练好的卷积神经网络模型,选择三个运行模式的其中之一,输出所选模式对应的人群密度图,对所输出的密度图进行积分操作,获得对图像的总人数估计。本发明的卷积神经网络模型轻量化,准确度高于同量级卷积神经网络模型,部署三个模式可以任意切换,每个模式的速度不同,速度可根据实际情况选择。</td>   <td>1.一种基于卷积神经网络模型的嵌入式人群密度估计方法,其特征在于,包括如下步骤：S10嵌入3个运行模式：通过3个具有生成人群密度图输出能力的卷积神经分支的结构嵌套,使得卷积网络模型具有3个运行模式,其中所述3个运行模式所使用卷积网络模型的参数由低到高数量逐渐递增且能够进行复用；S20模型训练：对训练图像进行预处理,用激励函数δ(x-x-i)表示图像像素点的标注,生成图像的标记图将标记图与高斯核G-σ(x)进行卷积,获得对应的密度图真值F(x)＝H(x)*G-σ(x),x为密度图中的像素,σ表示高斯核G-σ(x)的标准差,使用预处理好的训练数据对所述卷积神经网络模型进行训练,其中使用密度图真值和模型输出密度图之间的欧氏距离作为网络训练的损失函数；S30输入图像至训练好的卷积神经网络模型,根据设备性能和速度要求,选择三个运行模式的其中之一,输出所选模式对应的人群密度图；S40对所输出的密度图进行积分操作,获得对图像的总人数估计；所述3个运行模式包括快速模式、平衡模式和精准模式,所述3个运行模式所利用的参数量由低到高逐层递增的方法具体为：快速模式利用源自原始图像的基础参数快速获取密度图,该密度图根据运算需要直接作为输出或者给平衡模式提供信息；平衡模式利用源自原始图像的基础参数和由快速模式获得的密度图的参数,并对其进行补充和修正；精准模式利用源自原始图像的基础参数、快速模式及平衡模式所获取的密度图的参数,并对其进行了补充和修正；所述卷积神经网络模型包括一个图像输入口和多个卷积神经分支,每个卷积神经分支均设有对应的图像输出口,每个卷积神经分支包括：高度和宽度相等的卷积核,其中卷积核的高和宽为1、3、5或7；高度和宽度均相等且高与宽相等步长的最大值池化层MP；用于提取每个特征图像平均值的全局平均池化层G-A-P；用于将所有的均值点连接起来形成的四个全连接层；由上述四个全连接层和每个全连接层各自的激活层叠加得到的缩放分支结构：FC(G-A-P)-R-FC(12)-R-FC(8)-R-FC(1)-T,其中FC为全连接层,R为ReLU激活层,T为Tanh激活层,每个括号内的数字为神经元的数量；每个卷积神经分支通过卷积层、MP层和激活层得到各自的特征图；通过假设Tanh激活层的输出为Δ,使用1+Δ作为缩放因子,对每个特征图进行缩放得到缩放后的特征图；每个缩放后的特征图根据模型模式的选择来决定作为输出或者是下个卷积神经分支的特征图像。</td>   <td>G06V20/52;G06V10/82;G06V10/94;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁琪伟;              陈龙;                   轩辕哲       </td>   <td>中山大学</td>   <td>一种基于轻量神经网络的实时目标检测系统及检测方法</td>   <td>广东省</td>   <td>CN109685017B</td>   <td>2023-02-03</td>   <td>本发明涉及无人驾驶的技术领域,更具体地,涉及一种基于轻量神经网络的超高速实时目标检测系统及检测方法。一种基于轻量神经网络的超高速实时目标检测系统,包括视频流数据采集模块、神经网络训练模块、图像处理与检测模块、检测结果反馈模块；本发明操作流程简单、易于实施、成本低、效率高。</td>   <td>1.一种基于轻量神经网络的实时目标检测系统,其特征在于,包括视频流数据采集模块、神经网络训练模块、图像处理与检测模块、检测结果反馈模块；视频流数据采集模块：采集车辆正前方道路的路况图像信息,将采集到的视频流以帧为单位通过数据线传输到图像处理与检测模块,供其进行下一步处理；神经网络训练模块：选定合适的轻量神经网络对需要检测的目标物体使用数据集进行调参,训练,最终生成相应的网络权重模型；利用验证数据集对模型进行评估与选择,并选择出最优的网络权重模型；使用测试数据集来测试选出的网络模型的识别精度,以测试误差作为泛化误差的近似；图像处理与检测模块：在嵌入式硬件平台上预先部署相应的轻量神经网络架构,并将在神经网络训练模块中训练得到的神经网络权重移植到本模块的硬件平台上；将视频流数据采集模块传输过来的图像送入轻量神经网络中,神经网络在权重文件的配置下对该图像进行物体种类识别和边框定位；检测结果将被输入检测结果反馈模块；检测结果反馈模块：在此模块中会将获得的检测结果通过输入输出设备以视频流的形式进行展示；其中,所述的神经网络训练模块中,在具有大显存,高计算能力的并行GPU计算平台上利用训练集对轻量神经网络进行快速迭代训练；从而尽快得到神经网络模型,再利用验证数据集验证得到最优的网络模型；将该神经网络和网络模型移植到图像处理与检测模块的嵌入式硬件平台,并将该硬件平台部署于无人车上,即可作为数据的中央处理单元。</td>   <td>G06V20/56;G06V10/764;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   蔡岳       </td>   <td>中山大学</td>   <td>一种基于文档嵌入的短文本虚假问题分类预测方法及装置</td>   <td>广东省</td>   <td>CN110472045B</td>   <td>2023-02-03</td>   <td>本发明公开一种基于文档嵌入的短文本虚假问题分类预测方法及装置,本装置用于实现本方法,本方法包括对在问答社区提取的问题文本样本集进行去差异化的预处理；将预处理后的问题文本样本集嵌入词库映射并重组获得每个问题文本的问题向量；对问题文本进行主题模型训练,计算获取问题TFIDF特征向量,采用NMF非负矩阵分解法近似分解问题TFIDF特征向量并求出最优问题-主题概率分布向量W；将问题TFIDF特征向量和最优问题-主题概率分布向量输入深度学习模型进行训练学习,获取语义-主题表征向量,非线性激活语义-主题表征向量以获取预测问题的分类概率值,根据预测问题的分类概率值判断问题的虚实分类。本发明提高问题文本的虚实过滤效率。</td>   <td>1.一种基于文档嵌入的短文本虚假问题分类预测方法,其特征在于,包括：S10对在问答社区提取的问题文本样本集进行去差异化的预处理；S20将预处理后的问题文本样本集嵌入词库映射,以获取每个单词对应的词向量,重组单词的词向量获得每个问题文本的问题向量；S30对问题文本进行主题模型训练,计算获取问题TFIDF特征向量,采用NMF非负矩阵分解法近似分解问题TFIDF特征向量并求出最优问题-主题概率分布向量W；S40将问题TFIDF特征向量和最优问题-主题概率分布向量输入深度学习模型进行训练学习,获取语义-主题表征向量,非线性激活语义-主题表征向量以获取预测问题的分类概率值,根据预测问题的分类概率值判断问题的虚实分类；所述深度学习模型包括问题嵌入层、长短期记忆层、主题特征输入层、第一线性层、连接层、第二线性层、非线性激活层和预测判断层,所述S40的具体步骤为：将问题向量通过问题嵌入层输入长短期记忆层LSTM,以根据问题的上下文内容提取问题文本的语义表征；将最优问题-主题概率分布向量W通过主题特征输入层输入第一线性层以提取问题-主题概率分布特征向量的高维特征,拼接问题文本的语义表征和问题-主题概率分布特征向量的高维特征得到语义-主题表征向量,将语义-主题表征向量输入第二线性层得到语义-主题表征矩阵；将语义-主题表征矩阵输入非线性激活层,非线性激活层利用非线性激活函数计算得到预测问题的分类概率值；若预测问题的分类概率值大于预定阈值,则判断该问题为虚假问题；反之,则判断该问题为正常问题。</td>   <td>G06F16/35;G06F40/30;G06F40/284;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何兆成;              罗良奎;                   朱依婷       </td>   <td>中山大学</td>   <td>一种交通期望线的边绑定以及评价方法</td>   <td>广东省</td>   <td>CN110598052B</td>   <td>2023-02-03</td>   <td>本发明涉及一种交通期望线的边绑定以及评价方法,具体的过程包括：通过利用摄像头拍摄经过各个道路交叉口的车辆信息得到车辆的行驶路径,将行驶路径的起点与终点统称为顶点,通过聚类算法从顶点中筛选出控制点；通过将控制点连接起来形成交通期望线,采用力引导模型将交通期望线进行绑定,并对对交通期望线绑定后的效果进行评价。本发明将顶点进行聚类,减少原始图输入的顶点数量,解决了边绑定技术方法在大规模交通数据集的应用难点。同时,本发明提出了边绑定的量化指标。基于像素灰度强度的差异,提取了边绑定前后图像的角点特征,结合交通数据的时间维度信息,提出图像变化强度,能够较好地反映绑定效果。</td>   <td>1.一种交通期望线的边绑定以及评价方法,其特征在于,包括以下步骤：步骤S1：利用摄像头拍摄经过各个道路交叉口的车辆信息,结合交通网路数据,得到关于车辆的交通信息；步骤S2：将拍摄到同一车牌的时间差最小的两个摄像头所在的道路交叉口之间的路段作为拥有该车牌的车辆的行驶路径,根据两个摄像头拍摄到车牌时间的早晚将两个摄像头标记为车辆行驶路径的起点与终点；步骤S3：将行驶路径的起点与终点统称为顶点,通过聚类算法对顶点进行筛选,将筛选后的顶点作为的控制点；步骤S4：将控制点连接起来形成交通期望线,采用力引导模型将交通期望线进行绑定；其具体步骤如下：利用线段连接控制点形成多条边,每条边即为交通期望线,力引导模型用于将两条边绑定在一起,两条被绑定在一起的边可在弹簧力和库仑力的作用下相互靠近；首先,对两条边能否被绑定在一起做出判断,具体的,采用边与边之间的兼容性指标来判断,若两条边的兼容性大于设定的阈值,则表示该两条边可被绑定在一起,兼容性指标通过图的结构以及边的几何特征来计算,具体计算方式如下：(1)基于图的结构：                  对于两条边P边以及Q边,N-(min)(P,Q)表示P边的任意一个端点,,到Q边任意一个端点的距离满足设定的最小距离,若两条边节点与节点之间满足要求的连线数量为0,则C-c(P,Q)为0；如果两条边公用一个顶点,则C-c(P,Q)为1；(2)基于边的几何特征,包括角度、长度、位置以及平行关系四个方面；其中每一个方面的计算方式如下：关于角度：c-a(P,Q)＝|cosα|c-a(P,Q)表示角度兼容性,α表示两条边形成的锐角；关于长度：                  c-l(P,Q)表示长度兼容性,l-P表示P边的长度,l-Q表示Q边的长度,l-(avg)表示P边和Q边的平均长度；关于位置：                  c-p(P,Q)表示位置兼容性,l-(avg)表示P边和Q边的平均长度,m-P表示P边的中点,m-Q表示Q边的中点；关于平行关系：                  c-v(P,Q)＝min(V(P,Q),V(Q,P))c-v(P,Q)表示平行关系兼容性,m-P表示P边的中点,m-I表示I边的中点,I表示Q边在P边上的投影；最后,兼容性的计算公式为：C＝C-c (P,Q)·c-a(P,Q)·c-l(P,Q)·c-p(P,Q)·c-v(P,Q)当C大于设定的阈值c时,则被计算的两条边适合被绑定在一起,此时每一条边都能找到和其兼容的边,形成边束,因此,每一个边束都有一条主边,以及若干条兼容性边；在一个束内,主边和兼容性边都被打断成若干个点,其中主边的每个点受到相邻点的弹簧力作用,与此同时受到对应位置的兼容性边断点的库仑力作用,计算公式如下为                                    其中p-k为P边上的第k个点；q-k为Q边上的第k个点；k-p为P边上相邻的两个断点之间的弹力系数；l-p为P边的长度；n为P边的数量；s为库伦力取得最大值时,两点之间的距离；K-c为库伦力常数；N为断点的数量；主边上的断点由于受到弹簧力和库仑力的综合作用,会在力的方向产生位移,给定移动的步长S,经过一次迭代之后,可以获得断点的新坐标,坐标更新公式如下为：                  其中,S为断点的移动步长；z为迭代顺序；每次迭代后,计算全局每一个束的主边上的断点p-k和兼容性边对应断点q-k的距离,它们的和用D表示,当前后两次迭代的距离和小于设定的阈值ε,即完成绑定；                  ΔD＝D～z-D～(z-1)≤ε；步骤S5：将绑定后的边进行渲染处理,得到SVG格式的图形；步骤S6：根据SVG格式的图形对交通期望线绑定后的效果进行评价。</td>   <td>G06V30/422;G06V10/44;G06V10/762;G06V10/774;G06T11/20;G06F16/29;G08G1/01;G08G1/017</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   吕启越       </td>   <td>中山大学</td>   <td>一种图像区域复制粘贴篡改检测方法</td>   <td>广东省</td>   <td>CN110599478B</td>   <td>2023-02-03</td>   <td>本发明提供的图像区域复制粘贴篡改检测方法,包括：从待测图像提取特征点；根据特征点的局部图像块强度顺序计算其LIOP特征；利用Delaunay三角剖分Bowyer-Watson算法对特征点进行处理,计算每个三角形的LIOP描述子；进行三角形匹配并计算匹配后的三角形邻域；保留在三角形邻域内的特征点,形成特征点集合；生成特征点匹配对,并对特征点匹配对进行聚类,得到多个类别；计算每个类别的仿射矩阵；根据特征点匹配对和对应的仿射矩阵,计算对应区域变换前后的相关系数图,定位篡改区域。本发明提供的篡改检测方法,对旋转、缩放、JPEG压缩、添加噪声等具有更好的鲁棒性；速度快,实用性更强；便于更精确仿射变换矩阵,对匹配对的聚类操作能够应对多重复制的篡改操作。</td>   <td>1.一种图像区域复制粘贴篡改检测方法,其特征在于,包括以下步骤：S1：对待测图像进行预处理得到特征点,从而得到待提取特征的局部图像块；具体包括以下步骤：S11：对待测图像在相同核大小,不同的标准差下做高斯滤波得到不同的图像；S12：对相邻的滤波图像做差值运算得到一系列的差值图像,在标记各差值图像中统一的极值点作为特征点；S13：根据得到的特征点,用高斯滤波除去噪声,将其邻近的检测区域规范化处理为固定直径的圆形区域；S14：使用标准差不同于前者的高斯平滑去除规范化处理中差值操作产生的噪声,得到待提取特征的局部图像块；S2：将局部图像块根据像素强度进行子区域划分,计算每个像素点的局部强度顺序特征,得到对应特征点的LIOP特征；具体包括以下步骤：S21：将局部图像块根据像素强度升序为若干B个子区域,每个子区域具有相同的像素个数；S22：对每个子区域的各个像素点邻域进行像素采样,计算每个像素点的局部强度顺序特征；S23：将所有局部强度顺序特征进行相加,得到该子区域的LIOP描述子；S24：将所有子区域的LIOP描述子按顺序排列,得到对应特征点的LIOP特征；S3：利用Delaunay三角剖分Bowyer-Watson算法对特征点进行处理,生成Delaunay三角网,并分别计算每个三角形的三个顶点的LIOP描述子的平均值作为对应三角形的特征向量；S4：根据每个三角形的特征向量进行三角形匹配并计算匹配后的三角形邻域；具体包括以下步骤：S41：计算每个三角形特征与其他所有特征向量之间的欧式距离,并按照从小到达排序；S42：计算最近邻d-1和次近邻d-2之间的比值,如果比值小于0.6,则距离为d-1的两个特征匹配,并将d-2作为最近邻,计算与其次近邻d-3之间的比值,同样做阈值比较,直至比值大于0.6；S43：将重复的三角形匹配对和三角形内切圆圆心距离小于20的匹配对删除；S44：在每个匹配完毕的三角形附近计算三角形邻域,构建邻近方形区域组成区域集合；S5：判断对应的特征点是否位于三角形邻域内；若是,执行步骤S6；否则,丢弃该特征点及对应的LIOP特征；S6：保留该特征点及对应的LIOP特征,形成特征点集合；S7：根据特征点集合进行特征点匹配,生成特征点匹配对,并对特征点匹配对进行聚类,得到多个类别；具体包括以下步骤：S71：根据特征点集合,计算每个特征点与其他所有特征点之间的欧式距离,并按照从小到大排序；S72：计算最近d-1和次近邻d-2之间的比值,如果比值小于0.9,则距离为d-1的两个特征描述相匹配,并将d-2作为最近邻,计算与其次近邻d-3之间的比值,同样做阈值比较,直至比值大于0.9；S73：将重复的特征点匹配和坐标距离小于20的匹配对删除,完成特征点的匹配；S74：对特征点匹配对进行统一的角度调整,具体为：对于任意匹配对{(x-(1i),y-(1i)),(x-(2i),y-(2i))},其差值向量定义为：d-i＝(d-(xi),d-(yi))＝(x-(1i)-x-(2i),y-(1i)-y-(2i))匹配对的角度a-i定义为向量d-i与x轴正方向的夹角,其范围为[-π,π],对于匹配对{(x-(1i),y-(1i)),(x-(2i),y-(2i))},若其角度a-i＜0,则将匹配对进行逆转,即将{(x-(1i),y-(1i)),(x-(2i),y-(2i))}改为{(x-(2i),y-(2i)),(x-(1i),y-(1i))}；S75：将特征点匹配对的两个点坐标及其差值组成该特征点匹配对的特征向量,记为：(x-1,y-1,x-2,y-2,x-1-x-2,y-1-y-2),将特征点匹配对的所有特征向量作为分类依据,进行DBSCAN聚类,得到K个类；S8：计算每个类别的仿射矩阵；S9：根据特征点匹配对和对应的仿射矩阵,计算对应区域变换前后的相关系数图,定位篡改区域；S10：判断所有类是否计算完毕,若是,合并所有类的篡改区域作为检测结果；否则,执行步骤S9。</td>   <td>G06T7/00;G06T7/11;G06T5/00;G06V10/46;G06V10/44;G06V10/762;G06V10/75</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   曾令雯       </td>   <td>中山大学</td>   <td>一种半色调图像隐写分析方法</td>   <td>广东省</td>   <td>CN110619594B</td>   <td>2023-02-03</td>   <td>本发明提供的一种半色调图像隐写分析方法,包括：构造隐写图片,得到模拟的隐写图像数据集；确定模式块大小,统计模拟的隐写图像数据集中每张图片的模式块的直方图特征；根据模式块的直方图特征空间,对所有图像特征进行降维并构造变换矩阵；从数据集构造训练集和测试集,提取训练集、测试集图像模式块的直方图特征,利用变换矩阵计算训练集特征向量,输入SVM中进行分析模型的训练；将测试集特征向量输入到训练好的分析模型中,完成对图像隐写的分析。本发明提供的图像隐写分析方法,在选择大小合适的模式块的同时,采用PCA进行降维,对隐写的主要特征成分进行提取,降低特征维度,保持了更多的有效特征从而提高检测的准确率。</td>   <td>1.一种半色调图像隐写分析方法,其特征在于,包括以下步骤：S1：使用模拟嵌入的方法来构造M张隐写图片,得到一个模拟的隐写图像数据集,其中包含2M张图片；S2：确定模式块大小,统计模拟的隐写图像数据集中每张图片的模式块的直方图特征,得到模式块的直方图特征空间；具体包括以下步骤：S21：选取一个4*4的模式块大小,计算图像4*4模式块直方图特征,在半色调图像中,4*4模式块共有2～(16)种模式,对不同模式进行编号,某个4*4大小的模式块编号就等于该模式块内像素值矩阵和一个4*4的卷积核对图像进行卷积计算得到的值,卷积核W具体定义为：                  因此对于整幅图像X,使用卷积核W进行卷积运算,卷积计算移动步长为1,不对边界进行扩展,得到图像X中所有4*4模式块的编号矩阵M-1,具体表达式为：M-1＝X*WS22：对于一张图片初始化一个65536维的向量F,遍历图片对应编号矩阵M-1中的每个元素,第i个元素值为v,则在向量F中第v个位置的值加一,最终得到一张图像65536维直方图特征F＝(x-1,x-2,x-3,…,x-(65536))；对模拟的隐写图像数据集D中每一张图片都提取这样一个直方图特征；S3：根据模式块的直方图特征空间,采用PCA降维方法对所有图像特征进行降维并构造变换矩阵；使用PCA对特征进行降维过程具体为：对模拟嵌入的隐写图像数据集D中的特征进行归一化处理,数据集D中一共有2*M张图片的每一个维度特征进行归一化处理：                  数据集D中整体样本特征空间可以表示成F＝(F-1,F-2,...,F-(2*M)),计算该样本特征空间的协方差矩阵C:                  计算协方差矩阵C的特征值以及它对应的特征向量,将它的特征向量根据特征值的从大到小的排列,选取前k行构造一个变换矩阵P；对于每一张图片提取的特征均可以通过变换矩阵P进行变换得到新特征F',其中F'＝PF,F'为筛选后的特征；S4：从数据集构造训练集,提取训练集图像模式块的直方图特征,利用变换矩阵计算训练集特征向量,输入SVM中进行分析模型的训练；S5：从数据集构造测试集,提取测试集图像模式块的直方图特征,利用变换矩阵计算测试集特征向量,将测试集特征向量输入到训练好的分析模型中,完成对图像隐写的分析。</td>   <td>G06T1/00;G06V10/50;G06V10/77;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘智勇;              陈晓宏;              谢宇莹;              林凯荣;              涂新军;                   张清涛       </td>   <td>中山大学</td>   <td>一种旱涝急转风险评估方法</td>   <td>广东省</td>   <td>CN111680912B</td>   <td>2023-02-03</td>   <td>本发明公开了一种旱涝急转风险评估方法,其以水文气象变量的为基础,计算其连续N个时间段的平均时间序列为P-t,再从中提取滞后一个N时间段的时间序列为P-(t-1),然后根据时间序列P-t和P-(t-1),利用阈值水平法确定干旱和洪涝的阈值,此时基于copula联合分布函数,构建P-t和P-(t-1)之间的联合概率分布函数,并进一步构建P-t和P-(t-1)之间的旱转涝和涝转旱的条件分布函数模型,以实现对旱转涝和涝转旱的风险概率评估；即通过上述方式建立模型后,旱涝急转风险评估方法能有效地评估某一地区某一时期发生旱转涝灾害的可能性,也可以根据未来模拟预测的气象数据,预测未来气候情景下该地区发生此类风险的可能性,从而为抵抗旱涝灾害和风险管理决策提供准确可靠的依据。</td>   <td>1.一种旱涝急转风险评估方法,其特征在于,包括以下步骤：S1,对于某水文气象变量,计算其连续N个时间内的平均时间序列为P-t,提取滞后一个N时间段的时间序列P-(t-1),其中所述P-t为旱涝急转事件的第一个时间序列,所述P-(t-1)为旱涝急转事件的第二个时间序列；在所述S1中,所述水文气象变量包括降雨量、径流、水位和土壤湿度,所述时间段的单位包括小时、日、月和年；S2,定义干旱和洪涝,即根据时间序列所述P-t和所述P-(t-1),利用阈值水平法确定干旱和洪涝的阈值；在所述S2中,对所述P-t和所述P-(t-1)分别拟合一个边缘分布,用极大似然法估计各分布参数,并根据卡方拟合优度检验选择最优的分布,以最优分布的10％～30％和70％～90％分位数阈值来确定旱涝情况,即所述水文气象变量小于10％～30％分位数阈值则认为其是干旱情况,所述水文气象变量大于70％～90％分位数阈值则认为是洪涝情况；S3,基于copula联合分布函数,构建所述P-t和所述P-(t-1)之间的联合概率分布函数；在所述S3中,构建所述P-t和所述P-(t-1)之间的联合概率分布函数,所述P-t和所述P-(t-1)对应的二维联合概率分布函数为：F(x-1,x-2)＝C(F-(X1)(x-1),F-(X2)(x-2))＝C(u-1,u-2)；所述F-(X1)(x-1)和所述F-(X2)(x-2)分别代表所述P-t和所述P-(t-1)的边缘分布函数,所述u-1和所述u-2分别代表所述x-1和所述x-2的累积分布函数,所述C为copula函数；S4,基于构建的联合概率分布函数,进一步构建所述P-t和所述P-(t-1)之间的旱转涝和涝转旱的条件分布函数模型,以实现对旱转涝和涝转旱的风险概率评估；在所述S4中,分别构建旱转涝和涝转旱的条件概率分布模型；对于旱转涝的情况,在给定X-1≤x-1条件下,X-2&gt;x-2的概率表示为：F(X-2＞x-2|X-1≤x-1)＝1-C(u-1,u-2)/u-1；对于涝转旱情况,在给定X-1&gt;x-1条件下,X-2≤x-2的概率表示为：F(X-2≤x-2|X-1＞x-1)＝(u-1-C(u-1,u-2))/(1-u-1)；所述x-1和x-2分别指所述P-t和所述P-(t-1)中确定的干旱和洪涝阈值。</td>   <td>G06Q10/0635;G06Q50/26;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈定安;              陈明薇;              罗明;                   王先伟       </td>   <td>中山大学</td>   <td>一种基于LiDAR点云的电塔受灾风险评估方法及系统</td>   <td>广东省</td>   <td>CN112132795B</td>   <td>2023-02-03</td>   <td>本发明公开了一种基于LiDAR点云的电塔受灾风险评估方法及系统,该方法包括：获取LiDAR的3D点云数据并提取得到电塔点云；根据数字高程模型获取对应区域的地形控制指数并对地形控制指数进行分级,结合电塔点云得到位于不同灾害级别区域的电塔；获取电塔参数并分别计算不同灾害级别区域的电塔风险指数；根据地形控制指数和电塔风险指数生成电塔受灾风险评估分析图。该系统包括：点云处理模块、地形控制指数模块、电塔风险指数模块和分析模块。通过使用本发明,可使输电塔的相对抗洪灾性能可以客观地被观测、评估和分析。本发明作为一种基于LiDAR点云的电塔受灾风险评估方法及系统,可广泛应用于地理信息科学技术领域。</td>   <td>1.一种基于LiDAR点云的电塔受灾风险评估方法,其特征在于,包括以下步骤：获取LiDAR的3D点云数据并将整体点云分块,得到多块点云；对每块点云都进行网格化处理并分配网格值；根据预设规则删除部分网格,保留高程在Z轴上连续的网格并得到包含电塔的网格；所述根据预设规则删除部分网格具体为保留最大海拔高度减去最小海拔高度在给定阈值内的网格,并在剩余的网格中删除带有悬挂点集的网格；基于聚类算法粗略识别区域的点云数据,得到整个区域的特征点云集；从特征点云集中获取特征点云数据并根据高度进行分层,得到高度切片集；从高度切片集中取出包含塔身高度部分的切片集；根据包含塔身高度部分的切片集计算不同高程切片的中心点集；对中心点集进行直线拟合处理并计算得到对应斜率；根据高度切片集和中心点集得到塔的边缘位置和距中心点的距离；根据塔的边缘位置和距中心点的距离计算对应于两个边缘之间相同边缘的两个点之间的斜率并得到所有斜率在设定阈值内的特征点云；从斜率在设定阈值内的特征点云中提取得到具有电塔特征的点云；根据数字高程模型获取对应区域的地形控制指数并对地形控制指数进行分级,结合电塔点云得到位于不同灾害级别区域的电塔；获取电塔塔身和塔腿的数据参数并基于最小二乘法拟合正方椎体三维模型；拟合模型公式如下,                                                      具体地,R-0是从顶点到XY平面上的平截头体的平方中点的距离,即Z＝0,即对角线的一半长度,k是梯度因子,表示方形棱锥边缘的倾斜度,R-1,R-2,和R-3分别代表旋转矩阵,q是象限数,θ是初始位置中与XY平面上的X轴的夹角；根据正方锥体三维模型计算塔身倾斜度、塔腿倾斜度和塔身与塔腿间的倾斜度差；根据塔身倾斜度、塔腿倾斜度和塔身与塔腿间的倾斜度差计算得到不同灾害级别区域的电塔风险指数；所述电塔风险指数的表达式如下,                  上式中,H-t是电塔的高度,α是塔腿倾斜度,γ是塔身与塔腿间的倾斜度差,S-t是基于塔所在网格单元中数字高程模型的坡度,W是塔腿的根开；根据地形控制指数和电塔风险指数生成电塔受灾风险评估分析图。</td>   <td>G06T7/00;G06V10/762;G06T7/11;G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         古博;              束嘉乐;                   姜善成       </td>   <td>中山大学</td>   <td>基于时空注意力机制的电力负荷预测方法、装置及介质</td>   <td>广东省</td>   <td>CN113610277B</td>   <td>2023-02-03</td>   <td>本发明公开了一种基于时空注意力机制的电力负荷预测方法、装置及存储介质,该方法包括获取电力负荷数据；然后利用训练好的图时空注意力网络模型接收电力负荷数据并进行处理；最后获取训练好的图时空注意力网络模型输出的预测结果；本发明通过训练好的图时空注意力网络模型进行预测,不仅可以捕捉时间相关性,同时还可以捕捉动态空间相关性,从而能够显著提高电力负荷的预测精度。本发明可广泛应用于电力负荷预测技术领域。</td>   <td>1.一种基于时空注意力机制的电力负荷预测方法,其特征在于,包括：获取电力负荷数据；利用训练好的图时空注意力网络模型接收所述电力负荷数据并进行处理；获取所述训练好的图时空注意力网络模型输出的预测结果；构建图时空注意力网络模型,所述图时空注意力网络模型包括空间关系图建立模块、时空编码模块、时空注意力模块和转换注意力模块；所述空间关系图建立模块用于通过动态时间扭曲算法构建稀疏空间关系图,以捕捉用户之间的空间相关性；所述时空编码模块用于将节点的时间和空间信息进行编码输入到所述图时空注意力网络模型中；所述时空注意力模块包括空间注意力机制、时间注意力机制和门控融合机制,所述空间注意力机制用于捕捉邻居节点之间的相关性,所述时间注意力机制用于捕捉不同时间步长之间的时间相关性,所述门控融合机制用于控制每个节点在时间步长上的时空关联；所述转换注意力模块用于对每个未来时间步长和每个历史时间步长之间的关系进行建模,以转换编码的电力负荷特征。</td>   <td>G06Q10/04;G06Q50/06;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李超峰;              陈浩华;              经秉中;              邓一术;                   孙颖       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种多边形优化、多边形数据处理方法及装置</td>   <td>广东省</td>   <td>CN115690133A</td>   <td>2023-02-03</td>   <td>本发明公开了一种多边形优化、多边形数据处理方法及装置,包括：根据预设的第一过滤阈值对第一多边形的小面积碎片进行过滤；所述第一多边形包括若干子多边形；根据无损压缩和有损压缩相结合,对过滤后的第一多边形点数进行压缩；提取压缩后的第一多边形的连通域,分离多边形的自相交环,并根据所述连通域的外轮廓形成第二多边形。本发明先过滤小面积碎片,再对多边形点数进行压缩,最后分离多边形自相交换的形式。通过固定的最优的修复流程,剔除了多边形优化过程中的无效数据提高优化效率,同时,避免了在优化多边形数据过程中,对某一项数据进行修复时容易产生另一项非法数据和无效数据的问题,提高多边形优化效果。</td>   <td>1.一种多边形优化方法,其特征在于,包括：根据预设的第一过滤阈值对第一多边形的小面积碎片进行过滤；所述第一多边形包括若干子多边形；根据无损压缩和有损压缩相结合,对过滤后的第一多边形点数进行压缩；提取压缩后的第一多边形的连通域,分离多边形的自相交环,并根据所述连通域的外轮廓形成第二多边形。</td>   <td>G06T7/12;G06T7/187</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘丙军;              邱江潮;              谭学志;              彭为;                   杨子博       </td>   <td>中山大学</td>   <td>一种基于贝叶斯理论的天然河道水位流量关系确定方法</td>   <td>广东省</td>   <td>CN109635435B</td>   <td>2023-01-31</td>   <td>本发明涉及水利工程水文测验技术领域,更具体地,涉及一种基于贝叶斯理论的天然河道水位流量关系确定方法。包括以下步骤：基于水流运动规律,通过分析水文测站水力学属性和几何属性,建立水位流量关系模型；考虑测量误差和拟合误差计算实测流量的似然函数；基于贝叶斯理论,根据参数实际物理意义构造参数的先验分布；通过设计的自适应MCMC算法求解参数的后验分布。本发明建立的水位流量关系模型的参数物理意义明确,误差来源清晰,最大化利用了参数已有信息和样本信息,模拟求解效率较高。</td>   <td>1.一种基于贝叶斯理论的天然河道水位流量关系确定方法,其特征在于,包括以下步骤：S1.建立水位流量关系模型：Q＝a(H-b)～c式中,Q为流量,H为水位,a为系数,c为指数,b为零流水位；S2.似然函数计算；水位流量数据为成对出现的离散型随机变量,为单一对应关系,不考虑复杂绳套关系,且点对相互独立,则似然函数表示参数一定时水位流量点对数据被观测到的概率；由此可建立似然函数的一般表达式：                  式中,D为水位流量实测数据,共有N对,其中为实测水位,为实测流量；θ为参数集,θ＝(θ-(RC),γ),包括水力学参数θ-(RC)和误差参数γ,其中水力学参数为幂函数水位流量关系模型中的参数,有θ-(RC)＝(a,b,c)；S3.先验分布构造；用概率密度函数对参数集θ进行表示,利用实测水位流量数据以外的已有信息确定各参数分布形式；假定各参数彼此独立,则参数集先验分布的联合分布形式可表示为：                  式中,p(θ)为参数集的联合分布,其中p(a)、p(b)、p(c)为3个水力学参数的先验分布,p(γ-i)为误差参数的先验分布,m为误差参数的数量；S4.后验分布求解；根据S1步骤、S2步骤、S2步骤D中的表达式,基于贝叶斯公式,得到参数集θ后验分布的表达式：                  式中,为后验分布的概率密度函数；为似然函数；p(θ)为先验分布；为边际分布,与参数无关；最后,通过设计自适应马尔科夫链蒙特卡罗算法,求解参数集θ的后验分布。</td>   <td>G06F30/20;G06F30/28;G06F113/08;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭力;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于文章和标题动态融合的摘要提取方法及系统</td>   <td>广东省</td>   <td>CN112417865B</td>   <td>2023-01-31</td>   <td>本发明公开了一种基于文章和标题动态融合的摘要提取方法及系统,该方法包括：S1、获取数据集并对数据集中的文章和标题进行预处理,得到文章向量和标题向量；S2、以标题向量为指引计算文章向量句子的分值并选择部分句子与标题向量动态融合,得到融合向量；S3、将融合向量替换标题向量重新执行步骤S2直至达到预设循环次数,输出最终融合向量；S4、根据最终融合向量计算句子概率分布并按预设规则选择摘要句,得到文章摘要。该系统包括：预处理模块、动态融合与交互模块和预测与选择模块。本发明提高了最终提取摘要的精确性。本发明作为一种基于文章和标题动态融合的摘要提取方法及系统,可广泛应用于文本摘要提取领域。</td>   <td>1.一种基于文章和标题动态融合的摘要提取方法,其特征在于,包括以下步骤：S1、获取数据集并对数据集中的文章和标题进行预处理,得到文章向量和标题向量；S2.1、以标题向量为指引,并基于多头注意力机制学习向量之间的相关性,得到句子间的语义关系；S2.2、根据句子间的语义关系,采用线性映射和sigmoid函数计算文章向量中句子的分数值；计算文章向量中句子的分数值的具体计算公式如下,                  上式中,G～l表示第l层经过动态融合后文章各句子向量,表示第l层中文章各句子经过线性映射所得的分数值,和b～l分别是可学习的参数；S2.3、根据分数值排名,得到待融合向量和对应的分数值；S2.4、计算待融合向量中对应的句子的重要性比重,并转换为文章高级抽象表征；S2.5、将文章高级抽象表征与标题向量动态融合,得到融合向量；S3、将融合向量替换标题向量重新执行步骤S2直至达到预设循环次数,输出最终融合向量；S4、根据最终融合向量计算句子概率分布并按预设规则选择摘要句,得到文章摘要。</td>   <td>G06F40/289;G06F40/30;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡吉涵;                   胡建芳       </td>   <td>中山大学</td>   <td>用于智能人机交互的行为早期识别方法、系统及存储介质</td>   <td>广东省</td>   <td>CN112464861B</td>   <td>2023-01-31</td>   <td>本发明公开了一种用于智能人机交互的行为早期识别方法、系统及存储介质,方法包括：将视频流转化为图像帧；将图片帧转输入卷积神经网络提取特征,得到动作特征序列；将动作特征序列F输入到行为预测模型进行计算：首先利用多头注意力机制输出与动作特征序列F维度相同的向量,将该向量输入前馈神经网络中计算,将上述过程标记为EL Layer,经过L层的堆叠就形成了Transformer Encoder的编码过程；接着将编码结果输入到分类器中计算得到代表分类结果的概率向量；最后取最晚观测时刻对应的输出向量中概率最大的分类作为预测结果。本发明的方法利用时间维度上距离较远的信息之间的交互信息增强模型的表现力；同时,使用行为早期识别技术提前预测出动作分类可以提高交互系统的用户体验。</td>   <td>1.用于智能人机交互的行为早期识别方法,其特征在于,包括下述步骤：将视频流转化为图片帧；将图片帧转输入卷积神经网络提取特征,得到动作特征序列；将动作特征序列F输入到行为预测模型进行计算,所述行为预测模型包括TransformerEncoder计算过程和分类器的计算过程；所述Transformer Encoder计算过程为：利用多头注意力机制输出与动作特征序列F维度相同的向量,将该向量输入前馈神经网络中计算,将前述计算层记为EL Layer,每一层ELLayer的输出维度和原来输入的动作特征序列F维度大小相同,并将该输出作为下一层ELLayer的输入,经过L层的堆叠就形成了Transformer Encoder的编码过程；所述Transformer Encoder计算过程中,所述多头注意力机制采用内积形式的计算方式,给定查询Q,关键字K,值V,则注意力机制的计算公式为：                  其中,d-k为关键字K的特征维度；对动作特征序列F使用多个投影矩阵,最后将多个投影矩阵连结,具体方法如下：MultiHead(Q,K,V)＝Concat(head-1,head-2,…,head-h)W～o其中,每一个head的计算方法如下：head-i＝Attention(QW-i～q,KW-i～K,VW-i～V)输入序列Q、K、V的特征维度大小为d,投影矩阵为了降低计算量使得多头注意力机制和前文的自注意力机制的计算量相同,投影矩阵维度满足d-k＝d-v＝d/h；在计算过程中,Q,K,V矩阵初始化为动作特征序列F组成的列数为n的矩阵,即：Q＝K＝V＝F由于行为早期识别任务的特殊性,即最终不同观测率下的分类结果只能依赖于当前观测率下获取的信息,因此在该场景下为Transformer Encoder引入预测掩膜,具体为一个二维矩阵M满足以下公式：                  其中,i和j对应矩阵M的行和列；此时每一个head的计算要额外加上矩阵M,即：                  多头注意力机制的输出与原来输入的F维度相同,记该输出向量为X＝[x-1,x-2,…,x-n],将向量输入一个前馈神经网络中,该前馈神经网络包括两个线性层和一个Relu函数,计算方法如下：FFN(x-i)＝Relu(x-iW-1+b-1)W-2+b-2将上述的MultiHead操作和FFN操作合并记为EL Layer,在实际使用的过程中加上残差模块和层归一化,得到每一层EL Layer的输出维度和原来输入的F维度大小相同,将该输出作为下一层EL Layer的输入,经过L层的堆叠就形成了Transformer Encoder的编码过程,将编码结果记为H＝[h-1,h-2,…,h-n]；在上述计算过程中,由于抛弃了传统RNN的迭代式计算,在以上的计算过程中并没有加入输入序列的位置信息,因此Transformer在输入时还加入了位置编码,即在TransformerEncoder输入时对输入特征序列额外加入以下信息做位置编码：PE-((n,2i))＝sin(n/1000～(2i/d))PE-((n,2i+1))＝cos(n/1000～(2i+1/d))其中n为输入F的第n列,2i与2i+1表示对应特征向量的某一维度,则输入编码器的F经过位置编码后为：                  所述分类器的计算过程为：将编码结果输入到分类器中计算得到代表分类结果的概率向量,所述概率向量代表某一观测时刻对应观测结果的行为早期识别结果；取最晚一个观测时刻对应的输出向量中概率最大的分类作为预测结果。</td>   <td>G06V20/40;G06V10/764;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              杨明坤;              王杰;              林彬;                   钟立军       </td>   <td>中山大学</td>   <td>一种基于深度学习的封装芯片缺陷检测方法</td>   <td>广东省</td>   <td>CN113362306B</td>   <td>2023-01-31</td>   <td>本发明公开了一种基于深度学习的封装芯片缺陷检测方法,包括：对封装芯片的X射线图像进行降噪处理；对X射线图像进行图像分割,提取具有封装芯片的测试图像；基于模板匹配得到测试图像中芯片的密封圈内外边缘；建立训练数据集与目标检测模型,对目标检测网络进行训练；基于训练后的目标检测模型对测试图像进行检测,得到测试图像中缺陷区域对应的检测框；基于区域生长对检测框进行精定位修正；基于密封圈内外边缘与检测框的最短路径对芯片进行合格性判定。深入研究了以深度学习视觉检测技术为代表的计算机视觉技术,研制出电子元器件X射线检查气泡缺陷自动识别方法,解决了军工电子元器件质量检测的迫切需求。</td>   <td>1.一种基于深度学习的封装芯片缺陷检测方法,其特征在于,包括如下步骤：步骤1,获取封装芯片的X射线图像,并对其进行降噪处理；步骤2,对降噪处理后的X射线图像进行图像分割,提取具有封装芯片的测试图像；步骤3,基于模板匹配得到测试图像中芯片的密封圈内外边缘；步骤4,建立训练数据集与目标检测模型,并基于训练数据集对目标检测网络进行训练；步骤5,基于训练后的目标检测模型对测试图像进行检测,得到测试图像中缺陷区域对应的检测框；步骤6,基于区域生长对检测框进行精定位修正；步骤7,基于密封圈内外边缘与检测框的最短路径对芯片进行合格性判定,所述合格性判定具体为：以外封闭圈为起点、内封闭圈为终点,以各检测框自身为根节点,得到各检测框的最短路径,其中,检测框内部的距离默认为0；若所有检测框的最短路径中的最小值小于外封闭圈与内封闭圈之间距离的15％,则判定为不合格,反之则认定为合格。</td>   <td>G06T7/00;G06N3/0464;G06N3/08;G06T5/00;G06T7/11;G06T7/12;G06T7/181</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈川;              廖天驰;              陈鸿;              林昊;              郑子彬;              王福海;                   刘伟       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>文本分类方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115658899A</td>   <td>2023-01-31</td>   <td>本申请涉及一种文本分类方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取目标文本,将目标文本输入目标文本分类模型；通过目标文本分类模型,对目标文本进行文本特征提取,得到初始文本特征；通过目标文本分类模型,基于初始文本特征,构造目标文本的各单词之间的关联度,得到初始结构特征；通过目标文本分类模型,对初始文本特征和初始结构特征进行特征聚合,得到初始聚合特征；基于初始聚合特征输出目标文本对应的文本分类结果。采用本方法能够提高文本分类的准确性。</td>   <td>1.一种文本分类方法,其特征在于,所述方法包括：获取目标文本,将所述目标文本输入目标文本分类模型；通过所述目标文本分类模型,对所述目标文本进行文本特征提取,得到初始文本特征；通过所述目标文本分类模型,基于所述初始文本特征,构造所述目标文本的各单词之间的关联度,得到初始结构特征；通过所述目标文本分类模型,对所述初始文本特征和所述初始结构特征进行特征聚合,得到初始聚合特征；基于所述初始聚合特征输出所述目标文本对应的文本分类结果。</td>   <td>G06F16/35;G06F40/30;G06F18/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐英刚;              林瑶英;              谢康;              肖静华;                   邹波       </td>   <td>广东美云智数科技有限公司;中山大学</td>   <td>汽车知识图谱的应用方法及装置</td>   <td>广东省</td>   <td>CN115658909A</td>   <td>2023-01-31</td>   <td>本发明涉及人工智能技术领域,提供一种汽车知识图谱的应用方法及装置。所述方法包括：获取查询请求；所述查询请求包括汽车行业领域的待查询实体信息以及待查询关系信息中的至少一项；在汽车知识图谱中对所述查询请求进行匹配,得到与所述待查询实体或待查询关系相关联的目标三元组数据；根据与所述待查询实体或待查询关系相关联的目标三元组数据,生成目标信息,并输出所述目标信息；其中,所述汽车知识图谱是基于目标三元组数据构建的,每一目标三元组数据包括汽车行业领域的两个不同实体,以及所述两个不同实体之间的关系。本发明实施例提供的汽车知识图谱的应用方法及装置,可以为汽车行业的产品迭代创新提供知识输入,从而提高创新的成功率。</td>   <td>1.一种汽车知识图谱的应用方法,其特征在于,包括：获取查询请求；所述查询请求包括汽车行业领域的待查询实体信息以及待查询关系信息中的至少一项；在汽车知识图谱中对所述查询请求进行匹配,得到与所述待查询实体或待查询关系相关联的目标三元组数据；根据与所述待查询实体或待查询关系相关联的目标三元组数据,生成目标信息,并输出所述目标信息；其中,所述汽车知识图谱是基于目标三元组数据构建的,每一目标三元组数据包括汽车行业领域的两个不同实体,以及所述两个不同实体之间的关系。</td>   <td>G06F16/36;G06F16/35;G06F16/33;G06F40/295;G06F40/30;G06F40/211;G06N3/0464;G06N3/0442;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈亮;              张雨欣;              周克涌;              钟婧;              张秋銮;              李军;              郑子彬;                   王耀南       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>产品推送方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115659005A</td>   <td>2023-01-31</td>   <td>本申请涉及一种产品推送方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取多个用户标识的用户信息和多个产品标识的产品信息；基于所述用户信息和所述产品信息,构建包括用户节点、产品子节点和产品节点的异质图；对所述异质图进行特征提取,得到所述用户节点对应的用户目标特征向量和所述产品节点对应的产品目标特征向量；计算所述用户目标特征向量和所述产品目标特征向量之间的相似度,基于所述相似度确定所述多个用户标识中每个用户标识对应的待推送产品标识,所述待推送产品标识用于推送给对应的用户标识。采用本方法能够提高产品推送的精确性。</td>   <td>1.一种产品推送方法,其特征在于,所述方法包括：获取多个用户标识的用户信息和多个产品标识的产品信息；基于所述用户信息和所述产品信息,构建包括用户节点、产品子节点和产品节点的异质图；对所述异质图进行特征提取,得到所述用户节点对应的用户目标特征向量和所述产品节点对应的产品目标特征向量；计算所述用户目标特征向量和所述产品目标特征向量之间的相似度,基于所述相似度确定所述多个用户标识中每个用户标识对应的待推送产品标识,所述待推送产品标识用于推送给对应的用户标识。</td>   <td>G06F16/9535;G06F16/9537;G06Q30/06;G06F18/24;G06F18/25;G06F18/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              刘小慧;              周克涌;              蔡倬;              张鹏;                   王福海       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>资源推送数据处理方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115659022A</td>   <td>2023-01-31</td>   <td>本申请涉及一种资源推送数据处理方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：对获取的对象集合对应的资源关联信息提取特征；通过决策树将对象集合中各个对象分类,获取群体类别对应的历史资源数据并生成不同层次的候选项集,基于预设发生参数和不同层次的候选项集的历史发生参数的对比结果,对候选项集进行筛选得到群体类别对应的目标频繁项集并将其对应的每个非空真子集进行排列组合形成对应的项关联关系,基于项关联关系对应的置信参数和预设置信参数的对比结果,得到并存储群体类别及其对应的目标项关联关系,最后推送关联的资源数据到终端。采用本方法能够提高资源数据的利用率。</td>   <td>1.一种资源推送数据处理方法,其特征在于,所述方法包括：获取对象集合对应的资源关联信息,进行特征提取得到对应资源关联特征；基于所述资源关联特征和资源关联信息,通过决策树将所述对象集合中的各个对象分为对应的群体类别；获取群体类别对应的历史资源数据,基于历史资源数据生成多个不同层次的候选项集,基于预设发生参数和每种不同层次的候选项集的历史发生参数的对比结果,对候选项集进行筛选得到群体类别对应的目标频繁项集；对群体类别对应的目标频繁项集所对应的每个非空真子集进行排列组合形成对应的项关联关系,基于项关联关系对应的置信参数和预设置信参数的对比结果,得到群体类别对应的目标项关联关系；存储所述群体类别和对应的目标项关联关系,所述目标项关联关系用于向对应的群体类别推送关联的资源数据。</td>   <td>G06F16/9535;G06F18/2431;G06N5/025</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              肖鹏;                   李嘉雄       </td>   <td>中山大学中山眼科中心</td>   <td>白内障眼底图像的修复方法、修复模型的训练方法及装置</td>   <td>广东省</td>   <td>CN115660985A</td>   <td>2023-01-31</td>   <td>本公开提供一种白内障眼底图像的修复方法、修复模型的训练方法及装置,该训练方法包括构建训练数据集,训练数据集包括清晰眼底图像以及与清晰眼底图像对应的参考白内障图像；利用生成器将参考白内障图像作为输入以通过多次下采样获取不同尺度的第一特征图,将第一特征图与相应的上采样的第二特征图进行融合,生成修复图像,利用判别器将参考白内障图像和对应的清晰眼底图像作为输入以输出第一判别结果,将参考白内障图像和对应的修复图像作为输入以输出第二判别结果；基于训练数据集、第一判别结果和第二判别结果获取目标损失,基于目标损失对修复模型进行训练以优化修复模型,进而获得用于修复白内障眼底图像的训练后的生成器。</td>   <td>1.一种白内障眼底图像的修复模型的训练方法,其特征在于,所述修复模型包括生成器和判别器,所述训练方法包括：构建训练数据集,所述训练数据集包括清晰眼底图像以及与所述清晰眼底图像对应的参考白内障图像；利用所述生成器将所述训练数据集中的所述参考白内障图像作为输入以通过多次下采样获取不同尺度的第一特征图,并将所述不同尺度的第一特征图与相应的经上采样获取的第二特征图进行融合,进而生成修复图像；利用所述判别器将所述参考白内障图像和对应的清晰眼底图像作为输入以输出针对所述清晰眼底图像的第一判别结果,并将所述参考白内障图像和对应的修复图像作为输入以输出针对所述修复图像的第二判别结果；并且基于所述训练数据集、所述第一判别结果和所述第二判别结果获取目标损失,并基于所述目标损失对所述修复模型进行训练以优化所述修复模型,进而获得用于修复白内障眼底图像的训练后的所述生成器；其中,所述目标损失包括第一损失、第二损失、第三损失和第四损失,所述第一损失由所述第一判别结果和所述第二判别结果确定,所述第二损失由所述修复图像与对应的清晰眼底图像之间像素的差异所确定,所述第三损失由基于卷积神经网络的特征提取器提取的所述修复图像与对应的清晰眼底图像之间的不同尺度的特征图的差异所确定,所述第四损失由所述修复图像与对应的清晰眼底图像之间的结构相似性所确定。</td>   <td>G06T5/00;G06T5/50;G06V10/82;G06V10/77;G06V10/80;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         江颖;                   招海俊       </td>   <td>中山大学</td>   <td>一种基于自监督学习的姿态估计方法</td>   <td>广东省</td>   <td>CN115661246A</td>   <td>2023-01-31</td>   <td>本发明公开一种基于自监督学习的姿态估计方法,先基于对比性方法的自监督学习算法预训练得到视觉主干模型；然后基于部分整体关系约束的自监督训练得到部分分割网络；再通过回归学习训练得到关键点估计器；之后将目标图片依次通过视觉主干模型、部分分割网络及关键点估计器获取关键点图和标定视角特征图,然后结合深度图,提取得到关键点的标定视角特征和深度值,根据深度值与关键点坐标,得到关键点在相机坐标系统下的三维坐标,然后进行相机坐标系统与世界坐标系统之间的相似变换,得到姿态估计结果。本发明能够提取适用于细粒度下游任务的图像特征,并可直接提供关键点和标定视角特征,有效减少了数据标注复杂度和工作量。</td>   <td>1.一种基于自监督学习的姿态估计方法,其特征在于,包括以下步骤：S1、使用公开的图片数据集,基于对比性方法的自监督学习算法预训练得到视觉主干模型,视觉主干模型输出图像特征；S2、使用图像特征,基于部分整体关系约束的自监督训练得到部分分割网络,部分分割网络输出部分响应图；S3、以标注了关键点的图片及其对应的标定视角特征作为学习目标,将部分响应图的特征点作为输入,再通过回归学习训练得到一个网络作为关键点估计器,关键点估计器输出图片对应的关键点图和标定视角特征图；S4、将目标图片输入训练好的视觉主干模型,得到目标图片的图像特性,然后将目标图片的图像特性输入训练好的部分分割网络,得到目标图片的部分响应图,之后将目标图片的部分响应图输入训练好的关键点估计器,得到目标图片的关键点图和标定视角特征图；S5、获取目标图片的深度图,并将目标图片的关键点图通过非极大值抑制算法筛选出多个关键点,提取得到多个关键点坐标,再使用关键点坐标,提取得到多个关键点在标定视角特征图和深度图上对应位置的标定视角特征q-i和深度值d-i；S6、结合深度值d-i和关键点坐标,得到多个关键点在相机坐标系统下的三维坐标p-i,将相机坐标系统与世界坐标系统之间的转换关系表示为一个相似变换,该相似变换由标量s∈R～+、旋转矩阵R∈SO(3)、及平移t进行参数化表示,并通过最小化下列目标函数得到：                  式中w-i∈[0,1],表示信任分数,N-1表示关键点数量；s～★,R～★,t～★是最小化目标函数后得到的最优参数化表示,s～★,R～＊,t～★即为目标图片的姿态估计结果。</td>   <td>G06T7/73;G06V10/26;G06V10/44;G06V10/764;G06V10/774;G06V10/82;G06N3/0455;G06N3/048;G06N3/0895</td>  </tr>        <tr>   <td>中国专利</td>   <td>              谭金凯       </td>   <td>中山大学</td>   <td>基于变分自编码的台风云图外推方法、系统、设备和介质</td>   <td>广东省</td>   <td>CN115661277A</td>   <td>2023-01-31</td>   <td>本发明提供了基于变分自编码的台风云图外推方法、系统、设备及介质,所述方法包括：获取卫星云图数据和历史台风最佳路径数据,并根据卫星云图数据和历史台风最佳路径数据,构建台风云图外推数据集；根据台风云图外推数据集,构建得到台风云图外推预测模型；所述台风云图外推预测模型包括依次连接的变分自编码器、解码器和三维点云重采样器；获取待预测台风的初始卫星云图数据,并将初始卫星云图数据输入台风云图外推预测模型,得到对应的云图预测结果。本发明从“数据驱动”的角度出发,挖掘出卫星云图的多种潜在特征,不仅操作过程方便简单,而且能实现更高效、更精准地台风云图外推预测。</td>   <td>1.一种基于变分自编码的台风云图外推方法,其特征在于,所述方法包括以下步骤：获取卫星云图数据和历史台风最佳路径数据,并根据所述卫星云图数据和历史台风最佳路径数据,构建台风云图外推数据集；根据所述台风云图外推数据集,构建得到台风云图外推预测模型；所述台风云图外推预测模型包括依次连接的变分自编码器、解码器和三维点云重采样器；获取待预测台风的初始卫星云图数据,并将所述初始卫星云图数据输入所述台风云图外推预测模型进行云图外推预测,得到对应的云图预测结果。</td>   <td>G06T9/00;G06N3/04;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张艳;              曲承志;              黄坤;              许哲禹;                   马非凡       </td>   <td>中山大学·深圳;中山大学</td>   <td>点云异常值的移除方法、点云处理方法、装置及相关设备</td>   <td>广东省</td>   <td>CN115661421A</td>   <td>2023-01-31</td>   <td>本申请公开了一种点云异常值的移除方法、点云处理方法、装置及相关设备,该方法包括：将待处理的点云沿着参考坐标轴均匀地划分成多个层；对于点云每一层中的每一点,基于该点的包围框确定是否移除该点,得到第二点云；获取第二点云的平均近邻欧氏距离即其中各点的近邻欧氏距离；对于第二点云中的每一点,基于该点的近邻欧氏距离与平均近邻欧氏距离的差值,以及第二点云中各点的近邻欧氏距离与平均近邻欧氏距离的标准差,确定是否移除该点。通过上述各步骤,本申请能够在保留细节特征的前提下,比较直观且便捷的实现点云中的异常值的移除。</td>   <td>1.一种点云异常值的移除方法,其特征在于,包括：将待处理的点云沿着参考坐标轴均匀地划分成多个层；对于所述点云每一层中的每一点,设置以所述点为中心的包围框,若所述包围框内仅包含所述点,则移除所述点,得到第二点云；对于所述第二点云中的每一点,确定所述点的第一近邻点集合,其中,每一点的第一近邻点集合内所包含的第一近邻点的个数相同,且所述第一近邻点到所述点的欧氏距离,小于所述第一近邻点集合外的任一点到所述点的欧氏距离；获取所述第二点云中各点的近邻欧氏距离,以及获取所述第二点云的平均近邻欧氏距离,其中,所述近邻欧氏距离为点与所述点的各第一近邻点的欧氏距离的平均值,所述平均近邻欧氏距离为所述第二点云中各点的近邻欧氏距离的平均值；对于所述第二点云中的每一点,基于所述点的所述近邻欧氏距离与所述平均近邻欧氏距离的差值,以及所述第二点云中各点的所述近邻欧氏距离与所述平均近邻欧氏距离的标准差,确定是否移除所述点。</td>   <td>G06T19/20;G06T7/66;G06T3/00;G06F17/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张宇;              修长振;                   孙伟       </td>   <td>中山大学</td>   <td>一种基于方向性局部二值模式的二值图像隐写分析方法</td>   <td>广东省</td>   <td>CN109885987B</td>   <td>2023-01-24</td>   <td>本发明提出一种基于方向性局部二值模式的二值图像隐写分析方法,首先设置自适应阈值参数,在使用crmiLTP对二值图像进行扰动度量后,使用3×3像素点块模板对扰动得分图进行扫描,根据各像素点对应扰动得分数值大小及方向性得出局部二值模式值,然后利用各二值模式值出现频率提取特征,在特征提取时充分利用设置的阈值,对像素点所有扰动得分值之间的大小及方向关系进行遍历,最后选取最优检测效果对应阈值,能够使训练出的分类模型达到最佳的隐写分析准确率。在对使用不同隐写算法生成的隐秘图像进行隐写分析时可以设置不同阈值,从而使得在确保有效性的同时又有很强的针对性。</td>   <td>1.一种基于方向性局部二值模式的二值图像隐写分析方法,其特征在于,包括以下步骤：步骤S1：设置自适应阈值ρ；步骤S2：构建3×3像素点块模板；步骤S3：利用crmiLTP扰动度量方法对样本集中的二值图像进行扰动度量打分,获得扰动度量的得分图,然后利用3×3像素点块模板扫描扰动得分图；步骤S4：根据步骤S1所设置的自适应阈值ρ,计算出自适应对比阈值其中I-i为当前需要比较的像素点扰动得分值,i表示像素点的下标索引,i＝1,2,…8,u为3×3像素点块模板9个像素点扰动得分均值；步骤S5：比较各像素点扰动得分值关于3×3像素点块模板中心对称方向的大小关系,将I-i与I-c、I-c与I-(i+4)相比较,当i＝1时,比较I-1、I-c、I-5三者之间的大小关系,当i＝2,3,4时,分别比较三者相应的位置,I-c为中心像素点扰动得分值,比较结果如下：                                    式中td-1表示I-i与I-c扰动得分值的大小关系,当I-i比I-c大且相差幅度不小于I-i的自适应对比阈值t-i时,比较结果为1,否则为0；td-2表示I-c与I-(i+4)扰动得分值的大小关系,当I-c比I-(i+4)大且相差幅度不小于I-(i+4)的自适应对比阈值t-(i+4)时,比较结果为1,否则为0；步骤S6：比较处于3×3像素点块模板水平、竖直方向各像素点扰动得分值的大小关系,将同一方向上的三个像素点进行比较,比较结果如下：                                    式中i＝2,4,6,0,当i＝2时,比较I-2、I-3、I-4三者之间的大小关系,当i＝4,6时比较相应的I-4、I-5、I-6和I-6、I-7、I-8之间的大小关系,需要注意的是i＝0时对应的像素点位置为I-8、I-1、I-2,td-3表示I-i与I-(i+1)扰动得分值的大小关系,当I-i比I-(i+1)大且相差幅度不小于I-i的自适应对比阈值t-i时,比较结果为1,否则为0,td-4表示I-(i+1)与I-(i+2)扰动得分值的大小关系,当I-(i+1)比I-(i+2)大且相差幅度不小于I-(i+2)的自适应对比阈值t-(i+2)时,比较结果为1,否则为0；步骤S7：得出像素点关于3×3像素点块模板中心对称、水平、竖直方向上的扰动得分值大小关系后,计算像素点关于3×3像素点块模板在设置阈值下的方向性局部二值模式值；根据TD-k＝td-i⊙td-(i+1),i＝1,3得出二者之间的方向关系,式中⊙表示同或操作,当二者相同时结果为1,表示三个像素位置的扰动得分值具有依次减小或递增的变化趋势,当二者不同时结果为0,表示三个像素位置扰动得分值的大小变化趋势不具有一致性,将比较结果TD-k用8位二进制数表示,低4位为依次比较I-1、I-c、I-5,I-2、I-c、I-6,I-3、I-c、I-7,I-4、I-c、I-8的结果,高4位为依次比较I-2、I-3、I-4,I-4、I-5、I-6,I-6、I-7、I-8,I-8、I-1、I-2的结果,最后由公式                  可将8位二进制的比较结果转换为0到255之间的十进制数TD-LBP-((i,j)),即为当前以(i,j)为中心的3×3像素点块模板在阈值参数ρ下的方向性局部二值模式值；步骤S8：统计每个方向性局部二值模式的数值出现的频率,将每个方向性局部二值模式出现频率级联形成特征向量；步骤S9：对数据集中所有样本提取特征向量形成特征矩阵,利用支持向量机进行分类模型学习,得到最终的分类模型；步骤S10：使用训练出的分类模型中进行隐写分析,获得最终的分析结果,若分析结果为载密图像,那么该图像含有秘密信息,若分析结果为载体图像,那么该图像不含秘密信息。</td>   <td>G06F21/10;G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;              凌鹏;                   莫浩然       </td>   <td>中山大学</td>   <td>草图图像语义分割方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN113077469B</td>   <td>2023-01-24</td>   <td>本发明公开了一种草图图像语义分割方法、装置、终端设备及存储介质,包括：获取一草图图像；将所述草图图像输入到预先建立的交汇点识别模型,获得仅包含所述草图图像中交汇点的第一图像；对所述草图图像和所述第一图像作差,得到去除所述草图图像中交汇点的第二图像；将所述草图图像和所述第二图像组织成训练样本,并基于所述训练样本对预设的神经网络模型进行训练,得到语义分割模型；将待分割草图图像输入到所述语义分割模型,得到草图语义分割结果,能有效解决使用现有模型将位于一条连续线条上的像素被划分为多个类导致错误分割的问题,大大提高了图像语义分割的准确度。</td>   <td>1.一种草图图像语义分割方法,其特征在于,包括：获取一草图图像；将所述草图图像输入到预先建立的交汇点识别模型,获得仅包含所述草图图像中交汇点的第一图像；所述交汇点识别模型的构建,包括：获取多张使用多条随机位置形状的贝塞尔曲线填充的待处理草图图像；对所述待处理草图图像进行同步,得到具备草图交汇点的交汇点图像；将所述交汇点图像输入到预设的卷积神经网络进行训练,得到所述交汇点识别模型；对所述草图图像和所述第一图像作差,得到去除所述草图图像中交汇点的第二图像；将所述草图图像和所述第二图像组织成训练样本,并基于所述训练样本对预设的神经网络模型进行训练,得到语义分割模型；将待分割草图图像输入到所述语义分割模型,得到草图语义分割结果。</td>   <td>G06T7/10;G06V10/764;G06V10/40;G06V10/762;G06V10/774;G06V10/82;G06V10/74;G06N3/04;G06N3/08;G06N3/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   莫浩然       </td>   <td>中山大学</td>   <td>图像矢量化方法、装置及终端设备</td>   <td>广东省</td>   <td>CN113077477B</td>   <td>2023-01-24</td>   <td>本发明公开了一种图像矢量化方法、装置及终端设备,包括：获取像素级图像,并构造与像素级图像大小相同的画布,初始化裁剪窗口的信息,根据裁剪窗口,对像素级图像和画布进行对齐裁剪,得到区域小块,将区域小块输入到笔划生成器进行计算,获得相应的笔划信息,并根据笔划信息绘制笔划,基于裁剪窗口对笔划进行可微拼贴,得到与像素级图像相适配的笔划帧,将裁剪窗口移动到笔划绘制的末端位置,并更新裁剪窗口的窗口位置,当检测到当前绘制长度达到绘制最大长度时,停止绘制,获得矢量图。本发明可适用于不同风格、不同分辨率的图像,且无需调整大量参数以适配不同的图像,降低了计算复杂度,并能有效提高矢量化技术速度。</td>   <td>1.一种图像矢量化方法,其特征在于,包括：获取像素级图像,并构造与所述像素级图像大小相同的画布；初始化裁剪窗口的信息,所述信息包括窗口大小和窗口位置；根据所述裁剪窗口,对所述像素级图像和所述画布进行对齐裁剪,得到区域小块；所述根据所述裁剪窗口,对所述像素级图像和所述画布进行对齐裁剪,得到区域小块,包括：获取所述区域小块上任一像素对应的被裁剪图像上周围四个预设像素的值,以及所述像素与所述预设像素的距离,所述预设像素包括位于所述像素左上方的像素、位于所述像素左下方的像素、位于所述像素右上方的像素及位于所述像素右下方的像素；根据所述区域小块上任一像素对应的被裁剪图像上周围四个预设像素的值及所述像素与所述预设像素的距离,进行双线性插值计算,得到所述区域小块上所述像素的值；将所述区域小块输入到预先建立的笔划生成器进行计算,获得相应的笔划信息,并根据所述笔划信息绘制笔划；所述将所述区域小块输入到预先建立的笔划生成器进行计算,获得相应的笔划信息,并根据所述笔划信息绘制笔划,具体包括：将所述区域小块输入到预先建立的笔划生成器进行计算,得到下一笔划的矢量参数；将所述笔划的矢量参数转化为一贝塞尔曲线的参数；将所述贝塞尔曲线的参数输入到预设的可微渲染器进行处理,得到笔划图像；基于所述裁剪窗口对所述笔划进行可微拼贴,得到与所述像素级图像相适配的笔划帧；所述可微拼贴操作基于裁剪窗口进行,使用双线性图像插值算法,令拼贴后的笔划帧上每一个像素的值由笔划图像上与该像素临近的周围四个像素值的双线性插值计算得到；将所述裁剪窗口移动到所述笔划绘制的末端位置,并更新所述裁剪窗口的窗口位置；所述更新所述裁剪窗口的窗口位置,具体包括：根据公式和更新所述裁剪窗口的窗口位置；其中,Q-t为更新后t时刻的窗口位置,Q-(t-1)为上一个时刻的窗口位置,为更新后t时刻的未做数值范围剪裁的窗口位置；ΔQ-t为t时刻窗口位置的移动偏移值,ΔQ-t＝(Δx,Δy)-t∈[-1,+1]～2；W为所述裁剪窗口的窗口大小,W-I为所述像素级图像的大小；在更新所述裁剪窗口的窗口位置之后,获取当前的绘制长度,判断所述绘制长度是否达到预设的绘制最大长度；当所述绘制长度未达到所述绘制最大长度时,则重新根据所述裁剪窗口对所述像素级图像和所述画布进行对齐裁剪,直至所述绘制长度达到所述绘制最大长度；当检测到当前绘制长度达到预设的绘制最大长度时,停止绘制,获得矢量图。</td>   <td>G06T7/11;G06T11/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘洋;              经秉中;              李超峰;              邓一术;              陈浩华;              李彬;                   何立儒       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种危及器官自动勾画方法及系统</td>   <td>广东省</td>   <td>CN115409739B</td>   <td>2023-01-24</td>   <td>本发明公开了一种危及器官自动勾画方法及系统,通过将CBCT图像与计划CT图像模型进行优化处理后,得到经过处理后的CBCT图像和CT图像；再将经过处理后的CBCT图像和CT图像输入到自动分割模型中,通过使用自动分割模型对预处理CBCT图像和预处理CT图像进行分割得到自动分割结果后,利用预设函数对自动分割结果进行处理得到分割结果,对自动分割结果进行轮廓线提取得到自动勾画结果,通过使用该方法完成放疗计划中常见的危及器官自动勾画,且引入了对应计划CT的信息辅助,提升自动勾画准确性。</td>   <td>1.一种危及器官自动勾画方法,其特征在于,包括：接收待检测的CBCT图像和计划CT图像,并采用预设方法对所述CBCT图像和计划CT图像进行预处理,得到预处理CBCT图像和预处理计划CT图像；根据预设的自动分割模型对所述预处理CBCT图像和所述预处理计划CT图像进行处理后,得到自动分割结果,再利用预设函数对所述自动分割结果进行处理得到分割结果；对所述分割结果进行轮廓线提取得到自动勾画结果；所述根据预设的自动分割模型对所述预处理CBCT图像和所述预处理计划CT图像进行处理后,得到自动分割结果,再利用预设函数对所述自动分割结果进行处理得到分割结果,具体为：将所述预处理CBCT图像和所述预处理计划CT图像输入编码器分别进行编码得到CBCT特征编码和CT特征编码；根据所述预处理CBCT图像和所述预处理计划CT图像得到形变场；根据所述CBCT特征编码、所述CT特征编码和所述形变场得到邻域CT特征；根据所述CBCT特征编码、所述CT特征编码进行计算后得到非邻域CT特征；将所述邻域CT特征和非邻域CT特征进行特征融合后输入分割解码模块得到自动分割结果,再通过argmax函数对所述自动分割结果进行处理后得到分割结果；所述根据所述预处理CBCT图像和所述预处理计划CT图像得到形变场,具体为：将所述预处理CBCT图像作为参考图像,所述预处理计划CT图像作为移动图像,根据作为参考图像的所述预处理CBCT图像和作为移动图像的所述预处理计划CT图像通过Unet网络计算出形变场,其中,所述形变场表示为：                  其中,表示形变场,表示Unet网络,表示预处理计划CT图像；表示预处理CBCT图像。</td>   <td>G06T5/00;G06N3/0464;G06N3/047;G06N3/08;G16H30/40;G06T7/11;G06T7/187;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吕中荣;              尹智毅;              汪利;                   刘济科       </td>   <td>中山大学</td>   <td>一种结构损伤识别的不确定性定量分析方法及装置</td>   <td>广东省</td>   <td>CN113297773B</td>   <td>2023-01-24</td>   <td>本发明公开了一种结构损伤识别的不确定性定量分析方法及装置。所述方法,包括：建立结构的有限元模型,并根据所述有限元模型获得所述结构的计算特征数据；采用Tikhonov正则化方法,结合所述结构的计算特征数据以及所述结构的实测特征数据,构造目标函数；采用灵敏度方法求解所述目标函数,得到最优损伤参数和损伤参数的协方差矩阵；根据所述最优损伤参数和所述损伤参数的协方差矩阵进行不确定性定量分析,得到分析结果。本发明能够以较低复杂度的计算实现量化识别结果不确定性。</td>   <td>1.一种结构损伤识别的不确定性定量分析方法,其特征在于,包括：建立结构的有限元模型,并根据所述有限元模型获得所述结构的计算特征数据,所述计算特征数据包括计算频率和计算模态；采用Tikhonov正则化方法,结合所述结构的计算特征数据以及所述结构的实测特征数据,构造目标函数,其中,所述实测特征数据包括实测频率和实测模态,所述目标函数为：                  其中,ΔR(α)＝R～M-R～C(α)为所述结构的实测特征数据与所述结构的计算特征数据的差值项；R～M为所述结构的实测特征数据,是一个特征数据矩阵,表示所述结构的实测频率,表示所述结构的实测模态,n为选用所述实测频率和所述实测模态的阶次；R～C为所述结构的计算特征数据,是一个特征数据矩阵,表示所述结构的计算频率,表示所述结构的计算模态,m为选用所述计算频率和所述计算模态的阶次,m＝n；W为权重矩阵,为引入的Tikhonov正则化约束项,λ为通过L曲线法选取的Tikhonov正则化系数,α为引入的损伤参数；采用灵敏度方法求解所述目标函数,得到最优损伤参数和损伤参数的协方差矩阵,其中,所述最优损伤参数为：                  式中,为上一次迭代的灵敏度矩阵,为损伤参数α的上一次迭代值,为的转置矩阵,I为单位矩阵,所述上一次迭代的结构的实测特征数据与所述结构的计算特征数据的差值项；所述损伤参数的协方差矩阵为：∑-(aR)≈[S～T(α～*)WS(α～*)+λI]～(-1)式中,S(α～*)为最优损伤参数的灵敏度矩阵,S～T(α～*)为S(α～*)的转置矩阵；根据所述最优损伤参数和所述损伤参数的协方差矩阵进行不确定性定量分析,得到分析结果。</td>   <td>G06F30/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韦立坚;              林俊勤;              王帆;              马聪;                   郑娇龙       </td>   <td>中山大学;广州民间金融街信用数据技术有限公司</td>   <td>基于知识图谱和图计算的小贷行业团体借贷风险测度方法</td>   <td>广东省</td>   <td>CN115641202A</td>   <td>2023-01-24</td>   <td>本发明提出一种基于知识图谱和图计算的小贷行业团体借贷风险测度方法,涉及金融借贷风险测度,主要分为借贷相关数据的采集、知识抽取、数据处理、知识图谱数据库生成以及风险预测几个部分,其中,知识图谱数据库生成后,对其进行更新迭代,形成分析与更新的良性循环,保证知识图谱的准确性,知识图谱将客观真实业务场景转化为图结果或图关联格式,金融机构以此图结果为基础分析小贷公司的贷款企业所产生的关联风险和系统性风险,基于短期的、公开的、易得的信用信息,节省了核验时间,降低了核验成本,实现对中小企业信用风险的评估。</td>   <td>1.一种基于知识图谱和图计算的小贷行业团体借贷风险测度方法,其特征在于,所述方法包括以下步骤：S1.采集借贷相关数据；S2.对采集到的借贷相关数据进行知识抽取；S3.对已进行知识抽取的数据借贷相关数据进行预处理；S4.基于预处理后的数据生成小贷公司信贷业务的知识图谱数据库,并对知识图谱数据库分析更新；S5.从知识图谱数据库中提取用作识别借贷风险的特征参数,基于特征参数对小贷行业信贷风险进行预测。</td>   <td>G06Q40/03;G06F16/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              麦剑霆;              陈胜朋;                   张小虎       </td>   <td>中山大学</td>   <td>一种物体表面旋转角高精度测量方法及其系统</td>   <td>广东省</td>   <td>CN115631227A</td>   <td>2023-01-20</td>   <td>本发明公开了一种物体表面旋转角高精度测量方法及其系统,该方法包括：在待测目标表面制作信息环并进行编号；获取序列图像对其进行极坐标转换,并对转换后的序列图像进行拼接,得到基准图像；对基准图像进行校准,得到基准图像的全局位置与待测目标的圆周长；在测量过程中获取实时测量图像并进行粗配准,结合基准图像的全局位置计算实时测量图像的全局位置；获取最终测量图像并进行精配准,结合实时测量图像的全局位置和待测目标的圆周长计算最终测量图像的角度。该系统包括：编号模块、获取模块、校准模块、粗配准模块、精配准模块和计算模块。通过使用本发明,能够实现物体一维转角参数的高精度测量。</td>   <td>1.一种物体表面旋转角高精度测量方法,其特征在于,包括以下步骤：在待测目标表面制作信息环并进行编号；获取序列图像对其进行极坐标转换,并对转换后的序列图像进行拼接,得到基准图像；对基准图像进行校准,得到基准图像的全局位置与待测目标的圆周长；在测量过程中获取实时测量图像,并对实时测量图像在基准图像上的位置进行粗配准,结合基准图像的全局位置计算得到实时测量图像的全局位置；获取最终测量图像并与基准图像进行精配准,结合实时测量图像的全局位置计算得到最终测量图像的全局位置；根据最终测量图像的全局位置和待测目标的圆周长计算,得到最终测量图像的角度。</td>   <td>G06T7/60;G06T7/62;G06T7/33;G06T7/73;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   马璐       </td>   <td>中山大学</td>   <td>一种基于图向量表征的丰富短文本语义方法及装置</td>   <td>广东省</td>   <td>CN109543176B</td>   <td>2023-01-20</td>   <td>本发明公开一种基于图向量表征的丰富短文本语义方法及装置,该装置用于实现该方法,该方法包括对短文本语料数据进行分词和去停用词的处理；对处理后语料数据进行相邻词的两两相连构成词图；将词图随机游走,由上节点到下节点依次产生序列,待词图的文本链达到指定的文本链长度后停止游走,获取所有节点序列；输入所获取的节点序列至向量化表征模型,对所有节点进行向量化表征；输出所有节点对应的向量表征。本发明通过将短文本中相邻词连边构建成链,不同短文本构成的链之间用关键词相连的方式构建成图,对构建成的词图使用图向量表征算法得到每个节点的向量表征,以便于应用于机器学习模型中。</td>   <td>1.一种基于图向量表征的丰富短文本语义方法,其特征在于,包括如下步骤：S10输入短文本语料数据,对其进行分词和去停用词的处理；S20在处理后的语料数据中将相邻的词两两相连,通过将每个短文本转化为文本链,数个短文本之间通过相同的词相连,由此构成词图；S30将词图随机游走,上节点选取与其相连的一个词作为下一节点,由上节点到下节点依次产生序列,待词图的文本链达到指定的文本链长度后停止游走,获取所有节点序列；S40输入所获取的节点序列至向量化表征模型,对所有节点进行向量化表征；S50输出所有节点对应的向量表征；所述向量化表征模型包括输入层、向量表征层、投影层和输出层,其中：输入层输入S30所获取的所有节点序列,其中所有节点序列由当前词节点Cur的前后N个相邻的词节点组成,表示为Context(Cur)-i,i＝1,2,...,2n；向量表征层中的向量对应输入层中词节点向量,词节点向量满足：          其中d表示向量维度,是一个可以自定义的参数；投影层将当前词节点Cur的前后N个相邻词节点的向量表征累加而得,写为公式：                  输出层将当前短文本节点Cur当做模型训练的标签,根据游走得到的序列的集合来构建哈夫曼树,学习的过程转化为在哈夫曼树中寻找Cur节点的路径的过程,使用最大似然函数来定义目标函数,写为公式：                  将概率p展开成在哈夫曼树中逐步以二分类方式寻找Cur节点的概率；假设找到Cur节点总共需要k步,到达Cur节点的路径编码为r-2r-3...r-(k+1),则p(Cur|Context(Cur))可以写成如下形式：                  将目标函数进一步推导：                  通常使用Sigmoid函数评估分为正类的概率：                  结合这里的向量表征,使用二分类的概率来表示在哈夫曼树上寻找目标节点的路径过程：                  可以将其整合到一个公式：                  进一步可将目标函数写为：                  由上得到一个较为清晰的将词节点向量化的目标函数,再通过反向传播算法训练模型即可得到词节点对应的向量表征。</td>   <td>G06F40/30;G06F40/284;G06F16/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;              龚江涛;                   秦景辉       </td>   <td>中山大学</td>   <td>基于知识网络精准在线教育系统的多维度信息学情分析方法</td>   <td>广东省</td>   <td>CN109858797B</td>   <td>2023-01-20</td>   <td>本发明属于在线教育学情分析技术领域,涉及基于知识网络精准在线教育系统的多维度信息学情分析方法,基于知识网络精准在线教育,围绕服务对象学习痕迹及其多维度学情信息,对服务对象多维度综合学习评价,推荐个性化教学方案,提出强化学习计划,拓展个性化教学方案,优化个性化学习提升方案。本发明基于全学习痕迹、学习效果以及综合评价预测服务对象未来的学习效果,使得服务对象能够提前掌握学习效果变化的曲线,随时跟踪自己的学习数据；运用神经网络算法推荐个性化教学方案,推荐的个性化教学方案具有针对性；根据综合评价指标聚类和动态识别,使得教师可以根据不同的服务对象群体布置差异化的教学措施,体现了因材施教的教学理念。</td>   <td>1.基于知识网络精准在线教育系统的多维度信息学情分析方法,其特征在于,包括以下步骤：构建知识网络精准在线教育系统；基于知识网络精准在线教育系统,依据服务对象的学习痕迹记录多维度学情信息；基于服务对象已有的学习痕迹及其多维度学情信息,利用知识网络学情综合评估法,形成服务对象多维度综合学习评价；根据教学大纲要求和服务对象多维度综合学习评价,推荐个性化教学方案；根据推荐的个性化教学方案,记录服务对象学习生成的新的学习痕迹及评测结果,通过多维度综合学习评价指标,评估服务对象个性化学习效果；依据服务对象的全学习痕迹和多维度综合学习评价指标,判定服务对象所属类别,提出强化学习计划,拓展个性化教学方案,优化个性化学习提升方案；根据服务对象产生的学习痕迹及多维度学情信息,采用神经网络模型,迭代优化个性化教学方案推荐模型；学习痕迹中记录服务对象使用知识网络精准在线教育系统进行学习时产生的各种数据,包括学习时间、学习时长、在某个时间学习的知识元覆盖的广度与深度、学习资源选择偏好、学习行为、学习速度和进度、测评安排、测评方法和测评结果信息；多维度综合学习评价通过评价指标来评估,评价指标包括：大纲完成情况、智力竞争力、坚持力、集中力、自我拓展能力和实践能力；多维度综合学习评价方法为：①坚持力由投入学习时间、结束学习时间、投入学习的频率及每次投入学习时长来衡量；坚持力计算方法为根据学习痕迹中记录的投入学习时间、结束学习时间、学习频率、投入学习时长,计算与当前投入学习时间、结束学习时间、学习频率、投入学习时长的方差,得到方差向量D＝(d-1,d-2,d-3,d-4),根据四个要素的权重向量W＝(w-1,w-2,w-3,w-4),得到最终的坚持力为：                  ②智力竞争力由年龄、学习速度、测评效果、学习覆盖知识元的广度和深度来衡量；U＝(u-1,u-2,u-3,u-4,u-5)分别表示年龄、学习速度、测评效果、学习覆盖知识点的广度、学习覆盖知识点的深度；评价等级V＝(v-1,v-2,v-3,v-4,v-5)分别为很差、较差、合格、良好和优秀；当服务对象完成知识元的学习后,知识网络精准在线教育系统结合U和V,给出评分矩阵R；通过权值向量A,得到模糊后的向量B＝A*R,引入得分向量S,则智力竞争力I：I＝B*S～T其中,权值向量和得分向量通过知识网络专家给出,或者通过层次分析法给出；③自我拓展能力由评测服务对象在其现有知识覆盖范围的综合能力和拓展解决直接后续相关知识元问题能力来衡量；④实践能力P-(ra)通过评测服务对象在运用已获取的知识解决实际问题的能力来获取,取决于解决方案评分s、问题难度d和解决问题的时间t,单个拓展题或实践问题产生的拓展题能力或实践能力得分为：                  其中：k-1、k-2为常数；⑤集中力F-f由学习活跃时间比来衡量：                  其中：t-t为分心时间,t为总学习时间；分心时间由服务对象全学习痕迹中记录的页面超出停顿限制时间、页面切出时间和页面额外滚动时间组成；⑥大纲完成情况通过大纲要求完成比来衡量,指以一个知识元为单元,服务对象经过学习后大纲逐条完成度与该条大纲的重要程度乘积累加之后与大纲整体要求的完成度之比,则一个知识元的大纲完成情况的计算方式为：                  其中：d-i为第i条大纲的重要程度,p-i为第i条大纲服务对象的完成度,A为大纲整体要求的完成度；上述的单个自我拓展能力、单个实践能力、单个集中力和单个大纲完成情况,其总体拓展能力、实践能力、集中力、大纲完成情况采用迭代更新的方式获得：                  其中,i＝{1,2,3,4}分别表示自我拓展能力、实践能力、集中力和大纲完成情况,p-i表示单个指标的数值,n-i表示单个指标的评测次数,迭代开始时T-i＝0；总的多维度综合学习评价：E-(stu)＝(I,P,C-d,F,E,P-(ra))W～T其中,I、P、C-d、F、E、P-(ra)分别为智力竞争力、坚持力、大纲完成情况、集中力、自我拓展能力和实践能力,W＝(w-1,w-2,w-3,w-4,w-5,w-6)为权重,权重W通过专家获取或通过层次分析法获取。</td>   <td>G06Q10/06;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              刘洁利;              郭海旭;              蔡倬;              方耀;              郑子彬;                   张文锋       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>用户数据处理方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115630973A</td>   <td>2023-01-20</td>   <td>本申请涉及一种用户数据处理方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取目标用户关系图；目标用户关系图包括多个用户节点、用户节点之间的连接关系、各个用户节点的基础特征向量和标签特征向量；确定目标节点,基于用户节点之间的连接关系确定目标节点对应的各个邻居节点；聚合各个邻居节点的基础特征向量和标签特征向量,得到目标节点对应的基础特征聚合向量和标签特征聚合向量；拼接目标节点的基础特征向量、基础特征聚合向量和标签特征聚合向量得到目标特征增强向量；将目标特征增强向量输入目标账户状态预测模型,得到目标节点对应的目标账户的账户状态预测结果。采用本方法能够提高用户数据处理的准确性。</td>   <td>1.一种用户数据处理方法,其特征在于,所述方法包括：获取目标用户关系图；所述目标用户关系图包括多个用户节点、用户节点之间的连接关系、各个用户节点对应的基础特征向量和标签特征向量,所述标签特征向量是基于用户节点对应的账户的历史异常行为得到的；从所述各个用户节点中确定目标节点,基于用户节点之间的连接关系确定所述目标节点对应的各个邻居节点；聚合所述各个邻居节点对应的基础特征向量,得到所述目标节点对应的基础特征聚合向量,聚合所述各个邻居节点对应的标签特征向量,得到所述目标节点对应的标签特征聚合向量；拼接所述目标节点对应的基础特征向量、所述基础特征聚合向量和所述标签特征聚合向量,得到所述目标节点对应的目标特征增强向量；将所述目标特征增强向量输入目标账户状态预测模型,得到所述目标节点对应的目标账户的账户状态预测结果。</td>   <td>G06Q30/02;G06Q10/06;G06F18/24;G06F18/214;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈亮;              于宙鑫;              周克涌;              林昊;              余俭;              郑子彬;                   张鹏       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>信息推送模型构建方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115630224A</td>   <td>2023-01-20</td>   <td>本申请涉及一种信息推送模型构建方法、装置、计算机设备和存储介质。所述方法包括：获取历史特征数据；根据历史特征数据得到表征嵌入数据,表征嵌入数据包括对象表征数据、推送内容表征数据、推送方式表征数据、推送时间表征数据；将对象表征数据与推送内容表征数据作为训练数据进行神经网络训练得到推送内容子模型；将对象表征数据与推送方式表征数据作为训练数据进行神经网络训练得到推送方式子模型；将对象表征数据与推送时间表征数据作为训练数据进行神经网络训练得到推送时间子模型；基于推送内容子模型、推送方式子模型、推送时间子模型并行拼接得到信息推送模型。采用本方法提高生成线上推送信息的效率。</td>   <td>1.一种信息推送模型构建方法,其特征在于,所述方法包括：获取历史特征数据；根据所述历史特征数据得到表征嵌入数据,所述表征嵌入数据包括对象表征数据、推送内容表征数据、推送方式表征数据、推送时间表征数据；将所述对象表征数据与所述推送内容表征数据作为训练数据进行神经网络训练得到推送内容子模型；将所述对象表征数据与所述推送方式表征数据作为训练数据进行神经网络训练得到推送方式子模型；将所述对象表征数据与所述推送时间表征数据作为训练数据进行神经网络训练得到推送时间子模型；基于所述推送内容子模型、所述推送方式子模型、推送时间子模型并行拼接得到信息推送模型,所述信息推送模型用于根据待推送对象对应的对象表征数据得到对应的信息推送内容类别、信息推送方式类别以及信息推送时间。</td>   <td>G06F16/9535;G06N3/04;G06N3/08;G06F18/25;G06F18/214;G06F18/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              庞礼铧;                   黎明思       </td>   <td>中山大学</td>   <td>一种水生动物捕获收集的方法</td>   <td>广东省</td>   <td>CN115631512A</td>   <td>2023-01-20</td>   <td>本发明公开了一种水生动物捕获收集的方法,通过建立水生动物识别模型识别第一水生动物,能够具有针对性地对泛滥的水生动物进行捕获收集处理,而不会伤及其他水生动物；通过配置水生动物捕获收集装置进行自动巡航,根据识别到的第一水生动物和第二水生动物的密度,控制捕获收集装置进行捕获收集处理或不处理,能够大幅度缩减人力劳动的成本,并且由于本发明实施例是在水下自动进行工作,无需人力干涉,受到天气环境的影响较小,效率高；同时,由于本发明实施例通过采用自动巡航的装置进行水生动物的捕获采集工作,能够对不同的点位进行自主处理,具有更高的机动性和灵活性。本发明的实施例可以广泛应用于环境保护技术领域。</td>   <td>1.一种水生动物捕获收集的方法,其特征在于,包括：获取模拟水生环境图像,根据所述模拟水生环境图像使用Yolo-V5算法建立水生动物识别模型；配置水生动物捕获收集装置以及巡航控制设备；其中,所述巡航控制设备用于控制所述水生动物捕获收集装置进行自动巡航；通过所述水生动物识别模型识别第一水生动物,获得所述第一水生动物的活动图像；其中,所述第一水生动物是待捕获收集的水生动物；根据所述活动图像,估计所述第一水生动物的密度和第二水生动物的密度；根据所述第一水生动物的密度和所述第二水生动物的密度,控制所述水生动物捕获收集装置对所述第一水生动物进行捕获收集处理。</td>   <td>G06V40/10;G06V20/05;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              麦剑霆;              陈胜朋;                   张小虎       </td>   <td>中山大学</td>   <td>一种高精度线位移测量方法及其系统</td>   <td>广东省</td>   <td>CN115631170A</td>   <td>2023-01-20</td>   <td>本发明公开了一种高精度线位移测量方法及其系统,该方法包括：在待测目标表面制作信息条,获取序列图像并进行校准,得到基准图像；对基准图像进行标定,得到标定图像的像素位置和实际物理位置比例系数；在测量过程中获取实时测量图像并对其在基准图像上的位置进行粗定位,对粗定位后的实时测量图像进行精配准,结合标定图像的像素位置计算,得到实时测量图像的像素位置；获取待测目标测量图像,并根据实时测量图像的像素位置和实际物理位置比例系数计算,得到待测目标测量图像位置。该系统包括：获取模块、校准模块、标定模块、粗定位模块、精配准模块和计算模块。通过使用本发明,能够精准测量线位移。</td>   <td>1.一种高精度线位移测量方法,其特征在于,包括以下步骤：在待测目标表面制作信息条并获取具有重叠区域的序列图像；对序列图像进行校准,得到基准图像；对基准图像进行标定,得到标定图像的像素位置和实际物理位置比例系数；在测量过程中获取实时测量图像,并对实时测量图像在基准图像上的位置进行粗定位,结合标定图像的像素位置,得到基准图像与实时测量图像的像素偏移；对粗定位后的实时测量图像进行精配准,结合基准图像与实时测量图像的像素偏移计算,得到实时测量图像的像素位置；获取待测目标测量图像,并根据实时测量图像的像素位置和实际物理位置比例系数计算,得到待测目标测量图像位置。</td>   <td>G06T7/00;G06T7/38;G06T7/70;G06T5/00;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              龚海帆;              谢一凡;                   陈冠锜       </td>   <td>中山大学</td>   <td>甲状腺结节识别与分割方法、系统、存储介质及设备</td>   <td>广东省</td>   <td>CN113177554B</td>   <td>2023-01-20</td>   <td>本发明公开了一种甲状腺结节识别与分割方法,包括：获取预处理样本,并输入至骨架网络进行样本特征提取；将提取到的特征样本分别输入至第一分支及第二分支进行训练；分别计算训练后的第一分支的分类损失及第二分支的分割损失；通过分类损失及分割损失的线性加权得到总损失训练模型；其中,总损失训练模型能够对输入图像的甲状腺结节的良恶性类别和病变区域进行判断。本发明能够减轻对医生等人力资源的依赖,降低人为错误的可能性,实现智能化检测。同时充分考虑了甲状腺结节的影像学特点,以缓解深度学习模型由于影像类别和病理类别不一致带来的干扰问题,从而让分类器更好的学习到合适的影像学特征,实现在分类器上对病变区域的精确分割。</td>   <td>1.一种甲状腺结节识别与分割方法,其特征在于,所述方法包括：获取预处理样本,并输入至骨架网络进行样本特征提取；将提取到的特征样本分别输入至第一分支及第二分支进行训练；分别计算训练后的所述第一分支的分类损失及所述第二分支的分割损失；所述第一分支的分类损失为：所述第二分支的分割损失为：L-(seg)＝L-(dice)+αL-(bce),                  T-h＝T-(ada)*S-f(h)                  其中,CE为交叉熵损失,y’为样本的预测结果,y为样本的标签,k为样本的索引,c-k为样本的置信度,j为样本标签的索引,T-(ada)为自适应阈值,S-f为调度函数,h为当前的迭代次数,l-k为第二分支对困难样本筛选阈值筛选出的样本进行训练的模型,k为样本的索引,B为在当前样本中训练的批处理样本数大小；L-(dice)为Dice损失,L-(bce)为二值化交叉熵损失,α为超参数,L-(cls)为分类损失,L-(seg)为分割损失；通过所述分类损失及所述分割损失的线性加权得到总损失训练模型。</td>   <td>G06V10/26;G06V10/46;G06V10/764;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;                   钟圳伟       </td>   <td>中山大学</td>   <td>一种基于相对速度的社会力模型的人群仿真方法</td>   <td>广东省</td>   <td>CN110276123B</td>   <td>2023-01-20</td>   <td>本发明涉及计算机图形学、人群仿真技术,具体为基于相对速度的社会力模型的人群仿真方法,包括以下步骤：使用改进后的基于相对速度的社会力模型对仿真实验进行模拟计算；得出仿真模拟数据,包括行人的速度大小、速度方向和位置；根据仿真模拟数据进行仿真建模,显示仿真结果；所述改进后的基于相对速度的社会力模型,与现有基于相对速度的社会力模型公式相比,其计算公式添加了行人当前位置下的社会心理力的计算项。本发明通过对社会力模型结合相对速度进行改进,能有效减少行人震荡问题和避免行人重叠问题,使得社会力模型在人群疏散仿真的应用上更具有真实性。</td>   <td>1.一种基于相对速度的社会力模型的人群仿真方法,其特征在于,包括以下步骤：使用改进后的基于相对速度的社会力模型对仿真实验进行模拟计算；得出仿真模拟数据,包括行人的速度大小、速度方向和位置；根据仿真模拟数据进行仿真建模,显示仿真结果；所述改进后的基于相对速度的社会力模型,与现有基于相对速度的社会力模型公式相比,其计算公式添加了行人当前位置下的社会心理力的计算项；所述计算公式为：                                                      第一个式子表示在相同的预测时间步长t的情况下,行人i的预测位置pos′-i由当前位置pos-i和当前速度计算得出；表示行人i受到行人j的社会心理力,表示行人i受到边界或者障碍物的社会心理力,均为预测位置上的社会心理力与当前位置上的社会心理力之和；A-i和B-i是常数,分别表示行人i与其他行人的相互作用强度和相互作用范围；r-(ij)表示行人i和行人j的半径之和；d′-(ij)表示行人i和j在预测位置之间的距离；表示行人i和j在预测位置上由行人j指向行人i的单位向量；d-(ij)表示行人i和j在当前位置之间的距离；表示行人i和j在当前位置上由行人j指向行人i的单位向量；r-i表示行人i的半径,d′-(iW)表示行人i在预测位置上与边界或障碍物之间的距离,表示边界或障碍物指向行人i的预测位置的单位向量,d-(iW)表示行人i在当前位置上与边界或障碍物之间的距离,表示边界或障碍物指向行人i的当前位置的单位向量。</td>   <td>G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;                   刘鹏鹏       </td>   <td>中山大学</td>   <td>一种图形化和容器化的虚拟网络环境构建及批量部署方法</td>   <td>广东省</td>   <td>CN109725986B</td>   <td>2023-01-20</td>   <td>本发明涉及云计算和容器技术领域,为图形化和容器化的虚拟网络环境构建及批量部署方法,包括步骤：基于图形化工具的虚拟网络拓扑图设计与虚拟资源属性配置；模板可用性验证以及容器化的虚拟网络环境批量部署；运行时虚拟网络环境的生命周期管理。本发明简化了虚拟网络环境的构建和管理过程,克服了现有技术配置步骤繁琐、应用场景单一的缺陷,加快了批量虚拟网络环境的部署速度,提高了高校或研究机构进行网络教学和研究的效率。</td>   <td>1.一种图形化和容器化的虚拟网络环境构建及批量部署方法,其特征在于,包括步骤：基于图形化工具的虚拟网络拓扑图设计与虚拟资源属性配置；模板可用性验证以及容器化的虚拟网络环境批量部署；运行时虚拟网络环境的生命周期管理；所述图形化工具包括资源栏、展示台和控制栏,所述资源栏展示所有可供用户使用的虚拟资源；所述展示台放置用户从资源栏拖拽添加的虚拟资源,展示当前网络拓扑结构；所述控制栏展示对当前拓扑图所进行的管理操作按钮,包括保存、清空、保存为草稿以及验证可用性；所述基于图形化工具的虚拟网络拓扑图设计与虚拟资源配置,包括如下步骤：a)选择编辑已有模板或者新建模板以进入图形化工具,选择编辑已有模板时展示台将会读取相应模板信息并显示对应的网络拓扑图,选择新建模板时展示台将显示为空白；b) 通过从资源栏拖拽所需种类和数目的虚拟资源图标放置到展示台；c)通过在虚拟资源图标间添加直线,确定虚拟资源间的关联信息,从而得到初步的网络拓扑图；d)依次单击展示台中的虚拟资源图标完成所有虚拟资源属性配置；e)点击保存将拓扑图转译成文本格式；所述模板可用性验证以及容器化的虚拟网络环境批量部署,包括如下步骤：a)从所生成的模板中选择、部署模板；b)对所选模板进行可用性验证,包括检验模板中描述的资源类型是否存在并可用、资源大小需求能否满足、资源必选属性配置是否完善；c)若通过可用性验证,即可进行批量部署,否则提示错误信息并返回步骤a),重新进行模板选择；d)确定虚拟网络环境所需部署数量；e)设置虚拟网络环境开始使用时间和自动销毁时间；f)根据设置的开始使用时间提前生成部署任务,并传入消息队列；g)服务端从消息队列获取任务并异步执行；h)任务完成,返回批量部署结果。</td>   <td>G06F9/455;G06F9/48;G06F8/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;                   谢明森       </td>   <td>中山大学</td>   <td>一种批量大数据实验环境的快速自动构建方法</td>   <td>广东省</td>   <td>CN109783198B</td>   <td>2023-01-20</td>   <td>本发明涉及云计算技术领域,具体涉及一种批量大数据实验环境的快速自动构建方法。包括步骤：自动构建大数据集群网络资源池,大数据实验环境为已配置大数据环境的虚拟机集群,大数据集群网络资源池包括批量独立的虚拟网络,每个虚拟网络通过虚拟路由和外部网络进行连接；根据大数据集群模版自动生成大数据集群快照；基于大数据集群快照快速自动构建批量大数据集群。本发明通过上述批量大数据实验环境的快速自动构建方法,可以解决批量大数据实验环境的自动构建速度慢的问题。</td>   <td>1.一种批量大数据实验环境的快速自动构建方法,其特征在于,包括以下步骤：S1、自动构建大数据集群网络资源池；所述大数据实验环境为已配置大数据环境的虚拟机集群,大数据集群网络资源池包括批量独立的虚拟网络,每个虚拟网络通过虚拟路由和外部网络进行连接；S2、根据大数据集群模版自动生成大数据集群快照；S3、基于大数据集群快照快速自动构建批量大数据集群；步骤 S1 包括：S11、判断网络资源池中网络资源是否足够用于构建批量的大数据集群,如果不够则进入下一步；S12、构建批量独立的虚拟网络；S13、分别为每一个虚拟网络构建一个虚拟路由,并将虚拟网络和外部网络连接至虚拟路由；S14、将虚拟网络加入到大数据集群网络资源池中；步骤 S2步骤包括：S21、判断大数据集群模板对应的大数据集群快照是否存在,如果不存在则进行下一步；S22、从大数据集群网络资源池中获取网络资源；S23、生成集群公私钥；S24、根据大数据集群模版创建虚拟机集群,虚拟机自动将集群公钥复制到指定位置；S25、根据集群虚拟机网络地址和主机名生成 hosts 文件并通过网络传输到集群虚拟机中；S26、根据大数据集群模版生成大数据集群相关配置文件并通过网络传输到集群虚拟机中；S27、生成大数据集群中所有虚拟机的快照,所有虚拟机快照构成大数据集群模版对应的大数据集群快照；步骤S3中,大数据集群快速自动构建的具体步骤为：S31、从大数据集群网络资源池中获取网络资源；S32、使用大数据集群模版对应的大数据集群快照创建虚拟机集群；S33、根据集群虚拟机网络地址和主机名生成 hosts 文件并通过网络传输到集群虚拟机中。</td>   <td>G06F9/455;G06F9/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         江明;              吴承刚;              李正鹏;                   彭时玉       </td>   <td>中山大学</td>   <td>一种基于圆形投影的可见光成像定位方法</td>   <td>广东省</td>   <td>CN109949367B</td>   <td>2023-01-20</td>   <td>本发明提供了一种基于圆形投影的可见光成像定位方法。该方法通过对圆形LED灯或配有圆形灯罩的LED灯的成像透视投影的建模和分析,根据圆形投影性质获取LED灯中心在摄像头坐标系统(Camera Coordinate System,CCS)的位置坐标并结合LED灯中心在世界坐标系统(World Coordinate System,WCS)和CCS坐标变换的关系来实现精准定位。该方法只需要拍摄一幅包含两个圆形LED灯的图像,并利用倾斜传感器测出精准的滚转角和俯仰角,即可实现高精度定位。该方法克服了现有技术实施时LED灯具中心与LED成像中心无法对应而引起定位不准,或需要同时检测到数量较多的LED灯具才能进行定位,又或者受限于不精确的方位角测量结果等缺点,具有较好的实际应用价值。</td>   <td>1.一种基于圆形投影的可见光成像定位方法,其特征在于,包括以下步骤：步骤S1：移动终端通过其摄像头对LED灯进行拍照,获得至少有两个LED灯具的RGB图像,再将该RGB图像转为灰度图；步骤S2：移动终端从灰度图解调出各LED灯的ID信息,将该信息与其本地存储的LED-ID数据库的信息进行比对,找到与该ID信息相对应的第i盏LED灯中心的世界坐标系统WCS坐标圆形灯罩实体的半径L-i,i＝1,2,...,M,以及LED灯的姿态特征参数集&lt;Δα-i,Δβ-i,0&gt;,i＝1,2,...,M,其中Δα-i表示第i个圆形LED平面绕WCS的x-w轴的旋转角度,Δβ-i表示第i个圆形LED平面绕WCS的y-w轴的旋转角度；步骤S3：对步骤S1获取的灰度图像采用边缘提取技术,获取每个LED灯像的边缘像素点集合,记为S-i,i＝1,2,...,M；步骤S4：利用每个LED灯像的边缘像素点集合进行椭圆拟合,获取每个LED灯像的椭圆参数集合；步骤S5：根据椭圆参数集合以及圆形投影性质,获取每个LED灯中心在摄像头坐标系统CCS的位置坐标；步骤S6：移动终端通过其内置的倾斜传感器测量出移动终端的滚转角α和俯仰角β；步骤S7：通过步骤S2求得的LED灯中心的WCS坐标,圆形灯罩实体的半径,LED灯的姿态特征参数集；以及步骤S6求得的滚转角α和俯仰角β,利用LED灯中心在WCS和CCS的坐标变换关系来获取移动终端的位置；步骤S4的具体过程如下：假设第i个LED灯像边缘对应的椭圆曲线方程为：F-i(x,y)＝a-ix～2+b-ixy+c-iy～2+d-ix+e-iy+f-i＝0       (7)通过步骤S3获取的边缘像素点集合S-i,i＝1,2,...,M,利用最小二乘法拟合椭圆,可获取每一个LED灯像对应的椭圆参数集合,记为U-i＝[a-i,b-i,c-i,d-i,e-i,f-i],i＝1,2,...,M；步骤S5的具体步骤如下：首先需获取由平面成像坐标系IPCS上的一个椭圆及一个顶点O-c确定的锥面,利用步骤S4获取的LED灯像的椭圆参数U-i＝[a-i,b-i,c-i,d-i,e-i,f-i],i＝1,2,...,M及测得的有效焦距k,其确定的锥面在CCS的锥面方程如下：                  上式的[x-c,y-c,z-c]表示锥面在CCS上的坐标,上式用矩阵形式表达为：x～TM-ix＝0                            (9)其中：x＝[x-c y-c z-c]～T,k是透镜焦距；对称矩阵M-i进行特征值分解如下：                  其中：Λ-i＝diag(λ-(i,1),λ-(i,2),λ-(i,3)),λ-(i,1),λ-(i,2),λ-(i,3)是矩阵M-i的三个特征值,矩阵H-i表示特征向量矩阵,其各行是各特征值对应的单位特征向量,则式(9)重写为：                  利用矩阵H-i通过对CCS坐标系的任意一点(x-c,y-c,z-c)进行线性变换：                  可得到新的点(x′,y′,z′),将式(12)代入式(11),则式(8)的锥面方程变为标准锥面方程：λ-(i,1)x′～2+λ-(i,2)y′～2+λ-(i,3)z′～2＝0                      (13)由此,通过式(12)的坐标变换,将锥面方程简化；在CCS坐标系通过线性变换得到的新坐标系(O′x′y′z′)下椭圆锥面及其圆形特征投影；求解在新坐标系(O′x′y′z′)下的平面方程参数l-i、m-i、n-i和t-i,使得椭圆锥面和该平面的交集Φ-i(x′,y′,z′)为一个半径为L-i的圆,由于L-i为圆形LED灯罩的半径,故该圆即为LED灯罩边缘的包络；其中,定义为该平面的单位法向量,满足l-i～2+m-i～2+n-i～2＝1；Φ-i(x′,y′,z′)的定义如下：                  互相平行的平面与椭圆锥面的交集的形状相同,面积大小不同；因此,如果两个平面的单位法向量相等,且其中一个平面与椭圆锥面的交集是一个圆,则另一个平面与椭圆锥面的交集也是一个圆；故先求解平面的法向量使得所对应的平面与椭圆锥面的交集成为一个圆,再进一步求解；令该圆半径为L-i的t-i,则该圆的中心即为LED灯中心在坐标系O′x′y′z′的坐标；分两种情况进行讨论,由于式(13)的几何形状是椭圆锥,则满足的条件是：两个特征值大于0,另一个特征值小于0；以下假设λ-(i,1)≥λ-(i,2)＞0＞λ-(i,3)；1)第一种情况：λ-(i,1)＝λ-(i,2)当λ-(i,1)＝λ-(i,2)时,与平面(x′O′y′)平行的平面与椭圆锥面的交集为一个圆,将λ-(i,1)＝λ-(i,2)代入式(13),可知该平面与椭圆锥面的交集满足以下条件：                  由前面假设条件λ-(i,1)＝λ-(i,2)＞0＞λ-(i,3),可知该交集是一个圆；由于n-c为任意实数,因此与平面(x′O′y′)平行的任意平面与椭圆锥面的交集均为圆,在这种情况下,该椭圆锥面称为圆锥面；一个平面只有与平面(x′O′y′)平行时,它与圆锥面的交集才是圆,其他情况的交集均不是圆；LED灯平面是其所在平面与该圆锥面的交集,且LED灯平面是圆的,故在坐标系(O′x′y′z′)下,LED灯平面平行于平面(x′O′y′)；因此,LED灯平面在坐标系(O′x′y′z′)下的法向量和平面(x′O′y′)的法向量相同,均为代入式(14),LED灯平面方程简化为z′＝t-i；则式(14)的解集如下：                  若令Φ-i(x′,y′,z′)是一个半径为L-i的圆,有：                  解得即该圆的圆心坐标是因此,LED灯中心在坐标系(O′x′y′z′)下的坐标是根据式(12)的逆变换,LED灯中心在CCS的坐标为：                  由于LED灯中心坐标在CCS的z-c轴的坐标值大于0,式(18)只有一个解满足该条件,该解即为LED灯中心在CCS的坐标；2)第二种情况：λ-(i,1)≠λ-(i,2)＞0＞λ-(i,3)通过对坐标系(O′x′y′z′)进行线性变换得到一个新坐标系(O″x″y″z″),使得在坐标系(O′x′y′z′)的平面方程l-ix′+m-iy′+n-iz′＝t-i在新的坐标系(O″x″y″z″)转变成z″＝t-i,求解出平面法向量两个坐标系之间的线性变换关系如下：                  通过式(19),在坐标系(O″x″y″z″)下,式(14)定义的交集变换成如下形式：                  其中二次曲线方程参数g-(i,1)、g-(i,2)、g-(i,3)、g-(i,4)、g-(i,5)和g-(i,6)的取值如下：                  令Φ-i(x″,y″,z″)是一个圆,则必须满足以下条件：                  联立式(21)、式(22)和条件l-i～2+m-i～2+n-i～2＝1进行求解,解得l-i、m-i、n-i如下：                  从式(23)可知,平面法向量中的m-i和n-i的值是确定的,但l-i存在两个取值；所以平面法向量存在两组解,分别记为和而LED平面的法向量是确定且唯一的,故和中只有一个是和LED灯平面的法向量是相符的；从式(14)可知,和是在坐标系(O′x′y′z′)的值；假设通过式(12)和式(1)坐标逆变换后,它们在WCS坐标系的坐标分别记为和表示如下：                  其中R-x、R-y、R-z分别由式(3)、式(4)、式(5)给出,且γ是表征移动终端方位角的未知参数；获取移动终端的位置涉及到三个坐标系之间的坐标变换；这三个坐标系分别是中心为O-w(x-w,y-w,z-w)的WCS,中心为O-c(x-c,y-c,z-c)的CCS,以及中心为O-I(x-I,y-I)的IPCS；给定LED灯中心P点,点P通过摄像头的透镜中心O-c,映射到成像平面上的一个像点p,根据坐标变换原理,点P在WCS与CCS之间的坐标变换由式(1)、式(2)给出：                  R＝R-x(α)R-y(β)R-z(γ)                      (2)其中：是点P的WCS坐标,是点P的CCS坐标,是点O-c的WCS坐标；式(1)中的R表示从WCS变换到CCS的3×3旋转矩阵,且其为单位正交矩阵；R-x(α),R-y(β),R-z(γ)分别表示绕WCS的x-w轴旋转α、接着绕y-w轴旋转β以及最后绕z-w轴旋转γ的旋转矩阵,分别由式(3)、式(4)、式(5)给出：                                                      且满足以下性质：若成像平面与移动终端的屏幕所在平面相互平行,则式(2)中的α,β,γ分别等效为移动终端的滚转角、俯仰角和方位角,它们的组合用来表征移动终端的空间姿态,记为特征参数集&lt;α,β,γ&gt;；其中,滚转角α和俯仰角β表征了移动终端的倾斜状态,当它们取值均为0时,终端平面处于水平的状态；根据针孔成像的共线性性质,LED灯中心点P与像点p之间的关系如下：                  其中：是点p的IPCS坐标；是点P的CCS坐标；k表示摄像头透镜的焦距；在实际照明场景下的LED灯罩边缘的包络所在的平面未必是水平的,应考虑水平面(x-wO-wy-w)与LED灯平面存在的相对夹角θ,认为倾斜的圆形LED灯平面是由水平状态下的圆形LED平面绕x-w轴旋转Δα、再绕y-w轴旋转Δβ形成的,而绕z-w轴旋转Δγ并不会改变倾角状态,即满足Δγ＝0；因此,第i盏圆形LED灯的倾斜姿态由特征参数集&lt;Δα-i,Δβ-i,0&gt;表征,其中i＝1,2,...,M(M≥2),M为LED灯的个数；又已知LED平面的单位法向量在WCS的坐标是表述如下：                  其中&lt;Δα-i,Δβ-i,0&gt;,i＝1,2,...,M是步骤S2中获取LED灯的姿态参数集；和是求解得到的LED灯平面单位法向量在WCS的坐标,是LED平面的单位法向量在WCS的坐标,即和之一和是相等的；根据式(24),R-z(-γ)不改变和的第三分量的值,所以通过判断和的第三分量与的第三分量相等来确定l-i的值,进而确定平面法向量在式(23)的三个参数取值；根据式(20)设定Φ-i(x″,y″,z″)是一个半径为L-i的圆,将一般式圆方程转化成标准式圆方程,便可求解出LED灯中心在坐标系(O″x″y″z″)的坐标(x″-i,y″-i,z″-i)为：                  其中,L-i表示步骤二获取的第i个LED灯的灯罩半径,A-i、B-i、C-i和D-i的取值如下：                  其中q-(ij)由式(19)定义；因此根据式(12)和式(19)定义的坐标变换,LED灯中心在CCS的坐标为：                  因为式(26)存有两个解,故式(28)也有两个解；但由于LED中心坐标在CCS的z-c轴的坐标值大于0,只有一个解满足该条件,即式(28)中只有一个解是正确的；步骤7的具体步骤如下：根据坐标变换原理的式(1)、(2),则可以得到每个LED灯中心在WCS和CCS的坐标变换关系：                  观察上式(29)可知,其每个LED灯包括三个独立的等式方程,四个未知参数分别是方位角γ和移动终端在WCS的估计位置坐标而四个未知参数至少需要四个独立方程才能求解,故求解方程组需要满足M≥2；采用非线性估计方法或者线性估计方法来进行求解(29),即可获得移动终端的位置坐标的估计值。</td>   <td>G06T7/73;G06T7/66</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金舒原;              鲁金钿;                   陈浩       </td>   <td>中山大学</td>   <td>一种基于分布式信息流控制的跨云资源共享系统及方法</td>   <td>广东省</td>   <td>CN110990858B</td>   <td>2023-01-17</td>   <td>本发明提供的基于分布式信息控制的跨云资源共享系统及方法实现对云数据资源的细粒度跟踪及控制,从保密性和完整性方面严格保护共享数据的过程安全,系统开销小且不会造成额外的存储开销。</td>   <td>1.一种基于分布式信息流控制的跨云资源共享系统,其特征在于,包括注册管理模块、数据管理模块、身份认证模块、信息流控制模块、日志数据库和日志审计模块；所述的注册管理模块用于完成对资源请求云和资源提供云的信息注册；所述的身份认证模块用于完成当资源共享时资源请求云和资源所属云的身份认证；所述的数据管理模块用于存储云在注册时候提交的所拥有资源目录及数据映射关系,方便在根据资源请求云所发送的参数查询并确定资源所属云,进而辅助完成云身份认证；所述的信息流控制模块用于对接收到的资源提供云的数据资源进行降密、认证的安全操作；然后,对数据进行标记或重新标记；若所接收的数据未被标记则对其使用保密性标记和完整性标记进行标记,若接收的是标记后的数据,则在降密、认证操作完成后对数据进行重新标记；最后,将数据资源及相应操作特权传递给资源请求云；所述的日志数据库用于存储所述注册管理模块、数据管理模块、身份认证模块和信息流控制模块生成的日志信息；所述的日志审计模块用于对日志数据库中的日志信息进行审计分析,进行行为安全预警和检测。</td>   <td>G06F21/60;G06F21/62;G06F21/55</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              刘付康;              朱雄泳;              陈荣军;                   陆许明       </td>   <td>中山大学</td>   <td>一种低动态范围图像逆向生成高动态范围图像的方法</td>   <td>广东省</td>   <td>CN110009574B</td>   <td>2023-01-17</td>   <td>本发明公开了一种亮度、色彩自适应与细节丰富的低动态范围图像逆向生成高动态范围图像的方法,本发明方法首先对输入的低动态范围图像亮度灰度图全局细节增强；再由直方图裁剪与补偿、亮度与标准差估算模型获得输入图像到中间高动态范围图像的亮度直方图全局映射曲线,其中由最大熵亮度估算方法自适应选出最优输出中间高动态范围图像亮度；然后对中间高动态范围图像灰度图利用高效滤波器滤波去除映射产生的伪影得到输出高动态范围图像亮度；最后合并色彩通道并对色彩进行自适应校正,生成的高动态范围图像很好的体现了真实场景。本发明能将输入图像映射到高动态范围图像,输出的高动态范围图像亮度与色彩自适应,细节重现,视觉效果真实震撼。</td>   <td>1.一种低动态范围图像逆向生成高动态范围图像的方法,其特征在于,包括：a)对输入图像亮度灰度图进行全局细节增强,计算输入图像亮度灰度图细节增强后的对数,利用对数转换初步压缩原始场景中的亮度；其中所述图像为低动态范围图像或高动态范围图像；b)对全局细节增强的输入图像亮度对数进行直方图统计,计算其平均值与标准差,对直方图进行分段裁剪与补偿；c)由亮度与标准差估算模型计算映射到中间高动态范围图像的平均亮度与标准差,从而求解输入图像到中间高动态范围图像的亮度直方图全局映射曲线,其中由最大熵亮度估算方法自适应估算出最优输出中间高动态范围图像亮度；d)利用高效滤波器对中间高动态范围图像亮度滤波去除映射产生的伪影得到输出高动态范围图像亮度；e)将输入图像色彩通道映射到对应输出高动态范围图像色彩通道并进行自适应校正,合并色彩空间获得输出高动态范围图像；所述步骤a)包括：a1)定义输入图像红绿蓝三个色彩通道的数据分别为R,G,B,定义输入图像亮度L-w：L-w＝0.299R+0.587G+0.114B    (1)a2)定义输入高动态范围图像大尺度纹理层为b：                  其中,I为单位矩阵；α是平衡因子；Q-x,Q-y是前向差分算子；是后向差分算子；A-x和A-y是分别包含平滑权重a-x(L-w)和a-y(L-w)的对角矩阵；平滑权重a-x(L-w)和a-y(L-w)分别定义如下：                                    其中,ε-1是常数；β是决定ln(L-w)梯度灵敏度的参数；a3)计算输入图像亮度的对数L-e：L-e＝ln(L-w)    (5)a4)定义输入图像亮度细节层对数d：d＝L-e-ln(b)    (6)a5)定义输入图像全局增强亮度的对数L'-e：L'-e＝λ-1ln(b)+λ-2d    (7)其中,λ-1是修正因子；λ-2是增强因子,定义为：                  其中,μ-(Input)为输入图像平均亮度；C为输入图像对比度；μ-(Input)和C分别定义如下：                                    其中,M和N是输入高动态范围图像的长和宽；L-w(i,j)表示位置为(i,j)像素点的亮度值；δ(τ,υ)＝|τ-υ|即是相邻像素间的亮度τ和亮度υ的差值绝对值,P-δ(i,j)即相邻像素间的亮度灰度差为δ的像素分布概率。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈楚城;                   戴宪华       </td>   <td>中山大学</td>   <td>一种基于深度学习的铝材表面缺陷检测算法</td>   <td>广东省</td>   <td>CN109711474B</td>   <td>2023-01-17</td>   <td>本发明涉及一种基于深度学习的铝材表面缺陷检测算法,包括：(1)利用摄像头对铝材表面进行拍摄,获取相关数据集并用labelImg工具对图像进行标注,获取标签信息；(2)将图像划分成训练集和测试集,并对训练集进行数据增强；(3)每次同时输入一张有缺陷图像和无缺陷图像及有缺陷图像的标签信息到网络中进行模型训练；(4)将测试图像输入到训练好的铝材表面缺陷检测模型,获取缺陷的位置和对应的类别。本发明的方法可以有效利用有缺陷图像和无缺陷图像,提高模型的泛化能力和检测精度,通过充分利用候选区域周围的上下文信息进一步提高检测性能,利用软的非极大值抑制算法可以提高对密集小缺陷的检测性能,是一种高效的铝材表面缺陷检测算法。</td>   <td>1.一种基于深度学习的铝材表面缺陷检测算法,其特征在于包括如下步骤：(1)图像采集,利用摄像头对铝材表面进行拍摄,获取相关的图像并对图像重命名,采用labelImg工具对拍摄的图像进行标注,获取图像中关于缺陷的标签,缺陷的标签包含了缺陷在图像中左上角的坐标(x1,y1),右下角的坐标(x2,y2)和缺陷的类别defectN,其中N表示数字,如果拍摄的图像中没有缺陷,不会用labelImg进行处理,只记录其类别信息norm；(2)图像划分,将图像划分成训练集和测试集两部分,两个部分不存在相同的图像,训练集用来训练检测模型,测试集用来评估检测模型的性能；(3)图像预处理,包括随机上下翻转、随机左右翻转和随机光照改变,其中随机上下翻转、随机左右翻转和随机光照改变只针对训练集,当进行随机上下翻转和随机左右翻转的时候,缺陷的坐标信息也需要做出相应的变化；(4)训练检测模型,将经过图像预处理后的训练集中的图像和标签信息输入到铝材表面缺陷检测模型中进行训练,每次同时输入一张有缺陷的图像和一张无缺陷的图像,获取各图像中缺陷的预测框和类别,并与实际的标签信息中的真实框和类别进行对比,计算出定位误差和分类误差,然后采用多学习任务的方法,利用带动量的梯度下降算法进行训练；(5)检测铝材图像,将测试集中的图像输入到训练好的铝材表面缺陷检测模型中进行检测,获得铝材图像中缺陷的位置和类型；所述步骤(5)中测试过程具体为测试图像通过铝材表面缺陷检测模型后得到若干个预测框的位置和对应的类别,对这些预测框进行软的非极大值一致,最后保留类别置信度高于某个阈值的若干个预测框作为最后的输出结果；对得到的预测框使用软的非极大值抑制,最后保留类别置信度高于某个阈值的若干个候选框作为最后的输出结果,具体就是针对所有的预测框采用以下方式进行处理：首先,对于某一类别的缺陷,按照得到的置信度进行从大到小的排序,然后固定第1个预测框,依次计算其与第2个到最后一个预测框的交叠率,如果交叠率小于等于某一阈值,对应预测框的置信度不变化,如果交叠率大于某一个阈值,则更新该预测框对应此类别的置信度,更新置信度的公式为：                  其中M表示固定的候选框,b-i表示与固定的预测框进行交叠率计算的候选框,s-i表示b-i对应此类别的置信度,δ是超参数；采用迭代的方式依次固定第2个,第3个…,倒数第2个预测框,进行上面的操作；同样的,对于其他类别也采用以上方式进行处理；最后输出类别置信度高于某个阈值的预测框,作为铝材表面缺陷检测模型的输出结果。</td>   <td>G06V10/774;G06V10/762;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              吴炆芳;              朱雄泳;              陈荣军;                   陆许明       </td>   <td>中山大学</td>   <td>基于NSCT和PCNN的压缩感知域内的高动态范围图像融合方法</td>   <td>广东省</td>   <td>CN109978802B</td>   <td>2023-01-17</td>   <td>本发明公开了一种基于NSCT和PCNN的压缩感知域内的高动态范围图像融合方法,包括如下步骤：1)对输入多曝光图像序列进行归一化处理；2)对归一化处理后的多曝光图像序列使用相机响应函数进行辐射校准；3)对辐射校准后的多曝光图像序列进行NSCT变换得到各图像的低、高频系数；4)对各图像的高频系数进行压缩采样；5)计算各图像低、高频系数的空间频率作为PCNN网络的激励信号,通过最大值决策进行融合；6)对融合后的高频系数进行压缩感知重构；7)对融合后的低、高频系数进行NSCT逆变换,得到目标高动态范围图像。利用NSCT、PCNN和压缩感知方法完成对多曝光的低动态范围图像序列在压缩感知重构的同时融合,最后生成一幅包含丰富细节的高动态范围图像。</td>   <td>1.一种基于NSCT和PCNN的压缩感知域内的高动态范围图像融合方法,其特征在于,包括有如下步骤：1)对输入多曝光图像序列进行归一化处理；2)对归一化处理后的多曝光图像序列使用相机响应函数进行辐射校准；3)对辐射校准后的多曝光图像序列进行NSCT变换得到各图像的低、高频系数；4)对各图像的高频系数进行压缩采样；5)计算各图像低、高频系数的空间频率作为PCNN网络的激励信号,通过最大值决策进行融合；6)对融合后的高频系数进行压缩感知重构；7)对融合后的低、高频系数进行NSCT逆变换,得到目标高动态范围图像；所述步骤4)的具体实现过程为：41)对经过NSCT变换的各图像的高频系数矩阵,记为Coef-H,进行稀疏表示,得到Coef-H＝ψθ,其中ψ为稀疏表示基,设计观测矩阵Φ,则压缩采样的过程重写为：y＝ΦCoef-H＝Φψθ＝Θθ                      (1)所述步骤41)还包括如下内容：411)设计稀疏表示基,采用DCT基,定义图像的长度和宽度分别为row、col,则DCT的大小为row*row,通过如下方式生成：设有数据序列Data(n),n＝0,1,...,(N-1),则DCT基生成方式为：                                    得到变换矩阵ψ：                  412)观测矩阵Φ的行数为row乘上采样率,列数大小为row；传感矩阵Θ＝Φψ应满足RIP性质：保证观测矩阵不会把两个不同的稀疏信号映射到同一个集合中,保证原空间到稀疏空间的一一映射关系,定义观测矩阵Φ的RIP常数δ-h为满足下式的最小值：                  其中高频系数矩阵Coef-H为h稀疏的,即含有h个非零元素,若δ-h≤1,测成矩阵满则h阶RIP条件；所述步骤5)的具体实现过程为：51)定义第l层中第k个方向子带(i,j)的系数为则NSCT域内的空间频率定义为：                  52)初始化PCNN参数如下：迭代次数n：200；链接范围：3；衰变常数：α-l＝1、α-θ＝0.2；链接强度：β＝3；振幅增益：V-L＝1.0、V-θ＝20；链接权矩阵为53)将计算出的空间频率作为PCNN的输入以刺激神经元产生脉冲响应,计算公式如下所示：                                                                                          其中等于空间频率的大小,为链接范围内神经元点火次数总和,W-(ij,pq)为链接权重,p,q为PCNN中链接范围大小,分别为神经元的内部状态信号的外部输出,为阈值；如果则神经元将产生一个脉冲称为一次点火；54)计算点火次数,得到点火图,点火次数的计算如下：                  设定为两幅图像,定义点火图如下：                  55)设定为两幅图像,选取具有最大点火次数的系数作为最终融合图像的系数：                  其中和分别表示融合图像及两幅图像的系数；所述步骤6)的具体实现过程为：61)初始化：令标签索引集残差向量r-0＝y,y即为步骤41)中所获得的观测向量,迭代次数t＝1；62)辨识：在传感矩阵Θ中求出与残差向量r-(t-1)最相关的所对应的列向量λ-t,即内积值最大时所对应的索引：                  其中row为传感矩阵的列数,Θ-c表示传感矩阵的第c列；63)更新：更新标签索引集Λ-t＝Λ-(t-1)∪{λ-t},将找到的原子所对应的列向量添加到集合其中,t＞0,Λ-t表示t次迭代的索引,Θ-t表示按索引Λ-t选出的矩阵Θ的列集合；64)估计：求y＝Θθ的最小二乘解：                  65)更新残差向量                  66)令t＝t+1；并不断重复步骤62)至步骤66),若满足某个迭代停止条件,则停止迭代并进入第67)步；67)求得输出系数向量                  步骤66)中所述迭代停止条件包括3种情况：661)当运行到t＞s时,迭代停止,其中,s表示固定的迭代步数；662)残差向量的能量值小于某个预先给定的常数ε,例如取1e-6；||r-t||-2≤ε                            (14)663)当传感矩阵Θ的任何一列都没有残差向量r-t的明显能量时：||Θ～Tr-t||∞≤ε                         (15)。</td>   <td>G06T5/50;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任江涛;                   程僚       </td>   <td>中山大学</td>   <td>基于知识图谱的问答方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN110837550B</td>   <td>2023-01-17</td>   <td>本发明公开了一种基于知识图谱的问答方法、装置、电子设备及存储介质,所述基于知识图谱的问答方法包括：响应于触发进行的用户输入请求,获得问句；对经过命名实体识别得到的所述问句中实体,在已构建的知识图谱中进行实体链接,得到候选实体；在所述知识图谱中确定包含所述候选实体的搜索子图,根据所述搜索子图生成由所述候选实体指向候选答案的若干条候选路径；根据所述问句的上下文信息,从若干条所述候选路径中筛选得到目标路径,将所述目标路径中所述候选实体指向的候选答案作为所述问句的答案推送给用户。采用本发明所提供的基于知识图谱的问答方法、装置、电子设备及存储介质解决了现有技术中基于知识图谱的问答的准确率不高的问题。</td>   <td>1.一种基于知识图谱的问答方法,其特征在于,包括：响应于触发进行的用户输入请求,获得问句；对经过命名实体识别得到的所述问句中实体,在已构建的知识图谱中进行实体链接,得到候选实体；基于所述候选实体在所述知识图谱中的周边关系以及所述知识图谱的结构,通过最大关系搜索确定包含所述候选实体的搜索子图,根据所述搜索子图生成由所述候选实体指向候选答案的若干条候选路径；其中,若干条候选路径的生成过程包括：以所述候选实体作为路径第一跳的起点,基于深度学习模型配置的attention机制,在所述知识图谱中对所述路径第一跳的起点进行最大关系搜索；根据搜索到所述路径第一跳的起点在所述知识图谱中的最大关系,生成所述路径第一跳,并以所述路径第一跳的终点作为路径第二跳的起点,开始进行所述路径第二跳的起点在所述知识图谱中的最大关系搜索；直至路径最后一跳的终点满足路径截止条件,停止所述知识图谱中关于所述路径最后一跳的最大关系搜索,得到包含所述候选实体的搜索子图；以所述搜索子图中所述路径最后一跳的终点作为所述候选答案,得到由所述候选实体指向所述候选答案的若干条所述候选路径；根据若干条所述候选路径的上下文信息和所述问句的上下文信息,确定若干条所述候选路径的分数；基于若干条所述候选路径的分数以及若干条所述候选路径中候选实体的分数,从若干条所述候选路径中筛选得到目标路径,将所述目标路径中所述候选实体指向的候选答案作为所述问句的答案推送给用户。</td>   <td>G06F16/332;G06F16/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金舒原;                   李维龙       </td>   <td>中山大学</td>   <td>一种基于图卷积的恶意软件API调用序列检测方法</td>   <td>广东省</td>   <td>CN111259388B</td>   <td>2023-01-17</td>   <td>本发明提出一种基于图卷积的恶意软件API调用序列检测方法,包括以下步骤：采集并记录大量软件样本运行时的进程及子进程的API调用序列信息；对API调用序列信息进行向量化处理；抽取API函数的参数关系、依赖关系以及顺序关系；建立API调用图；将API调用图输入到图卷积神经网络中进行训练,得到恶意软件检测网络模型；将待检测的可执行文件运行时的进程及子进程的API调用序列信息进行采集,构建待检测的可执行文件的API调用图,然后将待检测的可执行文件的API调用图输入恶意软件检测网络模型中,若恶意软件检测网络模型的输出结果为1,则表示判定结果为恶意软件；若恶意软件检测网络模型的输出结果为0,则表示判定结果为正常软件。</td>   <td>1.一种基于图卷积的恶意软件API调用序列检测方法,其特征在于,包括以下步骤：S1：采集并记录大量软件样本运行时的进程及子进程的API调用序列信息,其中,所述API调用序列信息包括API函数和API参数；S2：对所述API调用序列信息进行向量化处理；S3：根据经过向量化处理的API调用序列信息,抽取所述API函数的参数关系、依赖关系以及顺序关系；所述S3步骤中,抽取所述API函数的参数关系、依赖关系以及顺序关系的具体步骤包括：S31：抽取所述API函数的参数关系：若某个API调用使用了文件名或注册表作为参数,则表示API调用与该文件或注册表存在参数关系；S32：抽取所述API函数的依赖关系：对每一个API调用序列,遍历其中API调用参数中的指针或句柄,若API调用api-a时使用了由API调用api-b返回或修改的指针或句柄作为参数,则表示调用api-a在参数上依赖于调用api-b,存在依赖关系；S33：抽取所述API函数的顺序关系：在同一程序中,若API调用api-b在API调用api-a之后调用,则表示调用api-b在参数上与调用api-a存在顺序关系；其中,api-a和api-b表示API函数；S4：根据经过向量化处理的API调用序列信息以及抽取的API函数的参数关系、依赖关系以及顺序关系建立API调用图；S5：将所述API调用图输入到图卷积神经网络中进行训练,得到恶意软件检测网络模型；S6：将待检测的可执行文件运行时的进程及子进程的API调用序列信息进行采集,执行S2～S4步骤得到所述待检测的可执行文件的API调用图,然后将所述待检测的可执行文件的API调用图输入所述恶意软件检测网络模型中,若所述恶意软件检测网络模型的输出结果为1,则表示判定结果为恶意软件；若所述恶意软件检测网络模型的输出结果为0,则表示判定结果为正常软件。</td>   <td>G06F21/56;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         戎利民;              刘斌;              余海阳;              庞卯;              刘珍珍;              骆秋霞;              陈宇勇;              武文斌;              刘仲宇;              陈子豪;              杨阳;              陈东亮;              温会泉;              谢沛根;                   吴亮       </td>   <td>中山大学附属第三医院(中山大学肝脏病医院)</td>   <td>基于MRI多模态神经成像评估脊髓损伤程度的方法</td>   <td>广东省</td>   <td>CN113284105B</td>   <td>2023-01-17</td>   <td>本发明公开了一种基于MRI多模态神经成像评估脊髓损伤程度的方法,基于MRI扫描损伤部位、高位颈脊髓和腰膨大以获得多模态神经成像,使用医学影像处理软件对神经成像中的靶区进行勾画,根据医学影像处理软件逐层计算整体脊髓面积、脊髓灰质、脊髓白质、后索高信号以及后索的以定量评估神经退变,能够从多角度多方面特别是神经微观结构反映病变组织的综合信息,让研究者和医生可以进行系统性的客观定量评估中枢神经系统继发性损伤的严重程度,还能对患者远期的预后进行预测。</td>   <td>1.一种基于MRI多模态神经成像评估脊髓损伤程度的方法,其特征在于：首先,基于MRI扫描损伤部位、高位颈脊髓和腰膨大以获得多模态神经成像；其次,使用医学影像处理软件对神经成像中的靶区进行勾画；最后,根据医学影像处理软件逐层计算脊髓面积、灰质面积、后索高信号区域,以定量评估神经退变程度；勾画神经影像靶区步骤包括使用医学影像处理软件对损伤部位、高位颈髓和腰膨大的轴位高分辨T2成像、弥散张量DTI成像进行坐标校正,使轴位高分辨T2成像同患者的3DT2的解剖像对应；接着使用医学影像处理软件在高分辨T2成像上对损伤部位病灶,以及高位颈髓和腰膨大的脊髓、脊髓的灰质、脊髓的后索区域的高信号区域进行逐层手工分割；所述定量评估神经退变步骤包括首先根据患者3DT2解剖像将脊髓根据节段进行划分,接着使用医学影像处理软件逐层计算整体脊髓面积、脊髓灰质面积、脊髓白质面积、后索的高信号面积,以勾画的靶区为基础创造掩模,提取掩模中各层脊髓的弥散张量成像DTI的FA值和T2值的平均值,作为评估脊髓损伤程度的依据。</td>   <td>G06T7/00;G06T7/13;G06T5/30;A61B5/00;A61B5/372</td>  </tr>        <tr>   <td>中国专利</td>   <td>              姚军艇       </td>   <td>中山大学</td>   <td>一种基于多任务学习模型的AI换脸视频检测方法</td>   <td>广东省</td>   <td>CN113361395B</td>   <td>2023-01-17</td>   <td>本发明公开了一种基于多任务学习模型的AI换脸视频检测方法,属于计算机视觉与深度学习领域,该检测方法具体步骤如下：(1)用户上传待检测视频；(2)构建人脸图像伪造检测器；(3)对视频进行逐帧取图；(4)对提取出的图片进行图片筛选；(5)对剩余图片进行换脸检测；(6)将检测结果反馈给用户；本发明能够避免计算机感染病毒,降低用户信息被窃取的风险,保护用户财产安全,同时人脸图像伪造检测器可以不断进行更新学习,不断提高其工作效率,方便工作人员查看,防止工作人员手动记录出现误差,提高工作人员的工作效率。</td>   <td>1.一种基于多任务学习模型的AI换脸视频检测方法,其特征在于,该检测方法具体步骤如下：(1)用户上传待检测视频：用户通过外部输入设备向计算机上传待检测视频,其中,外部输入设备具体为键盘、鼠标或触控屏中的一种,视频上传成功,用户将其放入检测软件；(2)构建人脸图像伪造检测器：检测软件接收到视频,并开始与互联网进行数据交互,并对其中换脸检测数据进行数据抓取,同时对抓取的数据进行安全检测,并开始构建人脸图像伪造检测器；(3)对视频进行逐帧取图：人脸图像伪造检测器开始自行扫描待检测视频,并对视频数量进行计算,同时进行检测排序,视频排序完成,人脸图像伪造检测器对视频进行逐帧取图；(4)对提取出的图片进行图片筛选：图片提取完成,开始构建图片筛选器,构建完成,图片筛选器开始与特征信息库进行数据交互,并开始对提取出的图片进行对比筛选；(5)对剩余图片进行换脸检测：对筛选后的图片进行伪造检测,并将检测结果分别录入XLSX工作表中,并在该XLSX工作表中标注检测时间；(6)将检测结果反馈给用户：将检测结果通过显示设备反馈给用户,同时用户可通过输入设备对XLSX工作表进行检索查看,并通过打印设备对其进行打印处理,其中,显示设备具体为CRT显示屏、LCD显示屏或LED显示屏,其中,打印设备具体为激光打印机、喷墨打印机或针式打印机；所述安全检测具体步骤如下：步骤一：从互联网上实时抓取FaceForensics、Face2Face、FaceSwap以及DeepFakes数据集,同时启动防火墙；步骤二：防火墙开始对各数据集中的数据进行检测,并对其中的病毒数据进行删除,同时将删除的病毒数据记录在云端病毒信息库中；步骤三：数据检测完成,将FaceForensics、Face2Face、FaceSwap以及DeepFakes数据集训练成当前最佳的人脸图像伪造检测器；所述检测排序具体步骤如下：第一步：开始收集用户上传的视频信息,并将其按照上传时间先后,进行排序；第二步：用户通过外部输入设备对视频进行排列调整,人脸图像伪造检测器开始依据用户调整信息对视频排列顺序进行更新；所述逐帧取图具体步骤如下：S1：将待检测的视频按照一帧进行视频分割处理,并将分割完成的片段分别标记为A1、A2、A3、…、An,其中,n为自然数,且n大小依次增加；S2：将A1～An转换为图片,并将其按照切割时间进行排序；所述对比筛选具体步骤如下：SS1：图片筛选器开始从特征信息库中提取人类特征信息,并将其处理生成对比数据；SS2：将A1～An分别与对比数据进行比对,并将其中不包含人类特征的图片删去,同时将经过筛选的图片分别标记为B1、B2、B3、…、Bm,其中,m为自然数,且m大小依次增加；所述伪造检测具体步骤如下：P1：将B1～Bm依次进行色彩空间转换,并开始对比转换前后边缘、纹理以及表面的差异；P2：若低对比度边缘与高对比度边缘一样明亮,则开始对比纹理差异,若低对比度边缘与高对比度边缘的明亮度存在差异,则判断该视频为换脸视频；P3：若纹理细节较多的区域的着色高于光滑的表面,则开始对比表面差异,若纹理细节较多的区域的着色低于光滑的表面,则判断该视频为换脸视频；P4：若表面在转换前后着色都一致,则判断该视频非换脸视频,若表面在转换前后着色不一致,则判断该视频为换脸视频；P5：检测完成,将视频名称以及判断结果进行数据匹配,同时将匹配完成的数据有序的录入XLSX工作表中,并在该XLSX工作表中标注检测时间。</td>   <td>G06V20/40;G06V10/774;G06V40/16;G06V10/26;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              章杨清;              黄宝莹;              赵山河;              尹川学;              郭海旭;                   郑子彬       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>账户状态模型构建方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115618008A</td>   <td>2023-01-17</td>   <td>本申请涉及一种账户状态模型构建方法、装置、计算机设备和存储介质。所述方法包括：获取历史用户特征数据；根据历史用户特征数据构建用户特征图谱；基于用户特征图谱中各节点的节点属性特征与模型训练参数初值生成对应的节点初始特征向量,模型训练参数初值为账户状态模型中待训练参数的初始值；基于节点初始特征向量融合得到关联矩阵,关联矩阵用于表征各节点的关联关系以及各节点的重要性；基于用户特征图谱、关联矩阵以及节点初始特征向量得到特征输入样本数据；基于特征输入样本数据训练得到账户状态模型,账户状态模型用于评估目标账户的操作状态。采用本方法能够有效提高账户状态模型预测的准确度。</td>   <td>1.一种账户状态模型构建方法,其特征在于,所述方法包括：获取历史用户特征数据；根据所述历史用户特征数据构建用户特征图谱；基于所述用户特征图谱中各节点的节点属性特征与模型训练参数初值生成对应的节点初始特征向量,所述模型训练参数初值为所述账户状态模型中待训练参数的初始值；基于所述节点初始特征向量融合得到关联矩阵,所述关联矩阵用于表征所述各节点的关联关系以及各节点的重要性；基于所述用户特征图谱、所述关联矩阵以及所述节点初始特征向量得到特征输入样本数据；基于所述特征输入样本数据训练得到账户状态模型,所述账户状态模型用于评估目标账户的操作状态。</td>   <td>G06F16/36;G06F18/24;G06F18/25;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李浩源;              由林麟;              侯英威;              郭子晗;              吴承瀚;                   林俊龙       </td>   <td>中山大学</td>   <td>一种基于联邦学习和区域规避的安全个性化出行推荐系统</td>   <td>广东省</td>   <td>CN115619057A</td>   <td>2023-01-17</td>   <td>本发明公开了一种基于联邦学习和区域规避的安全个性化出行推荐系统,系统包括：用户终端与服务端,用户终端先对全局模型进行联邦训练,服务端将不包含用户信息的全局模型进行联邦学习聚合再下发到用户终端,用户终端利用联邦学习聚合的全局模型预测用户的个性化出行方式,并利用最新的地区风险信息与服务端下发的路径规划算法确定出行路线。本发明将全局模型再本地进行训练,可以实现不向服务端泄露用户的个人数据,保护用户的隐私安全,且可以根据服务端下发的路径规划算法选择出行路线,合理利用了服务端的调度能力,本发明可以广泛应用于路径规划领域。</td>   <td>1.一种基于联邦学习和区域规避的安全个性化出行推荐系统,其特征在于,包括用户终端与服务端；所述用户终端,用于：从所述服务端获取地区风险信息,并获取用户根据所述地区风险信息确定的目的地；从所述服务端获取第一全局模型,根据所述地区风险信息与所述目的地对所述第一全局模型进行联邦学习,并将联邦学习训练后的第一全局模型上传至所述服务端,将联邦学习训练后的第一全局模型作为第二全局模型；利用第三全局模型并结合所述地区风险信息预测所述用户的出行方式,利用路径规划算法并结合所述出行方式预测所述用户从指定的出发点到所述目的地的第一出行路线；所述服务端,用于：将所述第二全局模型进行联邦学习聚合,在公开数据集上对联邦学习聚合后的第二全局模型进行检验,并将达到预设的检验要求的第二全局模型以及路径规划算法下发至所述用户终端,将达到预设的检验要求的第二全局模型作为第三全局模型。</td>   <td>G06Q10/047;G06F21/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王自鑫;              张仕杰;              陈弟虎;              胡胜发;              汤锦基;                   袁悦来       </td>   <td>中山大学;广州安凯微电子股份有限公司</td>   <td>一种基于高层次综合工具的图像处理方法及系统</td>   <td>广东省</td>   <td>CN115619618A</td>   <td>2023-01-17</td>   <td>本发明涉及图像处理技术领域,提出一种基于高层次综合工具的图像处理方法及系统,包括步骤：构建图像处理流程,其中包括依次执行的基于GAUSS算法的图像去噪处理、基于SOBEL算法的边缘提取处理、基于HARRIS算法或FAST算法的特征点提取处理；利用高层次综合工具对图像处理流程采用循环展开处理、数据流处理、流水线处理与数据分割处理中的一种或多种进行优化,生成图像处理IP核；将图像处理IP核在Vivado HLS工具中进行C/RTL联合仿真,通过仿真验证后,在FPGA中调用图像处理IP核以完成图像处理。本发明利用高层次综合工具进行的图像处理算法的设计与优化,针对图像处理算法进行并行化改进,从而提升图像处理速度,满足高速高吞吐量的应用需求,尤其适用于工业实时检测领域。</td>   <td>1.一种基于高层次综合工具的图像处理方法,其特征在于,包括以下步骤：构建图像处理流程,其中包括依次执行的基于GAUSS算法的图像去噪处理、基于SOBEL算法的边缘提取处理、基于HARRIS算法或FAST算法的特征点提取处理；利用高层次综合工具对所述图像处理流程采用循环展开处理、数据流处理、流水线处理与数据分割处理中的一种或多种进行优化,生成图像处理IP核；将所述图像处理IP核在Vivado HLS工具中进行C/RTL联合仿真,通过仿真验证后,在FPGA中调用所述图像处理IP核以完成图像处理。</td>   <td>G06T1/20;G06T5/00;G06T7/11;G06T7/13;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张亚琴;              陶雨溪;              韩佳悦;                   陈铭       </td>   <td>中山大学附属第五医院</td>   <td>基于FFDM的乳腺影像处理方法、系统、终端和介质</td>   <td>广东省</td>   <td>CN115619641A</td>   <td>2023-01-17</td>   <td>本发明提供了一种基于FFDM的乳腺影像处理方法、系统、终端和介质,方法包括：根据第一乳腺X线数据集和第二乳腺X线数据集构建第一数据集和第二数据集；第一乳腺X线数据集为DFM数据集,第二乳腺X线数据集为FFDM数据集；通过第一数据集训练预设的生成式对抗网络；通过训练好的生成式对抗网络,基于所述第二数据集生成目标乳腺X线数据集；其中,所述目标乳腺X线数据集为FFDM影像。相比于现有技术,采用了生成式对抗网络,在进行乳腺癌筛查过程中不需要额外进行标记；基于DFM的第二数据集生成相对更高分辨率的FFDM目标乳腺X线数据集,提高了影像的质量,使生成的影像与真实影像更为相近。</td>   <td>1.一种基于FFDM的乳腺影像处理方法,其特征在于,包括：从第一乳腺X线数据集和第二乳腺X线数据集中选取第一数据集,并根据所述第一乳腺X线数据集中未被选取的剩余数据集构建第二数据集；其中,所述第一乳腺X线数据集为DFM数据集,第二乳腺X线数据集为FFDM数据集；通过所述第一数据集训练预设的生成式对抗网络；其中,所述生成式对抗网络的生成器包括U-Net生成器；所述生成式对抗网络的鉴别器包括多尺度DNN架构；通过训练好的生成式对抗网络,基于所述第二数据集生成目标乳腺X线数据集；其中,所述目标乳腺X线数据集为FFDM影像。</td>   <td>G06T3/40;G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢志;              丁小燕;              何尧;                   周昊       </td>   <td>中山大学中山眼科中心</td>   <td>一种幼儿眼底视网膜全景影像图谱生成和随访数据对齐方法</td>   <td>广东省</td>   <td>CN115619747A</td>   <td>2023-01-17</td>   <td>本发明公开一种幼儿眼底视网膜全景影像图谱生成和随访数据对齐方法,通过十几例影像数据结合临床指南中图例便可以快速生成指南中对应疾病的视网膜影像图谱,再利用生成的影像图谱,能够对新的影像数据进行空间上的映射对齐,利用生成的影像图谱,能够对随访数据进行时间和空间上的映射对齐,以早产儿视网膜病变为例,能快速辅助医生进行随访数据在空间对齐后进行时间序列的分析。</td>   <td>1.一种幼儿眼底视网膜全景影像图谱生成和随访数据对齐方法,其特征在于,包括以下步骤：S1：整理若干例的方位图影像数据,每一例按左眼和右眼进行分组后,分别进行拼接融合得到每一例的全景图,再将所有的全景图进行配准变换叠加后,得到左眼和右眼对应的眼底影像图谱；S2：收集眼底方位影像,按左眼和右眼进行分组后,确定左/右眼的标准目标图,并利用标准目标图与眼底影像图谱计算由标准目标图向眼底影像图谱转换的关系矩阵,其它眼底方位影像拼接融合得到全景影像后,根据由标准目标图向眼底影像图谱转换的关系矩阵进行配准转换,再根据全景影像的视盘和黄斑坐标以及制作的影像图谱中的对应坐标进行尺度和位置的对齐；S3：获取多次随访的检查影像数据,根据检测日期分组后,对于每一组的检查数据,按左眼和右眼进行分组后,按照步骤S1生成左眼和右眼的标准图谱结果图,并按时间顺序排列生成的标准图谱结果图,完成随访数据在时间序列和空间方向上的对齐。</td>   <td>G06T7/00;G06T7/11;G06T5/50;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗毅;              郑永森;              陈子良;                   聂琳       </td>   <td>中山大学</td>   <td>基于片段和自注意力机制的序列推荐方法及系统</td>   <td>广东省</td>   <td>CN113343097B</td>   <td>2023-01-13</td>   <td>本发明公开了一种基于片段和自注意力机制的序列推荐方法及系统,所述方法包括：将输入的物品序列重组为片段序列；利用神经网络模型对所述片段序列进行特征提取；将部分提取结果输入至softmax函数,利用所述softmax函数预测每个物品为下一推荐物品的概率；根据所述概率建立神经网络模型的损失函数,当所述损失函数未满足预设条件时,将剩余提取结果输入至神经网络模型进行模型训练,直至所述损失函数满足预设条件时,将对应的神经网络模型作为目标模型,用于物品的序列推荐。本发明通过对BERT4Rec作出改进,使其性能优于现有技术下的BERT4Rec或其它推荐模型,最终提高了真实环境下物品序列推荐结果的准确度。</td>   <td>1.一种基于片段和自注意力机制的序列推荐方法,其特征在于,包括：将输入的物品序列重组为片段序列,包括：获取物品序列：                  式中,表示序列中的第t个物品,t表示时间戳；获取物品序列的子序列：                  式中,{,}表示向量的拼接,r表示片段的长度；x-t＝v-t+p-t,v-t、p-t分别表示物品的d维嵌入向量、位置向量；重组子序列,得到片段序列：                  式中,a表示片段的步长,n-u表示原物品序列的长度；将片段序列表示为矩阵形式：                  利用神经网络模型对所述片段序列进行特征提取；所述神经网络模型为transformer网络,包括：自注意力层,用于对所述片段序列进行特征提取；输出层,用于输出提取结果；将部分提取结果输入至softmax函数,利用所述softmax函数预测每个物品为下一推荐物品的概率；根据所述概率建立神经网络模型的损失函数,当所述损失函数未满足预设条件时,将剩余提取结果输入至神经网络模型进行模型训练,直至所述损失函数满足预设条件时,将对应的神经网络模型作为目标模型,用于物品的序列推荐。</td>   <td>G06F16/9535;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈春;                   陈剑辉       </td>   <td>中山大学附属第七医院(深圳);广州零端科技有限公司</td>   <td>就诊线上预约方法、系统及存储介质</td>   <td>广东省</td>   <td>CN115600705A</td>   <td>2023-01-13</td>   <td>本发明公开了一种就诊线上预约方法、系统及存储介质,应用于网络技术领域,能够缓解非法抢号和倒卖预约号的问题,减少医护人员的资源浪费,并提高患者就诊体验。该方法包括：获取预约取消时间；预约取消时间为用户取消预约号的时间节点；获取预约请求数据；预约请求数据包括医生信息以及预约时间信息；根据预约请求数据确定预约时间信息中的预设可预约数；根据预约请求数据确定预约时间信息中的未取消预约数；获取时间随机量；其中,时间随机量为预约号取消后重新放号的时间量；根据预约取消时间、时间随机量、预设可预约数以及未取消预约数,计算预约时间信息的当前可预约数；确定当前可预约数满足预设要求,根据预约请求数据生成预约号。</td>   <td>1.一种就诊线上预约方法,其特征在于,包括以下步骤：获取预约取消时间；所述预约取消时间为用户取消预约号的时间节点；获取预约请求数据；所述预约请求数据包括医生信息以及预约时间信息；根据所述预约请求数据确定所述预约时间信息中的预设可预约数；根据所述预约请求数据确定所述预约时间信息中的未取消预约数；获取时间随机量；其中,所述时间随机量为预约号取消后重新放号的时间量；根据所述预约取消时间、所述时间随机量、所述预设可预约数以及所述未取消预约数,计算所述预约时间信息的当前可预约数；确定所述当前可预约数满足预设要求,根据所述预约请求数据生成预约号。</td>   <td>G06Q10/02;G06Q10/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚顺;              铁艳梅;                   王海军       </td>   <td>中山大学附属第一医院</td>   <td>一种基于功能核磁共振成像的术前语言区定位方法及系统</td>   <td>广东省</td>   <td>CN113962966B</td>   <td>2023-01-10</td>   <td>本发明公开了一种基于功能核磁共振成像的术前语言区定位方法及系统,包括：在待测人员观影时进行核磁共振扫描,获取观影模式FMRI数据；对观影模式FMRI数据进行预处理,获得预处理后的数据,并对预处理后的数据进行分析,完成大脑语言网络提取与鉴定,即语言区定位。本发明设计了较为新颖的实验范式,即基于中文语言的观影模式功能核磁共振试验范式,同时采用了稳健的神经信息提取与处理技术,可以较为理想地构建出脑损伤患者的大脑语言网络,最终建立了临床应用工作框架,具有较高的科学价值和神经外科临床应用前景。</td>   <td>1.一种基于功能核磁共振成像的术前语言区定位方法,其特征在于,包括：S1、在待测人员观影时进行功能核磁共振图像扫描,获取观影模式FMRI数据,同时扫描大脑三维高分辨率结构核磁共振图像MPRAGE；S2、对所述观影模式FMRI、MPRAGE进行预处理,得到预处理后的数据；S3、并对预处理后的数据进行空间维度和时域维度神经信息的提取分析,完成大脑语言区定位；所述S2包括：将所述观影模式FMRI数据进行格式转换,对转换格式后的所述观影模式FMRI数据进行头部矫正；获取经过头动矫正后的观影模式FMRI数据,根据每个时间点的头动参数进行头动-时间曲线重建,然后鉴定出离群体素并将其剔除；所述S2还包括对所述MPRAGE进行处理,将处理后的数据配准到蒙特利尔标准空间,并获取反转换矩阵；其中所述S2具体包括：fMRI数据预处理包含以下几个步骤：S201、数据转换,将原始DICOM文件格式转换成可分析数据NIFTI格式；S202、头动矫正,对转换后的FMRI数据进行6个方向的刚体转换方法将所有时间点图像与FMRI数据第一个时间点图像进行对齐,并根据头动校正曲线,将头动平移＜2.0mm且旋转移动＜2.0°者纳入；S203、离群体素的探测基于伪影检测工具,排除异常扫描值并进行识别,同时将离群体素剔除；离群体素定义为相对框架位移大于0.9mm或者全脑信号改变大于5个标准差,如离群体素时间点之和大于总时间点的20％,该研究被试将被剔除该实验；S204、大脑功能核磁图像与结构核磁图像进行配准,为了拟补功能影像数据的低空间分辨率,调整功能影像数据体素的空间位置；S205、选择全宽半高6毫米平滑核对所述预处理后的所述观影模式FMRI数据进行空间平滑处理；对平滑处理后的所述观影模式FMRI数据的时间信号采用高通滤波器进行滤波,带宽为0.005至0.09, 以减小噪声和配准过程中产生的微小偏差,但是平滑核的选择至关重要,过大则容易产生假阳性；S206、高通滤波,时间信号采用带通滤波,带宽为0.005至0.09,滤除信号中的高频生理噪声,对经过以上预处理的所述观影模式FMRI数据进行非线性配准到结构核磁共振图像空间；结构核磁共振数据MPRAGE序列进行处理包括：S301、采用非局部平均滤波模型去除背景噪声；S302、采用基于最小二乘法的B样条曲面拟合函数进行场强非均匀性矫正；S303、去除颅骨：使用可变形模型,该模型通过应用一组局部自适应模型力而逐渐改进以判别大脑表面；S304、将经过S301-S303处理后的图像分割为灰质、白质和脑脊液；S305、将S301-S304处理后的数据进行非线性转换到蒙特利尔标准空间,并获取反转换矩阵；观影模式fMRI刺激任务共7分钟,主要有7个影视片段组成,影视片段来源于《家有儿女》情景剧里的言语对话场景,每个片段5-119秒,总时长5分54秒,中间有6个无言语对话的室内室外场景片段,每个片段持续4-25秒,总时长1分6秒；脑损伤患者在指导语的引导下进入观影模式,观影结束后再评估和记录病人对于观影内容的理解程度；识别出语言网络的成分包括：基于脑肿瘤患者的所有独立成分和额颞叶语言区空间模板、时域模板对比,获得最优匹配成分,即为主语言成分；基于脑肿瘤患者的所有独立成分和顶下小叶语言区空间模板、时域模板对比,获得最优匹配成分,即为次语言成分；基于所述主语言成分和次语言成分获得语言区定位；时域模板包括两个语言响应模型,即额颞皮层响应模型和顶叶皮层响应模型,语言响应模型基于60个健康正常人的观影模式fMRI数据的时间序列叠加平均获得；语言网络主成分为额颞皮层响应模型时间序列高度相关的成分,语言网络主成分为顶叶皮层响应模型时间序列高度相关的成分,语言网络主成分及语言网络主成分的选择基于以下标准：时间与空间相关性系数在所有成分中排列前五,成分稳定指数大于0.8。</td>   <td>G06T7/00;G06T7/11;G06T7/30;G06T5/00;A61B5/055</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李仲泓;              吴昱焜;              衣杨;              沈金龙;              佘滢;                   朱艺       </td>   <td>中山大学</td>   <td>一种基于二叉树的人体行为识别方法</td>   <td>广东省</td>   <td>CN109508698B</td>   <td>2023-01-10</td>   <td>本发明公开了一种基于二叉树的人体行为识别方法,应用于计算机视觉领域,旨在于解决现有技术中没有考虑到轨迹之间的相互关系以及对运动部分的特征提取不够细致的问题。本发明首先提取输入视频的综合显著轨迹；然后计算每条轨迹的特征描述符,包括新提出的均衡描述符；再利用谱聚类算法将视频的轨迹分成粒度不一的节点,构造中层语义二叉树；由于经费舍尔向量编码后的特征表示的维度过高,本发明采用子空间随机投影对编码向量进行降维；最终利用线性核的SVM(状态向量机)对特征表示分类,得到视频行为的类别标签。本方法在一定程度上移除背景的干扰,并提高了识别准确度。</td>   <td>1.一种基于二叉树的人体行为识别方法,其特征在于,包括以下步骤：S1：输入视频,对视频帧中的特征点进行采样,对采样后的特征点进行跟踪,生成轨迹,再对轨迹进行筛选；S2：计算筛选后轨迹的显著值,提取出综合显著轨迹；S21：分别提取轨迹的灰度显著值以及光流显著值；S22：通过灰度显著值以及光流显著值得到视频帧的综合显著值；S23：根据综合显著值提取出显著轨迹；S3：根据求得的综合显著轨迹计算轨迹的特征描述符,用来量化轨迹特征；S31：计算从第i帧处开始采样的轨迹在第f帧的采样点平均位置值；i≤f≤i+L,L表示轨迹长度；S32：计算从第i帧处开始采样的第n轨迹在第f帧的采样点相对于平均位置的位移；S33：由归一化处理结果得到第i帧处开始采样的第n条轨迹的均衡描述符；S4：根据轨迹特征将轨迹进行分类,并利用谱聚类方法将视频的轨迹分类到若干集合中,即分类到二叉树节点中,构造中层语义二叉树；步骤S4根据轨迹特征将轨迹进行分类,并利用谱聚类方法将视频的轨迹分类到若干集合中,即分类到二叉树节点中,构造中层语义二叉树的具体步骤包括：S41：利用轨迹之间的欧氏距离d作为轨迹之间的相似度,并对欧氏距离采用高斯核化；S42：采用归一化切割N-Cut对轨迹聚类,获得离散解；S43：利用K均值方法对特征向量组成的矩阵E进行处理,从而获得每一条特征的类别；所述的特征向量通过二叉树结构进行FV编码与随机投影得到；S44：利用方法根据轨迹的特征类别进行谱聚类；S45：将行为视频显式地划分为语义上的两类特征,其中一类为行为的主体部分,另一类则为辅助主体部分的人、物运动部分；S5：对若干集合内的轨迹进行编码得到编码向量,采用子空间随机投影对编码向量进行降维,并将若干集合的降维后的编码向量进行融合,用来表示一个视频；S6：利用线性核的SVM对视频进行分类,得到视频行为的类别标签并输出结果；步骤S3根据求得的综合显著轨迹计算轨迹的特征描述符的具体步骤包括：S31：计算从第i帧处开始采样的轨迹在第f帧的采样点平均位置值为：                  其中,i≤f≤i+L；N表示相同起始帧和采样尺度的轨迹数目,表示从第i帧处开始采样的第n条轨迹在第i帧上的采样点；x表示横轴上的值,y表示纵轴上的值；S32：计算从第i帧处开始采样的第n轨迹在第f帧的采样点相对于平均位置的位移为：ΔR-i～n(f)＝p-i～n(f)-A-i(f)对相对位移进行归一化处理：                  其中min(ΔR-i)表示第n轨迹在第f帧的采样点相对于平均位置最小位移,max(ΔR-i)表示第n轨迹在第f帧的采样点相对于平均位置最大位移；S33：由归一化处理结果得到第i帧处开始采样的第n条轨迹的均衡描述符：</td>   <td>G06V40/20;G06V10/778;G06T7/269</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴昱焜;              李仲泓;              衣杨;              沈金龙;              佘滢;                   朱艺       </td>   <td>中山大学</td>   <td>一种基于时空信息和层级表示的视频人体行为识别方法</td>   <td>广东省</td>   <td>CN109583360B</td>   <td>2023-01-10</td>   <td>本发明涉及人工智能领域,更具体的,涉及一种基于时空信息和层级表示的视频人体行为识别方法。本发明充分利用了视频中的时空信息,层级时空束将视频运动分为几个部分,进而得到视频运动的更高维度的表示。针对传统视频表示方法忽略视频的中高层语义信息,仅仅关注特征出现的次数,利用的只是0阶信息等不足,基于层级时空束的视频表示方法能够有效剪除视频的背景噪声干扰、并且弥补底层特征与高层特征之间的语义鸿沟,可以捕获更高阶更复杂的运动结构信息。层级时空束方法可以在更高的维度上,析取更加复杂和更具表现力的视频表示,能够有效提高视频识别的效果。</td>   <td>1.一种基于时空信息和层级表示的视频人体行为识别方法,其特征在于,包括以下步骤：步骤S1：基于摄像机运动补偿整个视频片段的整体光流,提取前景运动光流,并形成补偿轨迹；步骤S2：通过关键帧选择,过滤得到视频中具有判别力的关键帧；步骤S3：对补偿轨迹采样并训练得到混合高斯模型；步骤S4：选择关键帧得到视频关键帧集合,并结合混合高斯模型对补偿轨迹进行FV编码,形成关键轨迹集；步骤S5：将整个视频进行片段分割与排序模型,将分割后的视频片段执行步骤S1～步骤S4,获得分割后视频片段的层级时空束特征；步骤S6：将以层级时空束作为视频表示,并作为分类器的输入,经过SVM分类之后,得到视频分类标签；步骤S4的具体步骤如下：步骤S401：对于输入视频片段,选择关键帧得到视频关键帧集合；步骤S402：进行FV编码得到关键轨迹集表示TB,如果帧i在帧i+1之前,则定义这种时序关系为TB-(i+1)&gt;TB-i,如公式1所示,定义如下线性函数：                  公式1是顺序回归问题,在顺序回归问题中,定义P为视频帧特征对的集合P＝{(TB-i,TB-j):TB-i&gt;TB-j},并定义在结构风险最小化以及max-margin算法框架下,定义受限目标函数为公式2,其中C为惩罚因子,ξ-(ij)为松弛变量,w表示视频帧特征TB间的时空结构信息,作为视频X的表示</td>   <td>G06V40/20;G06V20/40;G06V20/70;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         詹羽荣;              赵常均;              李博;              万磊;                   肖定坤       </td>   <td>广州智能装备研究院有限公司;中山大学肿瘤防治中心</td>   <td>一种头颈部肿瘤检测方法、装置及计算机可读存储介质</td>   <td>广东省</td>   <td>CN109285142B</td>   <td>2023-01-06</td>   <td>本发明公开了一种头颈部肿瘤检测方法、装置及计算机可读存储介质,所述方法包括：采集头颈部CT数据,并根据所述头颈部CT数据中的窗宽和窗位调整Hu值,形成头颈部图片；将所述头颈部图片输入预设的区域分割模型,输出像素分割图；对所述像素分割图进行图形膨胀和腐蚀处理,分割出头颈部各个部位所在区域的区域图片；将所述区域图片输入预设的目标检测模型,检测出肿瘤的位置和种类。本发明能够基于深度学习,融合区域分割技术和目标检测技术对头颈部肿瘤进行检测,使得检测结果更加稳定,检测精度也更高。</td>   <td>1.一种头颈部肿瘤检测方法,适于在计算设备中执行,其特征在于,包括如下步骤：采集头颈部CT数据,并根据所述头颈部CT数据中的窗宽和窗位调整Hu值,形成头颈部图片；将所述头颈部图片输入预设的区域分割模型,输出像素分割图；对所述像素分割图进行图形膨胀和腐蚀处理,分割出头颈部各个部位所在区域的区域图片；将所述区域图片输入预设的目标检测模型,检测出肿瘤的位置和种类；所述预设的区域分割模型的训练步骤为：采集头颈部CT数据,并根据所述头颈部CT数据中的窗宽和窗位调整Hu值,形成头颈部图片；根据人工对所述头颈部图片中各个部位进行的所在区域的标注,生成各个部位的区域分割标签；将所述头颈部图片和所述区域分割标签输入区域分割深度神经网络中进行训练,生成相应的网络模型,即区域分割模型；其中,所述区域分割深度神经网络由收缩路径和扩张路径组成；所述收缩路径,以VGG16网络作为基础,使用一系列的卷积层和池化层操作,将VGG16结构中原来的全连接层分别转化为卷积层,所述收缩路径用于获取上下文信息,得到的输出尺寸为原图的1/32大小；所述扩张路径,采用上采样技术,将经过所述收缩路径的前四层池化层后的图像进行5次上采样,将所述图像恢复原始尺寸,所述扩张路径用于精确的定位；所述预设的目标检测模型的训练步骤为：采集头颈部CT数据,并根据所述头颈部CT数据中的窗宽和窗位调整Hu值,形成头颈部图片；根据人工对所述头颈部图片中各个部位进行的肿瘤种类的标注,生成各个部位的目标检测标签；截取所述头颈部图片中各个部位的所在区域,生成作为图像输入的小图片；将所述小图片和所述目标检测标签输入目标检测深度神经网络进行训练,生成相应的网络模型,即目标检测模型；所述目标检测深度神经网络进行训练时,以VGG16网络作为基础,使用一系列的卷积层和池化层操作,将不同层次的特征图分别用于边框的偏移以及不同类别得分的预测,并通过非最大值抑制得到检测结果,具体为：所述目标检测深度神经网络以VGG16网络作为基础,使用前面的前5层,然后利用astrous算法将fc6和fc7层转化成两个卷积层,接着再增加了3个卷积层和一个平均池化层,最后将不同层次的特征图分别用于边框的偏移以及不同类别得分的预测,并通过非最大值抑制得到检测结果。</td>   <td>G06T7/00;G06T7/11;G06T7/155;G06V10/774;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陆遥;              夏中舟;              吴峻峰;                   张勇瑞       </td>   <td>中山大学</td>   <td>一种基于Spark框架的文本聚类模型PW-LDA的并行化方法</td>   <td>广东省</td>   <td>CN109558482B</td>   <td>2023-01-06</td>   <td>本发明涉及文本主题聚类领域,更具体地,涉及一种基于Spark框架的文本聚类模型PW-LDA的并行化方法。本发明主要包括数据载入、对文本数据预处理、词向量训练、Partition提取目标段、LDA训练、计算主题向量以及文本聚类等步骤。本发明使用Spark框架,通过MapReduce以及GraphX技术对模型中各模块进行了并行化的设计与实现,大幅加速了程序运行,从而为其提供实时运行的可行性。</td>   <td>1.一种基于Spark框架的文本聚类模型PW-LDA的并行化方法,其特征在于,包括以下步骤：S1：载入科技文献的语料库数据并初始化为Spark的分布式数据类型对象；S2：对导入的语料库中文本通过Map方法进行分词、去停用词预处理得到训练样本；S3：对训练样本使用Spark的Word2Vec接口进行词向量训练；S4：根据Word2Vec的结果使用Partition算法从训练样本的文本中提取目标段并通过Map方法实现算法的并行；S5：对Partition算法提取出的目标段使用Spark的基于GraphX实现的LDA接口训练得到主题-词语矩阵；S6：根据LDA模型得到的主题-词语矩阵以及Word2Vec得到的词向量计算主题向量并通过Map方法实现计算过程并行化；S7：根据Word2Vec结果对Partition得到的目标段中词语计算得到文本向量,将其比对与所有主题向量的余弦相似度,寻找与目标段最匹配的主题,并通过Map方法实现计算过程的并行化；S8：使用Reduce技术从各计算节点汇总计算结果。</td>   <td>G06F16/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖丹宇;                   陈龙       </td>   <td>中山大学</td>   <td>基于半监督学习和细粒度特征学习的分类优化方法</td>   <td>广东省</td>   <td>CN109657697B</td>   <td>2023-01-06</td>   <td>本发明涉及计算机视觉的技术领域,更具体地,涉及基于半监督学习和细粒度特征学习的分类优化方法。本发明是一种利用半监督学习来筛选伪标签数据,并且指定一种细粒度图片特征提取、利用方法来提升神经网络的泛化能力,以提升分类网络其在细粒度分类任务上的表现。包括：通过伪标签数据来扩充数据集；通过SSD对输入图片进行目标检测,对检测结果通过多个尺度进行裁剪,将检测结果和裁剪得到的图像块一起送入分类网络中学习,通过加权输出抑制背景块的影响。本发明还涉及到迁移学习,具体涉及到利用ImageNet数据集上的预训练模型的,冻结卷积层,微调全连接层,极大的节省了训练内存,节省了训练时间。</td>   <td>1.基于半监督学习和细粒度特征学习的分类优化方法,其特征在于,包括以下步骤：S1.对无标记数据做投票操作,挑选具有一致的结果且不属于混淆类的数据当作伪标签；使用三个经典的卷积神经网络VGG19、ResNet18和GoogleNet来做投票操作,首先在目标数据集上训练三个网络,然后让训练好的网络各自对验证集做出分类判断,然后对三个网络得到各个类别的准确率做平均,以得到各类别判断准确率,将远低于平均值的类别视为混淆类,即难分类类别；将无标记样本中,三个模型分类结果一致且不属于混淆类类别的样本挑选出来,视为伪标签,即把三个模型的共同分类结果视为该无标记样本的类别；S2.用挑选好的伪标签扩充训练集；将步骤S1中挑选出来的伪标签加入到训练集,以此来扩充数据集；S3.选定一张有标记图片,得到检测结果图A；将训练数据先用SSD进行检测,得到要分类目标的位置,对此位置进行裁剪,裁剪时进行短边延伸,即使得到的图片块长和宽大小一致,记为图A；S4.将上一步得到的图A进行随机裁剪得到图片；从图A的中心点出发,以图A大小的1/4和1/9两种尺度随机裁剪各得到8张图片,共16张；S5.将裁剪得到的图像块和图A一起送进网络去学习；将步骤S4中得到的16张图片块都标记上和图A一样的类别,然后和图A一起送入网络中去学习,训练网络,在网络输出的时候,对每个输出概率向量,用最大预测概率减去次大预测概率作为他们的权重,累加加权后的概率,取最大概率所在类别作为测试图片的最终结果；S6.选定待测试图片,得到检测结果图B；测试的时候,对于待测试图片,用SSD检测,得到检测结果记为图B；S7.将图B划分大小,裁剪图像块；将步骤S6得到的图B以2×2的大小进行划分,然后裁剪,得到四个图像块,再从图片的中心点出发,裁剪一个为图B的1/4大小的图像块；S8.将裁剪得到图像块以及图B一起做预测；将划分的四个部分裁剪下来得到四个图像块,将这四个图像块和图A一起送入网络去做预测,得到五个预测概率向量；S9.对上一步得到的每张图像块的预测结果,用最大预测概率减去次大预测概率作为他们的权重,累加加权后的概率,取最大概率所在类别当作测试图片的最终结果；其中,分别用每个概率向量的最大值减去次大值作为它们各自的权重w1、w2、w3、w4、w5,将这五个权重乘以他们的概率向量,然后累加,最后取最大概率所在类别当作是待测试图片的真实类别。</td>   <td>G06V10/764;G06V10/774;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张耿伟;                   吴维刚       </td>   <td>中山大学</td>   <td>一种基于联盟链网络的去中心化跨集群资源共享方法</td>   <td>广东省</td>   <td>CN109670859B</td>   <td>2023-01-06</td>   <td>本发明提供一种基于联盟链网络的去中心化跨集群资源共享方法,基于联盟链网络中的联盟链网络技术,在集群之间建立一个去中心化的分布式账本,每个集群都有各自的资源额度,限制该集群所能使用其他集群的资源上限,提高集群间的公平性。同时,通过将资源竞价过程中的重要字段写入联盟链网络中来保证交易过程的不可篡改和可追溯,实现去中心化且可信任的资源竞价过程。集群根据资源利用率计算竞价系数,资源需求方选取竞价系数最小的集群。通过这种方式,使得整个集群联邦的资源使用和工作负载更加均衡。</td>   <td>1.一种基于联盟链网络的去中心化跨集群资源共享方法,其特征在于,包括以下步骤：S10.在集群联邦之间建立一个联盟链网络,在联盟链网络中建立一个集群间的分布式账本,记录每个集群的资源额度,集群的角色分为资源需求方与资源提供方,每个集群根据各自的资源利用率在两个角色之间切换；S20.每个集群设置本集群的两个资源利用率参数,期望利用率α和最大利用率β,整个集群联邦设置一个资源最低限额,当集群的资源额度小于最低限额时,则不能作为资源需求方发起竞价,只能作为资源提供方先赚取资源额度,最低限额应不小于零；S30.每个集群实时监控各自集群的资源利用率,当集群的资源利用率大于β时,该集群作为资源需求方若当前的资源可用额度大于集群联邦限定的最低限额时,将所需的资源描述广播到其他集群,发起竞价；当集群的资源利用率小于等于β时,该集群作为资源提供方,监听其他集群发出的资源请求当资源需求方的资源可用额度大于最低限额时,资源提供方根据α计算定价参数,通过定价参数参与竞价；资源需求方与资源提供方进行匹配,资源提供方的可用资源满足资源需求方的需求,且资源需求方选取定价参数队列中最小的定价参数并与该定价参数的资源提供方进行匹配,双方进行交易；S40.交易结束后,进行资源费用结算,资源需求方自身的资源额度上支付资源费用给资源提供方,资源提供方获得资源费用。</td>   <td>G06Q30/02;G06Q30/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              郭叙森;              古剑锋;              郭思璐;              杨铖章;                   许子潇       </td>   <td>中山大学</td>   <td>一种基于流数据的三维物体检测与跟踪方法</td>   <td>广东省</td>   <td>CN110570457B</td>   <td>2023-01-06</td>   <td>本发明涉及三维目标检测和追踪领域,更具体地,涉及一种基于流数据的三维物体检测与跟踪方法,通过输入包括点云数据和图像数据的前后两个关键帧,对数据进行特征提取得到特征图,并将两帧特征图做相关操作得到相关特征图。之后,将特征图输入候选框提取网络获得候选框；通过候选框在特征图和相关特征图获取特征块并输入回归网络,分别得到检测物体的三维框和三维框偏移量。通过插值法求出除关键帧之间的其他帧画面,并对所有帧中的目标进行关联,得到跟踪结果。本发明只需对关键帧进行检测,加快流数据检测的速度,满足自动驾驶环境对实时性的要求同时具有更好的稳定性；同时融合了点云信息和图像信息,优劣互补,提高检测物体的准确性。</td>   <td>1.一种基于流数据的三维物体检测与跟踪方法,其特征在于,包括如下步骤：步骤一：输入前后两帧由点云数据和图像数据组成的关键帧数据,对数据进行预处理,其中的点云数据在俯视图方向上投影结构转化成BEV图；步骤二：将步骤一中的两关键帧数据进行特征提取,得到特征图,并将提取的特征图输入区域特征提取模块,分别得到两个关键帧的候选框集合；步骤三：所述候选框在特征图中截取特征块和调整尺寸,然后输入分类网络与框回归网络,得到物体的类别和三维框位置；步骤四：对步骤二中提取的两个关键帧的数据做相关操作得到相关特征图,所述候选框在相关特征图中截取特征块和调整尺寸,然后输入回归网络得到两个关键帧对应物体的三维框的偏移量；步骤五：根据物体的三维框和三维框对应的偏移量,运用插值法得到两个关键帧数据之间的其他帧数据的物体的三维框,从而得到所有帧中的物体的三维检测结果；步骤六：根据检测结果,对所有帧数据对应的物体相互关联,得到跟踪结果。</td>   <td>G06T7/246;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              罗政煊;              林淑金;                   周凡       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的服装编辑和生成方法</td>   <td>广东省</td>   <td>CN112529768B</td>   <td>2023-01-06</td>   <td>本发明公开了一种基于生成对抗网络的服装编辑和生成方法。首先在用户原始图像被输入后,使用R-CNN区域检测卷积神经网络对图像中的服装进行检测识别；使用CPN级联金字塔网络来对服装物体进行轮廓点检测,单独提取无背景的服装图像显示给用户；并根据上述数据,返回给用户进行属性修改选择；将用户请求信息进行结构化处理后获得需要修改属性的语义信息,输入至训练好的带有指定属性的逼真图像能力的生成器生成最终服装图像。本发明为用户提供一种依靠计算机视觉技术端到端的服装编辑生成方案,一方面,解决了用户商品检索前对于服装样式进行更改的需求,另一方面,提高了服装编辑的可操作性和生成效果。</td>   <td>1.一种基于生成对抗网络的服装编辑和生成方法,其特征在于,所述方法包括：对服装图像进行结构化预处理,得到预处理后的服装图像；对所述预处理后的服装图像提取信息,包括标注服装属性、标注服装分割点和服装轮廓点,将所提取的信息进行结构化处理,获得向量格式记录的服装属性信息；将所述预处理后的服装图像、所述服装属性和所述服装分割点,作为Mask R-CNN卷积神经网络的输入,获得特征图,对特征图进行分类和回归训练获得网络模型,用于对所述服装图像进行服装属性分类识别和分割点检测,将所有分割点顺序连接得到轮廓图；使用CPN级联金字塔网络,对所述服装轮廓点进行检测,按不同的服装关键点提取整体服装轮廓,配合所述轮廓图,获得所述服装图像的精度较高的轮廓关键点坐标信息；综合所述服装分割点和所述轮廓关键点坐标信息形成精确掩码轮廓图和属性向量,对所述服装图像取掩码提取服装部分,并将轮廓点高亮显示给用户,提供属性修改功能；利用所述服装图像取掩码提取的服装部分预训练判别器D,判别器的网络沿用Att-GAN属性生成对抗网络的判别器,网络采取五层卷积层,卷积结果连接两个不同的全连接层至两个分支判别器Dimg和Datt用于判别生成图像各种属性的准确性；利用所述服装图像和所述向量格式记录的服装属性信息,构建生成器G,生成器采用U型编码-解码网络模型,编码器对所述服装图像取掩码提取的服装部分,提取特征向量,使用ACUs(Attribute Control Units)属性控制单元,各层ACU连接在编码器和解码器对应层之间,ACUs属性控制单元内,特征向量的每一层特征图,与所述向量格式记录的服装属性信息,生成属性编辑后的特征图,ACUs通过卷积得到综合后的特征图,传入解码器中,解码器反卷积后生成图像；将所述生成图像输入至所述预训练好的判别器D,按属性得到分类结果,来衡量属性编辑程度,并通过损失函数计算损失值,梯度反向传播更新所述生成器和所述判别器的卷积参数,迭代其相互对抗提升能力过程,得到具有生成带有指定属性的逼真图像能力的生成器G；输入待处理的服装图像,对该图像取掩码提取服装部分并高亮显示轮廓点,得到可供用户选择和修改的服装属性,之后把修改后的服装属性输入所述具有生成带有指定属性的逼真图像能力的生成器G,迭代地生成用户期望的服装图像；其中,所述综合所述服装分割点和所述轮廓关键点坐标信息形成精确掩码轮廓图和属性向量,具体为：用(X-(seg),Y-(seg))表示所述服装分割点包围区域,用(X-(con),Y-(con))表示所述服装轮廓点包围区域,并进行叠加获得最终服装掩码信息,{(X-(clo),Y-(clo))||X-(clo)＝X-(seg)∪X-(con),Y-(clo)＝Y-(seg)∪Y-(con)},找出边界点(X-(out),Y-(out)),若某一轮廓点(x-(con),y-(con))在边界线围绕区域内,不在边界线上则偏移至离边界线最近一点,                  其中,所述构建生成器G,具体为：生成器G采用U型结构的encoder-decoder编码-解码网络模型,输入为所述服装图像和所述向量格式记录的服装属性信息；编码器使用残差网络对所述服装图像取掩码提取的服装部分提取特征向量得到f-(enc)＝{f-(enc)～1,...,f-(enc)～5},f-(enc)＝G-(enc)(x),编码器包含5层卷积层,卷积核尺寸为4*4；使用ACUs(Attribute Control Units)属性控制单元实现对于属性的准确控制,各层ACU连接在编码器和解码器对应层之间,在ACUs属性控制单元内,特征向量中的每一层特征图,与所述向量格式记录的服装属性信息,生成属性编辑后的特征图；ACUs属性控制单元的输入包括所述编码器提取的l层的编码特征图f-(enc)～l,l+1层的ACUs输出的隐藏态s～(l+1),以及属性差分向量att-(diff)＝att-t-att-s,属性的种类和数目根据需要囊括的服装种类决定,输出包括l层的解码特征图f-(dec)～l和l层隐藏态和本层的隐藏态s～l；ACUs首先将l+1层的隐藏态s～(l+1)通过转置卷积进行上采样,使l层的隐藏态特征图尺寸匹配l+1层隐藏态特征图尺寸,s′～(l+1)＝W-t*T[s～(l+1),att-(diff)]r～l＝σ(W-r*[f-(enc)～l,s′～(l+1)])                  u～l＝σ(W-u*[f-(enc)～l,u′～(l+1)])f-t′～l＝tanh(W-h*[f-(enc)～l,s～l])                  其中,[·,·]表示向量的拼接,*T表示转置卷积,表示求矩阵的点积,σ(·)表示应用sigmoid激活函数,tanh(·)表示应用tanh激活函数,r～l是重置门,用于控制各属性是否使用l层上采样后的隐藏态信息,u～l是更新门,用于控制l层隐藏态信息对于l+1层特征图的重要度,s～l是l层的隐藏态,f-t～l是l层的转换后的编码特征；将综合后的特征图f-t～l传入解码器中,解码器包含5个对应的反卷积层,卷积核尺寸4*4,经5层反卷积后生成图像。</td>   <td>G06T3/00;G06T11/00;G06N3/04;G06N3/08;G06V10/82;G06V10/764;G06V10/26;G06V10/44</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙慧杰;              陈英伦;              刘万泉;                   吴雨瑶       </td>   <td>中山大学</td>   <td>基于机器视觉的室内人员跌倒预警检测方法及系统</td>   <td>广东省</td>   <td>CN115578792A</td>   <td>2023-01-06</td>   <td>本发明涉及一种基于机器视觉的室内人员跌倒预警检测方法和系统,其中的方法包括：获取机械视觉拍摄的现场图像并汇集形成现场数据集,将现场图像输入到基于目标检测算法的深度学习网络模型中,对现场图像进行图像预处理,获取人体图像及其体态特征,并将人体图像与现场图像关联后存储在现场数据集中,通过深度学习网络模型对人体图像的进行体态特征分析并输出检测结果,其中,深度学习网络模型由基于跌倒时行为体态特征选取并汇集形成的训练集和验证集来训练。本发明能够满足一定的实时性和准确性要求,在实际运用上能做到在几乎不妨碍老人日常生活的前提下,根据跌倒时行为体态特征及时检测到老人的跌倒并发出警报。</td>   <td>1.一种基于机器视觉的室内人员跌倒预警检测方法,其特征在于,所述方法包括以下步骤：S10、获取机械视觉拍摄的现场图像并汇集形成现场数据集,将所述现场图像输入到基于目标检测算法的深度学习网络模型中；S20、对现场图像进行图像预处理,获取人体图像及其体态特征,并将所述人体图像与现场图像关联后存储在所述现场数据集中；S30、通过所述深度学习网络模型对所述人体图像的进行体态特征分析并输出检测结果；其中,所述深度学习网络模型由基于跌倒时行为体态特征选取并汇集形成的训练集和验证集来训练。</td>   <td>G06V40/20;G06V20/40;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵莹;                   杨羽菲       </td>   <td>中山大学</td>   <td>一种游客行为数据提取方法</td>   <td>广东省</td>   <td>CN115577190A</td>   <td>2023-01-06</td>   <td>本申请属于旅游数据处理技术领域,公开了一种游客行为数据提取方法。该方法包括：获取旅游景区签到数据,进行结构化处理,得到签到时空数据库；从旅游网站获取第一游记样本,对其中游记文本的时间信息和地点信息进行标记,得到标记旅游时空路径,基于标记方法,形成初步解析模块；获取第二游记样本,运行初步解析模块得到第二游记样本的解析旅游时空路径,基于解析旅游时空路径对初步解析模块进行完善,得到最终解析模块；将最终解析模块应用在预设时间窗口和预设目的地范围的游记样本中,得到游记时空数据库；基于所述签到时空数据库和所述游记时空数据库,得到可视化的游客时空行为路径图。为后续的旅游领域的专利分析提供结构化的数据。</td>   <td>1.一种游客行为数据提取方法,其特征在于,所述方法包括：获取旅游景区签到数据,并对所述旅游景区签到数据进行结构化处理,得到基于所述旅游景区签到数据的签到时空数据库；从旅游网站获取第一游记样本,对所述第一游记样本中每一篇游记文本的时间信息和地点信息进行标记,得到标记旅游时空路径,基于所述标记旅游时空路径的标记方法,形成初步解析模块；获取第二游记样本,运行所述初步解析模块得到所述第二游记样本的所有游记文本的解析旅游时空路径,基于解析旅游时空路径对所述初步解析模块进行完善,得到最终解析模块；将所述最终解析模块应用在预设时间窗口和预设目的地范围的游记样本中,得到基于游记的游记时空数据库；基于所述签到时空数据库和所述游记时空数据库构建游客流动行为数据库,基于所述游客流动行为数据库得到可视化的游客时空行为路径图。</td>   <td>G06F16/9537;G06F16/9532;G06F16/957;G06F40/117;G06F40/205</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   徐贵       </td>   <td>中山大学</td>   <td>基于调色盘的属性预测方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113192148B</td>   <td>2023-01-03</td>   <td>本发明公开了基于调色盘的属性预测方法、装置、设备及介质,方法包括：采用基于几何位置的预测值方法对待测点进行属性编码,得到初始属性预测值；对所述初始属性预测值的残差值进行统计,得到残差值统计结果；根据所述残差值统计结果采用基于调色盘的属性预测方法确定目标属性预测值。本发明的适用范围广且计算复杂度较低,可广泛应用于数据处理技术领域。</td>   <td>1.基于调色盘的属性预测方法,其特征在于,包括：采用基于几何位置的预测值方法对待测点进行属性编码,得到初始属性预测值；对所述初始属性预测值的残差值进行统计,得到残差值统计结果；根据所述残差值统计结果采用基于调色盘的属性预测方法确定目标属性预测值；所述采用基于几何位置的预测值方法对待测点进行属性编码,得到初始属性预测值,包括：采用基于几何位置的预测值方法对所述待测点以及所述待测点的相邻点进行属性编码；确定所述待测点的第一属性预测值和所述相邻点的第二属性预测值；所述对所述第一属性预测值的残差值进行统计,得到残差值统计结果,包括：将所述第一属性预测值和所述第二属性预测值做差,得到所述待测点的属性的残差值；将大于或者等于3的残差值进行累加,得到残差值之和；计算所述残差值之和的平均值；所述根据所述残差值统计结果采用基于调色盘的属性预测方法确定目标属性预测值,包括：当所述平均值大于预设的第一阈值,则采用基于调色盘的属性预测方法确定目标属性预测值；所述采用基于调色盘的属性预测方法确定目标属性预测值,包括：统计已编码的32个不同属性预测值的出现频率；将所述出现频率由高到低进行排序,根据排序结果构建调色盘的属性预测表,并将只出现一次或排序低于32的属性预测值加入escape模式；从所述调色盘的属性预测表中选取跟所述待测点的属性最近的目标点,并将所述目标点的属性值作为所述待测点的属性预测值；在所述属性预测表中对所述目标点的索引结果进行二进制编码,得到二进制数；对所述二进制数进行上下文熵编码,得到目标属性预测值的比特流。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         方慧卉;              许言午;              刘军伟;              黄艳;              张秀兰;                   李飞       </td>   <td>北京百度网讯科技有限公司;中山大学中山眼科中心</td>   <td>粘连检测模型训练、粘连检测方法及相关装置</td>   <td>北京市</td>   <td>CN113850203B</td>   <td>2023-01-03</td>   <td>本公开提供了一种粘连检测模型训练、粘连检测方法、装置、电子设备、计算机可读存储介质及计算机程序产品,涉及计算机视觉、深度学习等人工智能技术领域。该方法的一具体实施方式包括：获取通过前段光学相干断层摄影技术对同一眼部对象在明、暗环境下拍摄的明暗图像对和眼部对象是否存在粘连的标注结果,利用初始模型的特征提取模块提取明、暗特征后输入至该初始模型的对比模块,以标注结果作为初始模型的输出,基于明特征和暗特征之间的差异特征确定用于监督训练的对比损失函数后,对该初始模型进行训练,在该对比损失函数满足预设的第一跳出条件时跳出,得到粘连检测模型。应用该实施方式提供的粘连检测模型能够识别眼部图像中是否存在粘连。</td>   <td>1.一种粘连检测模型训练方法,包括：获取通过前段光学相干断层摄影技术对同一眼部对象拍摄的明暗图像对,以及所述眼部对象是否存在粘连的标注结果；其中,所述明暗图像对中的明图像是在明亮环境下拍摄得到,暗图像是在黑暗环境下拍摄得到；响应于训练图像集中标注为粘连样本图像对的数量与标注为非粘连样本图像对的数量之间的差距大于预设阈值,生成基于所述粘连样本图像对得到的第一对比损失函数与基于所述非粘连样本图像对得到的第二对比损失函数之间的损失函数权重,其中,样本图像对中包括针对同一眼部对象拍摄的至少一张明图像和至少一张暗图像；基于所述第一对比损失函数、所述第二对比损失函数和所述损失函数权重生成优化对比损失函数；利用初始模型的特征提取模块分别提取出所述明图像的明特征和所述暗图像的暗特征；将所述明图像和所述暗图像输入至所述初始模型的图像放大模块,生成放大明图像和放大暗图像；提取所述放大明图像的放大明特征和所述放大暗图像的放大暗特征；将所述明特征和所述暗特征输入至所述初始模型的对比模块中,以所述标注结果作为所述初始模型的输出,基于所述明特征和所述暗特征之间的差异特征确定用于监督训练所述初始模型的对比损失函数后,对所述初始模型进行训练；将所述放大明特征和所述放大暗特征输入至所述初始模型的放大对比模块,以所述标注结果作为所述初始模型的输出,基于所述放大明特征和所述放大暗特征之间的差异特征确定用于监督训练所述初始模型的局部对比损失函数后,对所述初始模型进行训练；响应于所述对比损失函数满足预设的第一跳出条件、当前的局部对比损失函数满足预设的第三跳出条件以及当前的优化对比损失函数满足预设的第四跳出条件,将训练至当前的初始模型输出为粘连检测模型。</td>   <td>G06V40/18;G06V40/19;G06V10/60;G06V10/764;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              陈绿然;              严志伟;                   李烨       </td>   <td>中山大学</td>   <td>一种基于判别性区域挖掘的目标检测方法</td>   <td>广东省</td>   <td>CN109948628B</td>   <td>2023-01-03</td>   <td>本发明提供一种基于判别性区域挖掘的目标检测方法,通过特征提取网络进行特征提取,获取特征流；构建LDRM模块,将特征流进行局部的判别性特征学习；构建CDRM模块,对局部的判别性特征学习后的特征流进行上下文判别特征学习；构建特征流s-3,采用检测器对特征流s-3的特征图进行检测,得到最终的检测结果。本发明提供的一种基于判别性区域挖掘的目标检测方法,基于感受野的特征图产生判别性区域的特征表达,避免了从原图中提取判别性区域,再进行特征提取而引入的大量计算量,保证该方法以高的效率进行目标检测,防止受到表观相似的前景目标和背景区域的干扰；通过将生成的判别性区域特征与候选目标的特征进行融合,结合不同感受野的特征,优化特征表达。</td>   <td>1.一种基于判别性区域挖掘的目标检测方法,其特征在于,包括以下步骤：S1：通过特征提取网络进行特征提取,获取特征流s-1、s-2；S11：将一张图像及它的×2上采样图像输入同一特征提取网络中,选取特征层的输出构成特征流s-1和特征流s-2；所述特征流s-1用于目标的整体描述,所述特征流s-2用于目标的细节描述；S12：特征流s-1经检测器d-1进行目标类别判定及目标位置预测,分别得到分类损失和回归损失S2：构建局部判别性区域挖掘LDRM模块,将特征流s-1、s-2进行局部的判别性特征学习；S21：按照特征图生成的顺序,分别从特征流s-1和特征流s-2中取生成次序相同的特征图构成特征图对,构建LDRM模块的输入特征图对；对于每一个LDRM模块,其输入有基础特征图F-(basic)和互补特征图F-(comp)构成,其中特征图F-(basic)来自特征流s-1,特征图F-(comp)来自特征流s-2；S22：判别性区域定位：设输入的基础特征图F-(basic)的大小为W×H×C,其中W、H、C分别表示基础特征图F-(basic)的宽、高和通道数；基础特征图F-(basic)经过一个3×3的卷积层生成一个通道数为2的偏移量特征图,记为M；对于中心位置为(x-n,y-n)的候选目标区域,其判别性区域表示为：(x,y)＝(x-n,y-n)+λ(Δx,Δy)；                (1)其中,(x-n,y-n)遍历了基础特征图F-(basic)中所有的空间位置,即：x-n＝1,2,...,W；y-n＝1,2,...,H；(Δx,Δy)表示从候选目标区域到判别性区域的位置偏移量；其中,其表示特征图M中的空间位置为(x-n,y-n)的数值；λ为缩放权重,取值为0.75；S23：判别性特征学习：对于一个中心位置为(x-n,y-n)的候选目标,设其判别性区域表示为(x,y),则其判别性区域的特征表示为：                  其中：F-(discri)表示判别性特征图；表示特征图F-(discri)在空间位置(x-n,y-n)上的特征,表示以(x-n,y-n)为中心的候选目标的判别性区域特征表达；φ(F-(comp))～((x,y))表示互补特征图F-(comp)在判别性区域(x,y)的变换函数,这里取恒等换；其中：                  表示(x,y)的四个邻近整数空间位置,其中表示向下取整,表示向上取整；函数G是一个二维的双线性插值的核,表示为两个一维的双线性插值的核的乘积形式：G(u,v,x,y)＝g(u,x)·g(v,y)；            (3)其中,g(a,b)＝1-|a-b|；在LDRM模块中,特征图F-(discri)经过一个3×3的卷积层后与基础特征图F-(basic)进行融合拼接,得到LDRM模块的输出；S24：LDRM模块内的分类：将特征图F-(discri)输入由3×3的卷积层实现的分类器c-1中,完成对目标类别的判定；根据分类器c-1输出的结果,得到损失函数S3：构建基于上下文判别性区域挖掘CDRM模块,对局部的判别性特征学习后的特征流s-1、s-2进行上下文判别特征学习；S31：CDRM模块的输入特征图对由相邻的两个LDRM模块的输出构成,取输出空间分辨率大的特征作为基础特征图F′-(basic),输出空间分别率小的特征作为互补特征图F′-(comp),构建CDRM模块的输入特征图对；S32：判别性区域定位：设输入的基础特征图F′-(basic)的大小为W′×H′×C′,其中W′、H′、C′分别表示基础特征图F′-(basic)的宽、高和通道数；基础特征图F′-(basic)经过一个3×3的卷积层生成一个通道数为2的偏移量特征图,记为M′；对于中心位置为(x′-n,y′-n)的候选目标区域,其判别性区域表示为：(x′,y′)＝(x′-n,y′-n)+λ′(Δx′,Δy′)；                (4)其中,(x′-n,y′-n)遍历了基础特征图F′-(basic)中所有的空间位置,即：x′-n＝1,2,...,W′；y′-n＝1,2,...,H′；(Δx′,Δy′)表示从候选目标区域到判别性区域的位置偏移量；其中,其表示特征图M′中的空间位置为(x′-n,y′-n)的数值；λ′为缩放权重,取值为1；S33：判别性特征学习：对于一个中心位置为(x′-n,y′-n)的候选目标,设其判别性区域表示为(x′,y′),则其判别性区域的特征表示为：                  其中：F′-(discri)表示判别性特征图；表示特征图F′-(discri)在空间位置(x′-n,y′-n)上的特征,表示以(x′-n,y′-n)为中心的候选目标的判别性区域特征表达；φ′(F′-(comp))～((x′,y′))表示互补特征图F′-(comp)在判别性区域表示(x′,y′)中的变换函数,这里取核为2×2、步长为2的解卷积操作；其中：                  表示(x′,y′)的四个邻近整数空间位置,其中表示向下取整,表示向上取整；函数G′是一个二维的双线性插值的核,表示为两个一维的双线性插值的核的乘积形式：G′(u′,v′,x′,y′)＝g′(u′,x′)·g′(v′,y′)；            (6)其中,g′(a′,b′)＝1-|a′-b′|；在CDRM模块中,基础特征图F′-(basic)经过一个3×3的卷积层后与特征图F′-(discri)进行逐元素相加操作,从而得到CDRM模块的输出；S34：CDRM模块内的分类：将特征图F′-(discri)输入由3×3的卷积层实现的分类器c-2中,完成对目标类别的判定；根据分类器c-2输出的结果,得到损失函数S4：构建特征流s-3,采用检测器对特征流s-3的特征图进行检测,得到最终的检测结果；S41：取所有CDRM模块的输出和最后两个LDRM模块的输出构成的集合作为特征流s-3,采用检测器d-2对特征流s-3中的特征图进行最终的检测,在检测过程中对检测器d-2的输出进行非极大值抑制,得到最终的检测结果；S42：特征流s-3经检测器d-2进行目标类别判定及目标位置预测,分别得到分类损失和回归损失</td>   <td>G06V10/46;G06V10/764;G06V10/82;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭应林;              卢山富;              刘懿梅;              苗箐箐;              赵充;                   邓小武       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所);浙江柏视医疗科技有限公司</td>   <td>一种复发鼻咽癌放射治疗鼻咽坏死预测方法</td>   <td>广东省</td>   <td>CN115564735A</td>   <td>2023-01-03</td>   <td>本发明公开了一种复发鼻咽癌放射治疗鼻咽坏死预测方法,通过使用3DCNN深度学习网络提取剂量特征,同时融合病人影像组学特征,进行特征融合,联合3DCNN网络进行深度神经网络训练,包括医学影像图像预处理、影像组学特征提取、多模态组学特征选择、剂量数据预处理、剂量特征提取、3DCNN深度神经网络模型搭建、坏死概率预测模块。本发明能结合病人MRI影像信息和放疗剂量来预测病人放疗坏死的概率,根据预测的坏死情况来修改放疗计划,在一定程度上使得病人免于放射治疗副作用的影响。</td>   <td>1.一种复发鼻咽癌放射治疗鼻咽坏死预测方法,其特征在于：包括以下步骤：1)医学影像图像预处理：分别获取病人的MRI多模态数据T1、T1C、T2,再由医生手动分割出肿瘤区域；2)多模态影像组学特征提取：利用python pyradiomics程序库对步骤1)中得到的多模态数据及肿瘤区域提取影像组学特征；3)多模态组学特征选择：分别对三个模态数据提取到的影像组学特征进行特征参数相关性计算,筛选出相关系数高的多个特征,并将筛选出的多模态特征合并为病人组学特征；4)剂量数据预处理：将剂量数据的维度调整到一致,再对剂量数据进行z-score归一化操作；5)剂量特征提取：将步骤4)处理后的剂量数据输入多个3DCNN模块内,提取剂量特征,所述3DCNN模块由多个3D卷积算法、InstanceNorm算法、BatchNorm算法、Relu激活函数构成；6)坏死概率预测：将步骤2)得到的组学特征和步骤5)得到的剂量特征全连接嵌入后进行拼接操作,再经过两层全连接层得到模型的输出结果,即病人以该剂量数据进行化疗后的坏死概率。</td>   <td>G06T7/00;G06T7/11;G06N3/04;G06N3/08;A61N5/10;A61B5/055</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韩永;                   董理       </td>   <td>中山大学</td>   <td>基于高精度视差细化的立体匹配方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN115564812A</td>   <td>2023-01-03</td>   <td>本发明公开了一种基于高精度视差细化的立体匹配方法、系统、设备及介质,所述方法包括：获取极线矫正后的双目图像,双目图像包括第一图像和第二图像；根据纹理分割,将双目图像划分为多个纹理区域；在多个纹理区域内,以每个像素点为中心建立第一自适应窗口,进而计算第一图像和第二图像的代价集合；根据第一图像的代价集合和第二图像的代价集合,分别得到第一初始视差图和第二初始视差图；基于第一初始视差图和第二初始视差图,根据一致性检测、无效点分类以及基于适应度的视差重建,对第三初始视差图进行遮挡恢复；对遮挡恢复后的第三初始视差图进行边缘矫正,得到最终视差图。本发明可以在不增加计算复杂度的前提下,有效提高视差细化的能力。</td>   <td>1.一种基于高精度视差细化的立体匹配方法,其特征在于,所述方法包括：获取极线矫正后的双目图像,所述双目图像包括第一图像和第二图像；根据纹理分割,将双目图像划分为多个纹理区域；在多个纹理区域内,以每个像素点为中心建立第一自适应窗口,进而计算第一图像的代价集合和第二图像的代价集合；根据第一图像的代价集合和第二图像的代价集合,分别得到第一初始视差图和第二初始视差图；基于第一初始视差图和第二初始视差图,根据一致性检测、无效点分类以及基于适应度的视差重建,对第三初始视差图进行遮挡恢复,所述第三初始视差图为第一初始视差图和第二初始视差图的其中之一；对遮挡恢复后的第三初始视差图进行边缘矫正,得到最终视差图。</td>   <td>G06T7/33;G06T7/40;G06T7/55;G06T7/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   刘一晴       </td>   <td>中山大学</td>   <td>一种基于莫顿码的点云属性预测方法、装置和介质</td>   <td>广东省</td>   <td>CN113096199B</td>   <td>2023-01-03</td>   <td>本发明公开了一种基于莫顿码的点云属性预测方法、装置和介质,方法包括：获取点云数据的几何坐标,并对所述几何坐标进行莫顿排序；根据所述莫顿排序的结果,通过预设的搜索范围搜索共面共线点；计算所述共面共线点的权重值和；根据所述权重值和的数值大小,采用第一预测方法和第二预测方法预测目标点的目标属性值；其中,所述第二预测方法基于莫顿码来实现。本发明能够提高属性预测的准确度,可广泛应用于点云数据处理技术领域。</td>   <td>1.一种基于莫顿码的点云属性预测方法,其特征在于,包括：获取点云数据的几何坐标,并对所述几何坐标进行莫顿排序；根据所述莫顿排序的结果,通过预设的搜索范围搜索共面共线点；计算所述共面共线点的权重值和；根据所述权重值和的数值大小,采用第一预测方法和第二预测方法预测目标点的目标属性值；其中,所述第二预测方法基于莫顿码来实现；所述根据所述权重值和的数值大小,采用第一预测方法和第二预测方法预测目标点的属性值,具体为：判断所述权重值和的数值是否大于4,若是,则采用所述第一预测方法预测所述目标点的属性值；反之,则采用所述第二方法预测所述目标点的属性值；所述采用第二预测 方法预测所述目标点的目标属性值,包括：从所述点云数据中选定当前的目标点,确定所述目标点的几何坐标和莫顿排序；根据所述目标点的几何坐标和所述莫顿排序,从所述点云数据中确定3个与所述目标点的曼哈顿距离最小的已编码点；计算所述已编码点的第一权重值和原始属性值；根据所述第一权重值和所述原始属性值,计算所述目标点的属性补偿值；计算所述属性补偿值的第二权重值；根据所述第一权重值、所述原始属性值、所述第二权重值以及所述属性补偿值,计算得到所述目标点的目标属性值。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              黄毅;              卢心龙;              冼宇乔;                   黄翔星       </td>   <td>中山大学</td>   <td>一种基于三数据集交叉迁移学习的无监督行人再识别方法</td>   <td>广东省</td>   <td>CN109635708B</td>   <td>2023-01-03</td>   <td>本发明公开了一种基于三数据集交叉迁移学习的无监督行人再识别方法,步骤如下：将三个CNN在用于图像分类的大数据集上进行训练,得到三个预训练模型；并在三个有标签的源行人数据集A、B和C上分别进行微调；利用这三个CNN分别提取目标数据集中无标签行人图片的特征,用K-近邻聚类算法对提取到的特征分别进行聚类；筛选出三个模型聚类后靠近聚类中心域的图片样本,并打上拟标签；将三个打上拟标签的样本数据进行交叉轮换加入到另一个源行人数据集中,再对模型进行微调；将一张行人测试图片输入到训练好的三个模型得到三个特征矩阵,并进行最大池化操作,得到测试图片的唯一特征；计算唯一特征与数据库中的图片特征的欧氏距离,距离最小的数据库图片的身份即为本张测试图片的身份。</td>   <td>1.一种基于三数据集交叉迁移学习的无监督行人再识别方法,其特征在于,包括步骤如下：训练时：步骤1：将三个CNN在用于图像分类的大数据集上进行训练,得到三个预训练模型；将这三个预训练的CNN在三个有标签的源行人数据集A、B、C上分别进行微调,使其能有效提取行人特征；步骤2：利用微调后的三个CNN分别提取目标数据集中无标签行人图片的特征,并使用K-近邻聚类算法对提取到的特征分别进行聚类；步骤3：筛选出三个模型聚类后靠近聚类中心域的图片样本,并对这些样本分别打上拟标签；步骤4：将三个模型打上拟标签的样本数据进行交叉轮换加入到另一个源行人数据集中,从而对模型进行微调；重复步骤2～4操作,直到三个模型收敛为止,结束迭代；测试时：步骤5：将上述训练好的三个模型对同一张行人测试图片进行特征提取,得到三个特征矩阵,对这三个特征进行最大池化操作,得到测试图片的唯一特征；步骤6：利用该唯一特征与数据库中的图片特征进行匹配,计算他们之间的欧氏距离,距离最小的库图片身份即为这张测试图片的身份。</td>   <td>G06V10/762;G06V10/82;G06V40/10;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪涛;              陈小莹;              罗恒阳;                   邱祥燊       </td>   <td>中山大学</td>   <td>一种污染物扩散区域动态模拟方法、系统及装置</td>   <td>广东省</td>   <td>CN113033035B</td>   <td>2023-01-03</td>   <td>本发明公开了一种污染物扩散区域动态模拟方法、系统及装置,包括选择要估测的栖息地,获取该栖息地区域的卫星数据,基于卫星数据构建初始样本区域集；基于该栖息地的历史污染物信息构建污染物随时间变化的可达集。由于区域内各点处的速度集和该点的位置信息可以建立起函数关系,因此,利用求得的凸组合系数,代表点处的速度集合可以通过凸组合来预测区域内所有点处的速度集；加入时间因素,估测栖息地区域内森林火灾可达集随时间动态蔓延的范围。本发明引入微分包含是更好地预测火灾随时间在不同方向上的蔓延范围。同时,本发明又引入了有限元的思想,解决了在实际的预测计算工作中,求区域内所有点处的速度集计算量过大的问题。</td>   <td>1.一种污染物扩散区域动态模拟方法,其特征在于,包括：步骤1、选择要估测的栖息地,获取该栖息地区域的卫星数据,基于卫星数据构建初始样本区域集；步骤2、基于该栖息地的历史火灾信息构建森林火灾初始可达集R(0)；步骤3、基于有限元思想,选择有限个离散的代表点对栖息地区域进行三角剖分,划分出多个具有凸集性质的小三角形区域；建立小三角形区域上三个顶点和小三角形区域内所有点的点坐标凸组合公式,求得凸组合系数；步骤4、利用步骤3求得的凸组合系数,用小三角形区域上的三个顶点处的速度集预测小三角形区域内所有点处的速度集；由此利用有限个离散代表点处的速度集预测整个区域内所有点处的速度集；至此,建立起了微分包含蔓延离散模型；步骤5、加入时间因素,估测栖息地区域内森林火灾可达集随时间动态蔓延的范围。</td>   <td>G06F30/23;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              余文佳;              尹川学;              郭海旭;              方耀;              郑子彬;                   梁万山       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>风险评估方法、装置和存储介质</td>   <td>广东省</td>   <td>CN115564560A</td>   <td>2023-01-03</td>   <td>本申请涉及一种风险评估方法、装置和存储介质。上述方法包括：获取评估时间内的目标用户,并确定评估时间对应的用户关联图；确定与目标节点相邻的、位于不同层级的多个邻居节点集,并对多个邻居节点集进行聚合处理,得到目标节点的目标节点特征；确定评估时间对应的历史时间,并获取风险评估模型在对历史时间内的目标用户进行风险评估时所输出的历史隐藏状态；通过风险评估模型,并根据目标节点特征和历史隐藏状态,确定评估时间内的实际隐藏状态；根据实际隐藏状态,对评估时间内的目标用户进行风险评估,得到风险评估结果。采用本方法能够提高风险评估的准确性。</td>   <td>1.一种风险评估方法,其特征在于,所述方法包括：获取评估时间内的目标用户,并确定所述评估时间对应的用户关联图；所述用户关联图包括所述目标用户对应的目标节点；确定与所述目标节点相邻的、位于不同层级的多个邻居节点集,并对多个所述邻居节点集进行聚合处理,得到所述目标节点的目标节点特征；确定所述评估时间对应的历史时间,并获取风险评估模型在对所述历史时间内的所述目标用户进行风险评估时所输出的历史隐藏状态；通过所述风险评估模型,并根据所述目标节点特征和所述历史隐藏状态,确定所述评估时间内的实际隐藏状态；根据所述实际隐藏状态,对所述评估时间内的所述目标用户进行风险评估,得到风险评估结果。</td>   <td>G06Q40/02;G06Q10/06;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              吴永波;                   王伟轩       </td>   <td>中山大学</td>   <td>一种对抗强化的表情识别方法</td>   <td>广东省</td>   <td>CN109508689B</td>   <td>2023-01-03</td>   <td>本发明提出一种对抗强化的表情识别方法,其中的表情识别网络包括特征编码器和特征分类器,生成对抗网络包括特征编码器、特征解码器和鉴别器,首先构建人脸表情和无表情图片集,并对图片集的图片进行姿态归一化处理；将表情图片输入表情识别网络的特征编码器中获得表情特征编码,然后输入到特征分类器中进行分类输出；将无表情图片输入生成对抗网络的特征编码器中进行编码,获得无表情特征编码；将上述两种特征编码和高斯噪声进行串接,得到融合特征编码后输入到特征解码器中,输出新的表情图片；以新的表情图片为负样本,以输入的表情图片为正样本,鉴别器对其类别进行鉴别,重复上述步骤对表情识别网络和生成对抗网络进行交替训练并更新参数。</td>   <td>1.一种对抗强化的表情识别方法,其特征在于,包括表情识别网络和生成对抗网络,其中所述表情识别网络包括特征编码器和特征分类器,所述生成对抗网络包括特征编码器、特征解码器和鉴别器；具体步骤如下：S1：构建人脸无表情图片集和人脸表情图片集,并对人脸无表情图片集和人脸表情图片集中的图片进行姿态归一化处理；S2：将完成处理的人脸表情图片输入表情识别网络的特征编码器中进行编码,获得对应的表情特征编码,并将表情特征编码输入到表情识别网络的特征分类器中进行分类输出；S3：将完成处理的人脸无表情图片输入生成对抗网络的特征编码器中进行编码,获得对应的无表情特征编码；S4：将表情特征编码、无表情特征编码和高斯噪声进行串接,得到融合特征编码,然后输入到生成对抗网络的特征解码器,输出新的人脸表情图片；S5：以所述生成的新的人脸表情图片作为负样本,以输入表情识别网络的人脸表情图片作为正样本,使用生成对抗网络的鉴别器对正负样本图片的类别进行鉴别；S6：重复执行步骤S2～S5对表情识别网络和生成对抗网络进行训练,并基于训练的结果对表情识别网络、生成对抗网络的参数进行更新；S7：将待识别的人脸表情图片输入完成训练的表情识别网络中进行表情识别分类。</td>   <td>G06V40/16;G06V10/774;G06V10/82;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曹惠茹;              钟嗣东;              黄凯帆;              陈荣杰;                   陈玮       </td>   <td>中山大学南方学院</td>   <td>监护设备及监护轮椅</td>   <td>广东省</td>   <td>CN109740531B</td>   <td>2022-12-30</td>   <td>本申请公开了一种监护设备及监护轮椅,监护设备设置在监护轮椅上,监护设备包括：主控芯片、动作识别单元、传感单元、语音播放单元和通信单元,通过动作识别单元进行动作图像追踪和采集,通过传感单元采集生理信号,通过主控芯片对采集到的动作图像和生理信号进行识别,获得情绪信号后,利用语音播放单元生成语音信号,以及利用通信单元将情绪信号发送至智能终端。与现有技术相比,本发明采用了实时图像追踪,并利用多元信息实现多维度情绪识别后,根据识别到的情绪做出对应措施,克服了表征情绪变化的信息单一且监护效果不理想的问题,进而提高情绪识别的准确率以及监护效果。</td>   <td>1.一种监护设备,适用于配置在轮椅上,其特征在于,包括：主控芯片、动作识别单元、传感单元、语音播放单元和通信单元；所述主控芯片与所述动作识别单元、所述传感单元、所述语音播放单元和所述通信单元连接；所述动作识别单元用于进行动作图像追踪,并将追踪到的所述动作图像发送到所述主控芯片；所述传感单元用于采集人体的生理信号并将所述生理信号发送到所述主控芯片；所述主控芯片用于根据所述动作图像和所述生理信号进行情绪信号识别,并将识别到的所述情绪信号发送到所述语音播放单元和所述通信单元；所述语音播放单元用于根据所述情绪信号生成对应的语音信号；所述通信单元用于将所述情绪信号发送至与所述主控芯片绑定的智能终端；其中,所述动作识别单元包括：图像采集装置、树莓派和两轴自由度云台；所述图像采集装置与所述主控芯片和所述两轴自由度云台连接,所述两轴自由度云台与所述树莓派连接,所述树莓派与所述主控芯片连接；所述图像采集装置包括第一摄像头,所述树莓派包括第一树莓派,所述两轴自由度云台包括第一两轴自由度云台；所述第一摄像头与所述主控芯片和所述第一两轴自由度云台连接,所述第一两轴自由度云台与所述第一树莓派连接,所述第一树莓派与所述主控芯片连接；所述第一摄像头用于采集人脸动作图像并发送到所述主控芯片,以使所述主控芯片根据所述人脸动作图像中的人脸位置信息,生成第一控制信号；所述第一树莓派用于根据所述第一控制信号,控制所述第一两轴自由度云台调整所述第一摄像头的位置信息,直至所述第一摄像头采集的所述人脸动作图像的中心点的位置信息与所述人脸位置信息匹配；所述图像采集装置还包括第二摄像头,所述树莓派还包括第二树莓派,所述两轴自由度云台还包括第二两轴自由度云台；所述第二摄像头与所述主控芯片和所述第二两轴自由度云台连接,所述第二两轴自由度云台与所述第二树莓派连接,所述第二树莓派与所述主控芯片连接；所述第二摄像头用于采集手部动作图像并发送到所述主控芯片,以使所述主控芯片根据所述手部动作图像中的手掌位置信息,生成第二控制信号；所述第二树莓派用于根据所述第二控制信号,控制所述第二两轴自由度云台调整所述第二摄像头的位置信息,直至所述第二摄像头采集的所述手部动作图像的中心点的位置信息与所述手掌位置信息匹配。</td>   <td>G06V40/16;G06V40/20;G06V40/10;G06V10/40;G06V10/46;A61B5/0205;G01R19/00;A61G5/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   马铭       </td>   <td>中山大学</td>   <td>基于边缘点频域空域特征结合图像模糊区域定位方法</td>   <td>广东省</td>   <td>CN110619647B</td>   <td>2022-12-30</td>   <td>本发明提供的基于边缘点频域空域特征结合图像模糊区域定位方法,对待测图像进行边缘点检测,得到不同尺度参数下滤波后的边缘点；在不同尺度的窗口下,对各个边缘点处的窗口图像做再模糊操作,提取原图窗口和再模糊图像窗口的DCT比值的频域特征；计算待测图像的共生矩阵,计算图像空域特征信息；将频域特征与图像空域特征信息进行加权融合并进行滤波操作,得到模糊响应图；用两个模糊响应阈值对模糊响应图进行处理,并将处理结果进行抠图计算,对得到的多尺度全像素点模糊相应图进行多尺度融合,输出融合后的模糊定位结果。本发明提供的模糊区域定位方法,实现了对数字图像中的模糊区域的精确定位,定位精度高。</td>   <td>1.基于边缘点频域空域特征结合图像模糊区域定位方法,其特征在于：包括以下步骤：S1：对待测图像进行边缘点检测,得到不同尺度参数下滤波后的边缘点；S2：在不同尺度的窗口下,对各个边缘点处的窗口图像做不同程度的再模糊操作,提取基于原图窗口和再模糊图像窗口的DCT比值的频域特征；S3：计算待测图像的共生矩阵,计算共生矩阵的能量、熵、对比度从而得到图像空域特征信息；S4：将频域特征与图像空域特征信息进行加权融合并进行滤波操作,得到模糊响应图；S5：用两个模糊响应阈值对模糊响应图进行处理,并将处理结果进行抠图计算,对得到的多尺度全像素点模糊相应图进行多尺度融合,输出融合后的模糊定位结果。</td>   <td>G06T7/12;G06T7/194;G06T7/73;G06T5/00;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              唐建雄;                   谢晓华       </td>   <td>中山大学</td>   <td>用于图像分类的脉冲神经网络的训练方法</td>   <td>广东省</td>   <td>CN115546556A</td>   <td>2022-12-30</td>   <td>本发明针对现有技术的局限性,提出了一种用于图像分类的脉冲神经网络的训练方法,提供了一种快速、节省内存的脉冲神经网络训练方法,设计并运用了一种人工神经网络-脉冲神经网络的权重共享框架,将脉冲神经网络的训练迁移到一个人工神经网络上进行,在相同的网络结构以及时间窗口设置下,本发明的训练速度以及显存消耗是脉冲反向传播模型的43％～67％,33％～55％。</td>   <td>1.一种用于图像分类的脉冲神经网络的训练方法,其特征在于,包括以下步骤：S1,获取输入图像,对所述输入图像进行包括图像规范化在内的数据预处理；S2,获取待训练的脉冲神经网络以及相应的任务需求,根据所述任务需求,对所述脉冲神经网络进行网络初始化；S3,根据所述步骤S2的结果,构建一个权重参数共享的人工神经网络-脉冲神经网络双分支网络结构；S4,以所述步骤S1的结果,对所述人工神经网络-脉冲神经网络双分支网络结构中的人工神经网络分支进行训练；训练完成后,基于权重共享,以其中的脉冲神经网络分支作为可用于图像分类的脉冲神经网络训练结果。</td>   <td>G06V10/764;G06V10/774;G06V10/82;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         段凯;              方晨琦;              许景锋;              郑籽盈;              钟启瑞;                   袁亘宇       </td>   <td>中山大学</td>   <td>一种基于水体覆盖特征识别的山间溪流量测验方法</td>   <td>广东省</td>   <td>CN115546561A</td>   <td>2022-12-30</td>   <td>本发明涉及水文测验技术领域,公开了一种基于水体覆盖特征识别的山间溪流量测验方法,该方法针对流量小、比降大及断面形态高度复杂的山区溪流,通过卷积神经网络从溪流图像的RGB信息矩阵中提取水体覆盖范围的空间特征信息,为溪流图像赋予流量分类标签后,将携带标签的溪流图像对卷积神经网络模型进行训练,建立RGB信息矩阵与流量分类标签概率之间的关系映射表,将获取的待测验溪流图像为输入,通过卷积神经网络模型与关系映射表,得到该待测验溪流图像对应的流量,实现对山区溪流量的自动化连续观测；该方法不仅工程成本与环境成本低廉,还可快速、实时、自动化监测山区溪流量。</td>   <td>1.一种基于水体覆盖特征识别的山间溪流量测验方法,其特征在于,包括以下步骤：获取特定时间段内目标山间溪流的溪流图像样本及其对应的流量值,对所述溪流图像样本进行预处理,获取预处理后的溪流图像样本的RGB信息矩阵；通过卷积神经网络模型提取所述RGB信息矩阵中的图像特征数据,所述卷积神经网络模型为最后三层依次是一个全连接层、一个激活层和一个分类层的AlexNet深度卷积神经网络,所述图像特征数据为目标山间溪流的水体覆盖特征；将预处理后的溪流图像样本按照所述流量值划分的流量分类值进行分类,并为每个溪流图像样本赋予一个流量分类标签,将包含流量分类标签的溪流图像样本构建数据集,并将所述数据集划分为训练集和验证集；通过所述训练集对所述卷积神经网络模型进行训练,得到各流量分类标签对应的分类概率,并根据分类概率最大的流量分类标签,构建所述RGB信息矩阵与流量分类标签概率之间的关系映射表；获取待测验溪流图像样本,提取预处理后的所述待测验溪流图像样本的RGB信息矩阵,并将所述待测验溪流图像样本的RGB信息矩阵输入至所述卷积神经网络模型中进行识别,并根据所述关系映射表得到所述待测验溪流图像样本的RGB信息矩阵对应的流量分类标签,流量分类标签对应的流量值即为所述待测验溪流图像样本对应的溪流流量。</td>   <td>G06V10/764;G06V10/774;G06V10/82;G06V20/10;G06V10/56;G06V10/30;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周素红;              王林森;              邹丹;              宋江宇;                   吴帅霖       </td>   <td>中山大学</td>   <td>一种基于声景观智能分析的生态用地保护方法及系统</td>   <td>广东省</td>   <td>CN115545427A</td>   <td>2022-12-30</td>   <td>本发明公开了一种基于声景观智能分析的生态用地保护方法及系统,该方法包括：收集声景观数据并赋予对应的标签,构建样本数据集；输入样本数据集至深度学习模型进行训练,得到训练后的深度学习模型；获取生态保护红线并沿着生态保护红线设置音频采集设备,获取监测点数据集；输入监测点数据集至训练后的深度学习模型进行分类,并根据分类结果计算达标率,实现对生态保护红线的动态监测。通过使用本发明,能够更好地结合地域的生态环境状况对生态保护红线进行动态监测保护。本发明作为一种基于声景观智能分析的生态用地保护方法及系统,可广泛应用于生态保护范围监测技术领域。</td>   <td>1.一种基于声景观智能分析的生态用地保护方法,其特征在于,包括以下步骤：收集声景观数据并赋予对应的标签,构建样本数据集；输入样本数据集至深度学习模型进行训练,得到训练后的深度学习模型；获取生态保护红线并沿着生态保护红线设置音频采集设备,获取监测点数据集；输入监测点数据集至训练后的深度学习模型进行分类,并根据分类结果计算达标率,实现对生态保护红线的动态监测。</td>   <td>G06Q10/06;G06Q50/26;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘子锋;              高伟;              邱述洪;              岳强;              郑宇浩;              吴诗韵;              李永宏;              洪驹发;              方莹;              覃琳;              胡泽康;              鄞乐炜;              师雯琦;                   陈强       </td>   <td>联通(广东)产业互联网有限公司;中山大学附属第三医院</td>   <td>一种基于数据湖的云边协同医疗数据管理方法及平台</td>   <td>广东省</td>   <td>CN115543933A</td>   <td>2022-12-30</td>   <td>本发明公开一种基于数据湖的云边协同医疗数据管理方法及平台,所述方法应用于医疗数据管理平台,平台包括边缘云以及中心云,边缘云和中心云通信连接,方法包括：采集医疗数据,并将医疗数据发送至边缘云或中心云进行数据存储；边缘云以及中心云对医疗数据进行数据治理；中心云根据医疗数据训练数据分析模型,并将训练好的数据分析模型下发至边缘云,边缘云利用训练好的数据分析模型对医疗数据进行数据分析；边缘云以及中心云均采用数据湖技术进行数据存储。本发明构建云边协同机制,共同对医疗数据进行管理,既保证算力和存储的要求,又能满足时延及安全要求,且使用数据湖技术存储数据,可容纳繁杂的医疗数据,保障医疗数据的全面性和完整性。</td>   <td>1.一种基于数据湖的云边协同医疗数据管理方法,其特征在于,应用于云边协同医疗数据管理平台,所述云边协同医疗数据管理平台包括边缘云以及中心云,所述边缘云和中心云通信连接,方法包括：采集医疗数据,并将所述医疗数据发送至所述边缘云或中心云进行数据存储；所述边缘云以及中心云对所述医疗数据进行数据治理；所述中心云根据所述医疗数据训练数据分析模型,并将训练好的数据分析模型下发至所述边缘云,所述边缘云利用训练好的数据分析模型对所述医疗数据进行数据分析；所述边缘云以及中心云均采用数据湖技术对所述医疗数据进行数据存储。</td>   <td>G06F16/16;G06F16/25;G06F16/27;G16H10/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         南雨宏;              杨培福;              黄佳颖;              张玉亮;                   郑子彬       </td>   <td>中山大学</td>   <td>一种物联网设备敏感数据的识别方法、装置及电子设备</td>   <td>广东省</td>   <td>CN115544567A</td>   <td>2022-12-30</td>   <td>本发明公开了一种物联网设备敏感数据的识别方法、装置及电子设备,方法包括：从物联网设备的描述文本信息中提取多个物联网敏感数据项并构建物联网敏感语义词典；根据语义信息从物联网应用程序的源代码中筛选出若干物联网代码块,物联网代码块与物联网设备在语义上相关；根据物联网敏感语义词典识别出各物联网代码块中包含的若干物联网敏感数据点,物联网敏感数据点是与物联网设备语义相关的文本标签；从物联网应用程序的源代码中查找到与各物联网敏感数据点对应的别名标签组,将所有别名标签和所有物联网敏感数据点关联的程序变量作为物联网设备敏感数据。本发明能够支持大规模、自动化、高效准确地识别出物联网设备所包含的敏感数据。</td>   <td>1.一种物联网设备敏感数据的识别方法,其特征在于,包括：从物联网设备的描述文本信息中提取多个物联网敏感数据项,根据所述多个物联网敏感数据项构建物联网敏感语义词典；根据语义信息从物联网应用程序的源代码中筛选出若干物联网代码块,所述物联网代码块与所述物联网设备在语义上相关；根据所述物联网敏感语义词典识别出各所述物联网代码块中包含的若干物联网敏感数据点,所述物联网敏感数据点是与所述物联网设备语义相关的文本标签；从所述物联网应用程序的源代码中查找到与各所述物联网敏感数据点对应的别名标签组,将所有所述物联网敏感数据点对应的别名标签组和所述若干物联网敏感数据点关联的程序变量作为物联网设备敏感数据,所述别名标签组是所述物联网敏感数据点在所述物联网应用程序的源代码中的多个副本和/或多个引用。</td>   <td>G06F21/62;G06F40/242;G06F40/295</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;                   许翔智       </td>   <td>中山大学</td>   <td>一种基于FPGA和多分辨率哈希编码算法的NeRF渲染器及渲染方法</td>   <td>广东省</td>   <td>CN115546373A</td>   <td>2022-12-30</td>   <td>本发明公开了一种基于FPGA和多分辨率哈希编码算法的NeRF渲染器及渲染方法,涉及图像渲染技术领域,将NeRF渲染器部署到FPGA上,NeRF渲染器包括特征读取器、颜色与不透明度推理器、光线渲染器、内存；特征读取器根据输入的参数,计算得到采样点的光线方向、采样点之间的距离并分别发送给颜色与不透明度推理器、光线渲染器；根据计算得到的采样点的坐标计算所需特征在内存中的地址并读取特征后进行插值处理并发送给颜色与不透明度推理器；颜色与不透明度推理器计算出采样点的颜色、采样点的不透明度并发送到光线渲染器；光线渲染器根据采样点之间的距离、采样点的颜色、不透明度信息计算出渲染结果；对目标特征进行区分,减小了内存的占用,简化渲染步骤。</td>   <td>1.一种基于FPGA和多分辨率哈希编码算法的NeRF渲染器,其特征在于,将NeRF渲染器部署到FPGA上,其中NeRF渲染器包括特征读取器、颜色与不透明度推理器、光线渲染器、预先存储有不同分辨率的表的内存；所述的不同分辨率的表中对应存储有特征点不同频率的特征；所述的特征读取器根据输入需要渲染的图像的相机参数和图像参数,计算得到采样点的光线方向、将采样点之间的距离；所述的特征读取器将计算得到的采样点的光线方向发送给所述的颜色与不透明度推理器,将计算得到的采样点之间的距离发送给所述的光线渲染器；根据计算得到的采样点的坐标计算所需特征,基于多分辨率哈希编码查表法读取内存中的不同频率的表,获得相应的特征；并将获得的特征进行插值处理后发送给所述的颜色与不透明度推理器；所述的颜色与不透明度推理器根据得到的采样点的光线方向和插值处理后的特征计算出采样点的颜色、采样点的不透明度,发送到所述的光线渲染器；所述的光线渲染器根据得到的采样点之间的距离、采样点的颜色和不透明度信息计算出渲染结果。</td>   <td>G06T15/00;G06T9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>海外专利</td>   <td>              黄英哲       </td>   <td>国立中山大学</td>   <td>SYSTEM AND METHOD FOR COUNTING AQUATIC CREATURES</td>   <td></td>   <td>TW202228075</td>   <td>2022-07-16</td>   <td>A system and a method for counting aquatic creatures are provided. The system for counting aquatic creatures includes an image capture device and a computer system to perform the method for counting aquatic creature. The method for counting aquatic creatures includes: using the image capture device to capture images of a flow channel; defining a scan line in each of the images of the flow channel; performing a binarization process on pixels of the scan line in each of the images of the flow channel; determining aquatic creature range data sets in accordance with each of the binarized pixel data sets; determining identification and direction information of aquatic creature corresponding to each of the aquatic creature range data set in accordance with the aquatic creature range data sets; and determining a number of the aquatic creatures passing through the scan line in accordance with the identification and direction information of aquatic creature corresponding to each of the aquatic creature range data sets.</td>   <td></td>   <td>G06T7/20;</td>  </tr>        <tr>   <td>海外专利</td>   <td>         钱德明;                   温朝凯       </td>   <td>国立中山大学</td>   <td>Non-contact Method of Physiological Characteristic Detection</td>   <td></td>   <td>TWI765185</td>   <td>2022-05-21</td>   <td>A non-contact method of physiological characteristic detection is provided to reduce the time consumption and complexity in calculation. The method includes transmitting a radar signal to at least one detected object via a radar to obtain a reflected signal having at least one time session, setting an estimated frequency for each time session, obtaining a wave energy corresponding to the estimated frequency, and converging the wave energy with respect to the reflected signal via an optimized algorithm to thereby obtain a physiological characteristic of the detected object.</td>   <td></td>   <td>G16H50/20;</td>  </tr>        <tr>   <td>海外专利</td>   <td>              庄承鑫       </td>   <td>国立中山大学</td>   <td>認證管理系統</td>   <td></td>   <td>TWI765158</td>   <td>2022-05-21</td>   <td>An authentication management system includes a communication module, a memory module, and a processor, wherein the communication module is used to communicate with a blockchain; the memory module is used to store programs; the processor is electrically connected with the communication module and the memory module to execute programs to perform a coin assignment process. The coin assignment process is a payment process based on transaction information of a first consumer and a contract address of a smart contract, so that the smart contract on the blockchain assigns an authenticated coin to an electronic wallet of the first consumer, wherein the authenticated coin corresponds to single item identification information.</td>   <td></td>   <td>G06F21/62;</td>  </tr>        <tr>   <td>海外专利</td>   <td>         林远彬;              林伟哲;              庄凯强;              梁馨仪;              卢成宪;                   吴逸如       </td>   <td>国立中山大学;长庚医疗财团法人高雄长庚纪念医院</td>   <td>A Method For Evaluating Parkinson&#39;s Disease Related Impulse Control Disorder Via Brainwave And A System Thereof</td>   <td></td>   <td>TW202219979</td>   <td>2022-05-16</td>   <td>An electroencephalogram (EEG)-basis method and system is designed to assess the adverse effect of impulse control disorders in patients with Parkinson's disease. The method and system are based on a preparation step, an acquisition step, and an analysis step. The preparation step is to set up an evaluation system in order to cap an EEG acquisition headset on a test subject and initiate a brief cognitive test battery. The acquisition step is to utilize the evaluation system to measure two sets of EEG signals called reference and inference signals before and after taking drugs, respectively. The analysis step is to characterize the distinction between the measured reference and inference EEG signals by obtaining at least one differential feature corresponding to the engaged impulse-control test. This step is used to objectively assess the test subject’s impulse control integrity. The present method and system can be employed to longitudinally monitor the risk of impulse control disorders during ongoing treatment and thereby provide the EEG-basis evidence for the test patient in order to continue or adjust the personalized drug treatment.</td>   <td></td>   <td>G16H50/20;</td>  </tr>        <tr>   <td>海外专利</td>   <td>         李锡智;              陈佳如;              刘景寛;              周美鹃;              涂景盛;              吴振宇;                   游英杰       </td>   <td>高雄医学大学;国立中山大学</td>   <td>Alzheimer’s Disease Assessment System</td>   <td></td>   <td>TWI764233</td>   <td>2022-05-11</td>   <td>An Alzheimer’s disease assessment system is provided to solve the problem of a known inability to accurately diagnose Alzheimer’s disease. The system includes a data capture module obtaining a plurality of text samples of several subjects, a data preprocessing module is used to execute data pre-processing on the plurality of text samples to generate a clean data, a feature extraction module obtaining at least one importance feature data from the clean data, a data dimension reduction module is used to reduce the dimension of each at least one importance feature data to generate a training data, a processor module uses the training data as a train dataset for a neural network classifier to build a predictive model of Alzheimer’s disease, input a pending text sample into the predictive model to generate a predictive result, and an input module is used to output the predictive result.</td>   <td></td>   <td>G16H50/50;</td>  </tr>        <tr>   <td>海外专利</td>   <td>              黄英哲       </td>   <td>国立中山大学</td>   <td>SYSTEM AND METHOD FOR COUNTING AQUATIC CREATURES</td>   <td></td>   <td>TWI757025</td>   <td>2022-03-01</td>   <td>A system and a method for counting aquatic creatures are provided. The system for counting aquatic creatures includes an image capture device and a computer system to perform the method for counting aquatic creature. The method for counting aquatic creatures includes: using the image capture device to capture images of a flow channel; defining a scan line in each of the images of the flow channel; performing a binarization process on pixels of the scan line in each of the images of the flow channel; determining aquatic creature range data sets in accordance with each of the binarized pixel data sets; determining identification and direction information of aquatic creature corresponding to each of the aquatic creature range data set in accordance with the aquatic creature range data sets; and determining a number of the aquatic creatures passing through the scan line in accordance with the identification and direction information of aquatic creature corresponding to each of the aquatic creature range data sets.</td>   <td></td>   <td>G06T7/20;</td>  </tr>        <tr>   <td>海外专利</td>   <td>         李锡智;              陈佳如;              刘景寛;              周美鹃;              涂景盛;              吴振宇;                   游英杰       </td>   <td>高雄医学大学;国立中山大学</td>   <td>Alzheimer’s Disease Assessment System</td>   <td></td>   <td>TW202207243</td>   <td>2022-02-16</td>   <td>An Alzheimer’s disease assessment system is provided to solve the problem of a known inability to accurately diagnose Alzheimer’s disease. The system includes a data capture module obtaining a plurality of text samples of several subjects, a data preprocessing module is used to execute data pre-processing on the plurality of text samples to generate a clean data, a feature extraction module obtaining at least one importance feature data from the clean data, a data dimension reduction module is used to reduce the dimension of each at least one importance feature data to generate a training data, a processor module uses the training data as a train dataset for a neural network classifier to build a predictive model of Alzheimer’s disease, input a pending text sample into the predictive model to generate a predictive result, and an input module is used to output the predictive result.</td>   <td></td>   <td>G16H50/50;</td>  </tr>        <tr>   <td>海外专利</td>   <td>         林远彬;              林伟哲;              庄凯强;              梁馨仪;              卢成宪;                   吴逸如       </td>   <td>国立中山大学;长庚医疗财团法人高雄长庚纪念医院</td>   <td>A Method For Evaluating Parkinson&#39;s Disease Medication Related Impulse Control Disorder Via Brainwave And A System Thereof</td>   <td></td>   <td>TWI751772</td>   <td>2022-01-01</td>   <td>An electroencephalogram (EEG)-basis method and system is designed to assess the adverse effect of impulse control disorders in patients with Parkinson's disease medication. The method and system are based on a preparation step, an acquisition step, and an analysis step. The preparation step is to set up an evaluation system in order to cap an EEG acquisition headset on a test subject and initiate a brief cognitive test battery. The acquisition step is to utilize the evaluation system to measure two sets of EEG signals called reference and inference signals before and after taking drugs, respectively. The analysis step is to characterize the distinction between the measured reference and inference EEG signals by obtaining at least one differential feature corresponding to the engaged impulse-control test. This step is used to objectively assess the test subject’s impulse control integrity. The present method and system can be employed to longitudinally monitor the risk of impulse control disorders during ongoing treatment and thereby provide the EEG-basis evidence for the test patient in order to continue or adjust the personalized drug treatment.</td>   <td></td>   <td>G16H50/20;</td>  </tr>        <tr>   <td>海外专利</td>   <td>         黄英哲;              洪庆章;                   张云南       </td>   <td>国立中山大学</td>   <td>SYSTEM AND METHOD FOR SMART AQUACULTURE</td>   <td></td>   <td>TWI736950</td>   <td>2021-08-21</td>   <td>A smart aquaculture method is provided for an aquaculture system including a breeding pool, a feeding machine and a camera disposed in the breeding pool. The method includes: taking an underwater image through the camera; calculating a feed remaining amount according to the underwater image; and controlling the feeding machine to dispense feed to the breeding pool according to the feed remaining amount.</td>   <td></td>   <td>G06Q50/02;G06F15/163</td>  </tr>        <tr>   <td>海外专利</td>   <td>         钱德明;                   温朝凯       </td>   <td>国立中山大学</td>   <td>Non-contact Method of Physiological Characteristic Detection</td>   <td></td>   <td>TW202117745</td>   <td>2021-05-01</td>   <td>A non-contact method of physiological characteristic detection is provided to reduce the time consumption and complexity in calculation. The method includes transmitting a radar signal to at least one detected object via a radar to obtain a reflected signal having at least one time session, setting an estimated frequency for each time session, obtaining a wave energy corresponding to the estimated frequency, and converging the wave energy with respect to the reflected signal via an optimized algorithm to thereby obtain a physiological characteristic of the detected object.</td>   <td></td>   <td>G16H50/20;A61B5/02</td>  </tr>        <tr>   <td>海外专利</td>   <td>         黄英哲;              洪庆章;                   张云南       </td>   <td>国立中山大学</td>   <td>SYSTEM AND METHOD FOR SMART AQUACULTURE</td>   <td></td>   <td>TW202107392</td>   <td>2021-02-16</td>   <td>A smart aquaculture method is provided for an aquaculture system including a breeding pool, a feeding machine and a camera disposed in the breeding pool. The method includes: taking an underwater image through the camera; calculating a feed remaining amount according to the underwater image; and controlling the feeding machine to dispense feed to the breeding pool according to the feed remaining amount.</td>   <td></td>   <td>G06Q50/02;G06F15/163</td>  </tr>        <tr>   <td>海外专利</td>   <td>              庄承鑫       </td>   <td>国立中山大学</td>   <td>Authentication Management System which is managed by blockchain</td>   <td></td>   <td>TW202046150</td>   <td>2020-12-16</td>   <td>An authentication management system includes a communication module, a memory module, and a processor, wherein the communication module is used to communicate with a blockchain; the memory module is used to store programs; the processor is electrically connected with the communication module and the memory module to execute programs to perform a coin assignment process. The coin assignment process is a payment process based on transaction information of a first consumer and a contract address of a smart contract, so that the smart contract on the blockchain assigns an authenticated coin to an electronic wallet of the first consumer, wherein the authenticated coin corresponds to single item identification information.</td>   <td></td>   <td>G06F21/62;G06F16/245;G06F21/31;G06Q30/06;G06K7/00</td>  </tr>        <tr>   <td>海外专利</td>   <td>         林宗贤;              李承璋;              曾衡逸;                   赵宏昌       </td>   <td>国立中山大学</td>   <td>MATCHING METHOD OF SHARED DISPLAY MODULE</td>   <td></td>   <td>TW202018631</td>   <td>2020-05-16</td>   <td>A matching method of a shared display module is provided and includes steps of: receiving, by a mediation platform, a service requirement specification, wherein the service requirement specification includes a lease time zone of at least one display module disposed on a building exterior wall; comparing, by the mediation platform, the service requirement specification with at least one service providing specification of a plurality of service providers in the mediation platform; and transmitting, by the mediation platform, at least one compared providing specification conforming to the service requirement specification to an use end of the service requirement specification.</td>   <td></td>   <td>G06Q30/02;G06Q30/06</td>  </tr>        <tr>   <td>海外专利</td>   <td>         苏俊连;              郑凯恩;              温朝凯;                   卢展南       </td>   <td>国立中山大学</td>   <td>區域配電網電動車電能補充決策分析系統</td>   <td></td>   <td>TWI520092</td>   <td>2016-02-01</td>   <td>The present invention relates to a decision analysis system on electricity replenishment for electric vehicles in regional electricity distribution network. Regional electricity distribution network power transmission data and transformer specifications data of the system were inputted to analyze the value of electricity rechargeable margin under which the electric vehicle system will not affect transformers of the regional electricity distribution network, so that users may use the analysis result as a basis to control the regional electricity distribution network for inputting electricity to electric vehicles. This electric vehicle electricity replenishment decision analysis system comprises an input terminal for inputting the regional electricity distribution network power transmission data and transformer specifications data of the regional electricity distribution network; a processor electrically connected to the input terminal for receiving the regional electricity distribution network power transmission data and the transformer specifications data. The processor is written with analysis software, which can be executed by the processor. On the basis of transformer service life deterioration rate and by taking the regional electricity distribution network power transmission data and transformer specifications data, the electricity rechargeable margin of electric vehicle is analyzed. An output terminal is electrically connected to the processor to output the electric vehicle rechargeable power margin data.</td>   <td></td>   <td>G06Q50/06;H02J13/00;H02J7/02</td>  </tr>        <tr>   <td>海外专利</td>   <td>         李锡智;              江忠益;                   蔡宪奇       </td>   <td>国立中山大学</td>   <td>MULTI-LABEL TEXT CATEGORIZATION BASED ON FUZZY SIMILARITY AND K NEAREST NEIGHBORS</td>   <td></td>   <td>TWI452477</td>   <td>2014-09-11</td>   <td>The multi-label text categorization of the present invention includes the steps of: (a) calculating the fuzzy similarity of every training document to every class according to the similarity of every feature to every class and the similarity of every feature to every training document; (b) clustering all the training documents according to the fuzzy similarities; (c) calculating the distribution of k nearest neighbors of an un-known document according to the clustered results ; and (d) determining the classification of the un-known document according to the distribution of the k nearest neighbors.</td>   <td></td>   <td>G06F17/30;G06F17/21;G06N7/02</td>  </tr>        <tr>   <td>海外专利</td>   <td>         李锡智;                   廖庭亿       </td>   <td>国立中山大学</td>   <td>METHOD OF DETECTING NEAR-DUPLICATE DOCUMENT</td>   <td></td>   <td>TW201423448</td>   <td>2014-06-16</td>   <td>A method of detecting near-duplicate document including “preprocessing the training document”, “feature selection of the training document model”, “building the feature index”, “preprocessing the testing document”, “feature selection of the testing document”, “categorizing the testing feature set in the  
feature index” and “determining the test document is the near-duplicate document of the training document”. Wherein building the feature set based on the sentences can enhance the credibility of the detecting result, and detecting the similarity between the plurality documents can more faster through the feature index and reducing the computing resource of the near-duplicate document detecting, and decreasing the detecting time of the near-duplicate document detecting.</td>   <td></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>海外专利</td>   <td>         张玉盈;                   陈慧玲       </td>   <td>国立中山大学</td>   <td>EFFICIENT STRATEGY OF SPATIAL JOINS BASED ON NA-TREE</td>   <td></td>   <td>TWI435228</td>   <td>2014-04-21</td>   <td>In the efficient strategy of spatial joins based on NA-Tree of the invention, the NA-Tree is served as an index for analyzing and generalizing two spatial datasets to form an overlapping rule, thus establishing an efficient strategy of spatial joins. The NA-Tree has the characteristic that each spatial dataset is divided with nine categories of areas, wherein each object occupying limited space is with a spatial number and wholly and individually exists in a single node. Whereby, the strategy of spatial joins of the invention requires less number of comparisons and less number of disk accesses and thus being more efficient.</td>   <td></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>海外专利</td>   <td>         张玉盈;                   陈慧玲       </td>   <td>国立中山大学</td>   <td>NA-TREE-BIT-PATTERNS-BASED METHOD FOR CONTINUOUS RANGE QUERIES OVER MOVING OBJECTS</td>   <td></td>   <td>TWI430120</td>   <td>2014-03-11</td>   <td>In the NA-Tree-bit-patterns-based method for continuous range queries over moving objects of the invention, every range query is regarded as a single spatial object with a range. According to the range query an index thereof is constructed, in which every area is represented as a bit-patterns by numbering in binary and recognized according to the bit-patterns in a NA-Tree index. Utilizing the corresponding NA-Tree index and bit-patterns the relationship between range queries and objects are quickly decided in a continuous periodic period, and objects in queries are mined. Whereby, the efficiency of continuous range queries is improved, the usage of space is not increased and overloaded and the index needs not to be reconstructed.</td>   <td></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>海外专利</td>   <td>         温志宏;              吴柏贤;              刘文生;              张富信;                   陈琮崴       </td>   <td>国立中山大学</td>   <td>FISH BODY IMAGE ANALYSIS SYSTEM FOR USE IN THE SCREENING OF A CANDIDATE AS A SKIN WHITENING AGENT AND APPLICATIONS OF THE SAME</td>   <td></td>   <td>TWI421784</td>   <td>2014-01-01</td>   <td>Disclosed herein is a fish body image analysis system for use in the screening of a candidate as a skin whitening agent, comprising a first population of zebrafish, a second population of zebrafish, an image capture device, and an image analysis software. The fish body image analysis system can be used to screen a skin whitening agent.</td>   <td></td>   <td>G06K9/78</td>  </tr>        <tr>   <td>海外专利</td>   <td>              谢明辉       </td>   <td>国立中山大学</td>   <td>A METHOD, COMPUTER PROGRAM PRODUCT AND READABLE MEDIUM FOR SELECTING A NAME BY COMPUTERS</td>   <td></td>   <td>TW201348986</td>   <td>2013-12-01</td>   <td>A method for selecting a name by computers is disclosed. The method comprises a step for getting a keyword, analyzing strokes of the keyword for copying the keyword to a name; a step for displaying a plurality of to-be-select parameters based on the strokes, getting a select command for selecting a selected parameter that one of the to-be-select parameters fitted the select command and having a first stroke and a second stroke, displaying a plurality of first to-be-select word fitted the first stroke; a step for getting a first select-word command to select one of the first to-be-select word fitted the first select-word command to append to the name, displaying a plurality of second to-be-select word based on the second stroke and a step for getting a second select-word command to select one of the second to-be-select word fitted the second select-word command to append to the name, storing the name to a readable medium. Furthermore, a computer program product and a readable medium are disclosed to accomplish the method.</td>   <td></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>海外专利</td>   <td>         彭昭暐;                   戴嘉辉       </td>   <td>国立中山大学</td>   <td>METHOD FOR THREE-DIMENSIONAL GEOMETRIC MEASUREMENT</td>   <td></td>   <td>TW201346833</td>   <td>2013-11-16</td>   <td>A method for three-dimensional geometric measurement is provided and includes steps of: establishing initial coordinate data and image data of an object; comparing the initial coordinate data for generating a positioning date; structuring the positioning data for generating grid data; integrating the grid data and the image data to form a set of three-dimensional model; transforming three-dimensional coordinate data of the three-dimensional model to a project coordinate suitably applied to an application programming interface; and executing the application programming interface according to the project coordinate by a graphic processing unit of an image processing interface for drawing and measuring the three-dimensional image information of the object, and directly saving it to a storage disc. The present invention can not only effectively complete the size and volume measurements of a livestock to realize the purpose of humans and animals separation while measuring, but also improve the efficiency of real-time scanning and three-dimensional mapping.</td>   <td></td>   <td>G06T15/10;G01B11/24</td>  </tr>        <tr>   <td>海外专利</td>   <td>         黄英哲;                   杨馥璟       </td>   <td>国立中山大学</td>   <td>COMPRESSED DATA MANAGING SYSTEM AND METHOD FOR CIRCULAR BUFFER</td>   <td></td>   <td>TWI413899</td>   <td>2013-11-01</td>   <td>The invention relates to a compressed data managing system and method for circular buffer. By using the system and method of the invention, when storing the compressed data in a circular memory and an event occurs, the hardware compression mechanism can stop immediately, without jeopardizing the decompression of the compressed data. Therefore, the system and method of the invention can overcome the following conventional problem: Conventional real-time tracers need several cycles to write the compressed data into the trace memory, which is unbeneficial to error diagnosis. Since when a error occurs, the system might enter the unstable state, this could cause that the tracers fail to write the compressed data into the trace memory.</td>   <td></td>   <td>G06F12/16;G06F12/04</td>  </tr>        <tr>   <td>海外专利</td>   <td>         张云南;                   董庭吉       </td>   <td>国立中山大学</td>   <td>AN OPERATION METHOD OF A HIERARCHICAL BUFFER FOR APPLICATION OF VECTOR GRAPHICS RASTERIZATION</td>   <td></td>   <td>TW201335881</td>   <td>2013-09-01</td>   <td>An operation method of a hierarchical buffer for application of vector graphics rasterization includes providing a display device; providing a hierarchical buffer having a first-level, a second-level and a third-level buffer; clearing the first-level, the second-level and the third-level buffer; making a vector graphic displayed on a screen of the display, when an intersection point is intersected by the vector graphic and a scan-line, a value of address of the first-level buffer corresponded to the intersection point is able to proceed with a state update, wherein flags of the second-level and the third-level buffer corresponded to the updated value are renewed into set; reading the third-level buffer and determining whether each flag can be set or reset, if the flag is indicated as reset, reading the next flag of the third-level buffer, if the flag is indicated as set, reading the flags of the second-level buffer corresponded to the flag of the third-level buffer and determining whether each flag can be set or reset, if one of the flags of the second-level buffer is indicated as set, then reading the first-level buffer corresponded to the flag of the second-level buffer.</td>   <td></td>   <td>G06T1/00;G06T13/00</td>  </tr>        <tr>   <td>海外专利</td>   <td>         张玉盈;                   吴振彰       </td>   <td>国立中山大学</td>   <td>於Ｈｉｌｂｅｒｔ曲線中求範圍查詢之方法</td>   <td></td>   <td>TWI398828</td>   <td>2013-06-11</td>   <td>在本發明於Hilbert曲線中求範圍查詢之方法中，利用Hilbert曲線的特性，依據Hilbert曲線之路徑定義查詢區域之定位態樣且依據查詢區域及查詢視窗(window)定義視窗態樣，並以四等份切割法(Quad-Splitting)區分查詢範圍及查詢區域後，計算查詢視窗中所有區塊的排序(Hilbert index的值)。藉此，所需時間複雜度較低，且所計算之排序區段不需再經額外的排序與合併步驟，故可以有效減少計算執行時間。</td>   <td></td>   <td>G06T9/20;G06F17/10</td>  </tr>        <tr>   <td>海外专利</td>   <td>         李锡智;              江忠益;                   郑文豪       </td>   <td>国立中山大学</td>   <td>DISTRIBUTED DATA COLLECTING METHOD AND SYSTEM THEREOF USING MAP-REDUCE PROGRAMMING</td>   <td></td>   <td>TW201322012</td>   <td>2013-06-01</td>   <td>The present invention relates to a distributed data collecting method and system thereof using map-reduce programming. The method comprises the steps of providing a plurality of remote monitoring points and a database and performing a map process to divide the remote monitoring points into a plurality of clusters, collect a plurality of data of the remote monitoring points within each cluster and store the data of the remote monitoring points into the database. This invention is capable of enhancing the efficiency of data collection and improving the safety of data backup.</td>   <td></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>海外专利</td>   <td>         李淑敏;                   郑意学       </td>   <td>国立中山大学</td>   <td>TOPOLOGY SYNTHESIS METHOD FOR 3D NETWORK ON CHIPS</td>   <td></td>   <td>TW201312378</td>   <td>2013-03-16</td>   <td>A topology synthesis method for 3D NOCs includes: searching a plurality of source nodes and a plurality of target nodes on a circuit; analyzing communication relationships between the source nodes and the target nodes so as to obtain a plurality of source components and target components; transforming the source components and target components by a communication trace graph (CTG) so as to obtain a communication trace bipartite graph (CTB); calculating the communication trace bipartite graph by CTG so as to obtain a set of tiers and a number of through silicon via (TSV) connected therebetween; partitioning the circuit into partitions according to the tiers; assigning the partitions to the tires by tier assignment to obtain a 3D structure.</td>   <td></td>   <td>G06F17/50;G06F15/78</td>  </tr>        <tr>   <td>海外专利</td>   <td>         张玉盈;                   沈俊宏       </td>   <td>国立中山大学</td>   <td>HILBERT CURVE-BASED DISTRIBUTED INDEX FOR WINDOW QUERIES IN WIRELESS DATA BROADCAST SYSTEMS AND WINDOW QUERY METHOD</td>   <td></td>   <td>TWI377479</td>   <td>2012-11-21</td>   <td>This invention relates to a Hilbert curve-based distributed index for window queries in wireless data broadcast systems. It allocates spatial objects in the Hilbert-curve order to preserve the spatial locality. Moreover, to quickly answer window queries, it utilizes the neighbor-link index, which has knowledge about neighbor objects, to return the answered objects. Since battery power is a scarce resource in mobile devices, it is crucial for saving energy consumption of devices during the query process. Therefore, in the wireless environments, it can reduce the amount of time spent by a client listening the channel efficiently and save the power consumed by the client to retrieve the required data.</td>   <td></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>海外专利</td>   <td>         李锡智;              江忠益;                   刘仁嘉       </td>   <td>国立中山大学</td>   <td>FUZZY SELF-CONSTRUCTING FEATURE CLUSTERING ALGORITHM FOR TEXT CLASSIFICATION</td>   <td></td>   <td>TW201232297</td>   <td>2012-08-01</td>   <td>The fuzzy self-constructing feature clustering algorithm for text classification of the present invention includes the steps of: (a) representing a feature with the occurrences of each of documents in p classes; (b) clustering the features into a plurality of clusters according to every feature and a similarity threshold; (c) obtaining cluster features according to every feature of the clusters; and (d) categorizing all the documents according to the cluster features. Whereby, the number of features can be reduced, and the clustering algorithm has efficient processing ability and high classification accuracy. Furthermore, it requires less space for saving documents and less time of training and testing for classification.</td>   <td></td>   <td>G06F17/30;G06N7/02;G06F17/16</td>  </tr>        <tr>   <td>海外专利</td>   <td>         张玉盈;              沈俊宏;                   陈姿伊       </td>   <td>国立中山大学</td>   <td>A DATA-MINING-BASED METHOD OF CONSTRUCTING THE UPDATABLE TREE FOR RECORDING PERSONALIZED INFORMATION</td>   <td></td>   <td>TWI366772</td>   <td>2012-06-21</td>   <td>本發明係關於一種利用資料探勘以建立記錄個人化資訊可更新樹之方法。本發明方法可應用在資訊過濾技術中，使用者設定檔索引可以加速新進文件比對速度，主動將符合使用者關鍵字(興趣)的文件推薦給使用者，而非讓使用者在眾多的文件中搜尋想要的資料。並且，本發明之方法係提出考慮關鍵字權重，將使用者關鍵字區分為長期關鍵字與短期關鍵字，並利用資料探勘法以建立記錄個人化資訊可更新樹，以支援漸近式更新，而不需如習知方法必須重建整棵使用者設定檔索引樹，可減少更新花費。</td>   <td></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>海外专利</td>   <td>         张玉盈;                   陈慧玲       </td>   <td>国立中山大学</td>   <td>NA-TREE-BIT-PATTERNS-BASED METHOD FOR CONTINUOUS RANGE QUERIES OVER MOVING OBJECTS</td>   <td></td>   <td>TW201224800</td>   <td>2012-06-16</td>   <td>In the NA-Tree-bit-patterns-based method for continuous range queries over moving objects of the invention, every range query is regarded as a single spatial object with a range. According to the range query an index thereof is constructed, in which every area is represented as a bit-patterns by numbering in binary and recognized according to the bit-patterns in a NA-Tree index. Utilizing the corresponding NA-Tree index and bit-patterns the relationship between range queries and objects are quickly decided in a continuous periodic period, and objects in queries are mined. Whereby, the efficiency of continuous range queries is improved, the usage of space is not increased and overloaded and the index needs not to be reconstructed.</td>   <td></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>海外专利</td>   <td>              张云南       </td>   <td>国立中山大学</td>   <td>METHOD OF REDUCING MEMORY ACCESS FREQUENCY FOR GRAPHIC RENDERING SYSTEM AND CIRCUIT THEREOF</td>   <td></td>   <td>TWI360787</td>   <td>2012-03-21</td>   <td>一種降低圖形呈像系統記憶體讀取次數之方法，其包含下列步驟：a)進行一畫面分割步驟，其係將一畫面分割成複數個區塊，各該區塊係對應系統記憶體之一位址，且各該區塊係以一旗標位元(X,Y)紀錄區塊處理狀態；b)根據系統下達之一重置指令(Reset)，將各該區塊之各該旗標位元更改為(X1,Y1)，以表示預設該些區塊皆被更改過且不需要執行清除動作；c)根據系統下達之一清除緩衝區指令(Clear)，將旗標位元為(X1,Y1)之該些區塊之旗標位元更改為(X2,Y2)，以表示該些區塊需要執行清除動作；d)進行一繪圖步驟；以及e)進行一系統記憶體清除步驟，其係在繪圖結束後且欲輸出之前，對旗標位元為(X2,Y2)之該些區塊所對應系統記憶體之該些位址執行清除動作，並將清除完成之該些區塊之旗標位元更改為(X3,Y3)，以表示該些區塊已清除過。</td>   <td></td>   <td>G06T1/60</td>  </tr>        <tr>   <td>海外专利</td>   <td>         张玉盈;                   吴振彰       </td>   <td>国立中山大学</td>   <td>Method of finding range inquiry in the Hilbert curve</td>   <td></td>   <td>TW201135671</td>   <td>2011-10-16</td>   <td>In this invention a method of finding range inquiry in the Hilbert curve is disclosed, wherein the characteristic of the Hilbert curve is utilized to define the positioning type of an inquired area according to the route of the Hilbert curve and define the window type according to the inquired area and the inquired window, and after the inquired range and the inquired area are distinguished by using the Quad-Splitting, the sorting (Hilbert index value) of all blocks in the inquired window is calculated. Thus, the required computation complexity is lower, and the calculated sorting segments do not need extra sorting and combination steps, thereby effectively reducing the calculation and execution time.</td>   <td></td>   <td>G06T9/20;G06F17/10</td>  </tr>        <tr>   <td>海外专利</td>   <td>         温志宏;              吴柏贤;              刘文生;              张富信;                   陈琮崴       </td>   <td>国立中山大学</td>   <td>FISH BODY IMAGE ANALYSIS SYSTEM FOR USE IN THE SCREENING OF A CANDIDATE AS A SKIN WHITENING AGENT AND APPLICATIONS OF THE SAME</td>   <td></td>   <td>TW201117111</td>   <td>2011-05-16</td>   <td>Disclosed herein is a fish body image analysis system for use in the screening of a candidate as a skin whitening agent, comprising a first population of zebrafish, a second population of zebrafish, an image capture device, and an image analysis software. The fish body image analysis system can be used to screen a skin whitening agent.</td>   <td></td>   <td>G06K9/78</td>  </tr>        <tr>   <td>海外专利</td>   <td>              劳伯特律格 ROBERT RIEGER DE       </td>   <td>国立中山大学&lt;addr&gt; NATIONAL SUN YAT-SEN UNIVERSITY 高雄市鼓山区莲海路70号 TW NO. 70, LIEN-HAI RD., GUSHAN DIST., KAOHSIUNG CITY, TAIWAN, R. O. C.</td>   <td>用於Ａ／Ｄ转换器之取样控制系统及方法;SAMPLING CONTROL SYSTEM AND METHOD FOR A/D CONVERTER</td>   <td></td>   <td>TWI327825</td>   <td>2010-07-21</td>   <td>本发明系关於一种用於A/D转换器之取样控制系统及方法，该取样控制系统包括：一个一次微分电路、一个二次微分电路、至少一比较电路、一判断逻辑电路、一选择器及一计数器。藉由利用判断输入讯号之一次微分讯号绝对值是否小於一第一临界值，及输入讯号之二次微分讯号绝对值是否大於或等於一第二临界值，以决定一取样时脉讯号至A/D转换器。因此，本发明之取样控制系统及方法可以依据输入讯号调整取样频率，使得经取样後之重建讯号与原讯号接近，并且可以降低平均取样频率，减少取样次数，降低重复转换资料，减少所需储存空间及功率消耗。</td>   <td></td>   <td></td>  </tr>        <tr>   <td>海外专利</td>   <td>              张云南 CHANG, YUN NAN       </td>   <td>国立中山大学 NATIONAL SUN YAT-SEN UNIVERSITY</td>   <td>降低图形呈像系统记忆体读取次数之方法及其电路架构 METHOD OF REDUCING MEMORY ACCESS FREQUENCY FOR GRAPHIC RENDERING SYSTEM AND CIRCUIT THEREOF</td>   <td></td>   <td>TW200926051</td>   <td>2009-06-16</td>   <td>一种降低图形呈像系统记忆体读取次数之方法，其包含下列步骤：a)进行一画面分割步骤，其系将一画面分割成复数个区块，各该区块系对应系统记忆体之一位址，且各该区块系以一旗标位元(X,Y)纪录区块处理状态；b)根据系统下达之一重置指令(Reset)，将各该区块之各该旗标位元更改为(X1,Y1)，以表示预设该些区块皆被更改过且不需要执行清除动作；c)根据系统下达之一清除缓冲区指令(Clear)，将旗标位元为(X1,Y1)之该些区块之旗标位元更改为(X2,Y2)，以表示该些区块需要执行清除动作；d)进行一绘图步骤；以及e)进行一系统记忆体清除步骤，其系在绘图结束後且欲输出之前，对旗标位元为(X2,Y2)之该些区块所对应系统记忆体之该些位址执行清除动作，并将清除完成之该些区块之旗标位元更改为(X3,Y3)，以表示该些区块已清除过。</td>   <td></td>   <td>G06T1/60</td>  </tr>        <tr>   <td>海外专利</td>   <td>         袁中新 YUAN, CHUNG SHIN;              罗卓卿 LO, CHO CHING;              刘山豪 LIU, SAN HO;              罗金翔 LUO, CHIN HSINANG;              杨宏宇 YANG, HORNG YU;                   袁菁 YUAN, CHING       </td>   <td>国立中山大学 NATIONAL SUN YAT-SEN UNIVERSITY 高雄市西子湾莲海路70号</td>   <td>自动控制之能见度光学观测系统 AUTOMATED OPTICAL VISIBILITY OBSERVATION SYSTEM</td>   <td></td>   <td>TWI251788</td>   <td>2006-03-21</td>   <td>本发明系关于一种自动控制之能见度光学观到系统，包括：一光学系统、一中央处理系统以及一影像特征辨识系统。该光学系统用以取得定焦定向标的之影像。该中央处理系统用以控制该光学系统之操作，并接收该光学系统之标的影像。该影像特征辨识系统用以对于该标的影像，进行影像特征辨识，以分析能见度。利用本发明之能见度光学观测系统在于针对大气能见度之观测方式加以改进，由目测观测方式提升为利用该光学系统以数位影像观测方式取得影像，再结合中央处理系统，进行定焦定向自动拍摄控制与资料分类储存。同时亦可藉由网际网路以一远端控制管理系统做控制管理，进行即时或定时拍照。最后以影像特征辨识系统进行数位影像特征之分析，以自动进行大气能见度之判断，可有效提升能见度观测之准确性及节省人力。</td>   <td></td>   <td>G06K9/78</td>  </tr>        <tr>   <td>海外专利</td>   <td>         袁中新 YUAN, CHUNG-SHIN;              罗卓卿 LO, CHO-CHING;              刘山豪 LIU, SAN-HO;              罗金翔 LUO, CHIN-HSINANG;              杨宏宇 YANG, HORNG-YU;                   袁菁 YUAN, CHING       </td>   <td>国立中山大学 NATIONAL SUN YAT-SEN UNIVERSITY 高雄市西子湾莲海路70号</td>   <td>自动控制之能见度光学观测系统 AUTOMATED OPTICAL VISIBILITY OBSERVATION SYSTEM</td>   <td></td>   <td>TW200535722</td>   <td>2005-11-01</td>   <td>本发明系关于一种自动控制之能见度光学观测系统，包括：一光学系统、一中央处理系统以及一影像特征辨识系统。该光学系统用以取得定焦定向标的之影像。该中央处理系统用以控制该光学系统之操作，并接收该光学系统之标的影像。该影像特征辨识系统用以对于该标的影像，进行影像特征辨识，以分析能见度。利用本发明之能见度光学观测系统在于针对大气能见度之观测方式加以改进，由目测观测方式提升为利用该光学系统以数位影像观测方式取得影像，再结合中央处理系统，进行定焦定向自动拍摄控制与资料分类储存。同时亦可藉由网际网路以一远端控制管理系统做控制管理，进行即时或定时拍照。最后以影像特征辨识系统进行数位影像特征之分析，以自动进行大气能见度之判断，可有效提升能见度观测之准确性及节省人力。</td>   <td></td>   <td>G06K9/78</td>  </tr> </table></body></html>