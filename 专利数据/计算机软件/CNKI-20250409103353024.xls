<html xmlns:o='urn:schemas-microsoft-com:office:office' xmlns:x='urn:schemas-microsoft-com:office:excel' xmlns='http://www.w3.org/TR/REC-html40'><head><style>table td,th{vnd.ms-excel.numberformat:@;text-align: center;} table th{color:red}</style><title></title><meta http-equiv='Content-Type' content="text/html; charset=utf-8"></head><body><table cellspacing='0' border='1'>     <tr>   <td style='vnd.ms-excel.numberformat:@'>SrcDatabase-来源库</td>   <td style='vnd.ms-excel.numberformat:@'>Author-作者</td>   <td style='vnd.ms-excel.numberformat:@'>Applicant-申请人</td>   <td style='vnd.ms-excel.numberformat:@'>Title-题名</td>   <td style='vnd.ms-excel.numberformat:@'>CountryName-国省名称</td>   <td style='vnd.ms-excel.numberformat:@'>PubNo-公开号</td>   <td style='vnd.ms-excel.numberformat:@'>PubTime-公开日期</td>   <td style='vnd.ms-excel.numberformat:@'>Summary-摘要</td>   <td style='vnd.ms-excel.numberformat:@'>Claims-主权项</td>   <td style='vnd.ms-excel.numberformat:@'>CLC-中图分类号</td>  </tr>  <tr>   <td>中国专利</td>   <td>         林誉涵;              许浩然;                   谭光       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于状态估计的低延迟多车鸟瞰图感知方法及装置</td>   <td>广东省</td>   <td>CN117576660A</td>   <td>2024-02-20</td>   <td>本发明公开了一种基于状态估计的低延迟多车鸟瞰图感知方法及装置,方法包括：获取目标对象的摄像头数据以及GPS定位数据；对摄像头数据进行目标检测,得到第一目标检测框；根据第一目标检测框以及GPS定位数据,得到目标位置；根据GPS定位数据以及目标位置,得到第一观测数据；将第一观测数据作为新数据输入缓冲区,对第一观测数据进行聚类,获得目标对象的数量；对目标对象进行状态估计,得到中间结果,将中间结果返回；所述中间结果用于提供实时全局地图信息。本发明扩大了联网自动驾驶汽车的感知范围,能及时检测到障碍物,有助于事故预防,通过状态估计,提高感知系统的可解释性,可广泛应用于自动驾驶技术领域。</td>   <td>1.一种基于状态估计的低延迟多车鸟瞰图感知方法,其特征在于,包括：获取目标对象的摄像头数据以及GPS定位数据；对所述摄像头数据进行目标检测,得到第一目标检测框；根据所述第一目标检测框以及所述GPS定位数据,得到目标位置；根据所述第一目标检测框以及所述目标位置,得到第一观测数据；将所述第一观测数据作为新数据输入缓冲区,对所述第一观测数据进行聚类,获得所述目标对象的数量；结合所述目标对象的数量,对所述目标对象进行状态估计,得到中间结果,将所述中间结果返回；所述中间结果用于提供实时全局地图信息。</td>   <td>G06V20/58;G06V10/762;G06V10/764;G06V10/44;G06V10/52;G06V10/82;G06N3/0455;G01S19/42</td>  </tr>        <tr>   <td>中国专利</td>   <td>         盛璞义;                   李钦       </td>   <td>中山大学附属第一医院</td>   <td>人工关节感染识别方法、装置、电子设备及可读存储介质</td>   <td>广东省</td>   <td>CN117576726A</td>   <td>2024-02-20</td>   <td>本申请提供了一种人工关节感染识别方法、装置、电子设备及计算机可读存储介质。该人工关节感染识别方法,包括：获取假体关节部位图像和体征文本信息；对假体关节部位图像进行图像编码层特征提取,得到图像特征信息；对体征文本信息进行文本编码层特征提取,得到文本特征信息；对图像特征信息和文本特征信息进行多模态信息融合,得到融合特征信息；基于融合特征信息进行人工关节感染识别。根据本申请实施例,能够更加准确地识别人工关节感染。</td>   <td>1.一种人工关节感染识别方法,其特征在于,包括：获取假体关节部位图像和体征文本信息；对假体关节部位图像进行图像编码层特征提取,得到图像特征信息；对体征文本信息进行文本编码层特征提取,得到文本特征信息；对图像特征信息和文本特征信息进行多模态信息融合,得到融合特征信息；基于融合特征信息进行人工关节感染识别。</td>   <td>G06V40/10;G06V10/80;G06V10/771;G06V30/41;G06V30/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高峰;              丁俊翔;              刘俊伟;              盖宝文;              蔡都;              吴小剑;                   李亦学       </td>   <td>中山大学附属第六医院</td>   <td>一种基于多模态模型的癌症患者预后预测方法及装置</td>   <td>广东省</td>   <td>CN116994745B</td>   <td>2024-02-13</td>   <td>本申请属于癌症生存分析和预后预测技术领域,公开了一种基于多模态模型的癌症患者预后预测方法及装置,该方法包括：获取患者的待分析数字病理图像并预处理,得到病理图像数据；将病理图像数据输入训练好的多模态模型中；训练好的多模态模型包括病理图像模块、桥接网络、融合模块和风险评分模块；通过病理图像模块中的自注意力层和位置编码提取病理图像数据的病理特征；通过桥接网络根据病理特征进行推断,得到分子特征；通过融合模块对病理特征和分子特征进行融合,得到多模态融合特征；通过风险评分模块对多模态融合特征进行预测,得到患者的预测风险评分。本申请提高了预测风险评分的准确性,增强了本申请在临床应用中的实用性。</td>   <td>1.一种基于多模态模型的癌症患者预后预测方法,其特征在于,所述方法包括：获取患者的待分析数字病理图像并预处理,得到病理图像数据；将所述病理图像数据输入训练好的多模态模型中；所述训练好的多模态模型包括病理图像模块、桥接网络、融合模块和风险评分模块；通过所述病理图像模块中的自注意力层和位置编码提取所述病理图像数据的病理特征；其中,所述病理图像模块中有两个自注意力层和一个位置编码,所述自注意力层用来提取所述病理图像数据中的关联信息,所述位置编码用来提取所述病理图像数据的空间信息；通过所述桥接网络根据所述病理特征进行推断,得到分子特征；具体地,采用公式进行推断；其中,/&gt;是所述桥接网络中的自编码器网络模型,/&gt;是所述病理特征,/&gt;是所述分子特征；通过所述融合模块对所述病理特征和所述分子特征进行融合,得到多模态融合特征；具体地,采用公式进行融合,其中,/&gt;是所述多模态融合特征,/&gt;是向量积；通过所述风险评分模块对所述多模态融合特征进行预测,得到所述患者的预测风险评分。</td>   <td>G16H50/20;G16B40/00;G16H30/20;G06N3/0455;G06N3/048;G06N3/08;G06T7/00;G06T7/11;G06V10/26;G06V10/44;G06F18/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永强;              周永章;              王维曦;              王汉雨;              贺炬翔;              许娅婷;                   曹伟       </td>   <td>中山大学</td>   <td>一种基于知识图谱的场地土壤污染问答系统及问答方法</td>   <td>广东省</td>   <td>CN117131184B</td>   <td>2024-02-13</td>   <td>本发明公开了一种基于知识图谱的场地土壤污染问答系统及问答方法,包括：数据整合模块,用于从若干数据源中收集与场地土壤污染相关的文本数据,并通过自然语言处理技术进行处理和分析,以提取场地土壤污染数据；图谱构建模块,用于根据场地土壤污染数据构建场地土壤污染知识图谱,并将其存储在图数据库中；问答引擎模块,用于对目标问题进行语义理解和意图识别,然后在场地土壤污染知识图谱中进行语义匹配和数据检索,获取目标实体、目标属性和目标关系,并生成对应的目标答案；用户交互模块,用于获取用户输入的目标问题,以及将目标答案返回给用户。本发明能够通过智能问答的方式提供准确及时全面的场地土壤污染相关信息。</td>   <td>1.一种基于知识图谱的场地土壤污染问答系统,其特征在于,所述系统包括：数据整合模块,用于从若干数据源中收集与场地土壤污染相关的文本数据,并通过自然语言处理技术对所述文本数据进行处理和分析,以提取场地土壤污染数据；其中,所述数据源至少包括科研论文数据库、环境监测数据库、场地土壤污染调查报告和专家经验；图谱构建模块,用于根据所述场地土壤污染数据构建场地土壤污染知识图谱,以及将所述场地土壤污染知识图谱存储在图数据库中；其中,所述场地土壤污染知识图谱包括场地土壤污染实体、场地土壤污染属性和场地土壤污染关系；所述场地土壤污染知识图谱包括模式层和数据层；其中,所述模式层用于定义概念节点,包括概念实体和概念属性,以及概念节点间的层级语义关系与约束规则；所述数据层用于基于所述场地土壤污染数据获取场地土壤污染实例的具体要素,所述具体要素包括实体类型、实体属性和实体关系,并建立所述具体要素与对应的概念节点之间的映射；问答引擎模块,用于对目标问题进行语义理解和意图识别,然后在所述场地土壤污染知识图谱中进行语义匹配和数据检索,获取目标实体、目标属性和目标关系,并生成对应所述目标问题的目标答案；用户交互模块,用于获取用户输入的目标问题,以及将所述目标答案返回给所述用户；其中,所述图谱构建模块具体用于：构建所述场地土壤污染知识图谱的模式层,具体包括：定义所述模式层中所包含的核心概念；所述核心概念至少包括场地、污染、场地相关概念和污染相关概念；通过本体建模语言构建所述核心概念的概念节点；所述概念节点包括概念实体和概念属性；在所述概念节点中,确定所述概念节点之间的层次关系、语义关系和属性关系；以及构建所述场地土壤污染知识图谱的数据层,具体包括：基于所述场地土壤污染数据提取场地土壤污染实例的实体属性和实体关系,并识别实体类型；建立所述实体属性、所述实体关系和所述实体类型与所述核心概念之间的属性关系、语义关系和层次关系之间的映射,形成所述模式层到所述数据层的映射；其中,所述问答引擎模块具体包括：问题处理模块,用于对所述目标问题进行信息抽取,以提取关键信息,以及根据所述关键信息确定用户意图；具体用于通过文本分类技术对所述目标问题进行意图识别,以及从所述目标问题中识别命名实体,以及通过预先训练的有监督学习分类模型进行意图推理,确定所述用户意图；问题匹配模块,用于基于所述用户意图,通过预先训练的问题分类器确定所述目标问题所属的问题类别,以及根据所述问题类别生成问题模板；答案生成模块,用于根据所述问题模板和所述关键信息构建查询语句,以及根据所述查询语句从所述图数据库中查找与所述目标问题对应的目标实体、目标属性和目标关系,以及根据所述目标实体、所述目标属性和所述目标关系生成所述目标答案。</td>   <td>G06F16/332;G06F40/30;G06N3/0442;G06N3/08;G06F16/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>              张达庆       </td>   <td>中山大学</td>   <td>基于图文预训练模型的视频-文本检索方法及系统</td>   <td>广东省</td>   <td>CN117556083A</td>   <td>2024-02-13</td>   <td>本发明涉及数据检索领域,更具体地,涉及一种基于图文预训练模型的视频-文本检索方法及系统。本发明获取视频以及对应视频的描述文本；然后通过基于K-means的改进聚类算法提取出视频的关键帧,将关键帧和文本分别通过编码器得到视频的初步特征表示以及对应视频的描述文本的初步特征表示；然后进行微调,得到视频和对应视频的描述文本的进一步特征表示,再通过计算相似度的方式检索出匹配的视频文本对；最后输出匹配的视频文本对。本发明使用的基于K-means的改进聚类算法既保留了视频的完整信息,又去除了冗余的帧,因此本发明在视频-文本检索上的性能和效率上都能取得良好的表现。</td>   <td>1.基于图文预训练模型的视频-文本检索方法,其特征在于,包括以下步骤：S1:获取视频以及对应视频的描述文本；S2:通过基于K-means的改进聚类算法提取出视频的关键帧；S3:根据关键帧得到视频的初步特征表示；根据对应视频的描述文本得到对应视频的描述文本的初步特征表示；S4:将视频的特征表示进行微调,得到视频的进一步特征表示；将对应视频的描述文本的初步特征进行微调,得到对应视频的描述文本的进一步特征表示；S5:根据视频的进一步特征表示和对应视频的描述文本的进一步特征表示通过计算相似度的方式检索出匹配的视频文本对；S6：输出匹配的视频文本对。</td>   <td>G06F16/783;G06F16/75;G06F18/23213</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伍伟文;              王堰阳;                   李子荣       </td>   <td>中山大学</td>   <td>双域得分生成模型的稀疏视图断层扫描重建方法及系统</td>   <td>广东省</td>   <td>CN117557663A</td>   <td>2024-02-13</td>   <td>本发明公开了一种双域得分生成模型的稀疏视图断层扫描重建方法及系统,本发明实施例将正弦图域扩散模型与图像域扩散模型相结合,同时探索图像先验分布和正弦图先验分布进行稀疏视图断层扫描重建,进而通过图像域扩散模型生成的结果来方便构建精确的正弦图,反之,利用精确的正弦图来引导图像域结果的生成,促进了这两个域之间的协同作用。本发明实施例能够高效准确进行稀疏视图断层扫描重建,可广泛应用于图像处理技术领域。</td>   <td>1.一种双域得分生成模型的稀疏视图断层扫描重建方法,其特征在于,包括：获取高斯噪声图像和稀疏测量数据；以所述高斯噪声图像作为第一输入数据；将所述第一输入数据输入图像域模型进行第一重建处理,得到第一重建图像；基于所述第一重建图像,结合所述稀疏测量数据得到第二重建图像；对所述第二重建图像进行全视图拉东变换,得到第三重建图像；将所述第三重建图像、所述稀疏测量数据与第二输入数据相加的结果输入正弦图域模型进行第二重建处理,得到掩码；基于所述第二重建图像,结合所述掩码得到第四重建图像；以所述第四重建图像作为所述第一输入数据,以所述掩码作为所述第二输入数据,然后返回所述将所述第一输入数据输入图像域模型进行第一重建处理,得到第一重建图像这一步骤,直至达到预设迭代次数,以最后一次迭代的所述第四重建图像作为目标重建CT图像；其中,所述图像域模型基于扩散模型通过预设CT图像数据集训练生成的；所述正弦图域模型基于所述扩散模型通过预设正弦图数据集训练生成的；所述预设正弦图数据集通过对预设CT图像数据集进行拉东变换得到。</td>   <td>G06T11/00;A61B6/03;A61B6/00;A61B6/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周杰;                   农革       </td>   <td>中山大学</td>   <td>构造后缀数组的方法、终端设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN112765938B</td>   <td>2024-02-09</td>   <td>本申请适用于数据处理技术领域,提供了一种构造后缀数组的方法、终端设备及计算机可读存储介质,该构造后缀数组的方法包括：获取目标字符串的信息以及当前终端设备的信息；确定与目标字符串的信息以及当前终端设备的信息相匹配的目标后缀数组构造方式；获取目标后缀数组构造方式对应的样本集；从样本集中确定与目标字符串的信息以及当前终端设备的信息对应的性能最优的目标后缀数组构造算法；采用目标后缀数组构造算法构造目标字符串的后缀数组。本方案可以根据目标字符串的信息以及当前终端设备的信息自动选择出与其相匹配的性能最优的目标后缀数组构造算法来构造后缀数组,从而提高了后缀数组的构造效率。</td>   <td>1.一种构造后缀数组的方法,其特征在于,包括：获取目标字符串的信息以及当前终端设备的信息；确定与所述目标字符串的信息以及所述当前终端设备的信息相匹配的目标后缀数组构造方式；获取所述目标后缀数组构造方式对应的样本集；所述样本集中的每条样本数据均由一个样本字符串对应的样本后缀数组构造条件以及适用于所述样本后缀数组构造条件的性能最优的后缀数组构造算法组成,所述样本后缀数组构造条件包括所述样本字符串的信息以及构造所述样本字符串的后缀数组时所使用的样本终端设备的信息；从所述样本集中确定与所述目标字符串的信息以及所述当前终端设备的信息对应的性能最优的目标后缀数组构造算法；采用所述目标后缀数组构造算法构造所述目标字符串的后缀数组；所述目标字符串的信息包括所述目标字符串的字符串大小和重复度；相应地,所述获取目标字符串的信息,包括：获取所述目标字符串的字符串大小；对所述目标字符串依次进行字符串分割操作和字符串采样操作,得到所述目标字符串的多个采样字符串；采用预设的字符串相似度算法计算每两个所述采样字符串之间的第一相似度值,并基于所述第一相似度值确定所述目标字符串的重复度；所述当前终端设备的信息包括所述当前终端设备的内核数目和内存容量；相应地,所述确定与所述目标字符串的信息以及所述当前终端设备的信息相匹配的目标后缀数组构造方式,包括：若所述目标字符串的字符串大小大于所述当前终端设备的内存容量,则将外存后缀数组构造方式确定为所述目标后缀数组构造方式；若所述目标字符串的字符串大小小于或等于所述当前终端设备的内存容量,且所述当前终端设备的内核数目等于1,则将串行后缀数组构造方式确定为所述目标后缀数组构造方式；若所述目标字符串的字符串大小小于或等于所述当前终端设备的内存容量,且所述当前终端设备的内核数目大于1,则将并行后缀数组构造方式确定为所述目标后缀数组构造方式；所述从所述样本集中确定与所述目标字符串的信息以及所述当前终端设备的信息对应的性能最优的目标后缀数组构造算法,包括：将所述目标字符串的信息以及所述当前终端设备的信息作为所述目标字符串对应的目标后缀数组构造条件；从所述样本集中确定与所述目标后缀数组构造条件相匹配的样本后缀数组构造条件；基于与所述目标后缀数组构造条件相匹配的样本后缀数组构造条件所适用的性能最优的后缀数组构造算法,确定所述目标后缀数组构造算法。</td>   <td>G06F40/126</td>  </tr>        <tr>   <td>中国专利</td>   <td>         古博;              林敏;              陈柔柔;              牛宁杰;              李倩欣;                   聂苏程       </td>   <td>中山大学</td>   <td>一种基于视触觉进行加工元件表面凹陷的定位方法</td>   <td>广东省</td>   <td>CN115760805B</td>   <td>2024-02-09</td>   <td>本发明公开了一种基于视触觉进行加工元件表面凹陷的定位方法、装置、电子设备及存储介质,方法具体包括：获取加工元件表面所在的工作面的区域图像对比度,根据区域图像对比度选择视触觉定位法或者触觉定位法,通过触觉传感器获取加工元件表面的特征量后进行定位计算,确定加工元件表面的凹陷信息。本发明解决了在光照条件不佳而无法获得元件表面图像的情况下的凹陷定位问题,通过触觉传感器,还能有效区分微弱信号,获得更精确的定位,降低检测的故障率；本发明的实施例采用机器检测也可以减少人力资源的消耗,检测结果也不会受个人主观因素影响,可广泛应用于表面缺陷定位技术领域。</td>   <td>1.一种基于视触觉进行加工元件表面凹陷的定位方法,其特征在于,包括：获取加工元件表面所在的工作面的光照信息,根据所述光照信息确定所述加工元件表面的区域图像对比度；根据所述加工元件表面的区域图像对比度,选择视触觉定位法或触觉定位法；通过触觉传感器获取所述加工元件表面的特征量,对所述特征量进行定位计算,确定所述加工元件表面的凹陷信息；所述根据所述加工元件表面的区域图像对比度,选择视触觉定位法或触觉定位法,包括：当所述区域图像对比度大于或等于预设阈值,则确定所述凹陷定位方法为所述视触觉定位法；当所述区域图像对比度小于所述预设阈值,则确定所述凹陷定位方法为所述触觉定位法；当所述凹陷定位方法为所述视触觉定位法时,选择视触觉定位法,对所述特征量进行定位计算,确定所述加工元件表面的凹陷信息,包括：获取所述加工元件表面图像；对所述加工元件表面图像进行图像处理,获取所述加工元件的目标凹陷的图像信息；根据所述目标凹陷的图像信息通过机械臂手眼标定法得到所述目标凹陷相对于机械臂末端的坐标；根据所述坐标,通过所述机械臂的末端携带触觉传感器获取包含所述目标凹陷的矩形区域的特征量；根据所述特征量确定所述加工元件表面的目标凹陷的位置；当确定所述凹陷定位方法为所述触觉定位法时,选择触觉定位法,对所述特征量进行定位计算,确定所述加工元件表面的凹陷信息,包括：构建原点；确定候选路径算法,控制所述机械臂从所述原点出发,通过所述候选路径算法在所述加工元件表面进行遍历,通过所述触觉传感器确定所述目标凹陷的位置,其中所述候选路径算法由所述加工元件的类型确定；所述触觉定位法还包括以下步骤：根据所述加工元件表面的目标凹陷的位置,对所述目标凹陷的位置通过坐标变换获得所述目标凹陷的工作空间定位；所述工作空间用于表征所述机械臂的运行空间；所述方法还包括：获取所述触觉传感器的数据；根据所述触觉传感器的数据确定永磁体和三轴磁感应强度测量芯片间的距离；根据所述距离,确定所述加工元件的表面缺陷为凸起或孔洞。</td>   <td>G06T7/00;G06T7/136;G06T5/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁姗姗;                   张航       </td>   <td>中山大学</td>   <td>一种视线估计方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN113095274B</td>   <td>2024-02-09</td>   <td>本发明公开了一种视线估计方法、系统、装置及存储介质,该方法包括：获取人脸图像并进行关键点检测和3D模型拟合处理,得到人眼图像和3D头部旋转向量；对人眼图像和3D头部旋转向量进行数据正则化,得到正则化人眼图像和头部姿态估计向量；将正则化人眼图像和头部姿态估计向量输入到预训练的CNN网络,并将网络输出转换为3D视线方向向量。该系统包括：图像预处理模块、数据正则化模块和结果输出模块。该装置包括存储器以及用于执行上述视线估计方法的处理器。通过使用本发明,能够得到高精度的视线估计结果。本发明作为一种视线估计方法、系统、装置及存储介质,可广泛应用于视线估计领域。</td>   <td>1.一种视线估计方法,其特征在于,包括以下步骤：获取人脸图像并进行关键点检测和3D模型拟合处理,得到人眼图像和3D头部旋转向量；对人眼图像和3D头部旋转向量进行数据正则化,得到正则化人眼图像和头部姿态估计向量；将正则化人眼图像和头部姿态估计向量输入到预训练的CNN网络,并将网络输出转换为3D视线方向向量；所述获取人脸图像并进行关键点检测和3D模型拟合处理,得到人眼图像和3D头部旋转向量这一步骤,其具体包括：获取完整的人脸图像；基于dlib人脸检测和68个人脸关键点检测进行2D人脸对齐,得到图像对应的人脸关键点二维坐标；根据人脸关键点二维坐标中的眼部关键点位置,获取人眼图像；获取3D人脸关键点模型；基于EPnP算法将人脸关键点二维坐标和3D人脸关键点模型进行拟合,得到3D头部旋转向量；所述EPnP算法是将n个三维空间点表示为4个虚拟控制点的加权和；对人眼图像进行数据正则化之前,还包括对人眼图像进行眨眼检测并筛选这一步骤,具体包括：根据人眼图像中的左眼关键点信息和右眼关键点信息,得到穿过眼睛的一条水平线和一条垂直线；计算水平线与对应垂直线的比值；判断到比值大于预设阈值,确定该人眼图像为睁眼状态,将进行视线估计；判断到比值小于预设阈值,确定该人眼图像为闭眼状态,将不再进行视线估计。</td>   <td>G06V40/16;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈颖;                   董晨鹤       </td>   <td>中山大学</td>   <td>提高网络表示学习表示能力的方法、模型训练方法和系统</td>   <td>广东省</td>   <td>CN115564013B</td>   <td>2024-02-09</td>   <td>本发明提供的提高网络表示学习表示能力的方法、模型训练方法和系统,根据图网络得到各个子图的集合；将表示子图的邻接矩阵和特征矩阵输入到图卷积神经网络中,得到子图的网络表示学习的初始向量；根据子图中中心节点与每个非中心节点之间的关系,计算中心节点与每个非中心节点之间的注意力权重；根据初始向量和每个非中心节点之间的注意力权重,得到子图节点与关系组合后的具有权重的节点知识表示向量；采用注意力机制计算得到各个非中心节点之间关系的注意力权重；根据节点知识表示向量以及各个关系的注意力权重,得到子图的加权聚合向量。用加权聚合向量表示节点,使节点知识嵌入具有更丰富的语义信息,提升了异构网络的知识计算和推理能力。</td>   <td>1.一种问答模型的训练方法,其特征在于,包括：获取问答训练集,所述问答训练集包括多个问题答案对；将所述问题答案对的问题转化为对应的子图,将所述问题答案对的答案转化为对应的子图；所述子图包括：一个中心节点,至少一个非中心节点以及节点之间的关系；所述子图采用邻接矩阵和特征矩阵来表示；所述节点包括节点的标识以及节点的特征；对于每个子图,将表示子图的邻接矩阵和特征矩阵输入到图卷积神经网络中,得到子图的网络表示学习的初始向量；根据子图中中心节点与每个非中心节点之间的关系,计算中心节点与每个非中心节点之间的注意力权重；根据所述初始向量和每个非中心节点之间的注意力权重,得到子图节点与关系组合后的具有权重的节点知识表示向量；针对每个子图中的中心节点,采用注意力机制计算得到各个非中心节点之间关系的注意力权重；其中,所述采用注意力机制计算得到各个非中心节点之间关系的注意力权重包括：根据所述子图得到中心节点的各个邻域节点的关系对组,所述邻域节点的关系对组包括至少一个关系对；所述邻域节点的关系对组中,关系对的数量与该邻域节点的邻域节点数量有关；所述关系对包括中心节点与该邻域节点之间的关系e,以及该邻域节点与其他非中心节点之间的关系e’；计算各个关系对组中,各个关系对的关系e’与关系e之间的相似度；根据邻域节点的关系对组的各个关系对的相似度得到该邻域节点与其他非中心节点之间关系的注意力权重；根据各个邻域节点与其他非中心节点之间关系的注意力权重得到各个非中心节点之间关系的注意力权重；e′与e越相似,e′的注意力权重就越大,e′嵌入对节点的最终嵌入的贡献则更大；根据子图的节点知识表示向量,以及各个关系的注意力权重,得到子图的加权聚合向量；将问题子图的加权聚合向量以及对应的答案子图的加权聚合向量输入到问答模型中进行训练。</td>   <td>G06N3/0464;G06N3/08;G06N3/042</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;                   林伊妮       </td>   <td>中山大学</td>   <td>一种基于同态加密的隐私信息检索方法</td>   <td>广东省</td>   <td>CN117540406A</td>   <td>2024-02-09</td>   <td>本发明涉及信息安全技术领域,更具体地,涉及一种基于同态加密的隐私信息检索方法。包括：S1.服务器预处理；S2.客户端生成查询信息；S3.服务器在线响应查询；S4.客户端解密响应信息；S5.服务器更新数据库。本发明提供的一种基于同态加密的隐私信息检索方法,客户端的查询请求可以在亚线性的时间复杂度内得到响应,极大地缩短了以往的隐私信息检索的时间复杂度,有助于提高用户体验和数据检索的效率。此外,该技术还提供了强大的隐私保护,确保用户的个人信息和敏感数据得到充分保护。</td>   <td>1.一种基于同态加密的隐私信息检索方法,其特征在于,包括以下步骤：S1.服务器预处理；输入是一个安全参数λ和一个数据库DB,输出是一个“线索”h和一个公开的辅助信息aux；S2.客户端生成查询信息；输入是一个安全参数λ、一个要查询的索引i和一个公开的辅助信息aux,输出是查询信息qu和私钥s；S3.服务器在线响应查询；输入是数据库DB,查询信息qu,线索h,输出是响应信息a；S4.客户端解密响应信息；输入是私钥s和响应信息a,输出是要检索的数据项DB[i]；S5.服务器更新数据库；输入是数据库的第r行DB-r,输出是更新后的线索h-r。</td>   <td>G06F21/60;H04L9/00;G06F21/62;G06F16/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;              陈泽鑫;              段凯;              王海龙;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种模块化的新安江模型构建方法</td>   <td>广东省</td>   <td>CN117540560A</td>   <td>2024-02-09</td>   <td>本发明涉及水文模拟、水文预报与水文模拟精度评价领域,更具体的,涉及一种模块化的新安江模型构建方法,本发明使用气象数据驱动各组合模型,并用观测径流数据进行率定,分析SUPERFLEX框架下模块化新安江模型的模拟效果。该方法与已有的固定架构新安江模型构建方法不同,侧重于使用更为灵活的SUPERFLEX框架对新安江模型模块化,从而改造新安江模型,进一步地,对各模块进行组合,从而高效地构建适合目标流域的模型,实现水文模拟及预报,并且封装完成的类函数,调用方式简单,能够高效地对一个流域进行水文建模。</td>   <td>1.一种模块化的新安江模型构建方法,其特征在于,包含以下步骤：S1：构建新安江模型,根据新安江模型的原理由离散方程推导出连续方程；S2：根据推导后的连续方程基于SUPERFLEX框架对新安江模型进行模块化,构建模块化新安江模型；S3：对在SUPERFLEX框架下的新安江模型的各个模块进行自由组合,初始化自由组合后的新安江模型。</td>   <td>G06F30/20;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;              黄光玮;              蔡华阳;              刘智勇;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种长时序海平面数据的风暴增水分析方法与系统</td>   <td>广东省</td>   <td>CN117540561A</td>   <td>2024-02-09</td>   <td>本发明公开了一种长时序海平面数据的风暴增水分析方法与系统,包括以下步骤：S1、获取长时序海平面实测数据。S2、根据长时序海平面实测数据计算每年的海平面分量。S3、对去除海平面分量的长时序海平面实测数据进行潮汐调和分析得到风暴潮时序数据。S4、对风暴潮时序数据进行特征分析,得到风暴增水分析结果。本申请与传统技术相比,从沿海验潮站长时序海平面实测数据中分离和获取风暴潮,并进一步开展台风和非台风时期风暴增水分布、风暴增水与台风特征关系、历史前十风暴增水事件和年代际风暴增水变化趋势等分析。</td>   <td>1.一种长时序海平面数据的风暴增水分析方法,其特征在于,包括以下步骤：S1、获取长时序海平面实测数据；S2、根据长时序海平面实测数据计算每年的海平面分量；S3、对去除海平面分量的长时序海平面实测数据进行潮汐调和分析得到风暴潮时序数据；S4、对风暴潮时序数据进行特征分析,得到风暴增水分析结果。</td>   <td>G06F30/20;G06F111/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              郝偲成;              南雨宏;              刘小慧;                   姚沛源       </td>   <td>中山大学</td>   <td>文档缺陷检测方法</td>   <td>广东省</td>   <td>CN117540711A</td>   <td>2024-02-09</td>   <td>本申请公开了一种文档缺陷检测方法,该方法可以获取目标文档,所述目标文档中包含多个源代码结构及每个源代码结构对应的注释；从各个注释中提取所有约束描述,并确定每个源代码结构对应的约束描述；确定每个源代码结构对应的代码约束事实；基于此,本申请能够适应各类目标文档,提高了实用性及适用范围；对应同一源代码结构将代码相关的代码约束事实与注释相关的约束描述自然关联；随后,可以对同一源代码结构对应的约束描述及代码约束事实进行一致性校验,识别错误注释和/或错误代码；可见,本申请提供的文档缺陷检测方法可以在简化分析难度的同时,提高实用性及适用范围。</td>   <td>1.一种文档缺陷检测方法,其特征在于,包括：获取目标文档,所述目标文档中包含多个源代码结构及每个源代码结构对应的注释；从各个注释中提取所有约束描述,并确定每个源代码结构对应的约束描述；确定每个源代码结构对应的代码约束事实；对同一源代码结构对应的约束描述及代码约束事实进行一致性校验,识别错误注释和/或错误代码。</td>   <td>G06F40/169;G06F40/295;G06F40/289;G06F8/41</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青松;              刘彬媛;              林明鑫;              翁海松;              石珂;              赖涛;                   黄海风       </td>   <td>中山大学</td>   <td>一种基于图论的SAR图像拼接方法及装置</td>   <td>广东省</td>   <td>CN117541469A</td>   <td>2024-02-09</td>   <td>本申请属于SAR图像镶嵌技术领域,公开了一种基于图论的SAR图像拼接方法及装置,该方法包括：获取包括多个SAR图像的SAR图像集；根据预设连通准则检测各SAR图像,得到多个连通图像对；计算各连通图像对的权重影响因子；根据预计拼接结果确定参考图像；基于各权重影响因子得到各SAR图像到参考图像的匹配代价最小路径；基于各权重影响因子得到各SAR图像到参考图像的匀色代价最小路径；基于各SAR图像的匹配代价最小路径对其进行坐标校正；基于各SAR图像的匀色代价最小路径对其进行色彩校正；对各SAR图像进行拼接镶嵌,得到大区域SAR图像。本申请能够提高对图像集的适应性,并且不依赖于图像中的轨道信息。</td>   <td>1.一种基于图论的SAR图像拼接方法,其特征在于,包括：获取SAR图像集,所述SAR图像集包括多个SAR图像；根据预设连通准则检测各所述SAR图像,得到多个连通图像对；计算各所述连通图像对的权重影响因子；获取预计拼接结果,根据所述预计拼接结果确定参考图像；基于各所述权重影响因子得到各所述SAR图像到所述参考图像的匹配代价最小路径；基于各所述权重影响因子得到各所述SAR图像到所述参考图像的匀色代价最小路径；基于各所述SAR图像的所述匹配代价最小路径对其进行坐标校正；基于各所述SAR图像的所述匀色代价最小路径对其进行色彩校正；对校正后的各所述SAR图像进行拼接镶嵌,得到大区域SAR图像。</td>   <td>G06T3/4038;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚燕丹;              谢锐伟;              金亮;                   曾伟科       </td>   <td>中山大学孙逸仙纪念医院深汕中心医院</td>   <td>一种乳腺癌钙化区域增强突显方法和系统</td>   <td>广东省</td>   <td>CN117541524A</td>   <td>2024-02-09</td>   <td>本发明提供了一种乳腺癌钙化区域增强突显方法和系统,涉及医学图像处理领域,方法包括以下步骤：获取乳腺癌影像,读取乳腺癌影像中的体素点存放在二维矩阵中；初始化若干梯度算子,遍历乳腺癌影像,计算乳腺癌影像中每一个体素点与若干梯度算子的梯度变化情况；设定阈值和梯度变化情况中超过阈值的体素值的比例,超过该比例的体素值判断为钙化区域,否则为非钙化区域；将非钙化区域的体素值变为背景,将钙化区域和非钙化区域突显反转,保存成新的乳腺癌影像。通过对乳腺癌钙化区域的增强突显处理,保证了乳腺癌钙化区域在影像中提高亮度显示、且在轮廓中标记出来、而对于乳腺非钙化区域降低亮度显示,保证影像中的钙化区域独特显示、易于观察。</td>   <td>1.一种乳腺癌钙化区域增强突显方法,其特征在于,包括以下步骤：获取乳腺癌影像,利用python代码读取乳腺癌影像中的体素点存放在二维矩阵中；初始化若干梯度算子,遍历乳腺癌影像,计算乳腺癌影像中每一个体素点与若干梯度算子的梯度变化情况；设定阈值和梯度变化情况中超过阈值的体素值的比例,超过该比例的体素值判断为钙化区域,否则为非钙化区域；将非钙化区域的体素值变为背景,之后将钙化区域和非钙化区域突显反转,保存成新的乳腺癌影像。</td>   <td>G06T5/94;G06T7/11;G06T7/136;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青松;              余翠琳;              黄海风;              方佳骏;              赖涛;              钟梓炫;              张君豪;                   张子博       </td>   <td>中山大学</td>   <td>一种区域网平差模型的DEM校正方法、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117541752A</td>   <td>2024-02-09</td>   <td>本发明提供一种区域网平差模型的DEM校正方法、电子设备及存储介质,其中区域网平差模型的DEM校正方法,包括：把第一预设区域划分为至少一个网格；获取第一预设区域内的至少一个激光测高控制点；生成虚拟控制点；确定临时偏移量,并把合成影像平移临时偏移量得到平移合成影像；根据至少一个激光测高控制点和虚拟控制点中的至少一项和平移合成影像确定平移高程误差；确定平移高程误差最小时的临时偏移量为绝对偏移量,并平移合成影像绝对偏移量,得到平面绝对平差影像；高程平差该平面绝对平差影像,得到区域网平差影像。通过上述方法可以提高DEM影像的平差精度。</td>   <td>1.一种区域网平差模型的DEM校正方法,其特征在于,包括：把第一预设区域划分为至少一个网格；获取所述第一预设区域内的至少一个激光测高控制点；生成虚拟控制点；确定临时偏移量,并把合成影像平移所述临时偏移量得到平移合成影像；根据所述至少一个激光测高控制点和所述虚拟控制点中的至少一项和所述平移合成影像确定平移高程误差；确定平移高程误差最小时的所述临时偏移量为绝对偏移量,并平移所述合成影像所述绝对偏移量,得到平面绝对平差影像；高程平差所述平面绝对平差影像,得到区域网平差影像。</td>   <td>G06T17/20;G06N3/045;G06T19/20;G06V20/13;G01C25/00;G01C5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青松;              刘逸均;                   林明鑫       </td>   <td>中山大学</td>   <td>一种多模态图像匹配方法、系统、终端设备及存储介质</td>   <td>广东省</td>   <td>CN117541833A</td>   <td>2024-02-09</td>   <td>本发明公开了一种多模态图像匹配方法、系统、终端设备及存储介质,该方法包括：对光学图像和SAR图像进行自监督特征提取,得到光学图像和SAR图像之间的可重复特征点；根据可重复特征点将光学图像和SAR图像分割成第一图像块序列,并通过双分支网络对第一图像块序列进行特征提取,分别得到光学图像和SAR图像的特征描述向量；双分支网络包括用于提取全局特征的第一分支网络和用于提取局部特征的第二分支网络；根据特征描述向量对光学图像和SAR图像进行特征匹配,以得到光学图像和SAR图像之间的匹配点对。本发明采用两段式的训练方法首先训练得到稳健的SAR-光学图像特征描述向量,再结合特征描述向量学习到高匹配性能的特征点。</td>   <td>1.一种多模态图像匹配方法,其特征在于,包括：对光学图像和SAR图像进行自监督特征提取,得到所述光学图像和所述SAR图像之间的可重复特征点；根据所述可重复特征点将所述光学图像和所述SAR图像分割成第一图像块序列,并通过双分支网络对所述第一图像块序列进行特征提取,分别得到所述光学图像和所述SAR图像的特征描述向量；所述双分支网络包括用于提取全局特征的第一分支网络和用于提取局部特征的第二分支网络；根据所述特征描述向量对所述光学图像和所述SAR图像进行特征匹配,以得到所述光学图像和所述SAR图像之间的匹配点对。</td>   <td>G06V10/75;G06N3/0464;G06N3/0895;G06V10/26;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王可泽;              姜浩;              林倞;              李昊伟;              陈俊皓;              万文韬;                   薛磊       </td>   <td>中山大学</td>   <td>一种交互式语义感知自学框架及可解释视觉识别方法</td>   <td>广东省</td>   <td>CN117541855A</td>   <td>2024-02-09</td>   <td>本发明公开了一种交互式语义感知自学框架及可解释视觉识别方法,所述交互式语义感知自学框架包括教师模块和学生模块；所述学生模块用于视觉识别,所述教师模块用于对所述学生模块进行语义指导；所述学生模块将计算得出的分片-特征对输入到教师模块,教师模块将计算得出的富含语义的切片输出到学生模块；所述教师模块包括第一编码器、类别概念库和相似度比较子模块；所述学生模块包括分片库、第二编码器和特征选择子模块。本发明准确捕获不同粒度的特征,泛化性和准确性方面表现出色,增强抽象语义概念与具体图像区域对齐的可解释性,兼容不同结构网络。</td>   <td>1.一种交互式语义感知自学框架,其特征在于,所述交互式语义感知自学框架包括教师模块和学生模块；所述学生模块用于视觉识别,所述教师模块用于对所述学生模块进行语义指导；所述学生模块将计算得出的分片-特征对输入到教师模块,教师模块将计算得出的富含语义的切片输出到学生模块；所述教师模块包括第一编码器、类别概念库和相似度比较子模块；所述编码器用于提取图像的特征；所述类别概念库用于存储类别概念；所述相似度比较子模块用于生成富含语义的切片,即语义指导；所述学生模块包括分片库、第二编码器和特征选择子模块；所述分片库用于存储用于分类的图像分片；所述特征选择子模块用于对编码器生成的图像分片特征进行特征选择。</td>   <td>G06V10/764;G06V10/26;G06V10/40;G06V10/82;G06N3/0455;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭军;              黄晓楠;              肖海洋;                   毕宁       </td>   <td>中山大学</td>   <td>一种手写数学公式识别方法</td>   <td>广东省</td>   <td>CN117542064A</td>   <td>2024-02-09</td>   <td>本发明提出一种手写数学公式识别方法,涉及光学字符识别的技术领域,将采集的手写公式图像样本构建为图像数据集,然后构建包括编码模块、计数模块和解码模块的手写数学公式识别模型并利用图像数据集进行训练,通过双向解码机制和注意力精炼模块提升模型的聚焦能力和解码能力,并引入计数模块以多任务协同的方式进一步提升手写数学公式识别准确度,将待识别的手写公式图像输入训练好的手写数学公式识别模型,输出识别得到的手写公式的LaTeX序列,提高了手写数学公式的识别准确度。</td>   <td>1.一种手写数学公式识别方法,其特征在于,包括：S1.采集手写公式图像样本,组成图像数据集,将图像数据集划分为训练集、验证集和测试集；S2.构建手写数学公式识别模型,所述手写数学公式识别模型包括编码模块、计数模块和解码模块；利用训练集对手写数学公式识别模型进行训练,然后利用验证集对手写数学公式识别模型进行评估,利用测试集测试手写数学公式识别模型的有效性,得到训练好的手写数学公式识别模型；S3.将待识别的手写公式图像输入训练好的手写数学公式识别模型,输出识别得到的手写公式的LaTeX序列。</td>   <td>G06V30/244;G06V30/18;G06V30/19;G06N3/0455;G06N3/0464;G06N3/0895</td>  </tr>        <tr>   <td>中国专利</td>   <td>         叶炬航;              王亮;                   韩雨昊       </td>   <td>中山大学</td>   <td>一种人体步态智能感知方法</td>   <td>广东省</td>   <td>CN117542109A</td>   <td>2024-02-09</td>   <td>本申请涉及计算机视觉和智能感知技术领域,尤其涉及一种人体步态智能感知方法,其方法包括：获取待识别人体的标定特征向量；基于标定特征向量,引入特殊特征向量；根据标定特征向量和特殊特征向量,创建人体步态集,并构建诊断函数模型,其中,人体步态集至少包括正常步态、猫步、崴脚-瘸腿、跌倒和举手-摆手；获取待识别步态信息输入诊断函数模型中,得到判定结果；将判定结果以目标形式输出,得到人体步态识别结果。本申请具有识别精度更高,使得基于诊断函数的数学模型成为可以辅助用户理解的诊断工具,能够更好地适用于需给出进一步物理解释场合的人体步态智能感知的效果。</td>   <td>1.一种人体步态智能感知方法,其特征在于,包括以下步骤,获取待识别人体的标定特征向量；基于所述标定特征向量,引入特殊特征向量；根据所述标定特征向量和所述特殊特征向量,创建人体步态集,并构建诊断函数模型,其中,所述人体步态集至少包括正常步态、猫步、崴脚-瘸腿、跌倒和举手-摆手；获取待识别步态信息输入所述诊断函数模型中,得到判定结果；将所述判定结果以目标形式输出,得到人体步态识别结果。</td>   <td>G06V40/20;G06V10/40;G06V10/774;G06V10/82;A61B5/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱金汉;              王艺璇;                   陈立新       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>人体解剖结构勾画检测方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN117542489A</td>   <td>2024-02-09</td>   <td>本发明公开了一种人体解剖结构勾画检测方法,其特征在于,包括：获取待评估系统和参考系统对同一人体解剖结构医疗影像资料的勾画结果；获取若干预设的比较指标,根据每一比较指标,对待评估系统的勾画结果和参考系统的勾画结果进行比较,得到每一比较指标对应的比较结果；针对每一比较指标对应的比较结果,判断所述比较结果是否超过所述比较指标的置信范围,并统计超出置信范围的比较结果个数,判断所述比较结果个数是否超出预设值,若超出预设值,则所述待评估系统的勾画结果为异常；否则为正常。本发明实现了自动检测辅助,提升复核效率,并规避了人工复核时的人为错误。</td>   <td>1.一种人体解剖结构勾画检测方法,其特征在于,包括：获取待评估系统和参考系统对同一人体解剖结构医疗影像资料的勾画结果；获取若干预设的比较指标,根据每一比较指标,对待评估系统的勾画结果和参考系统的勾画结果进行比较,得到每一比较指标对应的比较结果；针对每一比较指标对应的比较结果,判断所述比较结果是否超过所述比较指标的置信范围,并统计超出置信范围的比较结果个数,判断所述比较结果个数是否超出预设值,若超出预设值,则所述待评估系统的勾画结果为异常；否则为正常。</td>   <td>G16H30/40;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>              马文娟       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>基于人工智能的危重症疑难病例的辅助诊断系统及方法</td>   <td>广东省</td>   <td>CN117542510A</td>   <td>2024-02-09</td>   <td>本发明公开了基于人工智能的危重症疑难病例的辅助诊断系统及方法,属于智能医疗诊断技术领域。本发明解决了现有临床危重症患者诊断困难的问题,通过调取数据库中对应的历史病症及类似数据,并与患者基础病、各项检验指标、检查结果、影像结果、病理结果图像数据及变化趋势进行比对分析,为临床疑难病例进行辅助诊断；通过获取患者整体图像数据及病理图像,提取图像中病灶区及异常数据,并分析病理原因；与数据库中对应数据进行比对分析,提升了临床疑难病例的诊断效果；采用临床数据结合人工智能的就诊方式,为临床患者提供更为准确的治疗方案,为患者节约宝贵的治疗时间,提升了临床疑难病例的诊断及治疗效果。</td>   <td>1.基于人工智能的临床检查疑难病例辅助诊断系统,其特征在于,包括：数据库,用于导入以往患者的历史病理图像,并存储以往患者的个人信息、历史病症以及诊断结果,包括现有各类数据库资料；身份识别单元,用于读取临床患者病历表的条形码,由此调取出临床患者的个人信息以及问诊记录信息；医患交互单元,用于为患者与医生建立交互方式,以及应对后续诊断信息的交互；资料获取单元,用于获取患者整体、面部、舌头的图像数据、患者脉搏信息以及扫描患者的病理图像；病症处理单元,基于数据获取单元所获得的患者资料分别与数据库中所对应的历史病症进行对比,并筛出对应度最高的历史病症,以作为临床疑难病例的参考样本,结合历史病症生成对应的诊断结果；诊断输出单元,基于外部的打印机将临床患者诊断过程中的检查项目清单、诊断结果以及西医药方进行打印。</td>   <td>G16H50/20;G16H10/20;G16H10/60;G16H50/70;G16H30/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张嫚宁;              谢晓华;                   龚文勇       </td>   <td>中山大学</td>   <td>一种基于计算机视觉的猴脸亲缘关系分析方法</td>   <td>广东省</td>   <td>CN110414299B</td>   <td>2024-02-06</td>   <td>本发明公开一种基于计算机视觉的猴脸亲缘关系分析方法,包括基于手工标记的猴脸图像,运用Faster R-CNN模型训练猴脸检测器；基于猴脸检测器获取猴脸坐标并保存猴脸图像,结合已有的猴子身份,种群信息,建立一个猴脸图像数据库；设计猴脸亲缘关系验证算法,通过对深度卷积神经网络的训练对猴脸分析目标特征进行猴脸亲缘关系分析。本发明方法应用卷积神经网络挖掘利用更多猴脸信息来达到更准确的亲缘关系分析,对测试样本和训练样本之间的相关性无要求,当猴脸姿势、尺度发生较大变化时,仍然能准确判断。</td>   <td>1.一种基于计算机视觉的猴脸亲缘关系分析方法,其特征在于,包括如下步骤：S10基于手工标记的猴脸图像,运用Faster R-CNN模型训练猴脸检测器；包括：S101在Faster R-CNN框架下,通过VGG16的13个可共享的卷积层网络来提取待分析猴脸图像的卷积特征图；S102使用猴脸图像深度学习模型的RPN在该卷积特征图上滑动扫描出数个滑动窗口,每个滑动窗口映射为一个低维特征输入至分类层和回归层,其中每个所述滑动窗口对应数个锚矩形框；S103将待分析猴脸图像分类为猴脸目标和背景,回归层输出每个锚矩形框对应的缩放参数,分类层输出每个锚矩形框所属猴脸目标或背景的概率,且将其中概率最高的锚矩形框确定为猴脸坐标；S20基于猴脸检测器获取猴脸坐标并保存猴脸图像,结合已有的猴子身份,种群信息,建立一个猴脸图像数据库；S30设计猴脸亲缘关系验证算法,通过对深度卷积神经网络的训练对猴脸分析目标特征进行猴脸亲缘关系分析；包括：S301通过深度卷积网络来对猴脸图像提取猴脸分析目标特征；S302构造一个具有三元组(a,p,n)属性的训练样本,其中三元组中包含一个锚点图像a和一个相对于a而言的亲子对图像作为正样本p,相对于a而言的非亲子对图像作为负样本n；S303设置三元组约束条件：若单个亲子对的图像(Anchor)和该亲子对的其他图像/&gt;(Positive)距离小于α,则认为它们相似度较高,若与其他非亲子对的图像/&gt;(Negative)距离大于α,则认为它们相似度不高,由上得到三元组约束条件式(1),                  其中,α是施加在正样本对和负样本对之间的距离(margin),Γ是训练集中的所有可能的三元组,x-i是VGG16网络的输出分数向量；S304将VGG16网络的输出分数向量进行l-2归一化处理；S305使用仿射投影将x-i投影到一个L＜＜D的低维空间中,得到最后投影后的结果为：W′∈R～(L×D),其中,W'即待求解的投影矩阵；S306通过最小化下式(2)三元损失函数来训练W',</td>   <td>G06V40/10;G06V10/764;G06V10/774;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢志;              何尧;              周昊;                   张昀       </td>   <td>中山大学中山眼科中心</td>   <td>一种适用多种视觉任务的领域自适应增强方法</td>   <td>广东省</td>   <td>CN115701868B</td>   <td>2024-02-06</td>   <td>本发明公开一种适用多种视觉任务的领域自适应增强方法,包括S01：针对基于深度学习算法的医学图像分析任务,从该任务中分析提取出该任务的业务模型；S02：根据业务模型,构建基于CycleGAN模型与辅助任务协同学习的域自适应框架,包括CycleGAN模块和辅助任务模块,其中,CycleGAN模块用于转换不同域的图像风格,所述辅助任务模块包括主辅助任务和次辅助任务；S03：使用未配对的目标域图像数据集和源域图像数据集训练所述基于CycleGAN模型与辅助任务协同学习的域自适应框架；S04：使用训练好的CycleGAN模型将目标域图像转换为源域图像风格,输入业务模型中,得到最终的结果。本发明改善由源域数据训练的业务模型对目标域图像的泛化性,不需要业务标签即可提高目标域图像上的业务性能。</td>   <td>1.一种适用多种视觉任务的领域自适应增强方法,其特征在于,包括以下步骤：S01：针对基于深度学习算法的医学图像分析任务,从医学图像分析任务中分析提取出医学图像分析任务的深度学习模型；S02：根据所述医学图像分析任务的深度学习模型,构建基于CycleGAN模型与辅助任务协同学习的域自适应框架,包括CycleGAN模块和辅助任务模块,其中,CycleGAN模块用于转换不同域的图像风格,所述辅助任务模块包括主辅助任务与次辅助任务；S03：使用未配对的目标域图像数据集和源域图像数据集训练所述基于CycleGAN模型与辅助任务协同学习的域自适应框架；S04：使用训练好的CycleGAN模型将目标域图像转换为源域图像风格,输入所述医学图像分析任务的深度学习模型中,得到最终的结果；所述主辅助任务的流程为：使用CycleGAN模型将源域图像转化为目标域图像风格,再转化为源域图像风格,最后输入至所述医学图像分析任务的深度学习模型中；将医学图像分析任务与主辅助任务结合,两个任务所使用的深度学习模型的特征对齐,将损失传递回CycleGAN模块；所述主辅助任务的深度学习模型和权重直接使用医学图像分析任务的深度学习模型及对应权重,且权重在训练过程中固定；所述次辅助任务包括自监督学习任务以及半监督学习任务。</td>   <td>G06T5/00;G06T3/04;G06V10/26;G06V10/764;G06V10/774;G06V10/82;G06N3/0464;G06N3/092</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王沛;                   任江涛       </td>   <td>中山大学</td>   <td>一种文本单类别分类方法、系统、计算机设备及存储介质</td>   <td>广东省</td>   <td>CN117520543A</td>   <td>2024-02-06</td>   <td>本发明提供了一种文本单类别分类方法、系统、计算机设备及存储介质,所述方法为对单分类文本集进行词性标注得到词性标注文本集,并将基于依此构建的多个词性自编码器获取的词性强语义词替换为预设无语义词得到弱语义困难样本集后,根据单分类文本集和弱语义困难样本集对预训练模型进行类别级监督对比学习训练得到领域特征提取器,并根据领域特征提取器构造领域特征原型和提取待识别文本的待识别领域特征,以及对待识别领域特征与领域特征原型进行相似度计算得到待识别文本领域评分,并结合预设评分阈值得到待识别文本分类结果。本发明能基于词性分析生成的弱语义困难负样本,极大提升对比学习训练效果,进而有效提高文本单类别的分类精度。</td>   <td>1.一种文本单类别分类方法,其特征在于,所述方法包括以下步骤：获取单分类文本集,并对所述单分类文本集进行词性标注,得到词性标注文本集；根据所述词性标注文本集,构建多个词性自编码器,并根据各个词性自编码器,获取所述单分类文本集的词性强语义词；将所述单分类文本集中的所有词性强语义词替换为等长的预设无语义词,得到对应的弱语义困难样本集；根据所述单分类文本集和所述弱语义困难样本集,对预设的预训练模型进行类别级监督对比学习训练,得到领域特征提取器,并根据所述领域特征提取器,构造所述单分类文本集对应的领域特征原型；将待识别文本输入所述领域特征提取器进行特征提取,得到对应的待识别领域特征,并对所述待识别领域特征与所述领域特征原型进行相似度计算,得到对应的待识别文本领域评分；根据所述待识别文本领域评分和预设评分阈值,得到对应的待识别文本分类结果。</td>   <td>G06F16/35;G06F40/30;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;              熊宇涵;              倪晓升;              蒋燕梅;              吕雅丽;                   秦小营       </td>   <td>中山大学</td>   <td>基于数字孪生的车队物流指挥决策建模方法、装置及设备</td>   <td>广东省</td>   <td>CN117522234A</td>   <td>2024-02-06</td>   <td>本申请涉及一种基于数字孪生的车队物流指挥决策建模方法、装置及设备,该方法包括获取车队物流所需的物流数据,物流数据包括实时采集物流数据、客户数据和历史物流数据；对物流数据进行数据处理与融合,得到一维向量数据；根据实时采集物流数据和历史物流数据构建数字孪生车队物流指挥决策模型；将一维向量数据输入数字孪生车队物流指挥决策模型中,输出配送目的地；根据配送目的地和实时采集物流数据的车辆目前所在位置共同输入数字孪生车队物流指挥决策模型中,输出车队物流指挥决策的配送路径规划。该方法生成车队物流指挥决策的配送路径规划,能够缓解信息孤岛效应,提高决策效率,实现可靠的决策推演论证。</td>   <td>1.一种基于数字孪生的车队物流指挥决策建模方法,其特征在于,包括以下步骤：获取车队物流所需的物流数据,所述物流数据包括实时采集物流数据、客户数据和历史物流数据；对所述物流数据进行数据处理与融合,得到一维向量数据；根据所述实时采集物流数据和所述历史物流数据构建数字孪生车队物流指挥决策模型；将所述一维向量数据输入所述数字孪生车队物流指挥决策模型中,输出配送目的地；根据所述配送目的地和所述实时采集物流数据的车辆目前所在位置共同输入所述数字孪生车队物流指挥决策模型中,输出车队物流指挥决策的配送路径规划。</td>   <td>G06Q10/067;G06Q10/0637;G06Q10/083;G06Q10/04;G06N3/006</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李泓舟;              郁思杰;                   谭光       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种解决视觉定位过程中回环闭合混淆问题的方法及装置</td>   <td>广东省</td>   <td>CN117522984A</td>   <td>2024-02-06</td>   <td>本发明公开了一种解决视觉定位过程中回环闭合混淆问题的方法及装置,方法包括：获取语义关键帧,根据所述语义关键帧,构建全局地图以及目标语义锚点；获取所述目标语义锚点的文字描述；根据所述全局地图以及所述目标语义锚点的文字描述,构建目标语义锚点地图；根据所述目标语义锚点地图,筛选第一候选关键帧；根据所述第一候选关键帧进行回环闭合。本发明使用文字描述作为依据,能更好地辨别相似的场景,通过构建局部语义锚点地图,比较语义锚点及其在局部语义锚点地图中的相对位置来区分重复场景,实现在重复环境中区分特定类型物体,可广泛应用于视觉定位技术领域。</td>   <td>1.一种解决视觉定位过程中回环闭合混淆问题的方法,其特征在于,包括：获取语义关键帧,根据所述语义关键帧,构建全局地图以及目标语义锚点；获取所述目标语义锚点的文字描述；根据所述全局地图以及所述目标语义锚点的文字描述,构建目标语义锚点地图；根据所述目标语义锚点地图,筛选第一候选关键帧；根据所述第一候选关键帧进行回环闭合。</td>   <td>G06T7/73;G06V10/44;G06V10/25;G06V10/75;G06V20/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张磊;              邓钧元;              丛玉来;                   孙一心       </td>   <td>中山大学</td>   <td>一种从ISAR图像中进行三维重建和新视图生成的方法</td>   <td>广东省</td>   <td>CN117523108A</td>   <td>2024-02-06</td>   <td>本发明公开了一种从ISAR图像中进行三维重建和新视图生成的方法,包括获取ISAR图像样本；将所述ISAR图像样本进行计算,得到解耦的后向散射系数和解耦的粒子密度；将所述解耦的后向散射系数和所述解耦的粒子密度进行计算,得到改良的ISAR成像渲染公式；建立隐式神经网络；使用所述改良的ISAR成像渲染公式对所述隐式神经网络进行训练,得到优化隐式神经网络。本发明能够提升ISAR三维重建的结果,并实现任意视角视图ISAR图像生成的功能。</td>   <td>1.一种从ISAR图像中进行三维重建和新视图生成的方法,其特征在于,所述从ISAR图像中进行三维重建和新视图生成的方法包括：获取ISAR图像样本；将所述ISAR图像样本进行计算,得到解耦的后向散射系数和解耦的粒子密度；将所述解耦的后向散射系数和所述解耦的粒子密度进行计算,得到改良的ISAR成像渲染公式；建立隐式神经网络；使用所述改良的ISAR成像渲染公式对所述隐式神经网络进行训练,得到优化隐式神经网络。</td>   <td>G06T17/00;G06T15/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         单云霄;                   张琪       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种基于多注意力机制的海面船舶目标跟踪方法及系统</td>   <td>广东省</td>   <td>CN117523230A</td>   <td>2024-02-06</td>   <td>本发明公开了一种基于多注意力机制的海面船舶目标跟踪方法及系统,该方法包括：将目标模板图像和当前帧图像分别进行特征提取；基于通道交叉注意力机制构建分类分支；基于空间交叉注意力机制构建定位分支；将目标模板特征和当前帧特征输入至分类分支；将目标模板特征和当前帧特征输入至定位分支；将分类特征和定位特征分别进行交互相关操作；将分类响应图和定位响应图经过多层卷积,得到目标在当前帧的位置与置信度。该系统包括：初步特征提取单元、分支构建单元、分支处理单元、互相关单元和预测单元。通过使用本发明,能够在复杂的海面环境下持续跟踪船舶目标。本发明可广泛应用于目标跟踪领域。</td>   <td>1.一种基于多注意力机制的海面船舶目标跟踪方法,其特征在于,包括以下步骤：将目标模板图像和当前帧图像分别进行特征提取,得到目标模板特征和当前帧特征；基于通道交叉注意力机制构建分类分支；基于空间交叉注意力机制构建定位分支；将所述目标模板特征和所述当前帧特征输入至所述分类分支,得到分类特征；将所述目标模板特征和所述当前帧特征输入至所述定位分支,得到定位特征；将所述分类特征和所述定位特征分别进行交互相关操作,得到分类响应图和定位响应图；将所述分类响应图和所述定位响应图经过多层卷积,得到目标在当前帧的位置与置信度。</td>   <td>G06V10/62;G06V10/44;G06V10/422;G06V10/54;G06V10/56;G06V10/52;G06V10/80;G06V10/25;G06V10/75;G06V10/74;G06V10/764;G06V10/766;G06V10/82;G06N3/0464;G06N3/045</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              汪瀚;              沈智华;              林彬;              覃军友;              杨夏;                   陈思洋       </td>   <td>中山大学</td>   <td>基于数据驱动的点状空间目标检测方法</td>   <td>广东省</td>   <td>CN117523254A</td>   <td>2024-02-06</td>   <td>本发明公开了基于数据驱动的点状空间目标检测方法,该方法包括：对待检测图像进行预处理,得到预处理后的图像；根据图像最小像素级半径对预处理后的图像进行搜索处理,得到候选区域；将候选区域作为数据驱动输入至SF-CNN分类模型进行引导分类,得到图像预测类别。通过使用本发明,能够通过对图像的各候选区域进行检测实现在减少全局标注的工作量的情况下提高图像的检测精度。本发明作为基于数据驱动的点状空间目标检测方法,可广泛应用于深度学习目标检测技术领域。</td>   <td>1.基于数据驱动的点状空间目标检测方法,其特征在于,包括以下步骤：对待检测图像进行预处理,得到预处理后的图像；根据图像最小像素级半径对预处理后的图像进行搜索处理,得到候选区域；将候选区域作为数据驱动输入至SF-CNN分类模型进行引导分类,得到图像预测类别。</td>   <td>G06V10/764;G06V10/30;G06V10/20;G06V10/82;G06V10/42;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高庆;                   张晔       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于无锚的实例级人体部位检测方法、装置和存储介质</td>   <td>广东省</td>   <td>CN117523282A</td>   <td>2024-02-06</td>   <td>本发明公开了一种基于无锚的实例级人体部位检测方法、计算机装置和存储介质,包括对待检测图片进行特征提取和融合获得多个特征层,对各特征层进行无锚的人体目标检测获得感兴趣区域,对感兴趣区域进行人体部位目标检测获得人体部位检测结果等步骤。本发明能够从待检测图片中检测到人体后,裁剪掉待检测图片中的无用的背景信息,然后在其基础上进一步关注人体部位,加大了人体部位与人体之间的从属性,也降低了无关背景对待检目标的影响；除此之外,本发明能够直接基于图像上的点生成候选框,不仅能够大大降低设计锚框的成本,也从像素级上解决了检测小目标的问题,例如对分辨率较小的物体的识别灵敏度更高。本发明广泛应用于图像处理技术领域。</td>   <td>1.一种基于无锚的实例级人体部位检测方法,其特征在于,基于无锚的实例级人体部位检测方法包括：获取待检测图片；对待检测图片进行特征提取和融合,获得多个特征层；各特征层分别用于检测相应尺度大小的目标；对各特征层进行无锚的人体目标检测,获得感兴趣区域；对感兴趣区域进行人体部位目标检测,获得人体部位检测结果。</td>   <td>G06V10/764;G06V10/40;G06V10/80;G06V10/25;G06V10/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高庆;                   张晔       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于骨架的多特征多流实时动作识别方法、装置和介质</td>   <td>广东省</td>   <td>CN117523659A</td>   <td>2024-02-06</td>   <td>本发明公开了一种基于骨架的多特征多流实时动作识别方法、计算机装置和存储介质,包括获取骨架数据的第一特征对、第二特征对和第三特征对,将第一特征对、第二特征对和第三特征对输入至多特征多流网络进行处理,根据多特征多流网络输出的处理结果识别动作类别等步骤。本发明通过获取骨架数据的具有动作直观性的第一特征对、具有尺度不变性的第二特征对和具有信息全局性的第三特征对,每个特征对都包含静态特征和动态特征,能够获得较充分和全面地表示骨架数据的关键特征；使用多特征多流网络同时对多个特征对进行处理,从而根据这些特征对所包含的充分和全面的特征信息进行推理,输出高精度的动作类别结果。本发明广泛应用于动作识别技术领域。</td>   <td>1.一种基于骨架的多特征多流实时动作识别方法,其特征在于,所述基于骨架的多特征多流实时动作识别方法包括：获取骨架数据的第一特征对、第二特征对和第三特征对；所述第一特征对、所述第二特征对和所述第三特征对分别包括一个静态特征和一个动态特征,所述第一特征对具有动作直观性,所述第二特征对具有尺度不变性,所述第三特征对具有信息全局性；获取多特征多流网络；将所述第一特征对、所述第二特征对和所述第三特征对输入至所述多特征多流网络进行处理；根据所述多特征多流网络输出的处理结果,识别动作类别。</td>   <td>G06V40/20;G06V10/40;G06V10/764;G06V10/80;G06N5/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高庆;                   张晔       </td>   <td>中山大学·深圳;中山大学</td>   <td>多特征融合的人体姿态估计方法、装置和存储介质</td>   <td>广东省</td>   <td>CN117523661A</td>   <td>2024-02-06</td>   <td>本发明公开了一种多特征融合的人体姿态估计方法、计算机装置和存储介质,包括获取预测子网络和估计子网络进行处理分别对人体姿势时间序列进行处理所输出的预测姿态特征与估计姿态特征,将预测姿态特征与估计姿态特征融合,获得人体姿态融合信息等步骤。本发明通过将预测姿态特征与估计姿态特征融合,获得人体姿态融合信息,一般情况下预测姿态特征能够达到良好的识别精度,在图像中的人体部位存在深度模糊或者被遮挡等情况下,通过估计姿态特征弥补精度下降的预测姿态特征,即估计姿态特征可以作为预测姿态特征的补充,避免因为遮挡问题导致特征提取不全的情况,实现多特征的优势互补,得到更准确的位姿信息。本发明广泛应用于图像处理技术领域。</td>   <td>1.一种多特征融合的人体姿态估计方法,其特征在于,所述多特征融合的人体姿态估计方法包括：获取人体姿势时间序列；将所述人体姿势时间序列分别输入至预测子网络和估计子网络进行处理；其中,所述预测子网络用于根据输入的所述二维人体姿势时间序列进行姿势预测,所述估计子网络用于对输入的所述二维人体姿势时间序列进行时间信息和空间信息提取；获取所述预测子网络输出的预测姿态特征；获取所述估计子网络输出的估计姿态特征；将所述预测姿态特征与所述估计姿态特征融合,获得人体姿态融合信息。</td>   <td>G06V40/20;G06V10/80;G06V10/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱柯;              林书盛;              杨彩妮;              张锐;              秦超;              宋之潇;                   朱太峰       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种肝细胞癌预后评估的标志物、模型及应用</td>   <td>广东省</td>   <td>CN117524468A</td>   <td>2024-02-06</td>   <td>本发明提供一种肝细胞癌预后评估的标志物,该标志物包括N-糖基化修饰相关基因,该N-糖基化修饰相关基因包括STT3A、DDOST和TMEM165。本发明所提供的分子标志物能够判断肝细胞癌(HCC)和评估其预后不良风险,因此能够筛选总体生存期较短、预后较不理想的肝细胞癌患者,将该分子标志物作为预后预测指标,可用于评估HCC患者的免疫状态和免疫治疗的效果,以提高治疗效果,实现肝细胞癌的个体化精准诊疗。</td>   <td>1.一种肝细胞癌预后评估的标志物,其特征在于,所述标志物包括N-糖基化修饰相关基因,所述N-糖基化修饰相关基因包括STT3A、DDOST和TMEM165。</td>   <td>G16H50/30;G06F18/23;G06F17/18;G16B40/00;G16B30/00;G16B25/00;G06F18/214;G01N33/574</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨坚新;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种提高内容一致性的长文本故事生成方法及系统</td>   <td>广东省</td>   <td>CN112395842B</td>   <td>2024-02-02</td>   <td>本发明公开了一种提高内容一致性的长文本故事生成方法及系统,该方法包括：获取数据集并对数据集进行预处理,得到训练集；基于训练集的故事标题、故事内容和故事情节序列对预构建故事生成模型进行训练,得到训练完成的故事生成模型；将待测标题输入到训练完成的故事生成模型,生成故事文本。该系统包括：数据获取模块、训练模块和生成模块。本发明可提高模型生成的故事的内容一致性。本发明作为一种提高内容一致性的长文本故事生成方法及系统,可广泛应用于故事生成领域。</td>   <td>1.一种提高内容一致性的长文本故事生成方法,其特征在于,包括以下步骤：获取数据集并对数据集进行预处理,得到训练集；基于训练集的故事标题、故事内容和故事情节序列对预构建故事生成模型进行训练,得到训练完成的故事生成模型；将待测标题输入到训练完成的故事生成模型,生成故事文本；所述故事生成模型包括故事情节自编码模块、故事规划模块和故事生成模块；所述基于训练集的故事标题、故事内容和故事情节序列对预构建故事生成模型进行训练,得到训练完成的故事生成模型这一步骤,其具体包括：基于训练集的故事内容训练故事情节自编码模块,得到训练完成的故事情节自编码模块；基于训练集中标题和对应故事内容得到对应故事情节序列,并训练故事规划模块,得到训练完成的故事规划模块；根据训练集中标题、对应故事内容和对应故事情节序列训练故事生成模块,得到训练完成的故事生成模块；根据训练完成的故事情节自编码模块、训练完成的故事规划模块和训练完成的故事生成模块,得到训练完成的故事生成模型；所述基于训练集的故事内容训练故事情节自编码模块,得到训练完成的故事情节自编码模块这一步骤,其具体还包括：对训练集中多个故事内容分别编码压缩,得到多个特征图；将多个特征图映射成向量情节序列,得到故事情节向量表；存储故事情节向量表,得到训练完成的故事情节自编码模块；所述将待测标题输入到训练完成的故事生成模型,生成故事文本这一步骤,其具体包括：基于故事情节自编码模块对待测标题进行编码,得到标题编码信息；将标题编码信息输入到训练完成的故事规划模块,映射得到故事情节序列；将故事情节序列输入到训练完成的故事生成模块,将故事情节向量序列解码得到故事文本；故事情节自编码模块,由多个卷积层堆叠而成,每个卷积层捕获输入文本不同粒度的语义信息。</td>   <td>G06F40/166;G06F18/214;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              苏航;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>基于语义的知识产权文本表示与分类方法及终端设备</td>   <td>广东省</td>   <td>CN117112734B</td>   <td>2024-02-02</td>   <td>本申请适用于深度学习技术领域,提供了一种基于语义的知识产权文本表示与分类方法及终端设备,包括：基于外观专利数据库构建第一训练集；在采用第一训练集对外观专利分类模型进行训练的过程中,针对各条训练数据,通过外观专利分类模型确定外观专利的专利名称对应的文本特征编码、专利草图对应的图像特征编码、专利名称和专利草图对应的融合特征编码及训练数据对应的预测分类概率分布,并基于目标损失函数及每条训练数据对应的文本特征编码、图像特征编码、融合特征编码以及预测分类概率分布,对外观专利分类模型的模型参数进行调整；通过训练好的外观专利分类模型对外观专利申请文本进行分类,提高了外观专利分类的效率和准确性。</td>   <td>1.一种基于语义的知识产权文本表示与分类方法,其特征在于,包括：基于外观专利数据库构建第一训练集；所述第一训练集中的每条训练数据包括一个外观专利的专利名称、目标附图以及专利分类号；在采用所述第一训练集对外观专利分类模型进行训练的过程中,针对各条所述训练数据,通过所述外观专利分类模型确定所述训练数据中外观专利的专利名称对应的文本特征编码、专利草图对应的图像特征编码、专利名称和专利草图对应的融合特征编码以及所述训练数据对应的预测分类概率分布,并基于目标损失函数以及每条训练数据对应的所述文本特征编码、所述图像特征编码、所述融合特征编码以及所述预测分类概率分布,对所述外观专利分类模型的模型参数进行调整；所述专利草图基于所述目标附图生成；所述预测分类概率分布指通过外观专利分类模型预测出的外观专利申请文本对应的外观专利属于各个外观专利类别的概率；通过训练好的外观专利分类模型对待分类的外观专利申请文本进行分类；所述目标损失函数包括第一损失函数、第二损失函数及第三损失函数；所述基于目标损失函数以及每条训练数据对应的所述文本特征编码、所述图像特征编码、所述融合特征编码以及所述预测分类概率分布,对所述外观专利分类模型的模型参数进行调整,包括：针对每条所述训练数据,从其他训练数据中确定所述训练数据的正关联数据和负关联数据；基于所述第一损失函数、所述训练数据对应的文本特征编码、所述训练数据的正关联数据对应的文本特征编码、所述训练数据的负关联数据对应的文本特征编码以及所述训练数据对应的预测分类概率分布,确定所述外观专利分类模型的第一损失值；基于所述第二损失函数、所述训练数据对应的图像特征编码、所述训练数据的正关联数据对应的图像特征编码、所述训练数据的负关联数据对应的图像特征编码以及所述训练数据对应的预测分类概率分布,确定所述外观专利分类模型的第二损失值；基于所述第三损失函数、所述训练数据对应的融合特征编码、所述训练数据的正关联数据对应的融合特征编码、所述训练数据的负关联数据对应的融合特征编码以及所述训练数据对应的预测分类概率分布,确定所述外观专利分类模型的第三损失值；基于所述第一损失值、所述第二损失值以及所述第三损失值对所述外观专利分类模型的模型参数进行调整；所述基于所述第三损失函数、所述训练数据对应的融合特征编码、所述训练数据的正关联数据对应的融合特征编码、所述训练数据的负关联数据对应的融合特征编码以及所述训练数据对应的预测分类概率分布,确定所述外观专利分类模型的第三损失值,包括：将每条所述训练数据对应的融合特征编码、每条所述训练数据的正关联数据对应的融合特征编码、每条所述训练数据的负关联数据对应的融合特征编码以及每条所述训练数据对应的预测分类概率分别代入所述第三损失函数中,得到所述外观专利分类模型的第三损失值；所述第三损失函数为：          ；其中,L-3为所述第三损失值,R-1为每条所述训练数据对应的融合特征编码、R-1～+为每条所述训练数据的正关联数据对应的融合特征编码,R-1～－为每条所述训练数据的负关联数据对应的融合特征编码,D-1(R-1,R-1～+)为每条所述训练数据对应的融合特征编码与每条所述训练数据的正关联数据对应的融合特征编码之间的第五距离值,D-1(R-1,R-1～－)为每条所述训练数据对应的融合特征编码与每条所述训练数据的负关联数据对应的融合特征编码之间的第六距离值,µ-3为第三控制系数,µ-3用于确保所述第六距离值大于所述第五距离值与µ-3之和,C为外观专利类别的总数量,y-i为每条所述训练数据中外观专利的专利分类号对应的独热编码,p-i为所述训练数据对应的预测分类概率分布中第i个元素的值。</td>   <td>G06F16/33;G06F16/35;G06F16/583;G06F16/532;G06F16/55;G06F18/25;G06F18/24;G06N3/0455;G06N3/0464;G06N3/08;G06F40/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;              王立华;                   尹雪梅       </td>   <td>中山大学</td>   <td>一种抗打印扫描拍摄的数字图像水印方法</td>   <td>广东省</td>   <td>CN112862656B</td>   <td>2024-02-02</td>   <td>本发明提出一种抗打印扫描拍摄的数字图像水印方法,解决了如何抵抗几何变换、打印扫描及拍摄对数字图像水印的不利影响,兼顾水印提取与水印图像主观质量的问题,数字图像水印嵌入过程基于原始图像的Zernike矩,通过量化嵌入的方法进行水印嵌入,根据水印嵌入前后的Zernike矩重构图像,对重构图像的差值采用选择性区域截断的方式,叠加到原始图像上生成水印图像,提升了水印图像的主观质量,基于Zernike矩变换,设计了一种匹配的数字图像水印提取算法,其中包含图像自动定位方法,提取水印过程可以抵抗旋转、缩放、噪声、压缩等带来的影响,从而保证了水印信息的有效提取。</td>   <td>1.一种抗打印扫描拍摄的数字图像水印方法,其特征在于,所述方法包括数字图像水印嵌入过程及数字图像水印提取过程,所述数字图像水印嵌入过程首先确定待嵌入水印的原始图像,基于原始图像的Zernike矩,通过量化嵌入的方法进行水印嵌入,根据水印嵌入前后的Zernike矩重构图像,对重构图像的差值采用选择性区域截断的方式,叠加到原始图像上生成水印图像；所述数字图像水印提取过程配合数字图像水印嵌入过程,将数字图像水印嵌入过程生成的水印图像经打印扫描/拍摄后作为待测图像,基于Zernike矩变换,进行水印提取；所述数字图像水印嵌入过程具体包括：S1.确定原始图像的种类,根据原始图像的种类选择水印嵌入通道；S2.确定原始图像Zernike矩的最大阶数N,计算单通道图像的n阶m重Zernike矩A-(nm)；S3.筛选Zernike矩,将筛选后的Zernike矩组成可嵌入水印的矩集合P,固定A-(nm),生成矩集合P中每个Zernike矩A-(nm)的重构图像；S4.计算重构图像的区域指标,根据指标大小确定待嵌入水印信息的Zernike矩位置；S5.对Zernike矩进行归一化,利用量化嵌入方法修改对应Zernike矩位置的Zernike矩幅值,嵌入水印,生成嵌入水印后的归一化Zernike矩幅值,并计算嵌入水印后的Zernike矩；S6.根据嵌入水印前后的Zernike矩重构图像,计算两幅重构图像的差值并进行选择性区域截断,将优化后的差值图像叠加到原始图像上生成水印图像；步骤S3所述筛选Zernike矩的过程包括：根据Zernike矩的共轭性和对称性,去除重复的矩；根据部分Zernike矩的正交性偏离问题,去除重复度为4的倍数的矩；筛选后的Zernike矩组成可嵌入水印的矩集合P表示为：P＝{A-(nm),n≤N,m≥0,m≠4i}；固定A-(nm),生成矩集合P中每个Zernike矩A-(nm)的重构图像表示为其中,                                                      x,y均表示图像的像素坐标；步骤S4所述区域指标为每个重构图像内切圆区域与圆环区域的像素指标,计算的具体过程包括：计算区域内像素值的均值平方与方差之和G-q：                  其中,q表示不同的分析区域,E-q表示区域内像素值的均值,表示区域内像素值的方差；计算矩集合P中所有Zernike矩在圆环区域的值的平均值/&gt;保留/&gt;的Zernike矩,构成集合P2；将集合P2中Zernike矩根据其在内切圆区域的/&gt;值从小到大排序,选取对应/&gt;最小的L个Zernike矩作为嵌入水印的位置,筛选后的L个Zernike矩组成Zernike矩向量/&gt;L表示待嵌入水印信息的比特长度；步骤S5中所述对Zernike矩进行归一化的过程为：利用Zernike零阶矩A-(00)对A-(pq)中的Zernike矩进行归一化,公式为：                  其中,T是归一化常数,取值为T＝10～κ,κ∈Ν～*；表示Zernike矩归一化后的值；利用量化嵌入方法修改对应Zernike矩位置的Zernike矩幅值的过程为：设待嵌入的水印信息序列表示为w＝{w-i,i＝1,…,36,w-i∈{0,1}},对于水印信息序列中的每个水印比特,利用量化嵌入方法修改对应Zernike矩位置的Zernike矩幅值,生成嵌入水印后的归一化Zernike矩幅值的公式为：                                    其中,S＝32,表示嵌入过程中的量化步长；表示生成嵌入水印后的归一化Zernike矩幅值；嵌入水印后的Zernike矩的表达式为：                  其中,表示Zernike矩向量中的第i个Zernike矩；步骤S6所述的根据嵌入水印前后的Zernike矩重构图像的过程为：利用嵌入水印后的Zernike矩重构得到图像/&gt;表达式为：                  利用嵌入水印前的Zernike矩重构得到图像I-(low),表达式为：                  对重构图像的差值采用选择性区域截断的方式,叠加到原始图像上生成水印图像的过程包括：计算嵌入水印前后重构图像的差值图像,表达式为：                  其中,I-(rw)表示差值图像；设差值图像I-(rw)圆环区域q-2的每个像素点表示为(x-i,y-i),若某一个像素点在原始图像中位于平滑区域,则对其在差值图像I-(rw)中的像素值v-i进行截断优化,优化公式为：                  其中,t表示截断阈值,表示截断优化后的像素值,优化后的图像记为/&gt;叠加到原始图像上生成水印图像表示为：                  其中,I表示原始图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              袁桂鑫;              王杰;              柏昊宇;              赵朕瑶;                   余超       </td>   <td>中山大学</td>   <td>基于径向差引导的圆形纹理目标定位方法</td>   <td>广东省</td>   <td>CN117495966A</td>   <td>2024-02-02</td>   <td>本发明公开了一种基于径向差引导的圆形纹理目标定位方法,包括：将模板匹配得到的圆形纹理目标图像作为初定位区域,计算其中心位置坐标；将修正区域分为四个象限区域,将初定位区域边缘灰度变化最平缓的象限区域作为搜索区域；在搜索区域中划定候选区域；遍历每一候选点,并计算候选点的数据特征径向差值；判断数据特征径向差值最大的候选点是否符合定位终止条件；若是,输出对应候选点作为圆形纹理目标的中心坐标；否则增加候选区域的范围。本发明应用于目标识别定位领域,以圆形纹理目标中心候选像素点的数据特征径向差值作为目标定位的主要依据,充分利用了圆形纹理目标的广泛性和复杂性,进而提升圆形纹理目标的定位精度。</td>   <td>1.一种基于径向差引导的圆形纹理目标定位方法,其特征在于,包括如下步骤：步骤1,将模板匹配得到的圆形纹理目标图像作为初定位区域,并计算原始图像中所述初定位区域的中心位置坐标；步骤2,基于所述初定位区域的中心位置坐标以及所述初定位区域的直径在所述原始图像中划定修正区域,其中,所述修正区域的中心、所述初定位区域的中心均与坐标系O-XY的原点重合；步骤3,将所述修正区域沿X轴、Y轴等分为四个象限区域,并将所述初定位区域边缘灰度变化最平缓的象限区域作为搜索区域；步骤4,在所述搜索区域中划定一矩形的候选区域,其中,所述候选区域的一角点与坐标系O-XY的原点重合,所述候选区域的两相邻边分别与X轴、Y轴重合；步骤5,定义所述候选区域中的像素点为候选点,遍历每一所述候选点,以各所述候选点为起点引出若干射线,并以所述射线在所述修正区域覆盖的像素点计算得到每一所述候选点的数据特征径向差值；步骤6,判断数据特征径向差值最大的候选点是否符合定位终止条件；若是,输出对应所述候选点作为圆形纹理目标的中心坐标；否则,增加所述候选区域的范围后再次进行步骤5至步骤6。</td>   <td>G06T7/73</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   朱春陶       </td>   <td>中山大学</td>   <td>基于小波变换和时序特征提取的深度伪造视频检测方法及装置</td>   <td>广东省</td>   <td>CN117496393A</td>   <td>2024-02-02</td>   <td>本发明公开了一种基于小波变换和时序特征提取的深度伪造视频检测方法及装置,包括：对视频进行预处理并进行数据增强操作,然后对经过处理的视频帧进行分组小波变换、拼接及通道调整操作；构建深度伪造视频检测模型,通过预设的时序特征提取模块进行帧间时序特征的提取操作；将提取到的帧间时序特征在预设的特征整合与结果判别模块中进行进一步的特征提取,并对伪造篡改视频进行判别以获取视频判别标签,然后计算损失训练模型；最后利用训练好的模型对待检视频进行判别。本发明设计了一个利用帧间时序关系检测深度人脸伪造视频的模型,能够提升人脸伪造视频检测的准确率,应对现有的检测技术在高压缩伪造视频中检测准确率不高、性能易受影响的问题。</td>   <td>1.基于小波变换和时序特征提取的深度伪造视频检测方法,其特征在于,包括下述步骤：对视频进行分帧和人脸区域提取预处理并对视频帧进行数据增强操作,然后对经过处理的视频帧进行分组；所述数据增强操作包括旋转、滤波模糊和高斯噪声处理；对分组的视频帧进行一级二维离散小波变换,得到每帧视频帧对应的低频子带部分和高频子带部分；将低频子带部分舍弃并将高频子带部分在通道维度上进行拼接和维度调整,得到视频帧的细节特征,即小波变换特征；构建深度伪造视频检测模型,首先将原视频帧的特征与视频帧的小波变换特征以成组的方式输入预设的时序特征提取模块,进行帧间时序特征的提取操作；然后将提取的帧间时序特征在预设的特征整合与结果判别模块中进行进一步的特征提取,并对伪造篡改视频进行判别以获取视频判别标签；利用视频真实标签与视频判别标签之间的交叉熵作为整个网络模型的损失函数,通过损失反向传播对模型进行训练,获取训练好的深度伪造视频检测模型；所述深度伪造视频检测模型包括时序特征提取模块和特征整合与结果判别模块；所述时序特征提取模块基于ViT模型构建,特征整合与结果判别模块基于3D深度可分离卷积进行构建；利用训练好的深度伪造视频检测模型对待检测的视频进行判别,并获取视频帧的判别结果。</td>   <td>G06V20/40;G06V40/16;G06V10/52;G06V10/44;G06V10/764;G06V10/82;G06N3/0455;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              沈颖       </td>   <td>中山大学</td>   <td>一种多任务学习的答案选择和问题分类的方法及系统</td>   <td>广东省</td>   <td>CN115438156B</td>   <td>2024-02-02</td>   <td>一种多任务学习的答案选择和问题分类的方法及系统,以及一种多任务学习的答案选择和问题分类的模型训练的方法及系统,依据上述实施例的多任务学习的答案选择和问题分类的方法及系统,以及多任务学习的答案选择和问题分类的模型训练的方法及系统,提出一个基本的多任务网络(例如答案选择任务和问题分类任务),以实现不同任务之间的相互交互；引入共享任务网络,关注和利用两个任务之间的语义和交互信息；引入共享标签嵌入网络,该网络通过问题分类任务中包含的有用信息,为未标记的答案句子提供伪标签,从而辅助答案选择进行预测,并提高两个任务的泛化性能。</td>   <td>1.一种多任务学习的答案选择和问题分类的方法,其特征在于,包括：获取输入信息；所述输入信息包括待分类的问题,或者问题及对应的一组候选答案；将所述输入信息输入到多任务学习的答案选择和问题分类的模型中；当所述输入信息为待分类的问题时,则所述多任务学习的答案选择和问题分类的模型输出问题的分类,当所述输入信息为问题及对应的一组候选答案,则多任务学习的答案选择和问题分类的模型输出从所述候选答案所选取的答案；其中,所述多任务学习的答案选择和问题分类的模型通过以下方式被训练：获取训练集；所述训练集至少包括问题,问题的标签,问题对应的一组候选答案；通过嵌入层将问题和候选答案分别转换为问题嵌入向量W-q和答案嵌入向量W-a；将所述问题嵌入向量W-q和答案嵌入向量W-a分别输入到双向长短期记忆网络中,以分别得到问题的初始上下文句子表示H-q和答案的初始上下文句子表示H-a；对于答案选择任务：通过问题嵌入向量W-q、答案嵌入向量W-a和共享注意力矩阵U-q,计算关联性矩阵F；对所述关联性矩阵F的行和列分别进行最大池化操作,以分别生成问题的基于上下文的注意力向量f-q和答案的基于上下文的注意力向量f-a；根据问题的初始上下文句子表示H-q和问题的基于上下文的注意力向量f-q计算问题的句子表示q-(out)；根据答案的初始上下文句子表示H-a和答案的基于上下文的注意力向量f-a计算答案的句子表示a-(out)；计算问题的句子表示q-(out)和答案的句子表示a-(out)之间的双线性相似性得分s(q-(out)；a-(out)),其中,M-s是要学习的相似度矩阵；至少根据问题的句子表示q-(out)、答案的句子表示a-(out)和双线性相似性得分s(q-(out)；a-(out))生成隐含层向量表示X；将隐含层向量表示X输入到隐藏层；对隐藏层的输出通过答案选择任务的softmax层进行二元分类；对于问题分类任务：将问题的初始上下文句子表示H-q作为注意力机制的输入,以得到权重W-c；根据权重W-c和问题的初始上下文句子表示H-q计算得到问题的句子表示Q；基于所述问题的句子表示Q,生成所述共享注意力矩阵U-q；将所述问题的句子表示Q,输入到完全连接层；对完全连接层的输出通过问题分类任务的softmax层进行二元分类；对于标签,获取标签嵌入向量L,并计算标签嵌入向量L和隐含层向量表示X之间的相似度S；将相似度S大于阈值的标签嵌入向量L输入到多层感知器中,得到伪标签,以更新所述训练集。</td>   <td>G06F16/332;G06F16/35;G06F18/2411</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张智伦;                   惠凤鸣       </td>   <td>中山大学</td>   <td>基于中法海洋卫星散射计的北极海冰分类方法</td>   <td>广东省</td>   <td>CN113095375B</td>   <td>2024-02-02</td>   <td>本发明提供的基于中法海洋卫星散射计的北极海冰分类方法,方法步骤包括：获取中法海洋卫星同极化的全球条带数据,根据全球条带数据生成散射计影像；散射计影像中包括第一冰区像元；获取亮温数据,通过阈值分割,从亮温数据中提取得到第二冰区像元；联合第一冰区像元和第二冰区像元得到海冰像元,根据海冰像元的后向散射系数以及亮温数据,将海冰像元进行分类；分类结果包括一年冰和多年冰；方法能够实现对源数据的自适应,提高了分类结果的精度及稳定,增强分类算法跨的普适性,可广泛应用于北极海冰遥感技术领域。</td>   <td>1.基于中法海洋卫星散射计的北极海冰分类方法,其特征在于,包括以下步骤：获取中法海洋卫星散射计同极化的全球条带数据,并获取所述全球条带数据的观测入射角,结合地标类型标签提取得到海冰像元数据；根据所述海冰像元数据的后向散射系数与入射角的变化关系,构建回归关系；将所述观测入射角归一化至目标角度,并根据所述回归关系将所述海冰像元数据矫正为目标角度下的海冰像元数据；根据矫正后的所述海冰像元数据,确定所述观测入射角下的观测结果；根据所述观测结果和高斯权重进行求和得到北极格网的格点值,构建得到所述北极格网；根据所述北极格网生成散射计影像；所述散射计影像中包括第一冰区像元；获取亮温数据,通过阈值分割,从所述亮温数据中提取得到第二冰区像元；联合所述第一冰区像元和所述第二冰区像元得到海冰像元,根据所述海冰像元的后向散射系数以及亮温数据,将所述海冰像元进行分类,所述分类的结果包括一年冰和多年冰。</td>   <td>G06V10/764;G06V10/26;G06V10/762</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              苏航;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>基于迁移学习的跨语种文本检索方法及终端设备</td>   <td>广东省</td>   <td>CN117076614B</td>   <td>2024-02-02</td>   <td>本申请适用于检索技术领域,提供了一种基于迁移学习的跨语种文本检索方法及终端设备,包括：基于预设语种专利数据库构建第一训练集；对跨语种专利检索模型进行训练时,通过跨语种专利检索模型确定每条样本数据对应的高维标签向量、第一高维文本向量及第二高维文本向量,计算每条样本数据对应的高维标签向量与第一高维文本向量之间的第一匹配度,每条样本数据对应的高维标签向量与第二高维文本向量之间的第二匹配度,基于预设损失函数、预设匹配条件及每条样本数据对应的第一匹配度和第二匹配度,对模型参数进行调整；通过训练好的跨语种专利检索模型输出通过目标语种描述的,与检索表达式相匹配的专利公开文本,提高了跨语种文本检索的匹配度。</td>   <td>1.一种基于迁移学习的跨语种文本检索方法,其特征在于,包括：基于预设语种专利数据库构建第一训练集；所述第一训练集包括多个训练数据组,每个训练数据组包括多条样本数据,每条样本数据均包括专利标签向量、正关联文本向量及负关联文本向量；同一个训练数据组中的各条样本数据的专利标签向量和正关联文本向量是对同一个专利的不同语种版本的专利公开文本对应的专利标签向量和专利文本向量进行排列组合得到的；每条样本数据中的负关联文本向量为不同训练数据组中其他样本数据中的正关联文本向量；所述专利标签向量是对相应的专利公开文本的扉页的所有文本信息进行预处理得到的第一文本向量；在采用所述第一训练集对跨语种专利检索模型进行训练的过程中,针对所述第一训练集中的每条样本数据,通过所述跨语种专利检索模型确定每条所述样本数据对应的高维标签向量、第一高维文本向量以及第二高维文本向量,并计算每条所述样本数据对应的高维标签向量与第一高维文本向量之间的第一匹配度,以及高维标签向量与第二高维文本向量之间的第二匹配度,且基于预设损失函数、预设匹配条件以及每条所述样本数据对应的第一匹配度和第二匹配度,对所述跨语种专利检索模型的模型参数进行调整；当接收到通过源语种描述的检索表达式时,通过训练好的跨语种专利检索模型输出通过目标语种描述的,与所述检索表达式相匹配的专利公开文本；所述跨语种专利检索模型包括标签向量编码模块、n个文本向量编码模块以及与n个文本向量编码模块一一对应的n个匹配度计算模块；n为预设语种的总数量；每个所述文本向量编码模块的输出端与对应的所述匹配度计算模块的第一输入端连接；所述标签向量编码模块的n个输出端分别与n个匹配度计算模块的第二输入端连接；n个文本向量编码模块分别对应n个不同的预设语种；所述基于预设损失函数、预设匹配条件以及每条所述样本数据对应的第一匹配度和第二匹配度,对所述跨语种专利检索模型的模型参数进行调整,包括：基于预设损失函数以及每条样本数据对应的第一匹配度和第二匹配度,计算所述跨语种专利检索模型的损失值；所述预设损失函数为：          ；其中,L为所述跨语种专利检索模型的损失值,n为预设语种的总数量,m为所述第一训练集中训练数据组的总数量,为每条样本数据对应的第一匹配度,/&gt;为每条样本数据对应的第二匹配度,µ为控制系数,µ用于确保每条样本数据对应的第二匹配度大于每条样本数据对应的第一匹配度与µ之和；在各条所述样本数据对应的第一匹配度满足预设匹配条件的情况下,将所述损失值最小时所述跨语种专利检索模型的各个模型参数的值,确定为所述模型参数的最终值,以完成对所述跨语种专利检索模型的训练；其中,所述预设匹配条件包括：每条所述样本数据对应的第一匹配度均大于或等于预设匹配度阈值,且每个训练数据组中的任意两条样本数据对应的第一匹配度之间的差值小于或等于预设微差量。</td>   <td>G06F16/33;G06F18/22;G06F18/214;G06F40/44;G06Q50/18;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              伍鸿俊;                   王晨曦       </td>   <td>中山大学</td>   <td>一种基于信息分治的图像增强方法、计算机装置和存储介质</td>   <td>广东省</td>   <td>CN117495748A</td>   <td>2024-02-02</td>   <td>本发明公开了一种基于信息分治的图像增强方法、计算机装置和存储介质,本发明包括将待处理图像分解成多个图像块,使用基于图像块灰度共生矩阵熵的图像块分类算法,分别对各图像块进行分类,获得类别标签,基于早退机制,分别根据各类别标签对各图像块进行增强,获得各图像块各自对应的增强特征信息,基于特征跳跃连接,对各增强特征信息进行聚合,获得增强结果图像等步骤。本发明使用信息分治策略,通过使用基于灰度共生矩阵熵的图像块分类算法,根据图像块信息量将其分为多类,并在早退机制的引导下,使用不同复杂度的网络结构对不同信息量的图像块进行对应增强,实现拥有良好的性能的同时保证了模型的低计算量。本发明应用于图像处理技术领域。</td>   <td>1.一种基于信息分治的图像增强方法,其特征在于,所述基于信息分治的图像增强方法包括：获取待处理图像；将所述待处理图像分解成多个图像块；使用基于图像块灰度共生矩阵熵的图像块分类算法,分别对各所述图像块进行分类,获得各所述图像块各自对应的类别标签；基于早退机制,分别根据各所述类别标签,对各所述图像块进行增强,获得各所述图像块各自对应的增强特征信息；基于特征跳跃连接,对各所述增强特征信息进行聚合,获得增强结果图像。</td>   <td>G06T5/90;G06T7/11;G06V10/764;G06V10/80;G06N3/0455;G06N3/098</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              柏昊宇;              王杰;              袁桂鑫;              李高敏;              张小虎;                   张锦绣       </td>   <td>中山大学</td>   <td>芯片粘接区域缺陷检测方法、系统及终端设备</td>   <td>广东省</td>   <td>CN117495830A</td>   <td>2024-02-02</td>   <td>本发明公开了一种芯片粘接区域缺陷检测方法、系统及终端设备,该方法包括：获取待检测的芯片X射线图像,并进行目标区域提取,得到目标图像；对目标图像进行图像滤波以及图像增强处理；基于分水岭算法对目标图像进行图像分割,其中,在分水岭算法进行图像分割的过程中,基于目标图像的对比度得到分水岭算法获取内部标记符时的阈值；基于图像分割结果对芯片粘接区域的合格性进行判定,并输出检测结果。本发明涉及元器件检测技术领域,通过将目标图像的对比度与分水岭算法获取内部标记符时的阈值关联,使得分水岭算法在进行图像分割的过程中更加具有针对下,提升图像分割的质量与准确性,从而提升芯片粘接区域缺陷的检测精度。</td>   <td>1.一种基于改进的分水岭算法的芯片粘接区域缺陷检测方法,其特征在于,包括如下步骤：步骤1,获取待检测的芯片X射线图像,并基于模板匹配对所述芯片X射线图像进行目标区域提取,得到目标图像；步骤2,对所述目标图像进行图像滤波以及图像增强处理；步骤3,基于分水岭算法对所述目标图像进行图像分割,其中,在所述分水岭算法进行图像分割的过程中,基于所述目标图像的对比度得到所述分水岭算法获取内部标记符时的阈值；步骤4,基于图像分割结果对芯片粘接区域的合格性进行判定,并输出检测结果。</td>   <td>G06T7/00;G06T7/73;G06T7/136;G06T7/187</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;              肖景博;                   殷琪林       </td>   <td>中山大学</td>   <td>基于时序差异的深度伪造视频检测方法及装置</td>   <td>广东省</td>   <td>CN117496392A</td>   <td>2024-02-02</td>   <td>本发明公开了一种基于时序差异的深度伪造视频检测方法及装置,包括：将数据集进行分帧并划分；对视频帧图像进行人脸区域捕获,获取高维特征空间中的帧级特征；将帧级特征输入细粒度差异捕获模块得到第一增强特征；将第一增强特征输入多尺度时空聚合模块得到第二增强特征；将所述细粒度差异捕获模块和多尺度时空聚合模块插入Xception主干网络构建伪造视频检测模型,用训练集训练并结合验证获取最优模型,并利用测试集预测结果。本发明设计了细粒度差异捕获模块和多尺度时空聚合模块,能够在不受面部运动的干扰的情况下定位深度伪造方法造成的视频帧间不一致,并对连续帧中的时空不一致进行建模,从而实现更高精度的深度伪造视频检测。</td>   <td>1.基于时序差异的深度伪造视频检测方法,其特征在于,包括下述步骤：将数据集进行分帧,得到视频帧图像并将其划分为训练集、验证集和测试集；所述数据集包括真实人脸视频和深度伪造人脸的视频；对视频帧图像进行人脸区域捕获,将视频帧图像中人脸区域投影到一个高维的特征空间,获取高维特征空间中的帧级特征；将高维特征空间中的帧级特征输入预先设立的细粒度差异捕获模块,从全局视角突出帧间不一致区域,得到含有帧间不一致信息的第一增强特征；所述细粒度差异捕获模块,通过计算视频片段中不同的视频帧图像之间对应位置的图像块的相似度,得到全局的不一致图；将第一增强特征输入预先设立的多尺度时空聚合模块利用跨帧的时间结构关联时域上的帧间不一致信息,得到了融合时空信息的第二增强特征；将所述细粒度差异捕获模块和多尺度时空聚合模块串行插入主干网络构建伪造视频检测模型,将训练集中的视频帧人脸区域图像数据进行下采样后输入伪造视频检测模型,以交叉熵损失作为损失函数训练伪造视频检测模型；在训练过程中,利用训练好的伪造视频检测模型结合验证集获取最优模型；将测试集输入最优模型,判定每个视频及每个视频帧是否被伪造,得到深度伪造视频检测结果。</td>   <td>G06V20/40;G06V40/16;G06V10/44;G06V10/764;G06V10/82;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>海外专利</td>   <td>         黄英哲;                   张云南       </td>   <td>国立中山大学</td>   <td>UNDERWATER CREATURE LENGTH ESTIMATION METHOD AND UNDERWATER CREATURE LENGTH ESTIMATION SYSTEM</td>   <td></td>   <td>TW202405747</td>   <td>2024-02-01</td>   <td>An underwater creature length estimation method and an underwater creature length estimation system are provided. The underwater creature length estimation system includes a memory and a processor. The processor is electrically connected to the memory to load instructions in the memory to perform the underwater creature length estimation method. The underwater creature length estimation method includes: receiving a underwater image, in which the underwater image is captured by an image capturing device and includes a creature pattern of a target creature; performing an identification step on the creature pattern to obtain creature lightness data corresponding to the target creature; calculating a creature distance between the target creature and the image capturing device. In some embodiments, the identification step further obtains creature structure data of the target creature, and thus a creature length of the target creature is calculated in accordance with the creature distance and the creature structure data.</td>   <td></td>   <td>G06T7/00;A01K61/59;G06T7/60;G06V30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈明远;                   游瑞       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>精准医疗临床决策术语支持系统</td>   <td>广东省</td>   <td>CN117476206A</td>   <td>2024-01-30</td>   <td>本申请公开了一种精准医疗临床决策术语支持系统,通过数据管理模块,可以收录多种尺度的医疗数据,包括临床病例数据、医学文献数据和药物数据；通过尺度变换模块可以对多尺度医疗数据进行处理,从而得到医疗文本数据,有助于降低医疗数据的复杂性并提取出更有用的特征,有效提高决策精度；通过自然语言处理模块利用自然语言处理算法,对医疗文本数据进行处理和理解,以建立癌种症状与诊断建议之间的语义关联特征数据；通过决策训练模块利用语义关联特征数据,对预设的决策推理模型进行训练,并通过决策推理模块利用训练好的目标决策推理模型,对目标癌症病例进行推理,生成相应的诊断建议数据,实现个性化和科学的临床决策支持。</td>   <td>1.一种精准医疗临床决策术语支持系统,其特征在于,包括：数据管理模块,用于收录多癌种的多尺度医疗数据,所述多尺度医疗数据包括多种尺度的临床病例数据、医学文献数据和药物数据；尺度变换模块,用于对所述多尺度医疗数据进行尺度变换,得到医疗文本数据；自然语言处理模块,用于利用自然语言处理算法,对所述医疗文本数据进行自然语言理解,以建立癌种症状与诊断建议之间的语义关联特征数据；决策训练模块,用于基于所述语义关联特征数据,对预设决策推理模型进行训练,以学习出用于生成针对多癌种诊断建议的目标决策推理模型；决策推理模块,用于利用所述目标决策推理模型,对目标癌症病例进行决策推理,生成所述目标癌症病例的诊断建议数据。</td>   <td>G16H50/20;G16H50/70;G06N5/04;G06F40/30;G06F18/22;G06V30/148;G06V30/19;G06F40/295;G06F16/31;G10L15/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张嵘;              杨秋霞;              麦芷君;              徐嘉慧;              周键尧;              谢传淼;                   王德玲       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于深度学习模型的肺转移瘤自动诊断系统</td>   <td>广东省</td>   <td>CN117476212A</td>   <td>2024-01-30</td>   <td>本发明公开了一种基于深度学习模型的肺转移瘤自动诊断系统,包括：图像获取模块,用于获取一患者对应的待诊断胸部CT图像；概率值生成模块,用于将所述待诊断胸部CT图像输入预设的肺转移瘤诊断模型中,以使所述肺转移瘤诊断模型对所述待诊断胸部CT图像中对应的结节区域进行标注以及分类,并生成每一结节区域为转移瘤的概率值；诊断结果生成模块,用于根据每一结节区域的转移瘤的概率值,生成所述患者的肺转移瘤诊断结果。与现有技术相比,本发明可以通过预先训练好的模型对待诊断胸部CT图像进行自动识别肺结节和生成对应的诊断结果,从而提高了肺转移瘤的诊断效率,且也进一步提高了肺转移瘤的诊断准确性。</td>   <td>1.一种基于深度学习模型的肺转移瘤自动诊断系统,其特征在于,包括：图像获取模块、概率值生成模块以及诊断结果生成模块；所述图像获取模块,用于获取一患者对应的待诊断胸部CT图像；所述概率值生成模块,用于将所述待诊断胸部CT图像输入预设的肺转移瘤诊断模型中,以使所述肺转移瘤诊断模型对所述待诊断胸部CT图像中对应的结节区域进行标注以及分类,并生成每一结节区域为转移瘤的概率值；所述诊断结果生成模块,用于根据每一结节区域的转移瘤的概率值,生成所述患者的肺转移瘤诊断结果；其中,所述肺转移瘤诊断模型包括肺组织分割子模型、肺结节检测子模型以及肺结节分类子模型；所述肺组织分割子模型,用于对所述待诊断胸部CT图像中肺组织的图像特征进行识别,并根据识别到的图像特征将肺组织区域从所述待诊断胸部CT图像中分割出来,生成待检测肺组织区域；所述肺结节检测子模型,用于将所述待检测肺组织区域中的细尺度特征与粗尺度特征结合起来,对所述待检测肺组织区中存在结节的结节区域进行识别和标注；所述肺结节分类子模型,用于对每一已标注的结节区域,根据已标注的结节区域的图像特征对各结节区域进行分类,生成对应的转移瘤的概率值。</td>   <td>G16H50/20;G16H30/00;G06T7/00;G06V10/764;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伍俊妍;              陈文戈;              余银儿;              叶穗雯;              吕晓枝;              王扶桑;              谭志明;              陈冠全;              许杰峰;                   张潜锋       </td>   <td>中山大学孙逸仙纪念医院;广州市品毅信息科技有限公司</td>   <td>基于机器学习的药物性肝损伤风险预测方法、系统</td>   <td>广东省</td>   <td>CN117476231A</td>   <td>2024-01-30</td>   <td>本发明公开了一种基于机器学习的药物性肝损伤风险预测方法、系统,该DILI风险预测方法包括以下步骤：S1：获取真实世界的诊疗数据作为数据集；S2：对数据集进行特征筛选,以提取出能够表达药物性肝损伤风险的重要特征；S3：利用重要特征构建药物性肝损伤风险预测模型；S4：利用药物性肝损伤风险预测模型进行风险预测。本发明能够提升DILI的风险预测准确性、可靠性；降低DILI风险预测模型的复杂度,提高预测精度；通过利用药物性肝损伤风险预测模型进行风险预测,可以预测患者是否面临药物性肝损伤的风险,有助于在患者受到进一步损害之前采取必要的预防措施和治疗措施,减少药物性肝损伤的发生率,从而保护患者的健康并降低医疗成本。</td>   <td>1.一种基于机器学习的药物性肝损伤风险预测方法,其特征在于,包括以下步骤：S1：获取真实世界的诊疗数据作为数据集；S2：对所述数据集进行特征筛选,以提取出能够表达药物性肝损伤风险的重要特征；S3：利用所述重要特征构建药物性肝损伤风险预测模型；S4：利用所述药物性肝损伤风险预测模型进行风险预测。</td>   <td>G16H50/30;G16H20/10;G06F18/2113;G06F18/2115;G06F18/243;G06F18/27;G06F18/214;G06N20/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蒋格格;              周檬;              刘轶君;              庞爱彤;              张欣;                   范庆雯       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种公交鲁棒性评价方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117474208A</td>   <td>2024-01-30</td>   <td>本发明公开了一种公交鲁棒性评价方法、装置、电子设备及存储介质,本发明实施例通过从宏观网络层面评估动态客流影响下的公交网络的鲁棒性,并准确地分析公交网络中的区间对整体公交网络鲁棒性所带来的影响。通过考量宏观网络,城市的公交运营者可以更加全面地了解动态公交网络的鲁棒性并进行针对性的改进,以提高公交系统的整体效率和服务质量。本发明实施例能够高效准确进行公交鲁棒性评价,可广泛应用于数据处理技术领域。</td>   <td>1.一种公交鲁棒性评价方法,其特征在于,包括：基于目标区域的公交站点构建拓扑网络；获取所述目标区域的公交历史数据,基于所述公交历史数据得到所述拓扑网络的各条连边的满载率；以所述拓扑网络作为第一网络；基于所述满载率,通过渗流理论得到所述第一网络的临界渗流阈值；基于所述第一网络中所有所述连边的所述满载率,确定最大满载率；基于所述满载率,结合所述临界渗流阈值和所述最大满载率得到所述第一网络的公交出行总阻抗；对所述第一网络的目标连边进行模拟网络攻击,得到第二网络；以所述第二网络作为所述第一网络,然后返回所述基于所述满载率,通过渗流理论得到所述第一网络的临界渗流阈值这一步骤,直至所述拓扑网络的所有连边均进行过所述模拟网络攻击；根据各轮次得到的所述公交出行总阻抗,获得关键区间集合。</td>   <td>G06Q10/063;G06Q50/26;G06Q50/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              李欣;                   周凡       </td>   <td>中山大学;中山大学深圳研究院</td>   <td>一种基于方向感知频域滤波的图像去雨方法与系统</td>   <td>广东省</td>   <td>CN117474802A</td>   <td>2024-01-30</td>   <td>本发明公开了一种基于方向感知频域滤波的图像去雨方法与系统。对雨图和无雨图进行数据增广预处理；利用方向感知的频域滤波器结合Resnet50网络共同对增广数据里面的雨图进行频域融合特征图的提取；把频域融合特征图输入到基于神经压缩的特征优化器中,得到噪声鲁棒的融合特征图；对噪声鲁棒的融合特征图进行上采样,所得到的最终特征图作为生成的去雨图像；构建损失函数训练并形成去雨模型；用户输入待处理的有雨图到去雨模型中得到生成的去雨图。本发明结合了雨水在图像中的分布特点,对图像的不同频率部分进行了区分处理,可以在有效去除雨水干扰的同时保留图像结构和细节信息。引入基于神经压缩的特征优化模块,避免了特征中可能存在的噪声的干扰。</td>   <td>1.一种基于方向感知频域滤波的图像去雨方法,其特征在于,所述方法包括：对合成雨水数据集中的每对雨图和对应无雨图进行数据增广预处理,得到增广数据集；利用方向感知的频域滤波器结合Resnet50网络共同对所述增广数据集里面的雨图进行频域融合特征图的提取；把所述频域融合特征图输入到基于神经压缩的特征优化器中,得到噪声鲁棒的融合特征图；对所述噪声鲁棒的融合特征图进行上采样,直至该噪声鲁棒的融合特征图逐步还原到原始图像大小,所得到的最终特征图作为生成的去雨图像；构建损失函数计算所述生成的去雨图像与所述增广数据集里面对应的无雨图之间的差异,将差异作为全局损失训练并形成去雨模型；用户输入待处理的有雨图到所述去雨模型中,得到生成的去雨图。</td>   <td>G06T5/73;G06T5/70;G06V10/80;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吕小州;              王伟;              胡航通;              陈立达;              柯伟平;              程美清;                   黄惠       </td>   <td>中山大学附属第一医院</td>   <td>基于全局纹理分析与局部包膜特征的自动化肝纤维化评估系统及方法</td>   <td>广东省</td>   <td>CN117474884A</td>   <td>2024-01-30</td>   <td>本发明公开了一种基于全局纹理分析与局部包膜特征的自动化肝纤维化评估系统及方法,包括图像获取模块获取患者肝脏的图像数据；数据预处理模块对图像数据进行预处理,包括去噪、增强、几何校正操作,以提高图像质量和减少干扰；全局纹理分析模块提取肝脏图像的全局纹理特征；局部包膜特征提取模块通过分析肝脏图像中各个区域的包膜特征来获取局部信息；特征融合模块将全局纹理特征和局部包膜特征进行融合；纤维化程度评估模块使用训练好的模型或算法,基于融合特征对肝脏图像进行纤维化程度的评估和分类。本发明能够大大提高肝纤维化诊断方面的准确性和综合性能。</td>   <td>1.一种基于全局纹理分析与局部包膜特征的自动化肝纤维化评估系统,其特征在于,包括图像获取模块、数据预处理模块、全局纹理分析模块、局部包膜特征提取模块、特征融合模块和纤维化程度评估模块；其中,所述图像获取模块,用于获取患者肝脏的图像数据；所述数据预处理模块,对图像数据进行预处理,包括去噪、增强、几何校正操作,以提高图像质量和减少干扰；所述全局纹理分析模块,用于提取肝脏图像的全局纹理特征；所述局部包膜特征提取模块,用于通过分析肝脏图像中各个区域的包膜特征来获取局部信息；所述特征融合模块,将全局纹理特征和局部包膜特征进行融合,以综合利用两种类型的信息；所述纤维化程度评估模块,使用训练好的模型或算法,基于融合特征对肝脏图像进行纤维化程度的评估和分类。</td>   <td>G06T7/00;G06V10/80;G06V10/54;G06V10/774;G06V10/764;G06V10/44;G06V10/20;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丛玉来;              张炜乐;                   何远见       </td>   <td>中山大学</td>   <td>一种集成动态任务子空间的图像分类方法、系统和介质</td>   <td>广东省</td>   <td>CN117475237A</td>   <td>2024-01-30</td>   <td>本发明公开了一种集成动态任务子空间的图像分类方法、系统和介质,方法包括：获取待分类图像；将待分类图像输入图像动态任务子空间模型,得到图像分类结果；其中,模型通过以下步骤得到：构建图像浅层特征提取器；构建图像深层特征提取器；构建图像任务子空间特征提取器；获取训练图像；根据训练图像和图像旧任务特征提取器,得到第一超级特征；根据训练图像和图像任务子空间特征提取器,得到第二超级特征；利用交叉熵计算分类损失；计算知识蒸馏损失；计算总损失；根据总损失对图像任务子空间特征提取器的参数进行更新,得到图像动态任务子空间模型。本发明提高了分类准确率,降低了参数存储成本。本发明可广泛应用于图像识别技术领域。</td>   <td>1.一种集成动态任务子空间的图像分类方法,其特征在于,包括以下步骤：获取待分类图像；将所述待分类图像输入图像动态任务子空间模型,得到图像分类结果；其中,所述图像动态任务子空间模型通过以下步骤得到：根据共享系数和子空间,构建图像浅层特征提取器；根据若干个深层卷积层,构建图像深层特征提取器；根据所述图像浅层特征提取器和所述图像深层特征提取器,构建图像任务子空间特征提取器；获取训练图像；根据所述训练图像和图像旧任务特征提取器,得到第一超级特征,所述图像旧任务特征提取器与所述图像任务子空间特征提取器的构建过程相同；根据所述训练图像和所述图像任务子空间特征提取器,得到第二超级特征；根据图像旧任务分类层和所述第二超级特征,利用交叉熵计算分类损失；根据所述第一超级特征和所述图像旧任务分类层,计算知识蒸馏损失；根据所述分类损失、所述知识蒸馏损失和图像判别分类层,计算总损失；根据所述总损失对所述图像任务子空间特征提取器的参数进行更新,直到所述总损失满足预设损失要求,则得到所述图像动态任务子空间模型。</td>   <td>G06V10/764;G06V10/77;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              李辉忠;              叶铭熙;              南雨宏;              白兴强;              李成博;              蔚菡萏;              张开翔;                   范瑞彬       </td>   <td>深圳前海微众银行股份有限公司;中山大学</td>   <td>一种智能合约漏洞检测方法、装置、介质和设备</td>   <td>广东省</td>   <td>CN117454384A</td>   <td>2024-01-26</td>   <td>本申请涉及计算机技术领域,尤其涉及一种智能合约漏洞检测方法、装置、介质和设备。其中方法包括：通过相似性比较获取到和待测函数相似的第一函数,并且,在相似性比较过程中,是在抽象语法树和控制流图的维度,比较了结构信息和语义信息,进而提高了函数相似性比较的准确度。而且不是在智能合约的维度上去匹配相似智能合约,而是函数的维度上去匹配相似函数,进而通过函数反映智能合约逻辑的漏洞,从而实现了智能合约漏洞的检测。此外,使用覆盖率满足测试要求的测试用例对待测函数进行测试,保证对函数测试的完整性,之后分析第一处理结果和第二处理结果,可以更准确的反映待测函数和第一函数的不同,从而保证智能合约漏洞检测的效率。</td>   <td>1.一种智能合约漏洞检测方法,其特征在于,应用于待测智能合约,所述待测智能合约中包括多个待测函数,所述方法包括：分别以智能合约中的函数对应的抽象语法树和智能合约中的函数对应的控制流图作为比较维度,对待测智能合约中的任一待测函数与多个参照智能合约中的参照函数进行相似性比较,从而确定出与所述待测函数相似的第一函数；任一参照智能合约为已在区块链上正常运行的智能合约；将各测试用例分别输入所述待测函数和所述第一函数,并获取所述待测函数的第一处理结果和所述第一函数的第二处理结果；所述各测试用例在被所述待测函数处理时,满足所述待测函数的测试覆盖要求；根据所述第一处理结果和所述第二处理结果确定所述待测函数是否存在漏洞；若所述待测函数存在漏洞,则确定所述待测合约存在漏洞。</td>   <td>G06F21/57;G06F11/36;G06F18/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              李辉忠;              叶铭熙;              南雨宏;              白兴强;              李成博;              蔚菡萏;              张开翔;                   范瑞彬       </td>   <td>深圳前海微众银行股份有限公司;中山大学</td>   <td>一种智能合约自动部署方法、装置、介质和设备</td>   <td>广东省</td>   <td>CN117454441A</td>   <td>2024-01-26</td>   <td>本申请涉及区块链技术领域,尤其涉及一种智能合约自动部署方法、装置、介质和设备。其中方法包括：确定第一智能合约中的多个调用函数,任一调用函数包括地址变量和签名变量；针对多个调用函数中的任一第一调用函数,确定出与第一调用函数匹配的第二智能合约,并构建第一智能合约与第二智能合约之间的调用关系；根据多个智能合约之间的调用关系,确定智能合约调用有向图；按照智能合约调用有向图,依序将多个智能合约部署在区块链上。通过上述方式,可以分析出与第一智能合约匹配的第二智能合约,进而可以确定智能合约调用有向图,按照这个智能合约调用有向图即可以自动的将多个智能合约部署在区块链上,提高了智能合约部署的效率。</td>   <td>1.一种智能合约自动部署方法,其特征在于,所述方法包括：确定第一智能合约中的多个调用函数,任一调用函数包括指示被调用合约的地址变量和指示被调用函数的签名变量；所述第一智能合约为待部署的多个智能合约中的任一个；针对所述多个调用函数中的任一第一调用函数,确定出与所述第一调用函数匹配的第二智能合约,并构建所述第一智能合约与所述第二智能合约之间的调用关系；所述第二智能合约为所述多个智能合约中除所述第一智能合约外的任一个,所述第二智能合约中具有第二调用函数的签名变量指示的被调用函数,且不具有第三调用函数的签名变量指示的被调用函数；所述第二调用函数为所述第一智能合约中与所述第一调用函数指示同一地址变量的调用函数；所述第三调用函数为所述第一智能合约中与所述第一调用函数指示不同地址变量的调用函数；根据所述多个智能合约之间的调用关系,确定智能合约调用有向图；按照所述智能合约调用有向图,依序将所述多个智能合约部署在区块链上。</td>   <td>G06F21/64;G06F9/448</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡茂川;              张龙海;              贺凯;              陈晓宏;                   刘丙军       </td>   <td>中山大学</td>   <td>一种水灾害信息管理方法及系统</td>   <td>广东省</td>   <td>CN117455024A</td>   <td>2024-01-26</td>   <td>本发明公开了一种水灾害信息管理方法及系统,方法包括构建数据库单元、区块链单元和数据应用单元；通过数据库单元实时收集水灾害信息监测站点的水灾害信息并上传到数据库；将水灾害信息经过各个网络节点自动上传到区块链；根据DPOS共识算法和时间戳,通过区块链单元将水灾害信息更新到所有网络节点的区块中；根据数据需求方的资质,开放水灾害信息的数据操作权限；其中,数据操作权限包括数据查询权限、数据下载权限和实时共享权限至少之一；通过数据应用单元对权限用户提供水灾害信息的数据操作功能；有利于安全可靠地管理水灾害信息,并且方便数据提供方和数据需求方进行实时数据交互。本发明可广泛应用于水灾害信息管理技术领域。</td>   <td>1.一种水灾害信息管理方法,其特征在于,包括：构建数据库单元、区块链单元和数据应用单元；通过所述数据库单元实时收集水灾害信息监测站点的水灾害信息并上传到数据库；通过所述数据库单元将所述水灾害信息经过所述区块链单元的各个网络节点自动上传到区块链；根据DPOS共识算法和时间戳,通过所述区块链单元将所述水灾害信息更新到所有所述网络节点的区块中；根据数据需求方的资质,通过所述区块链单元开放水灾害信息的数据操作权限；其中,所述数据操作权限包括数据查询权限、数据下载权限和实时共享权限至少之一；通过所述数据应用单元对权限用户提供所述水灾害信息的数据操作功能。</td>   <td>G06Q10/04;H04L67/1095;H04L67/1097;H04L67/12;H04L67/104;H04L9/40;G06Q50/26;G06F16/21;G06F16/27;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王帅先;                   谭光       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于神经隐式地图的相机定位方法、装置及电子设备</td>   <td>广东省</td>   <td>CN117455999A</td>   <td>2024-01-26</td>   <td>本发明公开了一种基于神经隐式地图的相机定位方法、装置及电子设备,方法包括：将查询图像输入卷积骨干网络,生成深度特征图以及粗糙位姿特征；根据所述深度特征图,得到目标张量；将所述目标张量输入Transformer编码器,得到目标输出；根据所述目标输出以及所述粗糙位姿特征,得到位置解码特征以及方向解码特征；将所述位置解码特征以及所述方向解码特征输入预测头,得到精细位姿。本发明能克服环境复杂因素的影响,提高位姿估计的准确率和精度,实现鲁棒精准的相机重定位,可广泛应用于视觉定位技术领域。</td>   <td>1.一种基于神经隐式地图的相机定位方法,其特征在于,包括：将查询图像输入卷积骨干网络,生成深度特征图以及粗糙位姿特征；根据所述深度特征图,得到目标张量；将所述目标张量输入Transformer编码器,得到目标输出；根据所述目标输出以及所述粗糙位姿特征,得到位置解码特征以及方向解码特征；将所述位置解码特征以及所述方向解码特征输入预测头,得到精细位姿。</td>   <td>G06T7/73;G06N3/0464;G06N3/0455;G06N3/0499</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              周朗;                   周凡       </td>   <td>中山大学;中山大学深圳研究院</td>   <td>一种基于结构功能分析的室内场景三维建模方法与系统</td>   <td>广东省</td>   <td>CN117456104A</td>   <td>2024-01-26</td>   <td>本发明公开了一种基于结构功能分析的室内场景三维建模方法,包括：获取场景三维建模,将精细化的场景三维建模进行标注,将标注的点云划分为训练集和验证集,并使用所述验证集获取平均交并比指标,对模型分割质量进行量化评估；进行语义分割网络的训练,利用训练好的语义分割模型,构建三维模型库和分类模型；将粗略的场景三维建模,输入到训练好的语义分割模型,利用生成的语义分割结果,构建目标场景三维建模。本发明还公开了一种基于结构功能分析的室内场景三维建模系统。本发明选取的是基于弱监督学习的室内场景点云语义分割方法,可以充分利用一部分精细化的建模和产出的三维模型库,提高了实际建模的效率。</td>   <td>1.一种基于结构功能分析的室内场景三维建模方法,其特征在于,所述方法包括：利用设备,获取精细化的场景三维建模和粗略的场景三维建模；将所述精细化的场景三维建模进行标注,标注完成后将一部分标注的点云作为验证集,剩余的作为训练集参与语义分割网络的训练,并使用所述验证集获取平均交并比mIoU指标,对模型分割质量进行量化评估；输入所述训练集到基于弱监督学习的室内场景点云语义分割网络中,得到训练好的语义分割模型,利用所述训练好的语义分割模型,构建三维模型库和分类模型；将所述粗略的场景三维建模,输入到所述训练好的语义分割模型,获取语义分割结果,从分割结果中将不同类别的物体提取出来,并利用所述分类模型,从所述三维模型库中检索出最为相近的精细化三维模型,用于替换所述粗略的场景三维建模,最后得到的包含所述精细化的场景三维建模,以及所述粗略的场景三维建模经过精细化处理并且重构的场景三维建模。</td>   <td>G06T17/00;G06V10/26;G06N3/0895;G06V10/764;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘祖浩;              杜佳润;              胡建芳;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于双分支框架的防护服穿戴指导方法、系统及介质</td>   <td>广东省</td>   <td>CN117456404A</td>   <td>2024-01-26</td>   <td>本发明公开了一种基于双分支框架的防护服穿戴指导方法、系统及介质,方法包括下述步骤：构建双分支框架；将摄像头接入双分支框架,实时采集工作人员的防护服穿戴动作视频；双分支框架根据摄像头帧率获取视采样间距,并采样视频帧片段；将视频帧片段同时输入粗粒度分支一和细粒度分支二中进行判断；若细粒度分支二判断结果为正确,则和粗粒度分支一输出的动作类别一起传输至topK细化模块中进行细化判断；若细粒度分支二判断结果为错误,则和粗粒度分支一输出的动作类别一起传输至流程指导模块中进行提示指导。本发明为工作人员提供全面的防护服穿戴操作指导和提示,从而降低其受到传染源等危害的风险,保障其安全和健康,具有广泛的应用前景。</td>   <td>1.一种基于双分支框架的防护服穿戴指导方法,其特征在于,所述方法包括下述步骤：构建双分支框架；所述双分支框架包括粗粒度分支一、细粒度分支二、topK细化模块及流程指导模块；将摄像头接入双分支框架,实时采集工作人员的防护服穿戴动作视频；双分支框架根据摄像头帧率获取视采样间距,并采样视频帧片段；将视频帧片段同时输入粗粒度分支一和细粒度分支二中进行判断,其中：粗粒度分支一对视频帧片段进行防护服穿戴动作类别判断；细粒度分支二根据预设需执行的动作判断视频帧片段中防护服穿戴动作的正确性；若细粒度分支二判断结果为正确,则和粗粒度分支一输出的动作类别一起传输至topK细化模块中,判断当前视频帧片段中正在执行的防护服穿戴动作是否存在粗粒度分支一输出的动作类别中；如果存在,就判断细粒度分支二判断结果是正确的；如果不存在,就判断细粒度分支二判断结果是错误的,反馈错误信息；细粒度分支二根据错误信息利用粗粒度分支一的输出进行自我纠错；若细粒度分支二判断结果为错误,则和粗粒度分支一输出的动作类别一起传输至流程指导模块中,获取错误防护服穿戴动作的前后顺序和当前应执行的正确防护服穿戴动作的前后顺序,并对工作人员进行提示及指导。</td>   <td>G06V20/40;G06V40/20;G06V10/98;G06V10/764;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任江涛;                   郑居武       </td>   <td>中山大学</td>   <td>一种智能交通车型识别检测方法、装置、终端设备及介质</td>   <td>广东省</td>   <td>CN117456478A</td>   <td>2024-01-26</td>   <td>本发明公开了一种智能交通车型识别检测方法、装置、终端设备及介质,包括：获取待识别交通场景图像；将所述待识别交通场景图像分别输入至预训练的Vision-Transformer模型和Swin-Transformer模型中,分别得到所述待识别交通场景图像中待检测车辆的第一车辆特征图和第二车辆特征图；将第一车辆特征图和第二车辆特征图输入至预设的注意力融合网络进行特征对齐并融合,生成融合特征；将融合特征输入至预设的目标检测模型,得到车型识别结果；其中,所述Vision-Transformer模型和所述Swin-Transformer模型采用无监督训练方式进行训练,减少了模型在交通领域的数据标注成本。</td>   <td>1.一种智能交通车型识别检测方法,其特征在于,包括：获取待识别交通场景图像；将所述待识别交通场景图像输入至Visi on-Transformer模型中,以使所述Visi on-Transformer模型,生成所述待识别交通场景图像中待检测车辆的第一车辆特征图；将所述待识别交通场景图像输入至Swin-Transformer模型中,以使所述Swin-Transformer模型,生成所述待识别交通场景图像中待检测车辆的第二车辆特征图；将所述第一车辆特征图和所述第二车辆特征图输入至预设的注意力融合网络,以使所述注意力融合网络将第一车辆特征图和所述第二车辆特征图,进行特征对齐并融合,生成融合特征；将融合特征输入至预设的目标检测模型,得到车型识别结果；其中,所述Vision-Transformer模型以及所述Swin-Transformer模型采用无监督训练的方式进行训练。</td>   <td>G06V20/54;G06V10/44;G06V10/80;G06V10/764;G06V10/82;G06N3/0455;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨跃东;              庞雨贤;              涂越;              劉煒星;              苏启睿;                   莫德林       </td>   <td>中山大学</td>   <td>一种猪肉肉质分级方法</td>   <td>广东省</td>   <td>CN117456524A</td>   <td>2024-01-26</td>   <td>本发明公开了一种猪肉肉质分级方法,涉及计算机视觉技术领域,包括：获取带有肉质评分标签的原始猪肉图像,经数据预处理得到猪肉图像数据集；对传统残差网络模型进行预训练,得到传统残差网络模型的权重和参数；修改传统残差网络模型得到第一残差网络模型；将所得的权重和参数载入第一残差网络模型,得到第二残差网络模型；将猪肉图像数据集划分为训练集、验证集和测试集；再使用猪肉图像数据集进行训练,调整第二残差网络模型的权重和参数,评估调整后的第二残差网络模型的效果,若效果达到预期则将其保存得到第三残差网络模型；将待检测的猪肉图像数据集输入第三残差网络模型,得到肉质评分结果。本发明具有对数据量需求量小、准确率高的优点。</td>   <td>1.一种猪肉肉质分级方法,其特征在于：所述方法包括如下步骤：获取带有肉质评分标签的原始猪肉图像；对带有肉质评分标签的原始猪肉图像通过数据预处理得到猪肉图像数据集；使用开源数据集对传统残差网络模型进行预训练,得到传统残差网络模型的权重和参数；在传统残差网络模型的基础上添加分支结构,得到第一残差网络模型；将传统残差网络模型的权重和参数载入第一残差网络模型,得到第二残差网络模型；将猪肉图像数据集划分为训练集、验证集和测试集；使用猪肉图像数据集对第二残差网络模型进行训练,具体通过训练集的输出结果与猪肉图像数据集中的肉质评分标签的偏差反向传播调整第二残差网络模型的权重,通过验证集调整第二残差网络模型的参数,通过测试集评估调整后的第二残差网络模型的效果,若调整后的第二残差网络模型的效果达到预期则将其保存得到第三残差网络模型；将待检测的猪肉图像数据集输入第三残差网络模型,得到肉质评分结果。</td>   <td>G06V20/68;G06V10/44;G06V10/80;G06N3/0464;G06N3/048;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵树之;              刘汉军;              燕楠;                   王岚       </td>   <td>中山大学附属第一医院;中国科学院深圳先进技术研究院</td>   <td>一种基于多模态影像融合的帕金森疾病检测模型及检测系统</td>   <td>广东省</td>   <td>CN117457184A</td>   <td>2024-01-26</td>   <td>本发明公开了一种基于多模态影像融合的帕金森疾病检测模型及检测系统,包括影像特征提取模块、多模态融合模块、预测模块和输出模块；在获得待测用户的sMRI、DTI和fMRI影像后,采用不同的方法对三通道的数据提取特征并融合,得到双模态和三模态的多模态融合特征,之后通过集成学习的方法最终获得诊断结果,供医生进行诊断辅助参考。针对目前帕金森早期诊断,本发明定量分析多模态数据,对于早期诊断帕金森病具有重要意义,不仅可以提高诊断的准确性,减少操作者的主观判断误差,而且对临床早期干预和减少后期残疾都具有应用价值。</td>   <td>1.一种基于多模态影像融合的帕金森疾病检测模型,其特征在于,包括影像特征提取模块、多模态融合模块、预测模块和输出模块；所述影像特征提取模块用于从待测用户的脑的结构核磁共振成像、弥散张量成像和功能性磁共振成像的影像中采集数据,并从中依次提取特征,共得到三种单模态特征,再递呈至多模态融合模块；所述三种单模态特征为结构核磁共振成像单模态特征、弥散张量成像单模态特征和功能性磁共振成像单模态特征；所述脑包括大脑和小脑；从所述结构核磁共振成像和弥散张量成像的影像中采集到的数据为结构数据,从所述功能性磁共振成像的影像中采集到的数据为功能数据；所述多模态融合模块用于融合所述三种单模态特征得到多模态融合特征,所述多模态融合特征为双模态融合特征和/或三模态融合特征,所述双模态融合特征由所述三种单模态特征经过两两融合得到三种双模态融合特征,所述三模态融合特征由所述三种单模态特征共同融合得到；所述预测模块用于利用言语能力预测模型和所述多模态融合特征,得到预测结果,所述预测结果包括待测用户的帕金森疾病的行为评分；所述言语能力预测模型由以所述运动能力预测模型作为源域,经过迁移学习得到；所述运动能力预测模型由以帕金森病数据集作为训练集在深度学习框架下进行训练得到；所述帕金森病数据集包括帕金森患者的结构核磁共振成像、弥散张量成像和功能性磁共振成像的影像以及帕金森疾病的行为评分；所述输出模块用于输出所述预测结果。</td>   <td>G16H50/20;G06T7/00;G06V10/44;G06V10/80;G06V10/764;G06V10/82;G06N3/0464;G06N3/049;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         贺智;                   周承乐       </td>   <td>中山大学</td>   <td>一种RGB图像光谱超分辨率重建方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN117455775A</td>   <td>2024-01-26</td>   <td>本发明提供了一种RGB图像光谱超分辨率重建方法、系统、设备及介质,通过机理嵌入学习模型的深度学习网络架构,将三个波段RGB图像的光谱波段数量提升至N维,即获得高光谱图像,能够提供丰富的光谱诊断性信息；光谱重建过程中,设计了频域子网络模型,从图像频域视角捕获高维图像空间细节信息,强调了频域特征信息对图像空间细节恢复的重要性,设计了光谱子网络模型,并提出光谱自主力机制,获取高维光谱波段间的特征依赖性及其深度先验信息,增强了光谱超分辨任务中光谱波段重建的可解释性。</td>   <td>1.一种RGB图像光谱超分辨率重建方法,其特征在于,所述方法包括：从RGB图像中捕获近似图像信息,并对所述近似图像信息进行校正,得到初始高光谱图像；将所述初始高光谱图像输入构建的深度展开网络模型进行迭代训练；所述深度展开网络模型包括依次叠加堆叠的频域重构网络模块、谱域重构网络模块和全局注意力网络模块,所述频域重构网络模块为基于卷积神经网络的频域子网络,所述谱域重构网络为Transformer神经网络和卷积神经网络相结合的网络架构,所述全局注意力网络模块基于全局注意力机制；通过预定次数的迭代训练,获得超分辨率光谱图像。</td>   <td>G06T3/4053;G06T5/80;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈俊周;              蒲佳俊;              尹柏乔;                   谭光       </td>   <td>中山大学·深圳;中山大学</td>   <td>交通异常事件感知方法、系统、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117456417A</td>   <td>2024-01-26</td>   <td>本申请实施例提供了一种交通异常事件感知方法、系统、电子设备及存储介质,属于人工智能技术领域。该方法通过多头自注意力重构单元的自适应层次化特征重构降低特征提取时所使用的通用视觉模型识别数据与视频交通异常事件检测数据存在域间隙,然后通过多头局部自注意力单元根据前后数个时间步的隐式特征对当前被检测视频片段的第一隐式特征进行局部自注意力池化,在实现片段级检测的同时,结合视频片段上下文信息的时间感知,使得训练得到的异常事件感知模型能够进行高效、准确地交通异常事件检测。</td>   <td>1.一种交通异常事件感知方法,其特征在于,包括以下步骤：获取交通监控视频；将所述交通监控视频的视频片段依次输入异常事件感知模型,得到异常事件感知结果；其中,所述异常事件感知模型的构建过程包括：获取训练数据集,其中,所述训练数据集的每一个视频样本标注有是否发生异常事件的真实标签；将所述视频样本的多个视频片段按照时间顺序输入通用视觉模型进行特征提取,得到每一个视频片段的多个片段特征；将每一个视频片段的多个片段特征输入多头自注意力重构单元进行特征重构,得到视频片段的第一隐式特征；将当前视频片段的第一隐式特征与相邻视频片段的第一隐式特征输入多头局部自注意力单元进行局部自注意力池化,得到当前视频片段的片段特征表示；根据所述片段特征表示输入多层感知机进行交通异常事件判别,得到片段预测概率；根据所述训练数据集中的视频样本的片段预测概率和标签进行反向更新,得到异常事件感知模型。</td>   <td>G06V20/40;G06V20/54;G06V10/44;G06V10/62;G06V10/764;G06N3/045;G06N3/084;G06N3/09;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王昊頔;                   操晓春       </td>   <td>中山大学</td>   <td>一种基于多模态信息控制的说话人脸视频生成方法及装置</td>   <td>广东省</td>   <td>CN117456587A</td>   <td>2024-01-26</td>   <td>本发明公开了一种基于多模态信息控制的说话人脸视频生成方法及装置,方法包括：对输入图像进行图像编码,获得隐式表征；对隐式特征进行扩散加噪,获得带噪隐变量；基于视觉人脸参考图像,获得人物身份特征和人脸掩码特征；基于输入音频,获得音频特征；基于情感文本,获得情感文本特征,并通过联合嵌入获得情感视觉联合特征,进一步获得情感控制特征；基于人物身份特征、人脸掩码特征、音频特征和情感控制特征,对带噪隐变量进行去噪和图像解码,获得说话人脸目标图像,进而获得说话人脸的目标视频。本发明能够生成高保真说话人脸,同时有效解决现有方法忽略人脸情感的局限性,具有广阔应用前景。</td>   <td>1.一种基于多模态信息控制的说话人脸视频生成方法,其特征在于,包括：获取输入图像,对所述输入图像进行图像编码,获得隐式表征；基于正态分布的噪声对所述隐式表征进行扩散加噪,获得带噪隐变量；获取视觉人脸参考图像,对所述视觉人脸参考图像进行图像编码,获得人物身份特征；并对所述视觉人脸参考图像进行掩码处理和图像编码,获得人脸掩码特征；获取输入音频,对所述输入音频进行特征提取,获得音频特征；获取输入情感文本,对所述输入情感文本进行特征提取,获得情感文本特征；基于所述人物身份特征和所述情感文本特征进行联合嵌入,获得情感视觉联合特征；基于所述情感视觉联合特征,获得情感控制特征；基于所述人物身份特征、所述人脸掩码特征、所述音频特征和所述情感控制特征,对所述带噪隐变量进行去噪和图像解码,获得说话人脸的目标图像；基于所述说话人脸的目标图像,获得说话人脸的目标视频。</td>   <td>G06V40/16;G06V10/30;G06V10/80;G06V10/82;G06V20/40;G06V30/164;G06V30/18;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         肖胜蓝;              王怀彬;              黄茜;                   舒跃龙       </td>   <td>中山大学</td>   <td>一种基于马尔可夫链模型的病毒传播风险计算方法及装置</td>   <td>广东省</td>   <td>CN117457231A</td>   <td>2024-01-26</td>   <td>本发明公开了一种基于马尔可夫链模型的病毒传播风险计算方法及装置,所述方法包括：获取参数信息,所述参数信息包括：待检测环境的环境特征参数、待检测病毒的特异性参数以及待检测环境内用户的行为参数；基于预设的马尔可夫链模型采用所述参数信息进行剂量计算,得到病毒在不同传播途径的传播剂量值,采用所述传播剂量值计算传播风险值。本发明可以分别采集环境特征参数、特异性参数以及行为参数,利用马尔可夫链模型综合对环境、病毒特异特征和行为参数进行评估计算,计算得到不同传播途径中病毒的剂量,再结合不同途径的病毒剂量评估病毒的风险,从而可以减少评估计算的偏差,提升计算的精度。</td>   <td>1.一种基于马尔可夫链模型的病毒传播风险计算方法,其特征在于,所述方法包括：获取参数信息,所述参数信息包括：待检测环境的环境特征参数、待检测病毒的特异性参数以及待检测环境内用户的行为参数；基于预设的马尔可夫链模型采用所述参数信息进行剂量计算,得到病毒在不同传播途径的传播剂量值,采用所述传播剂量值计算传播风险值。</td>   <td>G16H50/80;G06N7/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢宇彤;                   李尹健       </td>   <td>中山大学</td>   <td>一种半异步并行神经网络的计算优化方法及系统</td>   <td>广东省</td>   <td>CN112633480B</td>   <td>2024-01-23</td>   <td>本发明公开了一种半异步并行神经网络的计算优化方法及系统,该方法包括：初始化参数；将相关参数发送给空闲的计算节点；预测计算节点计算所需的时间；将计算节点分类；等待任一节点计算完毕后根据计算节点的类别发送对应命令；本次循环计算结束后进行参数更新；返回计算节点计算步骤直至更新后的神经网络的准确度达到预设值。该系统包括：参数服务器和计算节点。本发明克服了某些节点计算速度过慢导致整体速度过慢的问题。本发明作为一种半异步并行神经网络的计算优化方法及系统,可广泛应用于网络优化领域。</td>   <td>1.一种半异步并行神经网络的计算优化方法,其特征在于,用于网络优化,包括参数服务器的工作步骤：S1、初始化计算节点的相关参数和神经网络的相关参数；S2、将神经网络的相关参数发送给空闲的计算节点并命令计算节点执行计算；S3、基于速度预测器预测计算节点所需的计算时间,得到预测结果；所述预测计算节点所需的时间,得到预测结果这一步骤,其具体包括：将计算节点上一次循环的计算时长输入到预构建的速度预测器；根据计算节点上一次循环的计算时长预测该计算节点本次计算所需的时间,得到预测结果；S4、根据预测结果和节点状态估计本次循环计算用时并将计算节点分类,得到分类结果；S5、等待计算节点完成计算并根据分类结果命令计算节点执行对应的工作；所述等待计算节点完成计算并根据分类结果命令计算节点执行对应的工作这一步骤,其具体包括：等待任一计算节点计算完毕,根据计算节点的类别给出不同的指令；对于第一类别节点,参数服务器接收计算结果并发送停止计算命令给该计算节点,计算节点转为空闲等待状态；对于第二类别节点,参数服务器接收计算结果并发送继续计算命令给该计算节点,计算节点继续开始计算；S6、根据预设规则判断本次循环计算结束并对神经网络和速度预测器进行参数更新,得到更新后的神经网络；S7、返回步骤S2直至更新后的神经网络的准确度达到预设值。</td>   <td>G06N3/0464;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘建平;              黄炜基;              刘尊龙;                   任飞       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>肝内胆管细胞癌筛查指标及其预后因素的分析评价方法</td>   <td>广东省</td>   <td>CN117131468B</td>   <td>2024-01-23</td>   <td>本发明提出了肝内胆管细胞癌筛查指标及其预后因素的分析评估方法,包括：收集ICC患者的诊疗信息并形成作为ICC病例组的数据集,收集健康体检人群的诊疗信息并形成作为对照组的数据集；从对ICC病例组和对照组数据集中各单独指标进行统计学差异性检验,获取与统计学有差异的单独指标变量；分析比较所述述8个单独指标对ICC的诊断价值；构建联合指标并分析比较所述联合指标对ICC的诊断价值；所述筛选指标作为单独因素纳入Cox回归模型进行单独因素分析,判断每个单独因素对ICC的生存时间存在的影响以区分其是危险因素或保护因素。本发明联合常用的筛查指标,提高诊断筛查的成功率,通过对潜在的预后相关危险因素进行分析,找寻新的预后相关因素指导临床治疗。</td>   <td>1.肝内胆管细胞癌筛查指标及其预后因素的分析评价方法,其特征在于,所述方法包括：步骤1、收集ICC患者的诊疗信息并形成作为ICC病例组的数据集,收集健康体检人群的诊疗信息并形成作为对照组的数据集；其中,所述ICC患者为确诊肝内胆管细胞癌并具有完整临床诊疗信息及随访的患者；步骤2、从对ICC病例组和对照组数据集中各单独指标进行统计学差异性检验,获取与统计学有差异的单独指标变量,所述单独指标变量包括8个：CA19-9、CA125、AFP、CEA、GGT、ALP、ALT和AST；其中,所述ICC病例组中的上述8个单独指标变量均高于所述对照组的单独指标变量；步骤3：分析比较所述述8个单独指标对ICC的诊断价值,包括：构建所述8个单独指标的ROC曲线并计算AUC得到所述8个单独指标AUC值,从而得到所述8个单独指标中AUC值最大的单独指标为CA19-9；其中,AUC值越大对ICC的诊断价值越高；将ROC曲线中最大约登指数对应的检测值作为对应单独指标的对ICC的诊断阈值,并评估对应单独指标的灵敏度和特异度,从而得到灵敏度最高的单独指标为CA19-9～@,特异度最高的单独指标为CA19-9～$,其中,CA19-9～@表示以所述诊断阈值对ICC进行评估的单独指标,CA19-9～$表示以临床阈值对ICC进行评估的单独指标；步骤4、构建联合指标并分析比较所述联合指标对ICC的诊断价值,包括：采用ROC曲线推导的诊断阈值将所述8个单独指标变量转换为二分类变量,依次以CA19-9～@和CA19-9～$作为基础与其他单独指标进行联合试验以构建联合指标,从而得到灵敏度均显著高于单独指CA19-9～@和CA19-9～$的联合指标包括6个：CA19-9～@+CA125、CA19-9～@+GGT、CA19-9～@+ALP、CA19-9～$+CA125、CA19-9～$+GGT、CA19-9～$+ALP；以是否患有ICC为结局指标,将所述6个联合指标作为自变量构建二元Logistic回归模型以计算预测概率值,然后通过构建ROC曲线和计算AUC值以评估各个预测概率值对ICC的诊断价值,从而得到所述6个联合指标的AUC值均显著高于单独指标CA19-9的AUC值；步骤5、从所述ICC病例组的相关数据中筛选指标进行统计学描述,并采用Kaplan-Meier法评估ICC患者的生存时间；其中,所述生存时间是指确诊日期与死亡日期或最后一次随访之间的时间间隔；步骤6、将所述筛选指标作为单独因素纳入Cox回归模型进行单独因素分析,判断每个单独因素对ICC的生存时间存在的影响以区分其是危险因素或保护因素,从而得到所述筛选指标中肿瘤大小、TNM分期、是否行根治性手术、CA19-9、CA125、CEA,GGT、ALP和肝功能分级作为ICC患者的生存时间的危险因素；步骤7、通过最大偏似然估计的似然比检验,将所述筛选指标中的性别、年龄、肿瘤大小、TNM分期、是否行根治手术、D-二聚体、肝功能分级、CA19-9、CA125、CEA、GGT、ALP和ALT纳入以构造多因素Cox回归模型进行多因素Cox分析,从而得到年龄、TNM分期和GGT作为ICC患者的生存时间的危险因素。</td>   <td>G16H50/30;G06F18/27;G06F18/2113</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;              黄泽青;              刘智勇;              段凯;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种气候态集合预报的生成方法</td>   <td>广东省</td>   <td>CN117435585A</td>   <td>2024-01-23</td>   <td>本发明公开了一种气候态集合预报的生成方法,涉及水文预报技术领域。所述方法包括：获取水文气象历史观测数据；基于标准正态分布构建z-score,并采用数据变换与统计分布,基于所述z-score构建气候态集合预报生成模型；根据所述水文气象历史观测数据估计所述气候态集合预报生成模型的参数,生成候选气候态集合预报；对所述候选气候态集合预报进行可靠性评估,得到可靠性评估结果,并根据所述可靠性评估结果筛选可靠性最高的所述候选气候态集合预报,作为最终的气候态集合预报。相较于现有技术,本发明统一地由z-score出发,采用数据变换与统计分布生成预报,有助于克服传统建模方法在不同水文气象条件下稳定性不足的问题,预报可靠性更高。</td>   <td>1.一种气候态集合预报的生成方法,其特征在于,包括：获取水文气象历史观测数据；基于标准正态分布构建z-score,并采用数据变换与统计分布,基于所述z-score构建气候态集合预报生成模型；根据所述水文气象历史观测数据估计所述气候态集合预报生成模型的参数,生成候选气候态集合预报；对所述候选气候态集合预报进行可靠性评估,得到可靠性评估结果,并根据所述可靠性评估结果筛选可靠性最高的所述候选气候态集合预报,作为最终的气候态集合预报。</td>   <td>G06F16/215;G06F17/18;G06F30/20;G06F119/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林沛元;              袁勋;              黄胜;                   马保松       </td>   <td>中山大学</td>   <td>一种基于分布式光纤的排水管道灾害预警装置及方法</td>   <td>广东省</td>   <td>CN117436690A</td>   <td>2024-01-23</td>   <td>本申请属于排水管道结构健康监测技术领域,公开了一种基于分布式光纤的排水管道灾害预警装置及方法,该装置包括：光纤感测模块,包括光频域反射解调仪和多种感测光纤；各种感测光纤按预设方案粘贴于排水管道内壁,光频域反射解调仪用于获取各种感测光纤的感测数据；数据分析模块,用于通过统计学方法对感测数据进行分析,并在分析得到异常数据时,通过机器学习算法判断异常数据对应的灾害风险等级；灾害预警模块,根据异常数据和灾害风险等级生成预警信息；运维决策模块,用于基于风险知情理论的决策体系和预警信息进行排水管运维决策。本申请可以在早期及时准确地识别排水管道内的异常情况,延长排水管道的服役性能,降低运维成本。</td>   <td>1.一种基于分布式光纤的排水管道灾害预警装置,其特征在于,包括：光纤感测模块,包括光频域反射解调仪和多种感测光纤；各种所述感测光纤按预设方案粘贴于排水管道内壁,所述光频域反射解调仪用于获取各种所述感测光纤的感测数据；数据分析模块,用于通过统计学方法对所述感测数据进行分析,并在分析得到异常数据时,通过机器学习算法判断所述异常数据对应的灾害风险等级；灾害预警模块,根据所述异常数据和所述灾害风险等级生成预警信息；运维决策模块,用于基于风险知情理论的决策体系和所述预警信息进行排水管运维决策。</td>   <td>G06Q10/0635;G01K11/32;G01B11/16;G06Q10/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              李秀祥;              苏卓;                   陈小燕       </td>   <td>中山大学</td>   <td>一种知识融合的服饰试衣服务计算方法与系统</td>   <td>广东省</td>   <td>CN117436969A</td>   <td>2024-01-23</td>   <td>本发明公开了一种知识融合的服饰试衣服务计算方法。包括：输入虚拟试衣数据集至特征金字塔网络进行特征提取,输出参考人物特征和目标服装特征；输入提取后的两个特征至双流瓶颈变形器中进行特征融合,得到隐空间向量；采用服装变形模块,结合前面步骤分别输出的最终结果,得到最终的外观流；将参考人物特征、目标服装特征和最终的外观流输入至合成模块,经过UNET结构进行合成,输出最终的试衣结果。本发明还公开了一种知识融合的服饰试衣服务计算系统。本发明较其他发明,提出了一个新颖的加权外观流估计策略,并引入了双流瓶颈变形器和稀疏空间采样的方法,能够直接处理二维图像,对图片中的人物进行试衣,有效提高了实际使用时的合成效率。</td>   <td>1.一种知识融合的服饰试衣服务计算方法,其特征在于,所述方法包括：从服装数据集筛选并输入参考人物图片和目标服装图片,并处理成统一尺寸,然后输入所述参考人物图片和目标服装图片至两个结构完全相同的特征金字塔网络中进行特征提取,输出参考人物特征和目标服装特征；输入所述参考人物特征和目标服装特征至双流瓶颈变形器中进行特征融合,得到隐空间向量；将所述参考人物特征和目标服装特征和所述隐空间向量输入至服装变形模块,按照级联的方式对来自所述特征金字塔网络的每一层特征进行处理,每一层级的处理都会得到一个中间流,通过复用上一层级的中间流,得到最终的外观流；将所述参考人物特征和目标服装特征,以及所述最终的外观流输入至合成网络中,得到合成的试衣结果。</td>   <td>G06Q30/0601;G06V10/80;G06V10/32;G06V10/40;G06V10/82;G06N3/0455;G06N3/042;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蒋滔;              姜金圻;              郑桂勇;              冯宸;              周博宇;                   谷德峰       </td>   <td>中山大学</td>   <td>一种多模态大规模场景数据集的构建方法</td>   <td>广东省</td>   <td>CN117437366A</td>   <td>2024-01-23</td>   <td>本发明公开了一种多模态大规模场景数据集的构建方法,如下：对获取的原始大场景3D模型进行场景分割形成多个单一场景3D模型；对得到的每个单一场景3D模型进行不同视角的图像渲染生成对应多个视角的单一场景3D模型的深度图像和RGB图像；对渲染后得到的RGB图像进行文字说明并生成描述性文本；对渲染后得到的深度图像进行复原并生成部分点云信息；将渲染后得到的深度图像和RGB图像、RGB图像对应的描述性文本、深度图像对应的部分点云信息添加到多模态大规模场景数据集中,由此完成多模态大规模场景数据集的构建。本发明构建的多模态大规模场景数据集,能满足当前深度学习算法的训练需求、促进表面预测和补全技术的发展。</td>   <td>1.一种多模态大规模场景数据集的构建方法,其特征在于：所述方法包括步骤如下：对获取的原始大场景3D模型进行场景分割形成多个单一场景3D模型；对得到的每个单一场景3D模型进行不同视角的图像渲染生成对应多个视角的单一场景3D模型的深度图像和RGB图像；对渲染后得到的RGB图像进行文字说明并生成描述性文本；对渲染后得到的深度图像进行复原并生成部分点云信息；将渲染后得到的深度图像和RGB图像、RGB图像对应的描述性文本、深度图像对应的部分点云信息添加到多模态大规模场景数据集中,由此完成多模态大规模场景数据集的构建。</td>   <td>G06T17/00;G06T7/11;G06T11/60;G06T19/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>              高庆       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种手语识别方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117437694A</td>   <td>2024-01-23</td>   <td>本发明公开了一种手语识别方法、装置、电子设备及存储介质,包括：获取待识别的手语视频；提取待识别的手语视频中的关节综合特征数据和骨骼综合特征数据；其中,关节综合特征数据包括关节特征数据和关节运动特征数据；骨骼综合特征数据包括骨骼特征数据和骨骼运动特征数据；将关节综合特征数据和骨骼综合特征数据输入自蒸馏多特征学习网络中的多特征聚合模块进行聚合处理,得到骨架聚合特征数据；将骨架聚合特征数据、关节综合特征数据和骨骼综合特征数据输入至自蒸馏多特征学习网络中的特征提取网络进行特征提取处理,得到手语识别结果。本发明实施例能够更准确地识别和理解手语动作,实现精细化的手语识别任务,可广泛应用于图像识别技术领域。</td>   <td>1.一种手语识别方法,其特征在于,包括：获取待识别的手语视频；提取所述待识别的手语视频中的关节综合特征数据和骨骼综合特征数据；其中,所述关节综合特征数据包括关节特征数据和关节运动特征数据；所述骨骼综合特征数据包括骨骼特征数据和骨骼运动特征数据；将所述关节综合特征数据和所述骨骼综合特征数据输入自蒸馏多特征学习网络中的多特征聚合模块进行聚合处理,得到骨架聚合特征数据；将所述骨架聚合特征数据、所述关节综合特征数据和所述骨骼综合特征数据输入至所述自蒸馏多特征学习网络中的特征提取网络进行特征提取处理,得到手语识别结果。</td>   <td>G06V40/20;G06V10/44;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              高庆       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于信息共享机制的手语识别方法、装置和电子设备</td>   <td>广东省</td>   <td>CN117437695A</td>   <td>2024-01-23</td>   <td>本发明公开了基于信息共享机制的手语识别方法、装置和电子设备,包括：获取待识别的手语视频；提取待识别的手语视频中的关节综合特征数据、骨骼综合特征数据以及角度综合特征数据；将关节综合特征数据、骨骼综合特征数据以及角度综合特征数据作为模型输入数据,并将模型输入数据输入至配置有信息共享机制的信息共享网络中进行特征预测,得到模型输入数据对应的特征预测结果；其中,信息共享机制用于实现不同特征数据之间的数据共享；根据特征预测结果得到待识别的手语视频对应的手语识别结果。本发明实施例能够挖掘不同骨架特征之间的非线性关系,从而提高特征表征能力和手语动作识别准确度,可广泛应用于图像识别技术领域。</td>   <td>1.基于信息共享机制的手语识别方法,其特征在于,包括：获取待识别的手语视频；提取所述待识别的手语视频中的关节综合特征数据、骨骼综合特征数据以及角度综合特征数据；将所述关节综合特征数据、所述骨骼综合特征数据以及所述角度综合特征数据作为模型输入数据,并将所述模型输入数据输入至配置有信息共享机制的信息共享网络中进行特征预测,得到所述模型输入数据对应的特征预测结果；其中,所述信息共享机制用于实现不同特征数据之间的数据共享；根据所述特征预测结果得到所述待识别的手语视频对应的手语识别结果。</td>   <td>G06V40/20;G06V10/44;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张木水;                   沈毅龙       </td>   <td>中山大学</td>   <td>一种基于网络参数估计辐射功率对差分对信号相对偏斜灵敏度方法</td>   <td>广东省</td>   <td>CN111310304B</td>   <td>2024-01-19</td>   <td>本发明公开了一种基于网络参数估计辐射功率对差分对信号相对偏斜灵敏度方法,包括：S1：构建电路辐射结构的模型并获取电路辐射结构的网络参数；S2：将所述网络参数不同频率点对应的激励差分对正弦信号输入至电路辐射结构中,计算电路辐射结构的共振频率,得到共振频率范围；S3：将任意差分对信号输入至电路辐射结构,并判断所输入的任意差分对信号的信号谐波是否落在已获取的电路辐射结构的共振频率范围内,若是则进行步骤S4,若否则结束计算；S4：计算电路辐射结构对输入的差分对信号相对偏斜量的灵敏度；S5：利用谐波所在的频率值及差分对信号的相对偏斜量得到辐射功率值大小。本发明减少了差分对信号相对偏斜量的灵敏度分析的误差,实用性强。</td>   <td>1.一种基于网络参数估计辐射功率对差分对信号相对偏斜灵敏度方法,其特征在于,包括以下步骤：S1：构建电路辐射结构的模型并获取电路辐射结构的网络参数；S2：将所述网络参数不同频率点对应的激励差分对正弦信号输入至电路辐射结构中,计算电路辐射结构的共振频率,得到共振频率范围；S3：将任意差分对信号输入至电路辐射结构,并判断所输入的任意差分对信号的信号谐波是否落在已获取的电路辐射结构的共振频率范围内,若是则进行步骤S4,若否则结束计算；S4：计算电路辐射结构对输入的差分对信号相对偏斜量的灵敏度；计算电路辐射结构的共振频率的表达式如下：                  其中,H表示矢量/矩阵的共轭转置,“+”表示端口的入射信号,“-”表示端口的反射信号,P-+表示端口处的入射信号功率,P--表示端口处的反射信号功率,S表示散射参数,V表示入射波矢量,I表示单位矩阵,Z-0为辐射结构的特征阻抗,P-(radiated)表示辐射功率；步骤S4中计算电路辐射结构对输入的差分对信号相对偏斜量的灵敏度是通过对网络参数计算辐射功率计算公式的入射信号波矢量添加相移得到延伸公式,由延伸公式得到的辐射频率特性图,所述入射信号波矢量表示为：                  其中,V～+表示入射信号波矢量,f表示频率,Δt为相对偏斜量时延；以f表示频率,Δt为相对偏斜量时延为自变量辐射功率为因变量,得到对应的灵敏度分析图；S5：利用谐波所在的频率值及差分对信号的相对偏斜量得到辐射功率值大小。</td>   <td>G06F30/20;G06F30/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>              丁汝鑫       </td>   <td>中山大学</td>   <td>剥蚀厚度确定方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN111723471B</td>   <td>2024-01-19</td>   <td>本申请提出一种剥蚀厚度确定方法、装置、设备及存储介质,其中方法包括：获取岩石样品的第一热史曲线；确定所述第一热史曲线的拐点以及低温段；根据所述低温段对所述第一热史曲线的高温段进行趋势拟合,并根据趋势拟合后的高温段以及所述低温段生成所述岩石样品的第二热史曲线；根据所述第二热史曲线,确定所述岩石样品所在岩层在各个历史时间的剥蚀厚度。该方法实现了根据岩石样品的热史曲线,准确确定岩石样品所在岩层在各个历史时间的剥蚀厚度,从而为后期结合剥蚀厚度进行后续研究提供了重要的数据。</td>   <td>1.一种剥蚀厚度确定方法,其特征在于,包括：获取岩石样品的第一热史曲线；确定所述第一热史曲线的拐点以及低温段；根据所述低温段对所述第一热史曲线的高温段进行趋势拟合,并根据趋势拟合后的高温段以及所述低温段生成所述岩石样品的第二热史曲线；根据所述第二热史曲线,确定所述岩石样品所在岩层在各个历史时间的剥蚀厚度；其中,确定所述第一热史曲线的所述拐点以及所述低温段,包括：获取所述第一热史曲线中每个历史时间的温度斜率信息,并将每个所述历史时间的所述温度斜率信息与前一所述历史时间的所述温度斜率信息进行比较,得到每个所述历史时间的所述温度斜率信息相对前一所述历史时间的所述温度斜率信息的变化值,将所述温度斜率信息的变化值最大的点确定为所述第一热史曲线的所述拐点,将所述第一热史曲线的所述拐点之后的所述历史时间段的曲线段确定为所述第一热史曲线的所述低温段,将所述第一热史曲线的所述拐点之前的所述历史时间段的所述曲线段确定为所述第一热史曲线的高温段；其中,根据所述低温段对所述第一热史曲线的高温段进行趋势拟合,并根据趋势拟合后的高温段以及所述低温段生成所述岩石样品的第二热史曲线,包括：获取所述第一热史曲线对应所述低温段中的多个散点,并对所述多个散点进行趋势拟合,得到趋势拟合线,然后将所述趋势拟合线中与所述高温段的历史时间段匹配的曲线段,确定为所述趋势拟合后的所述高温段,根据所述趋势拟合后的所述高温段以及所述趋势拟合之前的所述低温段,生成所述岩石样品的所述第二热史曲线,所述多个散点为所述第一热史曲线的所述拐点之后且与所述拐点相邻的一段曲线段中获取的所述多个散点。</td>   <td>G06F30/20;G06F119/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         裴杰;                   谭绍锋       </td>   <td>中山大学</td>   <td>产量预测时间窗口确定方法、装置、设备及可读存储介质</td>   <td>广东省</td>   <td>CN116579521B</td>   <td>2024-01-19</td>   <td>本申请属于农作物产量预测的技术领域,公开了一种产量预测时间窗口确定方法、装置、设备及可读存储介质,该方法包括：获取待预测作物在目标种植区域的第一环境数据；对待预测作物进行物候阶段划分,并基于第一环境数据与划分的物候阶段确定目标种植区域中待预测作物在不同物候阶段对应的第二环境数据；将第二环境数据作为自变量,目标种植区域中待预测作物的单位面积产量值作为因变量,构建得到目标种植区域中待预测作物在不同物候阶段的产量预测模型；对比各产量预测模型的精度,并筛选得到精度超过预设精度的目标产量预测模型；将目标产量预测模型中对应的最早物候阶段确定为最佳时间窗口。本申请可以确定作物产量预测精度高的最佳时间窗口。</td>   <td>1.一种产量预测时间窗口确定方法,其特征在于,所述方法包括：获取待预测作物在目标种植区域的第一环境数据；基于地面物候调查数据,将目标种植区域中待预测作物的整个生长季划分为不同物候阶段,其中,地面物候调查数据包括基于农业气象站点的数据与行政区划的报告,当地面物候调查数据为行政区划的报告时,包括：基于每周行政区划的报告中的待预测作物数据确定每周进入同一物候阶段的待预测作物在目标种植区域的面积占比；将面积占比超过一半的物候阶段作为目标种植区域中待预测作物的对应物候阶段,并将面积占比超过一半的起始周作为对应物候阶段的起始时间点,直到确定待预测作物在整个生长季中的预设个起始时间点；基于预设个起始时间点对目标种植区域中待预测作物的整个生长季进行物候阶段划分；基于目标种植区域中待预测作物的物候阶段划分对第一环境数据进行统计计算,得到目标种植区域中待预测作物在不同物候阶段对应的第二环境数据；将第二环境数据作为自变量,目标种植区域中待预测作物的单位面积产量值作为因变量,构建得到目标种植区域中待预测作物在不同物候阶段的产量预测模型；对比待预测作物在不同物候阶段的产量预测模型的精度,并筛选得到精度超过预设精度的目标产量预测模型；将目标产量预测模型中对应的最早物候阶段确定为最佳时间窗口。</td>   <td>G06Q10/063;G06Q50/02;G06F18/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>              肖凡       </td>   <td>中山大学</td>   <td>MVT型铅锌矿成矿预测方法、装置、计算机设备及存储介质</td>   <td>广东省</td>   <td>CN116720976B</td>   <td>2024-01-19</td>   <td>本申请适用于矿产资源预测技术领域,提供了一种MVT型铅锌矿成矿预测方法、装置、计算机设备及存储介质,其中方法包括：获取MVT型铅锌矿的地质构造信息,矿石的物理参数以及流体参数；根据经验模态分解方法对成矿系统进行分解,获得多个物理过程模型；根据物理过程模型构建多个数值模拟模块,并结合地质构造信息,矿石的物理参数以及流体参数进行成矿地质作用过程中的力-热-流-质-化学五场耦合多物理场数值模拟计算,得到多个成矿条件参数；根据多个成矿条件参数以及成矿预测模型确定MVT型铅锌矿的成矿预测结果,本申请通过经验模态分解的方法将复杂的成矿系统拆分成简单物理过程,通过机器学习对模拟参量进行分析,可以更加精确地划定找矿靶区。</td>   <td>1.一种MVT型铅锌矿成矿预测方法,其特征在于,包括：获取MVT型铅锌矿的地质构造信息,矿石的物理参数以及流体参数；根据经验模态分解方法对成矿系统进行分解,获得多个物理过程模型,所述物理过程模型至少包括力学模型、传热模型、流体运移模型；根据所述物理过程模型构建多个数值模拟模块,并结合所述地质构造信息,矿石的物理参数以及流体参数进行成矿地质作用过程中的力-热-流-质-化学五场耦合多物理场数值模拟计算,得到多个成矿条件参数,所述成矿条件参数至少包括应力场参数、温度场参数、流体场参数、质量传递场参数以及化学场参数；根据所述多个成矿条件参数以及成矿预测模型确定所述MVT型铅锌矿的成矿预测结果；其中,所述成矿预测模型是基于预设的机器学习算法训练生成的；所述力-热-流-质-化学五场耦合多物理场至少由基于MVT型铅锌矿的勘探资料所建立的MVT型铅锌矿几何模型与基于力、热、流、质、化学多物理场的动力学方程所建立的多个数值模拟模块结合组成；所述基于力、热、流、质、化学多物理场的动力学方程所建立的多个数值模拟模块的步骤,具体包括：获取固体力学应力变化方程的变量参数,调用固体力学应力变化方程；获取达西定律方程的变量参数,根据达西定律,调用流体场的达西定律方程；获取多孔介质传热方程的变量参数,根据能量守恒和应用混合规则,调用温度场的多孔介质传热方程；获取成矿的化学反应方程,根据化学反应原理,调用化学场的化学反应方程；获取多孔介质稀物质传递方程的变量参数,根据质量守恒,调用质量传递场的多孔介质稀物质传递方程；根据所述固体力学应力变化方程构建固体力学数值模拟模块,根据所述达西定律方程构建流体数值模拟模块,根据所述多孔介质传热方程构建多孔介质传热数值模拟模块,根据所述化学反应方程构建化学反应数值模拟模块,根据所述多孔介质稀物质传递方程构建多孔介质稀物质传递数值模拟模块。</td>   <td>G06Q50/02;G06Q10/04;G06F30/27;G06F30/28;G06F119/08;G06F119/14;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚正安;                   王锦祥       </td>   <td>中山大学</td>   <td>一种基于缓存机制的图数据划分方法</td>   <td>广东省</td>   <td>CN117421450A</td>   <td>2024-01-19</td>   <td>本发明公开一种基于缓存机制的图数据划分方法,包括获取图数据,根据所述图数据获取图数据的全图顶点数、每个顶点的邻居列表、初始顶点划分集以及初始分区数；计算负载上限；根据顶点及该顶点的邻居列表计算该顶点在每一个当前未达到所述负载上限的顶点集的关联度得分；判断顶点是否满足缓存条件,若满足,根据关联度得分进行划分；若不满足,则将该顶点划分入缓存模块,当缓存模块达到最大容量限制时,缓存模块返回最适合当前进行划分的顶点及其邻居列表,返回；判断是否所有顶点均已被划分完成,如果是,则得到最终的图数据划分集；如果不是,则返回。本发明提高了Fennel算法在图数据规模过大的情况下的划分精度。</td>   <td>1.一种基于缓存机制的图数据划分方法,其特征在于,包括以下步骤：S1：获取图数据,根据所述图数据获取图数据的全图顶点数、每个顶点的邻居列表、初始顶点划分集以及初始分区数,顶点划分集包括若干顶点集；S2：根据图数据的全图顶点数和初始分区数,计算负载上限；S3：根据顶点及该顶点的邻居列表计算该顶点在每一个当前未达到所述负载上限的顶点集的关联度得分；S4：判断顶点是否满足缓存条件,若满足,不进行缓存处理,直接根据关联度得分进行划分；若不满足,则将该顶点划分入缓存模块,当缓存模块达到最大容量限制时,缓存模块返回缓存模块最适合当前进行划分的顶点及其邻居列表,返回步骤S3；S5：判断是否所有顶点均已被划分完成,如果是,则得到最终的图数据划分集；如果不是,则返回步骤S3。</td>   <td>G06F16/901;G06F16/2455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              苏卓;              陈小燕;                   陈伊琳       </td>   <td>中山大学</td>   <td>基于图卷积神经网络和胶囊图神经网络外观专利分类方法</td>   <td>广东省</td>   <td>CN117422902A</td>   <td>2024-01-19</td>   <td>本发明公开了一种基于图卷积神经网络和胶囊图神经网络外观专利分类方法。获取并预处理专利数据集；图片和文本特征提取；构建外观专利的图片-名称-用途-设计要点-设计人图网络,通过自注意力机制传递图中的节点信息,得到更新节点特征的图网络；构建图核算法层对节点特征排序,得到多视角的图特征；胶囊网络将多视角的图特征整理成胶囊的形式,使用动态路由算法得到更高层次的分类胶囊,再通过全连接层和softmax函数实现外观专利的分类。本发明通过使用图卷积网络、图核算法层和胶囊图神经网络,有效地从外观专利的图片和文本数据中提取重要的特征和结构信息。这样的设计可以更好地适应外观专利分类任务的需求,并提高分类性能。</td>   <td>1.一种基于图卷积神经网络和胶囊图神经网络外观专利分类方法,其特征在于,所述方法包括：获取并预处理外观专利数据集,该数据集包含每一个外观专利的图片数据、相应的文本描述数据以及专利类别标签；文本描述数据包括外观专利的名称、用途、设计要点、设计人；从所述图片数据、所述文本描述数据中分别提取外观专利的图片特征、文本特征；文本特征包括名称特征、用途特征、设计要点特征、设计人特征；根据所述图片特征、名称特征、用途特征、设计要点特征、设计人特征,构建外观专利的图片-名称-用途-设计要点-设计人图网络；通过自注意力机制传递图网络中的节点信息,更新图网络中每个节点的特征,得到更新节点特征的图片-名称-用途-设计要点-设计人图网络G；对所述更新节点特征的图片-名称-用途-设计要点-设计人图网络G构建图核算法层,形成移除部分节点的子图网络G″,再对子图网络G″中的节点特征根据节点度数进行排序,得到多视角的图特征；通过胶囊网络将所述多视角的图特征整理成胶囊的形式,使用动态路由算法得到更高层次的图分类胶囊,再通过全连接层和softmax函数实现外观专利的分类,形成外观专利分类模型；设计分类损失作为目标函数,采用梯度下降算法训练所述外观专利分类模型,形成最终的外观专利分类模型；用户输入待分类的外观专利数据集到所述最终的外观专利分类模型中,得到外观专利分类结果。</td>   <td>G06V10/764;G06V30/19;G06N3/0464;G06N5/022</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢宛宜;              郑彬;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于折扣的打车派单方法及系统</td>   <td>广东省</td>   <td>CN117422494A</td>   <td>2024-01-19</td>   <td>本发明涉及互联网约车技术领域,公开了一种基于折扣的打车派单方法,通过乘客自行定义最大忍受接驾距离和期待折扣,利用不同顾客对于等待时间容忍度的差异,对平台设置的全局接驾距离限制范围内的订单不给予任何折扣且调度范围内的汽车进行匹配,对平台设置的全局接驾距离限制范围外的汽车与订单,根据订单的期待折扣以及汽车与订单的匹配情况确定一个统一的折扣来调动该时间窗口内的订单和汽车,让等待时间长的乘客能以更低价格出行,“用折扣换等待时间”,提高了订单与汽车的匹配概率,使更多订单能被服务,提升用户体验。对平台来说,虽然平台给予了顾客折扣,但是因为优化了调度方案,能获取更高的利润。本发明还提供了实现上述方法的系统。</td>   <td>1.一种基于折扣的打车派单方法,其特征在于,包括如下步骤：S1：获取一个时间窗口内的订单集O和车辆集V；所述订单集O的订单包括最大忍受接驾距离和期待折扣；S2：判断订单集O中的订单是否为拼车订单,若为非拼车订单,则进行步骤S3,若为拼车订单,则进行步骤S4至S7；S3：对非拼车订单进行调度,包括：S301:若订单中的pd-(ij)≤pd-0,不给予任何折扣且调度最近的汽车匹配该订单；S302:若pd-0&lt;d-(ij)≤tol-i,根据平台给定的折扣因子不低于订单的期待折扣因子且使平台总利润最大化的原则,输出最优折扣因子的取值和相应的调度结果；其中,pd-0是平台设置的全局接驾距离限制,pd-(ij)是接驾距离,tol-i是客户最大容忍接驾距离限制；S4：调度全局接驾范围内的订单：找到所有在全局接驾距离范围内的订单-汽车对,并将它们放入pool-0中；不给予任何折扣,计算第一即时利润收益,根据第一即时利润收益最大化的原则调度订单；S5：删除订单集O和车辆集V中在步骤S4已被调度的拼车订单以及旅行计划中达到容量限制的汽车,以获得新订单集O’和新车辆集V’；在新订单集O’和新车辆集V’中,找到满足基于订单的期待折扣因子ep-i拼车问题的接驾距离约束和绕道约束的所有订单-汽车对,将它们放入pool中,并计算第二即时利润收益；根据第二即时利润收益最大化的原则调度pool中的订单-汽车对,得到旅行计划S6：设平台给定的折扣因子为γ,若平台给定的折扣因子γ大于或等于订单的期待折扣因子ep-i且平台总利润大于0时,将该平台给定的折扣因子γ视为有效折扣因子γ～1；计算每个有效折扣因子γ～1相应的平台总利润,选出平台总利润最大的有效折扣因子γ-k；S7：根据步骤S6获得的有效折扣因子γ-k,找到满足基于有效折扣因子γ-k的拼车问题的约束条件的所有可行的订单-汽车对,计算第三即时利润收益,根据第三即时利润收益最大化的原则调度pool中订单-汽车对,输出汽车的最终路线规划。</td>   <td>G06Q30/0207;G06Q30/0601;G06Q10/0631;G06Q50/47</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伍伟文;              王堰阳;                   李子荣       </td>   <td>中山大学</td>   <td>基于快速采样得分生成模型的图像重建方法和系统</td>   <td>广东省</td>   <td>CN117422784A</td>   <td>2024-01-19</td>   <td>本发明公开了基于快速采样得分生成模型的图像重建方法和系统,方法包括：获取得分生成模型和有限角度CT图像；通过得分生成模型的前向过程对有限角度CT图像进行注噪处理,生成高斯噪声特征；根据高斯噪声特征,通过得分生成模型的后向过程对有限角度CT图像进行图像重建,生成CT重建图像。本发明大幅度地减少了图像重建的采样步骤,显著地加快采样过程,提高了图像重建的效率和速率,同时在图像重建过程中能够有效地缓解有限角度CT扫描产生的定向伪影的负面影响,在实现快速重建的同时能够保持图像的清晰边缘和细节特征,提高图像重建的质量和效果。本发明应用于图像重建技术领域。</td>   <td>1.基于快速采样得分生成模型的图像重建方法,其特征在于,包括以下步骤：获取得分生成模型和有限角度CT图像；通过所述得分生成模型的前向过程对所述有限角度CT图像进行注噪处理,生成高斯噪声特征；根据所述高斯噪声特征,通过所述得分生成模型的后向过程对所述有限角度CT图像进行图像重建,生成CT重建图像。</td>   <td>G06T11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑蓝翔;              徐恺;              魏明鑫;              周博宇;                   成慧       </td>   <td>中山大学</td>   <td>一种点云压缩方法、解压缩方法及其装置</td>   <td>广东省</td>   <td>CN117409094A</td>   <td>2024-01-16</td>   <td>本发明公开了一种点云压缩方法、解压缩方法及其装置,包括：根据若干个视点获取若干个初始三维点云；按预设点云可见性确定若干个待合并三维点云；将若干个待合并三维点云进行合并,得到三维点云集合；将三维点云集合中包含的若干个初始三维点云映射到球形矩阵,得到点云球形总矩阵；对点云球形总矩阵进行子矩阵提取,得到点云球形子矩阵；将点云球形子矩阵进行频域变换处理,得到频域系数矩阵；对频域系数矩阵进行截断处理,得到截断矩阵；对截断矩阵对应的频域进行二进制转换处理,得到二进制矩阵；将二进制矩阵转换为字节向量,并将字节向量作为目标压缩三维点云；目标压缩三维点云为用于向接收端发送的三维点云数据。</td>   <td>1.一种点云压缩方法,其特征在于,应用于发送端,所述方法包括：确定若干个视点；根据若干个所述视点获取若干个初始三维点云；按预设点云可见性从若干个所述初始三维点云中确定若干个待合并三维点云；将若干个所述待合并三维点云进行合并,得到三维点云集合；将所述三维点云集合中包含的若干个初始三维点云映射到球形矩阵,得到点云球形总矩阵；对所述点云球形总矩阵进行子矩阵提取,得到点云球形子矩阵；将所述点云球形子矩阵进行频域变换处理,得到频域系数矩阵；对所述频域系数矩阵进行截断处理,得到截断矩阵；对所述截断矩阵对应的频域进行二进制转换处理,得到二进制矩阵；将所述二进制矩阵转换为字节向量,并将所述字节向量作为目标压缩三维点云；其中,所述目标压缩三维点云为用于向接收端发送的三维点云数据,所述接收端用于对所述目标压缩三维点云进行解压缩处理,并得到所述目标压缩三维点云中包含的若干个初始三维点云。</td>   <td>G06T9/00;G06T7/194;H04N19/103;H04N19/13;H04N19/132</td>  </tr>        <tr>   <td>中国专利</td>   <td>         侯雪姣;              刘金英;                   黄华兵       </td>   <td>中山大学</td>   <td>水生植被识别方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN117409330A</td>   <td>2024-01-16</td>   <td>本申请涉及一种水生植被识别方法、装置、计算机设备和存储介质。所述方法包括：根据目标湖泊对应的待分析遥感影像数据,确定待分析遥感影像数据对应的目标波段反射率数据；将目标波段反射率数据转换至目标色彩空间,得到待分析遥感影像数据对应的色彩空间色度坐标数据；将色彩空间色度坐标数据输入至预训练的颜色识别模型,得到针对待分析遥感影像数据的颜色识别结果；根据目标波段反射率数据,确定待分析遥感影像数据对应的归一化指数数据和光谱角数据；根据颜色识别结果、归一化指数数据和光谱角数据,确定待分析遥感影像数据对应的水生植被识别结果。采用本方法能够对目标湖泊中的水生植被进行准确识别,提高水生植被的识别效率。</td>   <td>1.一种水生植被识别方法,其特征在于,所述方法包括：根据目标湖泊对应的待分析遥感影像数据,确定所述待分析遥感影像数据对应的目标波段反射率数据；将所述目标波段反射率数据转换至目标色彩空间,得到所述待分析遥感影像数据对应的色彩空间色度坐标数据；将所述色彩空间色度坐标数据输入至预训练的颜色识别模型,得到针对所述待分析遥感影像数据的颜色识别结果；根据所述目标波段反射率数据,确定所述待分析遥感影像数据对应的归一化指数数据和光谱角数据；根据所述颜色识别结果、所述归一化指数数据和所述光谱角数据,确定所述待分析遥感影像数据对应的水生植被识别结果。</td>   <td>G06V20/10;G06T7/90;G06V10/56;G01N21/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李秋萍;              孟辉;                   刘心航       </td>   <td>中山大学</td>   <td>一种基于强化学习的车辆稀疏轨迹重构方法与系统</td>   <td>广东省</td>   <td>CN117407474A</td>   <td>2024-01-16</td>   <td>本发明公开了一种基于强化学习的车辆稀疏轨迹重构方法及系统,该方法包括：获取样本数据集并划分训练数据集和测试数据集；基于所述训练数据集,通过逆强化学习模型生成初始奖励表；引入约束调整所述初始奖励表,得到合成奖励表；确定Q学习模型参数,基于所述合成奖励表和所述测试数据集进行调优,得到调优后的Q学习模型；将待重构的轨迹数据输入至所述调优后的Q学习模型,输出轨迹重构结果。该系统包括：数据集构建模块、逆强化学习模块、奖励表合成模块、Q学习模型调整模块和轨迹重构模块。通过使用本发明,实现稀疏轨迹数据中的轨迹重构,提升稀疏轨迹数据的完整性和准确性。本发明可广泛应用于智能交通领域。</td>   <td>1.一种基于强化学习的车辆稀疏轨迹重构方法,其特征在于,包括以下步骤：获取样本数据集并划分训练数据集和测试数据集；基于所述训练数据集,通过逆强化学习模型生成初始奖励表；引入约束调整所述初始奖励表,得到合成奖励表；确定Q学习模型参数,基于所述合成奖励表和所述测试数据集进行调优,得到调优后的Q学习模型；将待重构的轨迹数据输入至所述调优后的Q学习模型,输出轨迹重构结果。</td>   <td>G06F16/29;G06N20/00;G06N7/01;G06N5/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              叶梓豪;                   刘坤华       </td>   <td>中山大学</td>   <td>一种基于互相关的多传感器数据时间对齐系统及其方法</td>   <td>广东省</td>   <td>CN112580683B</td>   <td>2024-01-12</td>   <td>本发明提供一种基于互相关的多传感器数据时间对齐系统,其中,数据处理模块是对相机传感器和激光雷达传感器的数据进行格式转换,将数据处理模块处理后的数据分别输入视觉帧处理模块、点云帧处理模块,得出图像的三轴角度差序列和点云帧的三轴角度差序列,序列输入模块是能够直接输出三轴角度差序列的传感器,序列对齐模块对各个三轴角度差序列进行对齐处理得出时域对齐的多传感器数据组。本发明还提供一种基于互相关的多传感器数据时间对齐方法。本发明不需要时间戳信息作为参考数据,可以完全基于原始数据本身所包含的信息来进行时间对齐,应用场景更广,可适用于各类的数据采集场景,泛用性更强,准确度更高。</td>   <td>1.一种基于互相关的多传感器数据时间对齐方法,其特征在于：包括以下步骤：S1.数据处理模块将相机传感器获取的数据和激光雷达传感器获取的数据分别转换为图像帧和点云帧；S2.视觉帧处理模块提取图像帧的三轴角度差序列；S3.点云帧处理模块提取点云帧的三轴角度差序列；具体步骤为：S31.对于所有的点云帧进行网格化形成点云；S32.针对两个相邻的点云帧,计算每个网格中所有点的正态分布参数均值q和协方矩阵E；S33.初始化变化参数p,基于步骤S32中正态分布参数均值q和协方矩阵E算出点云帧间转换点的概率密度,得出NDT配准的得分Score；S34.通过优化方法找到score的最大值,得到点云帧间的最优变换T和旋转矩阵R,求解出两帧之间的三轴角度差；S35.对所有相邻的点云帧执行步骤S32-S34,得出三轴角度差序列；S4.序列对齐模块将图像帧的三轴角度差序列、点云帧的三轴角度差序列以及序列输入模块的三轴角度差序列通过互相关方法进行序列对齐,求解各个序列的时间差,完成时间对齐；具体步骤为：S41.根据加权算法及传感器类别选择三轴角度差的权值weight,定义三轴上的互相关值加权和数组cof-on-3-Axis；S42.对各组三轴角度差序列,按照轴为区分,依次计算其加权互相关值并找到当前互相关值,插入互相关值数组cof-on-3-Axis中；S43.遍历所有序列的所有元素,得到完整的互相关值数组cof-on-3-Axis；S44.遍历cof-on-3-Axis数组,找到最大值max-cofs及其下标step,max-cofs即为三轴加权后最大互相关值,step为求出的时间偏移量；S45.通过求解出的时间偏移量,对各传感器原始数据进行简单删减,得到时域对齐的多传感器数据组。</td>   <td>G06V10/62;G06V10/44;G06V10/80;G06T7/246;G06T7/269;G01C21/00;G01C21/16;G01S17/58;G01S17/86;G01S17/88</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              李金膛;              王国倩;                   陈曾平       </td>   <td>中山大学</td>   <td>一种基于脉冲神经网络的SAR图像舰船目标识别方法</td>   <td>广东省</td>   <td>CN113111758B</td>   <td>2024-01-12</td>   <td>本发明提供一种基于脉冲神经网络的SAR图像舰船目标识别方法,该方法采用了基于视觉注意力机制的视觉显著图提取方法,可以增强图像特征、去除相干斑等噪声影响,提高模型泛化能力和鲁棒性；然后,利用泊松编码器对视觉显著图进行步长为T的脉冲编码,得到离散的脉冲时间序列,以便后续的网络进行信息传递；接着,利用卷积神经网络和LIF脉冲神经元构建脉冲神经网络模型,赋予神经网络更好的生物特性,从而能够更准确地模拟大脑的信息传递过程；最后,利用替代梯度训练方法,解决了脉冲神经网络模型难以利用梯度下降和反向传播进行优化的问题；该方法能够准确识别舰船目标,同时兼具有高效节能的优势。</td>   <td>1.一种基于脉冲神经网络的SAR图像舰船目标识别方法,其特征在于,包括以下步骤：S1：进行SAR图像视觉显著图提取和脉冲编码；S2：进行脉冲神经网络模型构建；S3：进行脉冲神经网络模型训练；所述步骤S1中,进行SAR图像视觉显著图提取的过程包括：进行SAR图像亮度信息提取：给定输入图像J,首先利用高斯金字塔对其进行尺度为2的特征图提取,实现图像在水平和垂直方向上尺度逐渐递减的八级下采样过程；每层图像的亮度特征图表示为I(k),其中k∈[0,8]代表图像高斯金字塔结构中的不同层级；在图像中,相邻像素之间在纹理和灰度层面上具有很强的相关性,如果某一像素点与周围像素点差异越大越容易引起视觉注意,成为视觉显著点,引入中央周边差方法对不同尺度分辨率的特征图做进一步处理得到注意力信息；定义为中央周边差算子,亮度特征图的提取过程为将不同层级的特征图缩放到同一尺度后进行逐像素点的相减,该过程表示为：                  其中,c∈{2,3,4},s＝c+δ,δ∈{3,4},表示将第c层的特征图与第s层的特征图进行差值运算。</td>   <td>G06V20/10;G06V10/46;G06V10/764;G06V10/82;G06N3/047;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              殷业熙;                   林淑金       </td>   <td>中山大学</td>   <td>点云数据不均匀的三维重建方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113592711B</td>   <td>2024-01-12</td>   <td>本发明公开了一种点云数据不均匀的三维重建方法。包括：对物体扫描得到一个完整的点集数据,并进行法向量归一化等预处理；对于缺失数据人为增加简要的轮廓线条,得到稀疏点集；利用稀疏点集构造埃米特矩阵并求得法向量；法向量和点集数据计算得到插值函数,之后上采样得到最终点云；进行三角形化的操作,得到最终的三维重建模型。本发明还公开了一种点云数据不均匀的三维重建系统、计算机设备及计算机可读存储介质。本发明使用插值法解决了缺失部分的物体表面重建问题,结合人工草图的形状信息补全,可以自由地在模型缺失部分修改,能够很好地结合实际物体的样本点的几何特征与人工添加草图的特征,得到一个较为完整的重建模型。</td>   <td>1.一种点云数据不均匀的三维重建方法,其特征在于,所述方法包括：使用扫描设备对物体做尽可能全视角的扫描,得到空间中一个完整的点集数据；对所述点集数据进行预处理,并保存为PLY数据格式,并对数据格式中的每个点的法向量进行归一化；对于没有扫描到的缺失数据部分人为增加简要的轮廓线条,得到缺失数据的稀疏点集；利用所述缺失数据的稀疏点集构造埃米特矩阵,再利用该矩阵通过最优化的方法求得所述缺失数据的稀疏点集的法向量；通过所述稀疏点集的法向量和所述稀疏点集的数据来计算得到插值函数,再根据该插值函数上采样增加点云的密度使得与完整数据部分的采样点密度一致,得到缺失数据的最终点云；结合扫描得到的点云以及所述缺失数据的最终点云,进行三角形化的操作,得到最终的三维重建模型。</td>   <td>G06T3/4007;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              刘诗昆;              杨鑫茹;              陈心怡;                   胡芮       </td>   <td>中山大学</td>   <td>一种预测车辆不同驾驶行为对排放影响的方法及系统</td>   <td>广东省</td>   <td>CN117391256A</td>   <td>2024-01-12</td>   <td>本发明公开了一种预测车辆不同驾驶行为对排放影响的方法及系统,包括：构造无信号控制路段人行横道的模糊元胞自动机模型并建立本地化车辆排放因子库；进而对不同的驾驶行为情景进行仿真,得到驾驶行为和驾驶行为对应的车辆逐秒运行参数；结合本地化车辆排放因子库,根据车辆逐秒运行参数计算车辆的第一排放量；根据所有车辆的第一排放量,计算所有车辆在预设时间段内的总排放量；根据第一排放量和总排放量,预测驾驶行为对排放的影响。本发明能够实现评估预测不同驾驶行为对排放的影响,并且由于构造了模糊元胞自动机模型和本地化车辆排放因子库进行评估预测,能考虑单个驾驶员的决策,预测准确率高、效果好,可广泛应用于计算机技术领域。</td>   <td>1.一种预测车辆不同驾驶行为对排放影响的方法,其特征在于,包括：构造无信号控制路段人行横道的模糊元胞自动机模型,并建立本地化车辆排放因子库；采用所述模糊元胞自动机模型,对不同的驾驶行为情景进行仿真,得到驾驶行为和所述驾驶行为对应的车辆逐秒运行参数；结合所述本地化车辆排放因子库,根据所述车辆逐秒运行参数计算所述车辆的第一排放量；根据所有所述车辆的所述第一排放量,计算所述无信号控制路段所有所述车辆在预设时间段内的总排放量；根据所述第一排放量和所述总排放量,预测驾驶行为对排放的影响。</td>   <td>G06Q10/04;G06F30/27;G06N7/02;G06Q50/40;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         冯仕庭;              李雪华;              黄炳升;              毛仁;              叶子茵;              李飞;              王海鹏;                   马锦婷       </td>   <td>中山大学附属第一医院</td>   <td>基于全视野数字切片的克罗恩病和肠结核的检测方法</td>   <td>广东省</td>   <td>CN117392105A</td>   <td>2024-01-12</td>   <td>本申请公开了一种基于全视野数字切片的克罗恩病和肠结核的检测方法,方法包括获取若干全视野数字切片,并且确定每个全视野数字切片对应的若干图像块,将各全视野数字切片对应的若干图像块输入经过训练的检测网络模型,通过所述检测网络模型确定每个全视野数字切片对应的初始预测概率矩阵；基于各全视野数字切片的初始预测概率矩阵,确定所述目标对象的预测结果。本申请通过整合多张全视野数字切片的初始概率来确定患者水平的预测结果,可以实现了通过多层次分类结果来确定患者水平的结果,提高了患者水平的预测精度,从而可以提高克罗恩病和肠结核的检测的准确性。</td>   <td>1.一种基于全视野数字切片的克罗恩病和肠结核的检测方法,其特征在于,所述方法包括：获取若干全视野数字切片,并且确定每个全视野数字切片对应的若干图像块,其中,若干全视野数字切片为同一目标对象的全视野数字切片；对于每个全视野数字切片,将所述全视野数字切片对应的若干图像块输入经过训练的检测网络模型,通过所述检测网络模型确定每个全视野数字切片对应的初始预测概率矩阵；基于各全视野数字切片的初始预测概率矩阵,确定所述目标对象的预测结果,其中,所述预测结果包括克罗恩病类别、肠结核类别或正常组织类别。</td>   <td>G06T7/00;G06V20/69;G06V10/44;G06V10/764;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何坤燕;              温欣;              卢吴柱;              黄涌泉;              陈晓波;              林宇红;                   苏中振       </td>   <td>中山大学附属第五医院</td>   <td>基于深度卷积神经网络的乳腺超声图像分析方法和系统</td>   <td>广东省</td>   <td>CN117392125A</td>   <td>2024-01-12</td>   <td>本发明提供一种基于深度卷积神经网络的乳腺超声图像分析方法和系统,方法包括：获取乳腺超声图像数据集并进行预处理；建立乳腺超声图像分析神经网络模型,该模型包括并列设置的结节图像分割网络和结节类型初步分类网络,以及结节类型二次分类网络；将预处理后的乳腺超声图像数据集输入模型中进行迭代训练；最后获取待分析的乳腺超声图像,并输入训练好的乳腺超声图像分析神经网络模型中,获取结节图像的分割结果和结节类型的二次预测结果,完成乳腺超声图像的分析；本发明将分割任务和分类任务融合为一个任务,能够在不显著增加模型参数的情况下,显著提高模型的特征提取能力和预测结果边缘的平滑,同时提高分析结果的精准度。</td>   <td>1.一种基于深度卷积神经网络的乳腺超声图像分析方法,其特征在于,包括以下步骤：S1：获取乳腺超声图像数据集并进行预处理；S2：建立乳腺超声图像分析神经网络模型；所述乳腺超声图像分析神经网络模型包括并列设置的结节图像分割网络和结节类型初步分类网络,以及结节类型二次分类网络；所述结节图像分割网络和结节类型初步分类网络的输出均与结节类型二次分类网络的输入连接；所述结节图像分割网络用于分割结节图像并提取结节图像的特征图；所述结节类型初步分类网络用于对结节类型进行初步预测；所述结节类型二次分类网络用于将结节图像的特征图与结节类型的初步预测结果进行融合,并进行二次预测,将结节图像的分割结果和结节类型的二次预测结果共同作为乳腺超声图像的分析结果；S3：将预处理后的乳腺超声图像数据集输入乳腺超声图像分析神经网络模型中进行迭代训练,获取训练好的乳腺超声图像分析神经网络模型；S4：获取待分析的乳腺超声图像,将待分析的乳腺超声图像输入训练好的乳腺超声图像分析神经网络模型中,获取结节图像的分割结果和结节类型的二次预测结果,完成乳腺超声图像的分析。</td>   <td>G06T7/00;G06N3/0464;G06V10/26;G06V10/80;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡宏基;              汤育新;              戴英波;                   延敏博       </td>   <td>中山大学附属第五医院</td>   <td>一种基于CT三维输尿管支架重建区域的附壁结石检测方法</td>   <td>广东省</td>   <td>CN117392195A</td>   <td>2024-01-12</td>   <td>本发明公开了一种基于CT三维输尿管支架重建区域的附壁结石检测方法,涉及医疗机器技术领域,包括如下步骤：从获取的二维CT影像序列重建生成三维矩阵数据；重采样后,提取输尿管支架的中心线,结合三维矩阵数据将输尿管支架划分K、U、B三个区域,得到U区域的有序中心点,与K、B区域的无序中心点；对U区域的有序中心点进行重切片,得到U区域的连续重切片序列；再进行异常面积区域检测,得到U区域的附壁结石区域；对K、B区域的无序中心点排序,得到K、B区域的分段连续中心点序列,再进行重切片,得到K、B区域的分段连续重切片序列,再进行分段凸起检测,得到K、B区域的附壁结石区域。本发明提高了输尿管支架附壁结石检测的准确率。</td>   <td>1.一种基于CT三维输尿管支架重建区域的附壁结石检测方法,其特征在于：包括步骤如下：从获取的二维CT影像序列中检测出的输尿管支架区域重建生成三维矩阵数据；根据获取的二维CT影像序列的生成间隔进行重采样后,提取输尿管支架的中心线,结合三维矩阵数据将输尿管支架划分K、U、B三个区域,得到U区域的有序中心点,与K、B区域的无序中心点；对U区域的有序中心点进行重切片,得到U区域的连续重切片序列；对U区域的连续重切片序列进行异常面积区域检测,得到U区域的附壁结石区域；对K、B区域的无序中心点排序,得到K、B区域的分段连续中心点序列；对K、B区域的分段连续中心点序列进行重切片,得到K、B区域的分段连续重切片序列；对K、B区域的分段连续重切片序列进行分段凸起检测,得到K、B区域的附壁结石区域。</td>   <td>G06T7/593;G06T7/00;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王伟;              李铭德;              佘超银;              陈立达;              黄庆华;              柯伟平;                   何丹妮       </td>   <td>中山大学附属第一医院</td>   <td>一种超声人工智能图像分析预处理方法及系统</td>   <td>广东省</td>   <td>CN117392413A</td>   <td>2024-01-12</td>   <td>本发明公开了一种超声人工智能图像分析预处理方法及系统,包括如下步骤：超声图像采集：使用超声设备对患者进行检查,获取超声图像；AI图像脱敏：采用人工智能算法对超声图像进行脱敏处理；像素级别语义分割标记及去除：利用像素级别的语义分割算法对步骤S2脱敏处理后的超声图像上的测量标尺进行识别、标记和去除；标准化图像生成：对步骤S3处理后的超声图像进行标准化处理,得到经过脱敏和去除标记的标准化超声图像。本发明能够获取超声人工智能图像分析预处理的标准化图像,能够提高图像处理的效率和准确性,为医学诊断提供更加可靠的依据。</td>   <td>1.一种超声人工智能图像分析预处理方法,其特征在于,包括如下步骤：步骤S1,超声图像采集：使用超声设备对患者进行检查,获取超声图像；步骤S2,AI图像脱敏：采用人工智能算法对超声图像进行脱敏处理；步骤S3,像素级别语义分割标记及去除：利用像素级别的语义分割算法对步骤S2脱敏处理后的超声图像上的测量标尺进行识别、标记和去除；步骤S4,标准化图像生成：对步骤S3处理后的超声图像进行标准化处理,得到经过脱敏和去除标记的标准化超声图像。</td>   <td>G06V10/72;G06V10/26;G06V10/82;G06V20/70;G06F21/62;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张丽丹;                   任勇       </td>   <td>中山大学附属第七医院(深圳);电子科技大学(深圳)高等研究院</td>   <td>一种用于PICU脓毒症患儿死亡风险的预测方法及系统</td>   <td>广东省</td>   <td>CN117393144A</td>   <td>2024-01-12</td>   <td>本发明公开了一种用于PICU脓毒症患儿死亡风险的预测方法及系统,属于人工智能和医疗技术领域,包括：采集PICU脓毒症患儿的指标数据,构建用于表征PICU脓毒症患儿死亡风险的先验知识模型,进而获取导致PICU脓毒症患儿健康变化的特征指标,以及特征指标对应的临床结局指标,对指标数据进行标注,生成数据集；基于ANN神经网络模型,在模型编译时采用Adam优化器,以及采用binary-crossentropy二分类交叉熵作为训练损失函数,通过数据集进行模型训练,构建人工智能预测模型,对PICU脓毒症患儿死亡风险进行预测；本发明实现了智能AI在PICU的临床应用,并提升了脓毒症患儿死亡风险的预测准确性。</td>   <td>1.一种用于PICU脓毒症患儿死亡风险的预测方法,其特征在于,包括以下步骤：采集PICU脓毒症患儿的指标数据,构建用于表征PICU脓毒症患儿死亡风险的先验知识模型；基于所述先验知识模型,通过获取导致PICU脓毒症患儿健康变化的特征指标,以及所述特征指标对应的临床结局指标,对所述指标数据进行标注,生成数据集；基于ANN神经网络模型,在模型编译时采用Adam优化器,以及采用binary-crossentropy二分类交叉熵作为训练损失函数,通过所述数据集进行模型训练,构建人工智能预测模型,对PICU脓毒症患儿死亡风险进行预测。</td>   <td>G16H50/20;G16H50/30;G06F18/2433;G06F18/214;G06F18/21;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚和瑞;              汪颖;              赵健丽;                   余运芳       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>晚期乳腺癌生存概率预测列线图、生存概率预测方法及患者分类方法</td>   <td>广东省</td>   <td>CN111354462B</td>   <td>2024-01-09</td>   <td>本发明提供晚期乳腺癌生存概率预测列线图、生存概率确定方法以及患者分类方法,其中的列线图包括分值标尺,还包括若干个的预后变量,均为分类变量,包括乳腺癌分期变量、乳腺癌分子分型变量、患者无疾病复发时间变量、肿瘤负荷变量和脑转移变量；每一个预后变量均包括若干个变量取值,每一个变量取值对应分值标尺上的一个分值；还包括总分值标尺和患者生存概率变量,均为连续性变量,包括一年生存概率变量,两年生存概率变量和三年生存概率变量；每个生存概率变量均包括变量取值范围,每一个变量取值范围均有对应总分值标尺上的一个分值范围；不仅考虑了医疗科学发展,同时考虑国内患者的需求,从而提高了对晚期乳腺癌的各项评估精准度。</td>   <td>1.一种晚期乳腺癌生存概率确定方法,其特征在于,在列线图中,根据患者的具体情况,在每一个所述列线图的预后变量中选择一个变量取值,将所有被选择的变量取值对应分值标尺的分值相加得到总分值,确定所述总分值对应总分值标尺的分值,确定所述总分值标尺的分值对应的一年生存概率变量上的变量取值作为患者1年后的生存概率、两年生存概率变量上的变量取值作为患者2年后的生存概率,以及三年生存概率变量上的变量取值作为患者3年后的生存概率；所述列线图包括分值标尺,其分值范围为0～10；所述列线图还包括若干个的预后变量,所述预后变量均为分类变量,包括乳腺癌分期变量、乳腺癌分子分型变量、患者无疾病复发时间变量、肿瘤负荷变量和脑转移变量；所述乳腺癌分期指患者首次诊断乳腺癌的分期,所述患者无疾病复发时间指从患者早期乳腺癌诊断时间到首次发生复发、转移或者死亡事件之间的时间；每一个所述预后变量均包括若干个变量取值,每一个所述变量取值均有对应所述分值标尺上的一个分值；所述乳腺癌分期变量包括2个变量取值,分别为乳腺癌I/II期和乳腺癌III/IV期,所述乳腺癌I/II期的分值对应所述分值标尺中的0,所述乳腺癌III/IV期的分值对应所述分值标尺中的1；所述乳腺癌分子分型变量包括3个变量取值,分别为HR+/HER2-、HER2+和TNBC,所述HR+/HER2-的分值对应分值标尺中的0,所述HER2+的分值对应分值标尺中的2,所述TNBC的分值对应分值标尺中的5；所述患者无疾病复发时间变量包括3个变量取值,分别为大于48个月、在24～48个月之间以及小于24个月,所述大于48个月的分值对应分值标尺中的0,所述在24～48个月之间的分值对应分值标尺中的1,所述小于24个月的分值对应分值标尺中的2；所述肿瘤负荷变量包括3个变量取值,分别为单纯复发、寡转移和多发转移,所述单纯复发的分值对应分值标尺中的0,所述寡转移的分值对应分值标尺中的5,所述多发转移的分值对应分值标尺中的10；所述脑转移变量包括2个变量取值,分别为存在脑转移和无脑转移,所述无脑转移的分值对应分值标尺中的0,所述存在脑转移的分值对应分值标尺中的3；所述列线图还包括总分值标尺,其分值范围为0～22,根据患者的情况在所述列线图的每个预后变量中选择一个变量取值后,将每一个被选择的变量取值的分值相加得到的总分值可对应所述总分值标尺上的分值；所述列线图还包括患者生存概率变量,所述患者生存概率变量均为连续性变量,所述患者生存概率变量包括一年生存概率变量,两年生存概率变量和三年生存概率变量；每一个所述患者生存概率变量均包括一个变量取值范围,每一个所述患者生存概率变量的变量取值范围均有对应所述总分值标尺上的一个分值范围；所述一年生存概率变量的变量取值的范围为0.4～0.9,对应所述总分值标尺中的分值范围12.4～21.6,其中一年生存概率变量的取值为0.4对应的分值范围为21.2～21.6,一年生存概率变量的取值为0.9对应的分值范围为12.4～12.8；所述两年生存概率变量的变量取值的范围为0.1～0.9,对应所述总分值标尺中的分值范围6～18.8,其中两年生存概率变量的取值为0.1对应的分值范围为18.4～18.8,两年生存概率变量的取值为0.9对应的分值范围为6～6.4；所述三年生存概率变量的变量取值的范围为0.1～0.9,对应所述总分值标尺中的分值范围3.2～16,其中三年生存概率变量的取值为0.1对应的分值范围为15.6～16,三年生存概率变量的取值为0.9对应的分值范围为3.2～3.6；所述分值标尺、每个所述预后变量、所述总分值标尺以及每个所述患者生存概率变量在所述列线图中各占一行,每个所述预后变量的所有变量取值与该预后变量在同一行,每个所述患者生存概率变量的变量取值范围与该患者生存概率变量在同一行。</td>   <td>G16H50/20;G16H50/30;G16H50/70;G06F18/2415</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              林格;              陈小燕;                   林谋广       </td>   <td>中山大学</td>   <td>一种基于案件相似度匹配的审判风险预警方法</td>   <td>广东省</td>   <td>CN111709236B</td>   <td>2024-01-09</td>   <td>本发明公开了一种基于案件相似度匹配的审判风险预警方法。本发明对法律文本进行word2vec词向量嵌入,并将关键词用词向量进行表示,使用余弦相似度来计算不同案件之间的相似度。当获得与案件相关联的多种案件之后,基于关键词抽取的技术找出其判决结果,智能化给出本案件合理的判决结果范围,当实际判决结果与推荐判决范围差别过大时及时进行智能预警。本发明使用了一种基于自然语言理解的类案提取和风险预警技术,拓展了类案提取的广度；使用了人工智能中的自然语言理解方法,可提取出更具有深层语义的案件；在风险预警方面,大大减轻了人力负担,充分挖掘了历史电子案宗和判决结果之间的联系信息,使得法官判决时具有更便捷的参考。</td>   <td>1.一种基于案件相似度匹配的审判风险预警方法,其特征在于,所述方法包括：步骤一：从法律判决书信息管理系统中获取近3年来的法院判决书,使用关键词匹配的方法,提取出对应的案件描述、裁决结果；步骤二：对提取的案件数据进行文本的预处理,得到案件文本的训练语料；步骤三：运用word2vec方法对预处理生成的案件文本语料进行词向量的训练,对每一个出现在语料中的单词都得到一个词向量,每个词向量具有d的维度；步骤四：在使用关键词匹配抽取得到的案件描述、判决结果中分别抽取k-1和k-2个高频词语作为本篇判决书的关键词,分别计算其TF-IDF词频,并取出其训练后得到的向量组,计算得到加权平均向量；此时第i篇判决书由两个维度为d的向量表示,分别是案件描述向量和判决结果向量；步骤五：从数据库系统中提取出当前案件的案件描述和判决结果,按照步骤一至步骤四进行处理,从而获取当前的案件判决书的案件描述向量和判决结果向量；步骤六：将步骤五获得的当前案件描述向量与步骤四中获得的历史案件描述向量进行矩阵点乘,计算当前判决书与数据库中每一个判决书的案件描述相似度；步骤七：将步骤六获取的文本相似度进行排序,选取相似度较高的M个案件,找到其判决结果向量；步骤八：对步骤七获得的M个案件的判决结果向量,与当前案件的判决结果向量进行点乘,得到不同案件判决结果的相似度；步骤九：计算步骤八获得的当前案件与历史案件的判决结果相似度的平均值,该平均值求倒数得到当前判决结果的风险值,当风险值大于阈值时,系统启动风险预警。</td>   <td>G06F40/289;G06F40/284;G06F40/216;G06F18/22;G06Q50/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              王金鹏;              蔡佳辉;              林佳玲;                   陈嘉敏       </td>   <td>中山大学;广州智慧城市发展研究院</td>   <td>一种基于相似性损失的行为识别方法</td>   <td>广东省</td>   <td>CN111339886B</td>   <td>2024-01-09</td>   <td>本发明涉及计算机视觉识别领域,公开了一种基于相似性损失的行为识别方法,涉及计算机视觉识别领域。该行为识别方法包括步骤：将视频片段输入前馈网络,得到特征图以及对应的分类概率；计算任意两个配对样本的预测结果,根据预测结果计算分布之间的成对距离；根据成对距离和交叉熵损失计算整个的相似性损失。本发明的方法提出了一种新的相似性损失用来指导整个网络的学习目标,相似性损失可以简单的集成在任意一个基础网络之中,在没有额外引入参数和没有额外开销的前提下,该方法在数据集上取得了最优效果,验证了相似性损失的有效性。</td>   <td>1.一种基于相似性损失的行为识别方法,其特征在于,包括以下步骤：S1、将视频片段输入前馈网络,得到特征图以及对应的分类概率；S2、计算任意两个配对样本的预测结果,根据预测结果计算分布之间的成对距离；S3、根据成对距离和交叉熵损失计算整个的相似性损失；其中,在所述步骤S2中,将两个输入视频样本x-1和x-2的条件概率分布记为p-θ(y|x-1),p-θ(y|x-2),共享相同的类,当模型参数为θ时为,两个输入视频样本x-1和x-2的成对距离为：D-(PD)(p-θ(y|x-1),p-θ(y|x-2))＝||p-θ(y|x-2)-p-θ(y|x-1)||-2；样本相似性损失为：          其中,λ为权重超参数,设定为1e-2,在类别一致时,γ(y-1,y-2)＝1；其中,D-(PD)表示两个输入视频样本x-1和x-2的成对距离；Lpair表示两个成对视频样本之间的距离,即样本的相似性损失；p-θ表示模型参数为θ的输入视频样本的条件概率分布；y表示视频样本的类别特征；y1表示视频样本x-1的类别特征,y2表示视频样本x-2的类别特征；其中,在所述步骤S3中,采用最小批梯度下降法对相似性损失进行集成,从每个训练集中随机抽取数目与批大小的数值相同的样本进行迭代；所述最小批梯度下降法的具体步骤为：S31、首先确定训练集合D以及人工设定的超参数θ～*,初始化配对损失以及根据预训练模型读入模型参数；S32、对于数据集D中的所有样本,根据类别标签构造两两配对关系,并定义和计算配对损失,将配对损失保留；S33、根据每个样本的计算结果,计算交叉熵损失；S34、根据设定的超参数θ～*计算整个网络的损失,而后进行反向传播,更新整个模型的参数。</td>   <td>G06V40/20;G06V20/40;G06V10/74;G06V10/82;G06N3/0499;G06N3/084;G06N3/0985</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖雨珊;              余建兴;              印鉴;              陈自豪;              田海川;                   蔡泽彬       </td>   <td>中山大学</td>   <td>一种面向虚拟现实的多源融合情感支持对话方法</td>   <td>广东省</td>   <td>CN117370534A</td>   <td>2024-01-09</td>   <td>本发明公开了一种面向虚拟现实的多源融合情感支持对话方法,涉及人工智能的技术领域,包括获取用户实时交互的文本信息、音频信息和眼动信息,分别进行特征提取操作,获得文本特征向量、语音特征向量和眼动特征向量；之后三种模态的特征向量进行特征融合,获得情绪表征向量；最后将所述文本特征向量和情绪特征向量输入预设的解码器中,生成对话回复文本,本发明克服了从单一文本模态抽取情感特征具有不确定性的问题,充分分析用户情绪,生成高质量的、贴合真实对话场景的情感对话,提高用户的交互体验。</td>   <td>1.一种面向虚拟现实的多源融合情感支持对话方法,其特征在于,包括：S1：采集用户的语音信息和眼动信息,并从所述语音信息中提取文本信息和音频信息；S2：分别对所述文本信息、音频信息和眼动信息进行特征提取操作,对应获得文本特征向量、语音特征向量和眼动特征向量；S3：对所述文本特征向量、语音特征向量和眼动特征向量进行特征融合操作,获得情绪表征向量；S4：将所述文本特征向量和情绪特征向量输入预设的解码器中,生成对话回复文本。</td>   <td>G06F16/332;G06F16/33;G06F18/22;G06F18/25;G06N3/0442</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              王若梅;              林格;                   张富为       </td>   <td>中山大学</td>   <td>一种具有可解释性和知识启发能力的视频问答方法与系统</td>   <td>广东省</td>   <td>CN117370608A</td>   <td>2024-01-09</td>   <td>本发明公开了一种具有可解释性和知识启发能力的视频问答方法与系统。包括：将视频输入VGG网络和I3D网络提取视频特征序列；将用户问题输入BERT网络提取问题向量表示；将视频特征序列和问题向量表示输入交叉Transformer网络和贝叶斯可微的神经网络,得到视频场景的因果表示；将问题向量表示和视频场景的因果表示输入GPT-3模型中,通过该模型的编码-解码结构生成知识引导的问题表示；将知识引导的问题表示输入Transformer解码网络得到用户问题的答案；通过自注意力机制、可视化工具和解释性描述,将所述知识引导的问题表示和所述用户问题的答案可视化。本发明能够提高视频问答模型的准确性、解释性和鲁棒性,从而提升用户体验和应用的实用性。</td>   <td>1.一种具有可解释性和知识启发能力的视频问答方法,其特征在于,所述方法包括：将视频输入VGG网络和I3D网络提取视频特征序列；将用户问题输入BERT网络提取问题向量表示；将所述视频特征序列和所述问题向量表示输入交叉Transformer网络和贝叶斯可微的神经网络,得到视频场景的因果表示；将所述问题向量表示和所述视频场景的因果表示输入GPT-3模型中,通过该模型的编码-解码结构生成知识引导的问题表示；将所述知识引导的问题表示输入Transformer解码网络得到所述用户问题的答案；通过自注意力机制、可视化工具和解释性描述,将所述知识引导的问题表示和所述用户问题的答案可视化为易于用户理解的答案选择和生成的合理解释。</td>   <td>G06F16/783;G06F16/732;G06V20/40;G06V10/82;G06N3/0455;G06N3/042;G06N3/047;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘帆;              戴宪华;                   莫康晓       </td>   <td>中山大学</td>   <td>基于CRF与多样式MRC的长跨度命名实体识别方法及系统</td>   <td>广东省</td>   <td>CN117371449A</td>   <td>2024-01-09</td>   <td>本发明涉及AI命名实体识别技术领域,为基于CRF与多样式MRC的长跨度命名实体识别方法及系统,其方法包括：获取需要命名实体识别的文本数据,作为训练数据；计算条件随机场CRF和机器阅读理解MRC的交叉熵,根据所计算的交叉熵获得模型的损失函数,通过损失函数训练模型；构建多样化查询生成器；通过CRF与softmax函数预测实体类型,通过线性层与softmax函数预测实体跨度；通过投票合并机制将实体类型和实体跨度合并再解码,识别得到最终的实体预测答案。本发明通过CRF模型完成实体分类,再通过多样式MRC完成实体提取,可以避免较高的模型耦合度,显著提高了模型的解码效率、召回率和识别精度,解决了传统序列模型难以有效识别长跨度命名实体的问题。</td>   <td>1.一种基于CRF与多样式MRC的长跨度命名实体识别方法,其特征在于,包括以下步骤：获取需要命名实体识别的文本数据,作为训练数据；计算条件随机场CRF和机器阅读理解MRC的交叉熵,根据所计算的交叉熵获得模型的损失函数,通过损失函数训练模型；构建多样化查询生成器；通过CRF与softmax函数预测实体类型,通过线性层与softmax函数预测实体跨度；通过投票合并机制将实体类型和实体跨度合并再解码,识别得到最终的实体预测答案。</td>   <td>G06F40/295</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;              李梦迪;              张易东;              倪晓升;              蒋燕梅;              吕雅丽;              熊宇涵;              秦小营;              谢雨琪;              冼军;                   成诚       </td>   <td>中山大学</td>   <td>一种无人机协同决策的评价方法、系统、设备和介质</td>   <td>广东省</td>   <td>CN117371655A</td>   <td>2024-01-09</td>   <td>本发明公开了一种无人机协同决策的评价方法、系统、设备和介质,涉及计算机装备研发与保障技术领域。通过获取无人机协同决策方案,将无人机协同决策方案进行任务综合分析,得到任务分析数据。采用任务分析数据更新初始协同决策自评价体系框架,得到目标协同决策自评价体系框架。采用目标协同决策自评价体系框架,结合无人机协同决策方案对应的环境态势,构建在线评价指标。基于在线评价指标和初始动态贝叶斯网络在线评价模型进行决策评价,得到无人机协同决策方案对应的评价结果。通过建立完备的协同决策自评价体系,有效解决了决策的定量评价问题,提高地面控制站对无人机任务的控制能力和决策水平。</td>   <td>1.一种无人机协同决策的评价方法,其特征在于,包括：获取无人机协同决策方案,将所述无人机协同决策方案进行任务综合分析,得到任务分析数据；采用所述任务分析数据更新初始协同决策自评价体系框架,得到目标协同决策自评价体系框架；采用所述目标协同决策自评价体系框架,结合所述无人机协同决策方案对应的环境态势,构建在线评价指标；基于所述在线评价指标和初始动态贝叶斯网络在线评价模型进行决策评价,得到所述无人机协同决策方案对应的评价结果。</td>   <td>G06Q10/063;G06Q50/26;G06N7/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;              秦小营;              倪晓升;              张易东;              蒋燕梅;              吕雅丽;              熊宇涵;              冼军;                   成诚       </td>   <td>中山大学</td>   <td>一种飞行器群协同决策生成方法、系统和设备</td>   <td>广东省</td>   <td>CN117371812A</td>   <td>2024-01-09</td>   <td>本发明公开了一种飞行器群协同决策生成方法、系统和设备,涉及飞行器技术领域。通过采用预设密度峰值聚类算法计算事件伪标签,基于事件伪标签集训练初始事件抽取模型,得到目标事件抽取模型。通过目标事件抽取模型分别对飞行器群数据集和地面控制站数据集进行事件抽取并进行事件比对,得到方案比对结果。当方案比对结果为不一致时,根据飞行器群对应的授权数据和预设改进的多智能体深度确定性策略梯度算法进行最优指令序列选取,得到飞行器群协同决策。当方案比对结果为一致时,将飞行器群方案作为飞行器群协同决策。基于事件伪标签微调初始事件抽取模型,进而抽取事件,快速把握飞行环境整体态势,制定出相应方案来应对突发状况。</td>   <td>1.一种飞行器群协同决策生成方法,其特征在于,包括：当接收到飞行器群的突发状况数据时,采用预设密度峰值聚类算法计算所述突发状况数据对应的飞行器群数据集和地面控制站生成的地面控制站数据集对应的事件伪标签,得到事件伪标签集；基于所述事件伪标签集训练初始事件抽取模型,得到目标事件抽取模型；通过所述目标事件抽取模型分别对所述飞行器群数据集和所述地面控制站数据集进行事件抽取并进行事件比对,得到方案比对结果；当方案比对结果为不一致时,根据所述飞行器群对应的授权数据和预设改进的多智能体深度确定性策略梯度算法进行最优指令序列选取,得到所述突发状况数据对应的飞行器群协同决策方案；当方案比对结果为一致时,将所述飞行器群数据集中的飞行器群方案作为所述突发状况数据对应的飞行器群协同决策方案。</td>   <td>G06Q10/0637;G06F18/23;G06F18/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洁旻;              蔡铭;                   陈依琳       </td>   <td>中山大学</td>   <td>一种列车售票方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117371840A</td>   <td>2024-01-09</td>   <td>本发明公开了一种列车售票方法、装置、电子设备及存储介质,本发明通过考虑乘客座位偏好辅助售票方案设计,以期通过确定车票分配份额及分批放票时间,使得结伴出行的乘客有更大的机会买到邻座票,且尽量减少余票量,提高购票成功率,避免现有售票方案的设计方法所带来的弊端,从而使得列车售票更加人性化,提高乘客的满意度,尤其是结伴出行乘客的满意度。本发明实施例能帮助结伴出行的乘客购买到想要的邻座票,提高乘客满意度,同时能够减少了余票量,提升了座位的使用率,可广泛应用于计算机技术领域。</td>   <td>1.一种列车售票方法,其特征在于,包括：获取列车和乘客信息,进行数据抽象,获得起讫点对矩阵；基于所述起讫点对矩阵,通过预设约束条件生成初步售票方案集合；根据所述起讫点对矩阵中的起讫点数量,确定需求情景集合；根据所述初步售票方案集合和所述需求情景集合,迭代进行乘客购票模拟,获得第二售票方案集合,并确定所述第二售票方案集合中各售票方案的评价指标值；所述第二售票方案集合包括若干模拟售票方案；当相邻两次迭代的所述第二售票方案集合中所述评价指标值最小的所述模拟售票方案相同且最小的所述评价指标值小于预设阈值,确定相同的所述模拟售票方案为目标售票方案；或,当达到预设迭代次数,根据最后一次迭代得到的所述第二售票方案集合中所述评价指标值最小的所述模拟售票方案作为目标售票方案。</td>   <td>G06Q10/0639;G06Q30/0601;G06Q50/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵毓斌;                   梁伟锡       </td>   <td>中山大学</td>   <td>基于移动方差自适应阈值的混合活动数据分割方法及系统</td>   <td>广东省</td>   <td>CN117372448A</td>   <td>2024-01-09</td>   <td>本发明公开了基于移动方差自适应阈值的混合活动数据分割方法及系统,该方法包括：获取CSI数据并进行数据预处理,构建预处理后的CSI矩阵；对预处理后的CSI矩阵依次进行滑动窗口方差计算与平滑处理,得到多个平滑后的滑动窗口线性差值；通过移动方差自适应阈值算法对多个平滑后的滑动窗口线性差值进行分割处理,得到分割后的CSI数据。本发明通过移动方差自适应阈值算法能够准确识别不同活动的开始点和结束点,提高活动数据的分割精度。本发明作为基于移动方差自适应阈值的混合活动数据分割方法及系统,可广泛应用于活动数据分割技术领域。</td>   <td>1.基于移动方差自适应阈值的混合活动数据分割方法,其特征在于,包括以下步骤：获取CSI数据并进行数据预处理,得到预处理后的CSI矩阵,所述CSI数据表示混合活动数据；对所述预处理后的CSI矩阵依次进行滑动窗口方差计算、差分计算和平滑处理,得到多个平滑后的滑动窗口线性差值；通过移动方差自适应阈值算法对多个所述平滑后的滑动窗口线性差值进行分割处理,得到分割后的CSI数据。</td>   <td>G06T7/11;G06T7/136;G06T5/70;G06V40/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         段凯;              方晨琦;              吕志朋;              钟启瑞;              袁亘宇;              郑籽盈;                   陈菁       </td>   <td>中山大学</td>   <td>基于SAM图像分割模型的水体水位监测方法</td>   <td>广东省</td>   <td>CN117372451A</td>   <td>2024-01-09</td>   <td>本发明涉及水文测验技术领域,尤其涉及一种基于SAM图像分割模型的水体水位监测方法,包括：对采集的水尺图像进行空间校正,得到水尺校正图像；以视觉自注意力机制为框架,建立用于水尺图像分割的SAM图像分割模型；获取水尺校正图像上的提示点信息,并将水尺校正图像和提示点信息输入SAM图像分割模型,得到水尺区域分割结果；建立掩码像素与实测水位之间的水位测量模型,并利用水位测量模型对水尺区域分割结果进行处理,得到测量水位值。本发明通过SAM图像分割模型实现水位的自动监测,解决了现有图像识别水位方法鲁棒性和适用性较差的问题,提高了水位监测的准确性和长期稳定性,降低了监测成本。</td>   <td>1.一种基于SAM图像分割模型的水体水位监测方法,其特征在于,包括以下步骤：采集水尺图像,对所述水尺图像进行空间校正,得到水尺校正图像；以视觉自注意力机制为框架,建立用于水尺图像分割的SAM图像分割模型；获取所述水尺校正图像上的提示点信息,并将所述水尺校正图像和所述提示点信息输入所述SAM图像分割模型,得到水尺区域分割结果；建立掩码像素与实测水位之间的水位测量模型,并利用所述水位测量模型对所述水尺区域分割结果进行处理,得到测量水位值。</td>   <td>G06T7/11;G01F23/00;G01F23/04;G06V10/26;G06T3/02;G06T5/80;G06N3/0464;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         池浩鑫;              陆智超;              廖国成;                   郑子彬       </td>   <td>中山大学</td>   <td>图像特征提取方法、装置、存储介质及设备</td>   <td>广东省</td>   <td>CN117372758A</td>   <td>2024-01-09</td>   <td>本申请提供图像特征提取方法、装置、存储介质及设备,包括：步骤S101获取待处理的图像,并将所述待处理的图像切割为多个图像块；步骤S102获取各个图像块的全局注意力得分和位置信息；步骤S103将所述图像块及各个图像块的全局注意力得分输入基于自注意力机制单元,更新各个图像块的全局注意力得分；步骤S104将更新后的各个图像块的全局注意力得分和位置信息输入剪枝单元对所述图像块进行融合-细分处理,得到更新后的图像块；步骤S105重复步骤S103和步骤S104达到预设次数后,输出待处理图像的特征向量。得到多个粒度的图像块,对重要的图像信息进行细分处理,不重要的信息进行融合处理,减少计算量的同时提高效率。</td>   <td>1.一种图像特征提取方法,其特征在于,包括：步骤S101,获取待处理的图像,并将所述待处理的图像切割为多个图像块；步骤S102,获取各个图像块的全局注意力得分和位置信息；步骤S103,将所述图像块及各个图像块的全局注意力得分输入基于自注意力机制单元,更新各个图像块的全局注意力得分；步骤S104,将更新后的各个图像块的全局注意力得分和位置信息输入剪枝单元对所述图像块进行融合-细分处理,得到更新后的图像块；步骤S105,重复步骤S103和步骤S104达到预设次数后,输出待处理图像的特征向量。</td>   <td>G06V10/764;G06V10/42;G06V10/26;G06V10/80;G06V10/82;G06N3/0499</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丛玉来;                   李思佳       </td>   <td>中山大学</td>   <td>一种可应对数据残缺场景下图像分类与生成的统一学习框架</td>   <td>广东省</td>   <td>CN117372803A</td>   <td>2024-01-09</td>   <td>本发明公开了一种数据残缺场景下的图像分类和生成模型的训练方法,获取原始图像的标签和图像信息；将图像信息输入VQ-VAE进行处理后得到第一离散信息,将标签和图像信息输入数据处理模型后得到第二离散信息；基于第二离散信息构建初始Big Learning模型；基于第一离散信息训练初始Big Learning模型得到最终Big Learning模型。通过VQ-VAE处理得到第一离散信息,并将通过数据处理模型得到的第二离散信息,能够在数据的缺失或者不完整的场景下训练得到准确识别图像中物体和特征的Big Learning模型,从而提高图像分类和生成的准确性,可广泛应用于计算机数据处理技术领域。</td>   <td>1.一种数据残缺场景下的图像分类和生成模型的训练方法,其特征在于,包括：获取原始图像的标签和图像信息；将所述图像信息输入VQ-VAE进行处理后得到第一离散信息,所述VQ-VAE用于将所述图像信息转换为编码信息；将所述标签和所述图像信息输入数据处理模型后得到第二离散信息,所述数据处理模型用于分别对所述标签和所述图像信息进行编码处理得到标签编码和图像编码,所述第二离散信息包括所述标签编码和所述图像编码；基于所述第二离散信息构建初始Big Learning模型,所述初始Big Learning模型表征图像分类和生成模型,所述第二离散信息通过随机遮掩率遮掩后构建所述初始BigLearning模型；基于所述第一离散信息训练所述初始Big Learning模型得到最终Big Learning模型。</td>   <td>G06V10/774;G06V10/764;G06V10/82;G06N3/0464;G06N3/0455;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         衡益;              黄明鸣;                   罗玖       </td>   <td>中山大学</td>   <td>一种池沸腾过程识别方法及模型训练方法、装置、设备</td>   <td>广东省</td>   <td>CN117372920A</td>   <td>2024-01-09</td>   <td>本公开实施例涉及一种池沸腾过程识别方法及模型训练方法、装置、设备。前述方法的主要步骤包括：获取容器内流体的目标图像,目标图像包括目标对象所对应的多个区域图像,目标对象包括气泡、气膜和池沸腾流体受热产生的液体膜中的至少一类对象,确定多个区域图像所对应的目标对象的几何属性数值,根据几何属性数值,对多个区域图像分组,提取每组区域图像的特征数据,将每组区域图像的特征数据输入预先训练好的识别模型中,输出池沸腾过程的识别结果,识别模型为根据多个池沸腾样本数据获得的训练数据集训练得到的机器学习模型。采用前述方法能够提高池沸腾过程识别的准确度和识别效率。</td>   <td>1.一种池沸腾过程识别方法,其特征在于,所述方法包括：获取容器内流体的目标图像,所述目标图像包括目标对象所对应的多个区域图像,所述目标对象包括气泡、气膜和池沸腾流体受热产生的液体膜中的至少一类对象；确定所述多个区域图像所对应的目标对象的几何属性数值；根据所述几何属性数值,对所述多个区域图像分组；提取每组区域图像的特征数据；将每组区域图像的特征数据输入预先训练好的识别模型中,输出池沸腾过程的识别结果,所述识别模型为根据多个池沸腾样本数据获得的训练数据集训练得到的机器学习模型。</td>   <td>G06V20/40;G06V10/26;G06V10/44;G06V10/764;G06V10/82;G06N3/0464;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         操晓春;              符仕一;              范斯卉;              卢衍帆;                   王家晖       </td>   <td>中山大学</td>   <td>基于人脸与背景融合增强的人物同框关系分析方法及系统</td>   <td>广东省</td>   <td>CN117373098A</td>   <td>2024-01-09</td>   <td>本发明公开了基于人脸与背景融合增强的人物同框关系分析方法及系统,其中方法包括：获取原始人脸图像集；对原始人脸图像集进行盲脸修复与人脸背景增强处理,得到增强人脸图像集；对增强人脸图像集进行人脸检测处理,得到人脸特征集合；对人脸特征集合进行分批聚类和合并处理,得到人脸特征聚类结果；根据人脸特征聚类结果对原始人脸图像集中的待分析图像进行人物同框关系分析处理,得到分析结果。本发明实施例通过对原始人脸图像进行增强,能够提高图像的质量,并通过对增强后的人脸图像进行人脸检测,进行分批聚类和合并处理,能够提高聚类的效率,从而提高人物同框关系分析结果的效率和准确度,可广泛应用于计算机技术领域。</td>   <td>1.一种基于人脸与背景融合增强的人物同框关系分析方法,其特征在于,所述方法包括：获取原始人脸图像集；对所述原始人脸图像集进行盲脸修复与人脸背景增强处理,得到增强人脸图像集；对所述增强人脸图像集进行人脸检测处理,得到人脸特征集合；对所述人脸特征集合进行分批聚类和合并处理,得到人脸特征聚类结果；根据所述人脸特征聚类结果对所述原始人脸图像集中的待分析图像进行人物同框关系分析处理,得到分析结果。</td>   <td>G06V40/16;G06V10/762;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         耿静;                   谭秋园       </td>   <td>中山大学</td>   <td>作物覆盖区域的土壤养分反演方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN116580318B</td>   <td>2024-01-05</td>   <td>本申请属于农业遥感的技术领域,公开了一种作物覆盖区域的土壤养分反演方法、装置、设备及介质,该方法包括：获取原始多光谱卫星影像数据并进行预处理；基于拓展的超分辨率卷积神经网络融合预处理后的原始卫星多光谱影像数据,得到目标时空分辨率的融合遥感数据集,其中,目标时空分辨率高于原始多光谱卫星影像数据的时空分辨率；提取并计算目标时空分辨率的融合遥感数据集中的植被变量数据；获取土壤样本养分实测数据,并基于土壤样本养分实测数据与植被变量数据,使用极端梯度提升树算法与遗传算法确定基于植被变量反演土壤养分的目标预测模型；基于目标预测模型预测农作物覆盖区域的土壤养分。本申请可实现植被覆盖条件下土壤养分的精确估算。</td>   <td>1.一种作物覆盖区域的土壤养分反演方法,其特征在于,所述方法包括：获取原始多光谱卫星影像数据并进行预处理,得到预处理后的原始多光谱卫星影像数据；基于拓展的超分辨率卷积神经网络融合预处理后的原始多光谱卫星影像数据,得到目标时空分辨率的融合遥感数据集,其中,目标时空分辨率高于原始多光谱卫星影像数据的时空分辨率；提取并计算所述目标时空分辨率的融合遥感数据集中的植被变量数据；获取土壤样本养分实测数据,并基于土壤样本养分实测数据与植被变量数据,使用极端梯度提升树算法与遗传算法确定基于植被变量反演土壤养分的目标预测模型；基于所述目标预测模型预测农作物覆盖区域的土壤养分；所述基于土壤样本养分实测数据与植被变量数据,使用极端梯度提升树算法与遗传算法确定基于植被变量反演土壤养分的目标预测模型的步骤包括：基于极端梯度提升树算法构建回归模型,所述回归模型为：                                                                        其中,为经纬度(x,y)位置处的土壤有机碳含量预测值,/&gt;为经纬度(x,y)位置处的土壤全氮含量预测值,/&gt;为经纬度(x,y)位置处的土壤全磷含量预测值,为经纬度(x,y)位置处的土壤全钾含量预测值,Rs为红光波段时间序列植被变量,NIRs为近红外波段植被变量,SWIRs为短波红外波段时间序列植被变量,NDVIs为植被指数时间序列植被变量,f-1、f-2、f-3、f-4为由极端梯度提升树所构建的非线性函数；基于遗传算法迭代优化所述回归模型,得到优化后的回归模型；基于土壤样本养分实测数据与植被变量数据对优化后的回归模型进行训练,得到基于目标植被变量反演土壤养分的目标预测模型。</td>   <td>G06V20/13;G06V10/82;G06N3/0464;G06N3/08;G06T3/4053;G06T3/4046</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              王伟轩;              黄福强;                   张俊轩       </td>   <td>中山大学</td>   <td>基于自适应模糊修复机制的车牌识别方法</td>   <td>广东省</td>   <td>CN109543753B</td>   <td>2024-01-05</td>   <td>本发明涉及计算机视觉识别技术领域,提出一种基于自适应模糊修复机制的车牌识别方法,包括以下步骤：搜索并收集车牌识别数据集的图像,构建训练数据集；利用所述训练数据集单独构建与训练车牌检测模块、车牌分类模块、车牌修复模块和车牌识别模块；将待识别图像输入车牌检测模块中,对其进行目标特征的切割,得到车牌的坐标信息；输入车牌分类模块中对车牌图像是否发生畸变进行判断；输入车牌修复模块中根据图像的畸变类别对车牌图像进行修复；输入车牌识别模块中对图像进行车牌号码识别。本发明能够实现对任意车牌图像的车牌进行检测、修复和识别,能够有效地定位车牌在图像中的位置,修复发生模糊的车牌图像,有效地识别出图像中的车牌号码。</td>   <td>1.基于自适应模糊修复机制的车牌识别方法,其特征在于,包括以下步骤：S1：搜索并收集由任意含有车牌的图像构成的车牌识别数据集的图像,构建训练数据集；S2：利用所述训练数据集构建与训练车牌检测模块；具体步骤如下：S2.1：将训练数据集输入车牌检测模块,将训练数据集通过卷积神经网络提取图像的区域视觉特征；S2.2：在区域视觉特征的每个位置上放置9个不同长宽比的偏置框；S2.3：将区域视觉特征输入区域提议网络,输出与预设定偏置框的坐标偏移值和所预测框包含车牌的置信得分；S2.4：保留置信得分最高的若干个目标框,利用最大值池化操作,根据目标框坐标在区域视觉特征上切割与目标框相同数目的目标特征；S2.5：将目标特征输入三个独立的全连接层,分别用于提取高层次的语义特征、输出预测的目标特征的类别和输出目标框的偏移值,然后根据预测类别和偏移值对目标框进行修正；S3：利用所述训练数据集构建与训练车牌分类模块；具体步骤如下：S3.1：将车牌检测模块输出的图像输入车牌分类模块,先对输入图像进行人工标记分类,再通过卷积神经网络提取图像的全局视觉特征；S3.2：将全局视觉特征输入三个独立的全连接层,分别用于提取高层次语义特征、输出预测的车牌类别和输出车牌畸变程度；S4：利用所述训练数据集构建与训练车牌修复模块；具体步骤如下：S4.1：将车牌检测模块输出的图像输入车牌修复模块,设置运动模糊函数和散焦模糊函数对输入的图像进行处理,得到模糊图像与对应清晰图像的训练集合；S4.2：将模糊图像的训练集合通过卷积神经网络提取所述模糊图像的全局视觉特征；S4.3：将所述模糊图像的全局视觉特征输入生成器中,获取与对应清晰图像相同分辨率的修复图像；S4.4：计算修复图像与清晰图像的分布差异,生成器根据所计算得到的损失值更新参数；S4.5：将修复图像输入到判别器中判断修复图像是否清晰：若模糊,则调整生成器参数,跳转到S4.3步骤；若清晰,则根据修复结果对车牌修复模块的参数进行更新；S5：利用所述训练数据集构建与训练车牌识别模块；S6：将待识别的车牌图像输入所述车牌检测模块中,车牌检测模块对车牌图像进行目标特征的切割,得到车牌在图像中的坐标信息；S7：将完成目标特征切割的车牌图像输入所述车牌分类模块中,车牌分类模块对车牌图像是否发生畸变进行判断,若是执行S8步骤,若否执行S9步骤；S8：将发生畸变的车牌图像输入所述车牌修复模块中,车牌修复模块对车牌图像进行修复；S9：将未发生畸变的车牌图像或修复后的车牌图像输入所述车牌识别模块中,车牌识别模块对车牌图像进行车牌号码识别。</td>   <td>G06V20/62;G06V10/25;G06V10/764;G06V10/766;G06V10/82;G06V30/19;G06T5/60;G06T5/73;G06N3/044;G06N3/045;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡跃新;              余晋刚;              李远清;              郑亿庆;                   刘楚       </td>   <td>中山大学孙逸仙纪念医院;华南理工大学</td>   <td>耳内镜图像神经网络模型构建方法及分类处理方法</td>   <td>广东省</td>   <td>CN110796249B</td>   <td>2024-01-05</td>   <td>本发明公开了一种基于深度学习的耳内镜图像神经网络模型构建方法及智能分类处理方法,该模型构建方法包括步骤A：从医院病例数据库中选取耳内镜图像构建耳内镜数据集,将数据集划分为测试集以及训练集；步骤B：加载预训练的神经网络模型,在所得到的训练集上微调预训练的神经网络模型,获得训练得到的神经网络模型；步骤C：在测试集上验证步骤B训练得到的神经网络模型的性能,筛选出最优神经网络模型。本发明同时公开了一种基于深度学习的耳内镜图像智能分类处理方法,该智能分类处理方法还包括步骤D：通过步骤C获得的最优神经网络模型,对新增的耳内镜图像进行智能分类,输出分类结果。</td>   <td>1.一种基于深度学习的耳内镜图像神经网络模型构建方法,其特征在于,该方法包括如下步骤：步骤A：从医院病例数据库中选取耳内镜图像构建耳内镜数据集,将数据集划分为测试集以及训练集；所述步骤A中构建数据集的方法如下：(a1)利用医院耳鼻喉科的耳内镜数据库,获取耳内镜的图像组成耳内镜数据集；(a2)按照病变程度将耳内镜图像分成正常、分泌性中耳炎、慢性化脓性中耳炎活动期、慢性化脓性中耳炎静止期四种类型,并且进行标注；(a3)筛除各种类型中图像模糊以及未拍摄到病变部位的耳内镜图像；(a4)随机选取耳内镜数据集的病例,使用交叉验证方法,划分多个测试集以及训练集,耳内镜数据集中一个病例会包含多张病例图像,具体划分时确保同一个病例的多张病例图像不会同时在训练集和测试集出现,即该病例包含的所有图片,要么全在训练集,要么全在测试集；步骤B：加载预训练的神经网络模型,在所得到的训练集上微调预训练的神经网络模型,获得训练得到的神经网络模型；所述步骤B中神经网络模型的训练方法如下：(b1)加载预训练的神经网络模型,所述神经网络模型采用InceptionV3模型或者ResNet50模型；(b2)微调预训练的神经网络模型：去除神经网络模型中最后的全连接层,更换为输出个数为类型种数的全连接层,并随机初始化该输出个数为类型种数的全连接层的权重,获得用于耳内镜图像分类的新的神经网络模型；(b3)在每个构建的训练集上训练获得的新的神经网络模型,获得训练得到的神经网络模型；步骤C：在测试集上验证步骤B训练得到的神经网络模型的性能,筛选出最优神经网络模型；所述步骤C中验证步骤B训练得到的神经网络模型性能的方法如下：(c1)使用准确率评估训练得到的神经网络模型在多折交叉验证的性能,准确率最高的神经网络模型即为最优神经网络模型；(c2)验证该最优神经网络模型的性能：在正常与分泌性中耳炎,以及慢性化脓性中耳炎活动期与静止期两种疑难情况之间,绘出最优神经网络模型的ROC曲线图,并将参与验证的医生的真阳性率、假阳性率绘于ROC曲线图中的对应位置,若最优神经网络模型的ROC曲线包围医生的结果点,则说明该最优神经网络模型能够达到或超过人类专家的表现,能够用于实际新增耳内镜图像的智能分类。</td>   <td>G06N3/084;G06N3/0464;G16H40/20;G16H50/20;G06V10/774;G06V10/764;A61B1/227;A61B1/04;A61B1/00;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              黄思恩;                   冯展祥       </td>   <td>中山大学</td>   <td>基于注意力机制的孪生网络解决换装行人重识别的方法</td>   <td>广东省</td>   <td>CN113158739B</td>   <td>2024-01-05</td>   <td>本发明公开了一种基于注意力机制的孪生网络解决换装行人重识别的方法,包括由视觉流和轮廓流组成的双流孪生网络结构,所述方法包括以下步骤：分别输入原始图和轮廓图；分别对原始图和轮廓图采用ResNet-50作为骨干网络提取特征；将提取到的特征分别送入注意力分支和全局分支进行处理；将两个经过处理后的流的总输出进行特征融合,获得最后的输出。其中,整个过程受损失函数模块引导和约束。本发明优势在于整个网络架构是一个双流体系结构,同时利用视觉特征和轮廓特征,并利用视觉特征和轮廓特征相结合,去学习既具有区别性又鲁棒稳定的特征,在换装行人重识别领域中非常有价值。</td>   <td>1.基于注意力机制的孪生网络解决换装行人重识别的方法,其特征在于,包括由视觉流和轮廓流组成的双流孪生网络结构,所述方法包括以下步骤：S1分别输入原始图和轮廓图；S2分别对原始图和轮廓图采用ResNet-50作为骨干网络提取特征；S3将提取到的特征分别送入注意力分支和全局分支进行处理；S4将两个经过处理后的流的总输出进行特征融合,获得最后的输出；其中,整个过程受损失函数模块引导和约束；所述注意力分支由位置注意力模块和通道注意力模块组成,将把ResNet-50的第五层输出经过一个还原层的结果作为输入,分别送进位置注意力模块和通道注意力模块；最后把位置注意力模块和通道注意力模块的输出与输入进行特征融合作为整个注意力分支的总输出；所述位置注意力模块包括：对提取特征后的原始输入特征图A,经过由BatchNormalization层和ReLU激活层组成卷积层得到特征图B,特征图C,特征图D；分别对特征图B,特征图C,特征图D进行重组,然后对特征图B进行转置；再将特征图B和特征图C进行一次矩阵乘法后,经过Softmax运算得到位置注意力图S,将注意力图S与特征图D进行一次矩阵乘法得到基于注意力的权重图,将权重图与原始输入进行逐元素求和运算得到最终的输出特征图；所述通道注意力模块包括：对提取特征后的原始输入特征图A进行重组,然后对重组特征图A以及重组转置特征图A进行一次矩阵乘法,经过Softmax运算得到注意力图X；将注意力图X与特征图A进行一次矩阵乘法得到基于注意力的权重图,将权重图与原始输入进行逐元素求和运算得到最终的输出特征图E1。</td>   <td>G06V40/10;G06V10/44;G06V10/84</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙伟;              包世诚;              林恩鹏;              倪芃芃;              冷振东;              刘凯文;              高军;                   巫志文       </td>   <td>中山大学</td>   <td>钢筋混凝土结构腐蚀破坏细观近场动力学模拟方法及装置</td>   <td>广东省</td>   <td>CN117350057A</td>   <td>2024-01-05</td>   <td>本发明公开了钢筋混凝土结构腐蚀破坏细观近场动力学模拟方法及装置,其中方法包括：获取拟模拟钢筋混凝土结构的二维细观结构数字模型；根据二维细观结构数字模型,获取钢筋混凝土结构的物质点数据；根据物质点材料性质对物质点数据进行分类建模处理,生成近场动力学细观模型；对钢筋混凝土结构进行非均匀腐蚀模拟处理,建立时间依赖性非均匀腐蚀模型；将近场动力学细观模型和时间依赖性非均匀腐蚀模型输入显式键基近场动力学系统进行腐蚀破坏模拟分析处理,得到模拟结果。本发明实施例通过对受腐蚀后的钢筋混凝土结构进行结构破坏分析和后续裂缝发展预测,提高了分析和预测结果的准确率,可广泛应用于混凝土材料数值模拟技术领域。</td>   <td>1.一种钢筋混凝土结构腐蚀破坏细观近场动力学模拟方法,其特征在于,所述方法包括：获取拟模拟钢筋混凝土结构的二维细观结构数字模型；根据所述二维细观结构数字模型,获取所述钢筋混凝土结构的物质点数据；根据物质点材料性质对所述物质点数据进行分类建模处理,生成近场动力学细观模型；对所述钢筋混凝土结构进行非均匀腐蚀模拟处理,建立时间依赖性非均匀腐蚀模型；将所述近场动力学细观模型和所述时间依赖性非均匀腐蚀模型输入显式键基近场动力学系统进行腐蚀破坏模拟分析处理,得到模拟结果。</td>   <td>G06F30/20;G06F30/13;G06F119/14;G06F119/12;G06F119/02;G06F113/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王菁;                   任江涛       </td>   <td>中山大学</td>   <td>基于全局协作的图对比学习推荐方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN117350803A</td>   <td>2024-01-05</td>   <td>本发明提供了一种基于全局协作的图对比学习推荐方法、系统、设备及介质,所述方法包括：获取预设数目的用户交互行为数据,并对各个用户交互行为数据进行标注,得到用户交互行为数据集；所述用户交互行为数据包括用户给各个商户打分、用户给各个商户评论、以及用户间的购物体验交流；根据所述用户交互行为数据集,构建物品推荐模型；所述物品推荐模型包括依次连接的全局图特征提取模块、奇异值分解降维模块和对比学习模块；获取目标用户行为交互数据,并将所述目标用户行为交互数据输入所述物品推荐模型进行推荐分析,得到对应的物品推荐结果。本发明能在图增强时很好地保留有用的结构信息,有效缓解过平滑问题,提升推荐效果和学习的鲁棒性。</td>   <td>1.一种基于全局协作的图对比学习推荐方法,其特征在于,所述方法包括以下步骤：获取预设数目的用户交互行为数据,并对各个用户交互行为数据进行标注,得到用户交互行为数据集；所述用户交互行为数据包括用户给各个商户打分、用户给各个商户评论、以及用户间的购物体验交流；根据所述用户交互行为数据集,构建物品推荐模型；所述物品推荐模型包括依次连接的全局图特征提取模块、奇异值分解降维模块和对比学习模块；获取目标用户行为交互数据,并将所述目标用户行为交互数据输入所述物品推荐模型进行推荐分析,得到对应的物品推荐结果。</td>   <td>G06Q30/0601;G06F16/9535;G06N3/0895;G06F16/9536</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韦艳宏;              钟霞丽;              陈俊周;              张祝谊;              郝俣;                   朱启诚       </td>   <td>中山大学</td>   <td>筛选PFAS血管毒性效应指标的方法、装置及介质</td>   <td>广东省</td>   <td>CN117350958A</td>   <td>2024-01-05</td>   <td>本申请公开了一种筛选PFAS血管毒性效应指标的方法、系统、装置和存储介质,其中方法包括以下步骤：获取不同暴露浓度的斑马鱼的高内涵荧光图集；高内荧光图集包括若干个子荧光图；从若干个子荧光图中分割出若干个血管区域并提取若干个血管区域的所有形态学指标；根据所有形态学指标,确定不同血管区域的若干个第一总得分；根据第一总得分,确定目标血管区域以及血管毒性评分；对目标血管区域的形态学特征进行分析并确定第一权重以及第二权重；根据第一权重以及第二权重,确定目标血管区域的若干个第二总得分。本方法可以快速确定目标血管区域、筛选血管毒性效应指标且得到血管毒性评分。本申请可广泛应用于数据处理技术领域。</td>   <td>1.一种筛选PFAS血管毒性效应指标的方法,其特征在于,包括：获取不同暴露浓度的斑马鱼的高内涵荧光图集；所述高内荧光图集包括若干个子荧光图；从所述若干个子荧光图中分割出若干个血管区域并提取所述若干个血管区域的所有形态学指标；根据所述所有形态学指标,确定不同血管区域的若干个第一总得分；所述第一总得分用于表征所有不同暴露浓度下某一个血管区域中所有形态学指标的总得分；根据所述第一总得分,确定目标血管区域以及血管毒性评分；对所述目标血管区域的形态学特征进行分析并确定第一权重以及第二权重；根据第一权重以及第二权重,确定所述目标血管区域的若干个第二总得分；所述第二总得分用于表征所有不同暴露浓度下目标血管区域中各形态学指标的总得分。</td>   <td>G06T7/00;G16H50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张靖文;              罗祺耀;              钟盈盈;                   吕祚彬       </td>   <td>中山大学</td>   <td>基于机器学习的农业灌溉用水量估算方法、系统及介质</td>   <td>广东省</td>   <td>CN117333321A</td>   <td>2024-01-02</td>   <td>本发明公开了一种基于机器学习的农业灌溉用水量估算方法、系统及介质。该方法包括收集农业灌溉用水量相关数据及研究区域田块尺度数据；构建初步的农业灌溉用水量预测模型并进行敏感性分析,调整参加训练的变量,确定变量对于农业灌溉用水量估算精度的贡献；构建基于机器学习的判断灌溉是否发生的0-1分类预测模型；构建基于机器学习的农业灌溉用水量的回归预测模型；对比基于不同机器学习算法的农业灌溉用水量回归预测模型,确定最稳健效率最高的回归预测模型。旨在估算高空间分辨率(田块尺度)和高时间分辨率(日尺度)的农业灌溉用水量数据,提高了现有技术的时空分辨率。</td>   <td>1.基于机器学习的农业灌溉用水量估算方法,其特征在于,包括下述步骤：收集研究区域田块尺度的农业灌溉用水量数据；获取研究区域田块尺度的叶面积指数、总初级生产力、叶片温度和土壤含水量数据；基于人工智能方法构建初步的农业灌溉用水量预测模型；用构建的农业灌溉用水量预测模型进行敏感性分析,调整参加训练的变量,确定变量对于农业灌溉用水量估算精度的贡献；构建基于机器学习的判断灌溉是否发生的0-1分类预测模型；构建基于机器学习的农业灌溉用水量的回归预测模型；对比基于不同机器学习算法的农业灌溉用水量回归预测模型,确定最稳健效率最高的回归预测模型。</td>   <td>G06Q50/02;G06Q50/06;G06Q10/04;G06F18/27;G06N20/20;G06N20/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              苗建明;                   杨清书       </td>   <td>中山大学</td>   <td>基于区块链的数据共享方法和装置</td>   <td>广东省</td>   <td>CN112269771B</td>   <td>2024-01-02</td>   <td>本申请涉及一种基于区块链的数据共享方法和装置。所述方法包括：获取数据使用方上传的测试数据,将上传的测试数据与数据平台的区块链中预先存储的结构化测试数据集进行比对,判定上传的测试数据质量；当上传的测试数据的质量合格时,将质量合格的测试数据按照测试要素进行整理,合并整理后的质量合格的测试数据与数据平台的区块链中预先存储的结构化测试数据集；获取数据使用方的下载请求,根据数据平台的智能合约判定数据使用方的下载权限,当判定数据使用方存在下载权限时,获取数据使用方下载时的反馈信息；基于反馈信息,优化数据平台的区块链中预先存储的结构化测试数据集。采用本申请实施例方法能够有效提高数据共享效率和安全性。</td>   <td>1.一种基于区块链的数据共享方法,所述方法包括：获取各测试平台的原始测试数据,所述原始测试数据包括间接测试数据和直接测试数据；获取所述原始测试数据的测试要素对应的实际测试值,对于所述直接测试数据,直接提取所述直接测试数据的测试要素,和所述直接测试数据的测试要素对应的实际测试值,对于所述间接测试数据,建立所述间接测试数据与各测试要素的反演算法,反推所述间接测试数据的测试要素,获取所述间接测试数据的测试要素对应的实际测试值；对所述原始测试数据进行数据清洗,所述数据清洗包括根据所述原始测试数据的测试要素对应的实际测试值,检查和填补所述原始测试数据中的无效测试要素,获得所述原始测试数据的有效测试要素；将所述原始测试数据按照所述有效测试要素进行整理,获得测试数据集；按照所述测试数据集的特征和来源对所述测试数据集进行标记,获得结构化测试数据集；由数据提供方创建父区块,由数据使用方创建子区块,通过哈希指针将所述子区块链接到所述父区块上形成区块链,所述父区块用于存储所述数据提供方的结构化测试数据集,所述子区块用于存储所述数据使用方的结构化测试数据集；获取所述数据提供方与所述数据使用方共同协商制定的智能合约,将所述智能合约创建区块存入所述区块链中,建立基于区块链的数据平台；获取数据使用方上传的测试数据,将所述上传的测试数据与数据平台的区块链中预先存储的结构化测试数据集进行比对,判定所述上传的测试数据质量；当所述上传的测试数据的质量合格时,将所述质量合格的测试数据按照测试要素进行整理,合并所述整理后的所述质量合格的测试数据与所述数据平台的区块链中预先存储的结构化测试数据集；获取所述数据使用方的下载请求,根据所述数据平台的智能合约判定所述数据使用方的下载权限,当判定所述数据使用方存在下载权限时,获取所述数据使用方下载时的反馈信息；基于所述反馈信息,优化所述数据平台的区块链中预先存储的结构化测试数据集。</td>   <td>G06F16/176;G06F16/23;G06F16/27;G06F21/60;G06F21/64;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何倩;              武文博;                   农革       </td>   <td>中山大学</td>   <td>一种数据检索方法及装置、终端设备</td>   <td>广东省</td>   <td>CN112765421B</td>   <td>2024-01-02</td>   <td>本申请适用于数据索引技术领域,提供了一种数据检索方法及装置、终端设备,包括：将源数据转换为目标字符串,并生成映射表；将所述目标字符串发送至云服务器；将检索字符串转换为目标检索字符串；将所述目标检索字符串发送至云服务器；根据云服务器返回的检索结果集以及所述映射表确定目标检索结果；其中,检索结果集为目标检索字符串在目标字符串中的出现的位置的集合能够借助具有强大算力的云服务器来构建后缀数据实现检索,又能保证用户数据的安全性。</td>   <td>1.一种数据检索方法,其特征在于,包括：将源数据转换为目标字符串,并生成映射表；根据所述源数据配置第一字符集、第二字符集、分块因子以及匹配因子；其中,所述第一字符集是所述源数据中所有字符所属的字符集；所述第二字符集是通过将第一字符集中的字符进行随机排列生成的字符集；所述将源数据转换为目标字符串,并生成映射表包括：根据第一字符集和第二字符集的映射关系,对源数据进行字符替换,生成待分块字符串；根据分块因子对待分块字符串进行分块处理,得到若干个字符分块,并将每个分块的起点下标保存在第一数组中；根据匹配因子在各个字符分块中填充字符,并将每个分块的字符保存在第二数组中；根据置换数组和第二数组生成目标字符串,并将当前顺序下每个字符分块在目标字符串中的起点下标保存在第三数组中；根据第一数组、置换数组以及第三数组生成映射表；将所述目标字符串发送至云服务器；将检索字符串转换为目标检索字符串；将所述目标检索字符串发送至云服务器,以使所述云服务器根据目标检索字符串在构造的后组数组中进行检索,得到检索结果集；根据云服务器返回的检索结果集以及所述映射表确定目标检索结果；其中,检索结果集为目标检索字符串在目标字符串中的出现的位置的集合,所述映射表记录每个分块在目标字符串的起点下标和待分块字符中的起始下标的对应关系。</td>   <td>G06F16/903;G06F16/9038;G06F16/953;G06F16/9538</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭军;              潘嵘;              毕宁;              任天宇;                   黄嘉树       </td>   <td>中山大学</td>   <td>一种大规模类别层级文本分类方法</td>   <td>广东省</td>   <td>CN113590819B</td>   <td>2024-01-02</td>   <td>本发明提供一种大规模类别层级文本分类方法,该方法将深度学习网络应用于平面分类器方法和全局分类器方法,分别对其进行分类计算,一方面在平面分类器方法上与机器学习方法对比分类性能,另一方面在深度学习方法上对比全局分类器方法在学习层级依赖信息后是否比平面分类器有着更好的表现；采用平面分类器时,与机器学习方法一致,不考虑层级结构,损失函数仅考虑训练集的经验损失函数；采用全局分类器时,将层级结构纳入考虑,损失函数中加入正则化项的惩罚；基于文本分类任务中经典的神经网络模型CNN和RNN,将注意力机制与RNN模型、CNN模型相结合,对文本的关键信息进行捕捉,有利于进一步推进政务信息化和自动化。</td>   <td>1.一种大规模类别层级文本分类方法,其特征在于,包括以下步骤：S1：采集政府采购公示数据；S2：利用机器学习的方式对步骤S1采集的数据进行分类；S3：将步骤S2的分类结果作为基准,使用ARCNN模型对步骤S1采集的数据进行分类；所述步骤S3中,对采集的政府采购公示数据进行中文文本分词,得到组词序列D＝[w-1；w-2；…；w-n],令w表示网络结构中的参数集合,p(k|D,w)表示文本实例属于类别k的概率,将词序列D＝[w-1；w-2；…；w-n]经过Word Embedding映射到词向量空间中,得到词序列的向量表示：[e(w-1)；e(w-2)；…；e(w-n)]；对输入的词序列,采用双向循环神经网络模型Bi-RNN分别学习当前词w-i的上下文信息,得到上文信息c-l(w-i)和下文信息c-r(w-i),其中,e(w-i)为具有|e|个实值元素的非稀疏向量,c-l(w-i)、c-r(w-i)均为具有|c|个实值元素的非稀疏向量；所述步骤S3中,基于双向循环神经网络模型Bi-RNN的结构,上下文信息c-l(w-i)、c-r(w-i)为隐藏层信息,其计算方式如下：c-l(w-i)＝f(W～((l))c-l(w-(i-1))+W～((sl))e(w-(i-1)))c-r(w-i)＝f(W～((r))c-r(w-(i+1))+W～((sr))e(w-(i+1)))其中,c-l(w-(i-1))来自于上文词语w-(i-1)处的隐藏层信息,e(w-(i-1))来自于上文词语w-(i-1)处自身的Word Embedding值,W～((l))是将隐藏层信息向后传递的转移矩阵,W～((sl))是将输入的WordEmbedding值信息向后传递的转移矩阵,c-r(w-(i+1))来自于下文词语w-(i+1)处的隐藏层信息,e(w-(i+1))来自于下文词语w-(i+1)处自身的WordEmbedding值,W～((r))是将隐藏层信息向前传递的转移矩阵,W～((sr))是将输入的Word Embedding值信息向前传递的转移矩阵,f是非线性激活函数,对聚合后的上文隐藏层信息和输入信息进行激活后向后传递到当前隐藏层,对于文档中的第一个词语而言,由于不存在上文,故使用共享参数c-l(w-1)；经过基于双向循环神经网络模型Bi-RNN,通过正向和反向的循环,对于当前词w-i,可以获得当前输入信息e(w-i)及其隐藏层信息c-l(w-i)、c-r(w-i)；将当前输入信息和隐藏层信息进行级联拼接,得到文本表示方式x-i：x-i＝[c-l(w-i)；e(w-i)；c-r(w-i)]；现在每个词语处都获取了上下文信息,但其利用程度并非完全相同,而且并非所有词语都对文本含义的表示有同等的贡献,为了让模型更好的聚焦于文本的关键部分,对于Bi-RNN模块的输出x-i,采用自注意力模型,来提取文本中重要性更高的词语,得到注意力标记后的文本表示：将RNN模块中所得的文本表示x-i进行编码,通过线性映射f-q、f-k、f-v分别得到查询编码Query：q-i、键编码Key：k-i和值编码Value：v-i；q-i＝f-q(x-i)k-i＝f-k(x-i)v-i＝f-v(x-i)计算Query和Key之间的相似程度,得到注意力分数作为词语重要性关注度的度量；接着,将该分数采用softmax函数进行归一化处理,得到注意力权重值：e-(i,j)＝a(q-i,k-j)a-(i,j)＝softmax(e-(i,j))根据所得归一化权重,对文本的Value进行加权求和,得到注意力标记后的文本表示                  当前词w-i得到了注意力转化后的文本表示将其进一步进行卷积,并使用tanh函数作为激活函数,得到w-i的潜在语义向量/&gt;其中W～((2))是权重矩阵,b～((2))是偏置向量：                  卷积层中,令filter的kernel size＝1,这是因为实际上包含了w-i的上下文信息,获得所有单词的潜在语义向量后,采用最大池化层进行计算,得到/&gt;其中/&gt;的第k个元素是/&gt;的第k个元素的最大值：                  经过池化层,将各种不同长度的文本表示转换为固定长度的向量,并且捕获整个文本中的信息,采用最大池化层,经过池化层的最大池化后得到进入输出层,通过一个全连接层和softmax函数得到文本实例属于类别的概率p-i如下,其中,W～((4))是权重矩阵,b～((4))是偏置向量：                                    在前向传播过程,需要经过模型训练学习的参数包括：其中,c-l(w-(i-1))来自于上文词语w-(i-1)处的隐藏层信息,e(w-(i-1))来自于上文词语w-(i-1)处自身的Word Embedding值,W～((l))是将隐藏层信息向后传递的转移矩阵,W～((sl))是将输入的Word Embedding值信息向后传递的转移矩阵,c-r(w-(i+1))来自于下文词语w-(i+1)处的隐藏层信息,e(w-(i+1))来自于下文词语w-(i+1)处自身的WordEmbedding值,W～((r))是将隐藏层信息向前传递的转移矩阵,W～((sr))是将输入的WordEmbedding值信息向前传递的转移矩阵,W～((2))是卷积层的权重矩阵,b～((2))是卷积层的偏置向量,W～((4))是全连接层的权重矩阵,b～((4))是全连接层的偏置向量：w＝{b～((2)),b～((4)),c-l(w-1),c-r(w-n),W～((2)),W～((4)),W～((l)),W～((r)),W～((sl)),W～((sr))}。</td>   <td>G06F16/35;G06F40/126;G06F40/289;G06F40/30;G06N3/044;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   李佳铭       </td>   <td>中山大学;中山大学深圳研究院</td>   <td>一种类别不平衡半监督目标检测方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN117333656A</td>   <td>2024-01-02</td>   <td>本发明提供了一种类别不平衡半监督目标检测方法、系统、设备及介质,所述方法为将获取的类别不平衡图像数据集输入预设目标检测器进行目标检测分析得到无标注和无标注图像分类损失以及无标注图像的伪标签,并计算梯度矩阵建立类别梯度平衡方程组,以及根据求解类别梯度平衡方程组得到的类别权重和权重求解损失计算总分类损失并在判定继续迭代时,根据由类别权重得到的标签类别阈值确定有效伪标签和无标注图像的图像采样率后,根据有效伪标签、图像采样率和总分类损失对预设目标检测器进行训练得到半监督目标检测器,并用其对待检测图像进行目标检测得到检测结果。本发明能有效保证类别不平衡场景目标检测的精准性,提升半监督目标检测的应用性能。</td>   <td>1.一种类别不平衡半监督目标检测方法,其特征在于,所述方法包括以下步骤：获取类别不平衡图像数据集,并将所述类别不平衡图像数据集输入预设目标检测器进行目标检测分析,得到无标注图像分类损失、有标注图像分类损失、以及各个无标注图像的伪标签；所述类别不平衡数据集包括有标注图像子数据集和无标注图像子数据集；所述伪标签包括标签类别、类别逻辑值和检测框位置坐标；计算各个标签类别的类别图像分类损失对各个类别逻辑值的偏导数,得到对应的梯度矩阵,并根据所述梯度矩阵,建立对应的类别梯度平衡方程组；所述梯度矩阵包括各个标签类别的正梯度和负梯度；求解所述类别梯度平衡方程组,得到各个标签类别的类别权重和权重求解损失,并根据各个标签类别的类别权重和所述权重求解损失,得到总分类损失；根据各个标签类别的类别权重,得到对应的标签类别阈值,并根据各个标签类别阈值,得到有效伪标签和各个无标注图像的图像采样率,以及根据所述有效伪标签、各个图像采样率采样和总分类损失,对所述预设目标检测器进行训练更新,得到半监督目标检测器；获取待检测图像,并根据所述半监督目标检测器对所述待检测图像进行目标检测,得到检测结果。</td>   <td>G06V10/25;G06N3/0895;G06V10/764;G06F17/10;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              孙亚;                   曾莹       </td>   <td>中山大学</td>   <td>一种基于多尺度特征融合的活体检测方法、系统及装置</td>   <td>广东省</td>   <td>CN113505722B</td>   <td>2024-01-02</td>   <td>本发明公开了一种基于多尺度特征融合的活体检测方法、系统及装置,包括：获取训练图像并对训练图像进行人脸关键点检测并进行裁剪,得到裁剪后的训练图像；基于特征提取网络对裁剪后的训练图像进行特征提取,得到真实人脸图像特征和攻击人脸图像特征；基于生成对抗网络对真实人脸图像特征进行重构,得到重构真实人脸图像特征；基于三元组损失函数对重构真实人脸图像特征和攻击人脸图像特征进行约束,得到分类边界；采用全连接层作为分类器并根据分类边界对待测图像进行检测,得到检测结果。本发明方法提高人脸活体检测性能。本发明作为一种基于多尺度特征融合的活体检测方法、系统及装置,可广泛应用于计算机视觉领域。</td>   <td>1.一种基于多尺度特征融合的活体检测方法,其特征在于,包括以下步骤：S1、获取训练图像并对训练图像进行人脸关键点检测并进行裁剪,得到裁剪后的训练图像；S2、基于特征提取网络对裁剪后的训练图像进行特征提取,得到真实人脸图像特征和攻击人脸图像特征；所述特征提取网络包括由8个级联的卷积层构成的神经网络和多尺度特征融合模块,所述基于特征提取网络对裁剪后的训练图像进行特征提取,得到真实人脸图像特征和攻击人脸图像特征这一步骤,其具体包括：S21、基于多个卷积层分别裁剪后的训练图像分别进行特征提取,得到真实人脸图像和攻击人脸图像各层特征；S22、基于多尺度特征融合模块对真实人脸图像和攻击人脸图像各层特征进行融合,得到真实人脸图像特征和攻击人脸图像特征；S3、基于生成对抗网络对真实人脸图像特征进行重构,得到重构真实人脸图像特征；S4、基于三元组损失函数对重构真实人脸图像特征和攻击人脸图像特征进行约束,得到分类边界；S5、采用全连接层作为分类器并根据分类边界对待测图像进行检测,得到检测结果；所述生成对抗网络包括特征生成器和特征判别器,所述基于生成对抗网络对真实人脸图像特征进行重构,得到重构真实人脸图像特征这一步骤,其具体包括：S31、特征生成器根据真实人脸图像生成多个重构特征；S32、特征判别器对重构特征进行判别；S33、当重构特征被判定为虚假特征,对特征生成器和特征判别器进行参数调整；S34、循环步骤S31-S33,直至生成的重构特征被判定为真实人脸图像特征；所述三元组损失函数的表达式如下：                  上式中,G表示输入的人脸图片数据集,表示计算欧式距离,/&gt;表示数据集中的锚点,/&gt;表示锚点对应的正例,/&gt;表示锚点对应的负例,α是/&gt;指/&gt;与之间的距离和/&gt;与/&gt;之间的距离的最小间隔。</td>   <td>G06V40/16;G06V40/40;G06V10/80;G06V10/82;G06N3/0464;G06N3/0475;G06N3/08;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         潘扬勋;              王炯亮;              张耀军;                   陈敏山       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种LCAT在肝细胞癌诊断、治疗和预测复发的应用</td>   <td>广东省</td>   <td>CN117334325A</td>   <td>2024-01-02</td>   <td>本发明属于医疗诊断、治疗和预测复发技术领域,提供了一种LCAT在肝细胞癌诊断、治疗和预测复发的应用,首先提取GEO数据库中KEGG代谢相关基因数据集并进行处理,接着使用LASSO回归算法基于KEGG代谢相关基因集在GEO数据库整合数据集并构建风险评估模型,然后与接受手术的肝癌病人的术后肿瘤和周围正常组织转录组测序数据进行差异分析的结果取交集；本发明通过结合GEO公共数据库分析发现LCAT在肝癌组织中低表达,与病人的不良预后相关；并且LCAT在肝癌组织和正常组织中呈现显著差异。进一步,通过临床肝癌病人组织样本,证明可以将LCAT作为诊断、治疗和预测复发的分子标志物在临床中应用。</td>   <td>1.一种LCAT在肝细胞癌诊断、治疗和预测复发的应用,其特征在于：包括以下步骤：S1、首先提取GEO数据库中KEGG代谢相关基因数据集并进行处理；S2、接着使用LASSO回归算法基于KEGG代谢相关基因集在GEO数据库整合数据集并构建风险评估模型；S3、然后与接受手术的肝癌病人的术后肿瘤和周围正常组织转录组测序数据进行差异分析的结果取交集,筛选并鉴定出LCAT作为肝癌病人术后高危复发基因；S4、然后通过公共数据库分析和小鼠皮下瘤模型发现LCAT的高表达能够激活TIME中的T细胞和NK细胞并发挥抑制肿瘤的作用,并且通过进一步探究鉴定出了TAMs作为关键的抗原递呈细胞(APCs)发挥了激活免疫效应细胞的作用；S5、最后结合前期研究成果选择MNK激酶家族进一步分析,并结合TCGA公共数据库分析发现MNK1在肝癌组织中高表达,得到最终结论。</td>   <td>G16H50/20;G16H50/70;G16B30/10;G16B50/00;G16B40/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任江涛;                   陈腾扬       </td>   <td>中山大学</td>   <td>一种路面坑洞图像数据增强方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN117333390A</td>   <td>2024-01-02</td>   <td>本发明提供了一种路面坑洞图像数据增强方法、系统、设备及存储介质,所述方法为根据目标检测标注中的标注框类别标签和坐标信息对路面病害数据集中各个路面病害图像的坑洞区域进行裁剪得到坑洞感兴趣区域图集,并根据依此构建的伪坑洞图像生成器生成伪坑洞感兴趣区域图库后,遍历伪坑洞感兴趣区域图库获取各个坑洞感兴趣区域图像的最接近伪坑洞感兴趣区域图像,根据纹理合成模型生成各个坑洞感兴趣区域图像的坑洞纹理图像,并将对应的最接近伪坑洞感兴趣区域图像和坑洞纹理图像进行融合得到的待嵌入坑洞图像嵌入至对应的路面病害图像得到路面病害增强图像。本发明能合成丰富且有效的路面坑洞图像的同时,有效提升路面病害检测的高效性和精准性。</td>   <td>1.一种路面坑洞图像数据增强方法,其特征在于,所述方法包括以下步骤：获取带有目标检测标注的路面病害数据集；所述路面病害数据集中的路面病害图像包括路面坑洞特征；根据所述目标检测标注中的标注框类别标签和坐标信息,对各个路面病害图像的坑洞区域进行裁剪,得到对应的坑洞感兴趣区域图集；根据所述坑洞感兴趣区域图集,构建伪坑洞图像生成器,并根据所述伪坑洞图像生成器,生成伪坑洞感兴趣区域图库；遍历所述伪坑洞感兴趣区域图库,获取所述坑洞感兴趣区域图集中各个坑洞感兴趣区域图像的最接近伪坑洞感兴趣区域图像；根据预设的纹理合成模型,生成所述坑洞感兴趣区域图集中各个坑洞感兴趣区域图像对应的坑洞纹理图像；将同一坑洞感兴趣区域图像对应的所述最接近伪坑洞感兴趣区域图像和所述坑洞纹理图像进行融合,得到对应的待嵌入坑洞图像；将所述待嵌入坑洞图像嵌入至对应坑洞感兴趣区域图像所属的路面病害图像,得到对应的路面病害增强图像。</td>   <td>G06T5/00;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭键清;                   周威       </td>   <td>中山大学;中山大学·深圳</td>   <td>一种基于深度学习的仪表读数方法、系统、设备和介质</td>   <td>广东省</td>   <td>CN117333742A</td>   <td>2024-01-02</td>   <td>本方案涉及一种基于深度学习的仪表读数方法、系统、设备和介质,该方法包括：获取待读数图像,将待读数图像输入到训练好的第一预估模型,得到待读数图像的读数区域及读数区域对应的角点坐标,根据角点坐标对读数区域进行扭曲校正,得到校正后的读数区域,将校正后的读数区域输入到训练好的第二预估模型,得到读数结果。本发明可以提高抄表读数的准确率,应用于仪表识别领域。</td>   <td>1.一种基于深度学习的仪表读数方法,其特征在于,包括：获取待读数图像；将所述待读数图像输入到训练好的第一预估模型,得到所述待读数图像的读数区域及读数区域对应的角点坐标；根据所述角点坐标对所述读数区域进行扭曲校正,得到校正后的读数区域；将校正后的读数区域输入到训练好的第二预估模型,得到读数结果。</td>   <td>G06V10/778;G06V10/774;G06V10/764;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   马杰       </td>   <td>中山大学;中山大学深圳研究院</td>   <td>一种半监督图像语义分割方法、系统、计算机设备及介质</td>   <td>广东省</td>   <td>CN117333666A</td>   <td>2024-01-02</td>   <td>本发明提供了一种半监督图像语义分割方法、系统、计算机设备及介质,所述方法为获取包括有标注图像数据和无标注图像数据的语义分割数据集,并对语义分割数据集进行数据增强处理得到对应的语义分割增强数据集后,根据语义分割增强数据集,采用交叉伪监督结合基于物体部分对比学习的半监督学习训练方式,构建半监督语义分割模型,并将获取的待处理图像数据输入半监督语义分割模型进行语义分割处理,得到对应的语义分割结果。本发明不仅能够通过动态软标签高效利用低置信度伪标签,引入更丰富的监督信息,避免有用信息损失,而且能够基于物体部分的对比学习,有效减少错误伪标签导致的模型退化风险,提升模型的类别辨识能力和鲁棒性。</td>   <td>1.一种半监督图像语义分割方法,其特征在于,所述方法包括以下步骤：获取语义分割数据集,并对所述语义分割数据集进行数据增强处理,得到对应的语义分割增强数据集；所述语义分割数据集包括有标注图像数据和无标注图像数据；所述语义分割增强数据集包括无标注强增强图像数据子集和无标注弱增强图像数据子集、有标注弱增强图像数据子集和有标注强增强图像数据子集；根据所述语义分割增强数据集,采用交叉伪监督结合基于物体部分对比学习的半监督学习训练方式,构建半监督语义分割模型；获取待处理图像数据,并将所述待处理图像数据输入所述半监督语义分割模型进行语义分割处理,得到对应的语义分割结果。</td>   <td>G06V10/26;G06N3/0895;G06N3/045;G06N3/0464;G06V10/762;G06V10/82;G06V10/764;G06V10/74</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋嵘;                   翁培煜       </td>   <td>中山大学;中山大学深圳研究院</td>   <td>一种康复训练任务难度自适应调节方法及装置</td>   <td>广东省</td>   <td>CN117332592A</td>   <td>2024-01-02</td>   <td>本申请属于康复训练技术领域,公开了一种康复训练任务难度自适应调节方法及装置,该方法包括：获取用户的初始步态参数和训练时下肢的运动学信息和动力学信息；对运动学信息和动力学信息进行步态分析,得到用户的对称性分析参数、稳定性分析参数和变异性分析参数；分别计算稳定性分析参数、变异性分析参数与初始步态参数的比值,基于预设模糊规则、稳定性比值和变异性比值确定任务难度等级；根据任务难度等级调整跑步机电机的输入频率；确定对称性分析参数与任务难度等级的差距,并反馈给用户。本申请能够对用户进行更加科学合理的康复训练,使受试者行走更加稳定,提高康复训练的效率和效果。</td>   <td>1.一种康复训练任务难度自适应调节方法,其特征在于,包括：获取用户的初始步态参数和训练时下肢的运动学信息和动力学信息；对所述运动学信息和所述动力学信息进行步态分析,得到所述用户的对称性分析参数、稳定性分析参数和变异性分析参数；分别计算所述稳定性分析参数、所述变异性分析参数与所述初始步态参数的比值,基于预设模糊规则、稳定性比值和变异性比值确定任务难度等级；根据所述任务难度等级调整跑步机电机的输入频率；确定所述对称性分析参数与所述任务难度等级的差距,并反馈给所述用户。</td>   <td>G06F30/20;A63B22/02;A63B24/00;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苟超;                   卓莹       </td>   <td>中山大学</td>   <td>一种用于人脸关键点检测的主动形状模型参数化方法</td>   <td>广东省</td>   <td>CN112115845B</td>   <td>2023-12-29</td>   <td>本发明提供一种用于人脸关键点检测的主动形状模型参数化方法,该方法使用主动形状模型参数对人脸关键点位置进行编码,使得可在新的空间中预测人脸关键点的位置,对人脸关键点位置的求解从而变得紧凑；以级联回归方法、并利用局部特征来更新主动形状模型参数,不仅提高了运算效率和检测精度,还增强了模型的稳健性。本发明具备检测速度快、匹配精度高、稳健性强等优点,同时有效解决了主动形状模型等参数化方法存在的运算效率低下问题和级联回归等非参数化方法存在的过拟合问题,具备具有较高的实际应用价值。</td>   <td>1.一种用于人脸关键点检测的主动形状模型参数化方法,其特征在于,包括以下步骤：S1：利用人脸关键点数据集的样本数据初始化主动形状模型参数；S2：使用级联回归方法来更新主动形状模型参数,直至迭代次数达到最大取值；S3：对步骤S2中主动形状模型参数的最终结果进行解码,得到对应的人脸关键点位置；所述步骤S1的具体过程是：S11：以人脸关键点数据集中第一张人脸的姿态为准,再依次读取数据集中各人脸中有关姿态的参数、并对齐第一张人脸,消除数据集中人脸姿态的影响；S12：对步骤S11中统一对齐后的各人脸图像使用主成分分析法,返回人脸图像平均脸x以及保留的特征值λ和特征向量Λ,特征值λ的维度由主成分分析法中所保留的能量比例来决定；S13：将形状参数d初始化为零向量,并根据步骤S12所得的平均脸和特征向量Λ,初始化人脸关键点位置x～0作为当前的人脸关键点估计值x-(temp)；S14：根据人脸关键点数据集中的关键点真值x～*和当前的人脸关键点估计值x-(temp),求得姿态参数{θ,s,t-x,t-y},其中θ表示旋转角度,s是缩放比例,t-x,t-y分别是水平方向和垂直方向的平移量；S15：由人脸关键点数据集的关键点真值x～*、平均脸和特征向量Λ,以及步骤S13中得到的姿态参数{θ,s,t-x,t-y},计算得到形状参数d；S16：由步骤S13中得到的姿态参数{θ,s,t-x,t-y}和步骤S15中得到的形状参数d组成所述人脸关键点数据集中对应人脸的主动形状模型参数p：p＝{θ,s,t-x,t-y,d}S17：根据步骤S16所得的主动形状模型参数p和步骤S12所得的平均脸特征向量Λ,重新估计当前的人脸关键点位置x-(temp),并计算其与对应的人脸关键点真值x～*的误差GTE：                  式中的e为对应人脸图像的瞳孔距离；S18：重复步骤S14-S17,直至当前的人脸关键点估计位置x-(temp)与人脸关键点真值x～*的误差GTE小于误差阈值GTE-(tresh)为止,此时的主动形状模型参数即为该人脸图像对应的主动形状模型参数p～*；S19：对所述人脸关键点数据集中所有人脸图像对应的主动形状模型参数p～*求取平均值,即为主动形状模型参数的初始值p～0；步骤S2的具体过程是：S21：读取人脸图像,并将其转换为灰度图像,然后以图像中所检测到的人脸范围的中心点为锚点进行图像缩放,再将人脸图像裁剪成宽统一的灰度图像,记为I；S22：读取步骤S1中得到的主动形状模型参数初始值p～0作为当前的主动形状模型参数p-(temp)；S23：根据当前的主动形状模型参数p-(temp)以及步骤S12所得的平均脸x和特征向量Λ,估计当前的人脸关键点x-(temp)；S24：由步骤S23中得到的当前人脸关键点的估计值x-(temp)和步骤S21中经统一缩放、裁剪后的灰度图像I,提取当前人脸中每个关键点附近的局部特征Φ,此处提取的局部特征为SIFT特征；S25：根据步骤S24中所得的人脸中关键点附近的局部特征Φ,使用回归模型R计算当前主动形状模型参数p-(temp)的增量Δp,此处使用的回归模型为线性模型：Δp＝R(Φ(x-(temp),I))S26：加上步骤S25所得的当前主动形状模型参数的增量Δp以更新当前的主动形状模型参数p-(temp),并重复步骤S23,估计对应的当前人脸关键点x-(temp)。</td>   <td>G06V40/16;G06V10/774;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         董国鹏;              冯丹;              桂文才;              邢闯锋;              朱卫威;              宗广辉;              赵威;              李金贝;              李辰;              黄林冲;                   赖正首       </td>   <td>中铁七局集团有限公司;中铁七局集团有限公司勘测设计研究院;中山大学</td>   <td>信息提取模型的训练方法、装置及电子设备</td>   <td>河南省</td>   <td>CN113420533B</td>   <td>2023-12-29</td>   <td>本申请属于信息处理领域,提出了一种信息模型的训练方法、装置及电子设备。该方法包括：对获取的第一样本数据集进行数据增广处理,得到增广后的第二样本数据集；将所述第二样本数据集中的文本数据转换为语义向量；将所述语义向量输入信息提取模型进行计算,输出字符所对应的信息类别,根据输出的信息类别与标定的信息类别的差异调整字符分类模型的参数,直到两者的差异符合预设的差异要求。通过将第二样本数据集中的文本数据转换为语义向量,可以消除了传统信息提取技术中的分词程序,使该模型能够适用于不同的语言种类,并且数据增强处理时不需要手动标注,可以更为充分利用小样本,高效的训练出可靠、鲁棒的信息提取模型。</td>   <td>1.一种信息提取模型的训练方法,其特征在于,所述方法包括：确定用于训练的、建筑工程行业的第一样本数据集,对所述第一样本数据集进行数据增广处理,得到增广后的第二样本数据集；将所述第二样本数据集中的文本数据转换为语义向量；将所述语义向量输入信息提取模型进行计算,输出字符所对应的信息类别,确定所输出的字符的信息类别与第二样本数据中所标定的信息类别的差异,根据所述差异调整所述信息提取模型的参数,直到两者的差异符合预设的差异要求；将所述第二样本数据集中的文本数据转换为语义向量,包括：确定第二样本数据集中包括的字符所对应的字符ID；确定第二样本数据集中的第i字符所对应周围字符；根据所述第i字符的周围字符的字符ID,以及第i字符的字符ID,确定权值矩阵W；根据所述权值矩阵和所述第i字符的字符ID,得到第i字符对应的语义向量；根据所述第i字符的周围字符的字符ID,以及第i字符的字符ID,确定权值矩阵W,包括：将第二样本数据集的字符,按照字符嵌入公式：以及/&gt;确定第二样本数据集对应的权值矩阵W,其中,c为第i字符的周围字符的窗口半径,Y-i为字符嵌入公式输出的第i字符,W'为用于将语义向量转换为第i字符的矩阵。</td>   <td>G06F40/151;G06F40/205</td>  </tr>        <tr>   <td>中国专利</td>   <td>         江凯萱;              杨翊;              孙硕博;              陈瑞钦;                   赵宝全       </td>   <td>中山大学</td>   <td>一种面向叙述性媒体数据结构化内容处理方法、系统</td>   <td>广东省</td>   <td>CN117312588A</td>   <td>2023-12-29</td>   <td>本申请涉及数据处理领域,尤其是涉及一种面向叙述性媒体数据结构化内容处理方法、系统、设备及介质,所述方法包括获取叙述性媒体数据；提取所述叙述性媒体数据中的语音信息和视觉信息；识别并提取所述语音信息中的文本数据,确定所述文本数据的关键词；识别并提取所述视觉信息中的视觉实体,所述视觉实体包括文本、公式和图形至少一种；根据所述关键词对所述文本数据进行话题分割,得到话题文本；将所述话题文本进行摘要生成；将生成的摘要和视觉实体进行关联。本申请针对叙述性媒体数据,提取其语音、视频多模态信息进行关联,能够提高对叙述性媒体数据结构化内容的全面性。</td>   <td>1.一种面向叙述性媒体数据结构化内容处理方法,其特征在于,所述方法包括：获取叙述性媒体数据；提取所述叙述性媒体数据中的语音信息和视觉信息；识别并提取所述语音信息中的文本数据,确定所述文本数据的关键词以及关键词所在的区间；识别并提取所述视觉信息中的视觉实体,所述视觉实体包括文本、公式和图形至少一种；根据所述关键词所在的区间对所述文本数据进行话题分割,得到话题文本；将所述话题文本进行摘要生成；将生成的摘要和视觉实体进行关联。</td>   <td>G06F16/483;G06F16/438;G06F40/211;G06F40/216;G06F40/289</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孟得山;              向润晖;              邹祥祥;              徐河振;                   徐贺杰       </td>   <td>中山大学</td>   <td>机械臂控制系统的动力学建模方法、装置及电子设备</td>   <td>广东省</td>   <td>CN117313261A</td>   <td>2023-12-29</td>   <td>本发明实施例提供了一种机械臂控制系统的动力学建模方法、装置及电子设备,包括：获取待建模的肌腱驱动双自由度机械关节臂的机械结构；根据机械结构,构建初始动能方程,并构建肌腱驱动双自由度机械关节臂的绳索做功与关节做功的关系表达式；根据关系表达式,确定肌腱驱动双自由度机械关节臂的关节轴的驱动力矩方程；根据驱动力矩方程以及初始动能方程,确定机械臂动力学方程；基于预设的动力学建模软件,根据机械臂动力学方程以及机械结构,生成肌腱驱动双自由度机械关节臂的动力学模型。该方法通过将绳索做功与关节做功的关系表达式与初始动能方程进行组合建模,提升针对绳驱空间机械臂的机械臂控制系统的动力学建模得到的系统模型的精度。</td>   <td>1.一种机械臂控制系统的动力学建模方法,其特征在于,包括：获取待建模的肌腱驱动双自由度机械关节臂的机械结构；根据所述机械结构,构建初始动能方程,并基于虚功原理,构建所述肌腱驱动双自由度机械关节臂的绳索做功与关节做功的关系表达式；根据所述关系表达式,确定肌腱驱动双自由度机械关节臂的关节轴的驱动力矩方程；根据所述驱动力矩方程以及所述初始动能方程,确定机械臂动力学方程；基于预设的动力学建模软件,根据所述机械臂动力学方程以及所述机械结构,生成所述肌腱驱动双自由度机械关节臂的动力学模型。</td>   <td>G06F30/17;B25J9/16;B64G4/00;G06F30/20;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周拱朗;              陈翔;                   梁国华       </td>   <td>中山大学</td>   <td>基于FPGA的点云压缩加速装置及方法</td>   <td>广东省</td>   <td>CN117314723A</td>   <td>2023-12-29</td>   <td>本发明公开了一种基于FPGA的点云压缩加速装置及方法,点云压缩加速装置包括：PL端、PS端和DDR,PS端用于向PL端发送点云数据压缩命令和前后帧标志信号；DDR,用于存储初始点云数据及压缩完成后的压缩码流；体素化模块,采用流水线技术对点云数据进行体素化,生成体素特征图；八叉树数组计算模块,用于通过由FIFO连接的的莫顿码生成模块和八叉树信息生成模块采用数据流并行方式处理体素特征图,生成八叉树数组信息；几何信息压缩模块,用于根据八叉树数组信息计算占用位,生成几何信息压缩码流；属性特征压缩模块,用于根据八叉树数组信息及前后帧标志信号对属性特征进行压缩,生成属性特征压缩码流。本发明可提高点云压缩的吞吐率、降低延时。</td>   <td>1.一种基于FPGA的点云压缩加速装置,其特征在于,所述点云压缩加速装置包括PL端、PS端和DDR,所述PS端分别与所述PL端、DDR电连接；其中,所述PS端,用于向PL端发送点云数据压缩命令,并标记每三帧点云图的第一帧为前帧,第二帧和第三帧为后帧,用向PL端发送本帧点云的前后帧标志信号；所述PL端包括数据搬移模块、体素化模块、八叉树数组计算模块、几何信息压缩模块、属性特征压缩模块；所述体素化模块,用于根据点云数据压缩命令生成点云数据读取命令,向数据搬移模块发送点云数据读取命令,从数据搬移模块接收初始点云数据,初始点云数据包括一组点的坐标以及点的RGB值,并采用流水线技术对初始点云数据进行体素化,生成体素特征图并传至八叉树数组计算模块；所述八叉树数组计算模块,用于通过由FIFO连接的莫顿码生成模块和八叉树信息生成模块采用数据流并行方式处理体素特征图；所述莫顿码生成模块,用于对所述体素特征图进行莫顿码的计算,得到莫顿码数组；所述八叉树信息生成模块,用于根据所述莫顿码数组数据生成基于八叉树结构的父数组；所述几何信息压缩模块,用于根据所述八叉树数组计算模块生成的莫顿码数组和父数组进行八叉树占用位信息计算,根据占用位信息对八叉树节点进行广度排序,输出为二进制编码流并传至数据搬移模块；所述属性特征压缩模块,用于根据八叉树数组计算模块生成的莫顿码数组对本帧的体素进行分段,并根据本帧的前后帧标志信号进行模式选择,选择启用帧内点云压缩模块或帧间点云压缩模块之一进行工作,生成属性特征压缩码流并传至数据搬移模块；所述数据搬移模块,还用于将几何信息压缩码流和属性特征压缩码流发送至DDR中进行存储；所述DDR,用于存储初始点云数据及压缩完成后的几何信息压缩码流和属性特征压缩码流。</td>   <td>G06T1/20;G06T1/60;G06T9/40;G06F15/78</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              马义坤;                   齐浩然       </td>   <td>中山大学</td>   <td>一种图像处理方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117314773A</td>   <td>2023-12-29</td>   <td>本发明公开了一种图像处理方法、装置、电子设备及存储介质,方法包括：获取待处理的原始图像,对原始图像进行下采样,并进行第一特征提取,获得浅层特征；将浅层特征输入多层编解码结构进行编解码处理,得到第一特征；对第一特征进行上采样,并进行卷积处理,获得第一图像；对第一图像进行小波变换,获得低频分量和高频分量；根据低频分量,通过低频内容提取得到低频输出；根据高频分量,通过高频细节增强得到高频输出；对低频输出和高频输出进行融合处理,得到目标图像。本发明实施例通过联合多层级编解码器结构、邻近交叉注意力机制,从而有效提升在跨分辨率去摩尔纹任务的鲁棒泛化能力,可广泛应用于图像处理技术领域。</td>   <td>1.一种图像处理方法,其特征在于,包括：获取待处理的原始图像,对所述原始图像进行下采样,并进行第一特征提取,获得浅层特征；将所述浅层特征输入多层编解码结构进行编解码处理,得到第一特征；其中,所述多层编解码结构包括多层数量相同的编码器和解码器,所述编码器和所述解码器通过邻近交叉注意力机制进行数据传输；对所述第一特征进行上采样,并进行卷积处理,获得第一图像；对所述第一图像进行小波变换,获得低频分量和高频分量；根据所述低频分量,通过低频内容提取得到低频输出；并根据所述高频分量,通过高频细节增强得到高频输出；对所述低频输出和所述高频输出进行融合处理,得到目标图像。</td>   <td>G06T5/00;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         冯仕庭;              李雪华;              黄炳升;              毛仁;              叶子茵;              李飞;              王海鹏;                   马锦婷       </td>   <td>中山大学附属第一医院</td>   <td>基于多示例学习和病理图像的克罗恩病检测方法</td>   <td>广东省</td>   <td>CN117314888A</td>   <td>2023-12-29</td>   <td>本申请公开了一种基于多示例学习和病理图像的克罗恩病检测方法,方法包括获取若干病理图像,并获取每个病理图像对应的切片特征,其中,若干病理图像对应同一目标对象,且每个病理图像均包括预设数量的图像块；基于各切片特征确定各病理图像各自对应的切片预测结果；基于各切片特征确定目标对象的对象特征,并基于对象特征和所述切片特征确定所述目标对象的对象预测结果。本申请在提取到病理图像对应的切片特征后,基于切片特征确定病理图像的切片预测结果和目标对象特征,然后基于切片水平的特征和病患水平的特征确定目标对象预测结果,将切片和病患水平共同作用于克罗恩病检测的过程,提高了克罗恩病检测准确性,降低误诊率。</td>   <td>1.一种基于多示例学习和病理图像的克罗恩病检测方法,其特征在于,所述方法包括：获取若干病理图像,并获取每个病理图像对应的切片特征,其中,若干病理图像对应同一目标对象,且每个病理图像均包括预设数量的图像块；基于各切片特征确定各病理图像各自对应的切片预测结果；基于各切片特征确定目标对象的对象特征,并基于对象特征和所述切片特征确定所述目标对象的对象预测结果。</td>   <td>G06T7/00;G06N3/0455;G06N3/0464;G06N3/048;G06N3/08;G06V10/44;G06V10/764;G06V10/80;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         崔应谱;              胡莹莹;              蒋永泺;              张虽虽;              秦菊;              贺长征;                   段博文       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所);北京赛迈特锐医疗科技有限公司</td>   <td>对初步报告的病变位置合理性的判断方法及系统</td>   <td>广东省</td>   <td>CN117316425A</td>   <td>2023-12-29</td>   <td>本发明提供了一种对初步报告的病变位置合理性的判断方法,包括：获取审核医生在初步报告上对病变位置的修改日志；判断修改日志的类型,若修改日志为在原有病变位置标签上重新选择新的解剖部位作为病变位置,则获取新的解剖部位标签；基于相邻解剖部位数据库,将新的解剖部位标签与原有病变位置对应的解剖部位标签进行对比,若两者相邻,则确定初步报告的病变位置合理；若两者不相邻,则确定初步报告的病变位置不合理,将判断结果自动显示在单病种结构化报告界面上。本发明还公开了一种对初步报告的病变位置合理性的判断系统。本发明能够通过对比初步报告、审核报告的病变位置标签及基于解剖逻辑相邻性,自动化的进行病变位置合理性的判断。</td>   <td>1.一种对初步报告的病变位置合理性的判断方法,其特征在于,包括：获取审核医生在初步报告上对病变位置的修改日志；所述修改日志为：在原有病变位置标签上重新选择新的解剖部位作为病变位置、新增病变位置标签、删除原有病变位置标签中的一种或两种；判断所述修改日志的类型,若所述修改日志为在原有病变位置标签上重新选择新的解剖部位作为病变位置,则获取新的解剖部位标签；基于相邻解剖部位数据库,将新的解剖部位标签与原有病变位置对应的解剖部位标签进行对比,若两者相邻,则确定初步报告的病变位置合理；若两者不相邻,则确定初步报告的病变位置不合理,将判断结果自动显示在单病种结构化报告界面上。</td>   <td>G16H50/20;G16H30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              肖逢枝;              陈荣军;              谢舜道;              朱雄泳;                   曾衍瀚       </td>   <td>中山大学</td>   <td>一种二维条码初定位方法</td>   <td>广东省</td>   <td>CN110717500B</td>   <td>2023-12-26</td>   <td>本发明提供的一种二维条码初定位方法,包括：对原始二维码图像进行预处理并进行降采样处理；利用二值化算法对降采样处理后的图像进行处理,得到Min-Max二值化图片；根据二值化图片建立对应的积分图,通过边缘检测算子计算得到候选的矩形区域；计算窗口内边缘点的方向梯度直方图EOH,通过EOH特征判定,将符合特征判定的候选区域坐标映射到原始尺寸的灰度图上,输出二维条码的大致区域,完成初定位操作。本发明提供的一种二维条码初定位方法,实现快速自适应分离、提取出二维条码大致区域图像,有效减少了后续处理的计算量,加快整体识别效率,适用于移植到嵌入式实时系统,实现了对实际拍摄的光照不均、模糊、即便二维条码图像的初定位。</td>   <td>1.一种二维条码初定位方法,其特征在于：包括以下步骤：S1：采集摄像头拍摄的含有二维条码的原始图像并对原始图像进行预处理；S2：对预处理后的不同分辨率的图像进行降采样处理；S3：利用改进的Bernsen局部二值化算法对降采样处理后的图像进行处理,得到Min-Max二值化图片；S4：根据二值化图片建立对应的积分图,统计窗口内前景数,滤去分散的前景像素；具体为：根据二值化图片建立对应的积分图,设定窗口大小为步骤S3中所述窗口大小的三倍；遍历二值化图片前景像素点,利用积分图统计当前窗口内的前景像素的个数,将少于1/4窗口总数的前景像素点剔除,滤去分散的前景像素；S5：通过边缘检测算子计算得到候选的矩形区域,对候选的矩形区域进行边缘提取,计算窗口内边缘点的方向梯度直方图EOH,通过EOH特征判定,将符合特征判定的候选区域坐标映射到原始尺寸的灰度图上,输出二维条码的区域,完成初定位操作；具体包括以下步骤：S51：通过Sobel边缘检测算子检测出余下的矩形区域并选取3个矩形区域作为候选区域,提取其各自中心坐标映射到原始图像上,并以原始图像为中心的窗口上进行边缘提取,计算窗口内边缘点的方向梯度直方图EOH；S52：通过EOH特征判定,将错误的候选区域提出,其中EOH特征提取计算式具体为：                  n＝9                  其中θ(x,y)为窗口坐标为(x,y)的边缘点的无符号梯度方向,n为梯度方向子区间个数,α-(θ2)为边缘点的方向梯度直方图的最大两个主导方向角,/&gt;为两个主导方向角区间的值,EOH-n为提取的窗口EOH特征；S53：将符合特征判定的候选区域坐标映射到原始尺寸的灰度图上,输出二维条码的区域,完成初定位操作。</td>   <td>G06V10/22;G06V10/44;G06V10/50;G06V10/24;G06V10/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁紫旭;              徐挺洋;              王辉;              姚建华;              秦秀森;              赵业标;              王怀明;              蔡建;              曹务腾;              范新娟;              马腾辉;              刘晓霞;              陈文乐;              李杨;              初丽丽;              杨梓锋;                   罗坚       </td>   <td>中山大学附属第六医院</td>   <td>肠癌腹膜转移人工智能预测模型及该模型的构建方法</td>   <td>广东省</td>   <td>CN111653355B</td>   <td>2023-12-26</td>   <td>本发明公开一种肠癌腹膜转移人工智能预测模型及该模型的构建方法,所述方法的步骤包括：筛选病例,勾画所述病例的肿瘤原发灶,根据所述病例和所述肿瘤原发灶构建并验证卷积神经网络模型,以及构建并验证支持向量机模型,基于CT特征的结直肠癌同时性腹膜转移人工智能模型预测准确性高,且具有高灵敏度,特异度。</td>   <td>1.一种肠癌腹膜转移人工智能预测模型构建方法,其特征在于,步骤包括：筛选病例,勾画所述病例的肿瘤原发灶,根据所述病例和所述肿瘤原发灶构建并验证卷积神经网络模型,以及构建并验证支持向量机模型；筛选病例,具体为：从腹膜转移组中筛选腹膜转移病例,从非腹膜转移组中筛选非腹膜转移病例,将所述腹膜转移病例分为训练组病例和验证组病例,将所述非腹膜转移病例分为训练组病例和验证组病例,所述腹膜转移病例的验证组病例数量与非腹膜转移病例的验证组病例数量相同；勾画所述病例的肿瘤原发灶,具体为：勾画所有所述腹膜转移病例的肿瘤原发灶；根据所述病例和所述肿瘤原发灶构建并验证卷积神经网络模型,以及构建并验证支持向量机模型,具体为：根据勾画后的所述腹膜转移病例的训练组病例和非腹膜转移病例的训练组病例,构建卷积神经网络模型,根据勾画后的所有所述腹膜转移病例,以及所有所述非腹膜转移病例,验证所述卷积神经网络模型；根据勾画后的所述腹膜转移病例、非腹膜转移病例以及所述卷积神经网络模型,构建并验证所述支持向量机模型；根据勾画后的所述腹膜转移病例的训练组病例和非腹膜转移病例的训练组病例,构建卷积神经网络模型,具体为：定义每一个勾画后的所述腹膜转移病例的训练组病例的CT影像作为卷积神经网络的输入张量,定义每一个非腹膜转移病例的训练组病例的CT影像作为卷积神经网络的输入张量,构建Residual learning运算元,根据Residuallearning运算元,基于Resnet-18架构构建所述卷积神经网络模型；对于病人i,定义其CT影像为的输入张量,/&gt;代表了CT影像第j,k,l位置上的像素,所对应的二值变量y-i∈{0,1},表示病人i是或否有肠癌腹膜转移的情况；构建Residual learning的运算元,其输入x与输出y满足以下条件：                                    其中,σ(·)表示一个ReLU层,其表达式为：对于3D图像,/&gt;为一个有64个通道的3×3×3×64的3DCNN,卷积操作*定义为b～(j,k,l)＝a～([j-1,j+1],[k-1,k+1],[l-1,l+1])·W-c,即a中的每个3×3×3的小方块与W-c内积后作为b张量中的一个元素；所述卷积神经网络模型最终一层取平均后为一个512维的向量此向量经过线性映射与softmax操作后变为一个2值的向量/&gt;                                    其中而为模型变量,最终的损失函数则为：                  所述卷积神经网络模型是上述损失函数得到的模型,通过计算得到值,如果/&gt;则预测患有直肠癌腹膜转移,反之则没有。</td>   <td>G16H50/20;G16H50/70;G06N3/0464;G06N20/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              周凡;                   冯钰新       </td>   <td>中山大学</td>   <td>一种基于颜色域和频域双重约束的视频去雾方法与系统</td>   <td>广东省</td>   <td>CN117291828A</td>   <td>2023-12-26</td>   <td>本发明公开了一种基于颜色域和频域双重约束的视频去雾方法与系统。包括：合成一个模拟真实雾霾场景的视频雾霾数据集；构建颜色域和频域双重约束的视频去雾网络；利用所述视频雾霾数据集对所述视频去雾网络进行训练,并使用损失函数L-1和L-c来约束网络的训练朝去雾自然的方向更新；在网络固定阶段,加载训练好的网络权值,将真实雾霾测试数据集输入到所述视频去雾网络得到预测无雾帧,评估去雾效果,性能良好时固定参数,形成最终的视频去雾网络；在网络应用阶段,用户将待处理的雾霾视频输入最终的视频去雾网络中,得到去雾视频。本发明能够对真实视频雾霾场景进行去除。相比于现有视频去雾方法,在去雾质量评价、去雾快速性方面具有明显的优势。</td>   <td>1.一种基于颜色域和频域双重约束的视频去雾方法,其特征在于,所述方法包括：合成一个模拟真实雾霾场景的低光照度的视频雾霾数据集；构建颜色域和频域双重约束的视频去雾网络；利用所述视频雾霾数据集对所述颜色域和频域双重约束的视频去雾网络进行训练,并使用相似度比较损失函数L-1和感知对比损失函数L-c来约束网络的训练朝去雾自然的方向更新；在网络固定阶段,加载训练好的网络权值,将基于真实雾霾视频的测试数据集输入到所述颜色域和频域双重约束的视频去雾网络得到预测无雾帧,利用无参考图质量评价指标评估去雾效果,当评价指标上性能良好时固定参数,形成最终的颜色域和频域双重约束的视频去雾网络；在网络应用阶段,用户将待处理的雾霾视频输入最终的颜色域和频域双重约束的视频去雾网络中,得到去雾视频。</td>   <td>G06T5/00;G06T5/50;G06V10/74;G06V10/776;G06V10/82;G06N3/0464;G06N3/0455;G06N3/0442;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈玥瑶;              林笑丰;              林楚旋;              曹康养;              樊雅恒;              黄炳升;              罗宴吉;              石思雅;              冯仕庭;              张健;              刁现芬;                   盘中贤       </td>   <td>深圳市中医院;中山大学附属第七医院(深圳)</td>   <td>一种胰腺导管腺癌隐匿性腹膜转移的预测方法及相关装置</td>   <td>广东省</td>   <td>CN117291869A</td>   <td>2023-12-26</td>   <td>本申请公开了一种胰腺导管腺癌隐匿性腹膜转移的预测方法及相关装置,方法包括获取待检测CT图像及临床信息；基于待检测CT图像、胰腺导管腺癌分割模型和腹膜分割模型,确定胰腺导管腺癌深度语义分割特征及腹膜深度语义分割特征；基于临床信息、胰腺导管腺癌及腹膜的深度语义分割特征,确定待检测CT图像对应的隐匿性腹膜转移类别。本申请通过深度语义分割模型确定胰腺导管腺癌及腹膜的深度语义分割特征,基于胰腺导管腺癌深度语义分割特征、腹膜深度语义分割特征和临床信息对胰腺导管腺癌隐匿性腹膜转移进行预测,发挥影像组学方法和深度学习技术的优势,同时引入病灶、腹膜区域和临床的监督信息,提高了胰腺导管腺癌隐匿性腹膜转移预测的准确性。</td>   <td>1.一种胰腺导管腺癌隐匿性腹膜转移的预测方法,其特征在于,所述方法包括：获取待检测CT图像以及临床信息；基于所述待检测CT图像以及经过训练的胰腺导管腺癌分割模型和经过训练的腹膜分割模型,确定胰腺导管腺癌深度语义分割特征以及腹膜深度语义分割特征；基于所述临床信息、胰腺导管腺癌深度语义分割特征以及腹膜深度语义分割特征,预测所述待检测CT图像对应的隐匿性腹膜转移类别。</td>   <td>G06T7/00;G06V10/26;G06V10/762;G06V10/764;G06V10/80;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄乙涓;                   高羽       </td>   <td>中山大学附属第六医院</td>   <td>用于MMDS辅助诊断的M Index模型的构建方法及应用</td>   <td>广东省</td>   <td>CN116994762B</td>   <td>2023-12-22</td>   <td>本发明涉及一种用于MMDS辅助诊断的M Index模型的构建方法及应用。本发明以羊水细胞中的特定代谢产物作为检测指标,可快速获得检测结果,进而对患者罹患MMDS的风险进行合理诊断和评估,以及时进行干预或治疗,大大简化了临床检测流程,降低了医疗成本,可有效避免医疗资源的浪费。本发明的M Index模型对于填补实现多发性线粒体功能障碍综合征精准快速诊断评估的空白,更快速、更准确地实现对多发性线粒体功能障碍综合征癌患儿的个体化精准干预或治疗具有重要的现实意义,具有极高的社会价值和市场应用前景。</td>   <td>1. 一种用于多发性线粒体功能障碍综合征辅助诊断的M Index模型的构建方法,其特征在于,包括如下步骤：(1)分别从正常羊水和异常羊水中离心得到羊水细胞,接种于细胞培养皿中；7天后收获细胞,离心后弃上清；所述异常羊水为胎儿确诊为多发性线粒体功能障碍综合征的孕妇的羊水；(2)对离心弃上清后的羊水细胞进行萃取,离心后取上清液,得到羊水细胞提取物；(3)加入等体积的3-硝基苯肼甲醇溶液和1-(3-二甲氨基丙基)-3-乙基碳二亚胺吡啶溶液,混匀后加热进行衍生化,得到衍生化溶液；(4)衍生化溶液中加入分别经～(13)C标记的3-硝基苯肼甲醇溶液和1-(3-二甲氨基丙基)-3-乙基碳二亚胺吡啶溶液反应得到的同位素内标液；(5)加入甲醇-水混合溶液进行稀释后,进行代谢物分析；(6)对正常孕妇和确诊胎儿为多发性线粒体功能障碍综合征的孕妇这两组中各代谢物水平按照差异程度进行排序,筛选得到存在显著性差异的代谢物；所述代谢物由己酰-L-肉碱、二十碳五烯酸、L-戊酰基肉碱、二十二碳五烯酸、亚油酰基肉碱组成；(7)基于步骤(6)中筛选得到的多发性线粒体功能障碍综合征具有显著相关性的代谢物,并按照如下公式进行与并按照如下公式进行M Index的计算：M Index=∑～N-(i=1)(k-i×Level of metabolite-i)/N；其中N=5,k-i表示各代谢物的系数,Level of metabolite-i表示各代谢物的相对水平；所述己酰-L-肉碱的k-i为6.0652,二十碳五烯酸的k-i为0.3024、L-戊酰基肉碱的k-i为3.198、二十二碳五烯酸的k-i为0.1113,亚油酰基肉碱的k-i为8.7800。</td>   <td>G16H50/50;G16H50/30;G16H50/70;G01N33/92;G01N33/68</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张文毅;              梁嘉迪;              杜云飞;                   卢宇彤       </td>   <td>中山大学</td>   <td>一种基于Arm架构的NumPy运算加速优化方法</td>   <td>广东省</td>   <td>CN112783503B</td>   <td>2023-12-22</td>   <td>本发明为克服Arm平台上原生NumPy库存在计算性能低下的缺陷,提出一种基于Arm架构的NumPy运算加速优化方法,包括以下步骤：配置Arm架构环境,获取NumPy源代码；对NumPy源代码中待优化函数进行类型判断：若待优化函数为数值计算类函数,则对待优化函数进行循环体优化,再对待优化函数进行多线程处理；否则直接对待优化函数进行多线程处理；然后将完成函数优化的NumPy源代码进行编译优化。本发明对Arm架构环境中的NumPy源代码进行优化,根据NumPy源代码中的函数类型执行循环体优化、多线程处理等操作,能够有效提高了依赖于NumPy的各类Python程序运行效率。</td>   <td>1.一种基于Arm架构的NumPy运算加速优化方法,其特征在于,包括以下步骤：S1：配置Arm架构环境,获取NumPy源代码；S2：对NumPy源代码中待优化函数进行类型判断：若待优化函数为数值计算类函数,则执行步骤S3；若待优化函数为非数值计算类函数,则跳转执行步骤S4；S3：对待优化函数进行循环体优化；对待优化函数进行循环体优化的具体步骤包括对循环体内部语句的SIMD改写优化,以及对循环体本身进行优化；在对循环体本身进行优化时,根据循环体的特性对循环体本身进行拆分、合并和展开操作；其中：对时间复杂度大于或等于的循环体进行拆分操作,将循环体拆分为若干小循环；对时间复杂度小于的循环体进行合并操作,将待优化函数上下流中的若干循环体合并至一个循环体；对循环之间存在循环依赖或访问冲突的循环体采用循环展开操作；S4：对待优化函数进行多线程处理；对待优化函数进行多线程处理的具体步骤包括使用OpenMP进行多线程改写、合理化并行执行的任务大小和避免不必要的共享写入；所述Arm架构中的一个计算节点包括128个核心,对待优化函数使用OpenMP进行多线程改写时,在需要多线程处理的语句前添加调用指令,使其能将所控制的语句分发到各核心上实行；对待优化函数进行合理化并行执行的任务大小时,对计算节点的任务大小进行线性化划分,然后对划分的任务进行实测,选取出合理的任务细粒度划分下的运行时间最短的任务大小作为核心的最小任务大小；对待优化函数进行避免不必要的共享写入时,通过OpenMP代码中使用reduction子句替代直接写入共享变量,在循环过程中写入线程私有变量；S5：将完成函数优化的NumPy源代码进行编译优化；对完成函数优化的NumPy源代码进行编译优化的具体步骤包括自动向量化处理和选择编译优化选项；对完成函数优化的NumPy源代码进行自动向量化处理时,设定Arm架构中的编译器自动采用Neon Intrinsics对程序的编译过程进行优化；对完成函数优化的NumPy源代码进行选择编译优化选项处理时,对Arm架构中的编译器设置O2优化选项,执行不包含时间和空间折中的优化,且不进行循环打开和函数内联。</td>   <td>G06F8/41</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;                   张易东       </td>   <td>中山大学</td>   <td>一种基于AO算法的碳排放量预测方法、装置及设备</td>   <td>广东省</td>   <td>CN115759346B</td>   <td>2023-12-22</td>   <td>本发明涉及环境科学与机器学习技术领域,公开了一种基于AO算法的碳排放量预测方法、装置及设备。本发明从预置的多个碳排放影响因素中筛选目标影响因素；运用AO算法,优化分数阶灰色预测模型的阶数和支持向量回归预测模型的核心参数,分别训练得到碳排放影响因素预测模型和碳排放量预测模型,基于所述碳排放影响因素预测模型对所述目标影响因素进行预测,得到目标影响因素的预测值,将该预测值作为模型输入,利用所述碳排放量预测模型对碳排放量进行预测。本发明存在可解释性强、客观性强、预测精度高以及适用范围较大的优点,能够为不同地区和行业的碳排放量预测提供较精确的科学依据。</td>   <td>1.一种基于AO算法的碳排放量预测方法,其特征在于,包括：从预置的多个碳排放影响因素中筛选目标影响因素；获取目标影响因素数据,基于所述目标影响因素数据训练分数阶灰色预测模型并运用AO算法优化所述分数阶灰色预测模型的阶数,得到碳排放影响因素预测模型；其中,所述从预置的多个碳排放影响因素中筛选目标影响因素,包括：基于解释结构模型法对各所述碳排放影响因素进行分析,基于分析得到的层次拓扑图筛选出关键影响因素；对筛选出的关键影响因素进行岭回归分析,得到各所述关键影响因素的岭回归系数,剔除所述岭回归系数不满足预置岭回归系数条件的关键影响因素,得到目标影响因素；AO算法采用原始数据与对应预测值的平均绝对百分误差作为AO算法的适应度函数；基于所述碳排放影响因素预测模型对所述目标影响因素进行预测,得到目标影响因素的预测值；获取碳排放量及对应影响因素的历史数据,根据所述历史数据构建训练样本数据集,基于所述训练样本数据集训练支持向量回归预测模型并运用AO算法优化所述支持向量回归预测模型的参数,得到碳排放量预测模型,所述参数包括惩罚系数和/或核函数参数；将所述目标影响因素的预测值作为模型输入,利用所述碳排放量预测模型对碳排放量进行预测；其中,所述AO算法将安康鱼在深海中随机游走觅食的过程模拟为全局寻优的过程,基于莱维飞行进行全局寻优,并将搜索种群分为雌鱼和雄鱼两大群体,按照安康鱼觅食和交配行为进行局部寻优,以得到最优解；所述AO算法具体包括：设置种群数量、求解维度和迭代次数,初始化种群；进行随机游走觅食,使用莱维飞行形成全局寻优新解；对所有解进行适应度值运算,计算得到全局寻优新解的适应度值；对比莱维飞行后的全局寻优新解与全局寻优原解的适应度值大小,选取适应度值较小的作为全局寻优解,具体的：将安康鱼在深海中随机游走觅食模拟为全局寻优的过程,用莱维飞行算法进行模拟,公式表达式为：          ；式中,表示安康鱼在第/&gt;时刻的位置,/&gt;表示安康鱼在第/&gt;时刻的位置,/&gt;为步长比例因子,/&gt;为服从莱维分布的路径,/&gt;为莱维飞行参数；在莱维飞行结束后获得一个新解,通过计算并比较新解和原解的适应度大小,从而获得适应度最小的解,实现全局搜索寻优；将种群分成雌鱼和雄鱼,并根据安康鱼觅食和交配行为分别进行局部寻优；对适应度最高的头鱼进行随机游走；雌鱼以头鱼的位置和种群平均位置为目标进行游走,具体的：雌鱼的头鱼占据了适应度最高的位置,通过寻找其它同类进行随机寻优,公式表达为：          ；式中,表示第/&gt;时刻适应度最高的安康鱼位置,/&gt;为鱼群搜索的步长修正系数,为0到1的随机数,/&gt;表示第/&gt;时刻随机安康鱼的位置；其他雌鱼数据为总群体的50%,受觅食本能和繁殖本能影响,不断往食物量较高的地方以及群体中心移动,公式表达为：          ；式中,表示第i条安康鱼在第/&gt;时刻的位置,/&gt;表示种群平均位置,/&gt;为鱼群搜索的第一回退系数；雄鱼以种群平均位置为目标,同时躲避适应度最差位置进行游走,具体的：将一半雄鱼设置为受繁殖本能以及生存环境和天敌的影响,不断往种群中心移动并远离适应度最低位置,另一半设置为仅受生存环境和天敌的影响进行寻优,公式表达为：          ；式中,为适应度最差安康鱼的位置,/&gt;为鱼群搜索的第二回退系数,/&gt;为迭代时间,/&gt;为预置的迭代时间阈值；对比局部寻优新解与原解的适应度大小,选取适应度较小的解；判断算法结束条件：当达到全局最大迭代次数时,停止计算,然后输出最优解,否则将全部安康鱼进行重新混合,转至进行全局寻优的步骤。</td>   <td>G06Q10/04;G06Q50/26;G06N20/10;G06N3/006;G06F17/18;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘彬媛;              翁海松;              王青松;              石珂;              林明鑫;              赖涛;                   黄海风       </td>   <td>中山大学</td>   <td>一种基于图像重叠区域的图像匀色方法及装置</td>   <td>广东省</td>   <td>CN116503274B</td>   <td>2023-12-22</td>   <td>本发明公开了一种基于图像重叠区域的图像匀色方法、装置及计算机可读存储介质,所述方法包括：获取多张经过预处理的航带图像；基于预设的屏蔽水域掩膜在相邻的所述航带图像中提取重叠区域,以及提取相邻的所述航带图像的辐射特性曲线；根据所述重叠区域的像素和所述辐射特性曲线对相邻的所述航带图像进行第一匀色处理。本发明可以获取多张经过预处理的航带图像,基于预设的屏蔽水域掩膜在相邻的两张航带图像的重叠区域,根据重叠区域的像素信息和待匀色航带图像的辐射特性信息对两张航带图像进行匀色处理,以降低匀色的偏差,提升匀色效果。</td>   <td>1.一种基于图像重叠区域的图像匀色方法,其特征在于,所述方法包括：获取多张经过预处理的航带图像；基于预设的屏蔽水域掩膜在相邻的所述航带图像中提取重叠区域,以及提取相邻的所述航带图像的辐射特性曲线；根据所述重叠区域的像素和所述辐射特性曲线对相邻的所述航带图像进行第一匀色处理；所述第一匀色处理的计算如下式所示：                  上式中,m-x和m-y分别是参考的航带图像X和待匀色的航带图像Y在所述重叠区域内像素的第一均值,σ-x和σ-y分别参考的航带图像X和待匀色的航带图像Y在所述重叠区域内像素的第一标准差,β为辐射特性拟合曲线；所述第一匀色处理的计算的门限条件如下式所示：                  其中,0&lt;γ&lt;1,0&lt;α&lt;1。</td>   <td>G06T5/00;G06T3/40;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭键清;              樊金飞;                   李蔚东       </td>   <td>中山大学</td>   <td>一种基于深度学习的物流包裹自主检测方法</td>   <td>广东省</td>   <td>CN113807466B</td>   <td>2023-12-22</td>   <td>发明提出了一种基于深度学习的物流包裹自主检测方法,其中,根据深度学习技术要求建立物流包裹图片数据集,数据集从多个场景采集,并且具备不同的角度、光线,也包含一些密集包裹和小包裹；再对数据集中的所有图片进行手动标注。同时,考虑到物流包裹传送过程中包裹堆积导致的包裹和包裹间存在遮挡,包裹错误分类问题,引入Deep-SORT算法,改善包裹堆积情况下的检测效果,引入Deep-SORT算法造成计算量加大,模型效率降低,使用剪枝的方法对模型进行简化,提高模型效率。</td>   <td>1.一种基于深度学习的物流包裹自主检测方法,其特征在于,所述方法包括：S1物流包裹数据采集：基于深度学习模型建立物流包裹图片数据集,数据集从多个场景采集,并且具备不同的角度、光线,也包含一些密集包裹和小包裹；S2建立物流包裹数据集：根据监督学习要求,使用数据标注工具对数据集中的所有图片进行手动标注；S3使用改进后的基于深度学习的目标检测模型进行训练：获得包裹位置异常识别模型；在包裹位置异常识别模型引入先验框机制,每个小格子设定预设数量的先验框来预测边界框坐标；聚类提取先验框尺寸；引入多尺度训练；聚类生成先验框；将坐标和置信度的损失沿用均方和误差损失函数,分类损失则改成焦点损失函数；引入Deep-SORT算法,解决物流包裹传送过程中包裹堆积导致的包裹和包裹间存在遮挡,包裹错误检测；其中,将物流包裹的运动和表面特征信息结合,将基于深度特征向量最小余弦距离的表观信息和基于马式距离的运动信息进行加权融合,得到一个新的度量匹配信息,改善遮挡对于检测性能的影响；使用剪枝方法,改善引入Deep-SORT算法导致的计算量加大；通过对模型进行剪枝,减少卷积层中特征性较弱的神经元,加快训练速度；基于模型进行稀疏化训练,得到稀疏化后的BN权重；使用随机梯度下降更新BN层参数γ,公式为：                                    排列得到的γ值,选定临界值s,小于s的γ全部剪掉,得到剪枝后的模型；R-g(γ)是稀疏正则项；对剪枝后的模型进行通道调整,减少特征通道数量,简化模型；S4使用包裹位置异常识别模型对物流包裹数据进行识别：对识别结果进行评价。</td>   <td>G06V10/75;G06V10/774;G06V10/778;G06V10/82;G06N3/0464;G06N3/082</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵雅宏;              马保松;              黄胜;                   闭靖杰       </td>   <td>中山大学</td>   <td>钢筋混凝土管道劣化检测方法、系统、设备和存储介质</td>   <td>广东省</td>   <td>CN117272725A</td>   <td>2023-12-22</td>   <td>本发明涉及管道检测技术领域,公开了一种钢筋混凝土管道劣化检测方法、系统、设备和存储介质,包括根据待检测管道的管道参数,构建初始有限元管道模型；采用数字图像技术构建所述待检测管道的应力应变场；根据所述应力应变场的应变云图,对所述初始有限元管道模型的精度进行判定,根据判定结果对所述初始有限元管道模型进行调整,得到有限元管道模型；根据所述有限元管道模型,生成所述待检测管道的典型荷载位移曲线,并根据所述典型荷载位移曲线,计算所述待检测管道的劣化程度指标。本发明通过数字图像技术与有限元技术相融合,能够全面反映结构体的损伤程度,实时准确地表征长期运营结构的劣化情况,从而提高了管网系统的运维安全。</td>   <td>1.一种钢筋混凝土管道劣化检测方法,其特征在于,包括：根据待检测管道的管道参数,构建初始有限元管道模型；采用数字图像技术构建所述待检测管道的应力应变场；根据所述应力应变场的应变云图,对所述初始有限元管道模型的精度进行判定,根据判定结果对所述初始有限元管道模型进行调整,得到有限元管道模型；根据所述有限元管道模型,生成所述待检测管道的典型荷载位移曲线,并根据所述典型荷载位移曲线,计算所述待检测管道的劣化程度指标。</td>   <td>G06F30/23;G01N21/88;G01N3/52;G06T17/20;G06T19/20;G06F119/14;G06F119/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张晓溪;              朱天祥;              周知;                   陈旭       </td>   <td>中山大学</td>   <td>一种考虑激励机制的电动汽车充放电动态定价方法及系统</td>   <td>广东省</td>   <td>CN117273836A</td>   <td>2023-12-22</td>   <td>本发明公开了一种考虑激励机制的电动汽车充放电动态定价方法及系统,该方法包括：构建V2G环境下的电动汽车充放电模型并获取其状态信息；基于状态信息,通过Q网络选择合适的激励方案；将动态定价策略的补贴电价反馈给电车用户,得到决策结果；基于决策结果进行状态更新,得到激励方案的奖励值、更新的激励预算总额和更新的状态信息；估计其他可选的激励方案的对应奖励值并更新Q网络。该系统包括：模型构建模块、信息获取模块、动态定价模块、策略反馈模块、信息更新模块和奖励估计模块。通过使用本发明能够在有限激励预算内,最大限度地平衡电网电力负载,实现更灵活地调控不同电车的充放电行为。本发明可广泛应用于强化学习技术领域。</td>   <td>1.一种考虑激励机制的电动汽车充放电动态定价方法,其特征在于,包括以下步骤：构建V2G环境下的电动汽车充放电模型并初始化；获取V2G环境下的电动汽车充放电模型的状态信息；基于状态信息,通过Q网络选择合适的激励方案；将激励方案的补贴电价反馈给电车用户,得到决策结果；基于决策结果进行状态更新,得到激励方案的奖励值、更新的激励预算总额和更新的状态信息；根据当前激励方案及其奖励值,估计其他可选的激励方案的对应奖励值并更新Q网络。</td>   <td>G06Q30/0283;G06Q50/06;G06Q10/0631;H02J3/00;G06Q30/0226</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王伟;              胡航通;              黄庆华;              柯伟平;              李铭德;              吕明德;                   王毅       </td>   <td>中山大学附属第一医院</td>   <td>基于增强现实的医学影像人工智能植入方法、系统及介质</td>   <td>广东省</td>   <td>CN117274549A</td>   <td>2023-12-22</td>   <td>本发明公开了一种基于增强现实的医学影像人工智能植入方法、系统及介质,包括：收集医学影像设备输出的历史医学影像数据集,以医学影像帧频为输入数据,以目标病灶的检测框及病灶诊断结果为输出结果,构建并训练医学影像人工智能模型,并植入GPU数据处理单元；实时采集医学影像数据,进行预处理获得连续帧频,通过医学影像人工智能模型,处理实时帧频输出每一帧图像对应病灶位置的检测框和恶性概率值；将实时帧频、病灶位置及诊断建议进行融合,并显示于AR眼镜；本发明基于增强现实眼镜将人工智能辅助结果与医学影像同时呈现于医生,实时辅助以提高诊疗水平和工作效率；同时避免可穿戴设备的算力限制对大型人工智能算法应用的负面影响。</td>   <td>1.一种基于增强现实的医学影像人工智能植入方法,其特征在于,包括以下步骤：S1.收集医学影像设备输出的历史医学影像数据集,以医学影像帧频为输入数据,以目标病灶的检测框及病灶诊断结果为输出结果,构建并训练卷积神经网络,获得医学影像人工智能模型；S2.将构建的医学影像人工智能模型植入GPU数据处理单元；S3.实时采集医学影像设备输出的医学影像数据,进行预处理获得连续帧频,导入GPU数据处理单元；S4.通过植入GPU数据处理单元的医学影像人工智能模型,处理实时帧频输出每一帧图像对应病灶位置的检测框和恶性概率值；S5.将实时帧频、病灶位置和恶性概率值进行融合,并显示于AR眼镜。</td>   <td>G06T19/00;G06T1/20;G06T7/00;G06T7/73;G06V10/764;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         匡铭;              胡航通;              吕明德;              王伟;              黄庆华;              柯伟平;              李铭德;              肖晗;                   龙思哲       </td>   <td>中山大学附属第一医院</td>   <td>基于增强现实的全平台医学影像人工智能植入方法及系统</td>   <td>广东省</td>   <td>CN117274550A</td>   <td>2023-12-22</td>   <td>本发明公开了一种基于增强现实的全平台医学影像人工智能植入方法及系统,包括模型构建训练模块和增强现实眼镜；增强现实眼镜包括数据采集模块、数据处理模块、医学人工智能模块和结果显示模块；包括以下步骤：基于增强现实眼镜拍摄历史医学影像,构建全平台影像数据集,进行预处理获得实时帧频,以历史医学影像的实时帧频为输入数据,目标病灶的检测框及病灶诊断结果为输出结果,训练获得轻量级医学人工智能模型并植入增强现实眼镜；拍摄实时影像输入植入的轻量级医学人工智能模型,输出每一帧图像对应的病灶位置检测框及恶性概率值；将拍摄的实时帧频与对应帧频的病灶位置检测框及恶性概率值进行融合,融合后的图像投屏于眼镜镜片。</td>   <td>1.一种基于增强现实的全平台医学影像人工智能植入方法,其特征在于,包括以下步骤：S1.基于增强现实眼镜拍摄历史医学影像,构建全平台影像数据集；S2.根据全平台影像数据集进行预处理获得实时帧频,以历史医学影像预处理获得的实时帧频为输入数据,目标病灶的检测框及恶性概率值为输出结果,基于卷积神经网络,训练获得轻量级医学人工智能模型；S3.将获得的轻量级模型植入增强现实眼镜；S4.通过增强现实眼镜的摄像头拍摄实时影像,处理获得实时帧频,输入植入的轻量级医学人工智能模型,输出每一帧图像对应的病灶位置检测框及恶性概率值；S5.将增强现实眼镜摄像头拍摄的实时帧频与对应帧频的病灶位置检测框及恶性概率值进行融合,融合后的图像投屏于增强现实眼镜镜片。</td>   <td>G06T19/00;G06T7/00;G16H50/20;G16H30/20;G06T7/73;G06V10/764;G06V10/82;G06N3/0464;G06N3/048;G06N3/045;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王伟;              胡航通;              柯伟平;              李铭德;                   黄惠       </td>   <td>中山大学附属第一医院</td>   <td>超声人工智能的图像标准化处理方法、系统、介质及终端</td>   <td>广东省</td>   <td>CN117274568A</td>   <td>2023-12-22</td>   <td>本发明公开了超声人工智能的图像标准化处理方法、系统、介质及终端,该系统包括数据获取模块、图像转化模块、目标检测神经网络模型和图像处理输出模块；该方法包括：S1.获取超声原始文件,并进行无损转换为PNG格式单帧或系列的PNG图像并储存；S2.对PNG图像利用目标检测神经网络模型,自动识别目标图像区域,并进行自动裁剪；S3.以裁剪后目标图像区域的长径为标准,在维持原始比例基础上拟定正方形区域,目标图像区域居中,并进行非目标图像区域的灰度填充,输出并以PNG格式保存,获得最终的标准化图像；本发明可降低超声人工智能图像预处理过程中的信息损失,提高模型效能,有助于降低超声人工智能研究中图像预处理过程的异质性、促进超声人工智能应用。</td>   <td>1.一种超声人工智能的图像标准化处理方法,其特征在于,包括以下步骤：S1.获取超声原始文件,并进行无损转换为PNG格式单帧或系列的PNG图像,并储存；S2.对PNG图像利用目标检测神经网络模型,自动识别目标图像区域,并进行自动裁剪；S3.以裁剪后目标图像区域的长径为标准,在维持原始比例基础上拟定正方形区域,目标图像区域居中,并进行非目标图像区域的灰度填充,输出并以PNG格式保存,获得最终的标准化图像。</td>   <td>G06V10/24;G06V10/22;G06V10/25;G06T7/00;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         莫康晓;              戴宪华;                   李嘉豪       </td>   <td>中山大学</td>   <td>一种基于深度学习的结核杆菌实时目标检测方法及系统</td>   <td>广东省</td>   <td>CN117274985A</td>   <td>2023-12-22</td>   <td>本发明公开了一种基于深度学习的结核杆菌实时目标检测方法及系统,该方法包括：从医疗显微图像中筛选出含结核杆菌的图像并进行数据处理,将处理后图像作为数据集；对数据集中每张图像的病害类型进行标注并将数据集分为训练集和测试集；利用训练集训练改进的YOLOv7网络模型；改进的YOLOv7网络结构基于Darknet主干网络,在主干网络中将单维度卷积层全部替换为全维度卷积层,在头部网络中将ELEN-H模块全部替换为ELAM模块；ELAM模块包括通道注意力模块、空间注意力模块和多个梯度路径；将测试集中的图像输入训练好的网络模型中,得到结核杆菌的检测结果。本发明利用改进的网络模型对结核杆菌进行高效、准确地检测。</td>   <td>1.一种基于深度学习的结核杆菌实时目标检测方法,其特征在于,所述方法包括：获取医疗显微图像,从医疗显微图像中筛选出含结核杆菌的图像并进行数据处理,将处理后的图像作为数据集；对数据集中每张图像的病害类型进行标注,并将数据集分为训练集和测试集；利用训练集训练改进的YOLOv7网络模型；所述改进的YOLOv7网络结构基于Darknet主干网络,在主干网络中将原有的单维度卷积层全部替换为全维度卷积层ODConv,在检测头部网络中将ELEN-H模块全部替换为高效多梯度注意力ELAM模块；所述高效多梯度注意力ELAM模块包括通道注意力模块、空间注意力模块以及多个梯度路径；将测试集中的图像输入训练好的改进的YOLOv7网络模型中,实时得到图像对应的结核杆菌的检测结果。</td>   <td>G06V20/69;G06V10/82;G06N3/0464;G06N3/045;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青松;              石珂;              翁海松;              刘彬媛;              林明鑫;              赖涛;                   黄海风       </td>   <td>中山大学</td>   <td>一种SAR图像的校正方法及装置</td>   <td>广东省</td>   <td>CN116503269B</td>   <td>2023-12-19</td>   <td>本发明公开了一种SAR图像的校正方法及装置,所述方法包括：获取初始DEM数据后,将所述初始DEM数据分别与若干个位置偏移量相加,得到若干个偏移DEM数据；采用每个所述偏移DEM数据计算待校正SAR图像的偏移平均灰度值,得到若干个偏移平均灰度值；利用所述若干个偏移平均灰度值与预设的初始平均灰度值对待校正SAR图像进行偏移校正。本发明可以在获取待校正SAR图像对应的DEM数据后,将水平偏移量添加在DEM数据中,然后分别计算添加了水平偏移量的DEM数据的平均灰度以及未添加水平偏移量的DEM数据的平均灰度,通过两个灰度值的比较筛选出符合实际需求的水平偏移量并进行图像校正,从而减少相对位置偏差所带来的影响,提升图像校正的效果。</td>   <td>1.一种SAR图像的校正方法,其特征在于,所述方法包括：获取初始DEM数据后,将所述初始DEM数据分别与若干个水平偏移量相加,得到若干个偏移DEM数据,所述初始DEM数据为待校正SAR图像对应区域的DEM数据；采用每个所述偏移DEM数据计算待校正SAR图像的偏移平均灰度值,得到若干个偏移平均灰度值；利用所述若干个偏移平均灰度值与预设的初始平均灰度值对待校正SAR图像进行偏移校正,所述预设的初始平均灰度值是采用初始DEM数据计算的待校正SAR图像的平均灰度值；所述利用所述若干个偏移平均灰度值与预设的初始平均灰度值对待校正SAR图像进行偏移校正,包括：从若干个偏移平均灰度值和预设的初始平均灰度值中筛选数值最大的灰度值；获取所述数值最大的灰度值对应的DEM数据的偏移量,得到目标偏移量；采用所述目标偏移量生成校正的SAR正射影像；所述采用所述目标偏移量生成校正的SAR正射影像,包括：所述目标偏移量为雷达与DEM数据相对位置误差的补偿量,在所述目标偏移量下生成的SAR正射影像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         覃章才;                   朱娅坤       </td>   <td>中山大学</td>   <td>一种土地利用变化的碳排放评估方法和系统</td>   <td>广东省</td>   <td>CN117252742A</td>   <td>2023-12-19</td>   <td>本发明公开了一种土地利用变化的碳排放评估方法和系统,引入了LUH2土地利用数据构建LUCE模型,实现了更精细和准确的LUC排放估算,针对于不同的土地利用变化活动,分别采用对应的专用碳通量估算数学模型进行估算,解决了现有的LUC排放模型的可靠性差,空间分辨率低,无法准确地估算出LUC活动所引起的碳排放,且很难区分不同活动所引发的组分通量的技术问题。</td>   <td>1.一种土地利用变化的碳排放评估方法,其特征在于,包括：基于LUH2数据集,采用薄记模型原理构建在全球范围内追踪土地利用变化活动引发的碳通量在时间上分布的LUCE模型；将土地利用变化活动分为四类,分别为开垦、撂荒、收获和其它,并分别建立开垦、撂荒、收获和其它所对应的专用碳通量估算数学模型；获取全球范围内的土地利用变化活动事件,基于专用碳通量估算数学模型计算每一个土地利用变化活动事件对应的碳通量,基于LUCE模型计算每一个碳库的碳存储量,碳库包括土壤碳库、木制品碳库、植被生物量碳库和大气碳库。</td>   <td>G06Q50/26;G06F17/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王昌栋;              赖培源;              刘再行;              杨永仕;              李奎;              廖晓东;                   赖剑煌       </td>   <td>中山大学;广东省华南技术转移中心有限公司;广州美术学院</td>   <td>一种基于知识与数据双驱动的智能创作方法与系统</td>   <td>广东省</td>   <td>CN117235249A</td>   <td>2023-12-15</td>   <td>本发明公开了一种基于知识与数据双驱动的智能创作方法与系统,通过从知识大数据中进行专业知识数据提取,并形成人文历史专业知识与艺术创作专业知识,根据所述人文历史专业知识与艺术创作专业知识进行结构化处理,得到具有结构化的专业知识图谱；基于艺术作品数据与艺术作品特征标注数据,生成艺术作品数据图谱；将专业知识图谱与艺术作品数据图谱中的数据导入创作模型进行预训练；根据用户需求生成需求参数,将所述需求参数导入创作模型并生成初始艺术作品数据,通过筛选模块,对初始艺术作品数据进行筛选并得到交付作品数据。通过本发明,能够基于深度学习模型生成满足用户需求的创作作品,进一步,通过GAN模型,基于知识与数据的驱动,有效提高艺术创造的能力。</td>   <td>1.一种基于知识与数据双驱动的智能创作方法,其特征在于,包括：从知识大数据中进行专业知识数据提取,并形成人文历史专业知识与艺术创作专业知识；根据所述人文历史专业知识与艺术创作专业知识进行结构化处理,得到具有结构化的专业知识图谱；基于艺术作品数据与艺术作品特征标注数据,生成艺术作品数据图谱；将专业知识图谱与艺术作品数据图谱中的数据导入创作模型进行预训练；根据用户需求生成需求参数,将所述需求参数导入创作模型并生成初始艺术作品数据,通过筛选模块,对初始艺术作品数据进行筛选并得到交付作品数据。</td>   <td>G06F16/338;G06F16/36;G06N3/0475;G06N3/045;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄袁;              王榕;              陈湘萍;                   郑子彬       </td>   <td>中山大学</td>   <td>一种以太坊交易重放系统</td>   <td>广东省</td>   <td>CN117235777A</td>   <td>2023-12-15</td>   <td>本发明公开了一种以太坊交易重放系统,包括：通信连接的以太坊客户端、数据记录器、存档数据库和重放引擎；其中,客户端根据账户的状态、区块头、交易信息从第一笔交易开始依次执行所有交易,将账户的状态更新信息和第一交易执行结果写入数据记录器；数据记录器获取区块头、交易信息、账户的状态更新信息和第一交易执行结果并写入存档数据库；存档数据库存储和检索数据记录器写入的信息；重放引擎根据预设的重放交易信息,获取对应的区块头信息、交易信息和账户的状态,执行重放交易得到第二交易执行结果,根据第一、第二交易执行结果判断交易重放是否正确。本发明能高效存储所有账户的历史状态,并实现高速的交易并行重放。</td>   <td>1.一种以太坊交易重放系统,其特征在于,包括：通信连接的以太坊客户端、数据记录器、存档数据库和重放引擎；其中,所述以太坊客户端根据账户的状态、区块头信息、交易信息从创世区块的第一笔交易开始依次执行所有交易,将所述账户的状态更新信息写入所述数据记录器和以太坊数据库,将第一交易执行结果写入所述数据记录器,所述账户的状态是从所述以太坊数据库中导出的；所述数据记录器获取所述区块头信息、所述交易信息、所述账户的状态更新信息和所述第一交易执行结果,并将所获取的信息写入所述存档数据库；所述存档数据库存储和检索所述数据记录器写入的信息；所述重放引擎根据预设的重放交易信息,从所述存档数据库中读取对应的所述区块头信息、所述交易信息和所述账户的状态,执行重放交易得到第二交易执行结果,根据所述第一交易执行结果、所述第二交易执行结果判断交易重放是否正确。</td>   <td>G06F21/62;G06F16/27;G06F16/25;G06F16/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李潭;              陈南江;              宋伟宁;              林燕文;              李润强;              刘小勇;                   刘斌儒       </td>   <td>南昌市言诺科技有限公司;中山大学南昌研究院</td>   <td>转炉炼钢一次拉成率预测方法、装置和计算机设备</td>   <td>江西省</td>   <td>CN117236516A</td>   <td>2023-12-15</td>   <td>本申请涉及一种转炉炼钢一次拉成率预测方法、装置和计算机设备。所述方法包括：获取转炉炼钢过程中的历史数据,根据历史数据构建总体数据集；根据总体数据集进行数据特征选择；对选择的特征采用训练好的Stacking实时数据清洗模型对数据缺失及异常值进行预测,得到最终预测值；将最终预测值进行均衡处理和归一化处理后采用神经网络模型进行一次拉成预测,得到一次拉成率预测结果；根据一次拉成率预测结果和实时数据,在线更新总体数据集。本方法可以实现转炉冶炼数据实时清洗,进而实现冶炼过程的实时分析,可以有效支撑自动化智能炼钢需求,本方法可用于解决转炉炼钢一次拉成率提升问题,满足转炉炼钢的效能提升需求。</td>   <td>1.一种转炉炼钢一次拉成率预测方法,其特征在于,所述方法包括：获取转炉炼钢过程中的历史数据,根据所述历史数据构建总体数据集；根据所述总体数据集进行数据特征选择；对选择的特征采用训练好的Stacking实时数据清洗模型对数据缺失及异常值进行预测,得到最终预测值；将所述最终预测值进行均衡处理和归一化处理后采用神经网络模型进行一次拉成预测,得到一次拉成率预测结果；根据所述一次拉成率预测结果和实时数据,在线更新所述总体数据集。</td>   <td>G06Q10/04;G06Q50/04;G06F18/214;G06F18/2415;G06F18/243;G06F18/27;G06N3/048;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蒋格格;              范庆雯;              张欣;              庞爱彤;                   刘轶君       </td>   <td>中山大学·深圳;中山大学</td>   <td>可交易碳积分方法及系统、装置和介质</td>   <td>广东省</td>   <td>CN117237012A</td>   <td>2023-12-15</td>   <td>本发明公开了一种可交易碳积分方法及系统、装置和存储介质,可交易碳积分方法包括根据用户的出行数据,确定碳减排量和碳积分,在私营部门端进行碳积分交易,私营部门端将碳积分交易的交易记录数据发送至公共部门端,公共部门端对交易记录数据进行审核处理等步骤。可交易碳积分系统包括私营部门端和公共部门端。本发明能够充分调动公共部门、私营部门和出行者参与碳减排的积极性,发挥公共部门、私营部门和出行者各方在各自位置上所起到的碳减排积极作用,有利于鼓励出行者采用环保低碳的出行交通方式出行,增强公众环保意识,有利于实现碳减排和可持续发展。本发明广泛应用于碳减排技术领域。</td>   <td>1.一种可交易碳积分方法,其特征在于,所述可交易碳积分方法包括：采集用户的出行数据；根据所述出行数据,确定用户的碳减排量；根据所述碳减排量,确定用户的碳积分；响应于请求,在私营部门端进行碳积分交易；由所述私营部门端将碳积分交易的交易记录数据发送至公共部门端；由所述公共部门端对所述交易记录数据进行审核处理。</td>   <td>G06Q30/0226;G06Q30/0208;G06Q30/018;G06Q40/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗莉霞;              张佳晴;                   谈旭华       </td>   <td>中山大学中山眼科中心</td>   <td>一种人工晶状体屈光力预测方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN117238514A</td>   <td>2023-12-15</td>   <td>本发明提供了一种人工晶状体屈光力预测方法、系统、设备及介质,所述方法包括：获取数个玻璃体切除术后白内障患者的数据集,基于堆叠算法建立用于人工晶状体屈光力预测的预测模型,并分别通过训练集和验证集对预测模型进行训练并验证；将目标玻璃体切除术后白内障患者的生物学病史参数输入训练并验证后的预测模型进行预测,得到有效晶状体位置的目标预测值；根据目标玻璃体切除术后白内障患者的生物学病史参数,得到对应的全角膜屈光力和光学眼轴长度；根据目标玻璃体切除术后白内障患者的目标预测值、全角膜屈光力和光学眼轴长度进行屈光力计算,得到人工晶状体屈光力。本发明有效提高了玻璃体切除术后白内障患者人工晶状体屈光力预测的准确性。</td>   <td>1.一种人工晶状体屈光力预测方法,其特征在于,所述方法包括：获取数个玻璃体切除术后白内障患者的数据集,并将所述数据集分为训练集和验证集；所述数据集包括各患者的生物学病史参数,所述生物学病史参数至少包括眼轴长度、角膜曲率、房水深度、角膜厚度、晶状体厚度、眼轴长度与角膜曲率比值、人工晶状体常数、白内障术前玻璃体腔状态、有无巩膜扣带术手术史和有无睫状沟植入；基于堆叠算法建立用于预测人工晶状体屈光力中有效晶状体位置的预测模型,并分别通过所述训练集和验证集对所述预测模型进行训练并验证；将目标玻璃体切除术后白内障患者的生物学病史参数输入训练并验证后的预测模型进行预测,得到有效晶状体位置的目标预测值；根据所述目标玻璃体切除术后白内障患者的生物学病史参数,得到对应的全角膜屈光力和光学眼轴长度；根据所述目标玻璃体切除术后白内障患者的目标预测值、全角膜屈光力和光学眼轴长度进行屈光力计算,得到所述目标玻璃体切除术后白内障患者的人工晶状体屈光力。</td>   <td>G16H50/70;G16H50/50;G16H10/60;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈浩宇;                   农革       </td>   <td>中山大学</td>   <td>一种搜索方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN113535710B</td>   <td>2023-12-15</td>   <td>本申请适用于信息技术领域,提供了一种搜索方法、装置、终端设备及存储介质,所述方法包括：当接收到待搜索信息时,识别所述待搜索信息的搜索类型；若所述搜索类型为二进制搜索,则根据所述待搜索信息生成多个子搜索信息；分别采用所述多个子搜索信息进行搜索,获得与每个子搜索信息相匹配的搜索结果；输出所述搜索结果。通过上述方法,可以实现高效且准确的二进制搜索。</td>   <td>1.一种搜索方法,其特征在于,包括：当接收到待搜索信息时,识别所述待搜索信息的搜索类型；若所述搜索类型为二进制搜索,则将所述待搜索信息扩展为完整的字节,获得多个子搜索信息；分别采用字节搜索的方式,对所述多个子搜索信息进行搜索,获得与每个子搜索信息相匹配的搜索结果；输出所述搜索结果；其中,所述搜索结果是索引库中与所述待搜索信息对应的原始数据,所述原始数据具有完整的后缀索引信息,所述后缀索引信息包括所述原始数据、所述原始数据的后缀索引以及所述原始数据的元数据,所述元数据用于描述所述原始数据,所述后缀索引信息以字节为单位进行存储；所述分别采用字节搜索的方式,对所述多个子搜索信息进行搜索,获得与每个子搜索信息相匹配的搜索结果,包括：针对所述每个子搜索信息,逐个判断映射表中是否存在与所述子搜索信息相对应的键值对；若所述映射表中存在与所述子搜索信息相对应的键值对,则返回所述键值对,所述键值对中包含所述子搜索信息和与所述子搜索信息相匹配的搜索结果；若所述映射表中不存在与所述子搜索信息相对应的键值对,则在预置的后缀索引中查找所述子搜索信息对应的偏移位置,根据所述偏移位置获取与所述子搜索信息相匹配的搜索结果；若不存在所述映射表,则创建新的映射表,所述新的映射表初始时内容为空,可存储若干个键值对,所述键值对用于记录所述子搜索信息和与所述子搜索信息相匹配的搜索结果,其中,键为所述子搜索信息,值为与所述子搜索信息相匹配的搜索结果。</td>   <td>G06F16/22;G06F16/23;G06F16/248</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              吴嘉豪;                   詹丹丹       </td>   <td>中山大学</td>   <td>一种曝光调整曲线估计方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117237248A</td>   <td>2023-12-15</td>   <td>本发明公开了一种曝光调整曲线估计方法、装置、电子设备及存储介质,方法包括：获取待处理的原始图片；对所述原始图片进行向量提取,得到直方图向量；对所述直方图向量进行全连接处理,得到预测卷积核参数；基于所述预测卷积核参数对所述原始图片进行卷积处理,得到曲线参数；基于所述曲线参数,结合sigmoid函数获得曝光调整曲线；其中,所述曝光调整曲线用于所述原始图片的曝光调整。本发明实施例得到的曝光调整曲线能够辅助图片进行准确曝光调整,可广泛应用于图片处理技术领域。</td>   <td>1.一种曝光调整曲线估计方法,其特征在于,包括：获取待处理的原始图片；对所述原始图片进行向量提取,得到直方图向量；对所述直方图向量进行全连接处理,得到预测卷积核参数；基于所述预测卷积核参数对所述原始图片进行卷积处理,得到曲线参数；基于所述曲线参数,结合sigmoid函数获得曝光调整曲线；其中,所述曝光调整曲线用于所述原始图片的曝光调整。</td>   <td>G06T5/40;G06T5/00;G06T7/80;G06N3/0464;G06N3/048;G06N3/088</td>  </tr>        <tr>   <td>中国专利</td>   <td>         印鉴;              李学思;              刘威;              余建兴;              朱怀杰;                   邱爽       </td>   <td>中山大学</td>   <td>一种基于二元信息网络的多视角注意力推荐方法</td>   <td>广东省</td>   <td>CN110968794B</td>   <td>2023-12-12</td>   <td>本发明提供一种基于二元信息网络的多视角注意力推荐算法,该算法从二元信息网络中生成高质量的、从目标用户到目标商品间的多条路径；对生成路径采用CNN和max-pooling操作,提取对应的路径向量；将生成的多种路径向量通过attention机制进行加权合并,得到一个可以对应目标用户和目标商品对的路径合并向量；同样通过attention操作,利用S3生成的对应路径合并向量更新用户向量和商品向量；将生成的路径合并向量、用户向量和商品向量进行拼接,传输到多层感知机进行训练,即可获得最后的打分预测。</td>   <td>1.一种基于二元信息网络的多视角注意力推荐方法,其特征在于,包括以下步骤：S1：从二元信息网络中生成高质量的、从目标用户到目标商品间的多条路径；S2：对生成路径采用CNN和max-pooling操作,提取对应的路径向量；S3：将生成的多种路径向量通过attention机制进行加权合并,得到一个可以对应目标用户和目标商品对的路径组合并向量；S4：同样通过attention操作,利用S3生成的对应路径合并向量更新用户向量和商品向量；S5：将S3和S4生成的路径合并向量、用户向量和商品向量进行拼接,传输到多层感知机进行训练,即可获得最后的打分预测；所述步骤S5的具体过程是：S51：将S3得到的路径组合并向量与S4得到向量和/&gt;向量进行拼接,多层感知机进行训练,其运行结果即为预测结果；即将它们通过MLP多层感知机进行训练,训练稳定后得到最终的预测结果,最终的结果公式如下：          ；S52：训练时采用Adam方式进行迭代,学习率为0.0001,训练迭代次数为40次,每次将训练集分若干batch,每组batch数为256个样本,样本获取采用算法动态负采样,使得一个训练样本包含1个正样本和4个负样本；通过分析上述提到的公式,可以确定优化目标为,然后根据似然概率公式,得到优化目标函数为如下：                  这个表示正样本,/&gt;表示负样本,为方便计算,将上述公式取对数,得到如下需要优化的目标函数：                  化简后得到算法的优化目标函数：          。</td>   <td>G06F16/9536;G06F18/214;G06F18/22;G06Q30/0601</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              庞礼铧;              王雅琦;              王和旭;              韦骏;              张淏酥;                   张晓鹤       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种三维流场重构方法、系统、电子设备及存储介质</td>   <td>广东省</td>   <td>CN116597085B</td>   <td>2023-12-12</td>   <td>本发明公开了一种三维流场重构方法、系统、电子设备及存储介质,包括：确定全球范围内的表层流场数据和深层流场数据,根据表层流场数据和深层流场数据确定整体尺度的第一流场数据；获取局部尺度中包括海域流速流向、温盐密压的参数,得到局部尺度的第二流场数据；构建初始重构模型,采用第二流场数据对初始重构模型进行训练,得到目标重构模型；进而对第一流场数据进行超分辨率重建,得到三维重构流场。本发明实施例能够对全球尺度的海洋进行多尺度的三维流场重构,并且通过超分辨率重建能够获得高精度、高分辨率的三维重构流场,该模型能够反映全球尺度的三维空间内任意海域的某一特定点位的流场数据。本发明可以广泛应用于流场重构技术领域。</td>   <td>1.一种三维流场重构方法,其特征在于,包括：确定全球范围内的表层流场数据和深层流场数据,根据所述表层流场数据和所述深层流场数据确定整体尺度的第一流场数据；获取局部尺度中包括海域流速流向、温度、盐度、密度和压力的参数,得到局部尺度的第二流场数据；构建初始重构模型,采用所述第二流场数据对所述初始重构模型进行训练,得到目标重构模型；通过所述目标重构模型对所述第一流场数据进行超分辨率重建,得到三维重构流场；其中,所述构建初始重构模型,采用所述第二流场数据对所述初始重构模型进行训练,得到目标重构模型的步骤中,训练初始重构模型的步骤包括：构建基于残差学习生成对抗网络的初始重构模型；其中,所述初始重构模型包括生成器和鉴别器；将第二流场数据转化为图像数据,得到第一分辨率图像；对第一分辨率图像进行图像退化处理得到第二分辨率图像；在生成器中,根据所述第二分辨率图像生成虚拟数据并计算生成器损失；在鉴别器中,将所述虚拟数据与所述第一分辨率图像进行对比,得到鉴别器损失；根据所述生成器损失和所述鉴别器损失进行所述生成器和所述鉴别器的相互对抗直至达到均衡状态,得到目标重构模型；其中,所述通过所述目标重构模型对所述第一流场数据进行超分辨率重建,得到三维重构流场,包括：对第一流场数据进行特征提取,得到第一特征；对所述第一特征进行非线性映射处理,得到第二特征；其中,所述第二特征的分辨率均高于所述第二特征；结合所述目标重构模型中的第二流场数据特征,根据第二特征进行数据重建,得到三维重构流场。</td>   <td>G06T17/00;G06N3/0475;G06N3/045;G01P5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢曦;              徐嘉荣;              黎洪波;              胡宁;              陈惠琄;              李柏鸣;              钟成锦;              李仁杰;              何根;                   杭天       </td>   <td>中山大学</td>   <td>一种鼠类行为分析方法及装置</td>   <td>广东省</td>   <td>CN112580552B</td>   <td>2023-12-12</td>   <td>本申请实施例公开了一种鼠类行为分析方法和装置,其中方法包括：采集用于训练的训练视频片段；获取视频中活动区域的边界框,将边界框和鼠类的信息作为鼠类目标检测的神经网络的的监督信息,并对人工卷积神经网络进行训练；采用训练后的人工卷积神经网络对鼠类视频片段进行目标检测,得到预设大小的感兴趣区域；根据连续两帧中感兴趣区域中心坐标的位移和时间差,得到实时运动总里程,从而获得鼠类的运动状态。本申请所提供鼠类行为分析方法可以有效对小鼠的行为信息进行量化和分析,为动物行为研究提供可靠的研究信息,解决了采取佩戴时传感器的方式来对实验动物进行追踪的办法存在的鲁棒性低,无线传感器传输距离短,使用成本高的问题。</td>   <td>1.一种鼠类行为分析方法,其特征在于,包括步骤：S1,采集用于训练的训练视频片段；S2,获取所述训练视频片段视频中鼠类的活动区域的边界框,并将所述边界框和鼠类的信息作为鼠类目标检测的第一人工卷积神经网络的第一监督信息,并对所述第一人工卷积神经网络进行训练；S3,采集用于分析的鼠类视频片段；S4,采用训练后的第一人工卷积神经网络对所述鼠类视频片段进行目标检测；S5,在检测到鼠类的视频帧中标记出预设大小的边界框和所述鼠类的信息,并将所述边界框内的区域定义为感兴趣区域；S6,获取所述鼠类视频片段的连续两帧中所述感兴趣区域的中心坐标的位移和时间差,得到鼠类的瞬时速度,对所述瞬时速度进行积分,得到鼠类的实时运动总里程；S7,根据所述实时运动总里程获得鼠类的运动状态；所述运动状态包括但不限于：静止、跑动、慢步；所述步骤S1之后,还包括：获取视频中鼠类的头部、背部和尾巴根部三个关键点,得到关键点坐标和关键点类别,将所述关键点坐标和所述关键点类别作为鼠类关键点检测的第一人工卷积神经网络的第一监督信息,并对所述第一人工卷积神经网络进行训练,以得到第二人工卷积神经网络；所述步骤S4之后,还包括：采用训练后的第二人工卷积神经网络对所述鼠类视频片段进行关键点检测；根据所述关键点检测结果得到鼠类的骨骼链路；根据所述鼠类视频片段的画面帧中所述骨骼链路的形态,获得鼠类的姿势状态；所述姿势状态包括但不限于：站立、趴伏、侧卧、蜷缩。</td>   <td>G06V20/40;G06V10/25;G06V10/46;G06V10/82;G06N3/0464;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王萍;              刘万泉;              韩瑜;              郭晓丽;                   钱军       </td>   <td>中山大学</td>   <td>一种无人系统大跨度穿梭多摄像头轨迹跟踪识别方法</td>   <td>广东省</td>   <td>CN117218382A</td>   <td>2023-12-12</td>   <td>本发明公开了一种无人系统大跨度穿梭多摄像头轨迹跟踪识别方法,该方法包括：对车辆视频数据进行存图截取,并划分为车辆目标检测数据集训练VFD-YOLOv4网络；根据训练完成的VFD-YOLOv4网络和DeepSORT算法对车辆进行检测跟踪；构建基于图像特征的多任务学习模型并进行训练,将训练完成的多任务学习模型与时空特征模型融合,得到车辆重识别模型；基于DE-LSTM对非重叠区域内的轨迹进行预测,得到非重叠区域内的轨迹。通过使用本发明,能够对多摄像头的数据进行联合处理,完成对共同目标车辆的信息共享与整合,实现车辆在大跨度桥梁上行驶轨迹的跟踪与预测。本发明作为一种无人系统大跨度穿梭多摄像头轨迹跟踪识别方法,可广泛应用于车辆轨迹分析领域。</td>   <td>1.一种无人系统大跨度穿梭多摄像头轨迹跟踪识别方法,其特征在于,包括以下步骤：对车辆视频数据进行存图截取,并划分为桥梁车辆目标检测数据集；根据车辆图像特点对YOLOv4网络进行改进并利用桥梁车辆目标检测数据集对改进后的网络进行训练,得到训练完成的VFD-YOLOv4网络；根据训练完成的VFD-YOLOv4网络和DeepSORT算法对车辆进行检测跟踪,得到不同监控设备下相同车辆的图片；构建基于图像特征的多任务学习模型并利用不同监控设备下相同车辆的图片进行训练,得到训练完成的多任务学习模型；构建时空特征模型并与训练完成的多任务学习模型融合,得到车辆重识别模型；利用车辆重识别模型对不同监控设备下相同车辆的图片进行识别,得到重叠区域内的轨迹；基于DE-LSTM对非重叠区域内的轨迹进行预测,得到非重叠区域内的轨迹。</td>   <td>G06V10/62;G06V20/54;G06V20/40;G06V10/762;G06V10/82;G06V10/22;G06V10/40;G06V10/80;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈泽涛;              王瑞轩;              施梦汝;              龚卓弘;              易辉轩;              蔡耿彬;              史佳敏;                   刘恒毅       </td>   <td>中山大学附属口腔医院</td>   <td>一种基于人工智能的口腔CBCT自动精细解剖方法</td>   <td>广东省</td>   <td>CN117218450A</td>   <td>2023-12-12</td>   <td>一种基于人工智能的口腔CBCT自动精细解剖的方法,主要包括以下步骤：S1获取口腔CBCT精细解剖标注数据集；S2基于第一解剖网络进行口腔CBCT一阶段自动粗略解剖；S3基于第二解剖网络进行口腔CBCT二阶段自动精细解剖；S4两阶段掩膜融合获取最终口腔CBCT精细解剖掩膜；本发明通过构建基于深度学习的口腔精细结构自动解剖网络,可以实现高效、自动、批量解剖口腔CBCT图像中的微毫米级(像素级)的、形态各异的、边界不明显的解剖结构,解决底层细节纹理信息丢失、计算量冗余等影像结构解剖问题,有效减轻口腔医生在CBCT口腔精细结构解剖过程中耗费的时间及精力。</td>   <td>1.一种基于人工智能的口腔CBCT自动精细解剖方法,其特征在于,包括以下步骤：S1获取口腔CBCT精细解剖标注数据集基于原始口腔CBCT图像获取第一口腔CBCT二维剖面；将所述第一口腔CBCT二维剖面经处理获得第二口腔CBCT二维剖面,将第二口腔CBCT二维剖面导入图像标注软件中处理得第一口腔精细解剖标注文件；将所述第一口腔精细解剖标注文件转换为包含标注信息及原始图片信息的第二口腔精细解剖标注文件；将第二口腔精细解剖标注文件归档,构成口腔CBCT精细解剖标注数据集；S2基于第一解剖网络进行口腔CBCT一阶段自动粗略解剖首先构建基于深度学习模型的第一解剖网络,将口腔CBCT精细解剖标注数据集输入构建的基于深度学习模型的第一解剖网络；对所述第一解剖网络训练及验证；经过训练及验证的基于深度学习模型的第一解剖网络对口腔影像结构处理获得一阶段口腔CBCT粗略解剖像素级掩膜；S3基于第二解剖网络进行口腔CBCT二阶段自动精细解剖首先提取一阶段口腔CBCT粗略解剖像素级掩膜中的细微区域,构建口腔CBCT二阶段自动解剖数据集；其次构建基于深度学习模型的第二解剖网络；训练及验证基于深度学习模型的第二解剖网络；经过训练及验证的基于深度学习模型的第二解剖网络对口腔影像结构处理获得二阶段口腔CBCT精细解剖像素级掩膜；S4两阶段掩膜融合获取最终口腔CBCT精细解剖掩膜将一阶段口腔CBCT粗略解剖像素级掩膜和二阶段口腔CBCT精细解剖像素级掩膜融合得融合图像,通过识别异常融合区域,消除异常标注区域,获得最终口腔CBCT精细解剖掩膜,对所述口腔精细解剖掩膜进行定性及定量分析。</td>   <td>G06V10/764;G06V10/40;G06V10/80;G06V10/82;G06N3/0464;G06N3/045;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;              蒋燕梅;              倪晓升;              张易东;              吕雅丽;              熊宇涵;              李梦迪;              秦小营;              谢雨琪;              冼军;                   成诚       </td>   <td>中山大学</td>   <td>一种无人机协同决策准则生成方法、系统、装备和介质</td>   <td>广东省</td>   <td>CN117218564A</td>   <td>2023-12-12</td>   <td>本发明公开了一种无人机协同决策准则生成方法、系统、装备和介质,涉及无人机技术领域。通过当接收到决策准则触发数据时,获取无人机的任务数据及对应的任务紧急状况数据。当任务紧急状况数据为不紧急时,将无人机对应的周围环境图像数据进行对手装备识别,得到对手装备数量和对手装备特征数据。当对手装备数量小于预设值时,提取无人机对应的无人机装备特征数据和地面控制站采集的地面数据。将对手装备特征数据、无人机装备特征数据和地面数据进行图像栅格化,构建环境态势网格图像。将环境态势网格图像输入多协同决策准则分类模型,能够科学、准确地生成符合无人机在当前环境态势下的协同决策准则。</td>   <td>1.一种无人机协同决策准则生成方法,其特征在于,包括：当接收到决策准则触发数据时,获取无人机的任务数据及对应的任务紧急状况数据；当所述任务紧急状况数据为不紧急时,将所述无人机对应的周围环境图像数据进行对手装备识别,得到对手装备数量和对手装备特征数据；当所述对手装备数量小于预设值时,提取无人机对应的无人机装备特征数据和地面控制站采集的地面数据；将所述对手装备特征数据、所述无人机装备特征数据和所述地面数据进行图像栅格化,构建环境态势网格图像；将所述环境态势网格图像输入多协同决策准则分类模型,得到所述无人机对应的协同决策准则。</td>   <td>G06V20/17;G06V10/764;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              刘梦梦;              刘凌波;                   林倞       </td>   <td>中山大学</td>   <td>一种领域适配的跨城市交通流量超分辨率重建方法及系统</td>   <td>广东省</td>   <td>CN112017118B</td>   <td>2023-12-08</td>   <td>本发明公开了一种领域适配的跨城市交通流量超分辨率重建方法及系统,所述方法包括：获取数据,并构建数据集；根据源领域城市区域的低分辨率交通流量图以及高分辨率交通流量图,采用监督学习的方式对预设的超分辨率网络进行预训练,获得优化的超分辨率网络；构建一对孪生优化的超分辨率网络；并采用领域分类器进行对抗训练,并同时更新网络参数；获得一对训练后的孪生超分辨率网络；将所述数据集输入到所述一对训练后的孪生超分辨率网络；获得目标领域城市高分辨交通流量图。本发明能够通过领域适配的方法使得两个不同领域(城市)的流量特征分布相近,从而实现对目标领域(城市)的超分辨率重建,降低对城市交通流量数据量的需求。</td>   <td>1.一种领域适配的跨城市交通流量超分辨率重建方法,其特征在于,包括：获取数据,并构建数据集；其中,所述数据包括：源领域城市区域的低分辨率交通流量图、高分辨率交通流量图以及目标领域城市的低分辨率交通流量图；根据所述源领域城市区域的低分辨率交通流量图以及高分辨率交通流量图,采用监督学习的方式对预设的超分辨率网络进行预训练,获得优化的超分辨率网络；构建一对孪生优化的超分辨率网络,包括超分辨率网络1和超分辨率网络2；并采用领域分类器进行对抗训练,并同时更新网络参数；获得一对训练后的孪生超分辨率网络；其中,所述一对训练后的孪生超分辨率同时更新,共享参数和权重；其中,所述更新网络参数包括对于所述超分辨率网络1恢复的超分辨率交通流量图,以及源领域城市高分辨率流量图,采用平方误差方式计算源领域高分辨交通流量图损失函数；对于所述超分辨率网络1和所述超分辨率网络2恢复的超分辨率交通流量图,采用超区域的流入流量、流出流量与所述超区域对应子区域的流入流量、流出流量约束关系公式计算损失函数；对于源领域城市和目标领域城市分类结果,采用平方误差公式计算分类损失以更新领域分类器,对于目标领域城市分类结果,采用平方误差公式计算欺骗损失以更新编码器；将所述数据集输入到所述一对训练后的孪生超分辨率网络；获得目标领域城市高分辨交通流量图；其中,所述获取数据,并构建数据集,具体为将城市中待研究的区域按照经纬度划分为X*Y的网格,其中一个网格表示一个区域；并统计出在特定时间间隔内,每个区域的交通流入流量图以及交通流出流量图,获得一个二通道的交通流量图；并根据所述二通道的交通流量图,得到源领域城市区域的低分辨率交通流量图、高分辨率交通流量图以及目标领域城市的低分辨率交通流量图；其中,所述低分辨率交通流量图中的区域称为超区域,分辨率图中的区域称为子区域。</td>   <td>G06T3/40;G06V10/764;G06V10/774;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              谢园;              王巨宏;                   黄婷婷       </td>   <td>中山大学;腾讯科技(深圳)有限公司</td>   <td>显著特征检测方法和装置</td>   <td>广东省</td>   <td>CN110163196B</td>   <td>2023-12-08</td>   <td>本申请涉及一种显著特征检测方法和装置,所述方法包括：获取视频帧序列,视频帧序列包括目标帧和多个参考帧；计算目标帧与各参考帧之间的光流图；通过第一神经网络模型,对各光流图进行编码,分别得到各参考帧对应的图像变换特征；通过第二神经网络模型,根据各图像变换特征对目标帧的图像特征进行编码,得到目标帧的协同编码图像特征；将协同编码图像特征输入像素级别分类器进行检测,输出目标帧的显著图。本申请提供的方案可以提升对视频进行显著特征检测的准确性。</td>   <td>1.一种显著特征检测方法,其特征在于,所述方法包括：获取视频帧序列,所述视频帧序列包括目标帧和多个参考帧,所述视频帧序列是视频流中连续的视频帧所构成序列,所述连续的各视频帧所表达的图像信息具有相关性,所述多个参考帧中的每个参考帧,是所述视频帧序列中的、对所述目标帧进行显著检测时所需参考的视频帧；计算所述目标帧与各所述参考帧之间的光流图；通过第一神经网络模型,对各所述光流图进行编码,得到各参考帧对应的编码光流图,基于对应的编码光流图,对相应参考帧的图像特征进行线性变换,得到相应参考帧对应的图像变换特征；通过第二神经网络模型,根据各参考帧对应的图像变换特征对所述目标帧的图像特征进行编码,得到所述目标帧的协同编码图像特征；将所述协同编码图像特征输入像素级别分类器进行检测,输出所述目标帧的显著图。</td>   <td>G06V10/25;G06V20/40;G06T7/269</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周颖;              王永福;              王伟;              邹小海;              饶彬;              王涛;              程旭;              谢恺;                   徐峰       </td>   <td>中山大学</td>   <td>一种基于知识图谱的安全漏洞分析方法</td>   <td>广东省</td>   <td>CN112613038B</td>   <td>2023-12-08</td>   <td>本发明为克服现有的安全漏洞库存在可视化效果不足、查询便利性不足、不具备通用性的缺陷,提出一种基于知识图谱的安全漏洞分析方法,包括以下步骤：采集CVE安全漏洞库数据作为原始数据；对原始数据进行分析,并根据原始数据的分析结果进行本体建模,得到CVE安全漏洞本体模型；遍历原始数据,从CVE安全漏洞本体模型中抽取相应数据并导入Neo4j图数据库中,构建CVE知识图谱。本发明对安全漏洞库数据中原始数据进行分析并根据原始数据的分析结果进行本体建模,再根据CVE安全漏洞本体模型对节点属性、关联关系等以可视化的形式进行结果展示,能够有效地挖掘出CVE安全漏洞库中的内在价值。</td>   <td>1.一种基于知识图谱的安全漏洞分析方法,其特征在于,包括以下步骤：S1：采集CVE安全漏洞库数据作为原始数据；S2：对原始数据进行分析,并根据原始数据的分析结果进行本体建模,得到CVE安全漏洞本体模型；S3：遍历所述原始数据,从所述CVE安全漏洞本体模型中抽取相应数据并导入Neo4j图数据库中,构建CVE知识图谱；其中,以年份为单位从所述CVE安全漏洞本体模型中抽取数据并导入Neo4j图数据库中；其具体步骤如下：S3.1：从所述CVE安全漏洞本体模型中抽取CVE的主要属性,将其作为漏洞节点类型CVE′存储在Neo4j图数据库中；S3.2：从所述CVE安全漏洞本体模型中抽取CVSS2的主要属性,将其作为评分节点类型CVSS2′存储在Neo4j图数据库中,并建立漏洞节点类型CVE′到评分节点类型CVSS2′的关系；从所述CVE安全漏洞本体模型中抽取CVSS3的主要属性,将其作为评分节点类型CVSS3′存储在Neo4j图数据库中,并建立漏洞节点类型CVE′到评分节点类型CVSS3′的关系；从所述CVE安全漏洞本体模型中抽取攻击向量节点的主要属性,将其作为攻击向量节点类型AttackVector存储在Neo4j图数据库中,并建立漏洞节点类型CVE′到攻击向量节点类型AttackVector的关系；从所述CVE安全漏洞本体模型中抽取产品版本节点的主要属性,将其作为产品版本节点类型ProductVersion存储在Neo4j图数据库中,并建立漏洞节点类型CVE′到产品版本节点类型ProductVersion的关系；从所述CVE安全漏洞本体模型中抽取引用节点的主要属性,将其作为引用节点类型Reference存储在Neo4j图数据库中,并建立漏洞节点类型CVE′到引用节点类型Reference的关系；从所述CVE安全漏洞本体模型中抽取CWE的主要属性,将其作为弱点类别节点类型CWE′存储在Neo4j图数据库中,并建立漏洞节点类型CVE′到弱点类别节点类型CWE′的关系；从所述CVE安全漏洞本体模型中抽取产品节点的主要属性,将其作为产品节点类型Product存储在Neo4j图数据库中,并建立产品版本节点类型ProductVersion到产品节点类型Product的关系；从所述CVE安全漏洞本体模型中抽取厂商节点的主要属性,将其作为厂商节点类型Vendor存储在Neo4j图数据库中,并建立产品节点类型Product到厂商节点类型Vendor的关系；S3.3：根据安全漏洞分析需求,从所述Neo4j图数据库中调用相应的节点类型和节点间关系并进行显示。</td>   <td>G06F21/57;G06F16/36;G06F16/242;G06F16/26;H04L9/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         石茜;                   傅浩       </td>   <td>中山大学</td>   <td>一种基于无人机自动巡航和深度学习的荔枝蝽象快速检测方法</td>   <td>广东省</td>   <td>CN117197688A</td>   <td>2023-12-08</td>   <td>本发明属于遥感地理信息系统领域和计算机领域,具体涉及一种基于无人机自动巡航和深度学习的荔枝蝽象快速检测方法,包括以下步骤：步骤1、无人机航拍建图；步骤2、获取树木坐标；步骤3、设置航点动作,进行航点设计；步骤4、开发程序,自动生成无人机自动巡航所需的航线文件；步骤5、将步骤4所生成的航线文件导入到无人机中即可实现自动巡航。本发明可以实现基于无人机遥感影像的荔枝蝽象快速检测的自动化,避免了人工调查带来的人力和财力的耗费,为以后荔枝蝽象以及其他树木病虫害的防治提供了一种有力的技术手段,所提模型结合了CNN和Transformer,增强了模型的特征提取过程,提升了对于小目标的检测准确性。</td>   <td>1.一种无人机自动巡航方法,其特征在于,包括以下步骤：步骤1、无人机航拍建图；步骤2、获取树木坐标；步骤3、设置航点动作,进行航点设计；步骤4、开发程序,自动生成无人机自动巡航所需的航线文件；步骤5、航线文件导入到无人机中。</td>   <td>G06V20/17;G05D1/10;G06V20/10;G06V10/774;G06V10/40;G06V10/82;G06N3/0464;G06N3/045;G06N3/0985</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘帆;                   戴宪华       </td>   <td>中山大学</td>   <td>基于历史位置编码的多轮对话问答方法及系统</td>   <td>广东省</td>   <td>CN117194619A</td>   <td>2023-12-08</td>   <td>本发明涉及语音文本处理技术,具体涉及基于历史位置编码的多轮对话问答方法及系统。其方法包括：获取对话问答的训练数据,包括问题、答案、与对话内容相关的阅读文档；训练ALBERT问题编码器；对历史记录采用位置编码嵌入对话问答的当前问题中,将嵌入结果输入ALBERT问题编码器,编码后得到输出序列；根据编码后的输出序列预测多轮对话问答的答案。通过位置编码嵌入历史记录的方式获取带有位置信息的历史编码层,解决了多轮对话中历史记录无法精确编码的问题。</td>   <td>1.一种基于历史位置编码的多轮对话问答方法,其特征在于,包括如下步骤：S1、获取对话问答的训练数据,包括问题、答案、与对话内容相关的阅读文档；S2、训练ALBERT问题编码器；S3、对历史记录采用位置编码嵌入对话问答的当前问题中,将嵌入结果输入ALBERT问题编码器,编码后得到输出序列；S4、根据编码后的输出序列预测多轮对话问答的答案。</td>   <td>G06F16/332;G06N3/045;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              请求不公布姓名       </td>   <td>中山大学</td>   <td>一种用于肿瘤标志物云端检测中的检测样本生成方法的改进方法</td>   <td>广东省</td>   <td>CN117195971A</td>   <td>2023-12-08</td>   <td>一种用于肿瘤标志物云端检测中的检测样本生成方法的改进方法,包括云端检测服务器,其特征在于：所述用于肿瘤标志物云端检测中的检测样本生成方法包括生成器网络结构,判别器网络结构,所述的用于肿瘤标志物云端检测中的检测样本生成方法的改进方法包括：生成器网络结构激活函数改进,判别器网络结构及损失函数改进,根据权利要求所述的用于肿瘤标志物云端检测中的检测样本生成方法的改进方法,其中所述改进激活函数生成器网络结构为：转置卷积层1、转置卷积层2、转置卷积层3的激活函数为Mish。通过采用Mish激活函数来改进生成网络激活函数的图像生成质量高于未改进的DCGAN网络生成的图像质量。</td>   <td>1.一种用于肿瘤标志物云端检测中的检测样本生成方法的改进方法,包括云端检测服务器,其特征在于：所述用于肿瘤标志物云端检测中的检测样本生成方法包括生成器网络结构,判别器网络结构,所述的用于肿瘤标志物云端检测中的检测样本生成方法的改进方法包括：生成器网络结构激活函数改进,判别器网络结构及损失函数改进。</td>   <td>G06N3/048;G06V10/774;G06N3/045;G06N3/0464;G06N3/0475</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              黄晓玲;              郑炎辉;              陈阳成;              蔡承志;              康丽;              林岚;                   田世拓       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种区域水资源短缺度的空间影响分析方法和系统</td>   <td>广东省</td>   <td>CN117196157A</td>   <td>2023-12-08</td>   <td>本发明涉及水资源分析技术领域,公开了一种区域水资源短缺度的空间影响分析方法和系统,从区域水资源短缺度的空间分布特征着手,采用全局莫兰指数检验水资源短缺度的空间自相关的存在,随后建立合适的空间面板计量模型,利用选定的空间计量模型识别区域水资源短缺度的驱动因子,对驱动因子进行空间效应分解,计算出驱动因子的直接效应、溢出效应、总效应,明晰了区域水资源短缺度的时空特点和空间效应,避免了因忽略空间效应导致评估结果出现偏差的问题,解决了传统的水资源短缺分析采用回归模型仅提供本地视角,而无法对空间交互作用进行控制,忽略空间效应,指标间的空间依赖可能导致评估结果出现偏差的技术问题。</td>   <td>1.一种区域水资源短缺度的空间影响分析方法,其特征在于,包括：对区域水资源短缺度的空间分布特征进行计算,得到区域水资源短缺度的空间分布特征；基于区域水资源短缺度的空间分布特征和预配置的空间权重矩阵,计算水资源短缺度的全局莫兰指数,根据全局莫兰指数判断区域水资源短缺度的空间自相关性；当区域水资源短缺度具有空间自相关性时,根据选定的区域水资源短缺度的空间计量模型,筛选出区域水资源短缺度的驱动因子,驱动因子为对水资源短缺度具有显著影响的解释变量,空间计量模型的被解释变量为区域水资源短缺度,解释变量为影响区域水资源短缺度的因素；对驱动因子进行空间效应分解,得到驱动因子对区域水资源短缺度的直接效应、总效应和溢出效应。</td>   <td>G06Q10/063;G06Q50/06;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         古博;              李煜;              黎家杰;              周晓婷;              姜善成;                   韩瑜       </td>   <td>中山大学</td>   <td>基于联盟链的供应商评价可追溯协同管理方法及装置</td>   <td>广东省</td>   <td>CN117196653A</td>   <td>2023-12-08</td>   <td>本发明公开了基于联盟链的供应商评价可追溯协同管理方法及装置,方法包括：获取供应商信息；选择符合预设要求的供应商作为目标供应商；对目标供应商进行评价得到待处理评价结果；通过非对称加密算法对所述待处理评价结果进行加密,得到目标评价结果；从待选取智能合约中选择一项作为目标智能合约；通过联盟链网络节点和所述目标智能合约管理所述目标评价结果。本发明实现了盐湖化工产业链供应商评价管理和联盟链的结合,优化了信息存储方式,提高了信息篡改难度和查询效率,降低了信息泄露风险和企业追责难度,从而提高了供应链管理效率。本发明可广泛应用于供应商评价管理技术领域。</td>   <td>1.基于联盟链的供应商评价可追溯协同管理方法,其特征在于,包括以下步骤：获取供应商信息；根据所述供应商信息,选择符合预设要求的供应商作为目标供应商；根据所述供应商信息和供应商评价指标体系,对目标供应商进行评价得到待处理评价结果；通过非对称加密算法对所述待处理评价结果进行加密,得到目标评价结果；从待选取智能合约中选择一项作为目标智能合约,所述待选取智能合约包括初始化智能合约、数据上链智能合约、数据查询智能合约或名誉值智能合约；通过联盟链网络节点和所述目标智能合约管理所述目标评价结果,所述目标评价结果保存于目标数据,所述目标数据还包括所述目标供应商、参评企业信息、用户身份信息或供应商名誉值。</td>   <td>G06Q30/018;G06Q30/0282;G06Q30/0601;G06Q10/101;G06F21/60;G06F21/64;G06F21/31</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丘昌镇;              张志勇;              谢雨含;              陈少龙;                   余淙竞       </td>   <td>中山大学</td>   <td>一种半月板图像的亚区分割方法及装置</td>   <td>广东省</td>   <td>CN117197466A</td>   <td>2023-12-08</td>   <td>本申请公开了一种半月板图像的亚区分割方法及装置,方法包括：将半月板三维图像输入半月板全亚区分割模型,输出全亚区分割切片图像,通过半月板亚区分割算法对全亚区分割切片图像进行亚区分割,得到多个亚区分割图像,其中,模型构建过程为构建远近端识别模型以及全亚区分割模型,提取远近端识别模型的第一参数以及全亚区分割模型的第二参数,将第一参数和第二参数赋予半月板全亚区分割架构,得到半月板全亚区分割模型。可见,远近端识别模型可以实现远近端分类,全亚区分割模型已学习了全亚区分割知识,而融合了第一参数以及第二参数的半月板全亚区分割模型能够对三维半月板图像精准分割,提高最终得到的多个亚区分割图像的精确度。</td>   <td>1.一种半月板图像的亚区分割方法,其特征在于,包括：获取半月板的三维图像,并将所述三维图像输入至预先建立的半月板全亚区分割模型,输出所述半月板的多个全亚区分割切片图像；整合所述多个全亚区分割切片图像,得到所述半月板的全亚区分割切片图像集；通过半月板亚区分割算法对所述全亚区分割切片图像集进行亚区分割,得到所述半月板的多个亚区分割图像；所述半月板全亚区分割模型的构建过程,包括：构建用于识别半月板切片图像的远近端识别模型；构建用于分割半月板切片图像的切片图像全亚区分割模型；提取所述远近端识别模型的第一模型参数,以及所述切片图像全亚区分割模型的第二模型参数；将所述第一模型参数和所述第二模型参数赋予预先建立的半月板全亚区分割架构,得到半月板全亚区分割模型。</td>   <td>G06V10/26;G06V10/764;G06V10/774;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭军;              吴敬林;              傅小勇;                   黎升       </td>   <td>中山大学</td>   <td>一种医学图像跨模态转换方法及系统</td>   <td>广东省</td>   <td>CN117198471A</td>   <td>2023-12-08</td>   <td>本发明提出一种医学图像跨模态转换方法及系统,涉及医学图像处理的技术领域,首先采集患者指定部位的两个模态的医学图像,将两个模态的医学图像构建为数据集,再对数据集中两个模态的医学图像进行近似配准处理,然后构建包含生成器、K相邻差异提取器、跨模态特征提取器的医学图像跨模态转换模型,利用训练集对医学图像跨模态转换模型进行训练,得到训练好的医学图像跨模态转换模型；最后将待转换的相同部位的任意源域医学图像输入训练好的医学图像跨模态转换模型,得到跨模态转换后的目标域医学图像,达到生成过程的阶段配准和内容配准的效果。</td>   <td>1.一种医学图像跨模态转换方法,其特征在于,包括：S1.采集患者指定部位的两个模态的医学图像,将两个模态的医学图像构建为数据集,将数据集划分为训练集和测试集；S2.对数据集中两个模态的医学图像进行近似配准处理；S3.构建医学图像跨模态转换模型,利用训练集对医学图像跨模态转换模型进行训练,利用测试集测试医学图像跨模态转换模型的有效性,得到训练好的医学图像跨模态转换模型；S4.将待转换的相同部位的任意源域医学图像输入训练好的医学图像跨模态转换模型,得到跨模态转换后的目标域医学图像。</td>   <td>G16H30/20;G06T3/00;G06N3/0475;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁悦;              刘江;              马腾;              傅媛;              陈晓熠;              雷柏英;              陈仲;                   肖杨       </td>   <td>生物岛实验室;中山大学孙逸仙纪念医院</td>   <td>模型训练方法、装置、电子设备及介质</td>   <td>广东省</td>   <td>CN111599467B</td>   <td>2023-12-05</td>   <td>本公开实施例公开了一种模型训练方法、装置、电子设备及介质。该模型训练方法包括：获取样本数据,所述样本数据包括采集于人体骨骼的超声射频信号以及与所述超声射频信号对应的采集对象的骨量标签；基于所述样本数据训练随机森林模型。本公开实施例提供的方法、装置、电子设备及介质能够改善骨量检测的灵敏度和特异度。</td>   <td>1.一种模型训练方法,其特征在于,包括：获取样本数据,所述样本数据包括采集于人体骨骼的超声射频信号以及与所述超声射频信号对应的采集对象的骨量标签,所述骨量标签包括正常骨量、骨量降低或者骨质疏松,所述超声射频信号为超声成像中未经处理的原始数据的标准形式,所述超声射频信号包括通过两组发射接收复合型换能器采集的原始数据,所述原始数据包含所有振幅、频率及相位信息,即声场和组织相互作用、微结构特征的信息；基于所述样本数据训练随机森林模型得到骨量检测模型；所述基于所述样本数据训练随机森林模型包括：根据预定步长确定所述随机森林模型的参数的全部取值组合；通过验证所述全部取值组合,从所述全部取值组合中确定所述参数的目标取值组合；从所述全部取值组合中确定所述参数的目标取值组合,包括：通过交叉验证的方式验证所述全部取值组合,从所述全部取值组合中确定所述参数的目标取值组合。</td>   <td>G16H50/70;G16H50/20;G06F18/2431;A61B5/00;G06N20/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈娟;              刘智勇;              陈晓宏;              林凯荣;                   涂新军       </td>   <td>中山大学</td>   <td>一种模拟树干瞬态液流变化的方法及系统</td>   <td>广东省</td>   <td>CN116484624B</td>   <td>2023-12-05</td>   <td>本发明公开了一种模拟树干瞬态液流变化的方法及系统,该方法包括：根据太阳辐射与树干液流的变化关系,得到树干瞬态液流变化原始模型；考虑复杂环境因素,根据树干瞬态液流变化原始模型构建树干瞬态液流变化模型；求解树干瞬态液流变化模型,得到树干液流速率。本技术方案将随日照辐射增加时气孔部分关闭以及辐射降低时液流的滞后性这一因素考虑在内,重新构建了瞬态树干液流变化模型,通过解模型得到树干液流速率的变化率,进而可以通过曲线模拟进行任意时刻液流变化速率的预测。</td>   <td>1.一种模拟树干瞬态液流变化的方法,其特征在于,包括以下步骤：根据太阳辐射与树干液流的变化关系,得到树干瞬态液流变化原始模型；考虑复杂环境因素,根据树干瞬态液流变化原始模型构建树干瞬态液流变化模型；求解树干瞬态液流变化模型,得到树干液流速率；所述树干瞬态液流变化原始模型具体表示为：                  其中,r-1(T)表示太阳辐射增加时树干液流上升函数,r-2(T)表示太阳辐射降低时树干液流降低函数,K-1表示树干液流增加速率,K-2表示树干液流降低速率,T表示时间；所述复杂环境因素包括随日照辐射增加气孔部分关闭以及随日照辐射降低液流对环境变化的反应存在滞后性；所述考虑复杂环境因素,根据树干瞬态液流变化原始模型构建树干瞬态液流变化模型这一步骤,具体包括：考虑日照辐射强度和其它环境因素对气孔的影响,构建太阳辐射增加或减弱引起的叶片内外水汽压差对树干液流的影响的非线性关系；基于所述非线性关系,构建树干瞬态液流变化模型；所述树干瞬态液流变化模型具体表示为：                  其中,T-1太阳辐射增加时树干液流上升函数值为零对应的时间,T-2表示太阳辐射降低时树干液流降低函数值为零对应的时间。</td>   <td>G06F30/20;G06F18/214;G06Q10/04;G06F113/08;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡天江;              朱劭豪;              朱波;              王勇;              张清瑞;                   潘亮       </td>   <td>中山大学</td>   <td>一种狼群围猎行为状态智能识别方法及系统</td>   <td>广东省</td>   <td>CN113255549B</td>   <td>2023-12-05</td>   <td>本发明公开了一种狼群围猎行为状态智能识别方法及系统,所述方法包括以下步骤:动物个体检测,其中,包括输入：狼群围猎视频,输出：视频每一帧图片动物所在的区域及动物种类；动物个体追踪,其中,包括输入：个体检测部分输出的每一帧的动物所在区域,输出：视频每一帧里成功追踪的动物编号；动物个体运动状态识别,其中,包括输入：视频每一帧每一个动物的区域及编号,输出：视频每一帧每一个动物的运动状态。本发明的系统的鲁棒性较强；本发明系统将目标外观空域流特征与运动时域流特征结合,共同判断种群里每一个个体的物种信息和运动状态,即针对群体的状态识别。本发明系统能直接运用于自然环境下的行为观测,使利用无人机实时观测和监督动物群落状况成为可能。</td>   <td>1.一种狼群围猎行为状态智能识别方法,其特征在于,包括以下步骤:S1动物个体检测,其中,包括输入：狼群围猎视频,输出：视频每一帧图片动物所在的区域及动物种类；S2动物个体追踪,其中,包括输入：个体检测部分输出的每一帧的动物所在区域,输出：视频每一帧里成功追踪的动物编号；S3动物个体运动状态识别,其中,包括输入：视频每一帧每一个动物的区域及编号,输出：每一个动物的运动状态和结果可视化视频；所述步骤S3包括：S3.1根据步骤S1输出的动物所在的区域,从图片中切割区域并输入分类神经网络Resnet-50,输出空域流分析结果；S3.2根据步骤S1的输出,屏蔽视频中存在动物的区域；S3.3在视频中生成光流角点,并计算在整个视频中角点的运动矢量,作为视频背景的运动矢量；S3.4根据步骤S2的输出,计算每一个个体的运动矢量；S3.5将个体的运动矢量与背景运动矢量叠加,得出每一个动物真实的运动矢量；S3.6结合动物于视频内的尺寸,估算动物真实的运动速度,并通过归一化输出时域流分析结果；S3.7对时域流和空域流的输出结果进行线性叠加,获得动物运动状态的最终结果。</td>   <td>G06V20/40;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              王若梅;              陈小燕;                   冯佳伟       </td>   <td>中山大学</td>   <td>一种基于深度学习的视频时刻检索方法与系统</td>   <td>广东省</td>   <td>CN117171391A</td>   <td>2023-12-05</td>   <td>本发明公开了一种基于深度学习的视频时刻检索方法。包括：输入视频数据集,并使用训练好的特征提取器提取特征序列；使用单模态特征编码器,对特征序列进行单模态编码；利用统计驱动的异质图推理方法对特征序列进行融合推理；利用查询生成器,生成时刻对齐的查询特征；利用查询解码器,生成用于视频时刻检索的特征序列；使用预测头进行最终结果预测,输出视频时刻检索的结果。本发明还公开了一种基于深度学习的视频时刻检索系统。本发明较其他发明,能够在低成本的硬件条件下完成高效的视频时刻检索和视频信息定位,方便使用者找到需要的视频片段,提高视频的利用价值和用户体验,具有很大的实际应用价值。</td>   <td>1.一种基于深度学习的视频时刻检索方法,其特征在于,所述方法包括：输入视频数据集,并使用训练好的特征提取器提取视频中的视频特征及音频特征；使用Transformer单模态特征编码器,分别对所述视频中的视频特征及音频特征进行单模态编码,得到编码后的视频序列及音频序列；输入所述编码后的视频序列及音频序列,构建异质图结构,然后利用统计驱动的异质图推理方法进行视频与音频数据的融合,输出推理融合的跨模态特征序列；将查询文本与所述推理融合的跨模态特征序列一起输入到查询生成器中,输出时刻对齐的查询特征；将所述时刻对齐的查询特征与推理融合的跨模态特征序列一起输入到查询解码器中进行解码,输出用于视频时刻检索的特征序列；使用预测头对所述用于视频时刻检索的特征序列进行最终处理,输出视频时刻检索的结果。</td>   <td>G06F16/78;G06F16/783;G06F16/738;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王萍;              王本斐;              韩瑜;              刘万泉;                   高原       </td>   <td>中山大学</td>   <td>一种基于计算机表达的应急交通体系仿真设计方法</td>   <td>广东省</td>   <td>CN117171832A</td>   <td>2023-12-05</td>   <td>本发明公开了一种基于计算机表达的应急交通体系仿真设计方法,该方法包括：对实际交通应用场景和用户需求进行分析,生成功能按钮；响应于用户点击,搭建物理场景,所述物理场景的对象包括个体、设备和中心,所述物理场景的图层包括信息流、服务图层和功能图层；获取物理场景下的信息流动过程,增设信息流播报界面对信息传递进行表达。通过使用本发明,能够实时展示信息流动过程,有助于进行动态运动模拟。本发明可广泛应用于交通仿真领域。</td>   <td>1.一种基于计算机表达的应急交通体系仿真设计方法,其特征在于,包括以下步骤：对实际交通应用场景和用户需求进行分析,生成功能按钮；响应于用户点击,搭建物理场景,所述物理场景的对象包括个体、设备和中心,所述物理场景的图层包括信息流、服务图层和功能图层；获取物理场景下的信息流动过程,增设信息流播报界面对信息传递进行表达。</td>   <td>G06F30/12;G06F30/20;G06F3/04847;G06F3/0486;G06F111/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吕熙敏;              梁显淇;              余皓文;                   刘星       </td>   <td>中山大学·深圳;中山大学;深圳市致映科技有限公司</td>   <td>一种风速和风向的预测方法及系统</td>   <td>广东省</td>   <td>CN117172371A</td>   <td>2023-12-05</td>   <td>本申请公开了一种风速和风向的预测方法及系统,方法包括：获取无人机传感器测得的目标测量数据,包括无人机的目标对地加速度、目标姿态以及目标电机转速；对目标测量数据进行数值优化,得到目标优化数据；将目标优化数据输入至预先构建的非线性扰动观测器,得到外界风力的目标三轴扰动力；将目标测量数据输入至经过预先训练的风况预测模型,得到第一预测风况数据；将目标三轴扰动力输入至经过预先训练的风况拟合模型,得到第二预测风况数据；第一预测风况数据包括第一预测风速和第一预测风向,第二预测风况数据包括第二预测风速和第二预测风向。本申请可以提高风况的预测精度并减少预测过程中运算资源的占用,可广泛应用于风况预测领域。</td>   <td>1.一种风速和风向的预测方法,其特征在于,包括：获取无人机传感器测得的目标测量数据；所述目标测量数据包括无人机的目标对地加速度、目标姿态以及目标电机转速；对所述目标测量数据进行数值优化,得到目标优化数据；将所述目标优化数据输入至预先构建的非线性扰动观测器,得到外界风力的目标三轴扰动力；将所述目标测量数据输入至经过预先训练的风况预测模型,得到第一预测风况数据；将所述目标三轴扰动力输入至经过预先训练的风况拟合模型,得到第二预测风况数据；其中,所述第一预测风况数据包括第一预测风速和第一预测风向,所述第二预测风况数据包括第二预测风速和第二预测风向。</td>   <td>G06Q10/04;G06Q50/26;G06F30/27;G06N3/0499;G06N3/084;G06F111/06;G06F111/10;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         覃章才;                   许逸凡       </td>   <td>中山大学</td>   <td>一种生物质能源的全生命周期评估方法和系统</td>   <td>广东省</td>   <td>CN117172504A</td>   <td>2023-12-05</td>   <td>本发明公开了一种生物质能源的全生命周期评估方法和系统,采集各个省份的基础数据,包括农产品产量、林种面积、原木产量、竹材产量、各种畜禽的出栏量和存栏量、发电部门各种燃料消耗量和发电量、供热部门各种燃料消耗量和供热量,基于各个省份的基础数据计算各省份的生物质资源可用量,从而计算生物质能源的能量产出和能量比、计算各省份生物质能源的减排潜力,计算各省份的生物质能源的经济成本。解决了现有的生物质能源生命周期模型不适用于中国区域化评估,缺乏对于生物质能源部署成本的评估以及未考虑生物质能源中的电力和供热行业的评估的技术问题。</td>   <td>1.一种生物质能源的全生命周期评估方法,其特征在于,包括：采集基础数据,基础数据包括各个省份每年的农产品产量、林种面积、原木产量、竹材产量、各种畜禽的出栏量和存栏量、发电部门各种燃料消耗量和发电量、供热部门各种燃料消耗量和供热量；根据基础数据计算各省份的生物质资源可用量,生物质资源可用量包括农业生物质资源可用量、林业生物质资源可用量和畜禽粪便生物质资源可用量；基于生物质资源可用量计算生物质能源的能量产出和能量比；根据基础数据计算各省份传统能源部门的排放因子,并根据排放因子和生物质能源的能量产出计算各省份生物质能源的减排潜力；根据各省份生物质能源的减排潜力,计算各省份的生物质能源的经济成本。</td>   <td>G06Q10/0631;G06Q10/0639;G06Q50/02;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何汇朗;                   刘慧       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于图像处理的鼻咽癌放疗方法及系统</td>   <td>广东省</td>   <td>CN117173092A</td>   <td>2023-12-05</td>   <td>本发明公开了一种基于图像处理的鼻咽癌放疗方法及系统,涉及放疗技术领域,所述方法包括：获取患者当前周期的颈部CT图像和生理状态信息,对所述颈部CT图像进行预处理,对预处理后的颈部CT图像进行局部图像裁剪获取局部图像集；根据所述局部图像集确定局部横径值,根据所述局部横径值确定横径变化系数；结合患者基础信息对所述生理状态信息进行分析确定生理变化系数,根据所述横径变化系数和所述生理变化系数确定当前周期是否为高变期,在当前周期为高变期时,修改下一周期的放疗计划。本发明能够对颈部轮廓图像进行处理,并结合患者体重指数、性别等数据进行分析,实现计划用量的自适应调节,提高了放疗效果。</td>   <td>1.一种基于图像处理的鼻咽癌放疗方法,其特征在于,包括：获取患者当前周期的颈部CT图像和生理状态信息,所述生理状态信息为BMI变化率；对所述颈部CT图像进行预处理,对预处理后的颈部CT图像进行局部图像裁剪获取局部图像集；根据所述局部图像集确定局部横径值,根据所述局部横径值确定横径变化系数；结合患者基础信息对所述生理状态信息进行分析确定生理变化系数,所述基础信息为性别；根据所述横径变化系数和所述生理变化系数确定当前周期是否为高变期,在当前周期为高变期时,修改下一周期的放疗计划。</td>   <td>G06T7/00;G06T5/00;G06V10/44;G06T7/11;G06T7/194</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              麦剑霆;              陈胜朋;              汪炜;              欧阳婧璇;              张锦绣;                   张小虎       </td>   <td>中山大学</td>   <td>基于窄带滤波的类圆柱目标位姿估计方法、装置和设备</td>   <td>广东省</td>   <td>CN117173246A</td>   <td>2023-12-05</td>   <td>本申请涉及一种基于窄带滤波的类圆柱目标位姿估计方法、装置和计算机设备。所述方法包括：通过设计在类圆柱目标上预先标记两个带反光涂层的不共面圆环,通过安装了特定波长的成像光源和相同波长的窄带滤波片的预处理相机得到类圆柱目标的窄带滤波图像,根据窄带滤波图像,通过基于弧段邻接矩阵的快速椭圆检测算法对类圆柱目标进行椭圆检测,得到两组椭圆信息,根据两组椭圆信息,通过EPnP算法求解得到类圆柱目标的位姿信息。本发明通过窄带滤波使得只有相应波长的光才能被用于成像,能够在复杂场景下有效减少复杂背景的干扰,结合弧段邻接矩阵的快速椭圆检测算法,在目标被遮挡的情况下也可以实现椭圆检测,检测精度更高,鲁棒性更强。</td>   <td>1.一种基于窄带滤波的类圆柱目标位姿估计方法,其特征在于,所述方法包括：通过预处理相机获取待检测的类圆柱目标的窄带滤波图像；所述预处理相机预先安装了特定波长的成像光源和相同波长的窄带滤波片；所述类圆柱目标上包括两个预先标记的带反光涂层的不共面圆环；所述成像光源和所述窄带滤波片的波长由所述反光涂层的材料性质确定；根据所述窄带滤波图像,通过基于弧段邻接矩阵的快速椭圆检测算法对所述类圆柱目标进行椭圆检测,得到两组椭圆信息；根据所述两组椭圆信息,通过EPnP算法求解得到所述类圆柱目标的位姿信息。</td>   <td>G06T7/73;G06T5/10;G06T7/80;G06T17/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         贺智;                   周承乐       </td>   <td>中山大学</td>   <td>高光谱遥感图像的异常检测方法、系统、设备和存储介质</td>   <td>广东省</td>   <td>CN117173540A</td>   <td>2023-12-05</td>   <td>本发明涉及遥感图像检测技术领域,公开了一种高光谱遥感图像的异常检测方法、系统、设备和存储介质,所述方法通过获取待检测高光谱遥感图像；将待检测高光谱遥感图像输入预先训练好的异常检测模型进行异常检测,得到待检测高光谱遥感图像的检测结果,异常检测模型包括依次相连的第一卷积模块、第二卷积模块、第一Transformer模块、第一Resize层和第一全连接层。本发明通过聚类启发来检测背景和异常样本,有效降低了网络模型对人工标注样本的依赖,对于异常检测模型的训练不仅区分异常信息和背景信息,还利用了高光谱图像的重构图像来提高模型的训练效果,使整个模型具有局部和全局感受野,有效提高了异常检测模型的检测精度。</td>   <td>1.一种高光谱遥感图像的异常检测方法,其特征在于,包括：获取待检测高光谱遥感图像；将所述待检测高光谱遥感图像输入预先训练好的异常检测模型进行异常检测,得到所述待检测高光谱遥感图像的检测结果,所述异常检测模型包括依次相连的第一卷积模块、第二卷积模块、第一Transformer模块、第一Resize层和第一全连接层。</td>   <td>G06V10/82;G06V10/764;G06V10/762;G06N3/045;G06N3/0455;G06N3/0464;G06N3/08;G06V10/58;G06V10/44</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王勇;              黄子荣;              周佳奇;              陈豫广;              胡天江;                   张焕龙       </td>   <td>中山大学</td>   <td>一种时序相关的自适应信息融合鱼类群体跟踪方法</td>   <td>广东省</td>   <td>CN117173743A</td>   <td>2023-12-05</td>   <td>本发明公开了一种时序相关的自适应信息融合鱼类群体跟踪方法。首先获取鱼类群体图像数据集,对鱼类群体图像数据集进行预处理,随后将预处理得到的鱼类群体图像数据集划分为训练集和测试集,同时搭建MixDLA模型,利用训练集对所述MixDLA模型进行训练,并利用测试集对训练后的MixDLA模型进行测试,得到训练完成的MixDLA模型,最后搭建时序相关的BF-Tracking模型,将训练完成的MixDLA模型与BF-Tracking模型相连接,得到时序相关的信息融合检测与跟踪模型,并利用时序相关的信息融合检测与跟踪模型对鱼类群体进行检测与跟踪,并输出检测与跟踪结果,有效的减小了跟踪误差,并减轻了跟踪工作量。</td>   <td>1.一种时序相关的自适应信息融合鱼类群体跟踪方法,其特征在于,包括以下步骤：S1：获取鱼类群体图像数据集,对鱼类群体图像数据集进行预处理；S2：将预处理得到的鱼类群体图像数据集划分为训练集和测试集；S3：搭建MixDLA模型；S4：利用训练集对MixDLA模型进行训练,并利用测试集对训练后的MixDLA模型进行测试,得到训练完成的MixDLA模型；S5：搭建时序相关的BF-Tracking模型,将训练完成的MixDLA模型与BF-Tracking模型相连接,得到时序相关的信息融合检测与跟踪模型,并利用时序相关的信息融合检测与跟踪模型对鱼类群体进行检测与跟踪,输出检测与跟踪结果；其中,MixDLA模型表示联合检测跟踪模型,BF-Tracking模型表示自适应决策融合跟踪模型。</td>   <td>G06V40/10;G06V10/44;G06V10/86;G06V10/774;G06V10/82;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              周凡;                   张尧权       </td>   <td>中山大学</td>   <td>一种着装人体热湿生理健康状态预测方法与系统</td>   <td>广东省</td>   <td>CN117174305A</td>   <td>2023-12-05</td>   <td>本发明公开了一种着装人体热湿生理健康状态预测方法与系统。利用人体热湿传输计算模型、服装热湿传输计算模型、人体-服装-环境交互计算模型对用户即将进行的运动及过程中的热湿生理状态进行仿真模拟,得到内核温度等生理指标；以内核温度、脱水百分比、心率作为输入变量,构建包含了运动过程中可能出现的热湿生理状态和症状的着装人体热湿生理状态机；输入内核温度、脱水百分比、心率,利用着装人体热湿生理状态机,计算得到用户运动时出现相关状态的概率值。本发明通过提前预测人体的热湿状态概率值,能够预测和规避健康风险。在日常健身活动中,用户可以及时采取相应的预防措施,如调整运动强度、增加水分摄入等,以规避潜在的健康风险。</td>   <td>1.一种着装人体热湿生理健康状态预测方法,其特征在于,所述方法包括：输入用户的人体参数、服装参数、环境参数、运动条件,利用人体热湿传输计算模型、服装热湿传输计算模型、人体-服装-环境交互计算模型对用户即将进行的运动及运动过程中的热湿生理状态进行仿真模拟,得到内核温度CT序列、出汗率m-(rsw)序列、新陈代谢速率MR序列三种生理指标；根据所述人体参数中的静息心率HR-(rest)、所述运动条件中的运动强度百分比EIP计算出最大心率MHR以及目标心率THR,根据所述出汗率m-(rsw)序列计算脱水百分比DAP序列,根据所述内核温度CT序列、新陈代谢速率MR序列计算心率HR序列；以所述最大心率MHR以及目标心率THR作为常量,内核温度CT、脱水百分比DAP、心率HR作为输入变量,构建着装人体热湿生理状态机；分别以所述内核温度CT序列、所述脱水百分比DAP序列、所述心率HR序列作为输入变量输入到所述着装人体热湿生理状态机中,计算得到每个输入变量i引起的状态转移概率θ-i,之后利用每个输入变量引起的状态转移概率θ-i计算得到每个输入变量i在t时刻的状态概率μ-i(t),最后利用每个输入变量i在t时刻的状态概率μ-i(t)计算得到用户在t时刻的综合状态概率μ-(overall)(t)。</td>   <td>G16H50/30;G16H50/50;G16H20/30;G16H10/60;G16H20/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王伟;              黄惠;              程美清;              陈立达;              胡航通;                   李铭德       </td>   <td>中山大学附属第一医院</td>   <td>一种基于强化学习的肝癌预测方法及系统</td>   <td>广东省</td>   <td>CN117174318A</td>   <td>2023-12-05</td>   <td>本发明公开了一种基于强化学习的肝癌预测方法及系统,包括如下步骤：数据采集,获取患者的标准化肝脏超声图像数据以及患者的临床数据；数据预处理,对数据采集模块采集的数据进行预处理,获得肝脏图像预处理数据；特征提取,利用强化学习算法对肝脏图像预处理数据进行特征提取；强化学习模型构建,利用强化学习算法,构建适用于肝癌预测的强化学习模型；模型训练与优化,利用数据采集模块采集的数据和肝脏图像预处理数据对强化学习模型进行训练和优化；肝癌预测,利用训练和优化好的强化学习模型,对新的患者数据进行预测。本发明能够提供准确的肝癌风险预测和个性化的决策支持,有助于改善肝癌的诊断和治疗效果。</td>   <td>1.一种基于强化学习的肝癌预测方法,其特征在于,包括如下步骤：步骤S1,数据采集,获取患者的标准化肝脏超声图像数据以及患者的临床数据；步骤S2,数据预处理,对数据采集模块采集的数据进行预处理,获得肝脏图像预处理数据；步骤S3,特征提取,利用强化学习算法对肝脏图像预处理数据进行特征提取；步骤S4,强化学习模型构建,利用强化学习算法,构建适用于肝癌预测的强化学习模型；步骤S5,模型训练与优化,利用数据采集模块采集的数据和肝脏图像预处理数据对强化学习模型进行训练和优化；步骤S6,肝癌预测,利用训练和优化好的强化学习模型,对新的患者数据进行预测。</td>   <td>G16H50/30;G16H50/70;G16H30/40;G16H10/60;G06T7/00;G06T7/13;G06T7/136;G06T5/00;G06T5/40;G06N3/048;G06N3/092</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杜紫明;              张仁静;              岑文鉴;              凌冬怡;                   冯沿芬       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种SFTs整合风险评估系统</td>   <td>广东省</td>   <td>CN117174323A</td>   <td>2023-12-05</td>   <td>本发明公开了一种孤立性纤维性肿瘤(SFTs)整合风险评估系统,包括：特征选定模块、风险评估模块以及无进展生存评估模块；通过特征选定模块获取待检测患者所对应的选定病理特征、选定免疫浸润特征以及选定基因变异信息,然后通过风险评估模块将选定病理特征、选定免疫浸润特征以及选定基因变异信息输入至风险评估模型中,以确定对应患者的风险评估分数,最后通过无进展生存评估模块根据风险评估分数,评估待检测患者在各无进展生存期的生存概率；通过实施本发明,能够从病理特征、免疫浸润特征以及基因变异特征三个维度对待检测SFTs患者的预后进行预测,与现有的2020WHO分类,mDemicco模型及G-score模型相比,提高了对待检测SFTs患者预后进行预测的准确性。</td>   <td>1.一种SFTs整合风险评估系统,其特征在于,包括：特征选定模块、风险评估模块以及无进展生存评估模块；所述特征选定模块,用于获取待检测患者所对应的选定病理特征、选定免疫浸润特征以及选定基因变异特征；所述风险评估模块,用于将所述病理特征、免疫浸润特征以及基因变异特征,输入至风险评估模型中,以使所述风险评估模型根据所述病理特征、免疫浸润特征以及基因变异特征,确定风险评估分数；所述无进展生存评估模块,用于根据所述风险评估分数,评估待检测患者在各无进展生存期的生存概率；其中,所述风险评估模型以训练样本的选定病理特征、选定免疫浸润特征以及选定基因变异特征为输入,以各训练样本所对应风险评估分数为输出进行训练得到。</td>   <td>G16H50/50;G16H50/20;G16B20/20;G06F18/27;G06F18/243</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;                   林军       </td>   <td>中山大学</td>   <td>医疗机器人控制软件测试数据的生成方法、注入方法</td>   <td>广东省</td>   <td>CN116048958B</td>   <td>2023-12-01</td>   <td>本发明提供了一种医疗机器人控制软件测试数据的生成方法、注入方法,生成方法包括步骤：S1、生成被测软件的CFG控制图；S2、计算CFG控制图内的有限路径数量；S3、以有限路径数量作为被测试软件的输入参数,进行总群的初始化；S4、若不存在未被覆盖的路径或者运行代数最大时,得到最佳染色体；S5、若存在未被覆盖的路径或者运行代数最大时,进行个体评价；S6、对染色体进行交叉操作和变异操作；S7、计算染色体的适应度值；S8、若适应度值不符合要求,则选择下一代个体,运行代数增加,并返回至步骤S4。采用本发明的方法能以更少的评估量提供更好的覆盖范围。</td>   <td>1.一种医疗机器人控制软件测试数据的生成方法,其特征在于,包括步骤：S1、生成被测软件的CFG控制图；S2、计算CFG控制图内的有限路径数量；S3、以有限路径数量作为被测试软件的输入参数,进行总群的初始化；S4、若不存在未被覆盖的路径或者运行代数最大时,得到最佳染色体；S5、若存在未被覆盖的路径或者运行代数最大时,进行个体评价；S6、对染色体进行交叉操作和变异操作；S7、计算染色体的适应度值；S8、若适应度值不符合要求,则选择下一代个体,运行代数增加,并返回至步骤S4。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张英朝;              王茂桓;              任科州;              钟元芾;              周丽萍;              李鸿旭;              孙蕾;              吕娜;              孙沁;              曹志钦;              曾逸凡;              冯姗姗;              苏倩;                   黄志文       </td>   <td>中山大学</td>   <td>一种可解释的装备组合快速构建方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116108613B</td>   <td>2023-12-01</td>   <td>本发明涉及武器装备组合技术领域,尤其涉及一种可解释的装备组合快速构建方法、系统、设备及介质,包括：构建武器装备组合优化模型,武器装备组合优化模型的约束条件包括武器装备系统价值递增性约束；利用元组合算法和类间组合算法,构建武器装备组合优化模型的装备组合求解算法；通过装备组合求解算法对武器装备组合优化模型进行求解,输出最优武器装备组合方案集合。本发明通过装备分类、元组合算法和类间组合算法,在武器装备系统价值递增性约束下求解得到最终武器装备组合方案集合,解决了传统装备组合构建方法难以满足复杂多变的场景,无法有效平衡可解释性和计算复杂度的问题,有效降低了武器装备组合方案的复杂性,具有较强的可解释性。</td>   <td>1.一种可解释的装备组合快速构建方法,其特征在于,包括以下步骤：构建武器装备组合优化模型,所述武器装备组合优化模型的约束条件包括武器装备系统价值递增性约束；利用元组合算法和类间组合算法,构建武器装备组合优化模型的装备组合求解算法；通过所述装备组合求解算法对所述武器装备组合优化模型进行求解,输出最优武器装备组合方案集合；所述利用元组合算法和类间组合算法,构建武器装备组合优化模型的装备组合求解算法的步骤包括：通过预设的分类指标将所有的武器装备划分为不同类别,得到各类武器装备分组；所述预设的分类指标包括功能需求指标和替换关系指标；基于元组合算法,对各类武器装备分组中的武器装备进行类内组合,得到各类武器装备分组的类内组合方案集合；基于类间组合算法,对不同所述类内组合方案集合之间进行类间组合,得到类间组合方案集合；对所述类间组合方案集合中的每一个类间组合方案进行对齐,以构建得到武器装备组合优化模型的装备组合求解算法；所述基于元组合算法,对各类武器装备分组中的武器装备进行类内组合,得到各类武器装备分组的类内组合方案集合的步骤包括：获取各类武器装备分组中武器装备的评价值；对各类武器装备分组中武器装备的评价值进行升序排序,得到各类武器装备分组对应的武器装备排序结果；从武器装备排序结果中第一个武器装备开始依次向后遍历,每遍历一个武器装备,判断是否存在与当前武器装备评价值相等的武器装备；若不存在与当前武器装备评价值相等的武器装备,则将当前武器装备与所有已遍历的武器装备以武器装备排序结果中的顺序进行组合,得到各类武器装备分组对应的类内组合方案集合；若存在与当前武器装备评价值相等的武器装备,则将评价值相等的武器装备作为同一次序进行排列组合,得到次序排列组合集合,将所述次序排列组合集合依次与所有已遍历的武器装备以武器装备排序结果中的顺序进行组合,得到各类武器装备分组对应的类内组合方案集合；所述类间组合算法,具体包括：计算类间组合方案规模数：；其中,/&gt;表示类间组合方案规模数,/&gt;表示第/&gt;类武器装备分组的武器装备数量为/&gt;；初始化装备优化组合方案集合,使,其中,/&gt;表示装备优化组合方案集合,/&gt;表示输入的第一个类内组合方案集合；依次输入其余的类内组合方案集合,并判断递归次序是否等于类内组合方案集合个数；若递归次序不等于类内组合方案集合个数,则将所述装备优化组合方案集合中的每一个装备优化组合方案逐一与当前输入的类内组合方案集合中的每一个类内组合方案进行并集操作,更新并保存装备优化组合方案；若递归次序等于类内组合方案集合个数,且装备优化组合方案集合中的装备优化组合方案数量等于类间组合方案规模数,则输出更新后的装备优化组合方案集合,并将其作为类间组合方案集合；所述对所述类间组合方案集合中的每一个类间组合方案进行对齐的步骤包括：对所有所述类间组合方案集合中的每一个类间组合方案进行遍历；对每一个类间组合方案中的武器装备进行遍历,并删除每个类间组合方案中重复的武器装备,得到最优武器装备组合方案集合。</td>   <td>G06F30/20;G06Q10/0631;G06Q10/0637;G06F18/24;G06F111/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪涛;              陈小莹;              杨逍;                   黄俊康       </td>   <td>中山大学</td>   <td>一种基于模型简化的火灾蔓延模拟加速方法及系统</td>   <td>广东省</td>   <td>CN113722894B</td>   <td>2023-12-01</td>   <td>本发明公开了一种基于模型简化的火灾蔓延模拟加速方法及系统,该方法包括：获取森林火灾火点监测数据并提取森林火灾的受灾区域边界,得到受灾区域边界信息；根据受灾区域边界信息确定蔓延模型关键参数的速度集并构建初始蔓延模型；对初始蔓延模型进行简化,得到简化后的离散蔓延模型；基于简化后的离散蔓延模型进行受灾区域动态仿真。该系统包括：信息提取模块、初始模型构建模块、简化模块和动态仿真模块。通过使用本发明,能够在保证预测精度的情况下,减小完成受灾区域动态仿真所需的时间。本发明作为一种基于模型简化的火灾蔓延模拟加速方法及系统,可广泛应用于地理信息处理领域。</td>   <td>1.一种基于模型简化的火灾蔓延模拟加速方法,其特征在于,包括以下步骤：S1、获取森林火灾火点监测数据并提取森林火灾的受灾区域边界,得到受灾区域边界信息；S2、根据受灾区域边界信息确定蔓延模型关键参数的速度集并构建初始蔓延模型；S3、对初始蔓延模型进行简化,得到简化后的离散蔓延模型；S4、基于简化后的离散蔓延模型进行受灾区域动态仿真；所述对初始蔓延模型进行简化,得到简化后的离散蔓延模型这一步骤,其具体包括：S31、将小三角形区域内的还未正确分类的离散点根据它们之间欧式距离的大小粗分类为k组数据子集；S32、遍历这k组数据子集,在每组数据子集中选择4个离散点作为一个4点组,4点组数量为k组；S33、判断每个4点组是否同处于一个的小三角形区域内；S34、保留包含在同一个小三角形内的4点组并将不处于同一小三角形的4点组设为空值；S35、遍历所有非空的4点组,去掉属于同一个小三角形的多余的4点组,剩余4点组的数量为k′组；S36、遍历区域内n个离散点,判断到离散点x-i和某个4点组属于相同小三角形,则将离散点x-i加入该4点组所代表的类；判断到离散点x-i不属于k′个4点组中的任意一组,则将该点加入到residue数组中,所述residue数组用于存储下次迭代需要遍历的离散点；S37、将k′个4点组每个组所代表的类的凸包边界点加入到residue数组中并去重,将k′个4点组每个组所代表的类的凸包边界加入到final-TB数组中并去重,所述final-TB数组用于存放已知凸包边界点；S38、循环步骤S31-S37直至residue数组与final-TB数组完全一致,得到简化模型所需的离散点及其速度集,生成简化后的离散蔓延模型。</td>   <td>G06F30/20;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         廖晓东;              王昌栋;              李奎;              赖培源;              杨哲锐;              王增辉;              赖凯煌;                   廖德章       </td>   <td>广东省华南技术转移中心有限公司;中山大学</td>   <td>基于上下文语义的任务自动分解方法和系统</td>   <td>广东省</td>   <td>CN117150046A</td>   <td>2023-12-01</td>   <td>本发明公开了一种基于上下文语义的任务自动分解方法和系统,根据已有技术知识大数据进行语义识别与实体数据提取并构建技术知识图谱；对所述任务需求文档数据进行语义分析与关键词提取,得到需求关键词,将所述需求关键词与任务需求文档数据导入基于BERT的上下文分析模型进行预训练并生成关键词向量；基于关键词向量进行聚类分析,基于多个词向量组生成多组技术需求信息；根据多组技术需求信息中的关键词进行实体语义转化并通过技术知识图谱进行关联技术检索,得到多组关联技术信息；基于多组技术需求信息与多组关联技术信息进行任务与资源分析,并生成任务资源分配方案。通过本发明能够实现对需求文档的精细化任务分解与资源匹配。</td>   <td>1.一种基于上下文语义的任务自动分解方法,其特征在于,包括：获取任务需求文档数据；根据已有技术知识大数据,通过基于RNN的语义识别模型进行语义识别与实体数据提取,基于提取的实体数据构建技术知识图谱；对所述任务需求文档数据进行语义分析与关键词提取,得到需求关键词,将所述需求关键词与任务需求文档数据导入基于BERT的上下文分析模型进行预训练并生成关键词向量；基于关键词向量进行基于k-means的聚类分析,并形成多个词向量组,基于所述多个词向量组生成多组技术需求信息；根据多组技术需求信息中的关键词进行实体语义转化并通过技术知识图谱进行关联技术检索,得到多组关联技术信息；基于多组技术需求信息与多组关联技术信息进行科技资源匹配并生成任务分配信息,基于所述任务分配信息进行科技资源匹配,并生成任务资源分配方案。</td>   <td>G06F16/36;G06F40/30;G06F40/295;G06F16/35;G06F40/216</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖培源;              王昌栋;              李奎;              廖晓东;              赖凯煌;              廖德章;              杨哲锐;                   王增辉       </td>   <td>广东省华南技术转移中心有限公司;中山大学</td>   <td>一种基于高维空间映射的科技资源组织方法及系统</td>   <td>广东省</td>   <td>CN117150138A</td>   <td>2023-12-01</td>   <td>本发明公开了一种基于高维空间映射的科技资源组织方法及系统,包括：构建资源池存储科技资源数据,获取不同类别科技资源的属性特征作为资源画像,基于资源画像的建立资源知识图谱；获取用户当前研发任务的技术需求,构建需求图谱；根据资源知识图谱及需求图谱映射到不同高维空间进行表征匹配,在不同高维空间中进行资源与需求匹配,获取匹配值；将匹配值通过聚类进行融合分析,基于分析结果向用户推荐各类资源对应的具体科技资源实体。本发明通过构建科技资源数据的动态画像,保证了大数据画像的精准度,同时利用需求画像实现用户需求的个性化推荐,提高了资源的交互效率和资源共享的灵活性。</td>   <td>1.一种基于高维空间映射的科技资源组织方法,其特征在于,包括以下步骤：通过大数据方法进行科技资源数据检索,将所述科技资源数据进行预处理,构建资源池存储预处理后的科技资源数据,并进行科技资源数据的分类；根据分类结果获取不同类别科技资源的属性特征,将所述属性特征作为资源画像,基于所述资源画像的建立资源知识图谱；获取用户当前研发任务的技术需求,将所述技术需求进行词向量表示,构建需求图谱,确定需求资源类型的数量；根据所述资源知识图谱及需求图谱映射到不同高维空间进行表征匹配,在不同高维空间中进行资源与需求匹配,获取匹配值；将所述匹配值通过聚类进行融合分析,基于分析结果向用户推荐各类资源对应的具体科技资源实体。</td>   <td>G06F16/9535;G06F16/35;G06F16/36;G06F16/335</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李皖越;              周梓达;                   成慧       </td>   <td>中山大学</td>   <td>一种主动脊椎四足机器人的建模与控制方法及装置</td>   <td>广东省</td>   <td>CN117150776A</td>   <td>2023-12-01</td>   <td>本发明公开了一种主动脊椎四足机器人的建模与控制方法及装置,方法包括：获取目标四足机器人的各个关节的期望轨迹；将期望轨迹映射到目标四足机器人的第一系统状态,并将期望轨迹映发送到模型预测控制器；获取目标四足机器人的关节状态,将关节状态映射到目标四足机器人的第二系统状态；基于目标四足机器人的单刚体动力学模型,通过模型预测控制器获得目标地面反作用力序列；基于目标地面反作用力序列,获得期望力矩；根据期望力矩进行目标四足机器人的运动控制,然后返回获取目标四足机器人的各个关节的期望轨迹这一步骤,直至完成目标四足机器人的运动控制。本发明能够高效实现主动脊椎四足机器人的建模与控制,可广泛应用于计算机技术领域。</td>   <td>1.一种主动脊椎四足机器人的建模与控制方法,其特征在于,包括：获取目标四足机器人的各个关节的期望轨迹；将所述期望轨迹映射到所述目标四足机器人的第一系统状态,并将所述期望轨迹映发送到模型预测控制器；获取所述目标四足机器人的关节状态,并将所述关节状态映射到所述目标四足机器人的第二系统状态；基于所述目标四足机器人的单刚体动力学模型,通过所述模型预测控制器获得目标地面反作用力序列；其中,所述单刚体动力学模型基于所述目标四足机器人的多刚体系统中各个刚体的空间惯量处理得到；所述多刚体系统通过浮动基模型对所述目标四足机器人进行整体建模得到；基于所述目标地面反作用力序列,获得期望力矩；根据所述期望力矩进行所述目标四足机器人下一时刻的运动控制,然后返回所述获取目标四足机器人的各个关节的期望轨迹这一步骤,直至完成目标四足机器人的运动控制。</td>   <td>G06F30/20;G06F30/17;G06F30/15;G06F119/14;G06F119/12;G06F111/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姜善成;              刘棋泽;              江汉康;              古博;                   韩瑜       </td>   <td>中山大学</td>   <td>一种面向动态环境的产业资源配置优化方法、装置及设备</td>   <td>广东省</td>   <td>CN117151402A</td>   <td>2023-12-01</td>   <td>本申请公开了一种面向动态环境的产业资源配置优化方法、装置及设备,方法包括：构建产业资源配置的优化模型；根据优化模型确定根据运营成本构建的目标函数；获取历史订单,并根据历史订单对第一模糊集进行约束,得到第一支持集；目标订单分布于第一模糊集中；获取目标函数的强对偶；利用商用求解器在第一支撑集求解强对偶,得到运营成本的最小值及对应的决策变量。本申请可以提高盐湖化工产业的运力资源利用效率,并减少运输与库存成本,可广泛应用于资源调度领域。</td>   <td>1.一种面向动态环境的产业资源配置优化方法,其特征在于,包括：构建产业资源配置的优化模型；根据所述优化模型确定根据运营成本构建的目标函数；获取历史订单,并根据所述历史订单对第一模糊集进行约束,得到第一支持集；目标订单分布于所述第一模糊集中；获取所述目标函数的强对偶；利用商用求解器在所述第一支撑集求解所述强对偶,得到运营成本的最小值及对应的决策变量。</td>   <td>G06Q10/0631;G06Q10/0835;G06Q10/087;G06Q10/047;G06F18/20;G06N3/092;G06N5/048;G06Q50/02;G06Q50/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林洛阳;              梁小丹;              操晓春;                   陈定纬       </td>   <td>中山大学</td>   <td>一种基于音频控制的虚拟人生成方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN117152285A</td>   <td>2023-12-01</td>   <td>本发明公开了一种基于音频控制的虚拟人生成方法、装置、设备及介质,方法包括：获取输入图像,对输入图像进行图像编码获得隐层向量；基于高斯分布的噪声对隐层向量加噪,获得加噪图像；获取视觉图像,对视觉图像进行特征提取,获得视觉特征；并获取输入音频,对输入音频进行特征提取和掩码处理,获得掩码音频特征；对输入图像或输入音频进行情感识别,获得情感特征；基于视觉特征、掩码音频特征和情感特征,对加噪图像进行反向去噪和图像解码,获得虚拟人的目标图像。本发明能够有效解决现有的虚拟人生成方法仅限于脸部建模的局限性,高效实现基于音频控制的虚拟人生成,可广泛应用于图像处理技术领域。</td>   <td>1.一种基于音频控制的虚拟人生成方法,其特征在于,包括：获取输入图像,对所述输入图像进行图像编码获得隐层向量；基于高斯分布的噪声对所述隐层向量加噪,获得加噪图像；获取视觉图像,对所述视觉图像进行特征提取,获得视觉特征；并获取输入音频,对所述输入音频进行特征提取和掩码处理,获得掩码音频特征；对所述输入图像或所述输入音频进行情感识别,获得情感特征；基于所述视觉特征、所述掩码音频特征和所述情感特征,对所述加噪图像进行反向去噪和图像解码,获得虚拟人的目标图像。</td>   <td>G06T11/00;G10L25/63;G10L25/57;G10L25/03;G06T5/00;G06T9/00;G06T7/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋嘉豪;                   梁上松       </td>   <td>中山大学</td>   <td>基于特征自适应的图像异常检测方法及系统</td>   <td>广东省</td>   <td>CN117152491A</td>   <td>2023-12-01</td>   <td>本发明涉及图像检测技术,为基于特征自适应的图像异常检测方法及系统,其方法的步骤包括：通过紧凑损失预训练特征提取器,使特征提取器提取出来的特征适应目标分布上的图像异常检测；将训练集的数据输入ResNeXt网络模型进行学习,获得训练后的ResNeXt网络模型；利用预训练后的特征提取器和训练后的ResNeXt网络模型,实现图像的异常检测。本发明在数据分析和处理过程中根据数据特征自动调整参数,以显著提高算法学习数据特征的能力,增强了算法的检测效率。</td>   <td>1.一种基于特征自适应的图像异常检测方法,其特征在于,包括以下步骤：通过紧凑损失预训练特征提取器,使特征提取器提取出来的特征适应目标分布上的图像异常检测；将训练集的数据输入ResNeXt网络模型进行学习,获得训练后的ResNeXt网络模型；利用预训练后的特征提取器和训练后的ResNeXt网络模型,实现图像的异常检测。</td>   <td>G06V10/764;G06V10/44;G06V10/74;G06V10/82;G06N3/0455;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭军;                   梁诗琪       </td>   <td>中山大学</td>   <td>一种害虫分类与检测方法</td>   <td>广东省</td>   <td>CN117152498A</td>   <td>2023-12-01</td>   <td>本发明提出一种害虫分类与检测方法,涉及图像分析与处理的技术领域,首先获取害虫样本图像数据集,然后构建害虫图像特征提取模型,利用数据集对害虫图像特征提取模型进行训练,得到训练好的害虫图像特征提取模型,将待处理的害虫图像输入训练好的害虫图像特征提取模型,得到害虫图像特征图,再分别通过分类分支和检测分支对图像特征图进行害虫的分类与检测,解决了密集目标检测遗漏问题,有效兼顾了害虫分类与检测方法的优性能和高精度,适用于不同分类与检测场景。</td>   <td>1.一种害虫图像特征提取方法,其特征在于,包括：S1.获取害虫样本图像数据集,将数据集划分为训练集、验证集和测试集；S2.构建害虫图像特征提取模型,利用训练集对害虫图像特征提取模型进行训练,然后利用验证集对害虫图像特征提取模型进行评估,利用测试集测试害虫图像特征提取模型的有效性,得到训练好的害虫图像特征提取模型；S3.将待处理的害虫图像输入训练好的害虫图像特征提取模型,得到害虫图像特征图。</td>   <td>G06V10/764;G06V10/774;G06V10/40;G06N3/0464;G06N3/0455;G06N3/0499</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林焕彩;              庞亮月;              庞义杰;                   刘焯莹       </td>   <td>中山大学附属口腔医院</td>   <td>一种牙齿健康状态检测方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN117152507A</td>   <td>2023-12-01</td>   <td>本发明公开了一种牙齿健康状态检测方法、装置、设备及存储介质,通过Mask R-CNN Restnet50模型对待检测口腔图像进行图像分割处理,得到待检测口腔图像中每个牙齿对应的牙齿图像；并基于单张牙齿图像的牙齿健康状态检测方法中的Tresnet检测模型,分别对分割出的每个牙齿图像进行牙齿健康状态检测,最后通过整合所有第一牙齿健康状态检测结果,得到待检测口腔图像对应的综合牙齿健康状态检测结果；与现有技术方案相比,本发明的技术方案基于预训练的模型对获取的口腔图像进行图像分割,并对分割出的每个牙齿图像进行牙齿健康状态检测,实现口腔内牙齿的个体化检测和评估,提高了检测准确性和全面性。</td>   <td>1.一种基于单张牙齿图像的牙齿健康状态检测方法,其特征在于,包括：获取待检测牙齿图像,将所述待检测牙齿图像输入到预训练的Tresnet检测模型中,以使所述Tresnet检测模型对所述待检测牙齿图像进行第一图像特征提取,得到多个第一牙齿图像特征,并对所述多个第一牙齿图像特征进行第一多标签分类预测,输出所述待检测牙齿图像的第一多标签分类结果；基于所述第一多标签分类结果,得到所述待检测牙齿图像的第一牙齿健康状态检测结果。</td>   <td>G06V10/764;G06V10/26;G06V10/56;G06V10/54;G06V10/422;G06V10/82;G06N3/0464;G06N3/08;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郝天一;              向金朝;                   崔廷伟       </td>   <td>中山大学</td>   <td>一种Chla浓度分布生成方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN117152608A</td>   <td>2023-12-01</td>   <td>本发明提供了一种Chla浓度分布生成方法、系统、设备及介质。所述方法包括：获取Chla浓度的遥感观测数据和现场观测数据,根据所述遥感观测数据和现场观测数据生成模型数据集,所述遥感观测数据包括CALIOP数据和MODISChla数据；根据所述模型数据集建立并训练Chla反演模型,将所述CALIOP数据输入所述Chla反演模型,得到Chla浓度分布。本发明能够基于CALIOP数据生成Chla浓度的时空分布。</td>   <td>1.一种Chla浓度分布生成方法,其特征在于,所述方法包括：获取Chla浓度的遥感观测数据和现场观测数据,根据所述遥感观测数据和现场观测数据生成模型数据集,所述遥感观测数据包括CALIOP数据和MODISChla数据；根据所述模型数据集建立并训练Chla反演模型,将所述CALIOP数据输入所述Chla反演模型,得到Chla浓度分布。</td>   <td>G06V20/10;G06V10/774;G06V10/82;G06N3/0464;G01S17/88</td>  </tr>        <tr>   <td>中国专利</td>   <td>         庄晓东;              廖新学;              许朝光;              张绍钊;              郭玥;              黄卓山;              谢佩含;              熊振宇;              林钇奋;                   黄日华       </td>   <td>中山大学附属第一医院</td>   <td>一种中重度主动脉瓣狭窄成年患者死亡风险的预测模型</td>   <td>广东省</td>   <td>CN117153377A</td>   <td>2023-12-01</td>   <td>本发明涉及医学预测及数据识别处理技术领域,所要解决的技术问题是提供一种中重度主动脉瓣狭窄成年患者死亡风险的预测模型,至少包括以下模块：模块一,用于收集数据；模块二,用于数据清洗；模块三,用于筛选关键预后指标；模块四,用于构建预测模型；模块五,用于验证预测模型准确性；模块六,用于绘制列线图及开发网页动态列线图。通过全面评估中重度主动脉瓣狭窄成年患者预后危险因素,首次使用机器学习方法LASSO回归筛选出与死亡风险相关的最优预测因子,避免预测模型中预测变量之间存在多重共线性,进而构建预测模型。同时将结果以列线图及网络动态列线图的形式呈现,适合在临床中推广使用。另外临床医生也可以计算不同时间点的死亡风险概率。</td>   <td>1.一种中重度主动脉瓣狭窄成年患者死亡风险的预测模型,其特征在于,至少包括以下模块：模块一,用于收集数据：收集中重度主动脉瓣狭窄患者常规的医疗数据,确定与中重度主动脉瓣狭窄患者死亡风险相关的候选预测因子；模块二,用于数据清洗：排除不符合指标要求的数据；模块三,用于筛选关键预后指标：将数据总样本随机分为训练队列及内部验证队列,在训练队列中,通过LASSO回归分析构造惩罚函数对候选预测因子的预测变量进行筛选,筛选出最优预测因子；模块四,用于构建预测模型：在训练队列中对筛选出的最优预测因子的预测变量进行COX比例风险回归分析,构建多因素COX回归预测模型,计算预测变量的相应回归系数；模块五,用于验证预测模型准确性：经过区分度、校准度、临床实用性评价,验证预测模型准确性；模块六,用于绘制列线图及开发网页动态列线图：将预测方程转变为评分模式及网站交互式界面,采集待测个体信息并输出不同时间点死亡风险预测概率。</td>   <td>G16H50/20;G16H50/70;G06F18/10;G06F18/2113;G06F18/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚燕丹;              李文佳;                   洪铅存       </td>   <td>中山大学孙逸仙纪念医院深汕中心医院</td>   <td>基于深度学习的乳腺癌预后生存预测方法、系统及介质</td>   <td>广东省</td>   <td>CN117153395A</td>   <td>2023-12-01</td>   <td>本发明提供了一种基于深度学习的乳腺癌预后生存预测方法、系统及介质,涉及图像处理、深度学习技术领域,方法包括：获取作为样本的WSI图像,所述WSI图像具有对应的患者级别；将所述WSI图像分割为patch,对所述patch进行聚类提取,得到所述WSI图像的表型特征；采用所述WSI图像对预先构建的深度神经网络进行训练和评价,得到训练好的预测模型；对采集到的WSI图像进行表型特征提取,基于训练好的预测模型对提取到的表型特征进行识别,得到所述WSI图像对应的患者级别,本发明能够提高患者级别预测的准确度。</td>   <td>1.一种基于深度学习的乳腺癌预后生存预测方法,其特征在于,所述方法包括以下步骤：S100,获取作为样本的WSI图像,所述WSI图像具有对应的患者级别；S200,将所述WSI图像分割为patch,对所述patch进行聚类提取,得到所述WSI图像的表型特征；S300,采用所述WSI图像对预先构建的深度神经网络进行训练和评价,得到训练好的预测模型；S400,对采集到的WSI图像进行表型特征提取,基于训练好的预测模型对提取到的表型特征进行识别,得到所述WSI图像对应的患者级别。</td>   <td>G16H50/30;G06T7/00;G06T7/10;G06V10/762;G06V10/40;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁金秋;              何强生;                   夏斌       </td>   <td>中山大学附属第七医院(深圳)</td>   <td>一种质子泵抑制剂的健康风险预测模型的构建方法及其危险分层应用</td>   <td>广东省</td>   <td>CN117153398A</td>   <td>2023-12-01</td>   <td>本发明涉及医学技术领域,具体涉及一种质子泵抑制剂的健康风险预测模型的构建方法及其危险分层应用,所述的预测模型包括如下步骤：(1)数据采集模块；(2)模型构建模块；(3)额外风险和安全阈值计算模块；最终进入模型的变量包括：年龄、BMI、吸烟、自我健康评价、是否处于长期性的疾病/虚弱/残疾状态、自我感知的步行速度、接受的治疗/药物种类数,所述的预测模型综合评估PPI使用后可能的任何远期健康风险,并建立预测模型,根据个体化风险进行精准化治疗,减少了控制剂量和使用时长所带来的疾病复发风险；与目前推荐常规筛查潜在健康风险以及进行生活方式等干预措施相比,本发明可以有效筛选高危人群,减少额外的花费。</td>   <td>1.一种预测质子泵抑制剂相关健康风险预测模型的构建方法,其特征在于,包括如下步骤：(1)数据采集模块：使用问卷采集个体性别、年龄、教育程度等人口学特征以及生活方式和健康状况相关的信息；(2)模型构建和评估模块：S1构建初始模型：通过单因素分析初步筛选潜在的预测特征变量,建立初始模型；S2模型优化：使用LASSO回归对模型进一步优化,删除预测价值较小的变量；S3最优模型获取：在Cox回归模型中,使用逐步回归法筛选进入模型的变量,根据变量的风险比&gt;1.15或者是&lt;0.85的标准,选择最终进入模型的变量,构建最终的预测模型；S4.模型验证：验证模型的区分度和校准度；(3)额外风险和安全阈值计算模块：计算不同风险的人群使用PPI后带来的额外风险大小,确定高危人群。</td>   <td>G16H50/30;G16H10/20;G16H50/70;G16H20/10;G16H70/40;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              罗经周;              王晨曦;              伍鸿俊;              齐浩然;                   黎以宁       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于半监督学习的低光照视频行为识别方法及系统</td>   <td>广东省</td>   <td>CN115205739B</td>   <td>2023-11-28</td>   <td>本发明公开了一种基于半监督学习的低光照视频行为识别方法及系统,方法包括：获取正常光照源视频和低光照源视频；分别进行像素级别域适应、弱增广和帧混合处理得到第一视频序列和第二视频序列；将第一视频序列和第二视频序列作为模型输入,使用真实标签来约束第一视频序列的模型预测结果；对正常光照源视频中提取的特征和低光照源视频中提取的特征进行特征级别域适应；对弱增广和帧混合处理后的视频序列的预测结果进行一致性训练,得到目标模型；将待识别视频序列输入目标模型,生成待识别视频序列对应的预测标签结果。本发明的识别准确率高,能够有效提升在正常光照视频与低光照视频之间的鲁棒泛化能力,可广泛应用于人工智能技术领域。</td>   <td>1.一种基于半监督学习的低光照视频行为识别方法,其特征在于,包括：获取正常光照源视频和低光照源视频；对所述正常光照源视频进行像素级别域适应得到第一视频序列,对所述低光照源视频进行弱增广和帧混合处理,得到第二视频序列；将所述第一视频序列和所述第二视频序列作为模型输入,使用真实标签来约束所述第一视频序列的模型预测结果,得到目标模型；将待识别视频序列输入所述目标模型,生成所述待识别视频序列对应的预测标签结果；所述对所述正常光照源视频进行像素级别域适应得到第一视频序列,包括：采用像素级自适应,分别从对比度和噪声这两个方面来对所述正常光照源视频进行退化处理；其中,所述退化处理的表达式为：N-(deg)＝D-(eg)(N-(in))+δ其中,N-(in)是正常光照帧；D-(eg)(·)是N-(in)的变暗操作；δ是随机高斯噪声；N-(deg)是经退化处理后的视频帧；所述对所述低光照源视频进行弱增广和帧混合处理,得到第二视频序列,包括：对所述低光照源视频连续采样多个帧,得到第三视频序列；对所述第三视频序列进行弱增广处理和强增广处理,得到第一处理结果,所述第一处理结果包括弱增广处理后的视频序列和强增广处理后的视频序列；设置混合帧中弱增广帧的比率,根据所述弱增广帧的比率随机获取弱增强帧的起始位置；根据所述弱增强帧的起始位置,合成混合帧；其中,所述弱增广处理包括以下至少之一：多尺度裁剪和随机水平翻转；所述强增广处理包括以下至少之一：随机翻转、随机旋转、随机高斯噪声、随机模糊、随机失真、随机亮度和随机对比度；所述将所述第一视频序列和所述第二视频序列作为模型输入,使用真实标签来约束所述第一视频序列的模型预测结果,包括：将退化处理后的视频序列作为模型输入,使用真实标签来约束所述第一视频序列的模型预测结果,从而在正常光照视频下进行监督训练；将退化处理后的视频序列和弱增广后的视频序列作为模型输入,使用真实标签来约束所述第一视频序列的模型预测结果,对所述正常光照源视频中提取的特征和所述低光照源视频中提取的特征进行特征级别域适应；将退化处理后的视频序列、弱增广后的视频序列和帧混合处理后的视频序列作为模型输入,使用真实标签来约束所述第一视频序列的模型预测结果,对所述弱增广和帧混合处理后的视频序列的预测结果进行一致性训练,得到目标模型。</td>   <td>G06V20/40;G06V10/34;G06V10/82;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              张瓅丹;              吴攀;              蔡承志;              郑炎辉;              康丽;              林岚;              孙姗珍;                   田世拓       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种基于DEM数据的坡面产汇流简易计算方法及装置</td>   <td>广东省</td>   <td>CN116305933B</td>   <td>2023-11-28</td>   <td>本发明涉及水文模拟技术领域,公开了一种基于DEM数据的坡面产汇流简易计算方法及装置。本发明以DEM数据栅格对目标区域进行划分并构建分布式水文模型,对该模型进行调整以使其所模拟的产流过程考虑因洼地滞水导致的净雨损失；该模型在进行汇流计算时基于Dijkstra算法计算各栅格的产流按流向汇至流域出口的最短路径,基于谢才公式计算属于河涌的栅格的水流流经时间,基于Kerby方程计算属于地表坡面的栅格的水流流经时间,以简化计算且保证计算精度,并基于Chapman-Maxwell滤波法从总流量中分割出地面径流以得到更好的分割效果。本发明实现了在进行坡面产汇流计算时同时兼顾高计算效率与高模拟精细度。</td>   <td>1.一种基于DEM数据的坡面产汇流简易计算方法,其特征在于,包括：获取目标区域的用于坡面产汇流计算的基础数据；所述基础数据包括地形DEM数据、子汇水区划分结果及对应倾泻点分布数据；对所述基础数据进行包括插值处理在内的预处理,得到目标基础数据；以DEM数据栅格对所述目标区域进行划分,并根据所述目标基础数据构建所述目标区域的分布式水文模型,包括：以DEM数据栅格对所述目标区域进行划分,并根据所述地形DEM数据、子汇水区划分结果及对应倾泻点分布数据进行水流流向和坡度计算,根据得到的计算结果设置各所述DEM数据栅格的属性；基于SCS-CN方法构建SCS-CN模型,并根据前期土壤湿度对所述SCS-CN模型的径流曲线数进行修正,得到修正后的SCS-CN模型作为实现DEM数据栅格的产流计算的产流计算模块；构建实现DEM数据栅格的汇流计算的汇流计算模块；结合所述产流计算模块和汇流计算模块得到所述目标区域的分布式水文模型；所述基础数据还包括土地利用类型网格数据和河道与地表坡面分布数据；所述汇流计算模块基于Dijkstra算法计算各DEM数据栅格的产流按流向汇至流域出口的最短路径,基于谢才公式计算属于河涌的DEM数据栅格的水流流经时间,以及基于Kerby方程计算属于地表坡面的DEM数据栅格的水流流经时间；所述汇流计算模块基于Chapman-Maxwell滤波法从总流量中分割出地面径流,相应的滤波方程为：          q-t＝Q-t-b-t式中,q-t为t时刻的地面径流,Q-t为t时刻的总径流,b-t为t时刻的基流,b-(t-1)为t-1时刻的基流,k为退水系数；构建洼地向外产流条件,包括：设所述目标区域内的一个洼地m具有n个DEM数据栅格,构建所述洼地m的洼地向外产流条件为：                  式中,P-k为洼地m内的第k个DEM数据栅格的累计降雨量,S-(max)(k)为洼地m内的第k个DEM数据栅格的最大潜在蓄水能力,d-k为洼地m内的第k个DEM数据栅格的填充凹陷水量；所述洼地向外产流条件假设洼地向外产流时下垫面的土壤含水量达到最大潜在蓄水能力；根据所述洼地向外产流条件调整所述分布式水文模型,使得调整后的分布式水文模型所模拟的产流过程考虑因洼地滞水导致的净雨损失；所述基础数据还包括历史降水径流数据；对所述调整后的分布式水文模型进行率定和验证,得到满足预置模拟精度要求的目标分布式水文模型,包括：确定所述调整后的分布式水文模型的目标参数的初始值及相应的率定范围；所述目标参数包括不同下垫面类型的糙率系数、径流曲线数及初损量与潜在蓄水能力的比值系数；基于决定系数、威尔莫特一致性指数、相对偏差、平均误差、平均绝对误差、均方根误差和/或纳什系数构建评价所述调整后的分布式水文模型的模拟效果的目标函数；根据所述历史降水径流数据,依据所述目标函数对所述目标参数进行率定和验证,以使得到的拟合结果满足预置模拟精度要求；基于所述目标分布式水文模型进行所述目标区域的坡面产汇流预报。</td>   <td>G06F30/20;G06Q10/047</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄袁;              练芷璐;              陈湘萍;                   郑子彬       </td>   <td>中山大学</td>   <td>模型训练方法、基于字节码的代码注释生成方法及装置</td>   <td>广东省</td>   <td>CN117130658A</td>   <td>2023-11-28</td>   <td>本申请公开一种模型训练方法、基于字节码的代码注释生成方法及装置,其中的模型训练方法使用字节码和控制流程图作为输入,并把控制流程图序列化为节点序列,模型从字节码学习语义信息,从控制流程图学习结构信息,建立了字节码和代码注释之间的连接,提高字节码的可读性；对控制流程图的序列化能够完整保留图的结构信息,模型在无源码场景下表现出更好的性能。</td>   <td>1.一种模型训练方法,其特征在于,所述方法训练得到的模型用于生成代码注释,包括第一编码器、第二编码器和解码器,所述方法包括：获取字节码,根据字节码生成控制流程图；对控制流程图序列化得到节点序列,节点序列表示控制流程图的图结构；把字节码和节点序列分别输入第一编码器和第二编码器进行编码；解码器根据第一编码器和第二编码器的输出,以及参考注释预测单词序列组成代码注释；计算生成的代码注释与参考注释的误差,误差用于更新预测模型的参数,误差结果收敛时,训练完成输出用于生成代码注释的预测模型。</td>   <td>G06F8/73;G06N3/0455;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永强;              周永章;              王维曦;              王汉雨;              贺炬翔;              许娅婷;                   曹伟       </td>   <td>中山大学</td>   <td>一种基于知识图谱的场地土壤污染问答系统及问答方法</td>   <td>广东省</td>   <td>CN117131184A</td>   <td>2023-11-28</td>   <td>本发明公开了一种基于知识图谱的场地土壤污染问答系统及问答方法,包括：数据整合模块,用于从若干数据源中收集与场地土壤污染相关的文本数据,并通过自然语言处理技术进行处理和分析,以提取场地土壤污染数据；图谱构建模块,用于根据场地土壤污染数据构建场地土壤污染知识图谱,并将其存储在图数据库中；问答引擎模块,用于对目标问题进行语义理解和意图识别,然后在场地土壤污染知识图谱中进行语义匹配和数据检索,获取目标实体、目标属性和目标关系,并生成对应的目标答案；用户交互模块,用于获取用户输入的目标问题,以及将目标答案返回给用户。本发明能够通过智能问答的方式提供准确及时全面的场地土壤污染相关信息。</td>   <td>1.一种基于知识图谱的场地土壤污染问答系统,其特征在于,所述系统包括：数据整合模块,用于从若干数据源中收集与场地土壤污染相关的文本数据,并通过自然语言处理技术对所述文本数据进行处理和分析,以提取场地土壤污染数据；其中,所述数据源至少包括科研论文数据库、环境监测数据库、场地土壤污染调查报告和专家经验；图谱构建模块,用于根据所述场地土壤污染数据构建场地土壤污染知识图谱,以及将所述场地土壤污染知识图谱存储在图数据库中；其中,所述场地土壤污染知识图谱包括场地土壤污染实体、场地土壤污染属性和场地土壤污染关系；问答引擎模块,用于对目标问题进行语义理解和意图识别,然后在所述场地土壤污染知识图谱中进行语义匹配和数据检索,获取目标实体、目标属性和目标关系,并生成对应所述目标问题的目标答案；用户交互模块,用于获取用户输入的目标问题,以及将所述目标答案返回给所述用户。</td>   <td>G06F16/332;G06F40/30;G06N3/0442;G06N3/08;G06F16/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         万文琦;                   邬树楠       </td>   <td>中山大学</td>   <td>一种面向机器人在轨组装的耦合动力学建模方法及系统</td>   <td>广东省</td>   <td>CN117131704A</td>   <td>2023-11-28</td>   <td>本发明公开了一种面向机器人在轨组装的耦合动力学建模方法及系统,该方法包括：通过面向在轨组装的渐增式大型空间结构动力学建模方法,构建空间结构渐增式动力学模型；基于机器人自由度广义坐标与结构自由度广义坐标获取耦合机器人系统的拉格朗日量,并构建机器人系统拉格朗日方程；将机器人的拉格朗日量代入至空间结构渐增式动力学模型,得到空间结构-机器人耦合动力学模型。本发明能够很好地描述组装空间结构组装过程结构参数跃变条件下的系统动态特性并提高动力学的分析效率。本发明作为一种面向机器人在轨组装的耦合动力学建模方法及系统,可广泛应用于耦合动力学建模技术领域。</td>   <td>1.一种面向机器人在轨组装的耦合动力学建模方法,其特征在于,包括以下步骤：通过面向在轨组装的渐增式大型空间结构动力学建模方法,构建空间结构渐增式动力学模型；基于机器人自由度广义坐标与结构自由度广义坐标获取耦合机器人系统的拉格朗日量,并构建机器人系统拉格朗日方程；将机器人系统拉格朗日方程与空间结构渐增式动力学模型进行结合,得到空间结构-机器人耦合动力学模型。</td>   <td>G06F30/20;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡俊;                   卢俊安       </td>   <td>中山大学</td>   <td>一种基于FPGA的雷达辐射源信号识别模型的构建方法</td>   <td>广东省</td>   <td>CN117131906A</td>   <td>2023-11-28</td>   <td>本发明公开了一种基于FPGA的雷达辐射源信号识别模型的构建方法,包括以下步骤：S1,构建数据集；S2,设计原始模型；S3,模型进行稀疏正则化训练,得到权重稀疏的模型；S4,对模型进行剪枝,根据预设的滤波器重要性的判定依据,逐层对滤波器进行排序,剪除稀疏的滤波器和相应通道；S5,对模型进行微调训练并重复迭代,直到模型精度和压缩比均满足预设要求；S6,对模型进行参数量化,并设计模型参数存储与读取的优化策略；S7,设计一种基于FPGA的网络层模块复用架构并结合加速策略,最终得到目标模型。本发明所得模型具有结构复杂度低、模型参数量少、识别实时性高以及低功耗的特点。</td>   <td>1.一种基于FPGA的雷达辐射源信号识别模型的构建方法,其特征在于,包括以下步骤：S1,构建雷达辐射源数据集；S2,设计基于深度可分离卷积的原始模型,记作1D-LDS-CNN模型；S3,步骤S2所得模型采用所述雷达辐射源数据集进行稀疏正则化训练,得到权重稀疏的1D-LDS-CNN模型；S4,对步骤S3所得模型进行模型剪枝,根据预设的滤波器重要性的判定依据,逐层对滤波器进行排序,剪除稀疏的滤波器和相应通道；S5,对步骤S4所得模型进行微调训练并重复迭代,直到模型精度和压缩比均满足预设要求；S6,对步骤S5所得模型进行模型参数量化,并设计模型参数存储与读取的优化策略；S7,构建基于FPGA的网络层模块复用架构并结合预设的加速策略以加速步骤S6所得模型的推理过程,最终得到目标模型。</td>   <td>G06N3/0464;G06N3/082;G06F18/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         岳泽宇;              黄林冲;              林越翔;              马建军;              赖正首;                   梁禹       </td>   <td>中山大学</td>   <td>隧道的正射影像生成方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN117132709A</td>   <td>2023-11-28</td>   <td>本申请涉及测绘领域,提出了一种隧道的正射影像生成方法、装置、设备及存储介质。该方法包括：通过移动激光扫描设备获取扫描点云,根据所述扫描点云拟合得到隧道断面对应的多边形；确定所述多边形的形心位置,以及对所述多边形进行等距离划分,得到多个等距离段的划分点；根据所述划分点和所述形心位置,确定所述等距离段的形心角；根据所述形心角确定对应的隧道断面的点云,根据所述形心角与所述隧道断面的点云的对应关系,对所述隧道断面的点云的灰度进行纠正,得到所述隧道的正射影像。通过拟合任意形状的隧道为多边形,根据多边形的形心角进行灰度纠正,可以有效的适应任意形状的隧道,且能够有效的提高正射影像的精度。</td>   <td>1.一种隧道的正射影像生成方法,其特征在于,所述方法包括：通过移动激光扫描设备获取扫描点云,根据所述扫描点云拟合得到隧道断面对应的多边形；确定所述多边形的形心位置,以及对所述多边形进行等距离划分,得到多个等距离段的划分点；根据所述划分点和所述形心位置,确定所述等距离段的形心角；根据所述形心角确定对应的隧道断面的点云,根据所述形心角与所述隧道断面的点云的对应关系,对所述隧道断面的点云的灰度进行纠正,得到所述隧道的正射影像。</td>   <td>G06T17/00;G06T5/00;G01B11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         夏娟;              江颖;              陈枝沛;              吴锐凡;              余嘉丽;              程斌;                   徐萌       </td>   <td>中山大学附属口腔医院;中山大学</td>   <td>一种舍格伦综合征的淋巴细胞分类方法及装置</td>   <td>广东省</td>   <td>CN117132977A</td>   <td>2023-11-28</td>   <td>本申请公开了一种舍格伦综合征的淋巴细胞分类方法及装置,方法包括：采用不同模型在病理影像矩阵中提取细胞特征列表和组织特征列表；基于细胞特征列表和组织特征列表分别计算细胞间距离矩阵和细胞-组织距离矩阵；根据细胞特征列表、细胞间距离矩阵和预置细胞特征信息构建细胞之间的细胞图模型；根据组织特征列表、细胞-组织距离矩阵和预置细胞特征信息构建细胞与组织的组织图模型；通过LightGCN算法分别对细胞图模型和组织图模型进行图嵌入演化分析,得对应细胞和组织嵌入演化结果；基于细胞和组织嵌入演化结果进行细胞分类,得到淋巴细胞信息。本申请能够解决现有技术依赖人工判断,导致效率和准确性较差的技术问题。</td>   <td>1.一种舍格伦综合征的淋巴细胞分类方法,其特征在于,包括：采用Stardist模型从目标病理影像矩阵中提取细胞特征列表,所述细胞特征列表包括多个细胞特征；通过SegmentAnything分割模型在所述目标病理影像矩阵中提取组织特征列表,所述组织特征列表包括多个组织特征；基于所述细胞特征列表和所述组织特征列表分别计算细胞间距离矩阵和细胞-组织距离矩阵；根据所述细胞特征列表、所述细胞间距离矩阵和预置细胞特征信息构建细胞之间的关联边,并生成细胞图模型；根据所述组织特征列表、所述细胞-组织距离矩阵和所述预置细胞特征信息构建细胞与组织结构的关联关系,并生成组织图模型；通过LightGCN算法分别对所述细胞图模型和所述组织图模型进行图嵌入演化分析,得到对应的细胞嵌入演化结果和组织嵌入演化结果；基于所述细胞嵌入演化结果和所述组织嵌入演化结果进行细胞分类,得到淋巴细胞信息,所述淋巴细胞信息包括淋巴细胞列表和淋巴细胞距离矩阵。</td>   <td>G06V20/69;G06V10/80;G06V10/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡楷欣;              任鹏真;                   梁小丹       </td>   <td>中山大学</td>   <td>一种文本监督语义分割方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117132987A</td>   <td>2023-11-28</td>   <td>本发明公开了一种文本监督语义分割方法、装置、电子设备及存储介质,方法包括：获取待分割的目标图像；利用图像编码器,通过聚合令牌对目标图像进行图像编码,获得聚合特征；其中,图像编码器基于已标注语义分割标签的若干混合图像训练生成的,混合图像基于已知分割掩码的不同原始图像的补丁随机混合得到,混合图像的各补丁的语义分割标签与各补丁来源的原始图像的分割掩码对应；聚合特征对应语义分割掩码；对聚合特征进行文本分类,获得分割类别,进而结合语义分割掩码得到语义分割结果。本发明能够在跨模态学习中获得更好的语义分割能力,学习到更高级的多模态对齐信息,进而高效准确实现文本监督语义分割,可广泛应用于数据处理技术领域。</td>   <td>1.一种文本监督语义分割方法,其特征在于,包括：获取待分割的目标图像；利用图像编码器,通过聚合令牌对所述目标图像进行图像编码,获得聚合特征；其中,所述图像编码器基于已标注语义分割标签的若干混合图像训练生成的,所述混合图像基于已知分割掩码的不同原始图像的补丁随机混合得到,所述混合图像的各所述补丁的所述语义分割标签与各所述补丁来源的原始图像的分割掩码对应；所述聚合特征对应语义分割掩码；对所述聚合特征进行文本分类,获得分割类别,进而结合所述语义分割掩码得到语义分割结果。</td>   <td>G06V30/148;G06V30/18;G06V30/182;G06V30/19</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              杨雅涵;              李睿扬;                   郭翀       </td>   <td>中山大学中山眼科中心</td>   <td>一种近视图像深度学习识别模型训练方法及系统</td>   <td>广东省</td>   <td>CN111259743B</td>   <td>2023-11-24</td>   <td>本发明涉及医学图像处理技术领域,更具体地涉及一种近视图像深度学习识别模型训练方法,包括以下步骤：采集眼外观图像；对所述眼外观图像进行预处理；以人脸识别大数据库VGG-Face中的人脸图像作为第一训练数据,对VGG-16网络模型进行预训练；以预处理后的所述眼外观图像作为第二训练数据,对预训练后的所述VGG-16网络模型进行训练,得到用于近视图像识别的深度学习模型。本发明提供一种近视图像深度学习识别模型训练方法,用于辅助使用者快速、准确地判断青少年近视情况。</td>   <td>1.一种近视图像深度学习识别模型训练方法,其特征在于,包括以下步骤：采集眼外观图像；对所述眼外观图像进行预处理；以人脸识别大数据库VGG-Face中的人脸图像作为第一训练数据,对VGG-16网络模型进行预训练；以预处理后的所述眼外观图像作为第二训练数据,对预训练后的所述VGG-16网络模型进行训练,得到用于近视图像识别的深度学习模型；采集眼外观图像,具体包括：在距离被采集者预设采集距离时,采集被采集者每只眼睛的三个角度的所述眼外观图像,所述三个角度分别为正侧面、斜45度和正面；采集具有验光数据的眼外观图像；以预处理后的所述眼外观图像作为第二训练数据,对预训练后的所述VGG-16网络模型进行训练,具体包括：将所述验光数据作为图像标签,按照等效球面镜度数是否小于-0.50D作为是否近视的分类标准,以预处理后的所述眼外观图像作为第二训练数据,对预训练所生成的模型参数作为初始模型参数,对所述VGG-16网络模型进行二分类神经网络的训练。</td>   <td>G06V40/16;G06V10/774;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨璐宇;                   成慧       </td>   <td>中山大学</td>   <td>一种三维物体检测方法</td>   <td>广东省</td>   <td>CN112365600B</td>   <td>2023-11-24</td>   <td>本发明涉及机器视觉技术领域,更具体的是涉及一种三维物体检测方法,包括以下步骤：S1：获取物体的点云数据,根据点云数据得到物体的俯瞰特征图；S2：构造二维旋转候选框,对俯瞰特征图进行二维旋转目标检测,提取得到初始特征图F；S3：通过初始特征图F得到旋转物体的二维初步检测结果P；S4：调整初始特征图F的特征值,得到调整特征图f,使初步检测结果P与特征图f中的像素点对齐；S5：将初步检测结果P作为候选框,对调整特征图f进行检测,得到二维旋转物体精细检测结果；S6：将二维旋转物体精细检测结果恢复到点云尺度,得到三维物体检测结果。通过二维旋转候选框检测三维物体,结果更为精确。</td>   <td>1.一种三维物体检测方法,其特征在于,包括以下步骤：S1：获取三维物体的点云数据,根据点云数据得到三维物体的俯瞰特征图；S2：构造二维旋转候选框,运用二维旋转目标检测网络对俯瞰特征图进行二维旋转目标检测,提取得到初始特征图F；S3：通过初始特征图F得到旋转物体的二维初步检测结果P；S4：调整初始特征图F的特征值,得到调整特征图f,使初步检测结果P与特征图f中的像素点对齐；所述步骤S4中通过特征插值调整初始特征图F的特征值,得到调整特征图f,具体包括以下步骤：S41：获取初步检测结果P的几何中心点和几何中心点周围的四个像素点对应的特征值；S42：分别计算四个像素点与几何中心点的距离；S43：根据距离进行加权计算四个像素点的和,得到几何中心点的特征值；S44：对特征图F中的每个像素点均执行步骤S41至步骤S43,得到调整后的特征图f；S5：将初步检测结果P作为候选框,对调整特征图f进行检测,得到二维旋转物体精细检测结果；S6：将二维旋转物体精细检测结果恢复到点云尺度,得到三维物体检测结果。</td>   <td>G06T17/20;G06V10/75</td>  </tr>        <tr>   <td>中国专利</td>   <td>         聂琳;              张吉祺;              林倞;              王广润;                   王广聪       </td>   <td>中山大学</td>   <td>一种基于可微图学习的行人重识别模型的弱监督训练方法</td>   <td>广东省</td>   <td>CN112395997B</td>   <td>2023-11-24</td>   <td>本发明提供一种基于可微图学习的行人重识别模型的弱监督训练方法,该方法首先将行人图片按拍摄时间段分组成袋并分配袋类别标签；然后,捕获每一个袋中所有图片之间的依赖关系,来为该类别的袋中每张图片生成可靠的伪行人类别标签,作为行人重识别模型训练的监督信息；然后,进行行人重识别模型和图模型的一体训练；将图模型损失和重识别损失的线性组合作为总损失函数,利用反向传播算法更新网络所有层的参数。本发明不需要繁重的人工标注成本、几乎不增加计算复杂度也能达到领先的模型性能。</td>   <td>1.一种基于可微图学习的行人重识别模型的弱监督训练方法,其特征在于,包括以下步骤：S1：将行人图片按拍摄时间段分组成袋并分配袋类别标签；S2：捕获每一个袋中所有图片之间的依赖关系,来为该类别的袋中每张图片生成伪行人类别标签,作为行人重识别模型训练的监督信息；S3：进行行人重识别模型和图模型的一体训练；S4：将图模型损失和重识别损失的线性组合作为总损失函数,利用反向传播算法更新网络所有层的参数；所述步骤S2的过程是：若弱监督行人重识别只有袋类别标签l可用,需要先为每张图片估计一个伪行人类别标签,用一个概率向量Y表示；假设l类别标签下的袋中包含n个行人类别,整个训练集共有m个行人类别,用袋类别标签限制Y,则每张图片x-j的行人类别标签的概率向量为：                  所述步骤S3的过程是：定义一个有向图,每个节点代表一个袋中的一张图片x-i,每条边代表图片之间的关系,在图上为节点x分配行人类别标签y的能量函数为：                  其中U和V分别表示节点和边,Φ(y-i|x-i)是计算为图片x-i分配标签y-i的代价的一元项,Ψ(y-i,y-j|x-i；x-j)是计算为图片对(x-i,x-j)分配标签的惩罚的成对项,公式(2)消除了弱监督学习生成的错误的伪标签；公式(2)中的一元项定义为：Φ(y-i|x-i)＝-log(Y-i[y-i]),其中Y＝Y-i⊙P-i  (3)其中P-i是神经网络为图片x-i计算的行人类别标签的概率,表示网络输出；Y-i是公式(1)表示的袋限制,⊙表示逐元素乘积,[·]表示向量索引；由于不同图片的一元项输出相互独立,一元项不稳定,需要用成对项平滑：                  其中用一个基于RGB颜色的高斯核计算外表相似度,超参数σ控制高斯核的尺寸,限制外表相似的图片有相同的标签；Y-i[y-i]Y-j[y-j]表示袋限制,表示外表相似度；标签兼容度ζ(y-i,y-j)用玻茨模型表示：</td>   <td>G06V20/52;G06V10/74;G06V10/764;G06V10/774;G06V10/82;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑俊炯;              林天歆;              孔坚秋;              卢思弘;                   蔡锦华       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>结合FISH检测的膀胱癌术后复发风险预测方法、装置及介质</td>   <td>广东省</td>   <td>CN116013528B</td>   <td>2023-11-24</td>   <td>本发明公开一种结合FISH检测的膀胱癌术后复发风险预测方法、装置及介质,所述方法包括：从候选临床因素筛选出多个预测因子；根据所述多个预测因子和FISH检测结果构建临床预测模型；根据目标患者的临床资料得到各个预测因子取值；根据所述目标患者的尿液样本确认FISH检测取值；将所述各个预测因子取值和所述FISH检测取值输入所述临床预测模型,得到所述目标患者的复发风险评分；根据所述复发风险评分对所述目标患者的术后复发风险进行预测,得到所述目标患者的危险分层。采用本发明,结合FISH检测进行膀胱癌术后复发风险预测,得到更加精确、可靠的预测结果。</td>   <td>1.一种结合FISH检测的膀胱癌术后复发风险预测方法,其特征在于,包括：从候选临床因素筛选出多个预测因子,具体包括：使用LASSOCox回归算法在训练组中对候选临床因素进行相关性筛选,将回归系数不为0的临床因素作为预测因子；所述训练组是对临床病理数据库进行数据分组得到的,用于训练临床预测模型；根据所述多个预测因子和FISH检测结果构建临床预测模型,具体包括：在Cox回归中,根据预设范数使用Lasso回归算法对所述多个预测因子和FISH检测结果进行收缩惩罚,调整所述多个预测因子和FISH检测结果对应的回归系数,得到复发风险评分的计算公式；使复发风险评分计算公式的C指数评分和校准曲线吻合度达到预期目标；在不同截断点下,做Kaplan-Meier生存分析和对数秩检验,选择最高χ2值对应的截断点作为复发风险评分的最佳截断点；根据目标患者的临床资料得到各个预测因子取值；根据所述目标患者的尿液样本确认FISH检测取值；将所述各个预测因子取值和所述FISH检测取值输入所述临床预测模型,得到所述目标患者的复发风险评分；根据所述复发风险评分对所述目标患者的膀胱癌术后复发风险进行预测,得到所述目标患者的危险分层。</td>   <td>G16H50/30;G16H50/70;G06F16/9535</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡泽杰;              卢宇彤;              罗嘉文;              冯浚轩;              刘志勇;                   陈志广       </td>   <td>中山大学</td>   <td>本地文件系统的管理方法、电子设备及可读存储介质</td>   <td>广东省</td>   <td>CN117112496A</td>   <td>2023-11-24</td>   <td>本申请公开了一种本地文件系统的管理方法、电子设备及可读存储介质,涉及文件管理技术领域,本地文件系统中的各对象均包括多个存储了索引节点数据的文件存储区域,将目标文件的目标文件元数据存储至基于空闲索引节点队列获取的空闲索引节点数据对应的文件存储区域,并依据目标文件名、目标文件类型和目标索引节点号,构建目标目录项；基于线性哈希函数确定目标文件名对应的目标对象；若基于多路布谷鸟哈希函数在目标对象中查找不到目标文件名,并且目标对象中不存在处于空闲状态的目录项槽位,则基于线性哈希函数对目标对象进行分裂,以创建得到目录项所需插入的空闲目录项槽位。解决了现有的在云存储环境下的本地文件系统的扩容便捷性差的问题。</td>   <td>1.一种本地文件系统的管理方法,其特征在于,所述本地文件系统中的各对象均包括多个存储了索引节点数据的文件存储区域,所述本地文件系统的管理包括：获取目标文件的目标文件元数据,并提取所述目标文件元数据中的目标文件名和目标文件类型；基于空闲索引节点队列获取空闲索引节点数据和所述空闲索引节点数据对应的目标索引节点号；将所述目标文件元数据存储至所述空闲索引节点数据对应的文件存储区域,并依据所述目标文件名、所述目标文件类型和所述目标索引节点号,构建目标目录项；基于线性哈希函数确定所述目标文件名对应的目标对象；若基于多路布谷鸟哈希函数在所述目标对象中查找不到所述目标文件名,并且所述目标对象中不存在处于空闲状态的目录项槽位,则基于线性哈希函数对所述目标对象进行分裂,以创建得到空闲目录项槽位；将所述目标目录项插入所述空闲目录项槽位,以完成所述目标文件的创建。</td>   <td>G06F16/11;G06F16/13;G06F16/182;G06F3/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡泽杰;              罗嘉文;              刘志勇;              陈志广;                   卢宇彤       </td>   <td>中山大学</td>   <td>目录分布方法、电子设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN117112527A</td>   <td>2023-11-24</td>   <td>本申请为数据存储领域,公开了一种目录分布方法、电子设备及计算机可读存储介质,包括：基于跳跃一致性哈希算法在分布式文件系统的虚拟集合的虚拟目录中插入待创建目录项,若虚拟目录的存储量大于预设存储阈值,则判断分布式文件系统中虚拟集合的集合数量是否小于预设集合阈值；若是则从虚拟集合中分裂出新目录集合并为新目录集合分配元数据节点；若否则判断虚拟目录的目录数量是否小于预设目录阈值；若目录数量小于预设目录阈值则基于虚拟目录所在的虚拟集合的全局位图进行目录分裂；若目录数量大于或等于预设目录阈值则控制目录扩展和目录分裂交替进行分裂。本申请旨在解决分布式文件系统中目录创建不够高效的技术问题。</td>   <td>1.一种目录分布方法,其特征在于,应用于分布式文件系统,所述目录分布方法包括：响应于目录项创建指令,在所述分布式文件系统中启动目录创建流程；其中,所述目录创建流程为：基于跳跃一致性哈希算法在所述分布式文件系统的虚拟集合的虚拟目录中插入待创建目录项,若所述虚拟目录的存储量大于预设存储阈值,则判断所述分布式文件系统中所述虚拟集合的集合数量是否小于预设集合阈值；若是,则从所述虚拟集合中分裂出新目录集合,并为所述新目录集合分配元数据节点以在所述新目录集合中进行目录存储；若否,则判断所述虚拟目录的目录数量是否小于预设目录阈值；若所述目录数量小于所述预设目录阈值,则基于所述虚拟目录所在的所述虚拟集合的全局位图进行目录分裂,其中,所述目录分裂为对所述虚拟目录进行分裂；若所述目录数量大于或等于所述预设目录阈值,则控制目录扩展和目录分裂交替进行,其中,所述目录扩展为扩展所述虚拟目录的存储量。</td>   <td>G06F16/182;G06F16/13;G06F16/188;G06F16/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘再行;              赖培源;              王昌栋;              杨永仕;              李奎;              廖晓东;                   赖剑煌       </td>   <td>广州美术学院;广东省华南技术转移中心有限公司;中山大学</td>   <td>基于用户特征及大数据训练的智能设计方法和系统</td>   <td>广东省</td>   <td>CN117112915A</td>   <td>2023-11-24</td>   <td>本发明公开了一种基于用户特征及大数据训练的智能设计方法和系统,包括：获取用户的交互信息生成用户的特征信息,结合基础信息生成用户信息；获取用户对目标工艺品的目标创作信息,进行预处理及格式化处理,结合用户信息确定用户需求信息；基于深度学习方法构建工艺品智能创作模型,基于用户需求信息进行目标工艺品的三维信息构建；将目标工艺品的三维信息反馈至用户,获取用户的对三维信息的交互信息进行用户需求信息的修正,更新目标工艺品的三维信息,并利用修正后的用户需求信息丰富用户特征。本发明通过用户的偏好及协同推荐特征等构建用户特征,提升工艺品设计的智能化程度,实现用户的专属化工艺品创作设计,提高了用户体验。</td>   <td>1.一种基于用户特征及大数据训练的智能设计方法,其特征在于,包括以下步骤：获取用户的交互信息,根据所述交互信息生成用户的特征信息,基于所述特征信息及基础信息生成用户信息；获取用户对目标工艺品的目标创作信息,将所述目标创作信息进行预处理及格式化处理,结合用户信息确定用户需求信息；基于深度学习方法构建工艺品智能创作模型,通过大数据手段进行训练,通过所述工艺品智能创作模型基于所述用户需求信息进行目标工艺品的三维信息构建；将目标工艺品的三维信息反馈至用户,获取用户的对三维信息的交互信息进行所述用户需求信息的修正,更新目标工艺品的三维信息,并利用修正后的用户需求信息丰富用户特征。</td>   <td>G06F16/9535;G06N3/0464;G06T17/00;G06T19/20;G06F16/9536</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              苏航;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>基于语义的知识产权文本表示与分类方法及终端设备</td>   <td>广东省</td>   <td>CN117112734A</td>   <td>2023-11-24</td>   <td>本申请适用于深度学习技术领域,提供了一种基于语义的知识产权文本表示与分类方法及终端设备,包括：基于外观专利数据库构建第一训练集；在采用第一训练集对外观专利分类模型进行训练的过程中,针对各条训练数据,通过外观专利分类模型确定外观专利的专利名称对应的文本特征编码、专利草图对应的图像特征编码、专利名称和专利草图对应的融合特征编码及训练数据对应的预测分类概率分布,并基于目标损失函数及每条训练数据对应的文本特征编码、图像特征编码、融合特征编码以及预测分类概率分布,对外观专利分类模型的模型参数进行调整；通过训练好的外观专利分类模型对外观专利申请文本进行分类,提高了外观专利分类的效率和准确性。</td>   <td>1.一种基于语义的知识产权文本表示与分类方法,其特征在于,包括：基于外观专利数据库构建第一训练集；所述第一训练集中的每条训练数据包括一个外观专利的专利名称、目标附图以及专利分类号；在采用所述第一训练集对外观专利分类模型进行训练的过程中,针对各条所述训练数据,通过所述外观专利分类模型确定所述训练数据中外观专利的专利名称对应的文本特征编码、专利草图对应的图像特征编码、专利名称和专利草图对应的融合特征编码以及所述训练数据对应的预测分类概率分布,并基于目标损失函数以及每条训练数据对应的所述文本特征编码、所述图像特征编码、所述融合特征编码以及所述预测分类概率分布,对所述外观专利分类模型的模型参数进行调整；所述专利草图基于所述目标附图生成；通过训练好的外观专利分类模型对待分类的外观专利申请文本进行分类。</td>   <td>G06F16/33;G06F16/35;G06F16/583;G06F16/532;G06F16/55;G06F18/25;G06F18/24;G06N3/0455;G06N3/0464;G06N3/08;G06F40/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              林芸晓;              王雨禾;              吴劲;              戴一凡;                   张充       </td>   <td>中山大学;广州搏创信息科技有限公司</td>   <td>一种基于海量知识图谱的深度学习问答方法、装置和系统</td>   <td>广东省</td>   <td>CN117112738A</td>   <td>2023-11-24</td>   <td>本发明公开了一种基于海量知识图谱的深度学习问答方法、装置和系统,通过对文本预处理后获得第一问题文本调用预设的命名实体识别模型进行深度学习识别处理获得第一实体和第一实体关系；通过预设的检索模型对第一实体和第一实体关系进行检索获得第一候选答案集,获得后对第一实体、第一实体关系和第一候选答案集进行迭代训练直到获得一个输出的答案文本作为第一答案文本进行输出和展示。本发明通过文本预处理、命名实体识别模型对用户输入的问题进行二次简化和明确,提高了获得第一实体和第一实体关系的准确性和效率,同时通过检索模型和循环迭代训练进一步提高了获得的答案文本与用户输入的问题文本的匹配度。</td>   <td>1.一种基于海量知识图谱的深度学习问答方法,其特征在于,包括以下步骤：接收并对第一待处理文本进行文本预处理,获得第一问题文本；调用预设的命名实体识别模型对所述第一问题文本进行深度学习识别处理,获得若干第一实体和所述第一实体一一对应的第一实体关系；通过预设的检索模型根据所述第一实体和所述第一实体关系在海量知识图谱中检索获得第一候选答案集；对所述第一实体、第一实体关系和所述第一候选答案集进行迭代训练直到输出一个答案文本,将输出的答案文本作为第一答案文本输出并展示。</td>   <td>G06F16/332;G06F16/36;G06F16/35;G06F18/214;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王勇;              晏靖明;              梁俊涛;              陈豫广;              张清瑞;              朱波;                   胡天江       </td>   <td>中山大学</td>   <td>一种基于视觉的仿生扑翼无人机空间位姿估计方法</td>   <td>广东省</td>   <td>CN117115252A</td>   <td>2023-11-24</td>   <td>本发明公开了一种基于视觉的仿生扑翼无人机空间位姿估计方法,如下：获取图像训练数据集；使用深度学习检测算法对图像训练数据集及标注信息进行训练；获取图像采集装置的内外参信息,获取仿生扑翼无人机飞行图像；根据深度学习检测算法对仿生扑翼无人机飞行图像进行测试,得到关键点图像坐标系测试结果和仿生扑翼无人机的翼型状态；测量不同翼型状态下仿生扑翼无人机坐标系关键点的三维坐标及翼型状态；通过解算得到仿生扑翼无人机的空间位置和姿态结果。本发明根据不同飞行姿态进行翼型状态标注定义,深度学习训练检测后进行解算,得到空间位置和姿态,解决由于无人机的结构复杂、翼型状态多样,通过外部图像难以求解其空间位姿的问题。</td>   <td>1.一种基于视觉的仿生扑翼无人机空间位姿估计方法,其特征在于：所述方法包括步骤如下：对获取仿生扑翼无人机图像进行标注,标注内容包括仿生扑翼无人机的图像坐标关键点和翼型状态信息,得到仿生扑翼无人机图像训练数据集；使用深度学习检测算法对仿生扑翼无人机图像训练数据集及标注信息进行训练,得到训练权重,更新深度学习检测算法,得到训练好的深度学习检测算法；对图像采集装置进行内外参标定,得到图像采集装置的内外参信息,并通过图像采集装置获取仿生扑翼无人机飞行图像；根据训练好的深度学习检测算法对仿生扑翼无人机飞行图像进行测试,得到关键点图像坐标系测试结果和仿生扑翼无人机的翼型状态；按照翼型状态分类,测量不同翼型状态下仿生扑翼无人机自身机体坐标系关键点的三维坐标信息,并记录翼型状态；根据图像采集装置的内外参信息、关键点图像坐标系测试结果、仿生扑翼无人机的翼型状态,和不同翼型状态下仿生扑翼无人机自身机体坐标系关键点的三维坐标信息,使用空间位置姿态估计算法进行解算,得到仿生扑翼无人机的空间位置和姿态结果。</td>   <td>G06T7/73;G06T7/80;G06V10/774;G06V10/764;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              麦剑霆;              陈胜朋;              汪炜;              欧阳婧璇;                   张小虎       </td>   <td>中山大学</td>   <td>基于YOLO的类圆柱目标位姿估计方法、装置和设备</td>   <td>广东省</td>   <td>CN117115260A</td>   <td>2023-11-24</td>   <td>本申请涉及一种基于YOLO的类圆柱目标位姿估计方法、装置、计算机设备和存储介质。所述方法包括：通过类圆柱目标的训练图像集训练基于YOLO的目标检测网络,用于得到待检测类圆柱目标的目标检测框,根据目标检测框进行图像裁剪,再通过基于弧段邻接矩阵的快速椭圆检测算法对类圆柱目标进行椭圆检测,得到两组椭圆信息,通过EPnP算法求解得到类圆柱目标的位姿信息。本发明在目标部分被遮挡、复杂背景的情况下均可以实现准确的椭圆检测,从而进行类圆柱目标的位姿估计,检测精度更高,鲁棒性更强。</td>   <td>1.一种基于YOLO的类圆柱目标位姿估计方法,其特征在于,所述方法包括：构建待检测的类圆柱目标的训练图像集；所述训练图像集中包括所述类圆柱目标的多种位姿的目标图像；所述目标图像上标注了所述类圆柱目标的目标检测框；所述类圆柱目标具有两个圆环特征；通过所述训练图像集对基于YOLO的目标检测网络进行训练,得到训练好的目标检测网络；获取待检测的类圆柱目标的图像,将所述待检测的类圆柱目标的图像输入所述训练好的目标检测网络中,得到对应的目标检测框,根据所述目标检测框对所述待检测的类圆柱目标的图像中的类圆柱目标进行裁剪,得到裁剪后图像；根据所述裁剪后图像,通过基于弧段邻接矩阵的快速椭圆检测算法对所述类圆柱目标进行椭圆检测,得到两组椭圆信息；根据所述两组椭圆信息,通过EPnP算法求解得到所述类圆柱目标的位姿信息。</td>   <td>G06T7/73;G06T17/10;G06T7/80;G06V10/26;G06V10/77;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              欧阳婧璇;              甘叔玮;              谢文韬;                   张小虎       </td>   <td>中山大学</td>   <td>基于单目的3D舱外航天服姿态估计方法</td>   <td>广东省</td>   <td>CN117115594A</td>   <td>2023-11-24</td>   <td>本发明公开了一种基于单目的3D舱外航天服姿态估计方法,包括：构建训练数据集构建姿态估计模型,包括生成器网络和鉴别器网络,生成器网络基于输入的2D Pose生成3DPose,并输出姿态估计结果以及相机位姿估计结果；鉴别器网络用于鉴别输入的3D Pose为真实的3D Pose或生成的3D Pose；构建总损失函数,总损失函数由2D-3D重投影误差损失函数、相机位姿矩阵损失函数以及鉴别器损失函数加权得到；再基于训练后的姿态估计模型得到姿态估计结果。本发明应用于姿态估计技术领域,可在舱外航天服地面试验中,提供更加有效和高效的运动捕捉,有效地降低了试验成本。</td>   <td>1.一种基于单目的3D舱外航天服姿态估计方法,其特征在于,包括如下步骤：步骤1,构建训练数据集,包括：采集若干2D Pose与若干3D Pose,其中,所述2D Pose与所述3D Pose一一对应；和/或采集若干单目彩色图像,并基于所述单目彩色图像得到对应的2D Pose与3D Pose；步骤2,模型构建：构建姿态估计模型,所述姿态估计模型包括生成器网络和鉴别器网络,其中：所述生成器网络基于输入的2D Pose生成3D Pose,并输出相机位姿估计结果；所述鉴别器网络用于鉴别输入的3D Pose为真实的3D Pose或所述生成器网络生成的3D Pose；步骤3,模型训练：构建总损失函数,所述总损失函数由针对所述生成器网络的2D-3D重投影误差损失函数、相机位姿矩阵损失函数以及针对所述鉴别器网络的鉴别器损失函数加权得到,并基于所述总损失函数与所述训练数据集训练所述姿态估计模型；步骤4,姿态估计：将采集的航天服2D Pose输入训练后的所述姿态估计模型,并输出所述生成器网络所生成3D Pose的姿态估计结果；或基于采集的航天服的单目彩色图像得到对应的2D Pose,并将得到的2D Pose输入训练后的所述姿态估计模型,并输出所述生成器网络所生成3D Pose的姿态估计结果。</td>   <td>G06V10/774;G06V20/64;G06V10/82;G06V10/40;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘洁琼;              孙志贤;              余运芳;              赵健丽;              袁中玉;                   林颖       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种基于CT影像组学的晚期乳腺癌治疗疗效预测方法、装置及设备</td>   <td>广东省</td>   <td>CN117115615A</td>   <td>2023-11-24</td>   <td>本申请提供晚期乳腺癌免疫治疗疗效预测方法,包括：获取增强CT图像(以下简称CT图像)；根据二维直径的内脏转移、胸壁转移、骨转移性软组织或淋巴转移中的病变,分割患者所述CT图像中的感兴趣体积(VOI)；采用pyradiomics提取所述CT图像的影像组学特征；利用深度学习的多层感知器算法对特征进行数据降维、特征选择和模型构建,包括在输入层中输入影像组学特征,通过隐藏层的神经网络构建影像组学模型,输出层输出晚期三阴性乳腺癌免疫治疗预测的结局指标。本申请晚期乳腺癌免疫联合治疗患者多VOI勾画,基于CT影像组学的分类算法,利用深度学习算法构建精准的预测模型,通过在独立的验证集中开展预测模型验证及性能评估,极大的提高了预测准确性。</td>   <td>1.一种基于CT影像组学的晚期乳腺癌治疗疗效预测方法,其特征在于,包括：获取免疫联合治疗前预设时间段的CT图像；基于所述CT图像,根据二维直径的内脏转移、胸壁转移、骨转移性软组织或淋巴转移中的病变,选取两个二维直径最大的病变,分割患者所述CT图像中的感兴趣体积；提取所述CT图像中感兴趣体积的影像组学特征,包括：强度特征、形状特征、纹理特征和图像滤波特征；利用深度学习中的多层感知器算法对影像组学特征数据进行降维、特征选择和模型构建,包括在输入层中输入影像组学特征,通过隐藏层的神经网络构建影像组学模型,输出层输出晚期三阴性乳腺癌免疫治疗预测的结局指标。</td>   <td>G06V10/82;G06V10/77;G06V10/771;G06V10/764;G06V10/776;G06V10/40;G06V10/54;G06V10/422;G06V10/26;G06V10/25;G16H30/40;G16H30/20;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘强;              刘颖;                   马艺涛       </td>   <td>中山大学</td>   <td>基于CT扫描图像的纤维增强复合材料微观有限元建模方法</td>   <td>广东省</td>   <td>CN112329300B</td>   <td>2023-11-21</td>   <td>本发明属于纤维增强复合材料有限元仿真领域,其公开了一种基于CT扫描图像的纤维增强复合材料的微观有限元建模方法,包括对纤维增强复合材料标准拉伸样件拉伸断面进行电镜扫描,对电镜扫描图像进行图像处理,统计多处局部扫描图像纤维拔出孔的面积,计算平均纤维直径数据,在拉伸试样中心切割部分试样进行X射线CT断层扫描,对CT扫描图像进行过滤处理,将过滤图像导入Mimics软件中,初步重建纤维,将粘连纤维分开以获得较好拟合中心线,在Creo中拉伸重建纤维几何,在HyperMesh中重建基质几何,划分网格,在ABAQUS软件中施加一般性周期性边界条件,施加所需工况,提交计算。本发明生成的有限元模型真实反映了纤维增强复合材料中纤维的分布情况,具有高保真的优点。</td>   <td>1.一种基于CT扫描图像的纤维增强复合材料微观有限元建模方法,其特征在于,通过以下具体步骤予以实现：步骤1-1：对纤维增强复合材料标准拉伸样件拉伸断面进行电镜扫描,获得电镜扫描图像；步骤1-2：使用CT设备对步骤1-1所述标准拉伸样件的中心切割部分试样进行X射线CT断层扫描,获得CT扫描图像；步骤2-1：选取步骤1-1所述电镜扫描图像中若干局部区域的电镜扫描图像,在ImageJ软件中调整图像阈值,使用Brush工具清除图像中无关信息和错误信息；步骤2-2：使用ImageJ软件中Analyze Particles功能统计步骤2-1所述图像中的纤维拔出孔面积,经过下式计算得到平均纤维直径：                  上式中Φ为单根纤维直径,I为扫描图像比例尺,S为纤维截面积；步骤3-1：对步骤1-2所述CT扫描图像进行过滤处理,获得过滤图像；步骤3-2：将步骤3-1所述过滤图像截取所需的区域图像导入Mimics软件中,初步重建纤维,使用区域增长功能将其中粘连的纤维分开,拟合获得准确的纤维中心线,并将纤维中心线三维模型保存为IGS格式文件；步骤4-1：将步骤3-2所述纤维中心线三维模型IGS格式文件导入Creo软件中,通过增材拉伸功能重建纤维几何,纤维直径为步骤2-2所述平均纤维直径,将纤维三维几何模型保存为prt文件；步骤4-2：将步骤4-1所述prt文件导入HyperMesh软件中,建立步骤3-2所述区域图像的基体几何模型,并使用布尔运算切除基体内部纤维与基体重合部分,完成代表性体积元几何模型的建立；步骤5-1：定义材料属性、网格类型、网格尺寸,为步骤4-2所述代表性体积元几何模型划分网格；步骤5-2：定义纤维与基体接触类型,在代表性体积元表面施加一般性周期性边界条件；步骤6：定义代表性体积元力学性能分析工况；步骤7：在ABAQUS软件中提交计算。</td>   <td>G06F30/23;G06T7/11;G06T7/136;G06T7/62;G06T17/20;G06F113/26;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              杨浩锴;              王雅琦;                   韦骏       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>基于区块链和联邦学习的海洋数据共享方法、系统及介质</td>   <td>广东省</td>   <td>CN114493594B</td>   <td>2023-11-21</td>   <td>本发明公开了基于区块链和联邦学习的海洋数据共享方法、系统及介质,方法包括：根据数据共享及权项分配机制搭建区块链网络；将数据共享及权项分配机制转变为智能合约；响应于数据使用方的联邦学习请求,在区块链网络进行学习检索；根据学习检索的结果,发送检索数据至数据使用方；根据检索数据,确定数据提供方；根据智能合约,在数据使用方和数据提供方之间建立支链；根据支链,数据提供方从数据使用方获取训练模型进行全局模型训练；根据智能合约结合所述全局模型训练的结果,进行参数聚合处理得到全局模型参数。本发明能够解决海洋数据分散、统一协调性差等问题,进而实现对基于区块链和联邦学习的海洋数据共享,可广泛应用于区块链技术领域。</td>   <td>1.一种基于区块链和联邦学习的海洋数据共享方法,其特征在于,包括：根据数据共享及权项分配机制搭建区块链网络；将所述数据共享及权项分配机制转变为智能合约；根据所述智能合约确定数据提供方与数据使用方的区块链权限；响应于数据使用方的联邦学习请求,在所述区块链网络进行学习检索；根据所述区块链权限,结合所述学习检索的结果发送检索数据至所述数据使用方；根据所述检索数据,确定数据提供方；根据所述智能合约,在所述数据使用方和所述数据提供方之间建立支链；根据所述支链,所述数据提供方从所述数据使用方获取训练模型进行全局模型训练；根据所述智能合约结合所述全局模型训练的结果,进行参数聚合处理得到全局模型参数；其中,所述方法还包括：根据所述智能合约,记录联邦学习数据,所述联邦学习数据包括历史学习数据、模型数据、模型参数数据、学习摘要数据和用户权限数据；根据所述联邦学习数据,进行虚拟现实交互处理。</td>   <td>G06Q20/38;G06Q20/40;G06N3/0442;G06N3/098;H04L67/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              林格;              陈小燕;              苏卓;                   汤武惊       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>基于小样本的自适应缺陷检测方法及终端设备</td>   <td>广东省</td>   <td>CN117094986A</td>   <td>2023-11-21</td>   <td>本申请适用于缺陷检测技术领域,提供了一种基于小样本的自适应缺陷检测方法及终端设备,方法包括：为正常样本图像集中的每张正常电池图像分别添加一个掩码区域,将添加了掩码区域的正常电池图像确定为掩码图像,并记录每张掩码图像中的掩码区域的位置信息和尺寸信息；通过训练好的缺陷图像生成模型分别对各张掩码图像进行处理,得到各张掩码图像分别对应的预测缺陷图像；基于所有预测缺陷图像以及对应的掩码图像中的掩码区域的位置信息和尺寸信息,生成第一训练集,并通过第一训练集对缺陷检测模型进行训练；通过训练好的缺陷检测模型对待检测电池图像进行缺陷检测,能够提高小样本情况下缺陷检测模型的缺陷检测准确度。</td>   <td>1.一种基于小样本的自适应缺陷检测方法,其特征在于,包括：为正常样本图像集中的每张正常电池图像分别添加一个掩码区域,将添加了掩码区域的所述正常电池图像确定为掩码图像,并记录每张所述掩码图像中的掩码区域的位置信息和尺寸信息；通过训练好的缺陷图像生成模型分别对各张所述掩码图像进行处理,得到各张所述掩码图像分别对应的预测缺陷图像；所述缺陷图像生成模型包括n个级联的缺陷预测网络；每一级所述缺陷预测网络均包括一个缺陷判别模块和一个缺陷生成模块；每一级缺陷预测网络中的缺陷判别模块用于对上一级缺陷预测网络输出的上一级预测缺陷图像进行缺陷判别,并提取所述上一级预测缺陷图像中的掩码区域的梯度信息,且向本级缺陷预测网络中的缺陷生成模块发送所述缺陷判别结果和所述梯度信息；每一级缺陷预测网络中的缺陷生成模块用于基于所述判别结果、所述上一级预测缺陷图像以及所述梯度信息,生成本级预测缺陷图像,并向下一级缺陷预测网络发送所述本级预测缺陷图像；基于所有所述掩码图像对应的预测缺陷图像以及所有所述掩码图像中的掩码区域的位置信息和尺寸信息,生成第一训练集,并通过所述第一训练集对缺陷检测模型进行训练；通过训练好的缺陷检测模型对待检测电池图像进行缺陷检测。</td>   <td>G06T7/00;G06V10/22;G06V10/82;G06V10/774;G06N3/045;G06N3/082;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              林格;              陈小燕;              苏卓;                   汤武惊       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>一种在线协同的工业视觉检测方法及终端设备</td>   <td>广东省</td>   <td>CN117095273A</td>   <td>2023-11-21</td>   <td>本申请实施例适用于计算机技术领域,提供了一种在线协同的工业视觉检测方法及终端设备,应用于任一计算节点,每个所述计算节点对应一个图像组别；所述方法包括：将服务器发送的关于所述图像组别的待检测图像输入至预设的工业视觉检测模型,生成关于所述待检测图像的安全检测结果；待检测图像是所述任一计算节点对应的所述图像组别中的图像；将安全检测结果发送至所述服务器,并接收所述服务器反馈的工业检测结果；工业检测结果由所述服务器基于N个计算节点发送的安全检测结果生成；工业检测结果用于确定所有所述工业图像中的待检测物体是否符合所述工业安全指标。通过本实施例提供的方法,可以提高工业视觉检测的效率。</td>   <td>1.一种在线协同的工业视觉检测方法,其特征在于,应用于任一计算节点,每个所述计算节点对应一个图像组别；所述工业视觉检测方法包括：将服务器发送的关于所述图像组别的待检测图像输入至预设的工业视觉检测模型,生成关于所述待检测图像的安全检测结果；所述安全检测结果用于确定所述待检测图像中的待检测物体是否符合预设的工业安全指标；所述待检测图像是所述任一计算节点对应的所述图像组别中的图像；所述图像组别是所述服务器对采集设备发送的多个工业图像进行分组得到的；将所述安全检测结果发送至所述服务器,并接收所述服务器反馈的工业检测结果；所述工业检测结果由所述服务器基于N个计算节点发送的安全检测结果生成；所述N为大于或等于2的正整数；所述工业检测结果用于确定所有所述工业图像中的待检测物体是否符合所述工业安全指标。</td>   <td>G06V10/96;G06V10/94;G06V20/50;G06V10/82;G06V20/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         莫康晓;                   戴宪华       </td>   <td>中山大学</td>   <td>一种基于改进Swin-Transformer的农作物病害检测方法及系统</td>   <td>广东省</td>   <td>CN117095285A</td>   <td>2023-11-21</td>   <td>本发明公开了一种基于改进Swin-Transformer的农作物病害检测方法及系统,该方法包括：获取农作物病害叶子图像作为数据集并将其划分为训练集和测试集；对训练集和测试集进行数据增强,得到预处理训练集和预处理测试集；基于预处理训练集对改进的Swin-Transformer网络结构进行训练,得到测试模型；将预处理测试集输入到测试模型中,得到农作物病害图像检测结果。该系统包括：图像分割模块、位置信息嵌入模块、特征提取模块、特征融合模块和特征映射模块。通过使用本发明能够有效提取农作物病害叶子特殊特征,实现对农作物病害高效诊断。本发明可广泛应用于深度学习技术领域。</td>   <td>1.一种基于改进Swin-Transformer的农作物病害检测方法,其特征在于,包括以下步骤：获取农作物病害叶子图像作为数据集并将其划分为训练集和测试集；对训练集和测试集进行数据增强,得到预处理训练集和预处理测试集；基于预处理训练集对改进的Swin-Transformer网络结构进行训练,得到测试模型；将预处理测试集输入到测试模型中,得到农作物病害图像检测结果。</td>   <td>G06V20/10;G06V10/82;G06V10/80;G06N3/0455;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;              席祖平;              盛紫琦;                   瞿左珉       </td>   <td>中山大学</td>   <td>基于特征增强的文档图像篡改检测与定位方法及装置</td>   <td>广东省</td>   <td>CN117095396A</td>   <td>2023-11-21</td>   <td>本发明公开一种基于特征增强的文档图像篡改检测与定位方法及装置,方法为：对文档图像进行滑动窗口分块预处理；对滑动窗口分块预处理后训练集中文档图像二次篡改和后处理操作,设置对应的掩膜图的篡改区域,得到数据增强后的图像；从多角度进行增强篡改痕迹特征,获得特征增强图；使用Swin Transformer V2Block构成模型的编码器、解码器,得出预测结果,计算损失并反向传播训练模型；将测试集输入训练好的文档图像篡改检测与定位模型,定位篡改区域。本发明设计了一种构建文档图像篡改检测与定位模型,能够提升生文档图像篡改检测与定位能力,从而避免现有的取证技术在文档图像篡改检测准确率不高、定位能力不足等问题。</td>   <td>1.基于特征增强的文档图像篡改检测与定位方法,其特征在于,包括以下步骤：将文档图像进行滑动窗口分块预处理；对滑动窗口分块预处理后训练集中文档图像进行二次篡改和后处理操作,并设置对应的掩膜图的篡改区域,得到数据增强后的图像；所述二次篡改包括复制粘贴、拼接及修复；所述后处理操作用于对文档图像进行压缩、参数调节及噪声处理；构建文档图像篡改检测与定位模型,将数据增强后的图像中篡改痕迹特征从多角度进行增强处理,获得特征增强图；具体为,使用卷积层增强RGB空间的篡改痕迹特征；使用约束卷积层自适应学习浅层篡改痕迹特征；使用Pre-Filtering层获取图像的残差；使用通道连接方法融合卷积层、约束卷积层、Pre-Filtering层得到低层篡改痕迹特征,对低层篡改痕迹特征进行卷积并归一化,获得特征增强图；所述文档图像篡改检测与定位模型包括利用Transformer V2 Block改进而成的Swin-Unet；使用Swin Transformer V2 Block构成模型的编码器、解码器,并利用特征增强图得出预测结果；对预测结果进行softmax操作,计算真实结果与预测结果的损失后进行反向传播训练文档图像篡改检测与定位模型；利用训练好的文档图像篡改检测与定位模型对待检测的文档图像的篡改区域进行检测和定位。</td>   <td>G06V30/14;G06V30/41;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄雨鑫;              袁艺玮;              谢凌;              曾祥宇;                   赵宝全       </td>   <td>中山大学</td>   <td>一种数字人重建运动评分方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN117095457A</td>   <td>2023-11-21</td>   <td>本发明提供了一种数字人重建运动评分方法、系统、设备及介质,所述方法包括：根据目标检测算法分别从用户视频和标准视频中获取用户骨架关键点和标准骨架关键点,所述用户视频为用户运动姿态视频,所述标准视频为标准运动姿态视频；分别计算用户骨架关键点连线的第一夹角和标准骨架关键点连线的第二夹角,根据所述第一夹角和所述第二夹角之间的差值计算各关键点分数；将所述各关键点分数与各关键点对应的预设权重相乘并求和得到运动总评分。本发明能够对用户各个身体部位运动情况进行精细的评价。</td>   <td>1.一种数字人重建运动评分方法,其特征在于,所述方法包括：根据目标检测算法分别从用户视频和标准视频中获取用户骨架关键点和标准骨架关键点,所述用户视频为用户运动姿态视频,所述标准视频为标准运动姿态视频；分别计算用户骨架关键点连线的第一夹角和标准骨架关键点连线的第二夹角,根据所述第一夹角和所述第二夹角之间的差值计算各关键点分数；将所述各关键点分数与各关键点对应的预设权重相乘并求和得到运动总评分。</td>   <td>G06V40/20;G06V20/40;G06V40/16;G06V10/44;G06V10/75;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>              沈颖       </td>   <td>中山大学</td>   <td>一种跨域问答迁移方法及其系统</td>   <td>广东省</td>   <td>CN117076421A</td>   <td>2023-11-17</td>   <td>本发明提供一种跨域问答迁移方法及其系统。该跨域问答迁移方法包括：获取与目标域模型对应的源域模型；利用问题生成模型生成模拟目标域数据；利用模拟目标域数据对源域模型进行更新；冻结经过更新的源域模型中答案分类器的所有参数,将所有参数被冻结的答案分类器和源域模型中的特征提取器作为目标域模型的答案分类器和初始的特征提取器,以得到初始的目标域模型；通过最小化目标域模型的联合损失函数对初始的目标域模型进行联合训练而得到训练好的目标域模型,进而完成从源域到目标域的迁移学习。该方法及其系统能够在保护源域数据的隐私的前提下,完成知识由源域向目标域的迁移过程,提高目标域模型进行知识迁移的能力。</td>   <td>1.一种跨域问答迁移方法,其特征在于,包括：获取与目标域模型对应的源域模型；其中,所述源域模型是基于源域数据训练得到的；利用问题生成模型生成模拟目标域数据；其中,所述模拟目标域数据用于训练所述目标域模型,所述模拟目标域数据包括：目标域上下文、与所述目标域上下文对应的模拟问题和与所述模拟问题对应的模拟生成答案；利用所述模拟目标域数据对所述源域模型进行更新；冻结经过所述更新的源域模型中答案分类器的所有参数,将所述所有参数被冻结的答案分类器和所述源域模型中的特征提取器作为所述目标域模型的答案分类器和初始的特征提取器,以得到初始的所述目标域模型；通过最小化所述目标域模型的联合损失函数对所述初始的目标域模型进行联合训练而得到所述训练好的目标域模型,进而完成从所述源域到所述目标域的迁移学习。</td>   <td>G06F16/21;G06F16/35;G06F16/332</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭应林;              刘懿梅;              陈美宁;              张俊;              祁振宇;                   邓小武       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于CBCT图像的快速三维剂量验证方法及装置</td>   <td>广东省</td>   <td>CN117078612A</td>   <td>2023-11-17</td>   <td>本申请属于医学影像技术领域,公开了一种基于CBCT图像的快速三维剂量验证方法及装置,该方法包括：步骤S1,获取待分析CBCT图像和计划CT图像；步骤S2,基于训练好的图像转换网络将待分析CBCT图像转换成伪CT图像；步骤S3,将计划CT图像形变配准至伪CT图像；步骤S4,采用智能分割模型对伪CT图像进行智能勾画,得到器官结构图像；步骤S5,对伪CT图像进行剂量计算,得到剂量分布结果；步骤S6,基于剂量分布结果和器官结构图像进行剂量体积图分析。本申请能够实现了针对CBCT图像的快速三维剂量验证。</td>   <td>1.一种基于CBCT图像的快速三维剂量验证方法,其特征在于,所述方法包括：步骤S1,获取待分析CBCT图像和计划CT图像；步骤S2,基于训练好的图像转换网络将所述待分析CBCT图像转换成伪CT图像；步骤S3,将所述计划CT图像形变配准至所述伪CT图像；步骤S4,采用智能分割模型对所述伪CT图像进行智能勾画,得到器官结构图像；步骤S5,对所述伪CT图像进行剂量计算,得到剂量分布结果；步骤S6,基于所述剂量分布结果和所述器官结构图像进行剂量体积图分析。</td>   <td>G06T7/00;G06T7/11;G06T7/62;G06V10/774;G06V10/82;A61N5/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高峰;              王烽傲;              刘俊伟;              胡楚凌;              蔡都;              吴小剑;                   李亦学       </td>   <td>中山大学附属第六医院</td>   <td>一种结直肠癌的预后风险预测系统</td>   <td>广东省</td>   <td>CN117079801A</td>   <td>2023-11-17</td>   <td>本发明公开了一种结直肠癌的预后风险预测系统,所述系统包括：图像获取模块以及预测模块；所述图像获取模块,用于获取待预测病人的CT图像,并将所述CT图像输入至预测模块；所述预测模块,用于在未检测到与CT图像配对的基因组学数据时,将所述CT图像输入一预设的CRC预后预测模型,以使所述CRC预后预测模型,根据所述CT图像特征对待预测病人的基因组学特征进行推断,生成待预测病人的预测基因组学特征,继而根据所述CT图像特征和预测基因组学特征,对待预测病人的预后风险进行预测,得到待预测病人的预后风险预测结果。通过本发明可以根据单CT图像来对待预测病人的预后风险进行预测。</td>   <td>1.一种结直肠癌的预后风险预测系统,其特征在于,包括：图像获取模块以及预测模块；所述图像获取模块,用于获取待预测病人的CT图像,并将所述CT图像输入至预测模块；所述预测模块,用于在未检测到与CT图像配对的基因组学数据时,将所述CT图像输入一预设的CRC预后预测模型,以使所述CRC预后预测模型对待预测病人的预后风险进行预测,得到待预测病人的预后风险预测结果；其中,所述CRC预后预测模型包括：CT图像特征提取单元、模态交互推断单元以及融合预测单元；所述CT图像特征提取单元,用于接收待预测病人的CT图像,提取所述CT图像的特征,并在未检测到与CT图像配对的基因组学数据时,将所提取的CT图像特征输入至模态交互推断单元；所述模态交互推断单元,用于在接收到CT图像特征之后,获取待预测病人的基因组学特征均值,根据所述基因组学特征均值以及所述CT图像特征,对待预测病人的基因组学特征进行推断,生成待预测病人的预测基因组学特征,并将所述CT图像特征和所述预测基因组学特征输入至融合预测单元；所述融合预测单元,用于在未检测到与CT图像配对的基因组学数据时,将所输入的CT图像特征和预测基因组学特征进行特征融合,并根据融合后的特征对待预测病人的预后风险进行预测,得到待预测病人的预后风险预测结果。</td>   <td>G16H50/20;G16B40/00;G06T7/00;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴维刚;                   肖汕斌       </td>   <td>中山大学</td>   <td>一种区块链支付通道网络交易手续费分配方法及系统</td>   <td>广东省</td>   <td>CN113763163B</td>   <td>2023-11-17</td>   <td>本发明提出一种区块链支付通道网络交易手续费分配方法及系统,解决了当前区块链链下支付通道交易中手续费分配方式不合理,不利于区块链网络交易效能提升的问题,首先确定交易的双方、交易路径及发送方需支付的手续费,在区块链链下建立支付通道,考虑支付通道路径节点的倾斜程度,基于HTLC合约,将资金按照对路径节点倾斜程度的利害进行分配,在给定支付通道交易的交易路径和手续费的情况下,合理地分配各个中间路径节点的手续费,从而吸引更多的路径节点加入,使整体网络更加健壮,达到提升区块链网络交易效能的目的。</td>   <td>1.一种区块链支付通道网络交易手续费分配方法,其特征在于,所述方法至少包括：S1.确定交易的发送方与接收方、发送方与接收方之间的交易路径节点、支付通道资金参数及原HTLC合约中路径节点之间的资金交易额度；S2.从发送方至接收方的方向,依次获取交易路径节点的倾斜程度；S3.根据交易路径节点的倾斜程度,由发送方计算每个中间路径节点的临时权重,根据临时权重计算总权重；S4.根据总权重,由发送方计算每个路径节点应获得的手续费；S5.在原HTLC合约中路径节点之间的资金交易额度上增加每个路径节点应获得的手续费,并按照HTLC交易流程完成交易,由接收方发送原像y至发送方；S6.以发送方至接收方的方向,依次发送以y为原像的HTLC合约至下一个路径节点,并设置资金交易额度；S7.从接收方至发送方的方向,依次接收HTLC合约,使用原像y完成HTLC合约交易；设交易的发送方为V-0,接收方为V-m,发送方与接收方之间的交易路径节点表示为P-i＝(V-0,V-1,V-2,V-3,...,V-(m-1),V-m)；交易路径节点之间生成支付通道,所述的支付通道资金参数包括：交易路径节点在支付通道上的资金及发送方提供的手续费,其中,交易路径节点在支付通道上的资金表示为C-i＝(C-0,C-1,C-2,C-3,...,C-(m-1),C'-m),发送方提供的手续费为Fee；原HTLC合约中交易路径节点之间的资金交易额度为：x-(0,1),x-(1,2),x-(2,3),x-(3,4),...,x-(m-1,m),其中,x-(m-1,m)表示交易路径节点V-(m-1)与交易路径节点V-m之间发生的资金交易额度；对于交易路径节点V-(m-1)与交易路径节点V-m而言,交易路径节点V-(m-1)与交易路径节点V-m之间的倾斜度分别表示为：                                    其中,C-(m-1,m)＝C-(m-1)+C-m；S-(m-1)表示交易路径节点V-(m-1)的倾斜度,记为S-m表示交易路径节点V-m的倾斜度,记作/&gt;C-(m-1)表示交易路径节点V-(m-1)在支付通道上的资金；C-m表示交易路径节点V-m在支付通道上的资金,S-(m-1)+S-m＝1；交易路径节点V-(m-1)与交易路径节点V-m之间发生x-(m-1,m)的资金交易后,倾斜程度分别表示为：                                    其中,表示交易路径节点V-(m-1)与交易路径节点V-m之间发生x-(m-1,m)的资金交易后交易路径节点V-(m-1)的倾斜度；/&gt;表示交易路径节点V-(m-1)与交易路径节点V-m之间发生x-(m-1,m)的资金交易后交易路径节点V-m的倾斜度；则基于及/&gt;的求解公式,步骤S2所述从发送方至接收方的方向,依次获取交易路径节点的倾斜程度表示为：                  步骤S3所述的每个中间路径节点的临时权重的计算过程为：设中间路径节点表示为：V-1,V-2,V-3,...,V-(n-1)1～m-1之间的第i个路径节点V-i在一笔交易中,在路径节点V-i与路径节点V-(i+1)之间的支付通道上的临时权重表达式为：                  其中,分别表示路径节点V-i的倾斜度、路径节点V-i与路径节点V-(i+1)之间发生x-(i,i+1)的资金交易后路径节点V-i的倾斜度；根据临时权重计算总权重的表达式为：                  其中,Power-i表示每个路径节点最终的权重；步骤S4所述根据总权重,由发送方计算每个路径节点应获得的手续费的表达式为：                  其中,Fee表示发送方提供的手续费；Fee-i表示0～m之间的第i个路径节点V-i应获得的手续费。</td>   <td>G06Q40/04;G06Q20/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         庄浩铭;                   刘小平       </td>   <td>中山大学</td>   <td>一种长时期网格人口分布构建方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN117076588A</td>   <td>2023-11-17</td>   <td>本发明提供了一种长时期网格人口分布构建方法、系统、设备及介质,所述方法包括：获取初始城市用地分布数据集、初始人口分布数据集和驱动因子数据集,根据所述初始城市用地分布数据集建立并训练城市用地分布模型,将所述驱动因子数据集输入训练后的城市用地分布模型,得到城市用地发展适宜性数据；将所述城市用地发展适宜性数据和所述初始城市用地分布数据集输入FLUS模型,构建城市用地分布；根据所述初始人口分布数据集和初始城市用地分布数据集建立并训练人口分布模型,将所述城市用地分布和所述初始人口分布数据集输入训练后的人口分布模型,构建长时期网格人口分布。本发明能够有效提升网格人口分布制图的精度。</td>   <td>1.一种长时期网格人口分布构建方法,其特征在于,所述方法包括：获取初始城市用地分布数据集、初始人口分布数据集和驱动因子数据集,所述驱动因子数据集包括高程、坡度、到河流的距离、到城市中心的距离和到主要道路的距离；根据所述初始城市用地分布数据集建立并训练城市用地分布模型,将所述驱动因子数据集输入训练后的城市用地分布模型,得到城市用地发展适宜性数据；将所述城市用地发展适宜性数据和所述初始城市用地分布数据集输入FLUS模型,构建城市用地分布；根据所述初始人口分布数据集和初始城市用地分布数据集建立并训练人口分布模型,将所述城市用地分布和所述初始人口分布数据集输入训练后的人口分布模型,构建长时期网格人口分布。</td>   <td>G06F16/29;G06F18/214;G06F18/243</td>  </tr>        <tr>   <td>中国专利</td>   <td>         方成;              王玮;                   周志伟       </td>   <td>中山大学</td>   <td>一种用于精准预测胃肠胰神经内分泌肿瘤患者预后的系统</td>   <td>广东省</td>   <td>CN110021433B</td>   <td>2023-11-17</td>   <td>本发明提供了一种用于精准预测胃肠胰神经内分泌肿瘤患者预后的系统,该系统基于本发明构建的Nomogram预后预测模型,相比传统的TNM分期系统,该系统具有精确度高、个体化预测,并具备符合胃肠胰神经内分泌肿瘤预后预测特点。同时,该系统对于临床工作中患者个体化治疗策略的选择、新药临床试验的设计和规范入组患者的一致性具有很好的指导作用。</td>   <td>1.一种用于精准预测胃肠胰神经内分泌肿瘤患者预后的系统,其特征在于,包括：数据输入模块,用于将胃肠胰神经内分泌肿瘤患者的年龄、肿瘤大小、肿瘤部位、肿瘤分级、N分期和M分期的检测结果输入模型计算模块；模型计算模块,包括3年生存概率模型、5年生存概率模型中的至少一种；所述3年生存概率模型用于根据胃肠胰神经内分泌肿瘤患者points得分数值以及3年生存概率模型计算胃肠胰神经内分泌肿瘤患者3年生存概率,所述3年生存概率模型包括3年生存概率公式,3年生存概率公式：3年生存概率＝1.16e-07*points～3-7.1956e-05*points～2+0.009526105*points+0.538865987；所述5年生存概率模型,用于根据胃肠胰神经内分泌肿瘤患者points得分数值以及5年生存概率模型计算胃肠胰神经内分泌肿瘤患者5年生存概率,所述5年生存概率模型包括5年生存概率公式,5年生存概率公式：5年生存概率＝1.16e-07*points～3-6.4312e-05*points～2+0.006525254*points+0.714986048；其中,所述胃肠胰神经内分泌肿瘤患者points＝年龄得分+肿瘤大小得分+肿瘤部位得分+肿瘤分级得分+N分期得分+M分期得分；所述年龄得分的规则：年龄≤50＝0分,年龄&gt;50＝24.451分；所述肿瘤大小得分的规则：肿瘤大小&lt;2cm＝0分,肿瘤大小为2～4cm＝17.979分,肿瘤大小&gt;4cm＝47.816分；肿瘤部位得分的规则：直肠＝0分,阑尾＝15.298分,小肠＝20.625分,胰腺＝24.302分,胃＝24.436分,结肠＝55.515分；肿瘤分级得分的规则：高/中分化＝0分,低分化＝100分；N分期得分的规则：N0＝0分,N1＝36.078分；M分期得分的规则：M0＝0分,M1＝69.143分；结果输出模块,用于根据胃肠胰神经内分泌肿瘤患者3年生存概率结果、5年生存概率结果中的至少一种来判定胃肠胰神经内分泌肿瘤患者预后情况；胃肠胰神经内分泌肿瘤患者的生存概率越高,则提示该胃肠胰神经内分泌肿瘤患者预后良好、生存期长的可能性越大。</td>   <td>G16H50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王波;              雷雅钦;                   符曼       </td>   <td>中山大学</td>   <td>一种城市活力综合测度方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN117078096A</td>   <td>2023-11-17</td>   <td>本发明提供了一种城市活力综合测度方法、系统、设备及介质,所述方法包括：获取多维度城市数据,多维度城市数据包括城市出行、社交和商业数据；城市出行数据包括热力地图数据,城市社交数据包括社交软件签到数据,城市商业数据包括店铺数量数据；根据热力地图数据计算对应的热力指数,并以热力指数表征城市出行活力强度；根据社交软件签到数据表征城市社交活力强度,根据店铺数量数据表征城市商业活力强度；根据城市全域的城市出行、社交和商业活力强度分别计算城市出行、社交和商业活力稳定度；采用因子分析法得到城市综合活力强度和稳定度并进行叠置分析,得到城市活力分布。本发明能够更全面地测度城市活力,提高了城市活力测度的真实性。</td>   <td>1.一种城市活力综合测度方法,其特征在于,所述方法包括：获取多维度城市数据,所述多维度城市数据包括城市出行数据、城市社交数据和城市商业数据；所述城市出行数据包括热力地图数据,所述城市社交数据包括社交软件签到数据,所述城市商业数据包括店铺数量数据；根据所述热力地图数据计算对应的热力指数,并以所述热力指数表征城市出行活力强度；根据所述社交软件签到数据表征城市社交活力强度,根据所述店铺数量数据表征城市商业活力强度；根据城市全域的所述城市出行活力强度计算出行基准活力强度,根据城市全域的所述城市社交活力强度计算社交基准活力强度,根据城市全域的所述城市商业活力强度计算商业基准活力强度；根据所述出行基准活力强度和各个区域的城市出行活力强度计算城市出行活力稳定度,根据所述社交基准活力强度和各个区域的城市社交活力强度所述计算城市社交活力稳定度,根据所述商业基准活力强度和各个区域的城市商业活力强度计算城市商业活力稳定度；采用因子分析法对所述城市出行活力强度、城市社交活力强度和城市商业活力强度进行分析,得到城市综合活力强度；采用因子分析法对所述城市出行活力稳定度、城市社交活力稳定度和城市商业活力稳定度进行分析,得到城市综合活力稳定度；对所述城市综合活力强度和城市综合活力稳定度进行叠置分析,得到城市活力分布。</td>   <td>G06Q10/0639;G06Q50/26;G06F16/29</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林夏娜;              倪江群;                   张木水       </td>   <td>中山大学</td>   <td>一种基于图像降噪的抗打印拍摄图像数字水印方法</td>   <td>广东省</td>   <td>CN111598761B</td>   <td>2023-11-17</td>   <td>本发明提供的一种基于图像降噪的抗打印拍摄图像数字水印方法,采用生成对抗网络构建一个能够抵抗图像在打印拍摄过程中可能存在的噪声攻击的图像降噪层,能够抵抗多种噪声的同时攻击,实现更好的降噪效果,保证图像具有高保真度；并且将图像降噪层加入到整个水印嵌入与提取的训练框架中,图像降噪层实现了抵抗噪声攻击的功能,在一定程度上保证了鲁棒性,使得水印编解码器可以更专注于提高水印嵌入后的视觉效果、水印的检测准确率和嵌入容量,从而实现鲁棒性、视觉效果和嵌入容量三种指标的均衡。</td>   <td>1.一种基于图像降噪的抗打印拍摄图像数字水印方法,其特征在于,包括以下步骤：S1：对打印拍摄过程中的噪声进行建模,构建噪声层；根据噪声层对生成式对抗网络GANs进行对抗训练,构建图像降噪层；S2：将原始图像和经过噪声层的噪声图像作为对抗训练后的图像降噪层的输入,得到一个对畸变过程具有一定鲁棒性的降噪层；S3：对降噪层进行预训练并构建水印编码器、水印解码器；S4：随机生成水印信息,将原始图像和水印信息输入水印编码器中,将水印信息嵌入到原始图像中,输出水印图像；S5：将水印图像经过噪声层和预训练的降噪层,模拟水印图像的畸变过程和降噪过程,得到降噪后的水印图像；S6：利用水印解码器对降噪后的水印图像进行解码,得到解码后的水印信息；S7：根据水印信息和解码后的水印信息判断解码正确率,若符合训练标准,则完成抗打印拍摄图像数字水印方法；若否,使用交叉熵函数对水印解码器的解码器正确率进行训练,返回执行步骤S4。</td>   <td>G06T1/00;G06T5/00;G06N3/0464;G06N3/0455;G06N3/0475;G06N3/094;G06N3/048;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建芳;                   李世顺       </td>   <td>中山大学</td>   <td>一种基于长期记忆学习的多通道神经网络实例分隔方法</td>   <td>广东省</td>   <td>CN113065650B</td>   <td>2023-11-17</td>   <td>本发明公开了一种基于长期记忆学习的多通道神经网络实例分隔方法,通过FPN提取已观察的过去帧的图像特征,并依次经过基于ConvLSTM的实例分割预测网络、Mask R-CNN head得到实例分割预测结果。本发明挖掘了各层级间的金字塔特征之间存在的内在联系,利用包含时空语义信息的金字塔特征对视频中的表现变化进行建模,模型中用ConvLSTM来捕捉对应的金字塔特征层级内部的时空联系,通过增加ConvLSTM之间的路径连接使得不同层级间可以相互传递语义信息,克服了现有技术根据观察到的过去帧中提取金字塔特征的过程中每个层级的金字塔特征都是独立预测的缺陷,进而提高特征预测的准确度。</td>   <td>1.一种基于长期记忆学习的多通道神经网络实例分隔方法,其特征在于,包括下述步骤：利用特征金字塔网络提取已观察的过去帧的RGB图像的多层金字塔特征,具体为：将已观察到的过去T帧的RGB图像经过特征金字塔网络,得到所述T帧的RGB图像分别对应的L层不同分辨率的多层金字塔特征；特征预测,将过去帧的RGB图像的多层金字塔特征经过基于卷积长短期记忆网络的实例分割预测网络,得到未来帧的多层金字塔特征的预测结果；所述基于卷积长短期记忆网络的实例分割预测网络包括L层的卷积长短期记忆网络ConvLSTM,每层ConvLSTM包括x个单元,每一层ConvLSTM用于表征同一层级金字塔特征内部的时空语义信息,不同ConvLSTM层级通过路径连接法捕捉层间时空语义信息；将未来帧的多层金字塔特征的预测结果输入到Mask R-CNN head中即得实例分割预测结果。</td>   <td>G06N3/082;G06N3/0464;G06N3/0442</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘海亮;              苏航;              汤武惊;                   张怡       </td>   <td>中山大学深圳研究院;中山大学</td>   <td>基于迁移学习的跨语种文本检索方法及终端设备</td>   <td>广东省</td>   <td>CN117076614A</td>   <td>2023-11-17</td>   <td>本申请适用于检索技术领域,提供了一种基于迁移学习的跨语种文本检索方法及终端设备,包括：基于预设语种专利数据库构建第一训练集；对跨语种专利检索模型进行训练时,通过跨语种专利检索模型确定每条样本数据对应的高维标签向量、第一高维文本向量及第二高维文本向量,计算每条样本数据对应的高维标签向量与第一高维文本向量之间的第一匹配度,每条样本数据对应的高维标签向量与第二高维文本向量之间的第二匹配度,基于预设损失函数、预设匹配条件及每条样本数据对应的第一匹配度和第二匹配度,对模型参数进行调整；通过训练好的跨语种专利检索模型输出通过目标语种描述的,与检索表达式相匹配的专利公开文本,提高了跨语种文本检索的匹配度。</td>   <td>1.一种基于迁移学习的跨语种文本检索方法,其特征在于,包括：基于预设语种专利数据库构建第一训练集；所述第一训练集包括多个训练数据组,每个训练数据组包括多条样本数据,每条样本数据均包括专利标签向量、正关联文本向量及负关联文本向量；同一个训练数据组中的各条样本数据的专利标签向量和正关联文本向量是对同一个专利的不同语种版本的专利公开文本对应的专利标签向量和专利文本向量进行排列组合得到的；每条样本数据中的负关联文本向量为不同训练数据组中其他样本数据中的正关联文本向量；在采用所述第一训练集对跨语种专利检索模型进行训练的过程中,针对所述第一训练集中的每条样本数据,通过所述跨语种专利检索模型确定每条所述样本数据对应的高维标签向量、第一高维文本向量以及第二高维文本向量,并计算每条所述样本数据对应的高维标签向量与第一高维文本向量之间的第一匹配度,以及高维标签向量与第二高维文本向量之间的第二匹配度,且基于预设损失函数、预设匹配条件以及每条所述样本数据对应的第一匹配度和第二匹配度,对所述跨语种专利检索模型的模型参数进行调整；当接收到通过源语种描述的检索表达式时,通过训练好的跨语种专利检索模型输出通过目标语种描述的,与所述检索表达式相匹配的专利公开文本。</td>   <td>G06F16/33;G06F18/22;G06F18/214;G06F40/44;G06Q50/18;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              汤成熙;              周凡;                   林格       </td>   <td>中山大学</td>   <td>一种基于域自适应学习的多复杂场景目标检测方法</td>   <td>广东省</td>   <td>CN112434586B</td>   <td>2023-11-14</td>   <td>本发明公开了一种基于域自适应学习的多复杂场景目标检测方法。首先收集得到通用目标检测图像集、降质场景图像集；之后利用通用目标检测图像集预训练目标检测网络YOLOv3,然后在此基础上嵌入域自适应模块,再利用通用目标检测图像集、降质场景图像集对其重新进行训练,得到最终的多复杂场景目标检测网络；输入待检测目标的图像即可计算出图像中物体的类别以及位置。本发明能够针对多种不同的降质场景进行目标检测,适用性广；能够在确保检测精度的前提下,实时对图像中的目标作出检测；采用了自适应学习的方法,降低了通用图像与多种不同降质场景图像的域间差异,使得目标检测能够同时在多种场景的图像上表现良好。</td>   <td>1.一种基于域自适应学习的多复杂场景目标检测方法,其特征在于,所述方法包括：收集通用目标检测图像数据,以及多种降质场景下的图像数据,并对数据进行预处理,得到通用目标检测图像集、降质场景图像集；利用所述通用目标检测图像集预训练目标检测网络YOLOv3；在所述预训练完成的目标检测网络YOLOv3的基础上嵌入域自适应模块,并利用所述通用目标检测图像集、所述降质场景图像集对嵌入了域自适应模块的目标检测网络重新进行训练,训练完成后,再把该域自适应模块进行拆除,得到最终的多复杂场景目标检测网络；输入待检测目标的图像,通过所述多复杂场景目标检测网络计算得出图像中特定物体的类别以及位置信息；其中,所述嵌入域自适应模块,具体为：在所述目标检测网络YOLOv3的基础上,在8倍下采样、16倍下采样和32倍下采样得到的特征图后面,分别串联增加域自适应模块,该域自适应模块的结构包括梯度反转层、卷积层、softmax操作和域分类器；所述梯度反转层在网络训练正向传播过程中传递的是正值,而在反向传播的过程中传播的是负值,该层的作用是将域自适应模块的损失最大化；所述卷积层和所述softmax操作将特征图映射到一个1*4的特征向量,表示该特征图属于某个域的类别概率；其中,所述利用所述通用目标检测图像集、所述降质场景图像集对嵌入了域自适应模块的目标检测网络重新进行训练,具体为：按照不同场景对所述通用目标检测图像集、所述降质场景图像集的图像数据加上域标注,其中所述通用目标检测图像的域标注为0,所述降质场景图像中雨的域标注为1,雾的域标注为2,低光的域标注为3；训练时,需要同时将所述通用目标检测图像集、所述降质场景图像集中的图像数据以及图像所包含的域标注输入到嵌入了域自适应模块的目标检测网络中,如果图像数据的域标注不为0,则只需要通过域自适应模块,计算域分类损失,并将损失的梯度回传,更新网络的参数；如果数据的域标注为0,则不仅要通过域自适应模块,也要通过整个目标检测网络,同时计算域分类损失以及检测损失,并将损失的梯度回传,更新网络的参数。</td>   <td>G06V20/40;G06V10/774;G06V10/764;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              丁汝鑫       </td>   <td>中山大学</td>   <td>基于多颗粒U-Th/He年龄的热史模拟方法及装置</td>   <td>广东省</td>   <td>CN112685909B</td>   <td>2023-11-14</td>   <td>本发明提供的一种基于多颗粒U-Th/He年龄的热史模拟方法及装置,包括：从岩石样品中获取多个矿物颗粒,并通过U-Th/He对各个矿物颗粒进行测年,得到每个矿物颗粒对应的实验年龄、实验年龄误差；获取若干条热史曲线,并计算每条热史曲线的模拟年龄,根据每个矿物颗粒对应的实验年龄、实验年龄误差、获取的颗粒数量以及每条热史曲线的模拟年龄计算对应的拟合优度；根据所述拟合优度筛选出符合条件的热史曲线,并根据筛选结果生成最终的热史模拟结果；本发明突出了多颗粒年龄分布与有效铀浓度呈现规律性变化的情况,在热史模拟过程中不但避免了对部分颗粒的舍弃,也提高了热史模拟的精度,为热历史模拟提供了新的提升方案。</td>   <td>1.一种基于多颗粒U-Th/He年龄的热史模拟方法,其特征在于,包括：从岩石样品中筛选矿物、挑选晶体以及计算校正参数后获取多个矿物颗粒,并通过U-Th/He对各个矿物颗粒进行测年,得到每个矿物颗粒对应的实验年龄、实验年龄误差；根据所述岩石样品在所经历的时间段内的冷却模式选取若干条热史曲线,并计算每条热史曲线的模拟年龄；根据每个矿物颗粒对应的实验年龄、实验年龄误差、获取的颗粒数量以及每条热史曲线的模拟年龄计算对应的拟合优度；根据所述拟合优度筛选出符合条件的热史曲线,并根据筛选结果生成最终的热史模拟结果,包括：根据每个矿物颗粒对应的实验年龄误差和获取的颗粒数量计算对应的实验年龄平均误差,计算公式如下：                  其中,σ-i为第i个矿物颗粒的实验年龄误差,n为颗粒数量,为实验平均误差；根据每个矿物颗粒对应的实验年龄以及单条热史曲线的模拟年龄计算多颗粒模拟年龄与实验年龄之间的平均误差,计算公式如下：                  其中,为多颗粒模拟年龄与实验年龄之间的平均误差,o-i为第i个矿物颗粒的实验年龄,M-i为第i个矿物颗粒所对应的单条热史曲线的模拟年龄范围；通过所述实验年龄平均误差、所述多颗粒模拟年龄与实验年龄之间的平均误差计算对应的拟合优度；获取若干条热史曲线与每个矿物颗粒之间的拟合优度,并根据所述拟合优度筛选出符合条件的热史曲线；将所述符合条件的热史曲线对应的均值作为最终的热史模拟结果；或者,在单个矿物颗粒的实验年龄误差范围内,将所述矿物颗粒对应的实验年龄与每条热史曲线的模拟年龄之间进行比对,并筛选出符合筛选标准的热史曲线；重复上述过程,直到所有的矿物颗粒均完成反演过程,得到最终符合筛选标准的热史曲线,并根据所述热史曲线生成最终的热史模拟结果。</td>   <td>G06F30/20;G06F119/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   高月       </td>   <td>中山大学</td>   <td>一种基于注意力增强以及输入扰动的分布外图像检测方法</td>   <td>广东省</td>   <td>CN113076980B</td>   <td>2023-11-14</td>   <td>本发明提供一种基于注意力增强以及输入扰动的分布外图像检测方法,该方法采用了输入扰动的技巧,对分布内的样本影响大于分布外样本,使得分布内样本的自信分数更高,同时使用了温度缩放的技巧,使得分布内样本的预测概率分布更加尖锐,分布外样本的预测概率更加平滑,进一步加大分布内外样本的自信分数差距；相较于直接使用生成模型进行分布外样本检测任务,本方法不需要引入额外的超参,并且模型相对简单,可以节省训练时间；相较于使用生成对抗的方法做分布外样本检测任务,本方法不会过度局限于训练数据,对于边缘样本不容易产生误判,可以得到更好的检测效果。</td>   <td>1.一种基于注意力增强以及输入扰动的分布外图像检测方法,其特征在于,包括以下步骤：S1：给输入图像添加扰动,并计算扰动后图像分类以及判别是否为分布内样本的两种不确定性；S2：利用S1不确定性进行注意力图计算,给特征进行加权；S3：将S2得到的加权后的特征作为分类器的输入进行温度缩放后得到数据分类的概率分布；所述步骤S1的具体过程是：获取图像数据,首先为其添加扰动,如公式(1),然后将扰动后的图像输入至特征提取器提取出特征,如公式(2),提取出的特征输入至分类器和判别器获取分类结果和判别结果,如公式(3),同时将特征输入至分类器以及判别器的不确定性估计器获取两种不确定性,如公式(4)：                                    y-c＝Softmax(C(h)),y-d＝Softmax(D(h))           (3)                  其中x表示输入的图像数据,σ表示分类结果的偶然不确定性,F表示特征提取器,C表示分类器,D表示判别器,U表示不确定性估计器；所述步骤S2的具体过程是：将S1中获得的不确定性对特征进行求导并进行梯度反转,如公式(5),根据数值确定不确定性,并保留确定的区域,如公式(6),再进行softmax,即获取特征的注意力图,如公式(7)：</td>   <td>G06V10/764;G06V10/774;G06V10/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洁旻;              付芳昊;                   蔡铭       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种交通小区划分方法、系统、电子设备及存储介质</td>   <td>广东省</td>   <td>CN117057963A</td>   <td>2023-11-14</td>   <td>本发明公开了一种交通小区划分方法、系统、电子设备及存储介质,其中,方法包括获取公交服务区域数据和边界数据；根据所述边界数据对待划分区域进行单元划分,得到基本单元集合；根据所述公交服务区域数据对所述基本单元集合进行聚类处理,得到初始交通小区划分结果；对所述初始交通小区划分结果进行异常修正处理,得到目的交通小区划分结果。本发明通过基于公交服务特性进行区域划分,以公交服务特征作为划分标准,提高了公交服务区划评价的准确性,可广泛应用于公共交通规划技术领域。</td>   <td>1.一种交通小区划分方法,其特征在于,所述方法包括：获取公交服务区域数据和边界数据；根据所述边界数据对待划分区域进行单元划分,得到基本单元集合；根据所述公交服务区域数据对所述基本单元集合进行聚类处理,得到初始交通小区划分结果；对所述初始交通小区划分结果进行异常修正处理,得到目的交通小区划分结果。</td>   <td>G06Q50/26;G06Q10/0631;G06F18/2321</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈佳俊;              姜善成;              彭宇璇;              张丞耀;              陈跃勇;                   邢宸翰       </td>   <td>中山大学</td>   <td>一种分布式医疗影像处理模型的训练方法及应用方法</td>   <td>广东省</td>   <td>CN117058091A</td>   <td>2023-11-14</td>   <td>本发明公开了一种分布式医疗影像处理模型的训练方法及应用方法,包括：收集来自多个医疗中心经过标注的医疗影像数据并进行数据预处理,得到各个医疗中心的局部数据集,根据局部数据集生成全局数据集；根据局部数据集生成局部对抗影像样本；基于变分贝叶斯框架构建初始分布式医疗影像处理模型；采用局部数据集和局部对抗影像样本对局部模型进行局部训练,当迭代次数每达到预设轮次时,对各个局部模型进行全局聚合处理,形成全局模型；当各个局部模型的局部损失函数收敛或者迭代次数达到预设的第二迭代次数阈值时,得到目标分布式医疗影像处理模型。本发明能够训练分散大规模数据,提高了模型准确率模型的鲁棒性,可广泛应用于图像处理技术领域。</td>   <td>1.一种分布式医疗影像处理模型的训练方法,其特征在于,包括：收集来自多个医疗中心经过标注的医疗影像数据,对所述医疗影像数据进行数据预处理,得到各个所述医疗中心的局部数据集,根据所述局部数据集生成全局数据集；根据所述局部数据集生成局部对抗影像样本；基于变分贝叶斯框架构建初始分布式医疗影像处理模型；其中,所述初始分布式医疗影像处理模型包括若干个与所述医疗中心一一对应的局部模型；采用所述局部数据集和所述局部对抗影像样本对所述局部模型进行局部训练,当迭代次数每达到预设轮次时,对各个所述局部模型进行全局聚合处理,形成一个全局模型；当各个所述局部模型的局部损失函数收敛或者所述迭代次数达到预设的第二迭代次数阈值时,得到目标分布式医疗影像处理模型；其中,所述目标分布式医疗影像处理模型包括一个全局模型和若干个与所述医疗中心一一对应的局部模型。</td>   <td>G06T7/00;G06T7/10;G06V10/774;G06V10/82;G06N3/045;G06N3/0464;G06N3/047;G06N3/094;G06N3/098</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              李睿扬;              陈文贲;                   李明远       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于晶状体图像的人体生物学年龄评估方法及系统</td>   <td>广东省</td>   <td>CN117058745A</td>   <td>2023-11-14</td>   <td>本发明公开了一种基于晶状体图像的人体生物学年龄评估方法及系统,通过预设的卷积神经网络对获取的待评估对象的眼部晶状体图像进行卷积运算,以使对所述眼部晶状体图像进行初步特征提取,获得所述眼部晶状体图像的初步特征图,接着利用所述卷积神经网络对所述初步特征图进行进一步的卷积运算及特征图拼接,并在所述卷积神经网络中设置残差计算,最终获得所述眼部晶状体图像对应的多维向量,以使通过卷积神经网络对所述多维向量中的每一个向量分别配置一个权重,进而根据所述权重及所述向量,输出所述待评估对象的生物学年龄,提高所述生物学年龄评估的准确性及效率。</td>   <td>1.一种基于晶状体图像的人体生物学年龄评估方法,其特征在于,包括：根据预设的卷积神经网络对获取的待评估对象的眼部晶状体图像进行初步特征提取,获得所述眼部晶状体图像对应的第一特征图；根据所述卷积神经网络对所述第一特征图进行第一卷积运算和第二卷积运算,获得第二特征图及第三特征图,并将所述第二特征图及第三特征图进行拼接,获得第四特征图；通过所述卷积神经网络对所述第四特征图进行卷积运算,获得第五特征图,并利用预设在所述卷积神经网络中的残差学习算法对所述第五特征图进行残差计算,获得第六特征图；通过所述卷积神经网络对所述第六特征图进行全局平均池化,获得所述第六特征图对应的多维向量,以使根据预设在所述卷积神经网络中的权重向量及所述多维向量,输出所述待评估对象的生物学年龄。</td>   <td>G06V40/18;G06V40/16;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何明光;                   李治玺       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于眼底图像的心脑血管疾病筛查方法</td>   <td>广东省</td>   <td>CN117059271A</td>   <td>2023-11-14</td>   <td>本发明公开了一种基于眼底图像的心脑血管疾病筛查方法,涉及图像处理技术领域,通过获取患者的眼底图像；对眼底图像进行预处理；对预处理后的眼底图像进行清晰度分析、视盘定位和黄斑中心凹定位；分割预处理后的眼底图像的视网膜血管网络及主血管；建立心脑血管疾病筛查模型对视盘定位和黄斑中心凹以及视网膜血管网络和主血管进行筛查,得到筛查结果。本发明通过提取眼底图像的多个序列特征,在多个序列特征的基础上,使用支持向量机分类器对其计算概率分布,得到RGB-D图像的分类结果,进一步的提高了筛查心脑血管疾病的效率和准确性。</td>   <td>1.一种基于眼底图像的心脑血管疾病筛查方法,其特征在于,包括：获取患者的眼底图像；对所述眼底图像进行预处理；对预处理后的眼底图像进行清晰度分析、视盘定位和黄斑中心凹定位；分割预处理后的眼底图像的视网膜血管网络及主血管；建立心脑血管疾病筛查模型对视盘定位和黄斑中心凹以及视网膜血管网络和主血管进行筛查,得到筛查结果。</td>   <td>G16H50/30;G16H50/20;G16H50/70;G06V10/764;G06T7/11;G06N3/0442;G06N3/0464;G06N3/048;G06T7/136;G06T7/155</td>  </tr>        <tr>   <td>中国专利</td>   <td>         闫志强;              苏蕾;              夏北成;              李志今;              石敏球;              吴迪;              林荣斌;              李永怿;              周刚;              张晓健;                   王广义       </td>   <td>广州资源环保科技股份有限公司;中山大学</td>   <td>一种用于模拟浅水湖泊生态系统模型的方法</td>   <td>广东省</td>   <td>CN109101707B</td>   <td>2023-11-10</td>   <td>本发明公开了一种用于模拟浅水湖泊生态系统模型的方法,利用生态模拟软件构建模型,包括,A、构建初级生产者生态过程方程；B、构建消费者生态过程方程；C、构建初级生产者和消费者生态子模型；D、构建生态系统模型。本发明的模拟浅水湖泊生态系统模型的方法,利用生态模拟软件构建了浅水湖泊生态系统模型,更精确的考虑了生物的生态过程,提高了模型模拟的准确度,为浅水湖泊生态系统研究与管理提供了理论参考与技术支持。</td>   <td>1.一种用于模拟浅水湖泊生态系统模型的方法,其特征在于,利用生态模拟软件构建模型,包括,A、构建初级生产者生态过程方程：根据初级生产者的光合作用生长过程、呼吸损失过程以及死亡过程构建初级生产者生态过程方程；B、构建消费者生态过程方程：根据消费者的捕食生长过程、基础代谢损失以及死亡损失构建消费者生态过程方程；C、构建初级生产者和消费者生态子模型：根据初级生产者生态过程方程,构建作为初级生产者的沉水植物生态动力学模型、浮游植物生态动力学模型和附生藻类生态动力学模型；根据消费者生态过程方程,构建作为消费者的浮游动物生态动力学模型、底栖动物生态动力学模型、滤食性鱼类生态动力学模型、草食性鱼类生态动力学模型和肉食性鱼类生态动力学模型；D、构建生态系统模型：根据限制函数,将沉水植物生态动力学模型、浮游植物生态动力学模型和附生藻类生态动力学模型与浮游动物生态动力学模型、底栖动物生态动力学模型、滤食性鱼类生态动力学模型、草食性鱼类生态动力学模型和肉食性鱼类生态动力学模型相应耦合,得到生态系统模型。</td>   <td>G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张东;              王梦瑶;              余萌;              陈伟聪;                   何坚       </td>   <td>中山大学</td>   <td>一种基于人眼动作特征的专注度分级方法及系统</td>   <td>广东省</td>   <td>CN113076885B</td>   <td>2023-11-10</td>   <td>本发明公开了一种基于人眼动作特征的专注度分级方法及系统,该方法包括：录制待测视频数据；根据待测视频数据提取用户的左眼视频数据、右眼视频数据、眨眼时长和眨眼频次,得到用户眼部动作特征；将用户眼部动作特征输入到预训练的分类网络,得到用户专注状态的眨眼次数和用户非专注状态的眨眼次数；根据用户专注状态的眨眼次数与用户非专注状态的眨眼次数的比值,判断用户的专注度等级。该系统包括：数据采集模块、特征提取模块、分类模块和分级模块。通过使用本发明,能够分析出该学生在上网课时的专注程度,从而提高学生学习的质量。本发明作为一种基于人眼动作特征的专注度分级方法及系统,可广泛应用于视频处理领域。</td>   <td>1.一种基于人眼动作特征的专注度分级方法,其特征在于,包括以下步骤：录制用户在观看网课时的视频,得到待测视频数据；根据待测视频数据提取用户的左眼视频数据、右眼视频数据、眨眼时长和眨眼频次,得到用户眼部动作特征；将用户眼部动作特征输入到预训练的分类网络,得到用户专注状态的眨眼次数和用户非专注状态的眨眼次数；根据用户专注状态的眨眼次数与用户非专注状态的眨眼次数的比值,判断用户的专注度等级；所述根据待测视频数据提取用户的左眼视频数据、右眼视频数据、眨眼时长和眨眼频次,得到用户眼部动作特征这一步骤,其具体包括：基于人脸配准算法对待测视频数据进行眼部特征点定位找到人眼位置,得到待测视频中的左眼视频数据和右眼视频数据；根据眼部特征点计算人眼横纵比值；根据人眼横纵比值判断用户的眨眼动作,并计算得到用户视频中的眨眼时长和眨眼频次；整合左眼视频数据、右眼视频数据、眨眼时长和眨眼频次,得到用户眼部动作特征；所述人脸配准算法包括68个特征点,所述人眼横纵比值的计算公式如下：                  上式中,EAR表示人眼横纵比值,h-1表示左眼高度,定义为特征点37与特征点41之间的欧氏距离和特征点38与特征点40之间的欧式距离的平均值,l-1表示左眼宽度,定义为特征点36与特征点39之间的欧式距离,h-2表示右眼高度,定义为特征点43与特征点47之间的欧氏距离和特征点44与特征点46之间的欧式距离的平均值,l-2表示右眼宽度,定义为特征点42与特征点45之间的欧氏距离。</td>   <td>G06V40/18;G06V40/16;G06V10/764;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓一术;              李超峰;              经秉中;              李彬;                   陈浩华       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于MR图像的鼻咽癌识别及肿瘤分割方法及系统</td>   <td>广东省</td>   <td>CN114155215B</td>   <td>2023-11-10</td>   <td>本发明公开了一种基于MR图像的鼻咽癌识别及肿瘤分割方法及系统,包括：接收第一用户上传的第一图像；其中,第一图像包括MR平扫序列图像和MR增强序列图像；对第一图像进行预处理,得到第一图像对应的第二图像；将第二图像输入至肿瘤分割模型,以使肿瘤分割模型对第二图像进行区域划分,输出第二图像对应的肿瘤分割图；其中,肿瘤分割模型是根据多个第一鼻咽良恶性MR影像数据以及对应的多个带有肿瘤标记的第二鼻咽良恶性MR影像数据,对三维卷积神经网络模型训练而获得。本发明采用适用于MR平扫序列和MR增强序列的肿瘤分割模型,实现对MR图像的鼻咽癌识别及肿瘤分割,并通过分割错漏的数据对模型进行优化,提升图像的分割效果。</td>   <td>1.一种基于MR图像的鼻咽癌识别及肿瘤分割方法,其特征在于,包括：接收第一用户上传的第一图像；其中,所述第一图像包括MR平扫序列图像和MR增强序列图像；对所述第一图像进行预处理,得到所述第一图像对应的第二图像；其中,所述对所述第一图像进行预处理,得到所述第一图像的第二图像,具体为：对所述第一图像进行影像数据清洗、数据归一化、平扫与增强影像配准的预处理,得到所述第一图像对应的第二图像；将所述第二图像输入至肿瘤分割模型,以使所述肿瘤分割模型对所述第二图像进行区域划分,输出所述第二图像对应的肿瘤分割图；其中,所述将所述第二图像输入至肿瘤分割模型,以使所述肿瘤分割模型对所述第二图像进行区域划分,输出所述第二图像对应的肿瘤分割图,具体为：将所述第二图像输入至肿瘤分割模型；其中,所述肿瘤分割模型包含编码器与解码器；通过所述编码器对所述第二图像执行若干次卷积,识别并提取所述第二图像中与鼻咽癌相关的影像特征,并对所述影像特征进行抽象处理,输出所述第二图像的鼻咽癌概率；将所述编码器的每一次卷积的结果与对应的所述解码器的每一次卷积的结果共同作为所述解码器的下一次卷积的输入,逐步重构所述第二图像的肿瘤区域,并对所述解码器的最后一次卷积的结果进行上采样操作,得到并输出所述第二图像对应的肿瘤分割图；其中,所述肿瘤分割模型是根据多个第一鼻咽良恶性MR影像数据以及对应的多个带有肿瘤标记的第二鼻咽良恶性MR影像数据,对三维卷积神经网络模型训练而获得。</td>   <td>G06T7/00;G06T7/11;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李丹;              张泽凯;                   郑子彬       </td>   <td>中山大学</td>   <td>一种工业设备的剩余生命预测方法及装置</td>   <td>广东省</td>   <td>CN117035179A</td>   <td>2023-11-10</td>   <td>本申请公开了一种工业设备的剩余生命预测方法及装置,方法包括：将工业设备的待测数据输入至预先建立的生命预测模型,输出工业设备的剩余生命时间,通过构建生命预测架构,获取训练数据,随机获取样本噪声数据,在迭代次数下对第一编码器、第一生成器和第一鉴别器进行训练,得到第一训练参数,随机获取预测噪声数据,并在迭代次数下对第二编码器、第二生成器和第二鉴别器进行训练,得到第二训练参数,基于第一训练参数和第二训练参数,构建生命预测模型。可见,采用了编码器并引入了随机源进行训练,生命预测架构能够更加稳定,编码器和生成器均采用对抗性再生结构,更好地捕捉数据中的多模态特征,使生命预测模型具备更高的预测准确率。</td>   <td>1.一种工业设备的剩余生命预测方法,其特征在于,包括：将工业设备的待测数据输入至预先建立的生命预测模型,输出所述工业设备的剩余生命时间；所述生命预测模型的建立过程,包括：构建生命预测架构,所述生命预测架构包括条件空间架构和预测空间架构,所述条件空间架构包括第一编码器、第一生成器和第一鉴别器,所述预测空间架构包括第二编码器、第二生成器和第二鉴别器,所述第一编码器、所述第一生成器、所述第二编码器和所述第二生成器均采用对抗性再生结构；从已有的工业设备训练集中获取本轮训练的训练数据,所述训练数据包括协变量数据和与所述协变量数据对应的剩余生命数据；随机获取初始的样本噪声数据,并在预设迭代次数下,基于所述协变量数据与所述样本噪声数据对所述第一编码器、所述第一生成器和所述第一鉴别器进行训练,确定第一编码器的训练参数、第一生成器的训练参数和第一鉴别器的训练参数；随机获取初始的预测噪声数据,并在所述预设迭代次数下,基于所述剩余生命数据与所述预测噪声数据对所述第二编码器、所述第二生成器和所述第二鉴别器进行训练,确定第二编码器的训练参数、第二生成器的训练参数和第二鉴别器的训练参数；基于所述第一编码器的训练参数、所述第一生成器的训练参数、所述第一鉴别器的训练参数、所述第二编码器的训练参数、所述第二生成器的训练参数和所述第二鉴别器的训练参数,构建生命预测模型。</td>   <td>G06Q10/04;G06Q10/20;G06N3/045;G06N3/0475;G06N3/084;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘建平;              郑剑锋;              刘尊龙;                   任飞       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>基于Cox回归分析的胰腺癌的预后模型构建方法</td>   <td>广东省</td>   <td>CN117038092A</td>   <td>2023-11-10</td>   <td>本发明提出了一种基于Cox回归分析的胰腺癌的预后模型构建方法,包括：从TCGA数据库下载胰腺癌表达谱,进行预处理形成样本数据；按照比例随机分为一个训练数据集和一个验证数据集,使用LASSO Cox回归分析对训练数据集进一步筛选与OS相关的lncRNA,计算每一个患者样本的风险评分；验证数据集和完整数据集中使用训练数据集筛选的lncRNAs建立预测模型,将样本分为高风险组和低风险组；构建列线图并进行一致性试验、校正曲线分析和时间依赖性ROC曲线分析；使用了Pearson相关分析筛选出与预后lncRNAs共表达的蛋白编码基因；使用LASSO Cox回归分析进一步选择并建立预后预测模型。本发明构建的预后模型的能力优于之前发表的lncRNAs模型和TNM分期系统,可以极大地提高胰腺癌预后预测准确性。</td>   <td>1.一种基于Cox回归分析的胰腺癌的预后模型构建方法,其特征在于,所述方法包括：步骤一、从TCGA数据库下载胰腺癌表达谱,对所述胰腺癌表达谱进行预处理形成样本数据；所述样本数据为完整数据集；步骤二、将所述完整数据集按照比例随机分为一个训练数据集和一个验证数据集,使用LASSOCox回归分析对训练数据集进一步筛选与OS相关的lncRNA,然后基于lncRNAs回归系数和表达量的风险评分计算公式,计算每一个患者样本的风险评分,再根据预测模型中位风险评分的临界值,将患者分为高危组和低危组；步骤三、验证数据集和完整数据集中使用训练数据集筛选的lncRNAs建立预测模型,基于模型中位风险评分的临界值,将验证数据集和完整数据集的样本分为高风险组和低风险组；步骤四、基于单变量和多变量Cox回归分析筛选的胰腺癌独立预后影响因子,构建一个模型与临床病理特征相结合的列线图并进行一致性试验、校正曲线分析和时间依赖性ROC曲线分析；步骤五、使用Pearson相关分析筛选出与预后lncRNAs共表达的蛋白编码基因；其中,所述步骤一中预处理的步骤包括：对基因进行整理和注释,然后用R语言的edgeR软件包对胰腺癌表达谱进行了处理,对比Ensembl ID后,对基因进行分离筛选出平均表达值大于1的lncRNA进行下一步的分析,在胰腺癌表达谱筛选|logFC|&gt;1和p&lt;0.05的差异表达lncRNA,并进行单变量Cox回归分析,筛选出与OS相关的lncRNA,再删除临床信息不完整、生存时间为0、重复的样本数据；所述与OS相关的lncRNA为L031658.1,ABCA9-AS1,DNAH17-AS1,AP003086.1,AC018755.4；所述风险评分包括：每个样本的风险评分计算公式为：风险评分＝-0.23189*AL031658.1的表达量+0.20984*ABCA9-AS1的表达量+0.03709*DNAH17-AS1的表达量+-0.26114*AP003086.1的表达量+0.15556*AC018755.4的表达量,其中所述风险评分公式为预测模型,以风险评分的中位数为临界值,其中：大于等于临界值的为高危组,小于临界值的为低危组。</td>   <td>G16H50/50;G16H50/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴文斌;              刘志华;              王志强;              黄达宇;              姜乃斌;              李捷;              马宇;                   王亚辉       </td>   <td>中山大学</td>   <td>基于光线追踪的中子输运计算CSG三维可视化方法及系统</td>   <td>广东省</td>   <td>CN117036597A</td>   <td>2023-11-10</td>   <td>本发明涉及核反应堆物理数值计算技术领域,公开了一种基于光线追踪的中子输运计算CSG三维可视化方法及系统,该方法包括：导入CSG几何模型,并在所述CSG几何模型的坐标系中分别设置初始屏幕、初始相机和初始焦点；根据所述初始相机和初始焦点构建射线；从所述射线与所述CSG几何模型的交点中提取可视点,得到所述可视点的坐标信息；所述可视点与所述CSG几何模型最顶层区域相交,且所述可视点为距离相机最近的交点；根据所述可视点的坐标信息查找对应的模型属性,对所述模型属性进行颜色映射,得到可视化图像；所述模型属性包括填充材料、栅元和裂变率。本发明基于光线追踪技术,实现构造实体几何堆芯建模的三维可视化,内存需求小,可移植性好。</td>   <td>1.一种基于光线追踪的中子输运计算CSG三维可视化方法,其特征在于,包括：导入CSG几何模型,并在所述CSG几何模型的坐标系中分别设置初始屏幕、初始相机和初始焦点；根据所述初始相机和初始焦点构建射线；从所述射线与所述CSG几何模型的交点中提取可视点,得到所述可视点的坐标信息；所述可视点与所述CSG几何模型最顶层区域相交,且所述可视点为距离相机最近的交点；根据所述可视点的坐标信息查找对应的模型属性,对所述模型属性进行颜色映射,得到可视化图像；所述模型属性包括填充材料、栅元和裂变率。</td>   <td>G06T17/00;G06F30/20;G06T7/73;G06T7/246;G06T19/20;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         印鉴;              陈智聪;                   陈殷齐       </td>   <td>中山大学</td>   <td>一种基于旋转不变感知哈希的无人机航拍视频帧定位方法</td>   <td>广东省</td>   <td>CN110942002B</td>   <td>2023-11-07</td>   <td>本发明提供一种基于旋转不变感知哈希的无人机航拍视频帧定位方法,该方法有一定的平移不变形(pooling原理)；编码时使用差分编码,使得光照天气条件无关；再加上起点无关的圆周编码顺序使具有旋转不变性；圆周编码顺序时不编码边角部分,因为边角部分会因为视角不同差异大,从而排除了旋转时边角的其他景物不同影响。通过在真实无人机视频上的实验表明,本发明对比之前的感知哈希方法,成功解决了传统感知哈希不具有旋转不变的特性。</td>   <td>1.一种基于旋转不变感知哈希的无人机航拍视频帧定位方法,其特征在于,包括以下步骤：S1：对需要定位的视频帧-参考帧和需要检索的视频帧-目标帧进行旋转不变的哈希值计算；所述步骤S1的具体过程是：S11：将参考帧和目标帧进行图片缩放；S12：将缩放后的图片进行灰度图转换；S13：将灰度图进行获取哈希值的圆周编码顺序；所述步骤S13的过程是：根据圆周的方式编码哈希使其有旋转不变性,根据图片的长H,取长度为r(1～H/2)作为圆周的半径,每一个半径长度用极坐标的方式,/&gt;,计算每一个圆周的坐标序列,其中/&gt;为按/&gt;的各个取值,/&gt;为缩放图片的中心,这样就得到r = 1时的一个圆周序列/&gt;其中,/&gt;表示半径为r的圆周下按照/&gt;的度数计算出来的第i个不重复的坐标索引,那么就得到/&gt;一个圆周坐标索引得到的像素值序列,得到r个这样的序列记为/&gt;,第r个序列为/&gt;,这样的编码顺序还会自动把边角影响去除,因为实际的拍摄视频中带有旋转差异的俩帧他们在边角部分会完全不一样；S14：对S13处理后的图片进行获取哈希值的二进制形式进而获取旋转不变的哈希值；所述步骤S14中获取哈希值的二进制形式的过程是：采用差分的方式对每一个序列进行编码,遍历灰度图片每一个像素,前一个值大于当前值记录为1,否则为0,最后一个像素值和投一个像素比较,使得它首尾相连,构成圆周,最终获得r个这样的二进制序列记为/&gt;,其中第r个序列为/&gt;；所述步骤S14中获取旋转不变的哈希值的过程是：把做循环移位,把循环移位之后二进制序列值最小的那一个序列作为该圆周的最终序列,最终获得r个这样的与起点无关二进制序列记为/&gt;,其中第r个序列为/&gt;；S15：根据S14的结果得出信息指纹；所述步骤S15的过程是：按照r从1到H/2的顺序,将组合起来,构成最终的信息指纹/&gt;；S2：将参考帧和目标帧与另一个时间的无人机视频所有帧对比哈希值差异找到差异最小的一帧。</td>   <td>G06V20/13;G06T7/80;G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘威;              何枷瑜;              王海明;              朱怀杰;              余建兴;              印鉴;                   邱爽       </td>   <td>中山大学</td>   <td>一种基于时空图信息最大化模型的路段特征表示学习算法</td>   <td>广东省</td>   <td>CN111754019B</td>   <td>2023-11-07</td>   <td>本发明提供一种基于时空图信息最大化模型的路段特征表示学习算法,该方法考虑路段状态的时间性,深入挖掘了路段的时间信息,并采用了最大化互信息机制,把路段信息、时间信息和交通信息三者之间相互影响、相互作用的关系提取并利用到基于神经网络的学习算法中。得到的路段表示更好的反映实时的全局交通情况,并学习到路段间上下游实时的依赖关系,大大提高了旅行时间预测的精度。</td>   <td>1.一种基于时空图信息最大化模型的路段特征表示学习算法,其特征在于,包括以下步骤：S1：从路网中提取路段属性,生成路段初始向量,并基于历史数据中的轨迹构造时间邻接矩阵；S2：对交通状况采用CNN和max-pooling操作,提取对应的交通状态/流表示；S3：将S1和S2得到的数据输入到编码器进行训练,获得实时的路段表示；S4：将得到的路段表示作为目标,通过全连接层得到路段的动态表示；所述步骤S1的具体过程是：S11：进行数据预处理,通过路网获取每条路段的静态属性,在这里使用路段类型、车道数、是否为单行路这三个属性；S12：对该三个属性生成对应的one-hot向量,进行拼接后通过全连接层得到路段初始向量R＝{r-1,r-2,…,r-N}；S13：将历史数据的路段轨迹按时间段分割,根据不同时间段的轨迹得到时间邻接矩阵A～((t)),即如果在某一时间段内,从历史轨迹中得到某些路段被多次行驶并存在上下游关系,则对应的路段则具有邻接关系,而不是简单的从拓扑关系确定邻接关系；所述步骤S2的具体过程是：S21：将对应城市进行网格划分,计算对应网格的拥堵情况、交通流；S22：将网格数据输入到CNN中得到交通状态、交通流的表示；基于CNN,从网格数据中学习到可以反映实时交通情况的表示；使用同样的方法得到网格流入流出的表示；具体计算公式如下：s～((t))＝CNN(S～((t)))；所述步骤S3的具体过程是：S31：利用图卷积神经网络,从路段初始向量以及时间邻接矩阵得到路段的邻接表示h～((t))；S32：通过负采样,重复S31的步骤得到损坏的路段邻接表示S33：利用readout函数对路段的邻接表示进行归纳,得到图的全局表示g～((t))；S34：将图的全局表示、交通状态、流入以及流出进行拼接,得到实时的图高阶归纳S35：将得到的路段的邻接表示、损坏的路段邻接表示、图高阶归纳根据以下目标函数使用梯度下降最大化进行模型的训练,训练稳定后得到的路段的邻接表示即为最终的路段表示,函数公式如下：</td>   <td>G06Q10/04;G06Q50/14;G06F16/29;G06N3/042;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢俊豪;              杜云飞;              卢宇彤;              钟康游;                   郭贵鑫       </td>   <td>中山大学</td>   <td>一种基于流水线环形参数通信的分布式深度学习方法</td>   <td>广东省</td>   <td>CN112862088B</td>   <td>2023-11-07</td>   <td>本发明为克服集群训练速度低、训练时间开销大的缺陷,提出一种基于流水线环形参数通信的分布式深度学习方法,包括以下步骤：获取训练模型,采用所述训练模型对集群中的计算节点进行初始化；采用流水线随机梯度下降法对集群中的计算节点进行分布式训练,执行训练模型更新、梯度计算,且期间并行执行梯度通信；当节点在本地上完成第i轮梯度计算后,对梯度数据进行压缩,然后启动通信线程执行环形AllReduce操作,同时启动第i+1轮迭代训练,至完成迭代训练。本发明采用环形AllReduce算法,通过环形通信来避免像参数服务器框架服务器节点的通信拥堵问题,通过本地流水线并行重叠计算与通信,减少时间消耗。</td>   <td>1.一种基于流水线环形参数通信的分布式深度学习方法,其特征在于,包括以下步骤：获取训练模型,采用所述训练模型对集群中的计算节点进行初始化；采用流水线随机梯度下降法对集群中的计算节点进行分布式训练,执行训练模型更新、梯度计算,且期间并行执行梯度通信；其中,对集群中的计算节点执行训练模型更新、梯度计算的步骤包括：对集群中的计算节点执行第i轮迭代训练时：当i＝1或2时,则直接对模型进行更新；当i&gt;2时,检测标记数组flag～g-(sum)[i-P],若标志为真,则用第i-P轮迭代的参数更新结果对模型进行更新,将更新后的模型存储在本地为m[i],且完成梯度计算后,对更新后的梯度数据进行压缩,并将标记数组flag～g-(local)[i]的值置为真；若标志为假,则等待所依赖迭代轮参数更新的完成；并行执行梯度通信的步骤包括：对集群中的计算节点执行第i轮迭代训练时：检测标记数组flag～g-(local)[i],若标志为真,则启动梯度通信线程,执行环形AllReduce操作,对各节点的梯度数据相加取平均值,解压缩更新后的梯度数据,将其保存在本地,并将标记数组flag～g-(local)[i]的值置为真；同时启动i+1轮迭代训练,形成流水线并行,至完成迭代训练；若标志为假,则等待对应迭代轮的本地梯度完成计算；执行环形AllReduce操作的具体步骤包括：(1)数据分散：将集群作为一个有向环形拓扑结构,将通信数据分为n块,并从0开始进行编号；执行第i轮数据分散时,节点j沿着环形拓扑结构将本地的(j-i+n)％n号数据块发送到下一节点,接收来自上一节点的(j-i-1+n)％n号数据块,节点将接收到的数据块与本地对应的数据块相加；执行n-1次数据分散后,每个节点都拥有其中一块的完整数据；(2)数据集中：在第i轮数据集中时,节点j沿着环形拓扑结构将本地的(j-i-1+n)％n号完整数据块发送到下一个节点,同时接收来自上一个节点的(j-i+n)％n号完整数据块,节点用接收到的数据块替换本地对应的数据块；完成n-1次集中后,每个节点将拥有所有块的完整数据；当节点在本地上完成第i轮梯度计算后,对梯度数据进行压缩,然后启动通信线程执行环形AllReduce操作,同时启动第i+1轮迭代训练,至完成迭代训练。</td>   <td>G06N3/098;G06N3/084;G06F9/38;G06F9/54</td>  </tr>        <tr>   <td>中国专利</td>   <td>         章影;              程晓;                   陈卓奇       </td>   <td>北京师范大学;中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>卫星影像自动化几何纠正方法、系统、介质及终端设备</td>   <td>北京市</td>   <td>CN113160071B</td>   <td>2023-11-07</td>   <td>本发明公开了一种适用于国产极地小卫星影像自动化几何纠正方法、装置、存储介质及终端设备,自动化择优筛选用于目标卫星影像自动化几何纠正的同源传感器参考影像；整景影像、影像分四部分及九部分进行图像增强处理后提取目标卫星影像与参考影像的同名点对,以得到用于几何纠正的地理坐标文件；对目标卫星采用不同方法校正后的影像进行校正精度评估,以筛选出最优校正方案,并根据所述最优校正方案对所述目标卫星的影像进行校正。本发明能够实现自动化择优筛选同源传感器配准参考影像,且通过影像增强法突出极地影像的细节特征来增加同名点的选择,并根据影像校正精度筛选出最优的几何校正方案,以克服我国极地小卫星几何定位精度不高的缺陷。</td>   <td>1.一种卫星影像自动化几何纠正方法,应用于极地小卫星,其特征在于,所述方法包括：从影像获取时间远近、空间覆盖程度以及同名点对数量三个方面择优筛选用于目标卫星影像自动化几何纠正的MODIS影像,以获得用于目标卫星影像几何校正的最优参考影像；具体为：批量地获取目标卫星影像当天少云的MODIS影像,创建目标卫星影像与MODIS影像的第一数据索引表；对目标卫星影像及MODIS影像进行预处理,采用一致的南极投影和250m分辨率,获得与目标卫星影像地理范围一致的MODIS影像；对所述MODIS影像进行初步筛选,筛选其有效数据范围覆盖了目标卫星影像80％以上的影像,并创建目标卫星影像与MODIS影像的第二数据索引表；对所述MODIS影像进行二次筛选,通过特征匹配法根据所述第二数据索引表提取目标卫星与MODIS影像对的同名点,根据所述同名点对的数量排序择优选取对应的MODIS影像,若仍有多景MODIS数据具有等量的同名点对,则取接近目标卫星影像拍摄时间的MODIS影像作为最终配准参考影像,并得出用于几何纠正的第三数据索引表；采用预设方案提取目标卫星影像与MODIS影像的同名点,以得到各方案用于几何校正的地理坐标文件；其中,所述预设方案包括通过整景影像提取同名点、影像分四部分和九部分进行影像增强处理后提取同名点；具体为：方案一：将目标卫星整景影像及依据所述第三数据索引表对应裁剪后的MODIS整景影像通过尺度不变特征变换算法提取同名点对后,按照同名点对的欧式距离进行排序,剔除欧式距离最大的10％的点,输出其余同名点对的真实地理坐标文件作为用于校正所述目标卫星影像的第一纠正地理坐标文件；方案二：将目标卫星影像规则分为四部分,并将各部分向外延40个像素裁剪对应的MODIS影像,将各影像对分别进行分段线性拉伸增强处理,再通过尺度不变特征变换算法提取同名点对,剔除欧式距离最大的30％的点,输出其余同名点的真实地理坐标文件,将此处的坐标文件与第一纠正地理坐标文件合并后剔除重复点对作为用于校正所述目标卫星影像的第二纠正地理坐标文件；方案三：将目标卫星影像规则分为九部分,方法同方案二,获得剔除欧式距离最大的30％的点后其余同名点的真实地理坐标文件,将此处的坐标文件与第一纠正地理坐标文件和第二纠正地理坐标文件合并后剔除重复点对作为用于校正所述目标卫星影像的第三纠正地理坐标文件；将三种方案得到的三种纠正地理坐标文件利用二次多项式方法分别用于目标卫星影像的几何校正,得到不同方案校正后的目标卫星影像；对目标卫星影像采用预设方案校正后的影像进行校正精度评估,以筛选出最优校正方案,并根据所述最优校正方案对所述目标卫星影像进行校正。</td>   <td>G06T5/00;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              陈家荣;              王自鑫;              粟涛;              胡炳翔;              陈润明;                   黄俊龙       </td>   <td>中山大学</td>   <td>一种基于高层次综合工具的深度学习模型优化方法及系统</td>   <td>广东省</td>   <td>CN113780553B</td>   <td>2023-11-07</td>   <td>本发明涉及深度学习技术领域,提出一种基于高层次综合工具的深度学习模型优化方法及系统,其中包括以下步骤：根据目标功能设计深度学习模型；获取训练样本,输入所述深度学习模型进行训练,得到深度学习模型的参数权值；根据所述深度学习模型的参数权值,通过高层次语言表示所述深度学习模型；对所述深度学习模型中的各层循环体进行优化；通过高层次综合工具将经过优化的深度学习模型进行联合仿真。本发明针对深度学习模型中的循环体进行循环展开以及流水线处理来缩短时延从而提升系统的吞吐量,从而降低深度学习模型的硬件功耗,且本发明中的深度学习模型经过高层次语言构建后,再通过高层次综合工具进行转换,能够有效缩短硬件设计的开发周期。</td>   <td>1.一种基于高层次综合工具的深度学习模型优化方法,其特征在于,包括以下步骤：根据目标功能设计深度学习模型；获取训练样本,输入所述深度学习模型进行训练,得到深度学习模型的参数权值；根据所述深度学习模型的参数权值,通过高层次语言表示所述深度学习模型；对所述深度学习模型中的各层循环体进行优化；其中,将循环体拆分为若干小循环体,再将循环体中各层循环下的自循环完全展开,最后对循环体进行流水线处理,以完成循环体的优化；通过高层次综合工具将经过优化的深度学习模型进行联合仿真,以及通过高层次综合工具对所述的深度学习模型的循环体进行循环流水优化；其中,对所述深度学习模型的循环体进行循环流水优化的步骤包括：判断所述深度学习模型的循环体是否为嵌套循环,若是,则将所述嵌套循环中各层循环下的子循环完全展开后再对子循环进行流水线处理；若否,则仅对最内层循环进行流水线处理。</td>   <td>G06N3/044;G06N3/0464;G06N3/08;G06F30/27;G06F111/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>              沈颖       </td>   <td>中山大学</td>   <td>一种图网络节点表示方法</td>   <td>广东省</td>   <td>CN114610950B</td>   <td>2023-11-07</td>   <td>本发明涉及图网络技术领域,具体涉及一种图网络节点表示方法,其包括：分别获取图网络中目标节点的属性交互表示向量和邻域聚合表示向量；将属性交互表示向量和邻域聚合表示向量进行拼接,得到图网络中目标节点的最终表示向量。本实施例考虑到图网络的邻域聚合机制从邻居节点中获取额外的信息补充节点自身的信息,使得所学得的目标节点表示具有更丰富的信息和更强的区分性。</td>   <td>1.一种图网络节点表示方法,其特征在于,包括：获取脑卒中的并发症,所述并发症为肺部感染,以脑卒中为中心节点,以肺部感染为邻居节点确定脑卒中和肺部感染的属性交互表示向量；分别获取图网络中目标节点的脑卒中和肺部感染的属性交互表示向量和脑卒中的邻域聚合表示向量；对于图网络；V表示网络所有节点的集合,E表示网络中边的集合,网络中节点和边的数量分别为/&gt;和/&gt;；所有节点的属性矩阵为：；F表示节点属性的维度,/&gt;表示节点的属性；通过嵌入表查找得到目标节点的所有非零属性对应的嵌入向量,获取所有嵌入向量组成嵌入向量集合/&gt;；/&gt;表示目标节点/&gt;的第/&gt;维属性值；采用二阶交互池化操作以点积方式计算二阶属性交互,将所述嵌入向量集合压缩为单个向量：          ；其中, 表示属性/&gt;和/&gt;之间的二阶交互关系；将所述单个向量输入全连接层,堆叠多个全连接层后,将最后一层的输出作为目标节点的属性交互表示向量/&gt;；所述全连接层为：          ；其中,为第/&gt;层权重矩阵, /&gt;为第/&gt;层偏移向量,/&gt;为非线性激活函数,表示堆叠多个全连接层后,最后一层的输出,/&gt;表示第/&gt;层的单个向量的值,表示第/&gt;层的单个向量的值,/&gt;表示第0层的单个向量的值,/&gt;表示多个全连接层后,最后一层的单个向量的值；计算目标节点/&gt;与邻居节点/&gt;的相关性/&gt;；          ；其中,ELU表示激活函数,表示目标节点经过图注意力层后输出的新的目标节点向量,T表示转置,/&gt;表示邻居节点经过图注意力层输出的新的邻居节点向量；通过softmax函数对所有与目标节点相邻的节点/&gt;的相关性/&gt;进行归一化,从而得到注意力权重系数/&gt;：          ；采用所述注意力权重系数对目标节点的所有邻居节点进行加权,得到目标节点的邻域聚合表示向量/&gt;,/&gt;表示与/&gt;相邻的邻居节点集合；r代表/&gt;里的任意一个节点；          ；其中,表示神经网络的第/&gt;层输出,/&gt;表示权重矩阵,/&gt;表示与/&gt;相邻的邻居节点集合,/&gt;和/&gt;分别表示第i和第j个神经网络节点的第/&gt;层的输出；将所述属性交互表示向量和邻域聚合表示向量进行拼接,得到图网络中目标节点的最终表示向量,以将最终表示向量展示给医生。</td>   <td>G06F16/901;G06N3/042;G06N3/0464;G06N3/045;G06N3/08;H04L41/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李荣昊;                   沈颖       </td>   <td>中山大学</td>   <td>模型训练方法、红外小目标检测方法、装置及电子设备</td>   <td>广东省</td>   <td>CN116152591B</td>   <td>2023-11-07</td>   <td>本申请公开了一种模型训练方法、红外小目标检测方法、装置及电子设备,其中的模型训练方法包括：利用特征增强网络对数据集进行图像超分辨率重构,利用改进YOLOv5模型进行模型训练时,结合Mosaic策略和Mixup策略对数据集进行数据增强,把增强数据集输入改进的YOLOv5模型进行训练；对YOLOv5模型的改进包括：在BackBone网络的特征层之间引入坐标注意力机制,在Neck网络增加浅层特征层P2,把Head网络中C3模块的BottleNeck块替换为Swin Transformer Block结构,训练得到的检测模型能够更好地把握图像的全局上下文信息,聚焦感兴趣的目标区域,解决过小目标过采样的特征丢失问题,有更好的鲁棒性。</td>   <td>1.一种模型训练方法,所述方法训练得到的模型用于红外小目标检测,包括：获取用于模型训练的数据集；利用特征增强网络对所述数据集进行超分辨率特征增强,得到第一增强数据集；对所述第一增强数据集进行二次数据增强得到第二增强数据集；所述二次数据增强的过程包括：利用Mosaic策略对所述第一增强数据集进行处理得到拼接图像；随机抽取设定数量的拼接图像,利用Mixup策略对拼接图像处理生成新的数据样本组成第二增强数据集；达到Mosaic策略的抽样次数要求时输出第二增强数据集；把所述第二增强数据集输入改进的YOLOv5模型进行模型训练,得到用于红外小目标检测的检测模型；所述改进的YOLOv5模型在BackBone网络引入坐标注意力机制,Neck网络增加浅层特征层P2,配合Head网络构成四层检测层,及,把Head网络中C3模块中的BottleNeck块替换为Swin Transformer Block结构形成C3STR模块,在所述Head网络中形成4个C3STR模块,所述4个C3STR模块分别和四种不同分辨率的检测头级联,形成多尺度的Swin Transformer检测头。</td>   <td>G06V10/774;G06V10/82;G06N3/08;G06T3/40;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李卓浩;              陆智超;                   郑子彬       </td>   <td>中山大学</td>   <td>图像阴影去除方法、装置、存储介质及设备</td>   <td>广东省</td>   <td>CN117011182A</td>   <td>2023-11-07</td>   <td>本申请提供图像阴影去除方法、装置、存储介质及设备,包括：获取阴影图像和阴影掩码图像,将所述阴影图像和阴影掩码图像输入Transformer模型的掩码深度融合模块,得到特征向量矩阵；将所述特征向量矩阵输入Transformer模型的注意力机制模块,得到去阴影图像。上述方法通过阴影掩码融合与Transformer模型多阶段融合,使Transformer模型将注意力集中在图像阴影区域的修复上,高效精确地得到去阴影图像。</td>   <td>1.一种图像阴影去除方法,其特征在于,包括：获取阴影图像和阴影掩码图像；将所述阴影图像和阴影掩码图像输入Transformer模型的掩码深度融合模块,得到特征向量矩阵；将所述特征向量矩阵输入Transformer模型的注意力机制模块,得到去阴影图像。</td>   <td>G06T5/00;G06V10/80;G06V10/82;G06N3/045;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张宁;              龙乐思;                   李俊炀       </td>   <td>中山大学</td>   <td>基于虚拟现实技术的古籍阅读方法、系统及其构建方法</td>   <td>广东省</td>   <td>CN112270768B</td>   <td>2023-11-03</td>   <td>本发明公开了一种基于虚拟现实技术的古籍阅读方法、系统及其构建方法,涉及虚拟现实技术领域。其中,方法包括：获取查阅指令,查找对应指令下的古籍内容；展示所述古籍内容；其中,所述古籍内容包括古籍原稿和书稿内容；读取所述古籍内容里文字信息,展示与所述文字信息匹配的标注内容；其中,标注内容分为知识元标注和故事线标注。本发明提出的基于虚拟现实技术的古籍阅读方法能够实现多感官阅读,提升读者的阅读体验、调动读者的阅读兴趣、帮助读者更好的理解书籍中的内容。</td>   <td>1.一种基于虚拟现实技术的古籍阅读方法,其特征在于,包括：获取通过VR手柄在VR头显的界面中给出的查阅指令,查找对应指令下的古籍内容；在VR头显的界面上展示所述古籍内容；其中,所述古籍内容包括古籍原稿和书稿内容；通过虚拟手执行与古籍交互的动作,读取所述古籍内容里文字信息,通过交互形式展示与所述文字信息匹配的标注内容；其中,所述标注内容包括知识元标注和故事线标注；其中,所述读取所述古籍内容里文字信息,通过交互形式展示与所述文字信息匹配的标注内容,包括：读取所述古籍内容里文字信息,通过主题分析法分析提取所述文字信息中的关键词和故事情节分别得到知识元和故事线；其中,所述知识元包括人物、物品、地点、时间和事件；根据所述知识元和所述故事线匹配相应的标注内容；所述知识元的标注内容包括文本、图片、视频、音频、3D/3D场景标注；所述故事线的标注内容包括故事线图谱、故事线语音讲解标注；所述故事线图谱包括第一级故事题名、第二级故事情节概述和第三级故事情节详细描述。</td>   <td>G06T19/00;G06T17/20;G06F3/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   熊少堂       </td>   <td>中山大学</td>   <td>一种降水预报空间效果可视化评估方法及系统</td>   <td>广东省</td>   <td>CN116992613A</td>   <td>2023-11-03</td>   <td>本发明涉及降水预报评估技术领域,提出一种降水预报空间效果可视化评估方法及系统,其中包括以下步骤：获取降水预报数据集,读取降水预报数据集中的降水数据和维度信息,并获取目标区域的矢量图形文件；降水数据包括预报降水数据和观测降水数据；根据维度信息和目标区域的矢量图形文件,从降水预报数据集中提取目标区域内的降水数据；根据目标区域内的降水数据绘制高维预报数据分析图；高维预报数据分析图包括按照时序匹配设置的预报降水数据和观测降水数据；根据目标区域内的降水数据,采用泰勒图评估降水预报数据集相应的降水预报模型在不同预见期、不同时间的预报效果,并将高维预报数据分析图和泰勒图进行可视化显示。</td>   <td>1.一种降水预报空间效果可视化评估方法,其特征在于,包括以下步骤：S1、获取降水预报数据集,读取所述降水预报数据集中的降水数据和维度信息,并获取目标区域的矢量图形文件；所述降水数据包括预报降水数据和观测降水数据；S2、根据所述维度信息和目标区域的矢量图形文件,从所述降水预报数据集中提取目标区域内的降水数据；S3、根据目标区域内的降水数据绘制高维预报数据分析图；所述高维预报数据分析图包括按照时序对应设置的预报降水数据和观测降水数据；S4、根据目标区域内的降水数据,采用泰勒图评估所述降水预报数据集相应的降水预报模型在不同预见期、不同时间的预报效果,并将所述高维预报数据分析图和泰勒图进行可视化显示。</td>   <td>G06F30/20;G06F119/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         匡铭;              翁宗鹏;              肖晗;              翁伟祥;              彭穗;              王伟;              陈淑玲;              刘施沂;              吴燕清;                   王依洁       </td>   <td>中山大学附属第一医院</td>   <td>一种多模态医学影像融合方法及系统</td>   <td>广东省</td>   <td>CN116993640A</td>   <td>2023-11-03</td>   <td>本发明公开了一种多模态医学影像融合方法及系统,包括：获取待处理的多个模态的医学影像序列,并对所有医学影像序列进行预处理,得到组合特征张量；其中,医学影像序列包括若干张超声图像、MRI图像或者CT图像；对组合特征张量进行语义特征提取得到序列语义特征矩阵,然后按照预设的孤立森林算法,基于序列语义特征矩阵中的各模态的序列语义特征,分析各医学影像序列之间的第一相似度,并根据所有第一相似度建立层级注意力结构；按照层级注意力结构,依次对各医学影像序列进行注意力加权计算,得到所有医学影像序列的融合结果。本发明在不需要对齐所有医学影像序列的模态的情况下根据用户需求,融合模态数不固定的多个模态的医学影像序列。</td>   <td>1.一种多模态医学影像融合方法,其特征在于,包括：获取待处理的多个模态的医学影像序列,并对所有所述医学影像序列进行预处理,得到一个组合特征张量；其中,所述医学影像序列包括若干张超声图像、MRI图像或者CT图像；对所述组合特征张量进行语义特征提取,得到对应的序列语义特征矩阵,然后按照预设的孤立森林算法,基于所述序列语义特征矩阵中的各所述模态的序列语义特征,分析各所述医学影像序列之间的第一相似度,并根据所有所述第一相似度,建立层级注意力结构；按照所述层级注意力结构,依次对各所述医学影像序列进行注意力加权计算,得到所有所述医学影像序列的注意力整合信息,以作为所有所述医学影像序列的融合结果。</td>   <td>G06T5/50;G06T5/00;G06V10/74;G06V10/82;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高峰;              丁俊翔;              刘俊伟;              盖宝文;              蔡都;              吴小剑;                   李亦学       </td>   <td>中山大学附属第六医院</td>   <td>一种基于多模态模型的癌症患者预后预测方法及装置</td>   <td>广东省</td>   <td>CN116994745A</td>   <td>2023-11-03</td>   <td>本申请属于癌症生存分析和预后预测技术领域,公开了一种基于多模态模型的癌症患者预后预测方法及装置,该方法包括：获取患者的待分析数字病理图像并预处理,得到病理图像数据；将病理图像数据输入训练好的多模态模型中；训练好的多模态模型包括病理图像模块、桥接网络、融合模块和风险评分模块；通过病理图像模块中的自注意力层和位置编码提取病理图像数据的病理特征；通过桥接网络根据病理特征进行推断,得到分子特征；通过融合模块对病理特征和分子特征进行融合,得到多模态融合特征；通过风险评分模块对多模态融合特征进行预测,得到患者的预测风险评分。本申请提高了预测风险评分的准确性,增强了本申请在临床应用中的实用性。</td>   <td>1.一种基于多模态模型的癌症患者预后预测方法,其特征在于,所述方法包括：获取患者的待分析数字病理图像并预处理,得到病理图像数据；将所述病理图像数据输入训练好的多模态模型中；所述训练好的多模态模型包括病理图像模块、桥接网络、融合模块和风险评分模块；通过所述病理图像模块中的自注意力层和位置编码提取所述病理图像数据的病理特征；通过所述桥接网络根据所述病理特征进行推断,得到分子特征；通过所述融合模块对所述病理特征和所述分子特征进行融合,得到多模态融合特征；通过所述风险评分模块对所述多模态融合特征进行预测,得到所述患者的预测风险评分。</td>   <td>G16H50/20;G16B40/00;G16H30/20;G06N3/0455;G06N3/048;G06N3/08;G06T7/00;G06T7/11;G06V10/26;G06V10/44;G06F18/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄乙涓;                   高羽       </td>   <td>中山大学附属第六医院</td>   <td>用于MMDS辅助诊断的M Index模型的构建方法及应用</td>   <td>广东省</td>   <td>CN116994762A</td>   <td>2023-11-03</td>   <td>本发明涉及一种用于MMDS辅助诊断的M Index模型的构建方法及应用。本发明以羊水细胞中的特定代谢产物作为检测指标,可快速获得检测结果,进而对患者罹患MMDS的风险进行合理诊断和评估,以及时进行干预或治疗,大大简化了临床检测流程,降低了医疗成本,可有效避免医疗资源的浪费。本发明的M Index模型对于填补实现多发性线粒体功能障碍综合征精准快速诊断评估的空白,更快速、更准确地实现对多发性线粒体功能障碍综合征癌患儿的个体化精准干预或治疗具有重要的现实意义,具有极高的社会价值和市场应用前景。</td>   <td>1. 一种用于多发性线粒体功能障碍综合征辅助诊断的M Index模型的构建方法,其特征在于,包括如下步骤：(1)分别从正常羊水和异常羊水中离心得到羊水细胞,接种于细胞培养皿中；7天后收获细胞,离心后弃上清；所述异常羊水为胎儿确诊为多发性线粒体功能障碍综合征的孕妇的羊水；(2)对离心弃上清后的羊水细胞进行萃取,离心后取上清液,得到羊水细胞提取物；(3)加入等体积的3-硝基苯肼甲醇溶液和1-(3-二甲氨基丙基)-3-乙基碳二亚胺吡啶溶液,混匀后加热进行衍生化,得到衍生化溶液；(4)衍生化溶液中加入分别经～(13)C标记的3-硝基苯肼甲醇溶液和1-(3-二甲氨基丙基)-3-乙基碳二亚胺吡啶溶液反应得到的同位素内标液；(5)加入甲醇-水混合溶液进行稀释后,进行代谢物分析；(6)对正常孕妇和确诊胎儿为多发性线粒体功能障碍综合征的孕妇这两组中各代谢物水平按照差异程度进行排序,筛选得到存在显著性差异的代谢物；(7)基于步骤(6)中筛选得到的多发性线粒体功能障碍综合征具有显著相关性的代谢物,并按照如下公式进行与并按照如下公式进行M Index的计算：M Index=∑～N-(i=1)(k-i×Level of metabolite-i)/N；其中N代表代谢物的数量,k-i表示各代谢物的系数,Level of metabolite-i表示各代谢物的相对水平。</td>   <td>G16H50/50;G16H50/30;G16H50/70;G01N33/92;G01N33/68</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张贺晔;              马成龙;              吴万庆;                   陈镇阳       </td>   <td>中山大学</td>   <td>心脏临床指标的检测方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN110400298B</td>   <td>2023-10-31</td>   <td>本申请提供了一种心脏临床指标的检测方法、装置、设备及介质,包括：利用人工神经网络的自学习能力,建立心脏MR图像与指定参数之间的对应关系；其中,指定参数包括心脏CT图像,针对心脏MR图像的心脏临床指标,以及针对心脏CT图像的心脏临床指标；获取患者的当前心脏MR图像；通过对应关系,确定与当前心脏MR图像对应的当前指定参数；具体地,确定与当前心脏MR图像对应的当前指定参数,包括：将对应关系中与当前心脏MR图像相同的心脏MR图像所对应的指定参数,确定为当前指定参数。可用于MR与CT的不同成像模态下多类型心脏临床指标的评估。挖掘和表征多类型心脏临床指标之间的复杂关系、获取任务相关性并且实现其在不同成像模态的转移。</td>   <td>1.一种心脏临床指标的检测方法,其特征在于,包括：利用人工神经网络的自学习能力,建立心脏MR图像与指定参数之间的对应关系,所述人工神经网络包括网络结构和网络参数,所述网络结构包括多任务学习神经网络和逆映射神经网络；其中,通过所述心脏MR图像及与该所述心脏MR图像对应的所述指定参数进行对所述人工神经网络的训练,通过第一判断器网络和第二判断器网络对所述人工神经网络的输入和输出参照进行对抗训练,获得训练完成的所述人工神经网络,其中,所述第一判断器网络和所述第二判断器网络两个依赖参数不同,结构相同,再基于该训练完成的所述人工神经网络的网络参数,对与所述心脏MR图像对应所述指定参数进行训练,从而获得所述心脏MR图像与所述指定参数之间的对应关系；其中,所述指定参数包括心脏CT图像,针对心脏MR图像的心脏临床指标,以及针对心脏CT图像的心脏临床指标；所述心脏临床指标包括：左心室外膜轮廓,左心室内膜轮廓,左心室肌轮廓,左心室外膜位置,左心室内膜位置,左心室肌位置,局部心腔壁厚度WT,心腔容积Dim,以及,心腔壁和心肌面积Area中的至少之一；所述建立心脏MR图像与指定参数之间的对应关系,包括：获取用于建立所述指定参数与所述心脏MR图像之间的对应关系的样本数据；分析所述心脏MR图像的特性及其规律,根据所述特性及其规律,确定所述人工神经网络的网络结构及其网络参数；使用所述样本数据,对所述网络结构和所述网络参数进行训练和测试,确定所述指定参数与所述心脏MR图像的所述对应关系；所述获取用于建立所述指定参数与所述心脏MR图像之间的对应关系的样本数据的步骤,包括：收集不同患者的心脏MR图像和指定参数；对所述心脏MR图像进行分析、并结合预存的专家经验信息,选取与所述指定参数相关的数据作为所述心脏MR图像；将所述指定参数、以及选取的所述心脏MR图像构成的数据对,作为样本数据；对所述网络结构和所述网络参数进行训练,包括：选取所述样本数据中的一部分数据作为训练样本,将所述训练样本中的所述心脏MR图像输入到所述网络结构,通过所述网络结构的激活函数和所述网络参数进行训练,得到实际训练结果；确定所述实际训练结果与所述训练样本中的相应指定参数之间的实际训练误差是否满足预设训练误差；当所述实际训练误差满足所述预设训练误差时,确定对所述网络结构和所述网络参数的所述训练完成；和/或,对所述网络结构和所述网络参数进行测试,包括：选取所述样本数据中的另一部分数据作为测试样本,将所述测试样本中的所述心脏MR图像输入到所述训练完成的所述网络结构中,以所述激活函数和所述训练完成的所述网络参数进行测试,得到实际测试结果；确定所述实际测试结果与所述测试样本中的相应指定参数之间的实际测试误差是否满足设定测试误差；当所述实际测试误差满足所述设定测试误差时,确定对所述网络结构和所述网络参数的所述测试完成；获取患者的当前心脏MR图像；通过所述对应关系,确定与所述当前心脏MR图像对应的当前指定参数；确定与所述当前心脏MR图像对应的当前指定参数,包括：将所述对应关系中与所述当前心脏MR图像相同的心脏MR图像所对应的指定参数,确定为所述当前指定参数。</td>   <td>G06T7/00;G16H50/30;G16H50/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;              谢雨琪;              张易东;                   熊宇涵       </td>   <td>中山大学</td>   <td>一种基于数字孪生的智慧城市绿化设计方法及装置</td>   <td>广东省</td>   <td>CN116090065B</td>   <td>2023-10-31</td>   <td>本发明涉及绿化规划与设计技术领域,公开了一种基于数字孪生的智慧城市绿化设计方法及装置。本发明根据目标城市绿化项目中需采集物理实体信息数据的目标数据类型建立相关的多元异构数据库；基于该数据库实时获取并存储该项目在建设过程中的物理实体信息数据,构建贯穿该项目全生命周期的虚拟数据孪生模型；基于该数据库中的时变数据调整该模型以实时反映相应物理实体的变化情况,并基于当前虚拟数据孪生模型对该项目的目标未来指标进行预测,进而输出绿化设计方案建议以提示用户；检测到方案调整指令被触发时相应调整绿化设计方案。本发明能够实现绿化设计方案的实时仿真预测与智能动态化调整,使数据信息得以从设计阶段传递至下一阶段。</td>   <td>1.一种基于数字孪生的智慧城市绿化设计方法,其特征在于,包括：确定目标城市绿化项目中需采集物理实体信息数据的目标数据类型,根据所述目标数据类型建立目标城市绿化项目相关的多元异构数据库；根据所述多元异构数据库,实时获取并存储所述目标城市绿化项目在建设过程中的各所述目标数据类型的物理实体信息数据；基于所述多元异构数据库构建贯穿所述目标城市绿化项目的全生命周期的目标虚拟数据孪生模型；基于所述多元异构数据库中的时变数据调整所述目标虚拟数据孪生模型以实时反映相应物理实体的变化情况,并基于当前的目标虚拟数据孪生模型对所述目标城市绿化项目的目标未来指标进行预测,基于得到的预测结果输出绿化设计方案建议以提示用户；所述目标未来指标包括目标植物的目标生长参数、目标植物的健康状态及目标环境参数；检测到方案调整指令被触发时相应调整所述目标城市绿化项目的绿化设计方案；所述方案调整指令在检测到物理实体约束条件发生改变或者接收到针对所述绿化设计方案建议的反馈信息时被触发；所述基于所述多元异构数据库构建贯穿所述目标城市绿化项目的全生命周期的目标虚拟数据孪生模型,包括：从所述多元异构数据库中提取地形数据、周边环境影像数据、植物数据、土壤数据、气候数据和居民数据；根据所述地形数据构建三维可视化城市环境,根据所述周边环境影像数据在所述三维可视化城市环境中补入相应的植物模型和公共设施,得到三维城市化景观模型；将所述植物数据、所述土壤数据、所述气候数据和所述居民数据绑定于所述三维城市化景观模型,得到相应的虚拟数据孪生模型；为所述虚拟数据孪生模型添加预置的对应物理实体间各类物体关系的智能预测算法,基于土壤数据、气候数据和居民数据训练并优化所述智能预测算法的准确性,以确定所述虚拟数据孪生模型的最优参数；其中,所述智能预测算法用于对所述目标未来指标进行预测；将优化得到的虚拟数据孪生模型与所述多元异构数据库建立连接,得到目标虚拟数据孪生模型。</td>   <td>G06F30/13;G06F30/20;G06T17/00;G06F16/23;G06F16/25;G06F16/51;G06Q10/0631;G06Q50/08;G06Q50/26;G06F111/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王甲海;              利国卿;                   陈思远       </td>   <td>中山大学</td>   <td>数据驱动的群体智能交互关系推断与演化计算方法</td>   <td>广东省</td>   <td>CN112269931B</td>   <td>2023-10-31</td>   <td>本发明为数据驱动的群体智能交互关系推断与演化计算方法,可准确预测群体智能系统中个体运动轨迹和状态。包括：通过具有关系交互机制的编码器模型,从群体智能系统的N个对象在T个时刻可观测轨迹数据中建模交互关系的分布；从离散的交互关系分布中采样出交互关系类型的特征向量；通过具有时空消息传递机制的解码器模型,根据可观测轨迹数据和交互关系类型的特征向量,学习动态演化规则并计算群体智能系统的未来状态；引入交互关系的对称性作为结构先验知识来实施软约束；多次训练模型参数直至收敛,获得损失函数值最小的模型作为最终模型,再推断出对象之间的交互关系,预测对象的运动轨迹和系统未来状态。</td>   <td>1.数据驱动的群体智能交互关系推断与演化计算方法,其特征在于,包括：S1、通过具有关系交互机制的编码器模型,从群体智能系统的N个对象在T个时刻可观测轨迹数据x中建模交互关系的分布；S2、从步骤S1中离散的交互关系分布中采样出交互关系类型的特征向量；S3、通过具有时空消息传递机制的解码器模型,根据可观测轨迹数据x和交互关系类型的特征向量,学习动态演化规则并计算群体智能系统的未来状态；S4、引入交互关系的对称性作为结构先验知识,即在损失函数中加入正则项来实施软约束；S5、多次训练模型参数直至收敛,获得损失函数值最小的模型作为最终模型；最终模型根据对象的历史轨迹数据,推断出对象之间的交互关系,进而预测对象的运动轨迹和群体智能系统的未来状态；可观测轨迹数据x为：                  其中表示第i个对象的轨迹序列,i＝1,…,N；/&gt;表示所有N个对象在t时刻的状态信息；步骤S1包括：S11、以每个对象的轨迹作为其在全连接图中的相应节点的特征,使用基于消息传递机制的图神经网络,为每对对象生成交互关系隐向量；S12：根据步骤S11得到的交互关系隐向量,使用基于序列模型的关系交互机制来捕获交互关系之间的依赖关系,从而进行交互关系的联合建模,得到融合了依赖关系的边缘特征向量；S13、根据融合了依赖关系的边缘特征向量,建模交互关系的分布；步骤S3包括：S31、根据可观测轨迹数据x和步骤S2得到的交互关系类型的特征向量,使用基于序列模型的关系级别的时空消息传递机制来计算关系隐状态；S32、使用基于序列模型的对象级别的时空消息传递机制来计算对象隐状态；S33、使用神经网络计算群体智能系统的未来演化状态；S34、演化计算群体智能系统未来多个时刻的预测值,得到群体智能系统的未来状态。</td>   <td>G06F16/9535;G06F16/9536;G06F16/9537;G06Q50/00;G06N3/0464;G06N3/047;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁朝峰;              欧云谋;              徐达政;              龚瑾;              张保豫;              吴登军;                   郭英       </td>   <td>中山大学附属第三医院</td>   <td>一种数字化颅脑标本血管模型重建方法</td>   <td>广东省</td>   <td>CN116402948B</td>   <td>2023-10-31</td>   <td>本发明公开了一种数字化颅脑标本血管模型重建方法,该方法包括以下步骤：获取离体的颅脑标本,将该颅脑标本的血管与体外循环灌注系统连接,启动体外循环灌注系统将造影剂灌注至颅脑标本的血管内形成闭环循环；采用扫描成像模块获取该颅脑标本的图像数据,并将该图像数据输入至数字化建模模块中,重建出含有血管信息的数字化颅脑标本三维模型,再对颅脑标本进行封存；将数字化颅脑标本三维模型导入手术导航模块进行处理,得到含有血管信息的数字化颅脑标本模型与离体的颅脑标本的一致性结果。本发明具有能够实现离体的颅脑标本的体外造影剂灌注循环以便于对该颅脑标本进行血管成像、进而得到含有血管信息的数字化颅脑标本模型的优点。</td>   <td>1.一种数字化颅脑标本血管模型重建方法,其特征在于,该方法包括以下步骤：S1、获取离体的颅脑标本,将该颅脑标本的颈总动脉和椎动脉与体外循环灌注系统(1)的输出端连接,将该颅脑标本的血管的颈内静脉与体外循环灌注系统(1)的输入端连接,启动体外循环灌注系统(1)工作将造影剂灌注至颅脑标本的血管内形成闭环循环以实现离体的颅脑标本的体外造影剂灌注循环；S2、在颅脑标本的体外造影剂灌注循环的作用下使造影剂在血管内正常流动,采用扫描成像模块(2)获取该颅脑标本的图像数据并将该图像数据输入至数字化建模模块(3)中重建出含有血管信息的数字化颅脑标本三维模型,再对颅脑标本的血管的颈总动脉以及椎动脉、颈内静脉分别灌注预设比例的不同染料的乳胶悬液进行封存；S3、将重建得到的数字化颅脑标本三维模型导入手术导航模块(4)中,利用手术导航模块(4)显示数字化颅脑标本三维模型,同时指引数字化颅脑标本三维模型的血管位置并将该血管位置与解剖的血管的实际空间位置按照预设的标准进行对比,从而得到对比的偏移结果,当偏移结果不符合预设的对比标准时,则数字化颅脑标本三维模型的血管与真实血管实际空间位置不吻合,反之,则数字化颅脑标本三维模型的血管与真实血管实际空间位置相吻合,进而得到含有血管信息的数字化颅脑标本三维模型与离体的颅脑标本的一致性结果；所述体外循环灌注系统(1)包括电动输注泵(10),所述电动输注泵(10)的输出端通过一输液管(20)与离体颅脑标本的血管的颈总动脉和椎动脉连接,所述电动输注泵(10)的输入端通过一连接管(30)连接有一用于加入和回收造影剂的储液器(40),所述储液器(40)的输入端通过一回液管(50)与离体颅脑标本的颈内静脉连接,还在所述回液管(50)上设有一用于防止离体颅脑标本内的引出残留组织堵塞管腔的滤网(60)。</td>   <td>G06T17/00;G06T19/20;G16H30/40;G09B23/30;G09B23/28</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈定安;              彭雄;              李名豪;                   王玉立       </td>   <td>中山大学</td>   <td>适用于移动生产线上的坚果智能检测方法及系统</td>   <td>广东省</td>   <td>CN116977274A</td>   <td>2023-10-31</td>   <td>本发明涉及不规则物体的计量和图像识别领域,公开了一种适用于移动生产线上的坚果智能检测方法及系统,包括使用Azure Kinect相机采集坚果点云数据并进行降噪、点云裁剪预处理；将背景点云和坚果点云分割进行分割；对背景点云进行平面拟合,再将其旋转至基准面；搜素局部点云最高点为单个坚果顶点；利用Horn’s Method算法进行配准；提出PNN算法将多个坚果点云分割为单个坚果点云；基于改进的SBF算法对单个坚果点云边缘噪声进行去除；基于最小二乘椭球拟合算法拟合去噪后单个坚果点云拟合参数求得坚果体积；结合光学图像和热红外图像获取坚果缺陷位置；本发明可广泛应用于不规则三维物体的计量和识别领域。</td>   <td>1.适用于移动生产线上的坚果智能检测方法,其特征在于,包括以下步骤：使用Azure Kinect相机采集坚果点云数据并进行降噪、点云裁剪预处理；基于点云颜色阈值将背景点云和坚果点云进行分割；对背景点云进行平面拟合,再将背景点云和坚果点云旋转至基准面；基于K最近邻点搜索方法,搜素局部点云最高点为单个坚果顶点；利用不同帧单个坚果点云最高点基于Horn’s Method算法进行配准；提出PNN算法将多个坚果点云分割为单个坚果点云；基于改进的SBF算法对单个坚果点云边缘噪声进行去除；基于最小二乘椭球拟合算法拟合去噪后单个坚果点云,根据拟合参数求得坚果体积和/或长宽表型参数；结合光学图像和热红外图像,基于Faster R-CNN网络对传送带上的坚果进行动态品质检测,定位坚果缺陷位置。</td>   <td>G06T7/00;G06T7/194;G06T5/00;G06T7/30;G06T7/70;G06N3/0464;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林铎儒;              林桢哲;              林浩添;              李明远;                   李龙辉       </td>   <td>中山大学中山眼科中心</td>   <td>眼底图像质量评估及优化的方法、装置、终端及存储介质</td>   <td>广东省</td>   <td>CN116977298A</td>   <td>2023-10-31</td>   <td>本发明公开了一种眼底图像质量评估及优化的方法、装置、终端及存储介质,包括：将获取的待检测婴幼儿的眼底图像输入至预设的眼底图像质量评估模型中,以使所述眼底图像质量评估模型,识别所述眼底图像所属的眼球部位；并输出所述眼底图像所属的眼球部位对应的评估结果。根据所述评估结果通过预设的公式计算所述眼底图像对应的图像质量连续性评分。通过所述眼底图像的评估结果以及图像质量连续性评分生成眼底图像的最终评价结果,根据所述最终评价结果,对所述待检测婴幼儿的眼底图像进行定向优化,输出优化后的眼底图像。</td>   <td>1.一种眼底图像质量评估及优化的方法,其特征在于,包括：获取待检测婴幼儿的眼底图像；将所述待检测婴幼儿的眼底图像输入至预设的眼底图像质量评估模型中,以使所述眼底图像质量评估模型,识别所述眼底图像所属的眼球部位；在确定所属的眼球部位为后极部时,输出眼底图像所对应的黄斑亮度、黄斑清晰度、视盘亮度、视盘清晰度、其余视网膜区域亮度以及其余视网膜区域清晰度的评估结果；在确定所属的眼球部位为周边部时,输出所述待检测眼底图像所对应的完整性、亮度和清晰度的评估结果；根据所述眼底图像质量评估模型输出的评估结果,通过以下公式计算得到所述待检测婴幼儿的眼底图像的图像质量连续性评分；                  其中,IQCS为图像质量连续性评分；k表示所述眼底图像对应的评价维度的数量；P-i是所述眼底图像在第i个评价维度不符合预设要求时的概率；w-i表示满足的权重系数；根据所述图像质量连续性评分以及所述眼底图像质量评估模型输出的评估结果,生成所述待检测婴幼儿的眼底图像的最终评价结果；根据所述最终评价结果,对所述待检测婴幼儿的眼底图像进行定向优化,输出优化后的眼底图像。</td>   <td>G06T7/00;G06V40/18;G06T5/00;G06V10/764;G06V20/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王佳琪;              邓铮渝;                   王弋航       </td>   <td>中山大学</td>   <td>一种重叠颗粒物的分离和轮廓重建方法及系统</td>   <td>广东省</td>   <td>CN116977476A</td>   <td>2023-10-31</td>   <td>本发明公开了一种重叠颗粒物的分离和轮廓重建方法及系统,该方法包括：对图片进行背景分离；然后对目标颗粒物进行轮廓跟踪提取,利用提取轮廓计算几何特征；接着根据几何特征筛对提取轮廓进行筛选,对筛选轮廓进行凸包检测,得到重叠颗粒物凸缺陷；最后对重叠颗粒物凸缺陷进行分割点对匹配和轮廓拟合重建,得到颗粒物重建轮廓。该系统包括：预处理模块、轮廓提取模块、几何计算模块、轮廓筛选模块、凸包检测模块、匹配模块和拟合重建模块。通过使用本发明,能够将重叠颗粒物从所有颗粒物中筛选出来并且较好地分离,还可以对残缺地轮廓进行较好较精确的拟合,最终实现计数。本发明可广泛应用于数字图像处理技术领域。</td>   <td>1.一种重叠颗粒物的分离和轮廓重建方法,其特征在于,包括以下步骤：对图像进行背景分离,得到预处理图像；对预处理图像进行轮廓跟踪提取,得到提取轮廓；对提取轮廓进行几何计算,得到轮廓几何特征；基于几何特征设立判断因子对提取轮廓进行筛选,得到重叠颗粒物轮廓；对重叠颗粒物轮廓进行凸包检测,得到重叠颗粒物凸缺陷；对重叠颗粒物凸缺陷进行分割点对匹配,得到残缺的颗粒物轮廓；对残缺的颗粒物轮廓进行拟合重建,得到颗粒物重建轮廓。</td>   <td>G06T11/20;G06T7/194;G06V10/44;G06T7/60;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;                   洪赛丁       </td>   <td>中山大学</td>   <td>基于小波变换和迁移学习的视网膜OCT图像分类方法</td>   <td>广东省</td>   <td>CN110472530B</td>   <td>2023-10-31</td>   <td>本发明属于计算机视觉、医学图像处理技术领域,为基于小波变换和迁移学习的视网膜OCT图像分类方法,包括步骤：对视网膜OCT图像进行小波变换,得到低频细节分量、水平细节分量、垂直细节分量、对角线细节分量四条子带；对四条子带的图像,基于迁移学习进行子带特征的提取；将所提取的四个子带图像的特征进行级联和特征融合,然后将级联和特征融合后的特征作为训练集输入到随机森林中,进行训练、分类和预测结果。本发明充分利用了视网膜OCT图像原本的信息,在一定程度上能减少训练参数、加速运行,提高最终分类预测的准确率。</td>   <td>1.基于小波变换和迁移学习的视网膜OCT图像分类方法,其特征在于,包括步骤：S1、对视网膜OCT图像进行小波变换,得到低频细节分量、水平细节分量、垂直细节分量、对角线细节分量四条子带；S2、对四条子带的图像,基于迁移学习进行子带特征的提取；基于迁移学习进行子带特征的提取时,使用基于ImageNet数据预训练权重初始化的深度残差网络作为特征提取器,并去掉该网络全连接层和softmax层；S3、将所提取的四个子带图像的特征进行级联和特征融合,然后将级联和特征融合后的特征作为训练集输入到随机森林中,进行训练、分类和预测结果；步骤S1将视网膜OCT图像经过2维离散小波变换,选用的小波为多贝西小波；所述2维离散小波变换的公式为：                                    其中W-Ψ和W-φ分别是小波系数和尺度系数,Ψ是小波函数,φ是尺度函数,f(m,n)是在m,n位置的特征图,k、l是小波位置,M、N是特征维度,H、V、D分别代表水平细节分量、垂直细节分量、对角线细节分量,j和j-0表示阶数。</td>   <td>G06V10/764;G06V40/18;G06V10/77;G06V10/774;G06V10/82;G06N3/0464;G06N3/048;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王静雯;              刘江;                   袁进       </td>   <td>广州视源电子科技股份有限公司;中国科学院宁波工业技术研究院慈溪生物医学工程研究所;中山大学中山眼科中心</td>   <td>一种图像分级方法、装置、设备和存储介质</td>   <td>广东省</td>   <td>CN111402217B</td>   <td>2023-10-31</td>   <td>本发明公开了一种图像分级方法、装置、设备和存储介质。该方法包括：确定原始AS-OCT图像对应的原始三维图像；将原始三维图像对应的第一预设个数尺度的中间三维图像依次输入至对应预设3D卷积神经网络,得到对应的一维向量；根据第一预设个数的一维向量计算得到对应的输出结果；根据输出结果和预先配置的浑浊类别确定原始AS-OCT图像的浑浊程度。本发明通过从不同角度拍摄原始AS-OCT图像,可以提取并学习到图像中的更多特征,有效提升了网络分类的精度；同时,通过构建多尺度的3D卷积神经网络,以将原始三维图像对应的多个尺度的中间三维图像输入至对应预设3D卷积神经网络中,从而将全局特征和局部特征相融合有利于网络挖掘到更具有辨别性的特征信息。</td>   <td>1.一种图像分级方法,其特征在于,包括：确定原始眼前段光学相干断层扫描AS-OCT图像对应的原始三维图像；将所述原始三维图像对应的第一预设个数不同尺度的中间三维图像依次输入至对应预设3D卷积神经网络,得到对应的一维向量；其中,所述预设3D卷积神经网络的数量与所述中间三维图像的数量是相同的；根据所述第一预设个数的一维向量计算得到对应的输出结果；根据所述输出结果和预先配置的浑浊类别确定所述原始AS-OCT图像的浑浊程度；所述确定原始AS-OCT图像对应的原始三维图像,包括：获取待检测用户中第二预设个数的原始AS-OCT图像；对所述第二预设个数的原始AS-OCT图像进行裁剪,得到对应的中间AS-OCT图像；将每个所述中间AS-OCT图像进行组合,得到对应的原始三维图像；所述将所述原始三维图像对应的第一预设个数不同尺度的中间三维图像依次输入至对应预设3D卷积神经网络,得到对应的一维向量,包括：将所述原始三维图像对应每个尺度的中间三维图像依次输入至对应预设3D卷积神经网络的第一卷积层、第二卷积层、第三卷积层、第四卷积层和第五卷积层,得到对应的一维向量；所述根据所述第一预设个数的一维向量计算得到对应的输出结果,包括：将所述第一预设个数的一维向量相加,得到对应的累加值；将所述累加值输入至第一预设个数的所述预设3D卷积神经网络共同对应的全连接层,得到对应的输出结果。</td>   <td>G06T7/00;G06T17/00;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         裴杰;              刘一博;                   邹耀鹏       </td>   <td>中山大学</td>   <td>一种作物产量统计数据降尺度方法</td>   <td>广东省</td>   <td>CN116432859B</td>   <td>2023-10-27</td>   <td>本申请涉及一种作物产量统计数据降尺度方法,其包括在研究时间范围内获取遥感变量影像数据；使用农作物空间分布数据对所述遥感变量影像数据进行掩膜处理,提取待估产区域；求取所述待估产区域的像元在县级尺度行政单元中的平均值,并获取待估产区域内各县各年的作物单产统计数据,得到模型训练自变量和模型训练因变量；构建Cubist模型；将所述模型训练因变量和所述模型训练自变量输入所述Cubist模型进行训练,输出达到预设精度的Cubist模型,作为产量预估模型；采用所述产量预估模型反演研究区域内像素尺度的农作物产量,获取更高分辨率的作物产量网格数据集。本申请具有提高产量预估模型预测精度的技术效果。</td>   <td>1.一种作物产量统计数据降尺度方法,其特征在于,包括以下步骤,在研究时间范围内获取各期的气象数据、植被指数数据和土壤数据,以及一期高程数据,作为遥感变量影像数据；使用农作物空间分布数据对所述遥感变量影像数据进行掩膜处理,提取待估产区域；求取所述待估产区域的像元在县级尺度行政单元中的平均值,得到与每个县区、每一年相对应的多元变量的统计数据,作为模型训练自变量,以及,将各县区待预测年份的前若干年产量数据作为模型训练自变量,并获取待估产区域内各县各年的作物单产统计数据,作为模型训练因变量；基于M5模型树的拓展算法,预设模型树组的数量参数和最近邻样本的数量参数,构建Cubist模型；将所述模型训练因变量和所述模型训练自变量输入所述Cubist模型进行训练,并进行精度验证,直至验证结果满足预设条件,输出达到预设精度的Cubist模型,作为产量预估模型；采用所述产量预估模型反演研究区域内像素尺度的农作物产量,获取作物产量网格数据集；还包括以下步骤,基于所述产量预估模型生产空间分布图,包括,采用最邻近的重采样方法,统一所述待估产区域各变量影像的分辨率；将相同分辨率的各变量影像的数据组成影像集合,逐像元提取所述影像集合中各像元的值,作为第一反演自变量；将各县待预测年份之前两年的产量数据制成分辨率相同的栅格影像数据加入所述影像集合,作为第二反演自变量；将所述第一反演自变量和所述第二反演自变量输入所述产量预估模型中,反演各变量影像的像素的产量值,生成研究区域内像素尺度的产量空间分布图；所述使用农作物空间分布数据对所述遥感变量影像数据进行掩膜处理的步骤前,先对每种变量的各期影像在目标作物生长季内做聚合处理,包括对与温度相关数据和与降水相关数据,在各生长阶段内求累积值；对植被指数数据和干旱指数数据,在各生长阶段内求平均值。</td>   <td>G06Q10/04;G06Q50/02;G06F18/214;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         涂朝勇;              陈淑敏;                   黎伟标       </td>   <td>中山大学</td>   <td>一种台风灾害评估方法、系统及装置</td>   <td>广东省</td>   <td>CN112418718B</td>   <td>2023-10-27</td>   <td>本发明公开了一种台风灾害评估方法、系统及装置,该方法包括：实时获取洋面台风信息和气象台的台风路径信息,得到台风信息和路径信息；根据台风信息、路径信息和预设规则判断对评估区域是否存在影响,并根据判断结果对评估区域进行实时预评估,得到预评估结果；根据预评估结果对评估区域进行灾情评估并生成评估报告。该系统包括：信息获取模块、预评估模块和评估报告生成模块。该装置包括存储器以及用于执行上述台风灾害评估的处理器。通过使用本发明,较为直观的看出台风灾害所致的破坏总程度。本发明作为一种台风灾害评估方法、系统及装置,可广泛应用于气象监测领域。</td>   <td>1.一种台风灾害评估方法,其特征在于,包括以下步骤：实时获取洋面台风信息和气象台的台风路径信息,得到台风信息和路径信息；所述实时获取洋面台风信息和气象台的台风路径信息,得到台风信息和路径信息这一步骤,其具体包括；实时获取洋面上台风信息,判断到有台风生成或已有台风生成但台风路径发生转变,采集台风路径预报信息,得到台风信息和路径信息；根据台风信息、路径信息和预设规则判断对评估区域是否存在影响,并根据判断结果对评估区域进行实时预评估,得到预评估结果；所述根据台风信息、路径信息和预设规则判断对评估区域是否存在影响,并根据判断结果对评估区域进行实时预评估,得到预评估结果这一步骤,其具体包括；根据台风信息和路径信息得到台风影响中心；判断到台风影响中心与评估区域的距离大于预设值,预评估结果为无影响；判断到台风影响中心与评估区域的距离小于预设值,获取实况和预报中心的降雨数据、风速数据和评估区域当前累计降雨量并给出台风强度,得到预评估结果；根据预评估结果对评估区域进行灾情评估并生成评估报告；所述根据预评估结果对评估区域进行灾情评估并生成评估报告这一步骤,其具体包括；根据预评估结果得到台风过程中的最低气压、最大风速、最大暴雨占比、过程累计面雨量、移动距离和持续时间的历史数据因子；将历史数据因子输入到预训练的投影寻踪聚类模型,得到各因子的特征向量；根据各因子的特征向量得到整个台风过程的台风强度特征值；根据台风强度特征值与台风历史数据匹配,得到相应的经济损失；将相应的经济损失结合经济增长速率得到预估的经济损失；将风过程中的最低气压、最大风速、最大暴雨占比、过程累计面雨量、移动距离、持续时间和预估的经济损失结合,生成评估报告；所述评估报告包括影响时段、降水强度、风速大小和预估损失。</td>   <td>G06Q10/0635;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭应林;              刘懿梅;              陈美宁;              陈利;                   邓小武       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种锥形束CT图像配准结果评价方法及系统</td>   <td>广东省</td>   <td>CN116188377B</td>   <td>2023-10-27</td>   <td>本发明公开了一种锥形束CT图像配准结果评价方法及系统,通过获取计划CT图像与CBCT图像的配准数据,配准数据包括计划靶区体积、靶区体积、计划CT体积和治疗前摆位CBCT图像中相应结构的体积,根据所述计划靶区体积和靶区体积得到计划靶区体积和靶区体积的覆盖率,根据计划CT体积和治疗前摆位CBCT图像中相应结构的体积得到相似性指数,通过相似性指数、靶区覆盖因子、危及器官安全因子、权重因子和各个器官的配准效果因子构建综合配准因子评价模型,将配准数据代入综合配准因子评价模型中得到综合配准得分,本方法通过设立和计算了不同解剖结构的配准权重因子,形成了可以量化评分的加权综合评价数学模型对配准结果进行评价,可以提高临床配准效果。</td>   <td>1.一种锥形束CT图像配准结果评价方法,其特征在于,包括：获取计划CT图像与CBCT图像的配准数据,其中,所述配准数据包括计划靶区体积、靶区体积、计划CT体积和治疗前摆位CBCT图像中相应结构的体积；根据所述计划靶区体积和靶区体积得到计划靶区体积和靶区体积的覆盖率,根据所述计划CT体积和治疗前摆位CBCT图像中相应结构的体积得到相似性指数；通过相似性指数、靶区覆盖因子、危及器官安全因子、权重因子和各个器官的配准效果因子构建综合配准因子评价模型,将所述配准数据代入所述综合配准因子评价模型中得到综合配准得分；所述通过相似性指数、靶区覆盖因子、危及器官安全因子、权重因子和各个器官的配准效果因子构建综合配准因子评价模型,将所述配准数据代入所述综合配准因子评价模型中得到综合配准得分,具体为：通过相似性指数、靶区覆盖因子、危及器官安全因子、权重因子和各个器官的配准效果因子构建综合配准因子评价模型,公式为：                  其中,DSC-(GTV)和DSC-(OARi)分别表示计划CT图像中相应靶区和危及器官与治疗摆位的在线CBCT图像中相应靶区和危及器官之间的相似性指数,F-(GTV)表示靶区覆盖因子,F-(OARi)表示危及器官安全因子,w-(GTV)和w-(OARi)表示权重因子,K-(GTV)和K-(OARi)表示各个解剖结构的配准效果因子,K-(GTV)和K-(OARi)分别为各个危及器官的手工配准平均相似性指数平均值与实际待评价配准的危及器官相似性指数的比值；将所述配准数据代入综合配准因子评价模型根据预设计算规则进行计算得到综合配准得分；所述预设计算规则,具体为：若计划CT靶区体积对治疗时CBCT图像上的靶区体积的覆盖率不是100％,则F-(GTV)＝0,若计划靶区体积对治疗时CBCT图像上的靶区体积的覆盖率是100％,则F-(GTV)＝1；若SBRT治疗时计划CT靶区体积范围没有与摆位配准后的CBCT危及器官重叠,则F-(OARi)＝1,反之,若SBRT治疗时所述计划CT靶区体积与所述摆位配准后的危及器官发生重叠,则F-(OARi)＝0；若是常规放射治疗,则F-(OARi)＝1。</td>   <td>G06T7/00;G06T7/62;G06T7/32</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈彦文;              韩裘辰;              刘剑鸿;              谢源丰;              张贤德;                   余向阳       </td>   <td>广州市高科通信技术股份有限公司;中山大学</td>   <td>远红外与可见光视频图像融合的行为分析方法</td>   <td>广东省</td>   <td>CN114120176B</td>   <td>2023-10-27</td>   <td>本发明公开了一种远红外与可见光视频图像融合的行为分析方法,包括以下步骤：对预先获取的红外视频文件和可见光视频文件分别进行帧图像提取,得到红外热成像图像和可见光图像；对红外热成像图像和可见光图像分别进行图像增强；对图像增强后的红外热成像图像和可见光图像分别进行配准；采用预设生成对抗网络对配准后的红外热成像图像和可见光图像进行融合,得到目标融合图像；采用预设目标检测模型对目标融合图像进行目标检测,得到红外视频文件和可见光视频文件内的用户行为。本发明有效保留红外热成像图像和可见光图像的特征,有效提高红外图像和可见光图像的融合结果的准确性。本发明可广泛应用于图像融合技术领域。</td>   <td>1.一种远红外与可见光视频图像融合的行为分析方法,其特征在于,包括以下步骤：对预先获取的红外视频文件和可见光视频文件分别进行帧图像提取,得到红外热成像图像和可见光图像；对所述红外热成像图像和所述可见光图像分别进行图像增强；对图像增强后的所述红外热成像图像和所述可见光图像分别进行配准；采用预设生成对抗网络对配准后的所述红外热成像图像和所述可见光图像进行融合,得到目标融合图像；所述预设生成对抗网络包括生成器和判别器；所述生成器包括5*5的卷积层、1*1的残差层、3*3的池化层、批标准化层和激活函数；所述判别器包括5*5的卷积层、5*5的池化层和线性分类层；采用预设目标检测模型对所述目标融合图像进行目标检测,得到所述红外视频文件和所述可见光视频文件内的用户行为；其中,所述对所述红外热成像图像进行图像增强,包括：对所述红外热成像图像进行多级二维离散小波变换,得到所述红外热成像图像对应近似信号的低频子带和所述红外热成像图像对应细节信号的高频子带；对所述高频子带采用如下公式进行小波去噪：                            表示高频去噪后的信号系数；/&gt;为阈值；/&gt;表示符号函数；/&gt;为小波系数；i=1,…,/&gt;；j=1,…,/&gt;；对所述低频子带采用如下公式进行非线性图像增强：                            表示增强后低频图像的小波系数,/&gt;表示增强前的小波系数,ENG表示非线性增强算子,/&gt;和/&gt;分别表示红外热成像图像的长和宽；k为亮度系数,用于调节整个图像的动态范围；根据图像增强后的所述低频子带和小波去噪后的所述高频子带进行小波重构。</td>   <td>G06V20/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张荣辉;                   杨尚谕       </td>   <td>中山大学</td>   <td>一种道路积水区域检测方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116958811A</td>   <td>2023-10-27</td>   <td>本发明公开了一种道路积水区域检测方法、系统、设备及介质,该方法包括：获取待检测道路图像；通过路面状态识别模型对所述待检测道路图像中的路面状态进行检测,得到道路类别标签；所述道路类别标签包括干燥、湿润和积水；所述路面状态识别模型采用分类网络；判断所述道路类别标签是否为积水；若是,则通过道路积水区域定位模型对具有积水标签的待检测道路图像进行分割,得到积水区域分割图；若否,则将所述道路类别标签输出；其中,所述道路积水区域定位模型采用在编码器中引入反射注意力模块的语义分割网络；所述反射注意力模块采用基于积水的反射特性而引入注意力机制的卷积神经网络。本发明具有高效率,高精度,多场景,鲁棒性强的特点。</td>   <td>1.一种道路积水区域检测方法,其特征在于,包括：获取待检测道路图像；通过路面状态识别模型对所述待检测道路图像中的路面状态进行检测,得到道路类别标签；所述道路类别标签包括干燥、湿润和积水；所述路面状态识别模型采用分类网络；判断所述道路类别标签是否为积水；若是,则通过道路积水区域定位模型对具有积水标签的待检测道路图像进行分割,得到积水区域分割图；若否,则将所述道路类别标签输出；其中,所述道路积水区域定位模型采用在编码器中引入反射注意力模块的语义分割网络；所述反射注意力模块采用基于积水的反射特性而引入注意力机制的卷积神经网络。</td>   <td>G06V20/10;G06V10/82;G06V10/26;G06V10/764;G06N3/0464;G06N3/0455;G06N3/047;G06N3/048;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         侯卫生;              常慧;              刘恒光;              陈勇华;              刘成军;                   王典       </td>   <td>中山大学;广州地铁设计研究院股份有限公司</td>   <td>一种融合马尔可夫链和多点统计学的地质建模方法和装置</td>   <td>广东省</td>   <td>CN116958470A</td>   <td>2023-10-27</td>   <td>本发明公开了一种融合马尔可夫链和多点统计学的地质建模方法和装置,所述方法包括：利用指示函数提取出三维网格图像中的转移面中的若干个非平稳地质特征和平稳地质特征,并基于马尔可夫链模型和反距离加权法得到在所述待模拟区域中各模拟点的概率分布,构建出所有非平稳特征对应的非平稳地质结构三维模型；将非平稳地质结构三维模型作为硬约束数据,并基于多尺度策略并根据最大期望算法对初始三维地质模型进行迭代优化,直至累计迭代次数达到预设迭代次数时,得到最终的三维地质模型。本发明通过融合马尔可夫链和反距离加权思想来明确地质剖面结构信息之间的耦合机制,并且能够更有效地重建出非平稳地质特征的空间结构。</td>   <td>1.一种融合马尔可夫链和多点统计学的地质建模方法,其特征在于,包括：获取目标二维地质剖面；将目标二维地质剖面导入到三维模拟网格中,得到所述目标二维地质剖面在三维空间中表示的二维网格图像,并通过三维模拟网络将所述二维网格图像转换为三维网格图像；利用指示函数对三维网格图像中的非平稳地质结构和平稳地质结构进行分别标识；对于所述三维网格图像中的每一与三维网格图像平行的转移面,提取出转移面中的若干个非平稳地质特征和若干个平稳地质特征,并设置所有非平稳特征对应的待模拟区域的尺寸,基于马尔可夫链模型和反距离加权法得到在所述待模拟区域中各模拟点的概率分布,采用随机抽样方法对各模拟点进行抽样得到若干选定模拟点,基于若干选定模拟点在所述待模拟区域中构建出所有非平稳特征对应的非平稳地质结构三维模型；基于多点统计学算法,从三维网格图像中提取各地质结构的空间分布模式,并基于各空间分布模式建立地质对象空间模式数据库,根据所述空间模式数据库对所述初始地质模型进行序贯模拟,得到初始三维地质模型；将非平稳地质结构三维模型作为硬约束数据,基于多尺度策略并根据最大期望算法对初始三维地质模型进行迭代优化,直至累计迭代次数达到预设迭代次数时,得到最终的三维地质模型。</td>   <td>G06T17/05;G06T17/20;G06N7/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨剑达;              赖韩江;                   印鉴       </td>   <td>中山大学</td>   <td>一种代码重构方法、系统、计算机设备及介质</td>   <td>广东省</td>   <td>CN116954594A</td>   <td>2023-10-27</td>   <td>本申请公开了代码重构方法、系统、计算机设备及介质,所述方法包括：构建代码编辑器,该代码编辑器设置有代码风格选项,向代码编辑器输入待重构代码片段,按照所重构的代码风格,将内置的chatGPT提示语与待重构代码片段进行拼接,得到对应代码风格的chatGPT请求。将chatGPT请求重复多次输入所述chatGPT模块,由chatGPT模块返回所述chatGPT请求对应的应答内容；对每次返回的应答内容进行抽取处理,得到多个重构代码片段,并对重构代码片段排序评分。本申请提供的代码重构方法针对特定风格的代码重构,不需要重新编写专门的程序,且使用门槛低,智能化和个性化程度高,代码重构效率高。</td>   <td>1.一种代码重构方法,其特征在于,所述方法包括：构建代码编辑器,并向所述代码编辑器输入待重构代码片段；所述代码编辑器设置有代码风格选项,所述代码风格至少包括：谷歌代码风格、函数式编程风格和面向对象风格；按照所重构的代码风格,将内置的chatGPT提示语与所述待重构代码片段进行拼接,得到对应代码风格的chatGPT请求；将所述chatGPT请求重复多次输入所述chatGPT模块,由所述chatGPT模块返回所述chatGPT请求对应的应答内容；对每次返回的应答内容进行抽取处理,得到多个重构代码片段。</td>   <td>G06F8/36;G06F8/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李聪端;              龙洋;                   张彩玉       </td>   <td>中山大学;中山大学·深圳</td>   <td>一种基于社区聚类的谣言传播溯源方法及系统</td>   <td>广东省</td>   <td>CN116955844A</td>   <td>2023-10-27</td>   <td>本发明公开了一种基于社区聚类的谣言传播溯源方法及系统,包括：对待溯源的感染子图进行社区聚类,以获得对应的社区关系图；通过社区关系图对应的节点源的ML估计器,对社区关系图中的各个第一社区的谣言传播可能性进行估计分析,确定社区关系图中的源社区；根据源社区的若干个边界节点,对源社区进行修正,以获得对应的社区展开图,并通过社区展开图对应的节点源的ML估计器,对社区展开图中的各个第一节点的谣言传播可能性进行估计分析,确定社区展开图中的源节点,以实现对感染子图的谣言传播溯源。本发明通过对待溯源的感染子图进行社区聚类,以优化感染子图的社区关系,减少需要溯源的感染节点的数量级,从而提升整体的溯源效率。</td>   <td>1.一种基于社区聚类的谣言传播溯源方法,其特征在于,包括：对待溯源的感染子图进行社区聚类,以获得对应的社区关系图；通过所述社区关系图对应的节点源的ML估计器,对所述社区关系图中的各个第一社区的谣言传播可能性进行估计分析,确定所述社区关系图中的源社区；其中,所述源社区是指所述社区关系图中最可能最先传出谣言信息的第一社区；根据所述源社区的若干个边界节点,对所述源社区进行修正,以获得对应的社区展开图,并通过所述社区展开图对应的节点源的ML估计器,对所述社区展开图中的各个第一节点的谣言传播可能性进行估计分析,确定所述社区展开图中的源节点,以实现对所述感染子图的谣言传播溯源；其中,所述源节点是指所述社区展开图中最可能最先传出谣言信息的第一节点。</td>   <td>G06F16/9536;G06F16/901;G06F16/906;G06F18/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              魏晓悦;              庞健宇;                   李龙辉       </td>   <td>中山大学中山眼科中心</td>   <td>一种早产儿视网膜病变的快速检测方法及装置</td>   <td>广东省</td>   <td>CN116958088A</td>   <td>2023-10-27</td>   <td>本申请属于图像处理技术领域,公开了一种早产儿视网膜病变的快速检测方法及装置,该方法包括：获取患者的临床眼底图像；采用眼底图像智能管理系统对临床眼底图像进行筛选,得到质量合格眼底图像；基于分割算法对质量合格眼底图像进行分类,得到眼底中央图像和眼底周边图像；将眼底中央图像输入训练好的图像分类模型,得到中央诊断结果；将眼底周边图像输入训练好的图像分割模型,得到周边诊断结果；根据中央诊断结果和周边诊断结果输出视网膜诊断结果。本申请可以提升模型诊断的准确性、加快最终诊断结果的输出,避免耽误早期治疗的时机,具有极好的临床应用性。</td>   <td>1.一种早产儿视网膜病变的快速检测方法,其特征在于,所述方法包括：获取患者的临床眼底图像；采用眼底图像智能管理系统对所述临床眼底图像进行筛选,得到质量合格眼底图像；基于分割算法对所述质量合格眼底图像进行分类,得到眼底中央图像和眼底周边图像；将所述眼底中央图像输入训练好的图像分类模型,得到中央诊断结果；将所述眼底周边图像输入训练好的图像分割模型,得到周边诊断结果；根据所述中央诊断结果和所述周边诊断结果输出视网膜诊断结果。</td>   <td>G06T7/00;G06V10/764;G06V10/26;G06V10/82;G06N3/0464;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王美琴;              虞志益;                   黄立文       </td>   <td>中山大学</td>   <td>一种行人重识别方法、系统、装置和存储介质</td>   <td>广东省</td>   <td>CN109902662B</td>   <td>2023-10-24</td>   <td>本发明公开了一种行人重识别方法、系统、装置和存储介质,其中方法包括以下步骤：将无标记的待检测数据集输入预设的特征提取模型,并提取待检测数据集的特征空间；对特征空间进行降维处理后,获得特征空间的稀疏表示；采用预设的聚类公式对稀疏表示进行聚类处理后,获得带标记的聚类结果；对聚类结果进行选择后,获得筛选后的分类结果；将分类结果输入预设的卷积神经网络进行训练优化；重复以上步骤,直到分类结果收敛,并获得行人重识别结果。本发明提出了一个易于实施的无监督学习的深度学习框架,把自步学习嵌入到无监督学习的过程中,实现了把无监督方法整合到深度学习框架当中,且该框架结构容易实施,可广泛应用于计算机视觉技术领域。</td>   <td>1.一种行人重识别方法,其特征在于,包括以下步骤：S1、将无标记的待检测数据集输入预设的特征提取模型,并提取待检测数据集的特征空间；S2、对特征空间进行降维处理后,获得特征空间的稀疏表示；S3、采用预设的聚类公式对稀疏表示进行聚类处理后,获得带标记的聚类结果；S4、对聚类结果进行选择后,获得筛选后的分类结果；S5、将分类结果输入预设的卷积神经网络进行训练优化；S6、重复步骤S1至S5,直到分类结果收敛,并获得行人重识别结果；所述步骤S2具体为：对特征空间进行字典学习后,获取特征空间的稀疏表示,从而实现特征空间的降维；所述步骤S3中预设的聚类公式为：                  其中,Φ(·；θ)为卷积神经网络模型,c-k为同属于k类的特征空间的均值向量,y为标签向量,K为行人类别的标签；x-i表示待检测数据的特征空间的稀疏表示,θ为卷积神经网络模型的权重参数,y-i表示筛选获得的分类结果。</td>   <td>G06V40/10;G06V10/762;G06V10/82;G06N3/0464;G06N3/088</td>  </tr>        <tr>   <td>中国专利</td>   <td>         印鉴;                   周晨星       </td>   <td>中山大学</td>   <td>一种基于语法约束和语言模型的文本风格迁移方法</td>   <td>广东省</td>   <td>CN110738057B</td>   <td>2023-10-24</td>   <td>本发明提供了一种基于语法约束和语言模型的文本风格迁移方法,该方法首先利用Stanford依存句法工具包提取输入句子x的语法关系图G-x,然后通过一个自身graph-transformer的结构对该语法关系图G-x加上原始输入句子的风格信息S-x与期望转化后句子的风格信息S-y得到语法关系图G′-x和G′-y,接着结合原始输入句子的语法关系图G-x通过一个交叉graph-transformer的结构重建输入句子x′以及得到风格迁移后的句子y′。为了更好地学习融入风格信息的自身graph-transformer结构以及学习重建风格迁移句子的交叉graph-transformer结构,该方法还利用一个语言模型替代传统的CNN分类器去指导后者的学习。通过这样一种方式在相应的数据集上的实验表明,本发明对比之前的文本风格迁移方法,可以在改变句子风格的条件下更好地保持语义不变性。</td>   <td>1.一种基于语法约束和语言模型的文本风格迁移方法,其特征在于,包括以下步骤：S1：建立抽取出句子语法信息获得语法关系图的网络结构；S2：将S1中得到的语法关系图分别加上原始风格信息和迁移风格信息通过自身graph-transformer网络结构得到蕴含原始风格信息和迁移风格信息的语法关系图；S3：将S2中得到的原始风格信息语法关系图与迁移风格信息语法关系图结合S1中的语法关系图通过交叉graph-transformer网络结构得到重构的具有原始风格信息的句子和重建的具有迁移风格信息的句子；S4：将S2中得到的原始风格信息语法关系图与迁移风格信息语法关系图经过一个分类器Dgraph区分输入的语法关系图属于原始风格还是迁移风格；S5：将S3中得到的具有原始风格信息的句子和具有迁移风格信息的句子经过一个语言模型Dlm去判别当前输入的句子是否符合其应该具有的风格；S6：通过重构输入句子的误差,Dgraph的误差以及Dlm的误差去训练S2中的自身graph-transformer结构和S3中的交叉graph-transformer结构,然后进行测试。</td>   <td>G06F40/30;G06F40/253;G06N3/042;G06N3/045</td>  </tr>        <tr>   <td>中国专利</td>   <td>         印鉴;                   蓝海珊       </td>   <td>中山大学</td>   <td>基于深度双向注意力机制的文本网络信息融合嵌入方法</td>   <td>广东省</td>   <td>CN110874392B</td>   <td>2023-10-24</td>   <td>本发明提供一种基于深度双向注意力机制的文本网络信息融合嵌入方法,该方法使用两种向量表示来分别代表网络中节点的结构信息和文本信息,通过深度双向注意力机制将同个节点的结构信息和文本信息进行融合,让结构信息和文本信息进行相互选择,最后将融合得到的结构、文本注意力信息再和原始信息进行融合,作为最终的结构和文本向量表达,每一个节点的最终向量表示由学习得到的结构和文本向量相拼接得到。对于损失函数的设计,本发明在训练的时候倾向于让相邻节点具备相似的结构表达和相似的文本表达,过程中使用的数据集为zhihu、Cora和Hepth,在这三个数据集上进行关系预测。</td>   <td>1.一种基于深度双向注意力机制的文本网络信息融合嵌入方法,其特征在于,包括以下步骤：S1：对节点的结构特征和文本特征进行提取；S2：建立深度双向注意力机制将同个节点的结构特征和文本特征进行融合；具体过程是：S21：对第一步得到的结构特征向量S∈R～(embedding-size×batch-size)和文本特征向量T∈R～(batch)～(-size×embedding-size)进行矩阵相乘,并将每个元素经过sigmoid函数计算,通过下列公式得到batch-size个相关性矩阵F∈R～(embedding-size×embedding-size)：F＝sigmoid(ST)在相关性矩阵F中,每个元素F-(i,j)代表结构特征向量和文本特征向量的相关性因子；S22：从相关性矩阵提取两个隐含的结构和文本相关性向量S-1和T-1,先通过行平均池化和列平均池化操作获得影响因子向量r＝[r-1,…,r-(embedding-size)]～T,c＝[c-1,…,c-(embedding-size)]～T,其中：r-i＝mean(F-(i,1),…,F-(i,embedding-size))c-i＝mean(F-(1,i),…,F-(embedding-size,i))通过softmax函数将影响因子向量转化为注意力向量s-1和t-1,其中                                    S23：得到融合之后的s-1和t-1注意力向量后,分别和原始结构特征向量s-0和文本特征向量t-0进行相加,将s-0+s-1、t-0+t-1作为第二层注意力融合机制的输入,注意力融合机制不变,输出s-2和t-2,再将s-0+s-2、t-0+t-2作为第三层注意力融合机制的输入,得到s-3和t-3,最终将三层经过结构和文本信息双向融合得到的注意力信息进行求和平均,得到最终的注意力融合信息s-add和t-add,公式如下：                                    S24：将注意力融合信息s-add和t-add与原始结构特征向量s-0和文本特征向量t-0进行拼接,再经过一层全连接层,最终得到经过深度双向注意力机制融合的结构特征表示s和文本特征表示t；S3：通过深度双向注意力机制融合得到的结构特征和文本特征,设计损失函数,使邻居节点的结构特征和文本特征相似。</td>   <td>G06F16/31;G06F16/33;G06F40/205;G06F40/30;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>              张鹏       </td>   <td>中山大学</td>   <td>基于多尺度的遥感影像地物分类方法、系统、装置及介质</td>   <td>广东省</td>   <td>CN111860207B</td>   <td>2023-10-24</td>   <td>本发明公开了基于多尺度的遥感影像地物分类方法、系统、装置及介质,方法包括：基于不同的预设尺度,对获取到的遥感影像进行图像分块,得到初始图像块集合；接着基于预设的语义分割模型,对所述初始图像块集合中的各个尺度下的图像块进行分割,得到不同尺度的分类结果；然后将相同尺度下各个图像块对应的分类结果拼接,得到不同尺度下的初始地物分类结果图集合；最后基于投票策略,将所述不同尺度下的初始地物分类结果图集合进行合并,得到目标地物分类结果图。本发明能够消除相邻图像块之间的不连续直线型接缝,具有很强的实用性,可广泛应用于图像处理技术领域。</td>   <td>1.基于多尺度的遥感影像地物分类方法,其特征在于,包括：基于不同的预设尺度,对获取到的遥感影像进行图像分块,得到初始图像块集合；基于预设的语义分割模型,对所述初始图像块集合中的各个尺度下的图像块进行分割,得到不同尺度的分类结果；将相同尺度下各个图像块对应的分类结果拼接,得到不同尺度下的初始地物分类结果图集合；基于投票策略,将所述不同尺度下的初始地物分类结果图集合进行合并,得到目标地物分类结果图；所述基于预设的语义分割模型,对所述初始图像块集合中的各个尺度下的图像块进行分割,得到不同尺度的分类结果这一步骤,包括：将等于所述语义分割模型要求的图像尺寸标准的图像块直接输入所述语义分割模型,输出与所述输入的图像块尺寸相同的分类结果；将小于所述图像尺寸标准的图像块进行放大处理后,再输入所述语义分割模型,将得到的分类结果缩小至与所述放大处理前图像块相同尺寸的大小；将大于所述图像尺寸标准的图像块进行缩小处理后,再输入所述语义分割模型,将得到的分类结果放大至与所述缩小处理前图像块相同尺寸的大小；所述将相同尺度下各个图像块对应的分类结果拼接,得到不同尺度下的初始地物分类结果图集合这一步骤,包括：按照图像块的排列顺序,将同一尺度下各个图像块对应的分类结果拼接,得到不同尺度下的初始地物分类结果图集合；若有一个像素对应多个图像块,则计算该像素与所述多个图像块的中心之间的距离,并将距离最近的图像块对应的像素值作为该像素的值；所述基于投票策略,将所述不同尺度下的初始地物分类结果图集合进行合并,得到目标地物分类结果图这一步骤,包括：获取地物分类结果图中每个像素值对应的不同尺度下的三个语义值；若一个像素值对应的任意两个语义值相同,则将所述语义值赋予该像素；若一个像素值对应的三个语义值都不同,则将所述三个语义值的中间尺度的语义值赋予该像素。</td>   <td>G06V10/764;G06V20/10;G06V20/70;G06V10/26;G06V10/52;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>              张鹏       </td>   <td>中山大学</td>   <td>基于超像素的遥感影像地物分类方法、系统、装置及介质</td>   <td>广东省</td>   <td>CN111860208B</td>   <td>2023-10-24</td>   <td>本发明公开了基于超像素的遥感影像地物分类方法、系统、装置及介质,方法包括：对获取到的遥感影像进行图像分块,得到第一图像块集合；基于预设的语义分割模型,将所述第一图像块集合进行语义分割,得到语义分割结果；对所述第一图像块集合进行超像素分割,得到超像素分割结果；根据所述超像素分割结果,对所述语义分割结果进行边缘修剪,得到第二图像块集合；将所述第二图像块集合进行图像块拼接,得到地物分类结果图。本发明能够消除相邻图像块之间的不连续直线型接缝,实用性高,可广泛应用于图像处理技术领域。</td>   <td>1.基于超像素的遥感影像地物分类方法,其特征在于,包括：对获取到的遥感影像进行图像分块,得到第一图像块集合；基于预设的语义分割模型,将所述第一图像块集合进行语义分割,得到语义分割结果；对所述第一图像块集合进行超像素分割,得到超像素分割结果；根据所述超像素分割结果,对所述语义分割结果进行边缘修剪,得到第二图像块集合；将所述第二图像块集合进行图像块拼接,得到地物分类结果图；所述对获取到的遥感影像进行图像分块,得到第一图像块集合这一步骤,包括：获取遥感影像；基于预设的分块顺序和预设的分块尺度,将所述遥感影像进行分块处理,得到第一图像块集合,所述第一图像块集合中包含多个相同尺度的图像块；其中,任意两个相邻图像块之间在横向和纵向上均保持预设比例的重叠；所述语义分割结果中各个图像块的尺度等于所述分块尺度：所述语义分割结果中各个图像块包含地物分类信息；所述超像素分割结果中各个图像块的尺度等于所述分块尺度；所述超像素分割结果中各个图像块不包含地物分类信息；所述根据所述超像素分割结果,对所述语义分割结果进行边缘修剪,得到第二图像块集合这一步骤,包括：根据所述语义分割结果中的每个图像块,确定待修剪超像素；其中,所述待修剪超像素与所述语义分割结果中的一个图像块边缘之间的距离小于30像素距离；对于所述语义分割结果中位于遥感影像边界位置的图像块,不做修剪处理；所述将所述第二图像块集合进行图像块拼接,得到地物分类结果图这一步骤,包括：基于预设的拼接顺序,将所述第二图像块集合中各个图像块进行拼接；对于各个图像块之间的重叠部分,用在后添加的图像块覆盖在先添加的图像块。</td>   <td>G06V10/764;G06V10/26;G06V20/70;G06V10/10;G06V20/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         董晨鹤;                   沈颖       </td>   <td>中山大学</td>   <td>一种跨领域层次关系的知识蒸馏方法和系统</td>   <td>广东省</td>   <td>CN113849641B</td>   <td>2023-10-24</td>   <td>本发明公开了一种跨领域层次关系的知识蒸馏方法和系统,为各个领域构建了一系列参考原型特征,建立多个领域关系图网络来充分地学习不同领域间的关系,每个图节点代表一个领域的原型特征,每个边的权重代表相连的两个原型特征的相似度,这样,不同领域的关系便可以同时被捕捉生成一系列领域关系系数对各个领域在知识蒸馏过程中的权重进行重分配,引导模型动态地关注更重要的领域信息,可以更方便高效地处理多领域环境下模型压缩,大幅度地提升模型的性能,解决了现有的跨领域知识蒸馏方法在捕捉不同领域之间的关系信息方面能力较差,泛化性能较低,难以提高压缩语言模型的表达能力的技术问题。</td>   <td>1.一种跨领域层次关系的知识蒸馏方法,其特征在于,包括：获取不同领域的训练样本,其中,训练样本为语言文本；对各领域的训练样本分别计算学生层的原型特征；对学生模型中的除了预测层外的每个学生层建立一个基于图注意力网络的两层领域关系图网络,在第一层领域关系图网络中,每个节点上应用一个共享参数矩阵和注意力机制,并将节点的输出送入ELU非线性函数和多头拼接机制,在第二层领域关系图网络中,去除多头拼接机制,使用softmax对输出归一化得到领域关系系数；将每个领域的训练样本的原型特征输入领域关系图网络,得到每个学生层的领域关系系数；将每个学生层的领域关系系数作为教师模型和学生模型的对应层的权重系数,确定蒸馏损失函数,教师模型和学生模型用于语言文本分类；根据蒸馏损失函数对学生模型进行迭代训练；蒸馏损失函数为：                  其中,为总体损失,r-(m,d)为第m层、第d个领域的领域关系系数,/&gt;为d个领域的嵌入层损失,/&gt;为预测层损失,/&gt;为第d个领域中的第m个学生层的注意力层损失,/&gt;为第d个领域中的第m个学生层的前馈网络层损失,D为总领域数,γ为用来控制预测损失/&gt;的权重；学生层的原型特征计算公式为：                  其中,h-(m,d)为d领域的第m个学生层的原型特征,为第d个领域的训练集,L为句子长度,为/&gt;中第i个采样学生嵌入的第l个单词,/&gt;为/&gt;中第i个采样的第m个学生层的前馈网络层输出,M为学生层总数。</td>   <td>G06F16/35;G06F18/241;G06F18/214</td>  </tr>        <tr>   <td>中国专利</td>   <td>         房若宸;              孙兴华;              刘京京;              陈翔;                   姜园       </td>   <td>中山大学</td>   <td>一种基于哈希多叉树的区块链智能合约服务框架设计方法及应用系统</td>   <td>广东省</td>   <td>CN116932647A</td>   <td>2023-10-24</td>   <td>本发明提出一种基于哈希多叉树的区块链智能合约服务框架设计方法及应用系统,涉及区块链智能合约的技术领域,令每个节点智能合约作为一个树节点,将若干个节点智能合约彼此相连,在区块链上形成一个哈希多叉树,实现了基于哈希多叉树构造区块链智能合约框架,实现了区块链上的可扩展性、可集成的多叉树结构,为哈希多叉树的每个树节点内置基于角色与权限的访问机制,检查用户是否具有特定的角色与权限,对外设置用户访问接口,提供序列化引擎与反序列化引擎,实现了数据管理和合约管理两大功能域,还可使DApp的可扩展性、兼容性、访问速度、可维护性、数据机密性、数据完整性均得到有效提升。</td>   <td>1.一种基于哈希多叉树的区块链智能合约服务框架设计方法,其特征在于,包括以下步骤：基于智能合约语言设计若干个节点智能合约Node；令每个节点智能合约Node作为一个树节点,所述若干个节点智能合约Node彼此相连,在区块链上形成一个哈希多叉树；为哈希多叉树的每个树节点内置基于角色与权限的访问机制,检查用户是否具有特定的角色与权限；对外设置用户访问接口,提供序列化引擎与反序列化引擎；所述序列化引擎将所述哈希多叉树的数据及拓扑序列化为字符串并提交给用户,所述反序列化引擎接受来自用户的字符串,并根据所述字符串在所述哈希多叉树上增加、修改或删除数据、拓扑。</td>   <td>G06F16/27;G06F8/20;G06F16/22;G06F16/23;G06F16/25;G06F21/31</td>  </tr>        <tr>   <td>中国专利</td>   <td>         肖绍球;              徐国凯;              李杜;                   龙云亮       </td>   <td>中山大学</td>   <td>基于COMSOL的低频电小压电天线的建模方法</td>   <td>广东省</td>   <td>CN116933345A</td>   <td>2023-10-24</td>   <td>本发明公开了基于COMSOL的低频电小压电天线的建模方法,该方法包括：基于实物结构参数构建低频电小压电天线的三维仿真模型；对三维仿真模型添加接口和对应接口偏微分方程、添加材料属性并设置材料切型和极化方向坐标系；将接口偏微分方程的求解结果导入到其他接口中；设置三维仿真模型的边界条件及求解的频率范围并进行网格划分；在“电磁波,频域”接口设置辐射性能变量；计算三维仿真模型,得到三维仿真模型的电磁场和弹性场。通过使用本发明,能够在不增加建模复杂度的前提下,完成从静电场到辐射场的转换,准确实现对辐射性能的量化计算。本发明可广泛应用于声波激励的电小天线技术领域。</td>   <td>1.基于COMSOL的低频电小压电天线的建模方法,其特征在于,包括以下步骤：基于实物结构参数构建低频电小压电天线的三维仿真模型；对三维仿真模型添加“压电,固体”接口和“电磁波,频域”接口,并增加对应接口偏微分方程；对三维仿真模型添加材料属性并设置材料切型和极化方向坐标系；将“压电,固体”接口偏微分方程的求解结果导入到“电磁波,频域”接口中；设置三维仿真模型的边界条件及求解的频率范围；对三维仿真模型进行网格划分；在“电磁波,频域”接口设置辐射功率、净输入功率和辐射效率变量；计算三维仿真模型,得到三维仿真模型的电磁场和弹性场。</td>   <td>G06F30/10;G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         魏亮亮;              刘东青;              许宏章;                   易涵       </td>   <td>中山大学</td>   <td>一种定子分区直流偏置混合励磁磁场调制电机的建模方法</td>   <td>广东省</td>   <td>CN116933532A</td>   <td>2023-10-24</td>   <td>本发明公开了一种定子分区直流偏置混合励磁磁场调制电机的建模方法,该方法包括：定义电机在静止双三相坐标系下的电压矩阵、电流矩阵、电感矩阵和定子电压方程；基于坐标变换矩阵,将静止双三相坐标系下的电压矩阵、电流矩阵、电感矩阵和定子电压方程变换至同步旋转坐标系下；基于同步旋转坐标系下的定子电压方程和电感表达式构建电机的电磁转矩方程；基于电机的电磁转矩方程,对励磁电流转矩成分、定子永磁转矩成分和转子永磁转矩成分进行解耦分析。通过使用本发明,解决了混合励磁定转子双永磁电机电感非线性建模问题和转矩解耦分析问题。本发明可广泛应用于系统建模领域。</td>   <td>1.一种定子分区直流偏置混合励磁磁场调制电机的建模方法,其特征在于,包括以下步骤：定义电机在静止双三相坐标系下的电压矩阵、电流矩阵和电感矩阵；构建电机在静止双三相坐标系下的定子电压方程；基于坐标变换矩阵,将静止双三相坐标系下的电压矩阵、电流矩阵、电感矩阵和定子电压方程变换为同步旋转坐标系下的电压矩阵、电流矩阵、电感矩阵和定子电压方程；基于同步旋转坐标系下的定子电压方程和电感表达式构建电机的电磁转矩方程；基于电机的电磁转矩方程,对励磁电流转矩成分、定子永磁转矩成分和转子永磁转矩成分进行解耦分析。</td>   <td>G06F30/20;H02P21/00;H02P25/02;H02P27/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚正安;                   张婧纯       </td>   <td>中山大学</td>   <td>一种基于两阶段处理的点到点最短路求解方法</td>   <td>广东省</td>   <td>CN116933956A</td>   <td>2023-10-24</td>   <td>本发明公开一种基于两阶段处理的点到点最短路求解方法,包括以下步骤：S1：获取地图信息,根据地图信息构建图G；S2：对Dijkstra算法进行改进,在Dijkstra算法的预处理阶段,引入reach值并改进reach值的计算方式,采用上界值限制reach值；在Dijkstra算法的在线查询阶段,引入Heap与Map数组求取精确解；通过reach值对在线查找的过程进行剪枝；S3：利用步骤S2改进的Dijkstra算法对步骤S1中得到的图G进行处理,得到源点与汇点的最短路径。本发明通过改进Dijkstra算法,实现点到点最短路的快速求解。</td>   <td>1.一种基于两阶段处理的点到点最短路求解方法,其特征在于,包括以下步骤：S1：获取地图信息,根据地图信息构建图G；S2：对Dijkstra算法进行改进,在Dijkstra算法的预处理阶段,引入reach值并改进reach值的计算方式,采用上界值限制reach值；在Dijkstra算法的在线查询阶段,引入Heap与Map数组求取精确解；通过reach值对在线查找的过程进行剪枝；S3：利用步骤S2改进的Dijkstra算法对步骤S1中得到的图G进行处理,得到源点与汇点的最短路径。</td>   <td>G06Q10/047;G06F16/29;G06F16/901</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡茂川;              范泳雅;              贺凯;              尹启东;                   刘丙军       </td>   <td>中山大学</td>   <td>一种基于水量水质变化影响的水资源价值估算方法及系统</td>   <td>广东省</td>   <td>CN116934361A</td>   <td>2023-10-24</td>   <td>本发明公开了一种基于水量水质变化影响的水资源价值估算方法及系统,方法包括：确定需要估算水资源价值的待估算区域；获取所述待估算区域的水资源价值评价指标数据；根据所述评价指标数据,基于收益现值原理计算水资源的分项价值；根据所述待估算区域的水资源数据,计算水量相关价值调整因子和水质相关价值调整因子；根据所述分项价值、所述水量相关价值调整因子和水质相关价值调整因子,确定水资源价值估算结果。本发明实施例能够量化水量和水质因素对水资源价值的影响,使得水资源价值评估更为准确。本发明实施例可广泛应用于水资源价值估算技术领域。</td>   <td>1.一种基于水量水质变化影响的水资源价值估算方法,其特征在于,包括：确定需要估算水资源价值的待估算区域；获取所述待估算区域的水资源价值评价指标数据；根据所述评价指标数据,基于收益现值原理计算水资源的分项价值；根据所述待估算区域的水资源数据,计算水量相关价值调整因子和水质相关价值调整因子；根据所述分项价值、所述水量相关价值调整因子和水质相关价值调整因子,确定水资源价值估算结果。</td>   <td>G06Q30/02;G06Q30/0201;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         文静;              林广荣;              凌逸虹;              傅剑华;              翁泽霖;                   谢秀英       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种淋巴结构图像识别方法及系统</td>   <td>广东省</td>   <td>CN116934742A</td>   <td>2023-10-24</td>   <td>本发明公开了一种淋巴结构图像识别方法及系统,通过将获取的待识别淋巴结构图像输入到粗淋巴结构识别模型中,以使粗淋巴结构识别模型对待识别淋巴结构图像进行淋巴结构区域识别,得到第一淋巴结构区域图像；将第一淋巴结构区域图像输入到细淋巴结构识别模型中,以使细淋巴结构识别模型对第一淋巴结构区域图像进行淋巴细胞识别,得到第一淋巴结构区域图像中的淋巴细胞特征值；获取第一淋巴结构区域图像在RGB颜色空间中各通道的像素值,根据像素值,计算第一淋巴结构区域图像的像素特征值；基于像素特征值和淋巴细胞特征值,确定待识别淋巴结构图像的图像识别结果；与现有技术相比,本发明的技术方案能提高对淋巴结构图像识别效率和准确性。</td>   <td>1.一种淋巴结构图像识别方法,其特征在于,包括：获取待识别淋巴结构图像,将所述待识别淋巴结构图像输入到预设的粗淋巴结构识别模型中,以使所述粗淋巴结构识别模型对所述待识别淋巴结构图像进行淋巴结构区域识别,得到第一淋巴结构区域图像；将所述第一淋巴结构区域图像输入到预设的细淋巴结构识别模型中,以使所述细淋巴结构识别模型对所述第一淋巴结构区域图像进行淋巴细胞识别,得到所述第一淋巴结构区域图像中的淋巴细胞特征值；获取所述第一淋巴结构区域图像在RGB颜色空间中各通道的像素值,根据所述像素值,计算所述第一淋巴结构区域图像的像素特征值；基于所述像素特征值和所述淋巴细胞特征值,确定所述待识别淋巴结构图像的图像识别结果。</td>   <td>G06T7/00;G06T7/11;G06V10/26;G06V10/44;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张磊;              温子轩;              方愚渊;                   吴亿锋       </td>   <td>中山大学</td>   <td>VideoSAR阴影跟踪方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN116934802A</td>   <td>2023-10-24</td>   <td>本发明公开了一种VideoSAR阴影跟踪方法、系统、装置及存储介质,方法包括：获取输入图片和输入跟踪框；利用相关滤波器,基于输入跟踪框对输入图片进行第一预测,获得估计跟踪框；基于互交多模型滤波器的运动状态进行第二预测,获得融合先验观测,并确定先验概率函数；基于先验概率函数,在估计跟踪框中进行动态阈值的双参数恒虚警检测,获得检测结果；根据检测结果,基于估计跟踪框或融合先验观测对相关滤波器和互交多模型滤波器进行适应性更新；基于适应性更新的结果,获得目标帧VideoSAR图片的输出跟踪框。本发明实施例能够高效准确地完成VideoSAR目标跟踪任务,可广泛应用于阴影跟踪技术领域。</td>   <td>1.一种VideoSAR阴影跟踪方法,其特征在于,包括：获取输入图片和输入跟踪框；其中,所述输入图片表征VideoSAR视频帧序列中的目标帧VideoSAR图片,所述输入跟踪框表针基于所述目标帧前一帧的VideoSAR图片得到的输出跟踪框；利用相关滤波器,基于所述输入跟踪框对所述输入图片进行第一预测,获得估计跟踪框；其中,所述相关滤波器包括进行位移估计的二维滤波器和进行尺度估计的一维滤波器；基于互交多模型滤波器的运动状态进行第二预测,获得融合先验观测,并确定先验概率函数；基于所述先验概率函数,在所述估计跟踪框中进行动态阈值的双参数恒虚警检测,获得检测结果；所述检测结果包括所述估计跟踪框中检测到目标和所述估计跟踪框中没有检测到目标；根据所述检测结果,基于所述估计跟踪框或所述融合先验观测对所述相关滤波器和所述互交多模型滤波器进行适应性更新；基于所述适应性更新的结果,获得所述目标帧VideoSAR图片的输出跟踪框。</td>   <td>G06T7/246;G06T7/277</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余翠琳;              王青松;              黄海风;              赖涛;              方佳骏;              钟梓炫;              张子博;                   张君豪       </td>   <td>中山大学</td>   <td>一种语义分割网络的DSM滤波方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116935046A</td>   <td>2023-10-24</td>   <td>本发明提供了一种语义分割网络的DSM滤波方法、系统、设备及介质,所述方法包括：采集自然场景遥感图像,根据所述自然场景遥感图像生成图像数据集；建立并训练图像语义分割网络,将所述图像数据集输入训练后的图像语义分割网络,得到语义分割光学图像；所述图像语义分割网络包括金字塔场景分析网络；将所述语义分割光学图像对应DSM的非地面区域高程值置零,得到非地面区域空洞DSM,以进行DSM滤波。本发明能够快速、精确地对非地面区域进行像素级别的语义分割,节省了人工再修饰的时间成本,有效提高DSM滤波效率,生成高质量的DEM。</td>   <td>1.一种语义分割网络的DSM滤波方法,其特征在于,所述方法包括：采集自然场景遥感图像,根据所述自然场景遥感图像生成图像数据集；建立并训练图像语义分割网络,将所述图像数据集输入训练后的图像语义分割网络,得到语义分割光学图像；所述图像语义分割网络包括金字塔场景分析网络；将所述语义分割光学图像对应DSM的非地面区域高程值置零,得到非地面区域空洞DSM,以进行DSM滤波。</td>   <td>G06V10/26;G06V10/774;G06V10/28;G06V20/10;G06V20/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭舟;                   许瑞       </td>   <td>中山大学</td>   <td>一种点云图像融合语义分割方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116935049A</td>   <td>2023-10-24</td>   <td>本发明提供了一种点云图像融合语义分割方法、系统、设备及介质,所述方法包括：采集遥感图像数据和点云数据；所述遥感图像数据和点云数据通过映射函数相对应；通过特征提取器分别从所述遥感图像数据和点云数据提取各自的多阶段遥感图像特征和多阶段点云特征；建立点云图像融合网络,依次融合所述多阶段遥感图像特征和多阶段点云特征,以训练所述点云图像融合网络；将所述遥感图像数据和点云数据输入训练后的点云图像融合网络,得到类别归属概率,以进行语义分割。本发明能够对神经网络中不同阶段的点云特征和图像特征进行融合,更好地进行语义分割。</td>   <td>1.一种点云图像融合语义分割方法,其特征在于,所述方法包括：采集遥感图像数据和点云数据；所述遥感图像数据和点云数据通过映射函数相对应；通过特征提取器分别从所述遥感图像数据和点云数据提取各自的多阶段遥感图像特征和多阶段点云特征；建立点云图像融合网络,依次融合所述多阶段遥感图像特征和多阶段点云特征,以训练所述点云图像融合网络；将所述遥感图像数据和点云数据输入训练后的点云图像融合网络,得到类别归属概率,以进行语义分割。</td>   <td>G06V10/26;G06V20/13;G06V10/40;G06V10/80;G06V10/82;G06N3/0464;G06N3/045;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘冶;              印鉴;              桂进军;              吕梦瑶;              傅自豪;              李宏浩;              刘春鹏;              岑卓;                   陈志良       </td>   <td>中山大学;广州赫炎大数据科技有限公司</td>   <td>一种基于地理位置和人脸特征的签到方法及系统</td>   <td>广东省</td>   <td>CN110046870B</td>   <td>2023-10-20</td>   <td>本发明涉及一种基于地理位置和人脸特征的签到方法及系统,通过获取用户签到时间、签到时刻所处的经度、纬度和人脸特征信息,通过对上述信息进行审核得到签到审核结果,并将签到审核结果返回客户端。相对于现有技术,本发明极大地提高了签到效率和准确性。</td>   <td>1.一种基于地理位置和人脸特征的签到方法,其特征在于,包括以下步骤：获取用户签到时间、签到时刻所处的经度、纬度和人脸特征信息；判断用户是否处于签到设定时间内,得到签到时间审核结果；调用半正矢模型计算出用户签到地点与签到规则预设地点的距离,判断用户是否在签到约束范围内,得到地理信息审核结果；其中,所述调用半正矢模型计算出用户签到地点与签到规则预设地点的距离的步骤具体包括：按照以下方式,获取用户签到地点与签到规则预设地点的距离：                  其中,d为用户签到地点与签到规则预设地点的距离,r为球面半径；和/&gt;分别为签到地点与预设地点的纬度,λ-1和λ-2分别为签到地点与预设地点的经度,hav为半正矢函数；调用通过对预训练的深度神经网络迁移学习得到的人脸识别模型,对接收到的人脸信息进行特征提取,并与数据库中的注册时的特征进行匹配,得到人脸信息审核结果；根据签到时间审核结果、地理信息审核结果和人脸信息审核结果得到签到审核结果并返回客户端。</td>   <td>G06Q10/1091;G06V40/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              区炳坚;                   周凡       </td>   <td>中山大学</td>   <td>一种基于生成式对抗网络的人像卡通化方法</td>   <td>广东省</td>   <td>CN110070483B</td>   <td>2023-10-20</td>   <td>本发明公开了一种基于生成式对抗网络的人像卡通化方法。本发明通过生成式网络将人脸与背景分割、将人脸转化为卡通的人脸、将背景转化为卡通背景,之后合成得到卡通图,并用判别式网络进行判别；然后通过损失函数对生成式网络与判别式网络进行训练；最后把待处理人脸图像输入训练好的生成式网络即可生成对应的卡通图像。本发明有助于根据输入的人脸图片全自动的生成人像卡通图片,或者根据用户输入人脸图像,给出推荐的卡通化方案,供用户选择或修改,节省用户选取素材拼接的时间。</td>   <td>1.一种基于生成式对抗网络的人像卡通化方法,其特征在于,所述方法包括：步骤一,获取人脸数据训练集和卡通数据训练集；步骤二,对人脸数据训练集进行预处理,得到头发掩模、脸部掩模以及五官掩模；步骤三,构建生成式网络,将人脸数据训练集中的人脸图像转化为卡通图像,以及将卡通数据训练集中的卡通图像转化为人脸图像；步骤四,构建判别式网络,对转化而成的卡通图像以及转化而成的人脸图像分别进行判别；步骤五,根据步骤二生成的掩模、步骤三生成式网络生成的人脸和卡通图像、步骤四得到的判别结果,计算损失函数值并优化生成式网络和判别式网络；步骤六,重复步骤三到步骤五,循环迭代多轮,得到训练好的卡通图像生成式网络；步骤七,把待处理的人脸图像输入到最终得到的卡通生成式网络,则可得到对应的具有个人特色的卡通图像；其中,所述构建生成式网络,将人脸数据训练集中的人脸图像转化为卡通图像,具体为：输入的人脸图记作x,在训练GAN的时候,使用到的卡通图记作y；x作为一个分割网络G1attn的输入,该网络用于分割前景,得到前景掩模,其输出G1attn(x)是一个掩模,其大小与输入图片大小一致,通道数为1,每个像素取值在0-1之间,越接近0,表示该像素为背景的可能性越高,越接近1,表示该像素是脸或头发的概率越高；从而背景掩模表示为1-G1attn(x)；同时,人脸图x也输入到人脸特征编码网络e1中,得到高层语义信息编码向量e1(x)；利用所述高层语义信息编码向量e1(x)作为卡通背景解码网络d1bg的输入,d1bg专注于生成与卡通数据集中的背景相近的背景,而不关注卡通人脸的生成；利用所述高层语义信息编码向量e1(x)作为卡通人脸解码解码网络d1cnt的输入,d1cnt专注于生成卡通数据集中的人脸,而不关注卡通数据集的背景生成；利用从所述G1attn(x)得到的人脸及头发掩模以及背景掩模,以及从所述d1bg和d1cnt得到的卡通背景以及卡通脸的生成结果,得到最终生成的卡通图：G1(x)＝G1attn(x)⊙d1cnt(e1(x))+(1-G1attn(x))⊙d1bg(e1(x))；⊙表示逐像素相乘；其中,所述构建判别式网络,对转化而成的卡通图像以及转化而成的人脸图像分别进行判别,具体为：将所述生成的卡通图以及从卡通数据训练集里取样的卡通图送入卡通图原图判别网络D1中,该网络用于判断输入的图像是否为非生成的卡通图样本；训练时,通过减少卡通图判别模型的影响权重,同时加入一个新的卡通图判别网络D1Edg,该判别网络D1Edg以经过边缘提取网络EdgeExtraNet后的卡通边缘图作为输入；EdgeExtraNet网络由两个卷积层组成,第一个卷积层用于得到灰度图,另一个卷积层用于边缘提取,卷积核为图像处理领域中的边缘算子,卷积核参数如下所示：                  人脸图像判别器网络由原图判别网络构成,与卡通图判别器不同的是,不需要使用边缘判别网络；其中,所述计算损失函数值并优化生成式网络和判别式网络,具体为：计算颜色损失：在人变卡通的过程中,为了保持低层语义信息,将输入图像x与生成的卡通图输入到一个平滑网络SmoothNet中,使用20个参数一样的卷积层组成平滑网络,卷积核参数如下所示：                  根据所述预处理得到的粗略的头发掩模Ahair,以及除去鼻子,眼睛和嘴巴区域的脸部部分Aface2,两个区域是结构和颜色不需要发生太大改变的区域,对这两个区域计算损失：L-(color)＝||SmoothNet(x)⊙(Ahair+Afce2)-SmoothNet(G1(x))⊙(Ahair+Aface2)||-1；计算循环一致性损失：在人变卡通再还原回人的这个循环中,循环一致性损失表达式如下：L-(cyc1)＝||x⊙(Aface1+Aface2)-G2(G1(x))⊙(Aface1+Aface2)||-1+||SmoothNet(x)⊙Ahair-SmoothNet(G2(G1(x)))⊙Ahair||-1对于卡通输入图y,在卡通转化为人再还原回卡通这一个循环中,沿用CycleGAN的循环一致性损失：L-(cyc2)＝||y-G1(G2(y))||-1；计算掩模循环损失：为使人脸照片的前景区域与生成卡通的前景区域保持一致,掩模循环损失定义如下：L-(cycattn1)＝||G1attn(x)-G2attn(G1(x))||-1；在卡通变人过程中,掩模循环一致性L-(cycattn2)与L-(cycattn1)定义类似；计算掩模监督损失：L-(msk sup1)＝||G1attn(x)-(Ahair+Aface2+Aface1)||-1；计算GAN对抗损失：希望生成模型能够生成可以欺骗判别模型的图片,而判别模型能够正确区分哪些图像是生成模型生成的,设X为人脸图像分布,Y为卡通图像分布,优化目标为：                  其中θ-(G1)表示G1模型中的参数,θ-(D1)表示模型D1中的参数,对应的由卡通到人脸的GAN对抗损失类似；计算GAN梯度图对抗损失：在人变卡通的过程中,加入了卡通梯度图判别器,使得生成器模型更加关注卡通的结构而非颜色,其优化目标为：                  其中θ-(D1Edg)为判别模型D1Edg的参数；最终损失函数值为上述所有损失结果的线性组合,首先固定生成式网络,通过反向传播优化判别器网络,然后固定判别器网络,优化生成式网络。</td>   <td>G06T3/00;G06V40/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄煜博;              王若梅;              林淑金;              周凡;                   林格       </td>   <td>中山大学</td>   <td>一种基于关键词的视频摘要生成方法</td>   <td>广东省</td>   <td>CN110442747B</td>   <td>2023-10-20</td>   <td>本发明公开了一种基于关键词的视频摘要生成方法,通过对视频进行视觉通道处理,进行基于关键词的视觉内容摘要提取,得到图像摘要；视频语音文本内容预处理,进行基于关键词的语音文本内容摘要提取,得到文本摘要；利用图像摘要和文本摘要,获得最终图文摘要。本发明提供了一种自动生成视频摘要的方法,大大减少了视频上传者手工操作的时间；充分考虑了视频搜索用户的需求,为用户提供了更加贴合自己搜索意图的视频摘要；使用基于人工智能深度学习技术的方法,使生成的视频摘要更能准确的反映视频的内容。</td>   <td>1.一种基于关键词的视频摘要生成方法,其特征在于,所述方法包括：对视频进行视觉通道预处理,获得初步分割镜头；利用分割镜头,进行视频场景分割进行视频帧聚类；利用聚类后的视频帧,进行基于关键词的视觉内容摘要提取,得到图像摘要；视频语音文本内容预处理,得到视频语音文本数据；利用视频语音文本数据,对视频语料库主题模型进行训练,得到文本子主题；利用文本子主题,进行基于关键词的语音文本内容摘要提取,得到文本摘要；利用图像摘要和文本摘要,获得最终图文摘要；其中,所述利用视频语音文本数据,对视频语料库主题模型进行训练,得到文本子主题,具体为：使用获得的视频数据,经视频语料库进行LDA训练,挖掘视频语音文本内容的潜在主题模型；LDA联合概率公式如公式所示：                  θ表示文档级别的变量,每个文档对应一个θ,z是主题的集合、w是单词的集合,z-n为第n个主题,w-n为第n个单词,是狄利克雷分布的参数,用于生成主题向量,表示各个主题对应的单词概率分布矩阵；将所述视频语音文本数据作为改进后的TextTiling算法的输入,算法改用主题包代替词语包表示文本语义,即用LDA训练后得到的主题；算法以句子为初始块,提取每个文本块的主题包特征后,以余弦相似度度量相邻文本块的语义相似度；计算深度分数,深度分数表示文本块与其上下文关联度分数的差值,反映了文本块两侧的语义变化的相对剧烈程度,以下公式为深度分数计算方法：                  其中hl(c)表示从文本块左边找到的第一个关联度分数最高的峰值,右边hr(c)同理,s(c)表示当前文本块和其上下文的关联度,s(c)的计算公式如下所示：                  p、c、f是相邻文本块,t表示文本块的语义特征维度,p表示和当前c文本块相邻的前一个文本块,f表示和当前c文本块相邻的后一个文本块,w-(t,c)表示c文本块第t维度主题包特征的值；深度分数越高表明文本块关联度变化的趋势越剧烈,越有可能是主题边界；深度大于预先设置的阈值的文本块即为主题边界；其中,所述利用文本子主题,进行基于关键词的语音文本内容摘要提取,得到文本摘要,具体为：对分割好的主题场景中由LDA提取出来的各个主题场景的文本主题运用TextRank算法提炼出每个主题的分数排在前n个的关键词；使用Word2Vec词向量空间的计算方法,分别获取用户输入关键词以及视频主题关键词的词向量；对上述两者进行余弦相似度计算,选取与用户输入关键词相似度高的视频主题关键词所对应的视频主题作为视频文本摘要输出；计算公式如下：                  t代表用户输入关键词,v代表视频主题关键词。</td>   <td>G06F16/738;G06V20/40;G06V10/762;G06V10/764;G06V10/82;G06F40/30;G10L15/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马锦华;              李璐圆;              严晓威;                   陈曦       </td>   <td>中山大学</td>   <td>一种基于双指标度量学习的工具异常放置检测方法及系统</td>   <td>广东省</td>   <td>CN111862036B</td>   <td>2023-10-20</td>   <td>本发明公开了一种基于双指标度量学习的工具异常放置检测方法及系统,该方法包括：获取正确放置工具的工具箱图片并标记,得到标记信息；根据标记信息将工具箱图片中的工具单独裁剪出正确工具图片,并对正确工具图片进行数据扩充,得到训练集和验证集；通过训练集和验证集对预设的基于双指标度量学习的工具异常放置检测模型进行训练和验证并调整参数,得到最终工具异常检测模型；获取当前工具箱图片,根据标记信息对当前工具箱图片裁剪出各个当前工具图片后,输入到最终工具异常检测模型并判断是否放置异常。本发明作为基于双指标度量学习的工具异常放置检测方法及系统,可广泛应用于图像处理领域。</td>   <td>1.一种基于双指标度量学习的工具异常放置检测方法,其特征在于,包括以下步骤：获取正确放置工具的工具箱图片并标记,得到标记信息；根据标记信息将工具箱图片中的工具单独裁剪出正确工具图片,并对正确工具图片进行数据扩充,得到训练集和验证集；通过训练集和验证集对预设的基于双指标度量学习的工具异常放置检测模型进行训练和验证并调整参数,得到最终工具异常检测模型；获取当前工具箱图片,根据标记信息对当前工具箱图片裁剪出各个当前工具图片后,输入到最终工具异常检测模型并判断是否放置异常；所述通过训练集和验证集对预设的基于双指标度量学习的工具异常放置检测模型进行训练和验证并调整参数,得到最终工具异常检测模型这一步骤,其具体包括：获取工具的两张训练工具图片,通过特征提取网络分别提取出两张训练工具图片的特征和二分类损失值；将两张训练工具图片的特征进行叠加并输入到距离度量网络,得到关系分数；根据二分类损失值和关系分数计算模型的总损失值,得到训练后的工具异常检测模型；通过验证集中该工具的验证工具图片对训练后的工具异常检测模型进行测试和参数调整,得到各个工具的最终工具异常检测模型；所述获取当前工具箱图片,根据标记信息对当前工具箱图片裁剪出各个当前工具图片后,输入到最终工具异常检测模型并判断是否放置异常这一步骤,其具体包括：获取当前工具箱图片,根据标记信息对当前工具箱图片裁剪出各个当前工具图片；将当前工具图片和该工具的正确工具图片输入到最终工具异常检测模型,得到当前二分类损失值和当前关系损失值；根据当前二分类损失值和当前关系损失值得到输出分数并判断当前工具是否放置异常,重复检测步骤直至当前工具箱图片中所有工具检测完成。</td>   <td>G06T7/00;G06T7/10;G06N3/0464;G06N3/084;G06V10/82;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         粟涛;              周雨迪;                   陈弟虎       </td>   <td>中山大学</td>   <td>一种单阶段遥感图像目标检测算法</td>   <td>广东省</td>   <td>CN112102241B</td>   <td>2023-10-20</td>   <td>本发明公开了一种单阶段遥感图像目标检测算法,以Yolo v3为基准,在Yolo v3的特征提取网络中加入金字塔卷积,将Yolo v3的检测网络替换为路径聚合网络,并改进所述路径聚合网络的上采样方式为转置卷积,最后在所述特征提取网络及所述检测网络之间加入空间金字塔池化作为中间连接。本发明的单阶段遥感图像目标检测算法与Yolo v3相比,检测速度基本没有影响,有效提高了检测精度。</td>   <td>1.一种单阶段遥感图像目标检测算法,其特征在于：以Yolo v3为基准,在Yolo v3的特征提取网络中加入金字塔卷积,将Yolo v3的检测网络替换为路径聚合网络,并改进所述路径聚合网络的上采样方式为转置卷积,最后在所述特征提取网络及所述检测网络之间加入空间金字塔池化作为中间连接；所述特征提取网络的主干网络前两层3×3卷积替换为所述金字塔卷积；所述金字塔卷积内部进行分组卷积；所述空间金字塔池化的步骤为,首先对所述特征提取网络输出的特征图进行通道数为512的1×1卷积,再经过尺度为5、步长为1的最大池化,之后又回到所述特征图并进行尺度为13、步长为1的最大池化,最后将所有最大池化的结果与所述特征图进行维度的拼接；训练过程使用损失函数更新权重,所述损失函数由预测框的位置损失、置信度损失和类别损失组成,所述位置损失的公式为GIOU损失,表达式如下,                  上式中A为候选框,B为原标记框,C为A、B的最小闭包；所述置信度损失的公式如下,                  上式中的FL为Focalloss,设置γ为0.5,λ-(noobj)为0.005；类别损失的公式如下,                  上式中,表示(i,j)预测框属于类别c的概率,λ-c为类别权重,/&gt;表示标记框所属类别真实值。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭雪梅;              王国利;              谢泳伦;                   陈焕杰       </td>   <td>中山大学</td>   <td>一种结合深度学习和图像处理的烟盒缺陷识别方法</td>   <td>广东省</td>   <td>CN112132196B</td>   <td>2023-10-20</td>   <td>本发明公开了一种结合深度学习和图像处理的烟盒缺陷识别方法,该方法包括：获取原始图像并对原始图像进行处理,得到样本图像和烟盒图像；根据样本图像训练神经网络模型,得到特征提取模型；将烟盒图像输入到特征提取模型,并对特征提取模型中的卷积层的数据进行求导及加权求和,得到热力图；根据热力图和烟盒图像,计算得到烟盒图像中的缺陷长宽。通过使用本发明,能准确判断工业流水线上的烟盒是否存在缺陷并计算出烟盒中的缺陷区域范围和缺陷的具体大小。本发明作为一种结合深度学习和图像处理的烟盒缺陷识别方法,可广泛应用于图像处理领域。</td>   <td>1.一种结合深度学习和图像处理的烟盒缺陷识别方法,其特征在于,包括以下步骤：获取原始图像并对原始图像进行处理,得到样本图像和烟盒图像；根据样本图像训练神经网络模型,得到特征提取模型；将烟盒图像输入到特征提取模型,并对特征提取模型中的卷积层的数据进行求导及加权求和,得到热力图；根据热力图和烟盒图像,计算得到烟盒图像中的缺陷长宽；所述获取原始图像并对原始图像进行处理,得到样本图像和烟盒图像这一步骤,其具体包括：获取原始图像并对原始图像进行预处理,得到分类后的预处理图像；将分类后的预处理图像进行图像增强,得到多个样本图像和烟盒图像；所述将烟盒图像输入到特征提取模型,并对特征提取模型中的卷积层的数据进行求导及加权求和,得到热力图这一步骤,其具体包括：将烟盒图像输入到特征提取模型,对烟盒图像进行推断并提取得到特征图；对特征提取模型中最后一个卷积层的数据进行求导得到梯度,并将梯度的均值作为特征图的权重；将特征图乘以对应权重得到带权重的特征图并对带权重的特征图求平方和,归一化处理得到热力图；所述根据热力图和烟盒图像,计算得到烟盒图像中的缺陷长宽这一步骤,其具体包括：将热力图转换为HSV格式,得到HSV格式的热力图；对HSV格式的热力图中的区域进行颜色设置并根据区域对应的颜色得到烟盒缺陷区域的掩膜图像；对掩膜图像进行图像处理,得到图像轮廓和缺陷坐标；根据缺陷坐标对烟盒图像进行裁剪,得到裁剪后的缺陷区域；对裁剪后的缺陷区域进行膨胀和腐蚀操作,得到缺陷区域最小面积矩形框；根据最小面积矩形框计算得到烟盒图像的缺陷长宽。</td>   <td>G06V10/764;G06V10/80;G06V10/82;G06N3/0464;G06V10/40;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              郭彤彤;                   李中华       </td>   <td>中山大学</td>   <td>一种基于多尺度特征融合的工业表面缺陷检测方法</td>   <td>广东省</td>   <td>CN112561910B</td>   <td>2023-10-20</td>   <td>本发明公开了一种基于多尺度特征融合的工业表面缺陷检测方法,该方法包括：获取训练样本并对训练样本进行预处理,得到训练样本数据；基于小卷积核构建分割网络并根据训练样本数据对分割网络进行训练,得到训练完成的分割网络；基于小卷积核构建分类网络并根据训练样本数据对分类网络进行训练,得到训练完成的分类网络；基于训练完成的分割网络和训练完成的分类网络对待测样本进行检测,得到检测结果；所述训练完成的分割网络包括低层特征提取模块、高层特征提取模块和多尺度特征融合模块。本发明在保证检测准确率的情况下,减少计算量。本发明作为一种基于多尺度特征融合的工业表面缺陷检测方法,可广泛应用于工业缺陷检测领域。</td>   <td>1.一种基于多尺度特征融合的工业表面缺陷检测方法,其特征在于,包括以下步骤：获取训练样本并对训练样本进行预处理,得到训练样本数据；基于小卷积核构建分割网络并根据训练样本数据对分割网络进行训练,得到训练完成的分割网络；基于小卷积核构建分类网络并根据训练样本数据对分类网络进行训练,得到训练完成的分类网络；基于训练完成的分割网络和训练完成的分类网络对待测样本进行检测,得到检测结果；所述训练完成的分割网络包括低层特征提取模块、高层特征提取模块和多尺度特征融合模块；所述基于小卷积核构建分割网络并根据样本数据对分割网络进行训练,得到训练完成的分割网络这一步骤,其具体包括：基于小卷积核构建分割网络；将样本数据输入到分割网络,经过低层特征提取模块得到低级细节特征；将低级细节特征经过高层特征提取模块,得到高级语义特征；将低级细节特征和高级语义特征经过多尺度特征融合模块,得到最终的分割特征；根据分割特征对图像样本进行分割,得到分割掩膜；将分割掩膜与对应的掩膜标签对比计算分割误差并反馈给分割网络进行迭代训练,得到训练完成的分割网络；所述分割误差的计算公式如下：l-n＝-[y-n.logσ(x-n)+(1-y-n).log(1-σ(x-n))]L(x,y)＝{l-1,l-2,l-3,...,l-N}～T上式中,l-n表示某个像素的分类误差,x-n表示某个像素的网络输出值,y-n表示某个像素真实的标签,σ表示Sigmoid函数,将x-n转换为0-1之间的概率值,L(x,y)表示一张图像上所有像素的分类误差集合,最后的loss值为L(x,y)集合的平均值；所述基于小卷积核构建分类网络并根据训练样本数据对分类网络进行训练,得到训练完成的分类网络这一步骤,其具体包括：基于小卷积核构建分类网络；将分割特征和分割掩膜输入到分类网络,输出该样本是缺陷样本的概率；将该概率与对应的类别标签对比计算分类误差并反馈给分类网络进行迭代训练,得到训练完成的分类网络；所述分类误差的计算公式如下：                  其中,y表示图像类别标签,0代表该样本是无缺陷的,1代表该样本是有缺陷的,out为样本输出的类别逻辑概率。</td>   <td>G06T7/00;G06T7/11;G06V10/80;G06V10/774;G06V10/764;G06V10/82;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢晓华;              黄俊嘉;                   赖剑煌       </td>   <td>中山大学</td>   <td>一种基于边缘增强的图像去模糊方法</td>   <td>广东省</td>   <td>CN112634153B</td>   <td>2023-10-20</td>   <td>本发明公开了一种基于边缘增强的图像去模糊方法,该方法包括：获取运动模糊图像并基于边缘提取算法对运动模糊图像进行处理,得到运动模糊图像边缘；将运动模糊图像和运动模糊图像边缘输入到预设的去模糊神经网络进行特征提取和特征融合,得到去模糊图像。本发明在保证去模糊质量的情况下,减少模型推导时间和模型参数数量。本发明作为一种基于边缘增强的图像去模糊方法,可广泛应用于图像处理领域。</td>   <td>1.一种基于边缘增强的图像去模糊方法,其特征在于,包括以下步骤：获取运动模糊图像并基于边缘提取算法对运动模糊图像进行处理,得到运动模糊图像边缘；将运动模糊图像和运动模糊图像边缘输入到预设的去模糊神经网络进行特征提取和特征融合,得到去模糊图像；所述将运动模糊图像和运动模糊图像边缘输入到预设的去模糊神经网络进行特征提取和特征融合,得到去模糊图像这一步骤,其具体包括：将运动模糊图像和运动模糊图像边缘输入到预设的去模糊神经网络；将运动模糊图像经过图像主体部分,得到内容特征；将运动模糊图像边缘经过边缘主体部分,得到边缘特征；将内容特征和边缘特征进行融合处理,得到去模糊图像；所述将运动模糊图像经过图像主体部分,得到内容特征这一步骤,其具体包括：运动模糊图像经过图像主体部分4级图像下采样模块和4级图像上采样模块分别提取特征图,并在每一级图像下采样模块中将图像下采样模块中对应维度的特征图与图像上采样模块中对应维度的特征图相加,得到长和宽均变为输入图像1/16的最终特征图；根据最终特征图得到内容特征；所述将运动模糊图像边缘经过边缘主体部分,得到边缘特征这一步骤,其具体包括：运动模糊图像边缘经过边缘主体部分的4级边缘下采样模块和4级边缘上采样模块分别提取特征图,并在每一级边缘下采样模块中将边缘下采样模块中对应维度的特征图与边缘上采样模块中对应维度的特征图相加,得到长和宽均变为输入图像1/16的最终边缘特征图；根据最终边缘特征图得到边缘特征；所述将内容特征和边缘特征进行融合处理,得到去模糊图像这一步骤,其具体包括：在上采样过程中通过将边缘特征经过一个卷积层转化为通道为1的掩膜,得到边缘特征掩膜信息；基于像素级相乘的方法将内容特征和边缘特征掩膜信息进行融合,得到去模糊图像。</td>   <td>G06T5/00;G06T5/50;G06T7/13;G06V10/52;G06V10/80;G06V10/82;G06N3/0464;G06N3/045;G06N3/048</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈焕杰;              王国利;              郭雪梅;                   谢泳伦       </td>   <td>中山大学</td>   <td>一种面向云端部署的多目标轨迹跟踪方法及系统</td>   <td>广东省</td>   <td>CN112669345B</td>   <td>2023-10-20</td>   <td>本发明公开了一种面向云端部署的多目标轨迹跟踪方法及系统,该方法包括：对预构建的目标检测模型进行FP16推断优化加速,得到优化后的目标检测模型；获取摄像头的实时图像数据并基于优化后的目标检测模型对实时图像数据进行检测,得到人员框和轨迹框；根据当前人员框中的人员信息,选择匹配方式与上一帧存在的轨迹信息进行匹配,得到匹配结果；根据匹配结果对人员信息和轨迹状态进行更新。该系统包括：优化模块、检测模块、匹配模块和更新模块。本发明能够提高多目标跟踪的性能。本发明作为一种面向云端部署的多目标轨迹跟踪方法及系统,可广泛应用于多目标跟踪技术领域。</td>   <td>1.一种面向云端部署的多目标轨迹跟踪方法,其特征在于,包括以下步骤：对预构建的目标检测模型进行FP16推断优化加速,得到优化后的目标检测模型；获取摄像头的实时图像数据并基于优化后的目标检测模型对实时图像数据进行检测,得到人员框和轨迹信息；根据当前人员框中的人员信息,选择匹配方式与上一帧存在的轨迹信息进行匹配,得到匹配结果；根据匹配结果对人员信息和轨迹状态进行更新；所述匹配方式包括外观特征匹配、重叠面积匹配和中心距离匹配,所述根据当前人员框中的人员信息,选择匹配方式与上一帧存在的轨迹信息进行匹配,得到匹配结果这一步骤,其具体为：提取当前人员框中的人员外观特征,选择外观特征匹配方法,与前一帧的人员外观特征计算特征距离并给予匈牙利算法进行匹配；对于未匹配上的人员框和轨迹信息,计算重叠匹配度并基于匈牙利算法进行重新匹配；对于仍未匹配上的人员框和轨迹信息,计算中心点之间的距离并基于匈牙利算法进行匹配；得到匹配结果；所述根据匹配结果对人员信息和轨迹状态进行更新这一步骤,其具体包括：对人员轨迹信息进行建模,将人员的轨迹信息表示为其中(u,v)是当前人员轨迹的中心坐标,γ是轨迹框的长宽比,h表示轨迹框的高度,/&gt;表示人员在图像坐标系中的速度信息；对于匹配上的轨迹信息,采用一个基于匀速模型和线性观测模型的卡尔曼滤波器,对该轨迹信息对应的人员信息进行更新并预测下一帧的位置,得到下一帧的轨迹信息(u,v,γ,h)；对于未匹配上的轨迹信息,基于预设规则对轨迹状态进行更新；所述特征距离包括平方马氏距离和余弦相似度的加权融合,所述平方马氏距离的计算公式如下：                  上式中,d-j表示第j个检测框的位置,y-i表示第i个轨迹对目标的预测位置,S-i表示检测框位置和预测轨迹位置之间的协方差矩阵,d～((1))(i,j)则表示第j个检测框和第i条预测轨迹之间的运动匹配度；所述余弦相似度的计算公式如下：                  上式中,表示第i个检测框中人员的外观特征向量库中的第k个外观特征向量,r-j表示第j条预测轨迹框的特征向量,d～((2))(i,j)表示第i个检测框中人员的外观特征向量库和第j条预测轨迹框的特征向量之间的最小余弦距离。</td>   <td>G06T7/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马锦华;                   陈曦       </td>   <td>中山大学</td>   <td>一种无需训练且无监督的目标协同定位方法、系统及装置</td>   <td>广东省</td>   <td>CN112686256B</td>   <td>2023-10-20</td>   <td>本发明公开了一种无需训练且无监督的目标协同定位方法、系统及装置,该方法包括：获取图像集合；将图像集合输入到预训练的CNN模型并得到特征集；对卷积激活张量进行降维,返回特征向量；根据卷积激活张量和特征向量,生成热图；基于热图生成边界框,完成目标协同定位。该系统包括：数据获取模块,卷积激活张量生成模块、特征向量生成模块、热图生成模块和边界框生成模块。该装置包括存储器以及用于执行上述无需训练且无监督的目标协同定位方法的处理器。通过使用本发明,能够解决计算机视觉中目标协同定位的问题同时提高现有模型的可重用性。本发明作为一种无需训练且无监督的目标协同定位方法、系统及装置,可广泛应用于目标定位领域。</td>   <td>1.一种无需训练且无监督的目标协同定位方法,其特征在于,包括以下步骤：获取数据,得到图像集合；将图像集合输入到预训练的CNN模型并将生成的卷积激活张量进行收集,得到特征集；基于TSNE算法对特征集中的卷积激活张量进行降维,返回特征向量；根据卷积激活张量和特征向量,生成热图；基于热图构建二值矩阵并生成边界框,完成目标协同定位；所述热图的生成公式如下：                  上式中,i,j表示单个位置,H-(i,j)表示热图,G-(i,j,k)表示图像经过模型得到的特征图,P-k表示特征向量,d表示维度,k表示第k维。</td>   <td>G06V10/22;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              李振昌;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种应用特征解耦的低剂量CT图像修复方法及系统</td>   <td>广东省</td>   <td>CN112767273B</td>   <td>2023-10-20</td>   <td>本发明公开了一种应用特征解耦的低剂量CT图像修复方法及系统,该方法包括：获取原始低剂量CT扫描图像；对原始低剂量CT扫描图像进行特征解耦,得到待处理的特征；将待处理的特征进行修复处理并聚合,得到聚合后特征；对聚合后特征进行解码,恢复出修复后的正常剂量CT扫描图像。该系统包括：图像获取模块、特征解耦模块、修复聚合模块和恢复模块。本发明考虑混合失真之间的相互干扰,对低剂量CT图像进行去噪和修复。本发明作为一种应用特征解耦的低剂量CT图像修复方法及系统,可广泛应用于图像修复领域。</td>   <td>1.一种应用特征解耦的低剂量CT图像修复方法,其特征在于,包括以下步骤：获取原始低剂量CT扫描图像；对原始低剂量CT扫描图像进行特征解耦,得到待处理的特征；将待处理的特征进行修复处理并聚合,得到聚合后特征；对聚合后特征进行解码,恢复出修复后的正常剂量CT扫描图像；所述对原始低剂量CT扫描图像进行特征解耦,得到待处理的特征这一步骤,其具体包括：基于编码器对原始低剂量CT扫描图像,得到图像的特征表征；基于FDM特征解耦器对图像的特征表征进行特征解耦,得到噪声失真的特征和纹理细节失真的特征；FDM特征解耦器引入引入谱值差正交正则化作为损耗约束,谱值差正交正则化表达式如下：                  其中,λ-1(FF～T)和λ-2(FF～T)分别表示FF～T的最大特征值和最小特征值,F是特征表征,T表示矩阵转置；所述将待处理的特征进行修复处理并聚合,得到聚合后特征这一步骤,其具体包括：基于预训练的去噪处理器对噪声失真的特征进行去噪处理,得到去噪后的特征；基于预训练的纹理修复器对纹理细节失真的特征进行纹理修复处理,得到纹理修复后的特征；将去噪后的特征和纹理修复后的特征经过FAM特征聚合模块进行特征聚合,得到聚合后的特征；FAM特征聚合模块对FDM时响应提取的公式进行反演：                  其中,F-(c-i)表示与干净图像的分布相对应的输出特征。</td>   <td>G06T5/00;G06N3/0455;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈翔;              安小洁;              叶东山;                   龚杰       </td>   <td>中山大学</td>   <td>一种面向家具板材的圆孔检测方法、系统及装置</td>   <td>广东省</td>   <td>CN112819823B</td>   <td>2023-10-20</td>   <td>本发明公开了一种面向家具板材的圆孔检测方法、系统及装置,该方法包括：对数据进行预处理；对预构建的RCF模型进行训练,得到边缘检测模型；对待测样本进行边缘粗提取,得到边缘概率图；选取像素点集；根据预设规则拟合计算圆心坐标、圆孔半径和方差并输出检测结果。该系统包括：预处理模块、边缘检测模型训练模块、边缘提取模块、像素点集选取模块和结果输出模块。该装置包括存储器以及用于执行上述面向家具板材的圆孔检测方法的处理器。通过使用本发明,能够在采样条件有限的情况下对包含复杂纹理的板材表面圆孔轮廓进行精准识别。本发明作为一种面向家具板材的圆孔检测方法、系统及装置,可广泛应用于计算机视觉边缘检测。</td>   <td>1.一种面向家具板材的圆孔检测方法,其特征在于,包括以下步骤：构建数据集并对数据集中的数据进行预处理,得到预处理后的数据；基于预处理后的数据对预构建的RCF模型进行训练,得到边缘检测模型；获取待测样本并基于边缘检测模型对待测样本进行边缘粗提取,得到边缘概率图；根据边缘概率图选取像素点集；将最小二乘法与Ransac算法结合并用于所选取的像素点集的拟合,得到圆心坐标、圆孔半径信息；所述构建数据集并对数据集中的数据进行预处理,得到预处理后的数据这一步骤,其具体包括：获取圆孔数据集并基于训练完成的超分辨率模型对圆孔数据集进行超分辨率重构,得到重构后圆孔数据集；将重构后圆孔数据集中的数据分别进行随机水平翻转、垂直翻转和随机剪切,得到扩充后圆孔数据集；对扩充后圆孔数据集中的数据进行灰度值均衡化处理,得到预处理后的数据；所述根据边缘概率图选取像素点集这一步骤,其具体包括：根据边缘概率图的大小初步限定得到圆孔边缘限定区域；根据边缘概率图中的纹理复杂程度将圆孔分为第一类圆孔和第二类圆孔；对于第一类圆孔,将圆孔边缘限定区域中像素值大于160的像素点记为数据点；对于第二类圆孔,将圆孔边缘限定区域中像素值大于235的像素点记为数据点；将数据点整合,得到像素点集；所述将最小二乘法与Ransac算法结合并用于所选取的像素点集的拟合,得到圆心坐标、圆孔半径信息这一步骤,其具体包括：基于最小二乘法和选取的像素点集进行拟合计算,得到圆心坐标、圆孔半径和方差；判断到方差小于预设值,以最小二乘法计算得到的圆心坐标和圆孔半径为检测结果；判断到方差不小于预设值,根据预设规则重新进行像素点集的选取并基于Ransac算法重新计算圆心坐标及半径值,得到检测结果。</td>   <td>G06T7/00;G06T7/13;G06T5/40;G06V10/774;G06V10/80;G06V10/77;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              严文俊;                   曾莹       </td>   <td>中山大学</td>   <td>一种基于光照差异消除的人脸活体检测方法及系统</td>   <td>广东省</td>   <td>CN113255562B</td>   <td>2023-10-20</td>   <td>本发明公开了一种基于光照差异消除的人脸活体检测方法及系统,该方法包括：获取人脸图像并输入到欺骗信息生成支路,得到欺骗信息；将人脸图像输入到光照生成模块模拟不同光照条件并分别提取对应的人脸特征；将不同光照条件下对应的人脸特征进行相似度约束,得到共同特征；将欺骗信息与共同特征结合判断,得到判断结果。该系统包括：欺骗信息单元、特征提取单元、特征约束单元和识别单元。通过使用本发明,能够消除光照对活体检测的影响,提高人脸活体检测的准确度。本发明作为一种基于光照差异消除的人脸活体检测方法及系统,可广泛应用于人脸图像处理领域。</td>   <td>1.一种基于光照差异消除的人脸活体检测方法,其特征在于,包括以下步骤：获取人脸图像并输入到欺骗信息生成支路,得到欺骗信息；将人脸图像输入到光照生成模块模拟不同光照条件并分别提取对应的人脸特征；将不同光照条件下对应的人脸特征进行相似度约束,得到共同特征；将欺骗信息与共同特征结合判断,得到判断结果；所述获取人脸图像并输入到欺骗信息生成支路,得到欺骗信息这一步骤,其具体包括：获取人脸图像并进行尺寸调整；将调整尺寸后的人脸图像输入到欺骗信息生成支路；经过欺骗信息编码网络和欺骗信息解码网络生成欺骗信息；所述将欺骗信息与共同特征结合判断,得到判断结果这一步骤,其具体包括：将欺骗信息与共同特征进行特征融合,得到活体特征；基于预构建的二分类任务对活体特征进行得分判定并与预设阈值进行比较；判断到该活体特征的得分大于预设值,对应的人脸图像为非真实人脸；判断到该活体特征的得分不大于预设值,对应的人脸图像为真实人脸。</td>   <td>G06V40/16;G06V40/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苗建明;              刘文超;              张淏酥;              孙兴宇;              王燕云;              郑若晗;              钟良靖;                   龚喜       </td>   <td>中山大学</td>   <td>水下无人航行器桨舵系统的构建方法、系统和航行器</td>   <td>广东省</td>   <td>CN116910907A</td>   <td>2023-10-20</td>   <td>本发明涉及水下无人航行器技术领域,公开了水下无人航行器桨舵系统的构建方法、系统和航行器,包括根据预设的图谱,得到螺旋桨的桨型参数,并根据预设的航行器最大航速,计算得到螺旋桨转速；根据所述桨型参数和所述螺旋桨转速,建立水下无人航行器的对转螺旋桨系统；根据水下无人航行器的尺寸参数,计算得到舵机参数；根据所述舵机参数,建立水下无人航行器的舵机系统,所述舵机系统包括四个控制舵,所述四个控制舵组成十字形结构。本发明简化了前桨与后桨的相互作用,提出了一种简化的新的构建方法,不仅推进效率高,还可以解决扭矩平衡的问题,具有极强的工程实用性,并且通过本发明提供的十字形舵,能够有效提高舵机的控制精度和执行效率。</td>   <td>1.一种水下无人航行器桨舵系统的构建方法,其特征在于,包括：根据预设的图谱,得到螺旋桨的桨型参数,并根据预设的航行器最大航速,计算得到螺旋桨转速,所述螺旋桨包括前桨和后桨,所述桨型参数包括叶数、盘面比和轴向间距；根据所述桨型参数和所述螺旋桨转速,建立水下无人航行器的对转螺旋桨系统；根据水下无人航行器的尺寸参数,计算得到舵机参数；根据所述舵机参数,建立水下无人航行器的舵机系统,所述舵机系统包括四个控制舵,所述四个控制舵组成十字形结构。</td>   <td>G06F30/15;G06F30/20;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚正安;                   王祎晨       </td>   <td>中山大学</td>   <td>一种根据偏离点划分的并行求解前K条最短路径的方法</td>   <td>广东省</td>   <td>CN116911474A</td>   <td>2023-10-20</td>   <td>本发明公开一种根据偏离点划分的并行求解前K条最短路径的方法,利用算法内各偏离点计算互不干扰的特点,将偏离点分成几个部分交给不同的进程分别计算,每个进程只需要处理各自的偏离点并生成候选路径,最后在同步所有进程的候选路径,即可快速得到前K条最短路径。本发明求解每一条最短路径时,都会有n个进程同时计算候选路径,这样就可以缩短算法收敛的时间。理想情况下,并行Yen算法的收敛时间是串行的1/n。考虑到各进程间通讯的损耗,实际收敛时间要多于理想时间,但相比于原始串行算法,算法的计算效率依旧提升了很多。</td>   <td>1.一种根据偏离点划分的并行求解前K条最短路径的方法,其特征在于,包括以下步骤：S1：读取图G,所述图G中的点表示不同的地点,两点之间的连线的权值表示两点的距离；S2：计算图G的最短路径,并将所述最短路径存入最短路径集合A中；S3：将图G和所述最短路径集合A传播至所有子进程；S4：读取最短路径集合A中的上一轮迭代得到的最短路径,获得上一轮迭代得到的最短路径上的所有的偏离点,将所述偏离点分割为若干份,每一份分配一个子进程；S5：每个子进程根据分配到的偏离点求解对应的候选路径,并保存至各自的子进程最短路径集合B中；S6：各子进程根据各自的子进程最短路径集合B,选出权值和最小且结点数最小的本地最短路径；S7：收集各子进程的本地最短路径信息,从中选出全局最短路径,将所述全局最短路径添加至最短路径集合A中,相应的子进程最短路径集合B中移除所述全局最短路径；S8：重复步骤S4至步骤S7,直到找到需要的K条路径或各进程内子进程最短路径集合B均为空,得到前K条最短路径。</td>   <td>G06Q10/047</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚正安;                   冯怀钰       </td>   <td>中山大学</td>   <td>一种基于纹理特征的图像色彩迁移方法和装置</td>   <td>广东省</td>   <td>CN116912080A</td>   <td>2023-10-20</td>   <td>本发明公开一种基于纹理特征的图像色彩迁移方法和装置,方法包括获取源图像和参考图像；将源图像和参考图像转换到lαβ色彩空间；对源图像的亮度直方图进行调整；对调整后的源图像和参考图像分别计算纹理特征；利用源图像的纹理特征和参考图像的纹理特征分别形成训练集和预测集；利用源图像的纹理特征形成的训练集和参考图像的纹理特征的训练集,分别训练第一预测模型和第二预测模型,得到训练好的第一预测模型和第二预测模型；利用源图像的纹理特征形成的预测集,利用训练好的第一预测模型预测α通道的取值,训练好的第二预测模型预测β通道的取值；完成参考图像到源图像的色彩迁移。本发明取得了良好的色彩迁移效果。</td>   <td>1.一种基于纹理特征的图像色彩迁移方法,其特征在于,包括以下步骤：S1：获取源图像和参考图像；S2：将所述源图像和参考图像转换到lαβ色彩空间；S3：对所述源图像的亮度直方图进行调整使得所述源图像的亮度和所述参考图像的亮度在同一范围内；S4：对经步骤S3调整后的源图像和参考图像分别计算纹理特征；S5：利用源图像的纹理特征和参考图像的纹理特征分别形成训练集和预测集；S6：利用源图像的纹理特征形成的训练集和参考图像的纹理特征的训练集,分别训练第一预测模型和第二预测模型,得到训练好的第一预测模型和第二预测模型,其中,所述第一预测模型用于预测α通道的取值,所述第二预测模型用于预测β通道的取值；S7：利用源图像的纹理特征形成的预测集,利用训练好的第一预测模型预测α通道的取值,训练好的第二预测模型预测β通道的取值；S8：完成参考图像到源图像的色彩迁移。</td>   <td>G06T3/00;G06T5/00;G06T5/40;G06T7/40;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑培嘉;              陈静怡;              曾惠聪;                   蔡志威       </td>   <td>中山大学</td>   <td>一种基于神经网络的加密域图像超分辨率重建方法及系统</td>   <td>广东省</td>   <td>CN116912089A</td>   <td>2023-10-20</td>   <td>本发明公开一种基于神经网络的加密域图像超分辨率重建方法及系统,涉及图像超分辨率重建的技术领域,将训练好的超分辨神经网络模型封装于图像超分辨率重建执行服务器中。隐私服务器生成公钥和私钥,并将公钥发送至图像超分辨率重建执行服务器,客户端对图像数据进行编码加密并发送给图像超分辨率重建执行服务器。图像超分辨率重建执行服务器利用模型在加密域中对加密图像进行超分辨率重建,将超分辨率重建结果发送给客户端,客户端进行解密得到图像超分辨率重建结果。在保证隐私安全性的同时,服务端图像重建质量不仅显著提高,客户端的图像拥有者可进行多张低分辨率图像重建,降低了单位加密图像超分辨率重建时间开销。</td>   <td>1.一种基于神经网络的加密域图像超分辨率重建方法,其特征在于,包括以下步骤：S1：收集图像数据,将所述图像数据划分为训练集和测试集；S2：构建超分辨神经网络模型,所述超分辨神经网络模型用于对输入图像进行超分辨率重建,利用所述训练集训练所述超分辨神经网络模型,利用所述测试集测试所述超分辨神经网络的性能,得到最终的超分辨神经网络模型,将最终的超分辨神经网络模型封装于图像超分辨率重建执行服务器中；S3：利用隐私服务器生成公钥pk和私钥sk,将公钥pk和私钥sk均发送至客户端,将公钥pk发送给所述图像超分辨率执行服务器；S4：客户端利用公钥pk对待重建低分辨率图像进行数据编码加密,然后将加密后的图像数据和目标像素的规格发给所述图像超分辨率执行服务器；S5：所述图像超分辨率执行服务器根据所述目标像素的规格对所述加密后的图像数据进行双三插值,得到密文编码,再利用所述最终的超分辨神经网络模型对密文编码在加密域中进行超分辨率重建,得到高分辨率图像对应的密文；S6：所述图像超分辨率执行服务器将所述高分辨率图像对应的密文发给客户端,客户端利用私钥sk解密后,获得图像超分辨率重建的结果。</td>   <td>G06T3/40;G06F21/60;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苗建明;              郑若晗;              张文睿;              张淏酥;              邵金鑫;              马成;              孙兴宇;              王燕云;              刘文超;                   钟良靖       </td>   <td>中山大学</td>   <td>一种水下图像自适应增强方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN116912115A</td>   <td>2023-10-20</td>   <td>本发明涉及计算机视觉技术领域,尤其涉及一种水下图像自适应增强方法、系统、设备及存储介质,包括：利用加权系数对原始水下图像进行锐化处理,将得到的锐化图像依次进行自适应中值滤波和自适应边缘检测,得到边缘增强图像；根据边缘增强图像、原始水下图像和锐化图像,得到融合图像；根据获取到的同态滤波参数最优值对融合图像进行同态滤波增强,得到水下增强图像。本发明对水下光照不均的图像进行自适应增强处理,解决了传统基于边缘检测的水下图像处理方法在处理复杂图像时会产生大量噪声和错误信息,导致获取到的水下图像质量较差的问题,使得增强后的图像细节更加丰富清晰,整体图像的对比度以及标准化亮度等都能得到进一步提升。</td>   <td>1.一种水下图像自适应增强方法,其特征在于,包括以下步骤：采集原始水下图像,并利用预先获取的加权系数对所述原始水下图像进行锐化处理,得到锐化图像；将所述锐化图像进行自适应中值滤波,得到自适应中值滤波图像；对所述自适应中值滤波图像进行自适应边缘检测,得到边缘增强图像；获取所述锐化图像的二值图像,并将所述二值图像和所述边缘增强图像进行按位与操作,得到边缘图像；根据所述锐化图像的亮度,将所述边缘图像与所述原始水下图像或者所述锐化图像融合,得到融合图像；确定同态滤波参数最优值,根据所述同态滤波参数最优值对所述融合图像进行同态滤波增强,得到水下增强图像。</td>   <td>G06T5/00;G06T5/20;G06T7/13;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑泳;              陈逸敏;              秦雁;              吉红香;              黄本胜;              冯明薇;              罗澍然;              姜明;              彭力恒;              王晟力;              徐张帆;              蔡季宏;              周晓鑫;              杨楚旋;              钟丽坤;              周华智;                   刘旭峰       </td>   <td>广东省水利水电科学研究院;中山大学</td>   <td>一种水浮莲变化检测方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN116912676A</td>   <td>2023-10-20</td>   <td>本发明公开了一种水浮莲变化检测方法、装置、电子设备及存储介质,方法包括：获取第一区域的遥感时序影像,从遥感时序影像获得目标遥感影像；根据目标遥感影像,通过归一化植被指数计算提取植被覆盖图；获取第一区域的高程数据,基于高程数据获取第一区域的平地图；对植被覆盖图和平地图进行取交集处理,获得单期植被覆盖平地图；根据遥感时序影像,得到第一区域的时序特征,并基于时序特征确定目标植被提取指数；对单期植被覆盖平地图和目标植被提取指数进行叠加分析,获得目标植被分布图。本发明基于构建的水浮莲提取指数,结合提取植被覆盖信息,以及得到的平地图,能够快速识别监测日期的水浮莲覆盖情况,可广泛应用于影像数据处理技术领域。</td>   <td>1.一种水浮莲变化检测方法,其特征在于,包括：获取第一区域的遥感时序影像,从所述遥感时序影像获得目标遥感影像；根据所述目标遥感影像,通过归一化植被指数计算提取植被覆盖图；获取所述第一区域的高程数据,基于所述高程数据获取所述第一区域的平地图；对所述植被覆盖图和所述平地图进行取交集处理,获得单期植被覆盖平地图；根据所述遥感时序影像,计算得到所述第一区域的时序特征,并基于所述时序特征确定目标植被提取指数；其中,所述时序特征包括所述第一区域各栅格点的归一化植被指数和改进归一化植被指数的历史数值；所述改进归一化植被指数通过绿光波段地表反射率和中红外波段地表反射率计算得到；对所述单期植被覆盖平地图和所述目标植被提取指数进行叠加分析,获得目标植被分布图。</td>   <td>G06V20/10;G06V20/13;G06V10/143</td>  </tr>        <tr>   <td>中国专利</td>   <td>         单云霄;                   张琪       </td>   <td>中山大学;中山大学深圳研究院;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种基于激光雷达和相机融合的海面目标检测方法及系统</td>   <td>广东省</td>   <td>CN116912688A</td>   <td>2023-10-20</td>   <td>本发明公开了一种基于激光雷达和相机融合的海面目标检测方法及系统,该方法包括：收集激光雷达和相机传感器数据,基于DBSCAN聚类进行点云目标检测,基于海天线提取算法和YOLOX目标检测网络进行图像目标检测,基于孪生目标跟踪器进行跟踪预测,最后融合点云目标检测结果、图像目标检测结果和跟踪预测结果,得到最终检测结果。该系统包括：点云数据获取模块、点云目标检测模块、图像数据获取模块、图像稳定模块、视觉目标检测模块、跟踪预测模块和目标融合模块。通过使用本发明,能够充分发挥激光雷达传感器和相机的优势,实现无人艇在复杂多变的海面环境下实现高鲁棒性的海面目标感知。本发明可广泛应用于无人艇自动驾驶领域。</td>   <td>1.一种基于激光雷达和相机融合的海面目标检测方法,其特征在于,包括以下步骤：通过激光雷达传感器获取点云数据；对点云数据进行聚类分析,得到点云目标；通过相机获取图像数据；对图像数据进行平稳处理,得到稳定图像；对稳定图像进行目标检测,得到视觉目标；利用孪生目标跟踪器对稳定图像和历史稳定图像进行跟踪,得到预测目标；通过基于置信度与重叠度的融合策略对点云目标、视觉目标和预测目标进行融合,得到最终检测目标。</td>   <td>G06V20/10;G01S7/48;G01S17/86;G01S17/93;G06V10/25;G06V10/24;G06V10/34;G06V10/44;G06V10/762;G06V10/764;G06V10/80;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈旭;                   王朴       </td>   <td>中山大学</td>   <td>一种基于联邦学习的人类行为识别应用的模型训练方法</td>   <td>广东省</td>   <td>CN116912942A</td>   <td>2023-10-20</td>   <td>本发明公开了一种基于联邦学习的人类行为识别应用的模型训练方法,该方法包括：获取全局混合模型的参数并下发至强算力设备和弱算力设备；设定训练参数并估算每个强算力设备最大可协同训练样本数量；获取用户上传的本地样本loss列表,结合预设阈值,生成每个弱算力设备选择的参与协同训练的样本数；以最大化参与协同训练的样本总数为目标,为强算力设备匹配弱算力设备进行协同训练,得到匹配结果；根据匹配结果进行训练,生成本地模型参数；将本地模型参数进行聚合,得到最终全局混合模型参数。通过使用本发明,使得异构设备可以根据自身的计算能力自适应地训练合适的深度学习模型,更充分的利用设备的计算资源。本发明涉及模型应用领域。</td>   <td>1.一种基于联邦学习的人类行为识别应用的模型训练方法,其特征在于,包括以下步骤：获取全局混合模型的参数并下发至强算力设备和弱算力设备；设定训练参数并估算每个强算力设备最大可协同训练样本数量；获取用户上传的本地样本loss列表,结合预设阈值,生成每个弱算力设备选择的参与协同训练的样本数；根据每个强算力设备最大可协同训练样本数量和每个弱算力设备选择的参与协同训练的样本数,以最大化参与协同训练的样本总数为目标,为强算力设备匹配弱算力设备进行协同训练,得到匹配结果；根据匹配结果进行训练,生成本地模型参数；将本地模型参数进行聚合,得到最终全局混合模型参数。</td>   <td>G06V40/20;G06V10/774;G06V10/75;G06V10/82;G06N3/098</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何海涛;                   关伟豪       </td>   <td>中山大学</td>   <td>一种人脸图片管理、同步的安全管理系统及方法</td>   <td>广东省</td>   <td>CN111159136B</td>   <td>2023-10-17</td>   <td>本发明提供的一种人脸图片管理、同步的安全管理系统,包括分布式人脸基准库平台、数据采集机和第三方应用平台；数据采集机进行人脸图片采集,在分布式人脸基准库平台中进行存储；分布式人脸基准库平台对人脸图片进行特征提取,生成特征文件；将特征文件推送至第三方应用平台；第三方应用平台利用特征文件完成人脸识别过程。本发明还提供一种安全管理方法,在分布式人脸基准库平台上将人脸图片进行特征的提取,生成特征文件,实现对人脸图片库的统一管理；第三方应用平台在需要调用人脸图片库时,只能根据特征文件完成人脸识别,避免了将人脸图片直接存储于识别前端所可能造成的隐私泄露问题,有效提高了人脸识别过程的安全性。</td>   <td>1.一种人脸图片管理、同步的安全管理系统,其特征在于：包括分布式人脸基准库平台、数据采集机和第三方应用平台；其中：所述数据采集机进行人脸图片采集,并将采集到的人脸图片通过https以base64编码格式的方式提交至分布式人脸基准库平台；所述分布式人脸基准库平台包括人脸图片库、特征提取模块、URL推送模块和SDK库管理模块；所述人脸图片库用于保存采集到的人脸图片,由特征提取模块对人脸图片进行特征提取,生成特征文件；最后由URL推送模块将特征文件推送至所述第三方应用平台；所述第三方应用平台包括注册模块、SDK特征生成接口和特征算法版本记录模块；所述第三方应用平台通过所述注册模块进行注册,注册时通过所述SDK特征生成接口将注册信息发送至所述SDK库管理模块,同时由所述特征算法版本记录模块记录特征算法版本信息；所述第三方应用平台利用特征文件完成人脸识别过程；所述分布式人脸基准库平台还包括图片库版本检测模块、算法规则模块、SDK调用模块和版本比对模块；所述第三方应用平台还包括SDK更新模块、特征库更新模块和特征库；其中：所述图片库版本检测模块周期性检测人脸图片库是否进行更新,若版本进行了更新,则通过所述SDK调用模块调用所述SDK特征生成接口,获取所述特征算法版本信息；所述算法规则模块与所述SDK库管理模块信息交互,用于记录不同的第三方应用平台的特征算法规则及版本；所述版本比对模块判断所述算法规则模块与第三方应用平台的特征算法版本信息是否一致,若一致,由特征提取模块对人脸图片进行特征提取,生成特征文件,由URL推送模块将特征文件推送至所述第三方应用平台,由所述特征库更新模块对存储于特征库中的特征文件的更新,并将更新结果发送分布式人脸基准库平台进行记录；否则,生成版本异常信息发送至所述第三方应用平台,由SDK更新模块对在所述版本信息记录模块中记录,并对所述算法规则模块中的特征算法进行更新；所述分布式人脸基准库平台还包括分布式文件存储系统和Base64 DB主备存储系统,分布式人脸基准库平台通过所述分布式文件存储系统、Base64 DB主备存储系统进行周期性的数据备份,并将备份文件进行独立保存。</td>   <td>G06F16/182;G06F16/178;G06F16/51;G06F16/532;G06F16/27;G06V40/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王立国;              冯瀚生;                   林茂峰       </td>   <td>中山大学</td>   <td>一种波浪能发电装置节间距优化方法及装置</td>   <td>广东省</td>   <td>CN112365026B</td>   <td>2023-10-17</td>   <td>本发明公开了一种波浪能发电装置节间距优化方法及装置,方法包括：设置目标区域的海洋环境参数,并根据目标区域的海洋环境参数计算波能谱；根据目标区域的波能谱和波浪能发电装置的几何参数,计算得到波浪能发电装置的水动力系数；根据水动力系数和谱方法计算得到目标区域中波浪能发电装置在物理约束下的总发电功率的时间平均值；采用优化算法,根据波浪能发电装置的总发电功率的时间平均值对波浪能发电装置中浮子的尺寸参数和节间距参数进行优化,得到波浪能发电装置总发电功率最大时,波浪能发电装置中浮子的最优尺寸参数和最优节间距参数。本发明实施例能够有效提高波浪能发电装置的波浪能捕获效率。</td>   <td>1.一种波浪能发电装置节间距优化方法,其特征在于,包括：根据目标区域的海况以及当地地形,设置海洋环境参数,并根据所述海洋环境参数计算波能谱；其中,所述海洋环境参数包括：非规则波情况下的有效波高和周期或者规则波情况下的波高和周期；根据所述波能谱和所述目标区域中的波浪能发电装置的几何参数,计算得到所述波浪能发电装置的水动力系数；根据所述水动力系数和谱方法求解波浪能发电装置的能量转换系统在计及约束条件下的最优控制量,采用所述最优控制量计算得到所述目标区域中所述波浪能发电装置在物理约束下的总发电功率的时间平均值；所述根据所述水动力系数和谱方法求解波浪能发电装置的能量转换系统在计及约束条件下的最优控制量,采用所述最优控制量计算得到所述目标区域中所述波浪能发电装置在物理约束下的总发电功率的时间平均值,具体为：利用基函数逼近波浪能发电装置状态量和能量转换系统的控制量,将所述水动力系数代入连续运动方程,并将所述连续运动方程离散化,将所述能量转换系统的控制变量的求解问题转化为标准优化问题,同时结合所述波浪能发电装置的物理约束条件,求解满足所述物理约束条件的能量转换系统的控制量的全局最优值,并根据所述全局最优值计算波浪能发电装置的总发电功率的时间平均值；采用优化算法,根据所述波浪能发电装置的总发电功率的时间平均值对所述波浪能发电装置中浮子的尺寸参数和节间距参数进行优化,得到所述波浪能发电装置总发电功率最大时,所述波浪能发电装置中浮子的最优尺寸参数和最优节间距参数；所述采用优化算法,根据所述波浪能发电装置的总发电功率的时间平均值对所述波浪能发电装置中浮子的尺寸参数和节间距参数进行优化,得到所述波浪能发电装置总发电功率最大时,所述波浪能发电装置中浮子的最优尺寸参数和最优节间距参数,具体方式为：根据优化算法求得在约束条件下函数的最小值,即为所述波浪能发电装置的最优总发电功率,同时可求得所述最优总发电功率对应的波浪能发电装置浮子的最优尺寸参数和最优节间距参数。</td>   <td>G06Q10/04;G06Q50/06;F03B13/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈舒雅;              王青松;                   焦润之       </td>   <td>中山大学</td>   <td>一种异源图像配准方法、系统及装置</td>   <td>广东省</td>   <td>CN113808180B</td>   <td>2023-10-17</td>   <td>本发明公开了一种异源图像配准方法、系统及装置,该方法包括：对SAR图像进行滤波并与对应的光学图像组成图像块对；将图像块对样本本输入深度卷积生成对抗网络进行训练；对训练样本进行数据增强并进行划分；基于训练集训练深度孪生匹配网络；基于训练完成的匹配网络生成匹配点对；根据匹配点对计算变换矩阵并配准图像。该系统包括：图像对样本模块、训练样本模块、划分模块、训练模块、匹配模块和配准模块。该装置包括存储器以及用于执行上述异源图像配准方法的处理器。通过使用本发明,能够提高异源配准精度。本发明作为一种异源图像配准方法、系统及装置,可广泛应用于图像配准领域。</td>   <td>1.一种异源图像配准方法,其特征在于,包括以下步骤：对SAR图像进行滤波并与对应的光学图像组成图像块对,得到图像块对样本；将图像块对样本本输入深度卷积生成对抗网络进行训练,得到训练样本；对训练样本进行数据增强并进行划分,得到训练集和测试集；基于训练集训练深度孪生匹配网络,得到训练完成的匹配网络；提取测试集中图片的图像块并输入至训练完成的匹配网络,得到匹配点对；根据匹配点对计算变换矩阵并配准图像；所述对训练样本进行数据增强并进行划分,得到训练集和测试集这一步骤,其具体包括：对训练样本进行几何变换,得到增强后训练样本；所述几何变换包括翻转、旋转、裁剪、平移和缩放；对增强后训练样本以7：3的比例划分训练集和测试集；所述基于训练集训练深度孪生匹配网络,得到训练完成的匹配网络这一步骤,其具体包括：根据训练集中由光学图像生成的伪SAR图像和对应的SAR图像对深度孪生匹配网络的一条分支进行训练；根据训练集中由SAR图像生成的伪光学图像和对应的光学图像对深度孪生匹配网络的另一条分支进行训练；结合判别标签对深度孪生匹配网络进行损失计算,得到训练完成的匹配网络；所述提取测试集中图片的图像块并输入至训练完成的匹配网络,得到匹配点对这一步骤,其具体包括：基于SIFT方法检测测试集中图片的特征点；根据图片的特征点对SAR图像和光学图像取图像块并输入至训练完成的匹配网络的两个分支,得到匹配结果；基于渐进一致采样方法对匹配结果进行处理,得到匹配点对。</td>   <td>G06T7/33;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   陈佳阳       </td>   <td>中山大学</td>   <td>基于邻居信息及互信息保留变分自编码器的语义哈希方法</td>   <td>广东省</td>   <td>CN116894075A</td>   <td>2023-10-17</td>   <td>本发明提出一种基于邻居信息及互信息保留变分自编码器的语义哈希方法,涉及文本处理的技术领域,基于文本数据的邻居信息,构建互信息保留的变分自编码器模型,结合变分自编码器模型,将待处理文本数据的邻居信息融入到哈希码训练的过程中,在该过程中,对于文本数据集中文本数据的相邻文本,得出具有容错能力的互信息下界,有效提高文本处理中语义哈希的准确性,提升了文本处理的准确率和效率。</td>   <td>1.一种基于邻居信息及互信息保留变分自编码器的语义哈希方法,其特征在于,所述方法包括以下步骤：S1.构造文本数据集中文本数据的邻居信息；S2.构建相邻文本之间互信息保留的变分自编码器模型；S3.将文本数据及其邻居信息输入至互信息保留的变分自编码器模型,计算文本数据的重构相似性；S4.从文本数据集中选取相邻文本,计算相邻文本对应的隐变量之间的互信息下界,所述互信息下界具有容错能力；S5.将本数据的重构相似性和相邻文本对应的隐变量之间的互信息下界最大化,更新互信息保留的变分自编码器模型的模型参数,得到更新后的互信息保留的变分自编码器模型；S6.获取待处理文本数据集,将待处理文本数据集中的文本数据输入至更新后的互信息保留的变分自编码器模型,确定最终的哈希码；S7.利用步骤S6得到的哈希码进行文档处理。</td>   <td>G06F16/31;G06F40/30;G06F18/22;G06N3/0455;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王帅;              何诗韵;              关贝贝;              雷箬儿;                   黎洁       </td>   <td>中山大学</td>   <td>基于超图和普通图混合求解最大影响力种子节点的方法</td>   <td>广东省</td>   <td>CN116894740A</td>   <td>2023-10-17</td>   <td>本发明公开了一种基于超图和普通图混合求解最大影响力种子节点的方法,该方法提供了一种基于超图的影响力的评估方法,并与现有的普通二部图影响力评估方法结合,得到一种性能更优的影响力最大化的方法。通过本发明可以从超图和普通图的混合网络结构中求解最大影响力种子节点,可广泛应用于计算机应用领域。</td>   <td>1.一种基于超图和普通图混合求解最大影响力种子节点的方法,其特征在于,包括：在超图和普通图中获取影响力最大的前K个节点,作为候选节点,K为正整数；对K个所述候选节点执行初始化算子,以生成初始种群,所述初始种群包括多个个体,每个所述个体对应多个所述候选节点；对所述初始种群中的各个个体进行交叉操作和变异操作,以更新所述个体对应的候选节点；根据各个所述个体对应的候选节点的影响力,更新所述个体对应的候选节点；根据各个所述候选节点的影响力从多个所述个体中选出多个目标个体组成新的种群；将所述新的种群作为新的所述初始种群,执行所述对所述初始种群中的各个个体进行交叉操作和变异操作,以更新所述个体对应的候选节点的步骤,直至满足设定的终止条件；输出最终得到的种群,并根据迭代次数从所述最终得到的种群中确定节点影响力最大的最优个体,所述最优个体对应的候选节点作为种子节点。</td>   <td>G06Q50/00;G06N3/126</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王鲁平;              王成龙;                   张渝东       </td>   <td>中山大学</td>   <td>基于混合尺度和聚焦网络的红外小目标检测方法及装置</td>   <td>广东省</td>   <td>CN116894959A</td>   <td>2023-10-17</td>   <td>本发明公开了基于混合尺度和聚焦网络的红外小目标检测方法及装置,方法包括：获取待检测的第一图像,对第一图像进行尺度变换,得到第二图像；其中,第二图像的尺度大于第一图像的尺度；对第一图像和第二图像分别进行多层特征提取,对应获得第一多尺度特征和第二多尺度特征；其中,多层特征提取中,每层特征提取的输入为上一层特征提取的输出；对第一多尺度特征和第二多尺度特征进行尺度整合,获得多尺度整合特征；对多尺度整合特征中的若干高层特征进行特征融合,获得融合特征；基于融合特征,对多尺度整合特征中剩余的底层特征逐层进行空洞聚焦,获得目标检测结果。本发明能够准确进行目标检测,可广泛应用于数据处理技术领域。</td>   <td>1.一种基于混合尺度和聚焦网络的红外小目标检测方法,其特征在于,包括：获取待检测的第一图像,对所述第一图像进行尺度变换,得到第二图像；其中,所述第二图像的尺度大于所述第一图像的尺度；对所述第一图像和所述第二图像分别进行多层特征提取,对应获得第一多尺度特征和第二多尺度特征；其中,所述多层特征提取中,每层所述特征提取的输入为上一层所述特征提取的输出；对所述第一多尺度特征和所述第二多尺度特征进行尺度整合,获得多尺度整合特征；对所述多尺度整合特征中的若干高层特征进行特征融合,获得融合特征；基于所述融合特征,对所述多尺度整合特征中剩余的底层特征逐层进行空洞聚焦,获得目标检测结果。</td>   <td>G06V10/52;G06V10/80;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何为;                   邓振淼       </td>   <td>中山大学</td>   <td>一种基于上下文聚类与多模态融合的目标检测方法和系统</td>   <td>广东省</td>   <td>CN116894963A</td>   <td>2023-10-17</td>   <td>本发明公开了一种基于上下文聚类与多模态融合的目标检测方法和系统,涉及计算机视觉和雷达信号处理的技术领域,包括获取图像数据和点云数据并进行数据增强处理；对数据增强处理后的图像数据提取特征,基于视觉分支特征计算对应的热图和属性参数,获得目标的第一检测结果；对数据增强后的点云数据进行矩形扩展,获得扩展后的点云矩形面；与第一检测结果进行区域关联,获得关联数据并提取特征,获得雷达分支特征；融合视觉分支特征和雷达分支特征,计算第二检测结果,连同第一检测结果共同输入解码器,获得目标的最终检测结果。本发明设计的基于上下文聚类的多模态特征融合网络结构,实现对多模态特征数据的融合互补,提高了目标检测的精度和效率。</td>   <td>1.一种基于上下文聚类与多模态融合的目标检测方法,其特征在于,包括：S1：获取成对的图像数据和点云数据,并对所述图像数据和点云数据进行数据增强处理,获得数据增强后的图像数据和点云数据；S2：对所述数据增强后的图像数据进行特征提取,获得视觉分支特征；S3：基于所述视觉分支特征,计算对应的热图和属性参数,获得目标的第一检测结果；S4：将所述数据增强后的点云数据映射到图像坐标系中并进行矩形扩展,获得扩展后的点云矩形面；S5：将所述目标的第一检测结果和所述扩展后的点云矩形面进行区域关联,获得关联数据；S6：对所述关联数据进行特征提取,获得雷达分支特征；S7：将所述视觉分支特征和所述雷达分支特征进行特征融合,获得融合特征；S8：基于所述融合特征,计算目标的第二检测结果；S9：将所述目标的第一检测结果和目标的第二检测结果输入预设的解码器,获得目标的最终检测结果。</td>   <td>G06V10/762;G06V10/86;G06V10/44;G06V10/82;G06N3/0464;G01S13/86</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              雍琪;              林格;                   陈小燕       </td>   <td>中山大学</td>   <td>一种基于模糊集理论的司法审判流程偏离预警方法</td>   <td>广东省</td>   <td>CN110738399B</td>   <td>2023-10-13</td>   <td>本发明公开了一种基于模糊集理论的司法审判流程偏离预警方法。本发明根据审判业务流程划分四大类审判风险,建立包含若干风险要素的风险层级结构；梳理案件审理流程,确定各个风险要素是否存在；聚合所有风险要素,计算不同类型风险的模糊风险值；每一个类型的模糊风险值分别与9个级别模糊数计算相似度；最高相似度所对应的级别为该类型风险的风险级别,如果级别高于中等,则认为当前流程出现偏离,审判系统将发起预警。本发明建立了完善的审判风险层级体系,为审判流程规范化监督工作提供保障；通过风险分析实现事前预警,扩展了审判全流程管理的方案；采用计算机技术对风险进行量化,减轻人力负担,提高审判管理工作效率。</td>   <td>1.一种基于模糊集理论的司法审判流程偏离预警方法,其特征在于,所述方法包括：根据审判业务流程划分四大类审判风险,包括质量风险、效率风险、舆情风险和廉政风险,建立包含若干风险要素的风险层级结构；梳理当前案件审理流程,确定各个风险要素是否存在,并用要素标识符表示；聚合所有风险要素,计算不同类型风险的模糊风险值；每一个类型的模糊风险值分别与9个级别模糊数计算相似度；最高相似度所对应的级别为该类型风险的风险级别,如果级别高于中等,则认为当前流程出现偏离,审判系统将发起预警,并将风险情况推送给审判管理部门进行处理；其中,所述根据审判业务流程划分四大类审判风险,包括质量风险、效率风险、舆情风险和廉政风险,建立包含若干风险要素的风险层级结构中,需要先从规则中抽取针对各个类型的风险要素,即审判流程中可能导致此类风险发生的具体事项,其中舆情风险包含的风险要素有：当事人是否先在社交平台上曝光此事、网络上是否有相关视频照片、报纸是否在报道此事；其中,所述模糊数,是包含两个权值的广义模糊数,表示为A＝(a-1,a-2,a-3,a-4；w-1,w-2),而模糊数A＝(a-1,a-2,a-3,a-4；w)被认为是w-1＝w-2的特殊情况；其中a为边界,w为权值；将风险要素的影响程度描述转换为模糊数,表示为impact-i＝(a-1,a-2,a-3,a-4；w-1,w-2),i表示该类型下的第i个风险要素；其中,所述梳理当前案件审理流程,确定各个风险要素是否存在,并用要素标识符表示,具体为：梳理当前案件审理流程,确定各个风险要素是否存在,并用要素标识符choice-i表示,如果该要素在本次案件审理流程中成立,则choice-i＝1,如果不成立,则choice-i＝0；其中,所述聚合所有风险要素,计算不同类型风险的模糊风险值,具体为：聚合所有风险要素,计算不同类型风险的模糊风险值Fuzzy-Risk：                  k表示第k类的风险,n表示该类风险中总共n个要素；impact-i×choice-i的运算按照以下规则进行：impact-i×choice-i＝(a-1,a-2,a-3,a-4；w-1,w-2)×choice-i＝(choice-i×a-1,choice-i×a-2,choice-i×a-3,choice-i×a-4；w-1,w-2)；其中,所述每一个类型的模糊风险值分别与9个级别模糊数计算相似度,具体为：对模糊数图形分割R区域,计算每个区域的转动惯量；根据回转半径和转动惯量的数学关系,计算模糊数整体的回转半径；结合回转半径、相对曼哈顿距离、权值计算模糊数之间的相似度。</td>   <td>G06Q10/06;G06Q10/0637;G06Q50/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈洛南;                   陈川       </td>   <td>中国科学院分子细胞科学卓越创新中心;中山大学</td>   <td>一种面向短期时间序列预测的预期性学习方法和系统</td>   <td>上海市</td>   <td>CN112529144B</td>   <td>2023-10-13</td>   <td>本发明公开了一种面向短期时间序列预测的预期性学习方法和系统,解决短期高维时间序列的预测问题,实现对短期高维数据的精确多步预测。其技术方案为：从时序数据中选出用于预测的变量,基于训练出的两个神经网络模型进行面向短期时间序列预测的预期性学习,最终输出已选预测变量需要预测的部分。</td>   <td>1.一种面向短期时间序列预测的预期性学习方法,其特征在于,方法包括：步骤1：从时序数据中选出一用于预测的变量并记为,再从数据集中选出时长为 /&gt;的数据段作为训练集/&gt;,对应的/&gt; 作为标签集用以预测未来的时长为/&gt;的变量 /&gt;,其中数据集来源于生活中各个领域的真实时间序列数据,包括大鼠基因数据集、浮游生物数据集、地面臭氧水平数据集；步骤2：执行后续步骤的循环处理当前预测的点,其中num表示本次预测的变量的下标,令num的初始值为0；步骤3：利用训练集和标签集来训练两个神经网络和/&gt;,其中神经网络的训练集/&gt;为/&gt;,神经网络/&gt;的训练集 /&gt;为,该两个神经网络的标签集/&gt;均为/&gt;,得到神经网络/&gt;训练的输出为/&gt;,/&gt;训练的输出为/&gt;,该两个神经网络的损失函数均为：          ,其中为超参；步骤4：神经网络的预测集为/&gt;,神经网络/&gt;的预测集为/&gt;,用步骤3中训练好的两个神经网络分别在该两个预测集上进行预测,分别得到预测结果/&gt;和/&gt;,最终取平均值得到本次预测结果,将本次预测结果添加至训练集的标签/&gt;的末尾,得到/&gt;,并将/&gt;作为下一轮训练过程中的标签,再令/&gt;并重复步骤3和步骤4的循环处理,直到/&gt;后跳出循环；步骤5：得到了长度为的预测值 /&gt;,预测结束,该长度为的预测值/&gt;代表时序预测任务的预测结果。</td>   <td>G06N3/0464;G06N20/00;G06Q10/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曹孟莹;                   辛秦川       </td>   <td>中山大学</td>   <td>一种植物生长时间的识别方法及装置</td>   <td>广东省</td>   <td>CN113516067B</td>   <td>2023-10-13</td>   <td>本发明涉及植物物候识别技术领域,公开了一种植物生长时间的识别方法及装置,所述方法包括：获取包括第一植物的第一图片；将所述第一图片输入到图像分割网络,获取所述第一图片的感兴趣区域；将所述感兴趣区域输入到预设的神经网络模型中,通过神经网络模型提取感兴趣区域的绿度信息,并将所述绿度信息和所述神经网络模型生成的植物不同生长时间的绿度信息曲线进行比较,得到所述第一图片中第一植物所处的生长时间。有益效果：通过提取第一图片的绿度信息并将所述绿度信息和预设的神经网络所生成的绿度信息曲线进行比较,可以更加准确的判断第一图片中第一植物所处的生长时间。</td>   <td>1.一种植物生长时间的识别方法,其特征在于,包括：获取包括第一植物的第一图片；将所述第一图片输入到图像分割网络,获取所述第一图片的感兴趣区域；将所述感兴趣区域输入到预设的神经网络模型中,通过神经网络模型提取感兴趣区域的绿度信息,并将所述绿度信息和所述神经网络模型生成的植物不同生长时间的绿度信息曲线进行比较,得到所述第一图片中第一植物所处的生长时间；所述神经网络模型的建立方法包括：获取样本图片数据集；所述样本图片数据集中的每张图片均包括所述第一植物；将所述样本图片数据集输入到图像分割网络,获取样本图片数据集中每个图片的感兴趣区域；将所述样本图片数据集中的每个图片的感兴趣区域输入到回归结构的ResNet神经网络,提取每个图片感兴趣区域的绿度信息并生成第一植物不同生长时间的绿度信息曲线；所述提取每个图片感兴趣区域的绿度信息并生成第一植物不同生长时间的绿度信息曲线,具体为：分别获取每个图片感兴趣区域中每个像素对应的DN值以及像素中红、绿、蓝波段DN值；根据每个图片中每个像素的DN值以及红、绿、蓝波段DN值得到每个图片的绿度信息；将获取到的所有绿度信息按照图片的时间顺序拟合为绿度信息曲线。</td>   <td>G06V20/10;G06V10/25;G06V10/26;G06V10/774;G06V10/82;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘阳;              严鸿;              李冠彬;              王青;                   林倞       </td>   <td>中山大学</td>   <td>一种基于掩码图自编码器的骨架序列识别方法及系统</td>   <td>广东省</td>   <td>CN116434347B</td>   <td>2023-10-13</td>   <td>本发明公开了一种基于掩码图自编码器的骨架序列识别方法及系统,包括步骤如下：建立骨架动作识别模型,利用骨架动作识别模型识别骨架序列,实现预测动作类别；所述的骨架动作识别模型包括一个M层的空间-时间表示学习模型和一层分类器；所述的空间-时间表示学习模型包括两个并联连接的掩码图自编码器,且掩码图自编码器的输出端通过1×1卷积与输入端进行残差连接。本发明将一个M层的空间-时间表示学习模型和一层分类器构建骨架动作识别模型,其利用不同骨架关节之间的细粒度依赖关系来训练学习,是一个高效的骨架序列学习模型,可以在不同的数据集上很好地泛化。</td>   <td>1.一种基于掩码图自编码器的骨架序列识别方法,其特征在于：所述的方法包括步骤如下：建立骨架动作识别模型,利用骨架动作识别模型识别骨架序列,实现预测动作类别；所述的骨架动作识别模型包括一个M层的空间-时间表示学习模型和一层分类器；所述的空间-时间表示学习模型包括两个并联连接的掩码图自编码器,且掩码图自编码器的输出端通过1×1卷积与掩码图自编码器的输入端进行残差连接；建立关于骨架关节和骨架关节的拓扑结构的图结构,将骨架关节的拓扑结构和骨架关节特征进行融合,得到骨架序列矩阵/&gt;,N表示骨架关节的数量,T表示骨架序列的数量；将骨架序列矩阵S转化为具有可学习参数的/&gt;,D表示对骨架序列矩阵S进行升维；对于每个骨架关节特征矩阵,图结构/&gt;表示一个骨架,其中,是包含所有骨架关节的节点集；/&gt;是一个邻接矩阵,如果i和j是物理连接的,则/&gt;,否则为0；节点/&gt;的骨架关节特征表示为/&gt;,/&gt;。</td>   <td>G06V40/20;G06N3/0455;G06N3/0464;G06N3/048;G06N3/08;G06V10/34;G06V10/44;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李文洁;              周凡;                   林谋广       </td>   <td>中山大学</td>   <td>一种基于指纹特征点的指纹加密方法与系统</td>   <td>广东省</td>   <td>CN116881888A</td>   <td>2023-10-13</td>   <td>本发明公开了一种一种基于指纹特征点的指纹加密方法与系统。包括：获取原始指纹图像,以二维坐标描述各点位置；对原始指纹图像进行归一化处理得到黑白标准化指纹图像；将黑白标准化指纹图像分块,获取指纹方向场,计算指纹频率场；利用指纹方向场和指纹频率场构造对称Gabor滤波器,并对所述黑白标准化指纹图像进行细化处理,获取指纹细化图像；在指纹细化图像的脊线上构建3×3的模板,获取指纹中的特征点；运用里德-所罗门算法对所述特征点的横坐标和纵坐标进行编码,在编码多项式中加入一定量噪声,完成指纹模板加密。本发明采用里德-所罗门算法可以保障参数恢复时的准确性,且加入噪声可以提高指纹模板保护的安全性。</td>   <td>1.一种基于指纹特征点的指纹加密方法,其特征在于,所述方法包括：通过基于光学全反射原理的指纹在线采集技术获取原始指纹图像,以该原始指纹图像中心为原点建立平面直角坐标系,以二维坐标描述各点位置；对所述原始指纹图像进行归一化处理得到黑白标准化指纹图像；将所述黑白标准化指纹图像分块,对每一子块内的纹线方向进行计算,以该方向代表对应子块内各像素的方向,获取指纹方向场,并将各像素灰度值投影计算指纹频率场；利用所述指纹方向场和指纹频率场构造对称Gabor滤波器,并对所述黑白标准化指纹图像进行细化处理,获取指纹细化图像；在所述指纹细化图像的脊线上构建像素3×3的模板,分别以每个值为1的像素点为中心形成3×3的窗口,通过分析窗口中的黑白像素分布情况获取指纹中的末梢点和分叉点；运用里德-所罗门算法对所述末梢点和分叉点的横坐标和纵坐标进行编码,在编码多项式中加入一定量噪声,保存编码结果,完成指纹模板加密。</td>   <td>G06F21/32;G06F21/60;G06V40/13;G06V10/44;G06V40/12;G06V10/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         古博;              詹俊辉;              林梓淇;              姜善成;              王萍;                   韩瑜       </td>   <td>中山大学</td>   <td>一种基于图注意力神经网络的硫酸钾产能预测方法及系统</td>   <td>广东省</td>   <td>CN116882579A</td>   <td>2023-10-13</td>   <td>本发明公开了一种基于图注意力神经网络的硫酸钾产能预测方法及系统,方法包括：对硫酸钾数据进行数据预处理,得到初始硫酸钾特征；对初始硫酸钾特征进行维度升高处理,得到第一硫酸钾特征；对第一硫酸钾特征进行基于图注意力机制的特征聚合处理,得到特征相关性特征；结合特征相关性特征,对第一硫酸钾特征进行基于图注意力机制的时间转换处理,得到时间相关性特征；对特征相关性特征和时间相关性特征进行全连接处理,得到预测信息；对预测信息进行局部相关性提取,得到硫酸钾产能预测结果。本发明能够捕获硫酸钾产能数据中普遍存在的复杂非线性特性,结合硫酸钾数据的特征进行更为准确的硫酸钾产能预测,能够广泛应用于硫酸钾产能预测技术领域。</td>   <td>1.一种基于图注意力神经网络的硫酸钾产能预测方法,其特征在于,包括：对硫酸钾数据进行数据预处理,得到初始硫酸钾特征；对所述初始硫酸钾特征进行维度升高处理,得到第一硫酸钾特征；对所述第一硫酸钾特征进行基于图注意力机制的特征聚合处理,得到特征相关性特征；结合所述特征相关性特征,对所述第一硫酸钾特征所述进行基于图注意力机制的时间转换处理,得到时间相关性特征；对所述特征相关性特征和所述时间相关性特征进行全连接处理,得到预测信息；对所述预测信息进行局部相关性提取,得到硫酸钾产能预测结果。</td>   <td>G06Q10/04;G06Q50/04;G06N3/0499;G06N3/042;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              麦剑霆;              欧阳婧璇;              沈智华;                   张小虎       </td>   <td>中山大学</td>   <td>一种最小二乘快速图像匹配方法、装置、设备和介质</td>   <td>广东省</td>   <td>CN116883493A</td>   <td>2023-10-13</td>   <td>本申请涉及一种最小二乘快速图像匹配方法、装置、设备和介质。所述方法包括：根据高精度位移测量场景下平移运动只包含2个平移参数的特点简化实时图像和参考图像之间的图像变换模型,将最小二乘匹配法的6个仿射参数减少为2个平移参数,从而将最小二乘目标函数直接表示为二维位移参数的代价函数,对代价函数进行直接求解,从而确定位移台的定位信息。本发明将目标函数表示为变换参数的函数,可以直接数值求解,避免了对图像进行多次重采样,能够得到全局最优解,避免收敛到局部最优解,提高了最小二乘图像匹配方法的工作效率,同时提升了精度和可靠性,具有执行效率高、实时性好、简单可靠的优点。</td>   <td>1.一种最小二乘快速图像匹配方法,其特征在于,所述方法包括：在高精度位移测量场景下构建实时图像和参考图像的图像变换模型；所述图像变换模型的变换参数为两个位移参数；所述高精度位移测量场景由位移台、位移台固定件,拍摄标的和相机构成；所述相机安装在所述位移台上,所述位移台能够在所述位移台固定件上移动,所述拍摄标的固定于所述位移台固定件上；所述实时图像由所述相机在所述位移台移动时对所述标的进行拍摄得到；所述参考图像由所述相机预先对所述标的进行连续拍摄后拼接得到；基于所述图像变换模型,通过图像插值算法得到所述参考图像关于以所述位移参数为自变量的权值函数矩阵的第一关系式；通过将所述权值函数表示为系数矩阵和位移参数矩阵相乘的形式,根据所述第一关系式得到所述参考图像关于已知常数矩阵和二维位移参数矩阵的第二关系式；根据所述第二关系式通过最小二乘法确定所述实时图像和所述参考图像匹配的代价函数；所述代价函数为关于所述二维位移参数矩阵的函数；实时定位时,根据待定位的实时图像、预设的参考图像及预先确定的二维位移参数初值,对所述代价函数进行求解,得到所述待定位的实时图像和所述预设的参考图像最佳匹配的位移参数结果,根据所述位移参数结果确定所述位移台的定位信息。</td>   <td>G06T7/70;G06T7/30;G06T3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              方桂安;                   姜祖涛       </td>   <td>中山大学</td>   <td>一种基于细粒度语义奖励的文本到图像生成方法</td>   <td>广东省</td>   <td>CN116883530A</td>   <td>2023-10-13</td>   <td>本发明公开了一种基于细粒度语义奖励的文本到图像生成方法,包括：获取提示文本；将提示文本输入到经过预先训练的文本到图像扩散模型,得到提示文本对应的目标图像；其中,文本到图像扩散模型的训练步骤包括：将训练文本输入到未经训练的文本到图像扩散模型,得到多张训练图像；确定每张训练图像的全局语义对齐得分,确定每张训练图像的局部语义对齐得分；根据全局语义对齐得分和局部语义对齐得分从多张训练图像中确定训练样本；以训练样本训练文本到图像扩散模型,得到经过训练的文本到图像扩散模型。本发明可以实现生成图像的语义与输入文本相匹配,可广泛应用于深度学习和计算机视觉领域。</td>   <td>1.一种基于细粒度语义奖励的文本到图像生成方法,其特征在于,包括：获取提示文本；将所述提示文本输入到经过预先训练的文本到图像扩散模型,得到所述提示文本对应的目标图像；其中,所述文本到图像扩散模型根据经过全局语义对齐和局部语义对齐的训练样本,训练得到。</td>   <td>G06T11/00;G06V10/774;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         阮冲;              吴坡;              张涛;              潘梦源;              宋彦楼;              宫灿锋;              张江南;              王丹;              李斌;                   张铮       </td>   <td>国网河南省电力公司电力科学研究院;中山大学;国网河南省电力公司;国家电网有限公司</td>   <td>一种基于BiGRU-CNN的缺陷分类方法</td>   <td>河南省</td>   <td>CN116881456A</td>   <td>2023-10-13</td>   <td>本发明公开了一种基于BiGRU-CNN的缺陷分类方法,包括以下步骤：获得CVE、CWE数据；根据获取的CVE、CWE数据,构建词汇表；根据词汇表得到单词对应索引,将单词列表转化为单词索引输入嵌入层,并得到对应索引处的词向量,获得文本的向量化表示；将词向量输入BiGRU-TextCNN模型得到特征向量；将特征向量输入全连接层,得到向量；其中,所述全连接层利用单层线性层将上一层的所有输出与这一层的所有输入相连；应用Softmax非线性激活函数,进行最大池化获取CVE漏洞对应的CWE缺陷。本发明实施例中所提供的一种基于BiGRU-CNN的缺陷分类方法,解决了分类困难的问题,并为CVE漏洞分类提供足够的分类指导。</td>   <td>1.一种基于BiGRU-CNN的缺陷分类方法,其特征在于,包括以下步骤：获得CVE、CWE数据；根据获取的CVE、CWE数据,构建词汇表；根据词汇表得到单词对应索引,将单词列表转化为单词索引输入嵌入层,并得到对应索引处的词向量,获得文本的向量化表示；将词向量输入BiGRU-TextCNN模型得到特征向量；将特征向量输入全连接层,得到向量；其中,所述全连接层利用单层线性层将上一层的所有输出与这一层的所有输入相连；应用Softmax非线性激活函数,进行最大池化获取CVE漏洞对应的CWE缺陷。</td>   <td>G06F16/35;G06F16/31;G06F40/284;G06F40/216;G06N3/0464;G06N3/0455;G06N3/0442;G06N3/047;G06N3/048;G06N3/084;G06F21/57;H04L9/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;                   吴婷晖       </td>   <td>中山大学</td>   <td>基于卷积神经网络的多维度跨模态行人重识别方法及装置</td>   <td>广东省</td>   <td>CN116884032A</td>   <td>2023-10-13</td>   <td>本发明公开了一种基于卷积神经网络的多维度跨模态行人重识别方法及装置,属于跨模态行人重识别技术领域。其中方法包括：获取输入图像和输入文本；将所述输入图像和所述输入文本输入多维度特征提取卷积神经网络中,进行全局特征和局部特征的提取,输出对应的图像特征和文本特征；根据所述图像特征和所述文本特征,通过跨模态特征之间的比较,判断所述输入图像和所述输入文本否是匹配,并输出判断结果。本发明通过多维度特征提取卷积神经网络,使文本信息和图像信息可以在同一个网络框架下并行提取全局特征和局部特征,无需使用双向循环神经网络,降低硬件设备的要求。</td>   <td>1.一种基于卷积神经网络的多维度跨模态行人重识别方法,其特征在于,包括以下步骤：获取输入图像和输入文本；将所述输入图像和所述输入文本输入多维度特征提取卷积神经网络中,进行全局特征和局部特征的提取,输出对应的图像特征和文本特征；根据所述图像特征和所述文本特征,通过跨模态特征之间的比较,判断所述输入图像和所述输入文本否是匹配,并输出判断结果。</td>   <td>G06V40/10;G06V10/42;G06V10/44;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘慧;                   何汇朗       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种放疗室用患者安全监控系统及方法</td>   <td>广东省</td>   <td>CN116884082A</td>   <td>2023-10-13</td>   <td>本发明公开了一种放疗室用患者安全监控系统及方法,涉及医疗技术领域,所述系统包括获取模块、处理模块、第一识别模块、第二识别模块和报警模块。本发明能够对放疗患者的手势进行识别,进而可精准掌握放疗患者的状态,并且可通过报警的方式有效的向医护人员提示患者目前的状态,避免在放疗过程中,医护人员无法及时发现放疗室中出现的问题,造成重大的医疗事故。</td>   <td>1.一种放疗室用患者安全监控系统,其特征在于,包括：获取模块,用于获取目标患者的手部视频数据；处理模块,用于从所述手部视频数据中抽取连续的两帧第一目标手部图像,分别提取两帧第一目标手部图像对应的手部轮廓图像,根据所述手部轮廓图像计算两帧手部图像的相似度,根据所述相似度确定手势类型,所述手势类型包括静态手势和动态手势；第一识别模块,用于在手势类型为静态手势时,根据任一组手部关键点提取静态手部特征,将所述静态手部特征输入静态手势识别模型,得到静态手势识别结果；第二识别模块,用于在所述手势类型为动态手势时,从所述手部视频数据中抽取位于所述第一目标图像之后的若干帧连续的第二目标图像,从所述第二目标图像中提取出动态手势特征,将手势动态手势特征输入动态手势识别模型,得到动态手势识别结果；报警模块,用于根据所述静态手势识别结果或者动态手势识别结果确定患者状态,根据所述患者状态进行报警。</td>   <td>G06V40/20;A61N5/10;G06V10/28;G06V10/44;G06V10/74;G06V10/80;G06V20/52</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢宇彤;                   关文轩       </td>   <td>中山大学</td>   <td>一种基于梯度稀疏的分布式深度学习方法</td>   <td>广东省</td>   <td>CN113159287B</td>   <td>2023-10-10</td>   <td>本发明公开了一种基于梯度稀疏的分布式深度学习方法,该方法包括：初始化本地模型参数,将本地模型参数在计算节点之间同步并初始化残差张量；计算节点将训练数据读取进内存并作为深度神经网络模型的输入；基于反向传播获取梯度并将残差张量累加至梯度上,得到新梯度；基于分块梯度稀疏方法对新梯度进行稀疏,并进行梯度通信；进行后续层梯度计数,得到全局梯度；基于全局梯度对本地模型参数进行更新；迭代直至满足预设的迭代终止条件。本发明方法大大减少了分布式深度学习的通信开销并提高训练效率。本发明作为一种基于梯度稀疏的分布式深度学习方法,可广泛应用于图像处理领域。</td>   <td>1.一种基于梯度稀疏的分布式深度学习方法,其特征在于,包括以下步骤：S1、初始化本地模型参数,将本地模型参数在计算节点之间同步并初始化残差张量；S2、计算节点将训练数据读取进内存并作为深度神经网络模型的输入；S3、基于反向传播获取梯度并将残差张量累加至梯度上,得到新梯度；S4、基于分块梯度稀疏方法对新梯度进行稀疏,并进行梯度通信；S5、进行后续层梯度计数,得到全局梯度；S6、基于全局梯度对本地模型参数进行更新；所述基于反向传播获取梯度并将残差张量累加至梯度上,得到新梯度这一步骤,其具体包括：S31、计算节点基于内存中的训练数据和本地的模型参数进行迭代训练,前向传播得到每一层的误差值loss；S32、根据误差值loss进行反向传播,逐层计算得到每一层的梯度g；S33、每得到一层的梯度就将该层的残差累加到梯度上,得到新梯度；所述每得到一层的梯度就将该层的残差累加到梯度上,得到新梯度这一步骤,公式表示为：g-1＝g+v上式中,所述g-1表示新梯度,所述v表示残差值；所述基于分块梯度稀疏方法对新梯度进行稀疏,并进行梯度通信这一步骤,其具体包括：S41、对每一层的新梯度按照压缩率p划分为多个梯度子块；S42、为每一个梯度子块计算其中所有梯度元素绝对值的平均值作为该梯度子块的贡献权重,得到贡献权重数组；S43、在计算节点之间对贡献权重数组执行一次AllReduce操作,同步平均所有计算节点的贡献权重数组；S44、每个计算节点选取贡献权重最大的梯度子块作为通信的传输对象；所述进行后续层梯度计数,得到全局梯度这一步骤,其具体包括：S51、对未被传输的梯度子块在本地进行残差累加并用于在下一次迭代累加到梯度上,对于已被传输的梯度子块,将其残差值v更新为0；S52、直至所有层的梯度计数完成,得到全局梯度。</td>   <td>G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              刘颜;              陈荣军;              谢舜道;              苏宏雄;              谢子豪;              朱雄泳;                   曾衍瀚       </td>   <td>中山大学</td>   <td>一种基于区块链技术的农作物种子安全溯源系统</td>   <td>广东省</td>   <td>CN110135860B</td>   <td>2023-10-10</td>   <td>本发明提供了一种基于区块链技术的农作物种子安全溯源系统,包括服务层、业务层、接口层和应用层；其中：服务层为所述业务层提供网络和数据处理服务；业务层提供系统的业务逻辑功能；接口层提供所述业务层和所述应用层的中间消息服务；应用层提供人机交互服务,与所述业务层信息交互；服务层包括区块链网络,通过所述区块链网络将区块链返回所述应用层。本发明提供一种基于区块链技术的农作物种子安全溯源系统,通过区块链网络保证链上记录的数据的安全性、完整性以及真实性,实现了防篡改、信息共享、强化溯源系统管理等功能,在提升农作物种子产品质量的同时,也提升农作物种子的市场竞争力和提升企业品牌形象。</td>   <td>1.一种基于区块链技术的农作物种子安全溯源系统,其特征在于：包括服务层、业务层、接口层和应用层；其中：所述服务层为所述业务层提供网络和数据处理服务；所述业务层提供系统的业务逻辑功能；所述接口层提供所述业务层和所述应用层的中间消息服务；所述应用层提供人机交互服务,与所述业务层信息交互；所述服务层包括区块链网络,通过所述区块链网络将区块链返回所述应用层；所述服务层还包括身份管理模块、通道管理模块、账本管理模块和排序服务模块；其中：所述身份管理模块包括种植组织单元、采收组织单元、加工组织单元、包装组织单元、质检组织单元、仓储组织单元、物流组织单元和销售组织单元；所述身份管理模块根据组织规模编写配置文件,为每个组织单元生成身份证书,每次交易都带上组织单元的身份签名；所述的每个组织单元均与所述业务层信息交互；所述通道管理模块管理应用通道,所述应用通道上设置有种植组织节点、采收组织节点、加工组织节点、包装组织节点、质检组织节点、仓储组织节点、物流组织节点和销售组织节点,共同管理和维护应用通道的账本数据；所述账本管理模块包括多个背书节点、合法性验证单元、信息获取单元、交易处理单元和账本；所述背书节点设置在各个组织节点上,运用AND的背书策略,即每个组织节点至少有个一个背书节点需要执行背书操作；所述合法性验证单元验证背书节点收到的提案数据的合法性并且验证发起者的身份合法性；信息获取单元用于获取合法交易提案的通道ID,通过通道ID获取所属组织节点对应的账本以及获取交易模拟器和账本历史查询对象,模拟执行交易产生结果,即读集合和写集合；交易处理单元在确定交易是唯一的之后,确认交易提案对组织节点对应的账本是否具有写数据的权限,在模拟执行交易产生的结果添加背书节点的签名,生成背书,并将背书返回排序服务模块；所述排序服务模块包括排序单元、打包单元和提交单元,所述排序单元将八个组织单元收集到的八个背书按照到达的顺序进行排序；所述打包单元将排序好的交易批量打包生成区块,并将区块发送给提交单元；所述提交单元对区块内的交易进行背书策略检查和语义检查,若检查不通过则视为无效交易；提交单元将验证过的区块添加至区块链网络,由区块链网络返回所述应用层。</td>   <td>G06Q30/018;G06Q50/02;G06Q40/04;G06F9/54;G06F21/62;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   陈培佳       </td>   <td>中山大学</td>   <td>基于置信度自适应和差分增强的视频显著物体检测方法</td>   <td>广东省</td>   <td>CN112784745B</td>   <td>2023-10-10</td>   <td>本发明公开了一种基于置信度自适应和差分增强的视频显著物体检测方法,所述方法输入一对原图和光流图,编码器分别提取不同层级的空间特征和时间特征；提取到的同一层级的空间特征和时间特征被送入置信度自适应模块中进行重新校正,使得有用信息被传递,噪声信息被抑制；然后,差分信息增强模块利用差分信息对重新校正后的空间特征和时间特征进行互补增强并得到融合特征；在不同层级的融合特征经过解码器层层上采样,最终得到显著物体图。提出的差分信息增强模块通过提取差分信息增强了空间信息和时间信息完整表示显著物体的能力,有利于模型完整地分割出显著物体。</td>   <td>1.基于置信度自适应和差分增强的视频显著物体检测方法,其特征在于,所述方法包括输入一对原图和光流图,编码器分别提取不同层级的空间特征和时间特征；提取到的同一层级的空间特征和时间特征被送入置信度自适应模块中进行重新校正,使得有用信息被传递,噪声信息被抑制；然后,差分信息增强模块利用差分信息对重新校正后的空间特征和时间特征进行互补增强并得到融合特征；在不同层级的融合特征经过解码器层层上采样,最终得到显著物体图；所述置信度自适应模块分别由分割器和预测器构成,其中,所述分割器和所述预测器均由3层卷积核大小为3x3的卷积层串联而成；接收来自编码器的特征作为输入,所述分割器分割得到一张低分辨率的显著物体图；将所述分割器预测得到的所述显著物体图与原先的输入特征进行通道上的拼接后送入所述预测器；所述预测器通过分析所述显著物体图与所述输入特征,预测一个能够表示输入特征置信度的得分；使用所述差分信息增强模块充分利用空间特征和时间特征之间的互补信息时,首先获得空间特征和时间特征之间的差,再通过一个卷积核大小为3x3的卷积层得到空间特征和时间特征的差分信息；将差分信息加回原来的空间特征和时间特征上,补充了原来的特征,起到特征增强的作用；最后,融合增强后的空间特征和时间特征以得到完整的显著性信息；差分信息增强模块的计算公式如下：                                    其中,R-i～(RGB)和R-i～(OF)分别表示置信度自适应模块校正后的空间特征和时间特征。</td>   <td>G06V20/40;G06V10/80;G06V10/30;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         万海;              沈大伟;              刘亚男;              曾娟;                   黄佳莉       </td>   <td>中山大学</td>   <td>一种可解释的文本推断方法</td>   <td>广东省</td>   <td>CN113590745B</td>   <td>2023-10-10</td>   <td>本发明提供一种可解释的文本推断方法,该方法通过观察人类对文本进行理解和推理的过程,模拟人类的文本推断的思维过程进行构建模型,使构建的模型具有可解释性。具体地,考虑到人类在进行长文本阅读的时候,对文本的理解主要基于空间顺序和内容关联两方面,将两方面的信息融合进行理解和推理,因此,本发明根据人类阅读文本的这一特点,根据文本中句子的空间顺序和句子的内容进行融合而构建神经网络模型,且该模型可模拟人类推理过程。为了更好地讲述和理解本发明提出的文本推断方法,本发明将该方法具体应用于机器阅读理解任务。</td>   <td>1.一种可解释的文本推断方法,其特征在于,包括以下步骤：S1：进行指代消解、实体识别；S2：进行信息编码；S3：构建句子关系图；S4：句子关系图的处理；S5：进行特征信息融合；S6：进行选项选择；步骤S1中,使用指代消解工具,对背景材料中的句子进行指代消解并将句子按顺序进行编号；然后,使用命名实体识别工具对问题和背景材料的句子进行实体抽取,得到每个句子中所含有的实体集合；步骤S2中,对背景材料、问题以及选项进行编码,采用预训练语言模型对背景材料按句子为单位进行编码,问题与各个选项也分别看作是句子输入预训练语言模型进行编码,从而得到每个句子的特征表示；步骤S3中,为了充分获取和利用背景材料中的信息,结合背景材料中句子之间以及句子和问题之间的关联关系,构建句子关系图,其中关联关系包括顺序关系和内容相关关系；步骤S5中,将句子关系图中的特征节点按顺序关系恢复排列,得到背景材料的句子序列和问题句子的新特征表示,然后,将选项的特征表示和背景材料的句子序列组合成新的序列,输入双向长短期记忆网络进行选项和背景材料的信息融合。</td>   <td>G06F16/33;G06N3/0442;G06N3/08;G06N5/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              聂宇翔;              赵颖;                   方超伟       </td>   <td>之江实验室;中山大学</td>   <td>一种模型训练的方法、装置、存储介质及电子设备</td>   <td>浙江省</td>   <td>CN116863270A</td>   <td>2023-10-10</td>   <td>本说明书公开了一种模型训练的方法、装置、存储介质及电子设备。本说明书实施例在模型训练的过程中,可以通过使用不同尺寸的图像对模型进行模型训练,以提高最终训练后的模型对于不同尺寸的图像的物体检测的准确性。</td>   <td>1.一种模型训练的方法,其特征在于,包括：获取第一模型和第二模型,以及获取样本图像；将所述样本图像进行图像增强,得到第一图像和第二图像；将所述第一图像输入到所述第一模型中,以得到所述第一模型从所述第一图像中识别出的指定对象所在的图像区域,作为参照区域；根据所述参照区域,从通过所述第二模型在所述第二图像中识别出的所述指定对象所在的各候选区域中确定出目标区域；调整所述第二图像的尺寸,得到若干调整后第二图像；确定所述第一模型基于所述目标区域,对所述第一图像进行处理得到的处理结果,作为第一结果,以及确定所述第二模型基于所述目标区域,对所述若干调整后第二图像进行处理得到的处理结果,作为各第二结果；根据所述第一结果与各所述第二结果之间的偏差,对所述第二模型进行训练。</td>   <td>G06V10/774;G06V10/764;G06V10/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余向阳;                   张鑫       </td>   <td>中山大学</td>   <td>一种区块链数据共享方法、系统、装置及介质</td>   <td>广东省</td>   <td>CN112181922B</td>   <td>2023-10-03</td>   <td>本发明公开了一种区块链数据共享方法、系统、装置及介质,方法包括：创建区块链中的成员机构；根据所述成员机构,进行区块链节点的初始化处理,创建联盟链中的数据链、规则链和应用链；对所述数据机构的数据源进行标准化处理,并通过所述监管机构对所述标准化处理的结果进行审核登记；通过第一数据机构向区块链中发布目标数据源的元信息及权限规则,并由所述监管机构对所述目标数据源进行确认后发布到数据链上；采用密钥加密的方法由第二数据机构对所述目标数据源发起数据请求,并获取所述目标数据源；由所述第二数据机构确定所述目标数据源的评价信息,并将所述评价信息存储到应用链中。本发明既能保护数据隐私,又能提高数据共享效率,可广泛应用于区块链技术领域。</td>   <td>1.一种区块链数据共享方法,其特征在于,包括：创建区块链中的成员机构,所述成员机构包括数据机构和监管机构；根据所述成员机构,进行区块链节点的初始化处理,创建联盟链中的数据链、规则链和应用链；对所述数据机构的数据源进行标准化处理,并通过所述监管机构对所述标准化处理的结果进行审核登记,以完成区块链中各个节点的数据同步；通过第一数据机构向区块链中发布目标数据源的元信息及权限规则,并由所述监管机构对所述目标数据源进行确认后发布到数据链上；由第一数据机构对目标数据源设置权限信息,确定数据可见度和范围,并发布到规则链中；采用密钥加密的方法由第二数据机构对所述目标数据源发起数据请求,并获取所述目标数据源；由所述第二数据机构确定所述目标数据源的评价信息,并将所述评价信息存储到应用链中；所述根据所述成员机构,进行区块链节点的初始化处理,创建联盟链中的数据链、规则链和应用链,包括：在云端或者成员机构本地上部署至少三个区块链节点；在所述区块链节点上安装数据链、规则链以及应用链的智能合约,并将所述区块链节点加入至所述数据链、规则链以及应用链；将各个区块链节点的数据进行链上同步,完成所述初始化处理；所述对所述数据机构的数据源进行标准化处理,具体为：由所述数据机构将业务数据的描述信息、内容范围以及数据摘要存储到数据链中；所述通过第一数据机构向区块链中发布目标数据源的元信息及权限规则,并由所述监管机构对所述目标数据源进行确认后发布到数据链上,包括：确定目标数据源的内容,并通过所述第一数据机构向区块链中发布目标数据源,所述目标数据源的内容包括数据持有方、数据库、数据表和数据项；通过所述监管机构对所述数据项的摘要信息进行审计；将审计通过的目标数据源发布至区块链中。</td>   <td>G06F16/176;G06F16/27;G06F21/60;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;                   李洁铃       </td>   <td>中山大学</td>   <td>一种三维点云数据的去噪方法、装置及存储介质</td>   <td>广东省</td>   <td>CN112508803B</td>   <td>2023-10-03</td>   <td>本发明公开了一种三维点云数据的去噪方法、装置及存储介质,该方法对激光雷达采集的三维点云数据进行处理,包括读取所述三维点云数据；对所述三维点云数据进行预处理,得到原始点云数据；融合粒子滤波法和动态半径滤波法,获取约束条件,所述约束条件包括点云追踪次数、点云相似度和点云FPFH特征差距；根据所述约束条件,对所述原始点云数据进行去噪处理；本发明采用融合粒子滤波法和动态半径滤波法来进行点云去噪处理,能够保证在去除噪声点的同时,不破坏其它点云的环境；去噪效果更佳,更完全,能够实现在不破坏非噪声点云的环境特征的同时,提高去除噪声点的准确率。本发明可广泛应用于数据处理领域。</td>   <td>1.一种三维点云数据的去噪方法,对激光雷达采集的三维点云数据进行处理,其特征在于,包括：读取所述三维点云数据；对所述三维点云数据进行预处理,得到原始点云数据；融合粒子滤波法和动态半径滤波法,获取约束条件,所述约束条件包括点云追踪次数、点云相似度和点云FPFH特征差距；根据所述约束条件,对所述原始点云数据进行去噪处理；所述点云相似度通过以下步骤获取：通过粒子滤波法获取第一帧点云数据的点云集,所述第一帧点云数据为原始点云数据中的任意一帧数据；通过动态半径滤波法,计算得到第二帧点云数据中粒子的观测值,所述第二帧点云数据为所述第一帧点云数据的下一个连续帧；根据所述点云集和所述粒子的观测值,计算得到点云相似度；所述通过动态半径滤波法,计算得到第二帧点云数据中粒子的观测值这一步骤,具体包括：通过动态半径滤波法,确定第二帧点云数据中粒子的观测半径；根据所述观测半径,计算得到所述观测值；所述通过动态半径滤波法,确定第二帧点云数据中粒子的观测半径这一步骤,具体包括：计算粒子到激光雷达的欧式距离；如果所述欧式距离小于第四阈值,则将预先设定的半径值确定为所述观测半径；如果所述欧式距离大于第四阈值,则根据公式计算得到所述观测半径,所述公式为：SR＝β×(r×α)；式中,SR为观测半径,r为期望点间距,α为激光雷达的水平角分辨率,β为参数。</td>   <td>G06T5/00;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李聪端;              贺柏宇;              赖东成;              朱甜甜;                   何晶亮       </td>   <td>中山大学</td>   <td>一种基于知识增强的深度对话语义角色标注方法及系统</td>   <td>广东省</td>   <td>CN112765991B</td>   <td>2023-10-03</td>   <td>本发明公开了一种基于知识增强的深度对话语义角色标注方法及系统,该方法包括：获取数据集并对数据集进行预处理,得到预处理后的文本；获取三元组并对三元组进行筛选,得到过滤后的三元组；将过滤后的三元组与预处理后的文本结合,得到句子树结构；将句子树结构转换为序列并输入到BERT编码器,输出词向量；对预处理文本进行处理,得到索引向量；将词向量和索引向量输入到预构建的语义角色标注模型,输出预测标注结果。该系统包括：预处理模块、三元组模块、树结构模块、词向量模块、索引向量模块和结果模块。通过使用本发明,提升标注的准确度。本发明作为一种基于知识增强的深度对话语义角色标注方法及系统,可广泛应用于自然语言处理技术领域。</td>   <td>1.一种基于知识增强的深度对话语义角色标注方法,其特征在于,包括以下步骤：获取数据集并对数据集进行预处理,得到预处理后的文本；根据预处理后的文本获取三元组并按照预设规则对三元组进行筛选,得到过滤后的三元组；将过滤后的三元组与预处理后的文本结合并转换,得到句子树结构；将句子树结构转换为序列并输入到BERT编码器,输出词向量；基于索引编码器对预处理文本进行处理,得到索引向量；将词向量和索引向量输入到预构建的语义角色标注模型,输出预测标注结果；所述根据预处理后的文本获取三元组并按照预设规则对三元组进行筛选,得到过滤后的三元组这一步骤,其具体包括：对预处理后的文本中的词语向知识图谱库请求常识三元组；过滤包含英文信息、包含数字信息、长度大于预设值和含有预设关键字的三元组,得到过滤后的三元组；所述BERT编码器包括嵌入层、可视化层和编码层,所述预构建的语义角色标注模型包括自注意力机制层和输出层；所述将句子树结构转换为序列并输入到BERT编码器,输出词向量这一步骤,其具体包括：将句子树结构拉平转换成序列；基于嵌入层对序列进行处理,得到词的软位置；基于可视化层对序列进行处理,得到可视矩阵；编码层根据词的软位置和可视矩阵,输出词向量；所述基于索引编码器对预处理文本进行处理,得到索引向量这一步骤,其具体包括：对预处理文本分别进行对话轮次索引、说话者索引和谓词索引处理并输入到索引编码器,生成对话轮次索引向量、说话者索引向量和谓词索引向量；所述将词向量和索引向量输入到预构建的语义角色标注模型,输出预测标注结果这一步骤,其具体包括：将词向量、对话轮次索引向量、说话者索引向量和谓词索引向量经过自注意力机制层,得到注意力向量；根据注意力向量和softmax函数生成注意力输出；将注意力输出经过输出层并通过Softmax归一化,输出预测标注结果。</td>   <td>G06F40/30;G06F40/289;G06F40/126;G06F40/146;G06F40/216</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建芳;                   侯智聪       </td>   <td>中山大学</td>   <td>基于双线性的多模态信息处理的人工智能方法、系统及介质</td>   <td>广东省</td>   <td>CN113033430B</td>   <td>2023-10-03</td>   <td>本发明公开了一种基于双线性的多模态信息处理的人工智能方法、系统及介质,该方法包括：将视频流转化为图像帧；划分动作序列；构建骨架时序特征、RGB和深度时序特征；构建三维特征立方体并输入双线性特征学习模块；输出分类识别结果。本发明通过双线性的处理方式构造深度网络融合RGBD视频中多模态信息,克服了现有的多模态模型中简单地拼接或加权不同模态输出的特征或激活向量,并没有深入挖掘模态间信息的缺陷,进行准确的动作行为识别。本发明的双线性操作为平面级计算,计算代价小,适于在实时性要求高的工业领域进行应用。</td>   <td>1.基于双线性的多模态信息处理的人工智能方法,其特征在于,包括下述步骤：将视频流转化为图像帧,并划分为动作序列；根据所述动作序列构建骨架时序特征、RGB和深度时序特征,并构建三维特征立方体；所述构建三维特征立方体具体为：将骨架时序特征、RGB和深度时序特征进行拼接,构成三维特征立方体,并记为A,其中M-A为模态维度,T为时间维度,C为特征通道维度；将所述三维特征立方体输至双线性特征学习模块中,得到激活向量；所述双线性特征学习模块为若干模态池化层和时序池化层的堆叠；所述模态池化层用于挖掘不同模态的信息,其计算过程如下式：L(:,:,c)＝X～TA(:,:,c),c＝1,2,…,C,也即：                  其中矩阵为该池化层的权重矩阵,M-A和M-L为模态维度；所述时序池化层用于挖掘时序信息,其计算过程如下式：Z(:,:,c)＝L(:,:,c)Y,c＝1,2,…,C；其中矩阵为该池化层的权重矩阵；取所述激活向量中的最大值对应的类别作为动作识别的分类结果。</td>   <td>G06V40/20;G06V20/64;G06V20/40;G06V10/764;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;                   陆柳村       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于循环转换器和历史感知的视觉对话方法、装置及设备</td>   <td>广东省</td>   <td>CN116842164A</td>   <td>2023-10-03</td>   <td>本发明公开了一种基于循环转换器和历史感知的视觉对话方法、装置及设备,方法包括：获取目标图像、目标图像对应的标题以及目标图像的对话历史；对话历史包括多个对话轮次,每个对话轮次包括问题和问题对应的回答；提取目标图像的图像特征；对标题和各个对话轮次进行逐轮编码,得到对话轮次特征；根据图像特征和对话轮次特征对目标图像和标题,与各个对话轮次进行匹配,得到与目标图像和标题匹配的各个候选对话轮次；确定各个候选对话轮次中回答正确的目标对话轮次。本发明可以提高视觉对话的时间依赖性和准确性,可广泛应用于人工智能神经网络模型领域。</td>   <td>1.一种基于循环转换器和历史感知的视觉对话方法,其特征在于,包括：获取目标图像、所述目标图像对应的标题以及所述目标图像的对话历史；所述对话历史包括多个对话轮次,每个所述对话轮次包括问题和所述问题对应的回答；提取所述目标图像的图像特征；对所述标题和各个所述对话轮次进行逐轮编码,得到对话轮次特征；根据所述图像特征和所述对话轮次特征对所述目标图像和所述标题,与各个所述对话轮次进行匹配,得到与所述目标图像和所述标题匹配的各个候选对话轮次；确定各个所述候选对话轮次中回答正确的目标对话轮次。</td>   <td>G06F16/332;G06F40/258;G06F40/117;G06V30/18;G06V30/19</td>  </tr>        <tr>   <td>中国专利</td>   <td>         史清丽;              卓莉;                   陶海燕       </td>   <td>中山大学</td>   <td>一种基于人群活动强度特征的通勤流量估计方法及系统</td>   <td>广东省</td>   <td>CN116843069A</td>   <td>2023-10-03</td>   <td>本发明涉及城市人群移动流量估计与预测技术领域,公开了一种基于人群活动强度特征的通勤流量估计方法及系统,提出的时间图注意力网络模型通过结合时空卷积和时间卷积,能同时考虑人群活动强度特征的时间、空间依赖性,并通过引入多任务约束学习策略,以及模型在训练和预测过程中采用统一的流量估计方法,提高了通勤流量预测的准确性,输入数据采用人群活动强度动态变化数据,具有更细粒度的时空分辨率且更易于获取。</td>   <td>1.一种基于人群活动强度特征的通勤流量估计方法,包括：S1、获取研究区的人群活动强度时间序列数据、平均通勤时长数据和通勤流量数据；S2、将研究区划分为固定大小的多个格网；对人群活动强度时间序列数据进行预处理,得到各格网的人群活动强度；对平均通勤时长数据进行预处理,得到各格网间的平均通勤时长；分别将每个格网作为图节点,人群活动强度作为节点特征,平均通勤时长作为边,构建通勤网络图；S3、构建时间图注意力网络模型,利用通勤流量数据对时间图注意力网络模型进行训练；时间图注意力网络模型用于学习图节点的人群活动强度的时间特征、图节点的空间结构特征,输出各节点的嵌入向量；S4、在通勤网络图上选取起点和终点,通过训练好的时间图注意力网络模型对起点和终点的人群活动强度的时间特征、空间结构特征进行学习,获得起点嵌入向量、终点嵌入向量；S5、将起点嵌入向量、终点嵌入向量以及起点和终点之间的距离特征作为梯度增强回归树方法的输入,获得两地之间的通勤流量估计值。</td>   <td>G06Q10/04;G06Q50/26;G06N3/045;G06N3/049;G06N3/042;G06N3/0464;G06N3/08;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韦立坚;              刘涵潇;              林俊勤;              王帆;              陈思航;                   马聪       </td>   <td>中山大学;广州民间金融街信用数据技术有限公司</td>   <td>基于可解释性机器学习的小额贷违约风险评估与归因方法</td>   <td>广东省</td>   <td>CN116843446A</td>   <td>2023-10-03</td>   <td>本发明提出一种基于可解释性机器学习的小额贷违约风险评估与归因方法,涉及可解释性机器学习应用的技术领域,采集小额贷款特征数据,并对其进行预处理,将预处理后的数据作为机器学习模型的输入特征,对机器学习的超参数进行调优,确保模型达到理想的效果,以将机器学习模型用于小额贷违约风险评估,最后,对企业的小额贷违约风险进行可解释性归因分析,得出不同类型的小额贷款特征数据在机器学习模型评估结果中的贡献度,可减少核验时间,降低核验成本,实现对中小企业贷款违约风险的评估与归因,从而可进一步提取出适用于各类型中小企业的通用信用风险评估指标体系。</td>   <td>1.一种基于可解释性机器学习的小额贷违约风险评估与归因方法,其特征在于,包括以下步骤：采集小额贷款特征数据；对小额贷款特征数据进行预处理；构建机器学习模型,以预处理后的小额贷款特征数据作为机器学习模型的输入,对机器学习模型进行参数调优,得到参数调优后的机器学习模型；利用参数调优后的机器学习模型对借款企业进行小额贷违约风险评估；基于小额贷违约风险评估结果,对企业的小额贷违约风险进行可解释性归因分析。</td>   <td>G06Q40/03;G06Q40/12;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵韦人;              李科铭;              王嘉辉;                   刘俊杰       </td>   <td>广东工业大学;中山大学</td>   <td>一种基于双目视觉与结构光融合的三维显微重建系统及方法</td>   <td>广东省</td>   <td>CN116843840A</td>   <td>2023-10-03</td>   <td>本发明公开了一种基于双目视觉与结构光融合的三维显微重建系统及方法,涉及三维重建技术领域。所述系统包括显微采样平台、结构光投影模块和后处理模块,通过显微采样平台和结构光投影模块的配合,获取显微场景下动态样品表面的特征信息,通过后处理模块采用点云补全稠密化算法,完成三维点云模型的创建。相较于现有技术,本发明在保持高精度的同时保障实时性,特别适用于显微场景下动态样品的点云快速重建。</td>   <td>1.一种基于双目视觉与结构光融合的三维显微重建系统,其特征在于,包括：显微采样平台,用于基于双目视觉方法,获取关于动态样品的实景图像和结构光编码图像；还用于对所述动态样品进行白光照明；结构光投影模块,用于对所述动态样品进行结构光编码照明；后处理模块,用于控制所述显微采样平台进行白光照明和所述结构光投影模块进行结构光编码照明；还用于根据获取实景图像和结构光编码图像,基于点云补全稠密化算法建立三维点云模型。</td>   <td>G06T17/00;H04N13/275;H04N13/239</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王成龙;              王鲁平;                   许泽明       </td>   <td>中山大学</td>   <td>基于多向环形Top-Hat的红外小目标检测方法</td>   <td>广东省</td>   <td>CN116843914A</td>   <td>2023-10-03</td>   <td>本发明公开了基于多向环形Top-Hat的红外小目标检测方法,方法包括：构建检测目标多个方向上的结构信息,其中结构信息包括外部结构元素、内部结构元素和环形结构元素；根据结构信息对初始开运算和初始闭运算进行重定义运算,得到目标开运算和目标闭运算；通过目标开运算和目标闭运算,对初始顶帽运算和初始底帽运算进行重定义运算,得到目标顶帽运算和目标底帽运算；基于目标顶帽运算,通过融合得到第一检测结果；将第一检测结果基于自适应阈值进行分割,得到红外小目标检测结果。本发明通过构建检测目标多个方向上的结构元素,可以充分获取对比度信息,解决了在背景复杂的情况下出现严重虚警的问题,可广泛应用于红外检测技术领域。</td>   <td>1.基于多向环形Top-Hat的红外小目标检测方法,其特征在于,包括：构建检测目标多个方向上的结构信息,其中所述结构信息包括外部结构元素、内部结构元素和环形结构元素；根据所述结构信息对初始开运算和初始闭运算进行重定义运算,得到目标开运算和目标闭运算；通过所述目标开运算和所述目标闭运算,对初始顶帽运算和初始底帽运算进行重定义运算,得到目标顶帽运算和目标底帽运算；基于所述目标顶帽运算,通过融合得到第一检测结果；将所述第一检测结果基于自适应阈值进行分割,得到红外小目标检测结果。</td>   <td>G06V10/44;G06V10/26;G06V10/80;G06V10/58</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王鲁平;              王成龙;                   张渝东       </td>   <td>中山大学</td>   <td>基于椭圆环形Top-Hat的红外小目标检测方法</td>   <td>广东省</td>   <td>CN116843915A</td>   <td>2023-10-03</td>   <td>本发明公开了基于椭圆环形Top-Hat的红外小目标检测方法,包括：构建检测目标的四个角度的结构元素,其中结构元素包括外部结构元素、内部结构元素和椭圆结构元素；根据所述结构元素,定义开运算与闭运算；基于所述开运算与所述闭运算,通过形态学变换得到顶帽变换运算与底帽变换运算；基于所述顶帽变换运算与所述底帽运算,通过融合得到第一检测结果；将所述第一检测结果基于自适应阈值进行分割,得到红外小目标检测结果。本发明通过构建检测目标的四个角度的结构元素,得到椭圆结构元素可以充分获取对比度信息,解决了在背景复杂的情况下出现严重虚警的问题,可广泛应用于红外检测技术领域。</td>   <td>1.基于椭圆环形Top-Hat的红外小目标检测方法,其特征在于,包括：构建检测目标的多个角度的结构信息,其中结构信息包括外部结构元素、内部结构元素和椭圆结构元素；根据所述结构信息,定义开运算与闭运算；基于所述开运算与所述闭运算,通过形态学变换得到顶帽变换运算与底帽变换运算；基于所述顶帽变换运算与所述底帽运算,通过融合得到第一检测结果；将所述第一检测结果基于自适应阈值进行分割,得到红外小目标检测结果。</td>   <td>G06V10/44;G06V10/26;G06V10/80;G06V10/58</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘修建;              刘毅;              谢佰洪;              薛晓飞;              王安邦;              高智凡;                   张贺晔       </td>   <td>中山大学</td>   <td>一种基于先验知识进行学习血流储备分数的方法及装置</td>   <td>广东省</td>   <td>CN116844714A</td>   <td>2023-10-03</td>   <td>本申请提供了一种基于先验知识进行学习血流储备分数的方法,包括：获取冠状动脉的成像数据与合成数据,提取所述成像数据的几何特征,并将所述几何特征投影到所述合成数据得到融合几何特征；提取所述合成数据中的血流的特异性信息,并将所述特异性信息与所述融合几何特征连接；依据所述融合几何特征与所述特异性信息预测血流储备分数值。通过将真实成像数据与合成数据进行融合,将真实数据引入预测,弥补合成数据分布与真实数据分布之间的域差距,使学习到的血流模型和血流储备分数的计算值更贴近临床实际。</td>   <td>1.一种基于先验知识进行学习血流储备分数的方法,其特征在于,包括：获取冠状动脉的成像数据与合成数据,提取所述成像数据的几何特征,并将所述几何特征投影到所述合成数据得到融合几何特征；提取所述合成数据中的血流的特异性信息,并将所述特异性信息与所述融合几何特征连接；依据所述融合几何特征与所述特异性信息预测血流储备分数值。</td>   <td>G16H50/20;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         耿立帅;                   朝红阳       </td>   <td>中山大学</td>   <td>基于深度摄像模组的物体三维重建方法</td>   <td>广东省</td>   <td>CN110751684B</td>   <td>2023-09-29</td>   <td>本发明涉及计算机视觉领域下的三维重建技术领域,涉及一种基于深度摄像模组的物体三维重建方法。本发明在体素哈希算法过程中采用了一种新的哈希方法：MD5,可以大幅提高数据插入、查找和索引的速度,减少碰撞；另外,本发明提出了一种新的内存分配方式,解决了现有方法中一次性分配固定大小内存的缺陷,从而能够在重建过程当中自动分配内存,实现动态扩展重构区域的目的；本发明采用了一种新的前后两帧对齐方式,计算前后两帧彩色图的orb特征点并挑选好的对应点对,利用对应点从深度图中得到前一帧的世界坐标以及后一帧的相机坐标,从而求解出后一帧的相机外参,实现前后两帧对齐,该方法能更加准确的找到对应点,减小三维重建中的漂移问题。</td>   <td>1.一种基于深度摄像模组的物体三维重建方法,采用基于体素哈希的算法实现三维重构；其特征在于,在体素哈希过程中采用一种新的哈希函数方法计算得到哈希值,新的哈希函数方法包括以下步骤：首先,首先经过如下公式将三维坐标转化为一维索引：                  式中,Δ为当前设备分辨率的大小,即一个体素的大小；然后,将计算好的一维索引数据通过MD5方法转化为哈希值；具体包括以下步骤：S1.设定当前架构下的世界观：三维重建技术本质上是建立一个足够大的空间体素集,使其将想要重建的物体包裹其中,这个母空间体素集向下又分为三层子结构：chunk为一级子结构,空间体素集当中包含n*n*n个chunk结构；block为二级子结构,每个chunk当中又包含m*m*m个block结构；voxel为三级子结构,每个block结构中包含t*t*t个voxel子结构；上述中的变量m、n、t均为正整数变量,根据具体情况进行设置；S2.建立基于TOF模组的“视频流”,从中获取其当前时间下的深度图、RGB图以及点云,并且将TOF模组的相机内参K、当前姿态下的相机外参T读取并储存到相关参数当中；S3.基于前后帧的彩色图,计算前后两帧彩色图的orb特征点并挑选好的对应点对,利用对应点从深度图中得到前一帧的世界坐标以及后一帧的相机坐标,从而求解出后一帧的相机外参,使当前帧下的点云对到标准帧所在的世界坐标系当中；S4.通过基于MD5编码方式的体素哈希方法在GPU设备端建立可扩展的动态哈希表；基于视锥原理将视锥范围内的block从主机端移动到设备端的哈希表当中；S5.基于当前帧的深度图并结合哈希表中的信息,挑选出其中在深度区域截断范围内有效的block,在GPU设备端中通过内存动态管理方法建立一个新的可动态分配的哈希表,并将有效的block移动到新的哈希表当中,新哈希表中记录所有有效block所对应的位置信息以及其所指向的voxel数组的位置；S6.遍历新哈希表中的所有block位置,并且利用cuda发射多线程遍历该block中全部voxel,根据母空间体素集在世界坐标系中起点的初始位置以及其中每个voxel的真实长度,计算该voxel的世界坐标系位置,利用反投影公式将其从世界坐标系位置投影到像素坐标系位置,判断此voxel所在世界坐标位置是否在该深度帧范围内真实可见,如果不可见则不做处理,否则利用TSDF-截断有向距离场公式更新其TSDF值以及更新当前权重；S7.TSDF值相当于等值面的集合,TSDF值为0的位置相当于物体表面,利用MarchingCubes技术生成三角表面网格,并对其进行渲染；S8.将新哈希表中所有的voxel从GPU设备端拷贝回主机端,在主机端记录该位置voxel的内容,并且释放GPU设备端的哈希表,防止造成显存泄露；S9.从TOF模组中读取当前时刻新的RGB图、深度图和点云,跳转至步骤S3。</td>   <td>G06T7/50;G06T17/20;G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         叶东山;              陈翔;              许坤桓;              安小洁;                   邱继云       </td>   <td>中山大学</td>   <td>一种花纹板材圆孔尺寸检测方法、系统及装置</td>   <td>广东省</td>   <td>CN111861997B</td>   <td>2023-09-29</td>   <td>本发明公开了一种花纹板材圆孔尺寸检测方法、系统及装置,该方法包括：获取输入图像并对输入图像进行滤波去噪处理,得到去噪图像；基于霍夫圆检测方法对去噪图像进行检测,得到第一区域；提取第一区域的曲线段并生成多个候选圆；对多个候选圆进行筛选后通过快速最小二乘法细化,得到最终候选圆；对最终候选圆进行完整性分析,确认得到最终圆。该系统包括：去噪模块、检测模块、曲线段模块、细化模块和确认模块。该装置包括存储器以及用于执行上述基于违章行为识别的安全施工方法的处理器。通过使用本发明,实现在花纹干扰严重的情况下识别图像中的圆孔。本发明作为一种花纹板材圆孔尺寸检测方法、系统及装置,可广泛应用于图像检测领域。</td>   <td>1.一种花纹板材圆孔尺寸检测方法,其特征在于,包括以下步骤：获取输入图像并对输入图像进行滤波去噪处理,得到去噪图像；基于霍夫圆检测方法对去噪图像进行检测,得到第一区域；提取第一区域的曲线段,筛选曲线段并生成多个候选圆；通过均值漂移聚类方式对多个候选圆进行筛选后通过快速最小二乘法细化,得到最终候选圆；对最终候选圆进行完整性分析,确认得到最终圆；所述提取第一区域的曲线段,筛选曲线段并生成多个候选圆这一步骤,其具体包括：基于LSD线段提取算法提取第一区域的曲线段；对第一区域的曲线段进行筛选,得到组合成圆的曲线段并生成多个候选圆；所述基于LSD线段提取算法提取第一区域的曲线段这一步骤,其具体包括：计算第一区域内每个像素的梯度,并去除梯度幅度小于第一预设值的点；通过主成分分析法获取弧线,得到第一区域的曲线段；所述对第一区域的曲线段进行筛选,得到组合成圆的曲线段并生成多个候选圆这一步骤,其具体包括：根据第一区域的曲线段得到弧线；根据弧线选出一对匹配的弧线使这一对弧线的弧心所指向的区域包含对方；确认到成功配对的弧线相对于对应弧平分线的交点的距离的差值小于第二预设值,得到一个候选圆；重复筛选步骤生成多个候选圆；所述对最终候选圆进行完整性分析,确认得到最终圆这一步骤,其具体包括：根据最终候选圆的半径计算对应完整圆边长的像素个数,得到第一像素个数；计算成功配对的弧线对应的像素个数,得到第二像素个数；判断到第二像素个数与第一像素个数的比值大于第三预设值,得到第一最终候选圆比值；重复计算像素和比值步骤直至得到所有最终候选圆的比值；取比值最大的最终候选圆作为最终识别结果,得到最终圆。</td>   <td>G06T7/00;G06T7/62;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张贺晔;              刘修健;              高智凡;                   林慧娴       </td>   <td>中山大学</td>   <td>一种基于血管内超声图像的血流储备分数测量方法及系统</td>   <td>广东省</td>   <td>CN112132203B</td>   <td>2023-09-29</td>   <td>本发明公开了一种基于血管内超声图像的血流储备分数测量方法及系统,该方法包括：获取批量血管内超声图像并将批量血管内超声图像划分为训练集和验证集,得到训练集图像和验证集图像；基于训练集图像和验证集图像对预设模型进行优化,得到机器学习模型；获取待测血管内超声图像并进行图像特征提取,得到特征数据；将特征数据输入到机器学习模型,得到待测血管内超声图像的血流储备分数。该系统包括：划分模块、优化模块、特征模块和输出模块。通过使用本发明,根据IVUS图像即可计算FFR值,并且具有准确率高和计算要求低的特点。本发明作为一种基于血管内超声图像的血流储备分数测量方法及系统,可广泛应用于医学图像处理领域。</td>   <td>1.一种基于血管内超声图像的血流储备分数测量方法,其特征在于,包括以下步骤：获取批量血管内超声图像并将批量血管内超声图像划分为训练集和验证集,得到训练集图像和验证集图像；基于训练集图像和验证集图像对预设模型进行优化,得到机器学习模型；获取待测血管内超声图像并进行图像特征提取,得到特征数据；将特征数据输入到机器学习模型,得到待测血管内超声图像的血流储备分数；所述机器学习模型为一个自动编码器类型的网络架构,具体包括两层LSTM单元；不同层数的LSTM单元以不同的帧图像作为输入数据；第一层LSTM单元的控制方程式如下：                                                                                          其中,*是卷积算子,是Hadamard乘积,下标m表示时间步长,上标l表示层索引,x∈R～d是从I3D特征中提取的LSTM单元的输入向量,f表示忘门激活,o表示输出门的激活,c表示单元状态向量,h表示隐藏状态向量,W、U和b是在训练期间学习的权重矩阵和偏差向量；第二层LSTM单元的控制方程如下：                                                                                                                                                                                    其中,下标n表示帧数,pc是合并的小区状态向量,ph是合并的隐藏状态向量,yc,yh,sc,sh是在合并功能模块内计算的潜在变量。</td>   <td>G06V10/778;G06V10/774;G06V10/40;G06V10/82;G06N3/0442;G06N3/0464;G06N3/08;G06N3/049</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高智凡;              申莹;                   张贺晔       </td>   <td>中山大学</td>   <td>一种心室图像分割方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN112132834B</td>   <td>2023-09-29</td>   <td>本发明公开了一种心室图像分割方法、系统、装置及存储介质,该方法包括：获取心室图像并基于特征金字塔架构对心室图像进行特征提取,得到特征图；引入DAPIS损失函数对特征图进行处理,生成预测图像和对应的概率值；结合语义特征融合网络和预测图像对特征图进行拼接融合,得到分割图像。该系统包括：特征提取模块、预测模块和拼接融合模块。该装置包括存储器以及用于执行上述心室图像分割方法的处理器。本发明作为一种心室图像分割方法、系统、装置及存储介质,可广泛应用于医学图像处理领域。</td>   <td>1.一种心室图像分割方法,其特征在于,包括以下步骤：获取心室图像并基于特征金字塔架构对心室图像进行特征提取,得到特征图；引入DAPIS损失函数对特征图进行处理,生成预测图像和对应的概率值；结合语义特征融合网络和预测图像对特征图进行拼接融合,得到分割图像；所述特征金字塔架构包括膨胀率为1的第一特征提取块、膨胀率为1的第二特征提取块、膨胀率为2的第三特征提取块、膨胀率为4的第四特征提取块、膨胀率为8的第五特征提取块和金字塔池,所述第一特征提取块、第二特征提取块、第三特征提取块、第四特征提取块、第五特征提取块和金字塔池依次连接；特征金字塔设计为深度金字塔级体系结构,包括5个级别的SE扩张密集块,即特征提取块,以提取多级别的整体语义特征；多层次信息捕获了LV的全局几何特征,多尺度信息增强了薄弱区域,有助于完善LV的边界；不同SE扩张密集块中不同的膨胀率生成了一个深而密集的金字塔层次结构,随着接受域的增加,特征提取的规模也随之增加,有助于在多尺度空间中搜索LV结构；一个SE扩张密集块包含T个紧密连接层,其中包含空洞卷积和嵌入的SE块,从第t层到第t+1前馈信息的传播公式如下：X-(t+1)＝Y-t＝H(Y-1,Y-2,Y-3,……,Y-(t-1))Y-t＝Q(X-t)其中X-t和Y-t是第t层的输入和输出特征图,H(·)表示前一层的输出特征图的串联,将Q(·)定义为以下四个连续操作的复合函数：嵌入SE块、批处理归一化、一个整流线性单元和一个空洞卷积；空洞卷积运算表示为：                  其中r是膨胀率,m和n是k的坐标偏移,k是空洞卷积核,Y-t(i,j)是第t层在(i,j)处的输出特征图值。</td>   <td>G06T7/10;G06V10/40;G06T5/50;G06T7/143</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高智凡;              刘修健;              张贺晔;                   徐梓峰       </td>   <td>中山大学</td>   <td>一种基于模态学习的血管边界检测方法、系统及装置</td>   <td>广东省</td>   <td>CN112132850B</td>   <td>2023-09-29</td>   <td>本发明公开了一种基于模态学习的血管边界检测方法、系统及装置,该方法包括：获取批量图像并将图像划分得到隐藏模态集和目标模态集；基于卷积自动编码器和双向金字塔网络结构构建模态学习模型；根据隐藏模态集和目标模态集对模态学习模型进行参数优化,得到优化模型；获取待测图像并输入到优化模型识别血管边界。该系统包括：获取模块、构建模块、模态学习模块和识别模块。该装置包括存储器以及用于执行上述基于模态学习的血管边界检测方法的处理器。通过使用本发明,可实现在各种血管环境依然可以进行准确的血管边界检测。本发明作为一种基于模态学习的血管边界检测方法、系统及装置,可广泛应用于血管图像处理领域。</td>   <td>1.一种基于模态学习的血管边界检测方法,其特征在于,包括以下步骤：获取批量图像并将图像划分得到隐藏模态集和目标模态集；基于卷积自动编码器和双向金字塔网络结构构建模态学习模型；根据隐藏模态集和目标模态集对模态学习模型进行参数优化,得到优化模型；获取待测图像并输入到优化模型,识别得到血管边界；所述模态学习模型包括第一卷积自动编码器、第二卷积自动编码器和双向金字塔网络,所述第一卷积自动编码器用于管腔区域的图像分割,所述第二卷积自动编码器用于管腔区域和中膜外膜区域的图像分割,所述双向金字塔网络用于图像特征提取；所述双向金字塔网络包括5个级联模块,每个级联模块中包括4个膨胀卷积层结构。</td>   <td>G06T7/13;G06V10/82;G06N3/0464;G06N3/08;G06V10/40;G06V10/80;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王甲海;              张勇鑫;                   张子臻       </td>   <td>中山大学</td>   <td>基于数据驱动的群体智能计算的城市车辆路径优化方法</td>   <td>广东省</td>   <td>CN112270047B</td>   <td>2023-09-29</td>   <td>本发明属于车辆路径优化技术,为基于数据驱动的群体智能计算的城市车辆路径优化方法,先将多目标车辆路径优化问题建模成无向图,仓库和客户为图中的结点；建立多目标函数；设定M个均匀分布的权重向量,使用权重和的方式将多目标函数的向量目标分解为M个单目标子问题；对每个单目标子问题使用强化学习方法训练一个带有全面环境信息的图注意力模型,再将得到的M个神经网络模型作为初始种群,使用演化学习方法训练模型种群,最终得到M个模型,从而对多目标车辆路径优化问题进行求解,获得一组在两个优化目标间权衡的解集。本发明求得的解集具有良好的收敛性和多样性。</td>   <td>1.基于数据驱动的群体智能计算的城市车辆路径优化方法,其特征在于,包括以下步骤：S1、将城市多目标车辆路径优化问题建模成一个无向图,仓库和客户为图中的结点,结点的属性包括坐标、需求量和服务时间窗；任意两个结点之间通过边相连接,边的属性包括旅行距离、旅行时间；并建立多目标函数,设定两个优化目标：所有车辆的旅行距离总和、最大的单个车辆旅行距离；S2、设定M个均匀分布在[0,1]间的权重向量,使用权重和的方式将多目标函数的向量目标分解为M个单目标子问题；S3、针对每个单目标子问题,训练一个带有全面环境信息的图注意力模型,直至模型收敛,得到M个神经网络模型；S4、将训练得到的M个神经网络模型作为初始种群,对初始种群进一步训练,得到最终的M个模型；S5、用训练好的M个模型对多目标车辆路径优化问题进行求解,获得一组在两个优化目标间权衡的解集；S6、计算解集中每个解对应的车辆旅行距离总和以及最大的单个车辆旅行距离；步骤S3的训练步骤包括：S31、图注意力模型包括编码器与解码器,将训练算例中的结点输入到编码器中,编码器提取训练算例中各个结点的特征以及图的结构特征,得到结点的特征向量序列H＝(h-0,h-2,…,h-N)；S32、更新当前的车辆状态,计算得到当前的全面环境信息,将全面环境信息与结点特征向量序列输入到解码器,由解码器决策选择下一个服务的结点；直到所有客户都被服务,得到关于训练算例的解；S33、第i个单目标子问题的目标为权重向量与向量目标函数F(s|G)的内积,即/&gt;通过权重和的方式将向量目标函数F(s|G)转化为在两个目标上根据权重向量λ-i进行权衡的标量目标,其中/&gt;分别是权重向量λ-i的两个分量,f-1(s)、f-2(s)分别表示车辆的旅行距离总和与最大的单个车辆旅行距离；步骤S33中,针对单目标子问题使用基于策略梯度的REINFORCE算法对神经网络模型的参数θ进行训练,即：                  其中b(G)是用于减小梯度方差的值函数,表示权重向量的转置,F(s|G)表示多目标车辆路径优化问题中的向量目标函数；步骤S4的训练包括过程：S41、将强化学习训练得到的M个模型{π-1,π-2,…,π-M}作为初始种群；S42、对种群中的每个模型π-i进行变异操作,即对模型的参数θ-i加入扰动,生成一个子代模型π-i～′,相应地模型π-i为子代模型π-i～′的父代模型；S43、在多目标车辆路径优化问题环境中对父代模型和子代模型进行评估,得到各个模型的适应度值；然后将适应度值根据非支配等级和拥挤距离进行排序,选择前M个模型作为下一代种群；S44、不断迭代S42与S43,直到达到设定的迭代次数。</td>   <td>G06F30/15;G06F30/27;G06F111/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   何智通       </td>   <td>中山大学</td>   <td>一种基于实例分割和图像修复的带遮挡行人重识别方法</td>   <td>广东省</td>   <td>CN112861785B</td>   <td>2023-09-29</td>   <td>本发明公开了一种基于实例分割和图像修复的带遮挡行人重识别方法,该方法包括：获取待查图像并对待查图像进行实例分割和图像修复处理,得到修复后行人图像；基于预训练的实例分割模型对行人图像库中的行人图像进行实例分割,得到分割后行人图像；分别对修复后行人图像和分割后行人图像进行特征提取并将提取的特征进行相似性度量,检索得到同一行人的其他图像。本发明方法通过对行人缺失部位进行检测并修复的方式,提供更大区域更加完整的行人信息,帮助后续网络获得更具判别性的特征表示,从而提高行人重识别效果。本发明作为一种基于实例分割和图像修复的带遮挡行人重识别方法,可广泛应用于行人重识别领域。</td>   <td>1.一种基于实例分割和图像修复的带遮挡行人重识别方法,其特征在于,包括以下步骤：获取待查图像并对待查图像进行实例分割和图像修复处理,得到修复后行人图像；基于预训练的实例分割模型对行人图像库中的行人图像进行实例分割,得到分割后行人图像；分别对修复后行人图像和分割后行人图像进行特征提取并将提取的特征进行相似性度量,检索得到同一行人的其他图像；所述基于预训练的实例分割模型对待查图像进行实例分割处理,得到目标行人图像这一步骤具体包括：将待查图像输入到预训练的实例分割模型,输出待查图像的置信度、类别、边界框和掩膜；根据类别将部分掩膜作为遮挡物模块；根据置信度和掩膜计算预测得分并根据预测得分将目标行人区域与干扰区域分离,得到目标行人图像；所述根据置信度和掩膜计算预测得分并根据预测得分将目标行人区域与干扰区域分离,得到目标行人图像这一步骤,其具体包括：根据置信度和掩膜计算预测得分并以得分最高的对应掩膜区域作为目标行人区域；将待查图像中该目标行人区域以外的部分设置为黑色,得到只保留目标行人区域的目标行人图像；所述预训练的图像修复网络的训练步骤包括：构建行人图像训练集并从行人图像训练集中获取完整行人图像；将遮挡物模板添加至完整行人图像,得到残缺行人图像；将完整行人图像和残缺行人图像输入到生成对抗网络；基于编码器对残缺行人图像进行处理,转换为隐空间内的特征；基于解码器将隐空间内的特征恢复,得到训练用修复图像；判别器根据完整行人图像对训练用修复图像进行判断,并根据判断结果对生成对抗网络进行参数调整,得到训练完成的图像修复网络；所述分别对修复后行人图像和分割后行人图像进行特征提取并将提取的特征进行相似性度量,检索得到同一行人的其他图像这一步骤,其具体包括：将修复后行人图像输入预训练的特征提取模块,得到第一特征表示；将分割后行人图像输入预训练的特征提取模块,得到第二特征表示；计算第一特征表示和第二特征表示的欧氏距离,进行相似性度量并排序,选择相似度高的图像作为检索结果,检索出同一行人的其他图像。</td>   <td>G06V40/16;G06V20/52;G06V10/25;G06V10/774;G06V10/82;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         乔宇;              张秀兰;              宋迪屏;              李飞;              熊健;              何军军;                   付彬       </td>   <td>中国科学院深圳先进技术研究院;中山大学中山眼科中心</td>   <td>基于跨模态关系推理的眼部检测数据的分类方法及装置</td>   <td>广东省</td>   <td>CN113158822B</td>   <td>2023-09-29</td>   <td>本申请适用于人工智能技术领域,提供了基于跨模态关系推理的眼部检测数据的分类方法及装置,包括：获取视野VF数据和视盘数据；将VF数据和视盘数据输入已训练的卷积神经网络模型,得到VF数据和视盘数据对应的分类结果,其中,卷积神经网络模型对VF数据和视盘数据的处理过程包括：分别提取VF数据和视盘数据的数据特征,得到VF数据特征和视盘数据特征,对VF数据特征和视盘数据特征进行联合处理,得到VF数据的增强特征和视盘数据的增强特征,将VF数据的增强特征和视盘数据的增强特征进行特征融合,得到融合特征,将融合特征进行分类,得到分类结果。通过上述方法,能够得到更准确的分类结果。</td>   <td>1.一种基于跨模态关系推理的眼部检测数据的分类方法,其特征在于,包括：获取视野VF数据和视盘数据；将所述VF数据和所述视盘数据输入已训练的卷积神经网络模型,得到所述VF数据和所述视盘数据对应的分类结果,其中,所述卷积神经网络模型对所述VF数据和所述视盘数据的处理过程包括：分别提取所述VF数据和所述视盘数据的数据特征,得到VF数据特征和视盘数据特征,对所述VF数据特征和所述视盘数据特征进行联合处理,得到所述VF数据的增强特征和所述视盘数据的增强特征,将所述VF数据的增强特征和所述视盘数据的增强特征进行特征融合,得到融合特征,将所述融合特征进行分类,得到所述分类结果；对所述VF数据特征和所述视盘数据特征进行联合处理,得到所述VF数据的增强特征,包括：根据所述VF数据特征和所述视盘数据特征确定由所述视盘数据特征转换得到的VF数据特征；根据所述VF数据特征和所述由所述视盘数据特征转换得到的VF数据特征,得到VF增强特征,所述VF增强特征为所述VF数据的增强特征；对所述VF数据的数据特征和所述视盘数据的数据特征进行联合处理,得到所述视盘数据的增强特征,包括：根据所述VF数据特征和所述视盘数据特征确定由所述VF数据特征转换得到的视盘数据特征；根据所述视盘数据特征以及由所述VF数据特征转换得到的视盘数据特征,得到视盘增强特征,所述视盘增强特征为所述视盘数据的增强特征。</td>   <td>G06V40/16;G06V10/764;G06V10/82;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈旭;              马惠荣;                   周知       </td>   <td>中山大学</td>   <td>多层边缘计算系统中联合绿色能量调度和动态任务分配方法</td>   <td>广东省</td>   <td>CN113159539B</td>   <td>2023-09-29</td>   <td>本发明公开了多层边缘计算系统中联合绿色能源调度和动态任务分配方法,所述方法包括模型建立并初始化；收集系统信息并建立问题成本模型；Lyapunov技术优化；策略实施；更新电池能量队列及策略。本发明优势在于,利用变量依赖性来求解最优解的方法,所指定的随机策略具有高度依赖性,其核心思想是一个向下舍入的变量将被另一个向上舍入的变量来补偿,从而确保即使在舍入后,系统的物理资源约束也能满足。并且本发明方法所得系统成本及计算耗时两方面明显优于现有技术中的方法。</td>   <td>1.多层边缘计算系统中联合绿色能量调度和动态任务分配方法,其特征在于,所述方法包括：S1模型建立并初始化：任务模型建模、前后端边缘服务器模型建模、前端边缘服务器电池模型建模,中心控制器设定绿色能量电池最大容量Q-(max),设定长期服务运行时间为T,并根据每个离散时间片段内中心控制器所收集到的信息为任务卸载执行进行长期成本建模；S2收集系统信息并建立问题成本模型：基站收集当前的设备任务卸载请求及前后端边缘服务器资源信息,并将其发送至中心控制器；S3Lyapunov技术优化：中心控制器根据任务卸载模型及约束进行Lyapunov优化,联合优化当前卸载成本和电池电量；S4策略实施：中心控制器将制定的任务卸载策略和绿色能量调度策略广播至网络中的所有服务器,处理相应的卸载请求；S5更新电池能量队列及策略：更新绿色能量电池容量,历史任务卸载策略、绿色能量调度策略,及时间t＝t+1,判断时间片段t是否小于总时间片段数T,如果是,则继续步骤S2,反之结束；其中,所述步骤S1还包括所述的长期成本包括任务卸载传输时延、前后端边缘服务器为处理任务消耗的能源成本、以及云服务器端云资源租用成本,初始化当前时间t＝0,初始化各个前端服务器的电池容量为0；其中所述的长期成本建模步骤包括：S1.1设备任务建模：中心控制器对每个任务卸载请求制定任务卸载策略x-(ij)(t),即在时间片段t内,将任务卸载至前端边缘服务器f(0&lt;f≤F)、或后端边缘服务器b(F&lt;b≤F+B)、或云服务器c(c＝F+B)进行处理,假定在给点时间片段t内,对于设备任务而言能且仅能卸载至一个服务器进行处理,任务卸载需要满足的约束有:                                                                        其中,公式(1)中,N表示网络中所有的设备,F表示网络中所有配备能量收集技术的前端边缘服务器,B表示网络中所有的后端边缘服务器；公式(2)表示时间片t内,前端边缘服务器j所能处理的任务周期数不能超过其总的处理能力公式(3)表示时间片t内,后端服务器j所能处理的任务周期数不能超过其总的处理能力/&gt;公式(4)表示时间片t内,设备任务仅能被卸载一次；S1.2对配备能量收集设备的前端边缘服务器建模：假定每个配备能量收集设备的前端边缘服务器f∈{1,2,...,F}在时间片段t内可收集的绿色能量用R-f(t)表示,实际能够收集到的绿色能量用r-f(t)表示,其中用于处理任务的绿色能量用表示,进一步有：r-f(t)∈[0,R-f(t)]     (5)                  配备能量收集设备的前端边缘服务器f∈{1,2,...,F}在时间片段t内所消耗的总的能耗可以表示为：                  其中表示处理i任务所消耗的j服务器的能耗；考虑到电池能量约束：                  进一步有：                                    每个能量收集模块的动态变化为：                  S1.3系统成本最小化建模假定收集到的绿色能量并不是免费的,使用一个单位的绿色能量成本系数为α,而使用一个单位电网电力能源的成本为β；模型中时延成本和能耗成本系数分别用来表示,用/&gt;和/&gt;来表示在前端边缘服务器和后端边缘服务器端的单位电价；前端服务器为处理系统内所有任务所需要的时延成本和能耗成本可以表示为：后端服务器为处理系统内所有任务所需要的时延成本和能耗成本可以表示为：                  云服务器为处理系统内所有任务所需要的时延成本及云资源租用成本为：                  从而引入能量收集技术后,制定任务卸载策略以及绿色能量调度策略,从而最小化系统内任务执行总成本,优化目标为：                  s.t.(1)-(11)。</td>   <td>G06Q10/0631;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林清音;              陈志广;                   卢宇彤       </td>   <td>中山大学</td>   <td>一种基于改进LSM树结构的数据存储方法及系统</td>   <td>广东省</td>   <td>CN113704260B</td>   <td>2023-09-29</td>   <td>本发明公开了一种基于改进LSM树结构的数据存储方法及系统,该方法包括：获响应于用户创建数据库的操作,系统根据用户指定容量,创建更新表并设置阈值；响应于用户向数据库中插入键值对,系统将键值对记录到Memtable,将键记录到更新表判断到更新表未达到预设阈值,则插入过程结束；判断到更新表达到预设阈值,选择符合预设条件的SStable触发特殊压缩操作。该系统包括：预创建模块和存储模块。通过使用本发明,降低LSM-Tree数据存储系统的读请求尾延迟。本发明作为一种基于改进LSM树结构的数据存储方法及系统,可广泛应用于数据存储领域。</td>   <td>1.一种基于改进LSM树结构的数据存储方法,其特征在于,包括以下步骤：响应于用户创建数据库的操作,系统根据用户指定容量,创建更新表并设置阈值,同时创建热数据记录表；响应于用户向数据库中插入键值对,系统将键值对记录到MemTable,将键记录到更新表；判断到更新表未达到预设阈值,则插入过程结束；判断到更新表达到预设阈值,选择符合预设条件的SSTable触发特殊压缩操作；改进LSM树结构包括MemTable、更新表、热数据记录表和SSTable；所述预设条件的SSTable具体包括：构建旧数据分割线；将分割线所在的层次记为L-d,从L-d的下一层L-(d+1)开始,逐层读取每个SSTable文件的元数据；根据元数据中的键范围与更新表的最大键和最小键作比较,并判断有无范围交叉；判断到有范围交叉,计算该SSTable文件中的无效键占比；判断到该SSTable文件中的无效键占比大于预设值,选择该SSTable文件进行压缩；所述无效键占比的计算公式为ratio＝H-k/N-k,ratio表示无效键值比,H-k表示更新表中的键命中该文件的布隆过滤器的数量,N-k表示该文件包含的键的总数量；所述特殊压缩操作的具体步骤包括：将该SSTable文件所在的层次记为L-c,从L-c的下一层次L-(c+1)开始,选择与该SSTable有键范围交叉的文件；为该SSTable文件以及选中的所有SSTable文件生成一个总体迭代器；依次迭代每个键值对并将键分为冷数据和热数据,分别将冷数据和热数据保存到不同的SSTable文件；将保存热数据的新SSTable文件写入L-c,保存冷数据的新SSTable文件写入L-(c+1),删除此次压缩过程涉及的旧SSTable文件。</td>   <td>G06F16/22;G06F16/23;G06F16/2455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              张夏茵;              肖辉;              邱伟;                   刘春新       </td>   <td>中山大学中山眼科中心</td>   <td>一种鉴别视神经脊髓炎和原发性开角型青光眼的系统</td>   <td>广东省</td>   <td>CN113781380B</td>   <td>2023-09-29</td>   <td>本发明涉及一种鉴别视神经脊髓炎和原发性开角型青光眼的系统,包括：图像采集模块；参数获取模块,用于根据患有视神经脊髓炎和患有原发性开角型青光眼的眼底光学相干断层扫描血管图像获得诊断参数；函数生成模块,用于利用所述诊断参数计算Fisher判别的分类函数系数,并根据所述分类函数系数分别生成视神经脊髓炎和原发性开角型青光眼的Fisher判别函数；比较判定模块,用于将待鉴别的眼底光学相干断层扫描血管图像的诊断参数分别代入Fisher判别函数中,比较两个函数值大小,若视神经脊髓炎的函数值大于原发性开角型青光眼的函数值,则判定为视神经脊髓炎,否则判定为原发性开角型青光眼。本发明提高两种疾病的准确率,同时有助于患者减少检查项目和检查时间。</td>   <td>1.一种鉴别视神经脊髓炎和原发性开角型青光眼的系统,其特征在于,包括：图像采集模块,用于采集患有视神经脊髓炎和患有原发性开角型青光眼的眼底光学相干断层扫描血管图像；参数获取模块,用于根据患有视神经脊髓炎和患有原发性开角型青光眼的眼底光学相干断层扫描血管图像,获得诊断参数,所述诊断参数包括眼底结构参数、血流参数和黄斑中心无血管区面积FAZ,所述眼底结构参数包括视乳头旁神经纤维层颞侧及下方的平均厚度TIpRNFL、黄斑神经节细胞层-内丛状层鼻侧厚度N GC-IPL和垂直杯盘比verticalC/D；函数生成模块,用于利用所述诊断参数计算Fisher判别的分类函数系数,并根据所述分类函数系数分别生成视神经脊髓炎和原发性开角型青光眼的Fisher判别函数；比较判定模块,用于将待鉴别的眼底光学相干断层扫描血管图像的诊断参数分别代入所述视神经脊髓炎和原发性开角型青光眼的Fisher判别函数中,得到两个函数值,并比较两个函数值大小,若视神经脊髓炎的函数值大于原发性开角型青光眼的函数值,则判定所述待鉴别的眼底光学相干断层扫描血管图像为患有视神经脊髓炎,否则判定为所述待鉴别的眼底相干断层扫描血管图像为患有原发性开角型青光眼。</td>   <td>G06T7/00;G06V10/77;G06V10/764;A61B3/12;A61B3/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              卢梓君;              王和旭;              韦骏;              龚喜;              谢鹏;                   孙鹏楠       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种浒苔堆积量估算方法、系统及存储介质</td>   <td>广东省</td>   <td>CN114049243B</td>   <td>2023-09-29</td>   <td>本发明公开了一种浒苔堆积量估算方法、系统及存储介质,方法包括：获取浒苔观测信息,其中,所述浒苔观测信息包括浒苔爆发信息、浒苔区域位置信息、浒苔覆盖范围信息、浒苔覆盖厚度信息、浒苔图片信息以及海气背景信息；根据所述浒苔观测信息,通过BIM三维方法构建三维浒苔空间模型；根据所述三维浒苔空间模型计算近海近岸的浒苔总量以及打捞区域。本发明增强了实时性,降低了人工成本,而且有助于提高打捞效率,可广泛应用于计算机技术领域。</td>   <td>1.一种浒苔堆积量估算方法,其特征在于,包括：获取浒苔观测信息,其中,所述浒苔观测信息包括浒苔爆发信息、浒苔区域位置信息、浒苔覆盖范围信息、浒苔覆盖厚度信息、浒苔图片信息以及海气背景信息；根据所述浒苔观测信息,通过BIM三维方法构建三维浒苔空间模型；根据所述三维浒苔空间模型计算近海近岸的浒苔总量以及打捞区域；根据所述浒苔总量以及所述打捞区域,生成无人艇编队的打捞路线规划；根据所述打捞路线规划,控制无人艇编队进行浒苔打捞；将打捞得到的浒苔进行回收利用；所述根据所述浒苔观测信息,通过BIM三维方法构建三维浒苔空间模型,包括：从所述浒苔观测信息中获取海气背景信息；从所述浒苔观测信息中获取浒苔覆盖区域的大小和形状信息；根据所述海气背景信息和所述浒苔覆盖区域的大小和形状信息,构建浒苔区域二维模型；在所述浒苔区域二维模型中,获取浒苔覆盖区域边缘作为网格划分的计算边界面,并确定所述计算边界面的经纬度的取值范围；通过无人艇进行边缘网格点测杆穿透,对浒苔覆盖区域边缘所划分的网格区域的边缘网格点进行测杆穿透,获取浒苔网格区域厚度信息；根据所述海气背景信息、所述浒苔覆盖区域的大小和形状信息、所述经纬度的取值范围以及所述浒苔网格区域厚度信息,构建三维浒苔空间模型；所述根据所述浒苔总量以及所述打捞区域,生成无人艇编队的打捞路线规划,包括：根据所述三维浒苔空间模型,读取浒苔堆积量、岸线地形及岛屿障碍物边界信息；根据待清理浒苔的任务量,通过等体积法对三维浒苔空间模型进行待作业区域的划分；配置无人艇的作业参数；根据多边形扫描填充算法对所述无人艇的作业航线进行初始化配置；通过贪婪算法对各个作业航线进行排序优化,得到各个无人艇的最短路径；根据最小跨度法对所述无人艇的作业航向进行优化；构建最优航线目标模型；根据所述最优航线目标模型,通过OR-Tools方法计算浒苔块的最优航线调度次序,并将所述最优航线调度次序分配给对应的无人艇；建立无人艇能量供应与浒苔装卸模型,对无人艇的能量供应及浒苔的存储量进行优化配置。</td>   <td>G06Q50/26;G06Q10/047;G06Q10/0631;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李超峰;              邓一术;              经秉中;              陈浩华;                   李彬       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种鼻咽癌淋巴结区域的识别分割方法、装置及系统</td>   <td>广东省</td>   <td>CN114445421B</td>   <td>2023-09-29</td>   <td>本发明公开了一种鼻咽癌淋巴结区域的识别分割方法、装置及系统。该装置包括数据获取单元以及识别分割单元。该系统包括识别分割模块以及数据存储模块。通过端到端的从粗到细的三维深度监督卷积神经网络三维模型对待识别分割的磁共振图像进行识别分割,从而获得包括鼻咽癌淋巴结的分割区域,该识别分割方法、装置及系统提升了鼻咽癌淋巴结区域的识别分割的准确性；进一步地,本发明提供的一种鼻咽癌淋巴结区域的识别分割方法、装置及系统还通过预设的双审数据处理方法先对第一训练图像数据组进行处理以获得第二训练图像数据组,从而充分根据淋巴结的形态特点设计合理的模型,进而提升了鼻咽癌淋巴结区域的识别分割的准确性。</td>   <td>1.一种鼻咽癌淋巴结区域的识别分割方法,其特征在于,所述识别分割方法包括：获取待识别分割的磁共振图像；通过预设的淋巴识别分割模型,对所述磁共振图像进行识别分割,从而获得分割区域图像；所述淋巴识别分割模型为端到端的、从粗到细的、三维深度监督卷积神经网络三维模型；通过预设的淋巴识别分割模型,对所述磁共振图像进行识别分割,从而获得分割区域图像,具体包括：对所述磁共振图像进行数据增强处理,从而获得磁共振增强数据组；对所述磁共振增强数据组进行过滤卷积处理,从而获得所述磁共振增强数据组的特征数据组；对所述特征数据组进行反卷积处理,从而获得不同分割粒度的鼻咽癌转移淋巴结区域图像以及对应的存在概率；筛选出所述存在概率大于预设的概率阈值的对应的一个或多个第一鼻咽癌转移淋巴结区域图像；筛选出所述第一鼻咽癌转移淋巴结区域图像的分割粒度达到预设的粒度阈值的对应的一个或多个第二鼻咽癌转移淋巴结区域图像；获取所述第二鼻咽癌转移淋巴结区域图像中分割粒度最高的第三鼻咽癌转移淋巴结区域图像,并将所述第三鼻咽癌转移淋巴结区域图像输出为分割区域图像；其中,在粗到细深度注意力监督中,粗尺度的预测概率图被用作权重图,以排除其他不相关的部分,并仅在粗尺度已经识别的前景超集内聚焦精细尺度。</td>   <td>G06T7/11;G06V20/64;G06N3/0464;G06N3/045;G06N3/09;G06V10/774;G06V10/26;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小玲;              林浩添;              郭翀;              于姗姗;              徐正杰;                   伍本娟       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于卷积神经网络的脉络膜血管指数预测方法和装置</td>   <td>广东省</td>   <td>CN115456962B</td>   <td>2023-09-29</td>   <td>本发明公开了一种基于卷积神经网络的脉络膜血管指数预测方法和装置。该方法包括步骤：获取待识别的光学相干断层扫描图像,将所述待识别的光学相干断层扫描图像输入至基于卷积神经网络的脉络膜血管指数预测模型,输出所述预测待识别的光学相干断层扫描图像对应的脉络膜面积、管腔面积和脉络膜血管指数(CVI)。本发明提高了对脉络膜面积、管腔面积和CVI值的识别准确度。</td>   <td>1.一种基于卷积神经网络的脉络膜血管指数预测方法,其特征在于,包括以下步骤：获取待识别的光学相干断层扫描图像,将所述待识别的光学相干断层扫描图像输入至基于卷积神经网络的脉络膜血管指数预测模型,输出所述待识别的光学相干断层扫描图像对应的脉络膜面积、脉络膜管腔面积和CVI值；所述脉络膜血管指数预测模型在进行训练时,训练集包括：历史光学相干断层扫描图像和图像所对应的脉络膜参数,所述脉络膜参数包括脉络膜面积、脉络膜管腔面积及CVI值；根据所述脉络膜面积、脉络膜管腔面积及CVI值对每一张所述历史光学相干断层扫描图像进行标记；其中,所述基于卷积神经网络的脉络膜血管指数预测模型包括1个输入层、1个Stem模块、5个Inception-resnet-A模块、1个Reduction-A模块、10个Inception-resnet-B模块、1个Reduction-B模块、5个Inception-resnet-C模块、1个平均池化层模块、1个dropout模块和1个Linear输出层；所述光学相干断层扫描图像依次经过输入层、Stem模块、Inception-resnet-A模块、Reduction-A模块Inception-resnet-B模块、Reduction-B模块、Inception-resnet-C模块、平均池化层模块、dropout模块和Linear输出层,输出所述待识别的光学相干断层扫描图像对应的脉络膜面积、脉络膜管腔面积和CVI值。</td>   <td>G06T7/00;G06T7/62;G06N3/0464;G06N3/08;A61B3/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         单云霄;                   付垚       </td>   <td>中山大学;中山大学深圳研究院;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种基于高斯过程建模的可通行区域提取的方法及系统</td>   <td>广东省</td>   <td>CN116824057A</td>   <td>2023-09-29</td>   <td>本发明公开了一种基于高斯过程建模的可通行区域提取的方法及系统,该方法包括：获取点云数据,然后将点云数据送入3d-mininet进行语义分割,得到植路面点云和障碍物点云；对路面点云进行栅格下采样、中心化,接着对中心化后路面点云进行区域划分,并对每个路面点云区域进行地面高斯过程建模,得到路面模型外点；通过对障碍物点云和路面模型外点共同进行欧式聚类,得到可通行区域。该系统包括：点云数据获取模块、语义分割模块、栅格采样模块、中心化模块、模型构建模块和聚类模块。通过使用本发明,能够针对复杂、颠簸的野外行驶环境,准确的提取车辆可通行区域。本发明可广泛应用于无人车智能驾驶技术领域。</td>   <td>1.一种基于高斯过程建模的可通行区域提取的方法,其特征在于,包括以下步骤：获取点云数据；对点云数据进行语义分割,得到路面点云和障碍点云；对路面点云进行栅格下采样,得到采样后路面点云；对采样后路面点云进行中心化,得到中心化后路面点云；对中心化后路面点云进行区域划分,并对每个区域进行地面高斯过程建模,得到路面模型外点；对障碍物点云和路面模型外点共同进行欧式聚类,得到可通行区域。</td>   <td>G06T17/00;G06T19/20;G06V10/762;G06V10/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵慧英;              林斯颖;              杨跃东;                   雍娟娟       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种病理图像自动分割方法和装置、电子设备及介质</td>   <td>广东省</td>   <td>CN116823854A</td>   <td>2023-09-29</td>   <td>本公开涉及医学图像处理技术领域,具体涉及一种病理图像自动分割方法和装置、电子设备及介质。所述方法包括：从病理图像得到具有第一分辨率的多个第一病理图像块和具有第二分辨率的多个第二病理图像块,病理图像包括多个图像区域,第一分辨率低于第二分辨率；针对每个图像区域进行图像分割,包括：将相应的第一病理图像块进行组织级别的ROI分割,将相应的多个第二病理图像块进行细胞级别的ROI分割,基于组织级别ROI分割结果与多个第一细胞级别ROI分割结果,得到图像区域的图像分割结果。本公开在关注图像细节的同时也关注图像块之间的全局空间关系,不仅对病理图像ROI区域信息进行了利用,同时ROI分割的准确率较高。</td>   <td>1.一种病理图像自动分割方法,其特征在于,包括以下步骤：从所述病理图像得到具有第一分辨率的多个第一病理图像块和具有第二分辨率的多个第二病理图像块,所述病理图像包括多个图像区域,每个图像区域对应于相应的至少一个第一病理图像块和相应的多个第二病理图像块,所述第一分辨率低于所述第二分辨率；针对每个图像区域进行图像分割,包括：将相应的第一病理图像块进行组织级别的ROI分割,获得组织级别ROI分割结果,将相应的多个第二病理图像块进行细胞级别的ROI分割,获得多个第一细胞级别ROI分割结果；基于所述组织级别ROI分割结果与所述多个第一细胞级别ROI分割结果,得到所述图像区域的图像分割结果；基于每个图像区域的图像分割结果,得到所述病理图像的分割结果。</td>   <td>G06T7/11;G06T7/136;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         熊会元;              张秋;              刘羽;              潘跃龙;                   张学岭       </td>   <td>中山大学;中广核工程有限公司</td>   <td>一种融合路侧稀疏点云和道路特征的车辆位姿估计方法</td>   <td>广东省</td>   <td>CN116823944A</td>   <td>2023-09-29</td>   <td>本发明涉及车辆跟踪技术领域,公开了一种融合路侧稀疏点云和道路特征的车辆位姿估计方法,进行了粗配准和精配准,使用两阶段配准提高准确率,使本发明既有无模型方法鲁棒性好的优点,又有模型方法精度高的优点,解决了稀疏点云位姿估计鲁棒性和准确度不高的问题。并且在进行粗配准时,利用了地面点云的法向量,使用环境特征代替目标车辆点云特征作为约束,环境特征不随目标车辆和雷达间距变化,提高了算法的鲁棒性,解决了稀疏点云车辆特征少、车辆特征随距离变化大的问题。另外,本发明实施例使用一个目标车辆全视角稠密点云模板代替目标车辆多视角稠密点云库,降低了模型存储成本和搜索时间成本,实现了在相同运行速度下计算设备成本的降低。</td>   <td>1.一种融合路侧稀疏点云和道路特征的车辆位姿估计方法,其特征在于,包括如下步骤：S1：获取路侧激光雷达采集到的实时点云数据；S2：提取步骤S1得到的点云数据中位于车辆行驶区域的点云；S3：拟合地面,根据拟合地面,将车辆行驶区域的点云分为地面点云和地上点云；S4：将地上点云进行聚类,得到目标车辆点云聚类；S5：估计地面点云的法向量,得到地面点云法向量[-x,N-y,N-z]；S6：将步骤S4得到的目标车辆点云和步骤S5得到的地面点云法向量通过主成分分析法进行粗配准,得到粗配准矩阵和粗配准后的目标点云；S7：将粗配准后的目标点云和点云模板进行精配准,得到精配准矩阵；S8：将步骤S6得到的粗配准矩阵和步骤S7得到的精配准矩阵相乘,得到最终配准矩阵；S9：根据步骤S8得到的最终配准矩阵转换成位姿表达式。</td>   <td>G06T7/73;G06T7/33;G06V10/762;G06V10/77;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡立;                   刘洁       </td>   <td>中山大学</td>   <td>一种复杂地质结构三维建模过程中断层厚度处理方法</td>   <td>广东省</td>   <td>CN116824071A</td>   <td>2023-09-29</td>   <td>本发明公开了一种复杂地质结构三维建模过程中断层厚度处理方法,所述的方法如下：在建立初步的三维地质结构模型之后,采用定义岩墙的基本方法添加断层厚度,具体在定义岩墙的基本形态后,通过定义指定位置上岩墙的厚度,使其端部的厚度渐变为零,实现断层终止的效果。由于无厚度断层的三维地质结构模型在后续网格化处理时,难以形成断层单元,给后续分析研究带来极大不便。本发明通过在初步建立三维地质结构模型后,给断层施加合适的厚度,既保证了三维地质结构模型的真实性,又为后续处理分析提供了极大的便利。</td>   <td>1.一种复杂地质结构三维建模过程中断层厚度处理方法,其特征在于：所述的方法如下：在建立初步的三维地质结构模型之后,采用定义岩墙的基本方法添加断层厚度,具体在定义岩墙的基本形态后,通过定义指定位置上岩墙的厚度,使其端部的厚度渐变为零,实现断层终止的效果。</td>   <td>G06T17/05</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李健;              陈俊周;              何子诚;              张凯;              赵楠;              王永权;              侯伟坚;              孟庆翔;                   李春炜       </td>   <td>中山大学附属第一医院</td>   <td>一种基于深度学习模型的鼻咽癌检测系统</td>   <td>广东省</td>   <td>CN116824333A</td>   <td>2023-09-29</td>   <td>本发明公开了一种基于深度学习模型的鼻咽癌检测系统,包括：所述图像获取模块,用于获取鼻咽内镜检查视频中截取的待检测图像；所述鼻咽癌预测结果生成模块,用于将所述待检测图像输入到预设的深度学习模型中,以使所述深度学习模型对所述待检测图像对应的鼻咽癌病灶区域进行标注,并生成具有病灶标注区域的目标图像和鼻咽癌概率。与现有技术相比,本发明的深度学习模型可以得到更加还原待检测图像的融合特征图,通过检测头子模型对融合特征图进行预测,可以得到更加精准的具有病灶标注区域的目标图像和鼻咽癌概率,即通过本发明可以准确识别并定位出鼻咽癌病灶,并且让临床医生能够对活检区域进行更加准确的指导。</td>   <td>1.一种基于深度学习模型的鼻咽癌检测系统,其特征在于,包括：图像获取模块和鼻咽癌预测结果生成模块；所述图像获取模块,用于获取鼻咽内镜检查视频中截取的待检测图像；所述鼻咽癌预测结果生成模块,用于将所述待检测图像输入到预设的深度学习模型中,以使预设的深度学习模型对所述待检测图像对应的鼻咽癌病灶区域进行标注,并生成具有病灶标注区域的目标图像和鼻咽癌概率；其中,所述预设的深度学习模型包括图像特征提取子模型、特征融合子模型以及检测头子模型；所述图像特征提取子模型,用于提取待检测图像的特征,并生成若干个特征图；所述特征融合子模型,用于通过特征融合子模型中的可变形池化模块学习的空间偏移量对每个特征图的感受野进行调整,并将调整后的所有特征图进行多尺度特征融合,生成融合特征图；所述检测头子模型,用于通过检测头子模型中的解耦头模块对融合特征图进行检测,对融合特征图中的鼻咽癌病灶区域进行标注,生成具有鼻咽癌病灶标注区域的目标图像和鼻咽癌概率。</td>   <td>G06V10/82;G06V10/764;G06V10/766;G06V10/80;G06V10/52;G06V10/24;G06N3/0464;G06N3/048;G06N3/08;A61B1/04;A61B1/233;A61B1/267</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨建荣;              陈小舒;              袁梦;              杨绪疆;              林景华;              曹小龙;              陈锋;              张晓玉;              李梓彰;              郑贵锋;                   王学钦       </td>   <td>中山大学</td>   <td>基于动态规划的有向无环图比对方法、模块及系统</td>   <td>广东省</td>   <td>CN112100448B</td>   <td>2023-09-26</td>   <td>本发明公开了一种基于动态规划的有向无环图比对方法,包括：获取预设超参数、DAG文件及节点类型匹配分数文件,预设超参数包括统计检验强度,DAG文件包括源DAG文件及目标DAG文件；通过基于动态规划的DAG比对算法,生成目标DAG文件与源DAG文件的匹配分数；根据统计检验强度,随机分叉生成伪DAG文件,通过基于动态规划的DAG比对算法,生成目标DAG文件与伪DAG文件的匹配分数；根据目标DAG文件与源DAG文件的匹配分数在目标DAG文件与伪DAG文件的匹配分数的分布,生成统计显著指标值。本发明还公开了一种计算模块及一种基于动态规划的有向无环图比对系统。本发明将动态规划与有向无环图比对相结合,可以用于解决有向无环图比对计算量庞大的问题。</td>   <td>1.一种基于动态规划的有向无环图比对方法,其特征在于,包括：获取预设超参数、DAG文件及节点类型匹配分数文件,所述预设超参数包括输出结果数量、删除节点罚分及统计检验强度,所述DAG文件包括源DAG文件及目标DAG文件,所述节点类型匹配分数文件包括节点类型匹配分数矩阵并用于存储源DAG文件及目标DAG文件中的不同节点类型的所有配对及匹配分数；通过基于动态规划的DAG比对算法,根据所述预设超参数、DAG文件及节点类型匹配分数文件,生成所述目标DAG文件与源DAG文件的源比对结果,所述源比对结果包括所述目标DAG文件与源DAG文件的匹配分数；根据所述统计检验强度,随机分叉生成伪DAG文件,通过基于动态规划的DAG比对算法,根据所述预设超参数、DAG文件及节点类型匹配分数文件,生成所述目标DAG文件与伪DAG文件的伪比对结果,所述伪比对结果包括所述目标DAG文件与伪DAG文件的匹配分数；根据所述目标DAG文件与源DAG文件的匹配分数在所述目标DAG文件与伪DAG文件的匹配分数的分布,生成统计显著指标值；所述基于动态规划的DAG比对算法的步骤包括：根据节点匹配分数矩阵,沿正向传播方向,计算待比对DAG文件及目标DAG文件中末端节点之间的正向匹配分数,并将所述正向匹配分数输出至初始动态规划分数矩阵中,所述待比对DAG文件为源DAG文件或伪DAG文件；根据所述节点匹配分数矩阵,沿反向传播方向,计算所述待比对DAG文件及目标DAG文件中内部节点之间的反向匹配分数,并将所述反向匹配分数输出至所述初始动态规划分数矩阵中,以构成目标动态规划分数矩阵；根据最低共同祖先原则,提取所述目标动态规划分数矩阵中最大的匹配分数所对应的祖先节点集合； 根据所述祖先节点集合,回溯输出子节点的匹配策略,得到比对关系、待比对DAG文件选择的子节点及目标DAG文件选择的子节点；输出所述最大的匹配分数、祖先节点集合、比对关系、待比对DAG文件选择的子节点及目标DAG文件选择的子节点。</td>   <td>G06F16/901;G06F16/903;G06F16/9038;G06F16/904;G06F16/906</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              程凤雯;              张伟;                   刘泽华       </td>   <td>中山大学</td>   <td>一种基于部分解耦条件下通道分配的动作识别方法及系统</td>   <td>广东省</td>   <td>CN112597856B</td>   <td>2023-09-26</td>   <td>本发明公开了一种基于部分解耦条件下通道分配的动作识别方法及系统,该方法包括：获取视频信息并对视频信息进行处理,抽取视频帧图像；将视频帧图像输入到预设的卷积神经网络进行动作识别,得到识别结果；所述预设的卷积神经网络包括残差层、两个R(2+1)块、Decoupled-3D模块、池化层和全连接层。该系统包括：视频帧抽取模块和识别模块。本发明通过Decoupled-3D模块分配空间和时间上的通道维度信息来平衡模型的表达能力。本发明作为一种基于部分解耦条件下通道分配的动作识别方法及系统,可广泛应用于模型改进领域。</td>   <td>1.一种基于部分解耦条件下通道分配的动作识别方法,其特征在于,包括以下步骤：获取视频信息并对视频信息进行处理,抽取视频帧图像；将视频帧图像输入到预设的卷积神经网络进行动作识别,得到识别结果；所述预设的卷积神经网络包括残差层、两个R(2+1)块、Decoupled-3D模块、池化层和全连接层；所述Decoupled-3D模块基于通道分解的部分解耦时空滤波器设计形成,所述Decoupled-3D模块包括部分解耦条件下利用通道分解形成的空间卷积层和时间卷积层；所述将视频帧图像输入到预设的卷积神经网络进行动作识别,得到识别结果这一步骤,其具体包括：将视频帧图像输入到预设的卷积神经网络；依次经过残差层、两个R(2+1)D块和Decoupled-3D模块对视频帧图像的数据进行卷积操作,经过池化层进行下采样,最后基于全连接层对特征进行分类,得到识别结果；经过Decoupled-3D模块对视频帧图像的数据进行卷积操作具体为数据进入Decoupled-3D模块后依次进行空间卷积、归一化、激活、时间卷积、归一化、激活操作,输出特征图。</td>   <td>G06V20/40;G06V10/82;G06N3/0464;G06N3/048</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周榆明;                   成慧       </td>   <td>中山大学</td>   <td>一种适用于多平台协同感知的地图融合方法</td>   <td>广东省</td>   <td>CN112669358B</td>   <td>2023-09-26</td>   <td>本发明公开了一种适用于多平台协同感知的地图融合方法,方法包括：获取里程信息和局部地图信息；根据所述里程信息对所述局部地图信息进行预处理,得到子地图特征点；根据所述子地图特征点进行点云配准,得到子地图间的匹配关系；根据所述里程信息、局部地图信息和子地图间的匹配关系构建全局位姿图,优化得到融合地图。本发明实施例降低了配准难度且扩展了应用场景,可广泛应用于点云处理技术领域。</td>   <td>1.一种适用于多平台协同感知的地图融合方法,其特征在于,包括：获取里程信息和局部地图信息；根据所述里程信息对所述局部地图信息进行预处理,得到子地图特征点；根据所述子地图特征点进行点云配准,得到子地图间的匹配关系；根据所述里程信息、局部地图信息和子地图间的匹配关系构建全局位姿图,优化得到融合地图；所述根据所述子地图特征点进行点云配准,得到子地图间的匹配关系,包括：根据所述子地图特征点,计算源点云中四点集合的两个比例因子；所述比例因子用于保持点云在进行旋转和平移变换时的仿射不变性；根据所述比例因子,计算四点集合的基线交点位置,并确定所述交点的坐标；根据所述交点的坐标,确定匹配对；根据LCP策略对所述匹配对进行计算,得到最大重叠度四点对,进而确定所述子地图间的匹配关系；所述根据LCP策略对所述匹配对进行计算,得到最大重叠度四点对,进而确定所述子地图间的匹配关系,包括：通过GC-RANSAC框架进行迭代计算,通过图割算法来求解内点集；根据所述内点集中每个单点的判别误差约束和邻近点对的空间一致性约束来构建能量函数；根据所述能量函数确定所述子地图间的匹配关系；所述能量函数为：                                    其中,E-K(L)代表当前内外点标签设置对于每个点带来的误差；E-S(L)代表基于空间一致性假设构造的能量函数；L代表所有点的内外点标签；θ表示模型参数,模型参数包括点云间的旋转和平移；φ(p,θ)表示点p在参数θ下计算得到的误差值,误差值包括旋转和平移后到目标点的距离；∈为内外点判别阈值；K-p代表点p的K(δ,∈)值；K-q代表点q的K(δ,∈)值。</td>   <td>G06T7/33;G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              庞志勇;                   黄铚聪       </td>   <td>中山大学</td>   <td>一种多视点图像合成方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN113256544B</td>   <td>2023-09-26</td>   <td>本发明公开了一种多视点图像合成方法、系统、装置及存储介质。该方法包括以下步骤：获取原始图像,根据原始图像获取深度特征图；根据缩放因子对深度特征图的深度维度进行插值处理得到第一深度特征图,缩放因子用于调节深度特征图的视点；根据第一深度特征图和原始图像,得到视点图像,若干张视点图像组成多视点图像。本发明利用缩放因子在原始图像的深度特征图的深度维度上进行插值处理,得到包含新的深度信息的第一深度特征图,再将第一深度特征图与原始图像进行融合,即可得到包含有新视点的视点图像,多张包含不同视点的视点图像即可组成多视点图像,具有价格低廉、应用范围广的特点。本发明可广泛应用于视点图像合成方法技术领域内。</td>   <td>1.一种多视点图像合成方法,其特征在于,包括以下步骤：获取原始图像,根据所述原始图像获取深度特征图；根据缩放因子对所述深度特征图的深度维度进行插值处理得到第一深度特征图,所述缩放因子用于调节所述深度特征图的视点；根据所述第一深度特征图和所述原始图像,得到视点图像,若干张所述视点图像组成多视点图像；所述根据缩放因子对所述深度特征图的深度维度进行插值处理得到第一深度特征图这一步骤,包括以下步骤：为所述深度特征图的深度维度创建深度索引表,所述深度索引表中包括若干个深度索引,每一个所述深度索引对应一个深度值；利用所述缩放因子和所述深度索引表确定第一深度索引表,所述第一深度索引表包括若干个第一深度索引；确定所述第一深度索引的第一深度值,根据所述第一深度索引及其对应的第一深度值得到第一深度特征图；确定第一深度索引表,包括以下步骤：将所述缩放因子与所述第一深度索引表做乘积得到中间索引表,所述中间索引表包括若干个中间索引；对每一个所述中间索引进行取整得到第一深度索引,若干个所述第一深度索引构成所述第一深度索引表；所述根据所述第一深度特征图和所述原始图像,得到视点图像这一步骤,包括以下步骤：对所述第一深度特征图的深度维度进行归一化处理,得到第二深度特征图；将所述第二深度特征图映射到所述原始图像上得到视点图像。</td>   <td>G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              彭晖;              张夏茵;                   肖辉       </td>   <td>中山大学中山眼科中心</td>   <td>一种识别慢性肾病图像的系统</td>   <td>广东省</td>   <td>CN113781381B</td>   <td>2023-09-26</td>   <td>本发明涉及一种识别慢性肾病图像的系统,包括：图像采集模块,采集患有慢性肾病患者和健康人群的眼底光学相干断层扫描血管图像；参数获取模块,根据采集的眼底光学相干断层扫描血管图像获得诊断参数；函数生成模块,利用所述诊断参数计算Fisher判别的分类函数系数,并根据所述分类函数系数分别生成慢性肾病和健康人群的Fisher判别函数；比较判定函数模块,将待识别患者的诊断参数分别代入所述慢性肾病和健康人群的Fisher判别函数中,得到两个函数值,并比较两个函数值大小,若慢性肾病的Fisher判别函数的函数值大于健康人群的Fisher判别函数的函数值,则判定为患有慢性肾病的图像,否则判定为健康状态的图像。本发明识别准确率高,有助于患者减少检查项目和时间。</td>   <td>1.一种识别慢性肾病图像的系统,其特征在于,包括：图像采集模块,用于采集患有慢性肾病患者和健康人群的眼底光学相干断层扫描血管图像；参数获取模块,用于根据采集的眼底光学相干断层扫描血管图像获得诊断参数,所述诊断参数包括眼底结构参数和血流参数,所述眼底结构参数包括视乳头旁神经纤维层鼻侧厚度NpRNFL、黄斑神经节细胞层-内丛状层鼻侧上方厚度NS GC-IPL和垂直杯盘比verticalC/D；函数生成模块,用于利用所述诊断参数计算Fisher判别的分类函数系数,并根据所述分类函数系数分别生成慢性肾病和健康人群的Fisher判别函数；比较判定模块,用于将根据待识别患者的眼底光学相干断层扫描血管图像获得的诊断参数分别代入所述慢性肾病和健康人群的Fisher判别函数中,得到两个函数值,并比较两个函数值大小,若慢性肾病的Fisher判别函数的函数值大于健康人群的Fisher判别函数的函数值,则判定所述待识别患者的眼底光学相干断层扫描血管图像为患有慢性肾病的图像,否则判定为所述待识别的眼底相干断层扫描血管图像为健康状态的图像。</td>   <td>G06T7/00;A61B3/10;A61B3/12;A61B3/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;                   黎明思       </td>   <td>中山大学</td>   <td>一种海岸线侵蚀程度的监测方法、装置以及电子设备</td>   <td>广东省</td>   <td>CN115439748B</td>   <td>2023-09-26</td>   <td>本发明公开了一种海岸线侵蚀程度的监测方法、装置以及电子设备,方法包括：获取同一时间戳下目标监测区域的不同角度的多张图像,并将所述图像进行拼接,得到一张拼接图像；从所述拼接图像中提取海岸线的海岸平面面积变化量以及海岸垂向堆积变化量,作为所述拼接图像的特征参数；将所述特征参数输入至海岸线侵蚀程度的识别模型,得到所述拼接图像中的海岸线对应的侵蚀模态识别结果,所述识别模型为以标注有侵蚀模态的特征参数作为训练数据训练得到。本发明实施例基于海岸线的具体变化量,即海岸平面面积变化量以及海岸垂向堆积变化量,可以迅速确定海岸线当前的侵蚀程度,实现了高效率的监测海岸线的地貌变化。</td>   <td>1.一种海岸线侵蚀程度的监测方法,其特征在于,包括：获取同一时间戳下目标监测区域的不同角度的多张图像,并将所述图像进行拼接,得到一张拼接图像；从所述拼接图像中提取海岸线的海岸平面面积变化量以及海岸垂向堆积变化量,作为所述拼接图像的特征参数；将所述特征参数输入至海岸线侵蚀程度的识别模型,得到所述拼接图像中的海岸线对应的侵蚀模态识别结果,所述识别模型为以标注有侵蚀模态的特征参数作为训练数据训练得到；所述从所述拼接图像中提取海岸线的海岸平面面积变化量以及海岸垂向堆积变化量,包括：确定并补充所述拼接图像中丢失的像素值,得到补充像素值后的拼接图像；将补充像素值后的拼接图像进行灰度处理,得到灰度化的拼接图像；从灰度化的拼接图像中提取海岸线的海岸平面面积变化量以及海岸垂向堆积变化量。</td>   <td>G06V20/10;G06N3/04;G06N3/08;G06N20/00;G06V10/764;G06V10/77;G06V10/82;G06V20/52</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈颖;                   林仕阳       </td>   <td>中山大学</td>   <td>优化网络表示学习的方法、模型训练方法和系统</td>   <td>广东省</td>   <td>CN115496174B</td>   <td>2023-09-26</td>   <td>本发明提供的优化网络表示学习的方法、模型训练方法和系统,通过获取图网络中的待处理节点及其预测时间点；从图网络中获取以待处理节点为中心节点的子图网络；去除子图网络中时间戳晚于预测时间点的邻域节点,得到有效的子图网络；基于图卷积神经网络,使用注意力机制分别计算子图网络中待处理节点与各个邻域节点之间的相关性；对各个相关性进行归一化,得到对应的注意力权重系数；采用注意力权重系数对待处理节点的所有邻域节点进行加权,得到待处理节点的邻域聚合表示向量。可见,本发明可解析预测时间点附近的最新节点交互,更好地捕捉由于时间错位而产生的动态异构网络变化,从而提高了网络表示学习的准确性。</td>   <td>1.一种基于图网络的推荐方法,其特征在于,包括：获取图网络中的待处理节点以及所述待处理节点的预测时间点；所述图网络包括：多个节点以及节点之间交互的时间戳；用户购买的商品为待处理节点,购买的时间为待处理节点的预测时间点；从所述图网络中获取以所述待处理节点为中心节点的子图网络；所述子图网络包括：所述待处理节点,所述待处理节点的邻域节点以及节点之间交互的时间戳；将所述子图网络和预测时间点输入知识表示学习模型,得到知识表示学习模型输出的所述待处理节点的邻域聚合表示向量以及所述待处理节点的邻域节点的邻域聚合表示向量；基于所述待处理节点的邻域聚合表示向量以及所述待处理节点的邻域节点的邻域聚合表示向量进行概率计算并排序,根据排序结果推荐相应的邻域节点；其中所述知识表示学习模型通过以下方式被训练：获取训练集,所述训练集包括多个子图网络；所述子图网络包括：所述待处理节点,待处理节点的预测时间点,所述待处理节点的邻域节点以及节点之间交互的时间戳；去除所述子图网络中时间戳晚于预测时间点的邻域节点,得到有效的子图网络；基于图卷积神经网络,使用注意力机制分别计算所述子图网络中待处理节点与各个邻域节点之间的相关性；对各个相关性进行归一化,得到对应的注意力权重系数；采用所述注意力权重系数对待处理节点的所有邻域节点进行加权,得到待处理节点的邻域聚合表示向量。</td>   <td>G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;              倪晓升;                   张易东       </td>   <td>中山大学</td>   <td>一种基于数字孪生的交通运输设备运行预测方法及装置</td>   <td>广东省</td>   <td>CN116108717B</td>   <td>2023-09-26</td>   <td>本发明涉及交通运输技术领域,公开了一种基于数字孪生的交通运输设备运行预测方法及装置。本发明基于目标交通运输设备的拓扑结构数据和基础环境数据构建数字孪生模型,向数字孪生模型导入目标交通运输设备在历史运行过程中产生的运行数据,对得到的目标数字孪生模型进行仿真计算,根据得到的仿真运行数据和所述运行数据对目标数字孪生模型进行训练以得到目标运行状态预测模型,将目标数字孪生模型的实时状态数据输入至目标运行状态预测模型进行预测计算,最终得到运行状态预测结果。本发明实现了对交通运输设备的运行状态的智能预测,为实现交通运输设备运行的可靠性和安全性提供客观有效的数据基础。</td>   <td>1.一种基于数字孪生的交通运输设备运行预测方法,其特征在于,包括：获取目标交通运输设备的拓扑结构数据和基础环境数据；所述基础环境数据包括路况数据、气候数据、人员数据和货物数据；根据所述拓扑结构数据构建相应的数字孪生设备模型,根据所述基础环境数据构建相应的数字孪生环境模型,将所述数字孪生设备模型和所述数字孪生环境模型相互关联得到数字孪生模型；获取所述目标交通运输设备在历史运行过程中产生的运行数据；向所述数字孪生模型导入所述运行数据,得到匹配所述目标交通运输设备的目标数字孪生模型；对所述目标数字孪生模型进行仿真计算,得到所述目标数字孪生模型运行过程中所产生的仿真运行数据；根据所述运行数据和所述仿真运行数据对所述目标数字孪生模型进行训练,得到目标运行状态预测模型；对所述目标数字孪生模型进行实时状态更新,获取相应的实时状态数据；将所述实时状态数据输入至所述目标运行状态预测模型进行预测计算,得到所述目标交通运输设备的运行状态预测结果；所述运行状态预测结果包括故障诊断结果,所述目标数字孪生模型在训练过程中生成若干功能链组并记录各个零部件所属的功能链组,所述功能链组由若干实现具体功能的零部件组成；所述将所述实时状态数据输入至所述目标运行状态预测模型进行预测计算,包括：根据功能链组的输出响应判断故障；结合功能链组的零部件交叉进行故障定位。</td>   <td>G06F30/23;G06F30/28;G06Q10/04;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张贺晔;              郑晓鹏;              薛晓飞;              王安邦;              高智凡;                   刘修建       </td>   <td>中山大学</td>   <td>一种CT血管肺动脉血流储备分数的预测方法及装置</td>   <td>广东省</td>   <td>CN116805535A</td>   <td>2023-09-26</td>   <td>本申请提供了一种CT血管肺动脉血流储备分数的预测方法及装置,获取样本训练数据包；其中,样本训练数据包包括血管图像数据集和患者肺动脉样本数据集,以及与样本训练数据包相对应的血流储备分数；依据样本训练数据包提取患者肺动脉的几何特征信息；通过所述几何特征信息构建网络模型框架,并依据所述网络模型框架建立所述几何特征信息与所述血流储备分数之间对应关系；获取目标肺部CT血管造影图像,并通过所述对应关系,确定所述目标肺部CT血管造影图像对应的血流储备预测分数。通过使用深度学习的无监督PINN框架,以及获取肺动脉树的几何特征数据训练神经网络,实现了基于肺部CT血管造影图像的整个肺动脉树的虚拟FFR预测。</td>   <td>1.一种CT血管肺动脉血流储备分数的预测方法,其特征在于,包括步骤：获取样本训练数据包；其中,所述样本训练数据包包括血管图像数据集和患者肺动脉样本数据集,以及与所述样本训练数据包相对应的血流储备分数；依据所述样本训练数据包提取患者肺动脉的几何特征信息；通过所述几何特征信息构建网络模型框架,并依据所述网络模型框架建立所述几何特征信息与所述血流储备分数之间对应关系；获取目标肺部CT血管造影图像,并通过所述对应关系,确定所述目标肺部CT血管造影图像对应的血流储备预测分数。</td>   <td>G16H50/70;A61B6/03;A61B6/00;G16H30/40;G06V10/40;G06V10/774;G06V10/82;G06N3/0464;G06N3/088;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              严志伟;              陈蔓薇;                   李烨       </td>   <td>中山大学</td>   <td>一种基于异构复合主干的目标检测方法及系统</td>   <td>广东省</td>   <td>CN112699914B</td>   <td>2023-09-22</td>   <td>本发明公开了一种基于异构复合主干的目标检测方法及系统,该方法包括：获取训练数据并对训练数据进行预处理,得到预处理数据；基于异构复合主干架构构建目标检测网络；基于预处理数据和预设的训练策略对目标检测网络进行训练,得到训练后的目标检测网络；获取待测数据并输入到训练后的目标检测网络,输出检测结果。该系统包括：预处理模块、网络构建模块、训练模块和检测模块。通过使用本发明,整合两个异构主干网络学习到的互补特征,避免特征冗余,从而增强检测器总体的特征表达与目标检测性能。本发明作为一种基于异构复合主干的目标检测方法及系统,可广泛应用于目标检测网络领域。</td>   <td>1.一种基于异构复合主干的目标检测方法,其特征在于,包括以下步骤：获取训练数据并对训练数据进行预处理,得到预处理数据；基于异构复合主干架构构建目标检测网络；基于预处理数据和预设的训练策略对目标检测网络进行训练,得到训练后的目标检测网络；获取待测数据并输入到训练后的目标检测网络,输出检测结果；所述目标检测网络包括细节提取主干、深度主干和复合模块,所述细节提取主干和深度主干通过复合模块实现主干网络复合；所述复合模块包括1×1卷积层和加法单元；所述基于预处理数据和预设的训练策略对目标检测网络进行训练,得到训练后的目标检测网络这一步骤,其具体包括：将数据按照一定比例分为训练集,验证集,测试集；以训练集作为目标检测网络训练过程中的输入,通过卷积运算,计算出网络输出,得到预测框集合；根据分类子任务和定位子任务,所述预测框集合中每个预测框包含类别向量和位置向量；对于分类子任务,使用预测框类别向量与标注框类别向量之间的交叉熵作为损失函数；对于定位子任务,通过Smooth L1损失函数来计算预测框与标注框的位置损失；根据计算出的损失按照随机梯度下降方法逐层计算卷积层中参数的梯度,更新网络中各层的参数；训练过程中,每间隔固定迭代次数以验证集作为输入对网络的泛化性进行评估；训练完成后,以测试集作为网络的输入对网络的性能进行评估,同时保存网络中的卷积核和偏置参数,得到训练后的目标检测网络。</td>   <td>G06V10/764;G06V10/774;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;                   谭骏朗       </td>   <td>中山大学</td>   <td>一种基于FPGA的色调映射系统</td>   <td>广东省</td>   <td>CN110009577B</td>   <td>2023-09-22</td>   <td>本发明涉及图像处理领域,更具体的,涉及一种基于FPGA的实时色调映射算法系统,本发明针对输入视频特定的分辨率,结合其权重值固定不变的特点,将原来需要进行大量计算的权重值使用了预先计算的方法来减低整个算法的计算量,在需要使用权重值时直接在存储器中读取即可,提高整个系统的吞吐率,满足实时映射需求。同时,本发明整个硬件系统的结构采用全局流水,局部并行的方式进行数据映射,整个系统各个模块间都以流水形式进行数据处理,在模块中以并行方式进行处理,极大地提高了整个系统的吞吐率,满足实时映射的需求。</td>   <td>1.一种基于FPGA的色调映射系统,其特征在于,包括有分块映射模块、图像融合模块以及细节增强模块,所述的分块映射模块和图像融合模块相连接,所述的图像融合模块与细节增强模块相连接；在分块映射模块中,通过使用前一帧图像中计算出来的统计信息,实现N块映射图片并行映射；在图像融合模块中,通过提前计算出融合图片的权重值并储存到RAM上,避免权重值的大量计算,当图像融合模块接收到分块映射模块传入的数据后,图像融合模块分别读取对应图像的权值并进行卷积融合操作；细节增强模块负责对融合后图像进行细节增强,得到最终输出映射后的图像；所述的分块映射模块包括有统计单元以及映射单元；所述的统计单元包括累加单元以及比较单元,所述的映射单元包括有控制单元、对数计算单元以及乘法器；所述的控制单元与对数计算单元相连接,所述的对数计算单元与乘法器相连接；当分辨率为m*n的视频流输入到系统时,首先进入分块映射模块,统计单元中的比较单元识别视频流当前帧中N块区域的最大亮度值L-(wmax)并将最大亮度值L-(wmax)更新到对应寄存器值中,同时累加单元会将视频流当前帧中N块区域的亮度值进行累加、计算,得到各区域的平均亮度值L-(wa)并更新到对应寄存器值中,在映射单元组中,控制单元通过寄存器组提取上一帧视频的统计值L-(wmax)和L-(wa)提供给对数计算单元使用,最后将对数计算单元的输出值输入到乘法器进行计算,得到分块映射后的视频流数据,最终实现的计算公式如下所示：                                    上述公式中,j表示分块的行号,k表示分块的列号,L-(jk)(x,y)表示分块映射后第jk块区域坐标为(x,y)的像素点亮度值,表示jk块区域的最大亮度值,/&gt;表示jk块区域的平均亮度值,L-w(x,y)表示输入坐标为(x,y)的像素点亮度值；所述的图像融合模块包括有存储器、第二控制单元以及卷积融合单元,所述的存储器与第二控制单元相连接,第二控制单元与卷积融合单元相连接；经过映射后的并行视频流数据输入到图像融合模块,在图像融合模块中存储器的权重值首先需要通过以下公式先进行计算,计算完成后存储到存储器上待图像融合时使用；                                    上述公式中,G-(jk)(x,y)表示第jk块局部块上坐标为(x,y)的像素点在高度为1的高斯曲面上的函数值,j表示分块的行号,k表示分块的列号,d为融合函数系数；(x-(jk),y-(jk))表示第jk块局部块的中心位置坐标,n-r、n-c分别表示第jk块局部块包含的像素点的行数和列数,I-(jk)(x,y)表示第jk块局部块上坐标为(x,y)的像素点的亮度值,W-(jk)(x,y)表示第jk块局部块上坐标为(x,y)的像素点的权重值；图像融合模块中的第二控制单元会从存储器中取出对应的权重值供卷积融合模块计算使用,并将对应分块中的亮度值与权重值进行相乘并相加,最终得到经过融合后的视频流数据,其计算公式如下所示：                  上述公式中,F(x,y)表示融合后的亮度值,j表示分块的行号,k表示分块的列号,n-r、n-c分别表示第jk块局部块包含的像素点的行数和列数,W-(jk)(x,y)表示第jk块局部块上坐标为(x,y)的像素点的权重值。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              严志伟;              黄梓轩;              李烨;                   陈绿然       </td>   <td>中山大学</td>   <td>一种基于检测主干与局部特征优化的目标检测方法及系统</td>   <td>广东省</td>   <td>CN112396126B</td>   <td>2023-09-22</td>   <td>本发明公开了一种基于检测主干与局部特征优化的目标检测方法及系统,该方法包括：获取训练数据并对训练数据进行预处理,得到预处理数据；基于长颈主干架构和局部特征优化模块构建目标检测网络；基于预处理数据和预设的训练策略对目标检测网络进行训练,得到训练后的目标检测网络；获取待测数据并输入到训练后的目标检测网络,输出检测结果。该系统包括：预处理模块、网络构建模块、训练模块和检测模块。通过使用本发明,保证检测器在计算力友好的前提下获得满意的性能。本发明作为一种基于检测主干与局部特征优化的目标检测方法及系统,可广泛应用于目标检测网络领域。</td>   <td>1.一种基于检测主干与局部特征优化的目标检测方法,其特征在于,包括以下步骤：获取训练数据并对训练数据进行预处理,得到预处理数据；基于长颈主干架构和局部特征优化模块构建目标检测网络；基于预处理数据和预设的训练策略对目标检测网络进行训练,得到训练后的目标检测网络；获取待测数据并输入到训练后的目标检测网络,输出检测结果；所述目标检测网络包括长颈残差主干网络和局部特征优化模块,所述长颈残差主干网络包括六个特征提取卷积模块,所述局部特征优化模块包括局部融合模块和尺度监督模块；所述局部融合模块包括细节重引分支、局部上下文分支和原始输入映射分支,所述细节重引分支将输入特征图按顺序通过1×1卷积层、最大池化层、3×3卷积层和批归一化层,所述局部上下分支将输入特征图按顺序通过1×1卷积层、反卷积层、3×3卷积层与批归一化层,所述原始输入映射分支将输入特征图按顺序通过1×1卷积层、3×3卷积层和批归一化层；所述获取待测数据并输入到训练后的目标检测网络,输出检测结果这一步骤,其具体包括：获取待测数据得到需检测目标的图像；将需检测目标的图像输入到训练后的目标检测网络,经过卷积层输出一个表示预测框位置的4维向量序列以及一个表达类别预测的N维向量序列；检测器通过人工预定的类别置信度阈值并根据类别预测的N维向量序列丢弃一部分低质量结果,得到剩余的检测结果；将剩余的检测结果通过预测框置信度以及基于位置4维向量计算出预测框之间的重叠率,并基于非极大值抑制算法对预测框进行去重,得到检测器的最终检测结果并输出。</td>   <td>G06V10/774;G06V10/80;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李中华;                   林柏顶       </td>   <td>中山大学</td>   <td>基于RFID和极限学习机的冷链产品质量预测及智能配送方法</td>   <td>广东省</td>   <td>CN110110909B</td>   <td>2023-09-22</td>   <td>本发明涉及物联网技术领域,提出一种基于RFID和极限学习机的冷链产品质量预测及智能配送方法,包括以下步骤：在冷链产品进行配送路线规划前,采用RFID传感器标签采集冷链产品的环境数据并作为极限学习机的输入,通过极限学习机训练与预测产品的质量指数；以配送总成本最小为目标根据质量指数通过路径规划算法对配送路线进行规划,输出原始配送方案并进行配送；在配送过程中定时通过RFID识别传感器标签对冷链产品的环境数据进行采集,通过极限学习机预测当前质量指数,并判断：若当前质量指数大于或等于报警阈值,则按原始配送方案继续配送；若当前质量指数小于报警阈值,则发出报警信息并采取动态调度策略对配送方案进行优化规划。</td>   <td>1.一种基于RFID和极限学习机的冷链产品质量预测及智能配送方法,其特征在于,包括以下步骤：S1：在冷链产品进行配送路线规划前,采用射频识别传感器标签采集冷链产品的环境数据；S2：将采集的环境数据作为极限学习机的输入,通过极限学习机训练与预测产品的质量指数C；S3：以配送总成本最小为目标根据质量指数C通过路径规划算法对配送路线进行规划,输出原始配送方案,然后根据输出的原始配送方案对冷链产品进行配送；所述路径规划算法为禁忌搜索算法；其中,采用禁忌搜索算法对配送路线进行规划,具体包括以下步骤：S3.1：设置R＝1,初始化配送方案,设置一条从仓储中心出发的配送路径；S3.2：计算各个未安排交付点当其作为一个配送节点的成本,选择成本最低的未安排交付点作为配送节点并更新配送路径的总成本；若没有未安排交付点,则执行S3.5步骤；S3.3：计算各个未安排交付点插入当前配送路线的成本,选择成本最低的交付点插入当前配送路径,并判断该交付点在配送时间和配送车辆的储货量的约束条件下插入当前配送路径是否可行：若可行,则更新配送路径的总成本,然后重复本步骤；若不可行,则执行S3.4步骤；S3.4：设置R＝R+1,重新设置一条从仓储中心出发的配送路径,然后跳转执行S3.2步骤；S3.5：将当前设置的配送路径作为全局最佳配送方案,即S-b＝S；S3.6：初始化禁忌列表和候选列表,并将全局最佳配送方案添加到禁忌列表中；S3.7：根据禁忌列表探索全局最佳配送方案的邻域并更新候选列表；S3.8：从候选列表中选出最佳配送方案并设定为S-0,当S-0的配送成本小于S的配送总成本时,设置S-b＝S-0,并更新禁忌列表,然后执行S3.9步骤；当S-0的配送成本大于或等于S的配送总成本时,使用随机跳跃产生的随机配送方案更新候选列表,然后重复执行本步骤；S3.9：判断当前迭代次数是否小于预设的最大迭代次数,若是,则执行S3.7步骤；若否,则结束搜索并将最佳配送方案作为原始配送方案输出；S4：在配送过程中定时通过射频识别传感器标签对冷链产品的环境数据进行采集,通过极限学习机预测冷链产品当前的质量指数C′,然后判断当前的质量指数C′与预设的报警阈值的大小关系：若当前的质量指数C′大于或等于预设的报警阈值,则按照原始配送方案继续进行配送；若当前的质量指数C′小于预设的报警阈值,则发出警报信息,采取动态调度策略对配送方案进行优化规划。</td>   <td>G06Q10/0639;G06Q10/047;G06Q10/0832;G06Q10/0835;G06K7/10;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         倪芃芃;              李剑锋;              林存刚;              覃小纲;              陈清树;              叶明鸽;              刘凯文;              高军;                   巫志文       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种管道运行状态评估方法、系统、计算机设备及介质</td>   <td>广东省</td>   <td>CN116796524A</td>   <td>2023-09-22</td>   <td>本发明提供了一种管道运行状态评估方法、系统、计算机设备及介质,所述方法包括：对待评估管道进行预设数目的等长切分,得到多个待评估管段和对应的管道节点；对各个待评估管段进行位移荷载下的受力分析,建立管段挠度控制方程,并通过求解得到各个管道节点对应的节点挠度和节点弯曲应变；根据各个待评估管段对应的两个管道节点的节点挠度得到的变形管段长度,计算得到对应的节点轴向应变；根据节点轴向应变和节点弯曲应变,得到节点管顶应变和节点管底应变；根据节点管顶应变和节点管底应变,得到待评估管道的状态评估结果。本发明通过简单、高效且通用的计算分析得到管道各截面的轴向应变,进而为管道安全状态的快速精准评估提供可靠保障。</td>   <td>1.一种管道运行状态评估方法,其特征在于,所述方法包括以下步骤：对待评估管道进行预设数目的等长切分,得到多个待评估管段和对应的管道节点；对各个待评估管段进行位移荷载下的受力分析,建立对应的管段挠度控制方程；求解所述管段挠度控制方程,得到各个管道节点对应的节点挠度和节点弯曲应变；根据各个待评估管段对应的两个管道节点的节点挠度,得到对应的变形管段长度,并根据各个待评估管段的变形管段长度,得到对应的节点轴向应变；根据所述节点轴向应变和所述节点弯曲应变,得到对应的节点管顶应变和节点管底应变,并根据所述节点管顶应变和所述节点管底应变,得到待评估管道的状态评估结果。</td>   <td>G06F30/20;G06F30/23;G06F17/11;G06F17/16;G01N3/08;G06F111/10;G06F113/14;G06F119/02;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭超;              靳思博;              马成;              谭爽;                   张淏酥       </td>   <td>中山大学</td>   <td>水下航行器密封罐模型的生成方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN116796529A</td>   <td>2023-09-22</td>   <td>本发明公开了一种水下航行器密封罐模型的生成方法、装置、设备及介质,该方法包括：获取水下航行器密封罐模型的壳体材料所对应的屈服强度、弹性模数、泊松比及最大承受压力,确定水下航行器密封罐模型初始厚度、壳体厚度的取值范围、初始环肋间距及环肋间距的取值范围,构建水下航行器密封罐模型；对水下航行器密封罐模型进行校核,调整水下航行器密封罐模型的环肋间距和壳体厚度；在完成所有校核后,对水下航行器密封罐模型进行重新建模,并计算对应的模型重量,若重量不超标,则生成最终的水下航行器密封罐模型；若重量超标,则在满足各校核的前提下,重新调整水下航行器密封罐模型的待调参数直至重量不超标,生成最终的水下航行器密封罐模型。</td>   <td>1.一种水下航行器密封罐模型的生成方法,其特征在于,包括：获取水下航行器密封罐模型的壳体材料所对应的屈服强度、弹性模数、泊松比以及最大承受压力；根据所述最大承受压力确定壳体的初始可承受压力；根据壳体的初始可承受压力、预设壳体外径及所述屈服强度确定所述壳体的初始厚度及壳体厚度的取值范围；根据所述弹性模数、壳体的初始可承受压力、预设壳体外径及初始厚度确定水下航行器密封罐模型的初始环肋间距及环肋间距的取值范围；根据所获取的壳体材料、所述初始厚度、初始环肋间距、水下航行器密封罐模型中环肋伸展板的预设初始长度及环肋伸展板的预设初始宽度构建水下航行器密封罐模型；对所述水下航行器密封罐模型中环肋所在壳板的局部稳定性进行校核,在所述环肋间距的取值范围内,调整所述水下航行器密封罐模型的环肋间距；对所述初始的水下航行器密封罐模型中壳体的总体稳定性以及总体强度进行校核,在所述壳体厚度的取值范围内,调整水下航行器密封罐模型的壳体厚度；在完成所有校核后,对所述水下航行器密封罐模型进行重新建模,并在建模后对计算对应的模型重量,若重量不超标,则生成最终的水下航行器密封罐模型；若重量超标,则在满足各校核的前提下,重新调整水下航行器密封罐模型的待调参数直至重量不超标,生成最终的水下航行器密封罐模型；其中,所述待调参数包括以下任意一项或其组合：壳体材料、壳体厚度、环肋伸展板的长度及环肋伸展板的宽度。</td>   <td>G06F30/20;G06F30/10;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈泽涛;              王瑞轩;              施梦汝;              龚卓弘;              蔡耿彬;              曾家洋;                   林嘉鸿       </td>   <td>中山大学附属口腔医院</td>   <td>一种基于人工智能的口腔CBCT影像截面生成方法</td>   <td>广东省</td>   <td>CN116797731A</td>   <td>2023-09-22</td>   <td>本发明公开了一种基于人工智能的口腔CBCT影像截面生成方法,包括S1、根据标准化拍摄口腔CBCT三维影像资料获取第一CBCT三维影像文件；S2、对第一CBCT三维影像进行切片预处理后重建为第二CBCT三维影像文件；S3、构建第一神经网络模型提取第二CBCT三维影像文件中的标志解剖结构,以及获取标准化口腔CBCT水平截面；S4、构建第二神经网络模型,并根据准化口腔CBCT水平截面对牙齿进行分割；S5、根据牙齿的分割结果获取牙弓曲线；S6、根据牙弓曲线获取标准化牙齿冠状截面或矢状截面；通过上述结构能够实现高效、自动、批量生成口腔CBCT影像截面,有效减轻口腔医生在选取CBCT截面过程中耗费的时间及精力,提高口腔疾病的诊断、筛查、术前影像分析的效率。</td>   <td>1.一种基于人工智能的口腔CBCT影像截面生成方法,其特征在于,包括：S1、根据标准化拍摄口腔CBCT三维影像资料获取第一CBCT三维影像文件；S2、对第一CBCT三维影像进行切片预处理后重建为第二CBCT三维影像文件；S3、构建第一人工智能网络模型提取第二CBCT三维影像文件中的标志解剖结构,进而获取标准化口腔CBCT水平截面；S4、构建第二人工智能网络模型,并基于标准化口腔CBCT水平截面实现解剖结构分割；S5、根据口腔解剖结构分割结果自动获取个性化牙弓曲线；S6、根据个性化牙弓曲线获取牙齿冠状截面或矢状截面。</td>   <td>G06T17/00;G06T19/20;G06T5/00;G16H30/40;G16H30/20;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋鸿展;              谢晓华;                   彭勃       </td>   <td>中山大学</td>   <td>实时三维物体动态重建方法</td>   <td>广东省</td>   <td>CN116797733A</td>   <td>2023-09-22</td>   <td>本发明公开了实时三维物体动态重建方法,属于物体动态重建方法技术领域,包括准备三维物体数据集和特征点回归模型训练,深度学习网络模型获取单张图片,基于单张图片信息深度学习网络模型输出三维物体网格以及在二维图像平面上投影的地标,采用PnP算法获取三维物体网络和二维图像平面上投影的地标信息输出六自由度姿态参数得到三维物体重建模型。</td>   <td>1.实时三维物体动态重建方法,包括准备三维物体数据集和特征点回归模型训练,其特征在于：还包括如下步骤：深度学习网络模型获取单张图片；基于单张图片信息深度学习网络模型输出三维物体网格以及在二维图像平面上投影的地标；采用PnP算法获取三维物体网络和二维图像平面上投影的地标信息输出六自由度姿态参数得到三维物体重建模型。</td>   <td>G06T17/00;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张博弘;                   段仕强       </td>   <td>中山大学附属第七医院(深圳)</td>   <td>一种麻醉安全控制系统</td>   <td>广东省</td>   <td>CN116798037A</td>   <td>2023-09-22</td>   <td>本发明涉及医疗器械领域,具体公开了一种麻醉安全控制系统,包括智能控制终端、药物识别模块和标签打印模块,所述智能控制终端、药物识别模块和标签打印模块之间互联；所述药物识别模块用于识别目标药物,并对识别内容进行语音播报,将标签打印命令传递给所述标签打印模块；所述标签打印模块用于将所述药物识别模块传输的信息打印标签；所述智能控制终端用于控制所述药物识别模块以及所述标签打印模块。本发明包含多个相互联网的模块：智能控制终端、药物识别模块、标签打印模块,能够有效解决临床麻醉工作中药物使用的各个环节中的安全性与便捷性问题。</td>   <td>1.一种麻醉安全控制系统,其特征在于,包括智能控制终端、药物识别模块和标签打印模块,所述智能控制终端、药物识别模块和标签打印模块之间互联；所述药物识别模块用于识别目标药物,并对识别内容进行语音播报,将标签打印命令传递给所述标签打印模块；所述标签打印模块用于将所述药物识别模块传输的信息打印标签；所述智能控制终端用于控制所述药物识别模块以及所述标签打印模块。</td>   <td>G06V30/10;G06T7/60;G06T7/62;G06V10/14;G06V10/74;G06F3/12;A61M5/20;A61M5/31;A61M19/00;G08B21/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张吴明;              张展鹏;                   张书航       </td>   <td>中山大学</td>   <td>文档图像二值化方法、系统、计算机设备及可读存储介质</td>   <td>广东省</td>   <td>CN116798043A</td>   <td>2023-09-22</td>   <td>本发明公开了一种文档图像二值化方法、系统、计算机设备及可读存储介质,方法包括：获取输入图像和反色图像；基于地面滤波器,根据将灰度值视为高程值的方式,对所述输入图像和所述反色图像进行二值化处理,得到第一二值影像和第二二值影像,其中,第一二值影像作为正底面,第二二值影像作为反底面；根据所述正底面和灰度值反转后的所述反底面,得到暗场文字掩膜；基于所述输入图像的背景亮度估计值,扣除所述输入图像的背景光,得到去背景光图像；利用所述暗场文字掩膜增强所述去背景光图像的文字信息,获得文档图像二值化结果。本发明可以提供比传统局部阈值分割方法更好的文本二值化结果,提高OCR工具在恶劣光照条件下对文档图像的识别准确率。</td>   <td>1.一种文档图像二值化方法,其特征在于,所述方法包括：获取输入图像和所述输入图像对应的反色图像,其中,所述输入图像包含文字信息；基于地面滤波器,根据将灰度值视为高程值的方式,对所述输入图像和所述反色图像进行二值化处理,得到所述输入图像对应的第一二值影像和所述反色图像对应的第二二值影像,其中,所述第一二值影像作为正底面,所述第二二值影像作为反底面；所述正底面中,黑色区域覆盖所述输入图像中的第一亮度预设值区域的文字、第二亮度预设值区域的文字和远离文字预设值的背景区域,其中,第一亮度预设值小于第二亮度预设值；所述反底面中,黑色区域覆盖所述反色图像中的背景区域；根据所述正底面和灰度值反转后的所述反底面,得到暗场文字掩膜；基于所述输入图像的背景亮度估计值,扣除所述输入图像的背景光,得到去背景光图像；利用所述暗场文字掩膜增强所述去背景光图像的文字信息,进而获得文档图像二值化结果。</td>   <td>G06V30/162;G06T5/00;G06T5/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              陈崴;              吴倩妮;              赵兰琴;              李剑波;              刘冬;                   温静怡       </td>   <td>中山大学中山眼科中心;中山大学附属第一医院</td>   <td>一种慢性肾病全流程诊断预测系统</td>   <td>广东省</td>   <td>CN116798607A</td>   <td>2023-09-22</td>   <td>本发明提供了一种慢性肾病全流程诊断预测系统,包括：第一检查数据获取模块,用于获取待检测者的第一检查数据；其中,所述第一检查数据包括：眼部检查数据；肾病筛查模块,用于将所述第一检查数据输入到预设的慢性肾病筛查模型中,以使所述慢性肾病筛查模型预测出所述待检测者是否患有慢性肾病(CKD)。本发明可基于眼部检查数据识别出CKD患者,并进一步辅助医生精准预测CKD的病理诊断及预后。本发明与现有技术相比提供了一种无创、便捷的CKD筛诊技术,并解决了不具备肾脏活检技术的医疗卫生服务机构无法客观、准确判断CKD病因和预后的技术问题。</td>   <td>1.一种慢性肾病全流程诊断预测系统,其特征在于,包括：第一检查数据获取模块,用于获取上传的第一检查数据,并对第一检查数据进行预处理；其中,所述第一检查数据包括：眼部检查数据；慢性肾病筛查模块,用于将预处理完的第一检查数据输入到预设的慢性肾病筛查模型中,以使所述慢性肾病筛查模型预测所述待检测者患有慢性肾病的概率结果；其中,所述慢性肾病筛查模型的训练,包括：获取若干未患慢性肾病的检测者的第一检查数据,以及若干患有慢性肾病的检测者的第一检查数据,并对第一检查数据进行预处理,得到若干第一训练样本；根据第一训练样本对慢性肾病筛查模型进行迭代训练,直至模型收敛；其中,在每次训练时,将第一训练样本输入到慢性肾病筛查模型中,以使所述慢性肾病筛查模型输出第一训练样本所对应的检测者是否患有慢性肾病的预测概率结果；将预测概率结果与第一训练样本所对应的检测者是否患有慢性肾病的实际概率结果进行比对,根据比对结果对模型的网络参数进行调整；其中,慢性肾病筛查模型采用以卷积神经网络为架构的深度学习算法进行训练,所述深度学习算法包括：EfficientNet-B5模型、EfficientNet-B6模型、EfficientNetB7模型、ResNet-101模型、VGG-16模型或MobileNet-V2模型。</td>   <td>G16H50/20;G16H50/70;G06N3/0464;G06F18/214</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱斌;              王妍;              陈芳;              张红雨;              周之昊;              曹媛;              庞佩珊;                   徐巧芬       </td>   <td>佛山市第一人民医院(中山大学附属佛山医院)</td>   <td>基于角色的麻精类药品处方访问控制方法及装置</td>   <td>广东省</td>   <td>CN110378130B</td>   <td>2023-09-19</td>   <td>本发明公开了基于角色的麻精类药品处方访问控制方法及装置,当任务到来,授权步初始化以后,一个来自受信者集中的成员将被授予授权步,这个受托人被称为授权步的执行者,执行者执行任务时所需的权限称为执行者权限。授权步根据当前访问控制策略使其中部分权限生效,执行者权限集和激活权限集一起称为授权步的保护态,在满足应有权限的情况下,同时系统条件满足授权步时才能开始进行任务中的计算,可以对未取得麻、精一处方开具资格的医师进行拦截,确保开具麻醉药品和第一类精神药品的医师符合资质要求,有效解决了麻、精一药品单次处方时间超限的问题。</td>   <td>1.基于角色的麻精类药品处方访问控制方法,其特征在于,所述方法包括以下步骤：步骤1,初始化访问控制系统；步骤2,定义并设置授权步；步骤3,通过授权步计算授权比值；步骤4,通过授权步与授权比值构建访问控制模型；步骤5,根据访问控制模型判断是否能访问麻精类药品处方的电子数据文件；在步骤1中,初始化访问控制系统的方法为：控制系统为需要访问控制安全的电子系统,定义控制系统中的主体S、客体O、权限P、角色R、用户角色指派URA,主体集合由控制系统用户通过唯一标识名映射到节点的本地用户或用户代理组成,客体集合包括控制系统节点中的文件、程序、磁盘、打印机和传感器,对客体的操作通过WSDL 描述控制系统服务时定义,访问控制模型的角色不与权限直接关联,而是和节点任务关联,以下定义访问控制模型的基本元素；令T为任务集合,在控制系统中通过任务句柄标识,由任务管理模块定义,TI为时间限制,即在TI时间段,TRA T×R×TI,表示任务角色指派,是任务到角色的多对多关系,PTA P×T,表示任务权限指派,是任务到权限的多对多关系,PS为保护态,由完成任务所需的权限组成；在步骤2中,定义并设置授权步的方法为：令AT为授权条件集合,是关于任务状态的断言,由&lt;变量名&gt;&lt;逻辑操作符&gt;&lt;变量值&gt;组成,用来描述激活授权步需要的基本条件；令AC为授权步激活约束条件的规则表达式,AC=AL1∪AL2∪…∪ALm,其中,AL=AT1∩AT2∩…∩ATn,则授权步为AS T×PS×AC,当任务到达且满足AC定义的激活条件时,激活T所属角色R对应的相关任务权限；在步骤3中,通过授权步计算授权比值的方法为：计算最近N天内各药物在药品处方中出现次数降序排列,N单位为小时,取值范围为1到30天,将药物出现次数排序第i的药物元素进行排序,其出现次数满足授权比值： ,其中/&gt;为所有药品的元素出现次数之和,参数/&gt;的表达式为/&gt;,将满足授权比值/&gt;的数据按降序排列,j=1,2,...,N；在步骤4中,通过授权步与授权比值构建访问控制模型的方法为：令访问控制模型={S,O, P, R, T, AC, AS, TI} AND &lt;Tre,Tre为授权度门限,是0.2到1之间的小数,默认值0.7,授权函数G(AS)表示授权步生效后,角色获得激活权限；访问控制模型是用户与服务器之间和权限管理员的交互,通过资源的情况来限制任务是否运行,判断资源的情况是由用户来进行的。</td>   <td>G06F21/60;G06F21/62;G16H20/10;G16H40/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄晓;              万林鸿;                   倪江群       </td>   <td>中山大学</td>   <td>一种生成式鲁棒图像隐写方法</td>   <td>广东省</td>   <td>CN111598762B</td>   <td>2023-09-19</td>   <td>本发明提供一种生成式鲁棒图像隐写方法,包括：构建图像数据集,并对图像数据集进行预处理；构建并初始化深度学习网络架构；采用联合-精调式方法训练深度学习网络架构,得到网络架构模型；利用网络架构模型生成载密伪图并进行秘密通信,完成图像隐写过程。本发明提供的图像隐写方法,通过利用生成对抗网络StyleGAN,将秘密信息的嵌入过程融入到图像的生成过程中,构建一种能承担较大容量秘密信息并具备一定鲁棒性的生成式图像隐写架构,从而得到的生成式图像隐写方法具有嵌入的容量较大、生成的图像质量好、载密图像统计不可检测性强、实用性高等优点,并克服了现有的生成式图像隐写生成的载密图像质量差、嵌入容量低下、信息提取准确率不高等问题。</td>   <td>1.一种生成式鲁棒图像隐写方法,其特征在于,包括以下步骤：S1：构建图像数据集,并对图像数据集进行预处理；S2：构建并初始化深度学习网络架构；S3：采用联合-精调式方法训练深度学习网络架构,得到网络架构模型；S4：利用网络架构模型生成载密伪图并进行秘密通信,完成生成式鲁棒图像隐写过程；所述步骤S2具体为：基于StyleGAN网络构建深度学习网络架构,包括调制模块、编码模块、生成器、判别器、提取器和加噪模块；其中：调制模块将秘密信息调制到随机生成的噪声图中,生成载密噪声图；编码模块对载密噪声图进行非线性变化以适应鲁棒图像隐写任务,使秘密信息分布到鲁棒的图像特征中；生成器以随机隐向量和从编码模块得到的含有秘密信息的噪声图作为输入,生成载密伪图；判别器以载密伪图或真实图像作为输入,生成判别分数,作为生成器对抗训练的对象；提取器以载密伪图作为输入,从载密伪图中提取出秘密信息进行输出；加噪模块设置在生成器和提取器中间,对传输过程中的载密伪图进行信道攻击,以训练提升载密伪图的鲁棒性。</td>   <td>G06T1/00;G06N3/0464;G06N3/0475;G06N3/048;G06N3/084;G06N3/088;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈德霖;              张冬傲;                   郑培嘉       </td>   <td>中山大学</td>   <td>一种基于数据打包技术的加密域图像分割优化方法</td>   <td>广东省</td>   <td>CN112288757B</td>   <td>2023-09-19</td>   <td>本发明提出一种基于数据打包技术的加密域图像分割优化方法,涉及加密域图像分割优化的技术领域,解决了当前图像分割方法在分割过程中存在空间资源占用大,计算复杂度高的问题,首先隐私服务提供商生成公钥和私钥发送至客户端,并将私钥发送给图像分割执行服务器,客户端对图像进行加密并进行数据打包,基于数据打包技术实现了计算复杂度及空间资源占用度的降低,提高图像分割的速度,图像分割执行服务器与隐私服务提供商之间通过多方安全计算进行交互,获取加密分割图像,图像分割执行服务器将加密分割图像发送给客户端解密,加密的图像仅能由图像拥有者进行解密,保障了安全隐私。</td>   <td>1.一种基于数据打包技术的加密域图像分割优化方法,其特征在于,包括：S1.隐私服务提供商生成公钥pk和私钥sk,将公钥pk和私钥sk均发送至客户端,并将私钥sk发送给图像分割执行服务器；S2.客户端利用公钥pk对图像进行加密并进行数据打包,压缩加密图像尺寸,并将加密打包后的图像发送至图像分割执行服务器；步骤S2所述的数据打包,压缩加密图像尺寸的过程为：客户端利用公钥pk对图像加密后形成加密图像尺寸为s-m×s-n,将加密图像/&gt;分割成相同尺寸大小的L块图片,表示为：I～0,I～1,…,I～(L-1),执行公式：                  其中,i＝0,1,…,利用公钥pk对I～P打包成尺寸为/&gt;的压缩图像表示压缩图像/&gt;的尺寸参数,t,Q均表示打包参与参数,/&gt;I～k(i,j)表示第k块图片中索引为(i,j)的图像的像素值；步骤S2之后,步骤S3之前还包括：图像分割执行服务器将压缩图像进行高斯滤波,高斯滤波后的结果表示为/&gt;满足：          保留乘法运算结果,表示为：                  其中,m＝0,1,…,s-m；n＝0,1,…,s-n,均表示图像尺寸参数,G为高斯滤波模板,Q为高斯滤波模板量化参数,s-g为高斯滤波模板尺寸；S3.图像分割执行服务器与隐私服务提供商之间通过多方安全计算及乱码电路技术进行交互,获取加密分割图像；步骤S3所述图像分割执行服务器与隐私服务提供商之间通过多方安全计算及乱码电路技术进行交互的过程包括：对高斯滤波后的加密打包数据进行比较,步骤为：S31.以水平方向的Sobel滤波模板G-x为例,图像分割执行服务器构建两个临时模板：模板系数为正的部分表示为和模板系数为负的部分表示为/&gt;构建公式为：                                    其中,和/&gt;分别是水平方向Sobel卷积核中系数为正和负的部分,                  S32.图像分割执行服务器生成两个随机数α-+、α--,并执行公式对两个随机数打包：                                    其中,表示随机数α-+进行数据打包后的值；/&gt;表示随机数α--进行数据打包后的值,基于打包后的随机数,图像分割执行服务器生成中间密文/&gt;及垂直/&gt;分别满足：                                    图像分割执行服务器将中间密文及/&gt;发送至隐私服务提供商：S33.隐私服务提供商利用私钥sk对中间密文及/&gt;进行解密,分段得到/&gt;和并利用随机数α-1生成集合{δ},集合{δ}中任意一个值δ-i满足：                  其中,i＝0,1,…,L-1,c为额外变量,c∈{0,1},为隐私服务提供商随机挑选；S34.根据随机数α-+、α--,图像分割执行服务器计算中间参数σ-0及σ-1,满足：σ-0＝α-+-α--,σ-1＝α---α-+,然后通过随机数α-2修饰σ-i,公式为：                  其中,表示修饰后的σ-i,i＝0,1；图像分割执行服务器与隐私服务提供商之间执行茫然传输后,图像分割执行服务器持有/&gt;隐私服务提供商持有δ-i；S35.由图像分割执行服务器创建乱码电路,生成一个对应带额外输入的比较电路C的加密乱码电路表GCT,另一方对乱码电路表GCT解码,以持有值及δ-i计算最终电路的输出/&gt;基于比较乱码电路完成加密打包数据/&gt;的比较,图像分割执行服务器获取比较结果r∈{0,1}；S4.图像分割执行服务器将加密分割图像发送给客户端,客户端解密后得到最终边缘图像。</td>   <td>G06T7/12;G06T7/136;G06T1/00;G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李宇栋;                   任江涛       </td>   <td>中山大学</td>   <td>一种基于神经机器翻译的相似病历预测方法</td>   <td>广东省</td>   <td>CN112836485B</td>   <td>2023-09-19</td>   <td>本发明涉及一种基于神经机器翻译的相似病历预测方法,包括以下步骤：S1：将电子病历中的相关文本信息作为编码网络的输入；S2：初始化编码网络中的参数,并将电子病历中的相关文本信息向量化；S3：用编码网络中的每一步的输出向量求平均值,作为解码器中的初始细胞状态；S4：将编码网络得到的每一步的输出向量输入attention中,然后将解码器每一步的输出输入attention中,得到attention的输出,作为解码器的隐含层向量；S5：最后通过解码器的隐含层向量解码得到输出相似病历的编号；用编码网络和初始化的参数,可以学习到电子病历文本信息的特征向量表示,将编码器的输出传输到attention层,并求平均值后初始化解码器,可以准确地预测到相似的病历。</td>   <td>1.一种基于神经机器翻译的相似病历预测方法,其特征在于,包括以下步骤：步骤S1：将电子病历中的相关文本信息作为编码网络的输入；在步骤S1中,所述相关文本信息为对应输入词的上下文信息以及位置信息；步骤S2：初始化编码网络中的参数,并将电子病历中的相关文本信息向量化；在步骤S2中,所述编码网络包括第一嵌入层和12个Transformer子层,编码网络将输入病历中的文本信息的词语通过第一嵌入层映射为待编码向量,再将待编码向量通过12个Transformer子层进行特征提取,得到输入病历的文本信息的特征,作为解码器的输入和初始化向量；编码网络采用嵌入层和Transformer子层中的编码器,每一个Transformer子层的输出向量输出给下一个Transformer子层,编码器的输出为最后一个Transformer子层的输出,最后一个Transformer子层的输出向量作为输入病历的特征表示,用于解码器中的LSTM层的输入和初始化；Transformer子层包括多头注意力层、全连接层和残差连接层；输入向量被输入到多头注意力层中,经过计算后得到Transformer子层的输出向量,再与残差连接层输入向量相加,得到残差连接层的输出,再将残差连接层的输出传输给全连接层,得到全连接层的输出,再与上一残差连接层的输出相加,得到这一残差连接层的输出,作为Transformer子层的输出向量；步骤S3：用编码网络中的每一步的输出向量求平均值,作为解码器中的初始细胞状态；步骤S4：将编码网络得到的每一步的输出向量输入attention中,然后将解码器每一步的输出输入attention中,得到attention的输出,作为解码器的隐含层向量；解码器采用基于Attention机制的长短期记忆层来进行解码；解码的每一步接收上一步的隐藏层状态和细胞状态,结合这一步的输入,产生新的细胞状态和隐藏层状态；且长短期记忆层在解码的每一步都计算对于编码器每一步输出的注意力向量,基于注意力向量和这一步的输出得到长短期记忆层解码器的每一步的最终输出,并作为新的隐藏层状态；步骤S5：通过解码器的隐含层向量解码得到输出相似病历的编号；在步骤S5中,解码器的输出方式为：                                                      a-t＝f(c-t,h-t)＝tanh(W-c[c-t；h-t])h-t和分别是指解码器的隐藏层状态和编码器的每一步的输出向量；α-(ts)为解码器隐藏层状态对于编码器的每一步的输出向量的注意力权重；/&gt;为对解码器隐藏层状态和编码器的每一步的输出向量打分的函数；c-t为对应于解码器隐藏层状态的上下文对齐向量；a-t为计算得到的注意力向量,即注意力层的输出；t表示解码器的解码步骤,即t时刻；s和s’都表示编码器的时刻的变量。</td>   <td>G06F40/194;G06F40/58;G06N3/049;G06N3/08;G16H10/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨猛;                   钟琴       </td>   <td>中山大学</td>   <td>一种基于主动半监督字典学习的图像分类方法</td>   <td>广东省</td>   <td>CN112861999B</td>   <td>2023-09-19</td>   <td>本发明提供一种基于主动半监督字典学习的图像分类方法,包括以下步骤：S1：获取训练样本集,将训练样本集分类为有标签样本集和无标签样本集；S2：构建初始的半监督字典模型；S3：分别构建有标签样本集和无标签样本集的判别表示；S4：构建图像分类目标函数；S5：结合主动学习对图像分类目标函数进行更新,得到更新好的图像分类目标函数,将更新好的图像分类目标函数用于图像分类。本发明提供一种基于主动半监督字典学习的图像分类方法,通过整合主动学习机制使得图像分类目标函数的更新更加高效并且更适用于现实场景,能够有效地利用大量无标签样本,解决了目前的图像分类方法还无法有效地利用大量无标签样本的问题。</td>   <td>1.一种基于主动半监督字典学习的图像分类方法,其特征在于,包括以下步骤：S1：获取训练样本集,将训练样本集分类为有标签样本集和无标签样本集；S2：根据有标签样本集和无标签样本集构建初始的半监督字典模型；S3：根据半监督字典模型分别构建有标签样本集和无标签样本集的判别表示；有标签样本集的判别表示为：                  其中,令表示有标签样本集,/&gt;为类别个数,/&gt;为第/&gt;个类别的第/&gt;个样本,为第/&gt;个类别的样本数量；/&gt;表示训练得到的半监督字典模型,/&gt;为第/&gt;个类别的子字典；/&gt;为类共性表示系数矩阵,/&gt;,/&gt;是/&gt;通过/&gt;得到的类共性编码系数矩阵,/&gt;,/&gt;是样本特殊性编码系数向量,/&gt;和/&gt;均为标量；无标签样本集的判别表示为：                  其中,为第/&gt;个无标签样本/&gt;的类估计概率,/&gt;满足/&gt;且/&gt;,/&gt;为/&gt;通过/&gt;得到的编码系数向量,/&gt;为标量；S4：根据有标签样本集和无标签样本集的判别表示构建图像分类目标函数；构建得到的图像分类目标函数为：                  其中,表示无标签样本的类别估计概率矩阵；/&gt;表示无标签样本集/&gt;通过半监督字典模型得到的判别表示编码系数矩阵；S5：结合主动学习对图像分类目标函数进行更新,得到更新好的图像分类目标函数,将更新好的图像分类目标函数用于图像分类。</td>   <td>G06V10/764;G06V10/774;G06N3/0895</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丘昌镇;              黄宇荣;              张志勇;                   陈少龙       </td>   <td>中山大学</td>   <td>一种多目标跟踪方法、装置、设备和存储介质</td>   <td>广东省</td>   <td>CN113570637B</td>   <td>2023-09-19</td>   <td>本申请公开了一种多目标跟踪方法、装置、设备和存储介质,方法包括：对第一帧图片中的目标进行检测,得到若干第一目标；在第二帧图片中,对各所述第一目标进行跟踪,得到各所述第一目标对应的第一跟踪结果；对第二帧图片中的目标进行检测,得到目标检测结果；根据所述第一跟踪结果和所述目标检测结果,确定所述第二帧图片中的若干第二目标；根据所述第一目标和所述第二目标之间的第一欧式距离,确定所述第二帧图片对应的目标跟踪结果。解决了现有基于神经网络的多目标跟踪方法,在小型化、低功耗的嵌入式平台难以实时运行的技术问题。</td>   <td>1.一种多目标跟踪方法,其特征在于,包括：对第一帧图片中的目标进行检测,得到若干第一目标；在第二帧图片中,对各所述第一目标进行跟踪,得到各所述第一目标对应的第一跟踪结果；对第二帧图片中的目标进行检测,得到目标检测结果；根据所述第一跟踪结果和所述目标检测结果,确定所述第二帧图片中的若干第二目标；根据所述第一目标和所述第二目标之间的第一欧式距离,确定所述第二帧图片对应的目标跟踪结果；所述在第二帧图片中,对各所述第一目标进行跟踪,得到各所述第一目标对应的第一跟踪结果的步骤,具体包括：在所述第一帧图片中,对各所述第一目标进行特征点采样,得到各所述第一目标对应的第一特征点；由所述第一帧图片到所述第二帧图片的跟踪顺序,计算各所述第一特征点在所述第二帧图片中对应的第二特征点；由所述第二帧图片到所述第一帧图片的跟踪顺序,计算各所述第二特征点在所述第一帧图片中对应的第三特征点；根据所述第一特征点和对应的所述第三特征点之间的第二欧式距离,得到各所述第一目标对应的第一跟踪结果；所述对第二帧图片中的目标进行检测,得到目标检测结果的步骤,具体包括：基于滑动窗口,获取所述第二帧图片对应的若干图像片；通过方差分类器,基于各所述图像片的方差,对各所述图像片进行是否含有目标的检测,得到第一目标检测结果；通过随机蕨分类器,基于各所述图像片的采样特征点,对各所述图像片进行是否含有目标的检测,得到第二目标检测结果；通过最近邻分类器,基于各所述图像片和模板图像的相似度计算结果,对各所述图像片进行是否含有目标的检测,得到第三目标检测结果；所述根据所述第一目标和所述第二目标之间的第一欧式距离,确定所述第二帧图片对应的目标跟踪结果的步骤,具体包括：计算所述第一目标和所述第二目标之间的第一欧式距离；将所述第一欧式距离最短的一对所述第一目标和所述第二目标认为是同一目标,以得到所述第二帧图片对应的目标跟踪结果。</td>   <td>G06T7/246;G06V10/74;G06V10/762;G06V10/764;G06V10/82;G06N3/04;G06N3/0895</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢志;              丁小燕;              何尧;                   周昊       </td>   <td>中山大学中山眼科中心</td>   <td>幼儿眼底视网膜全景影像图谱生成和随访数据对齐方法</td>   <td>广东省</td>   <td>CN115619747B</td>   <td>2023-09-19</td>   <td>本发明公开一种幼儿眼底视网膜全景影像图谱生成和随访数据对齐方法,通过十几例影像数据结合临床指南中图例便可以快速生成指南中对应疾病的视网膜影像图谱,再利用生成的影像图谱,能够对新的影像数据进行空间上的映射对齐,利用生成的影像图谱,能够对随访数据进行时间和空间上的映射对齐,以早产儿视网膜病变为例,能快速辅助医生进行随访数据在空间对齐后进行时间序列的分析。</td>   <td>1.一种幼儿眼底视网膜全景影像图谱生成和随访数据对齐方法,其特征在于,包括以下步骤：S1：整理若干例的方位图影像数据,每一例按左眼和右眼进行分组后,分别进行拼接融合得到每一例的全景图,再将所有的全景图进行配准变换叠加后,得到左眼和右眼对应的眼底影像图谱；S2：收集眼底方位影像,按左眼和右眼进行分组后,确定左/右眼的标准目标图,并利用标准目标图与眼底影像图谱计算由标准目标图向眼底影像图谱转换的关系矩阵,其它眼底方位影像拼接融合得到全景影像后,根据由标准目标图向眼底影像图谱转换的关系矩阵进行配准转换,再根据全景影像的视盘和黄斑坐标以及制作的影像图谱中的对应坐标进行尺度和位置的对齐；S3：获取多次随访的检查影像数据,根据检测日期分组后,对于每一组的检查数据,按左眼和右眼进行分组后,按照步骤S1生成左眼和右眼的标准图谱结果图,并按时间顺序排列生成的标准图谱结果图,完成随访数据在时间序列和空间方向上的对齐；步骤S1中将所有的全景图进行配准变换叠加,具体为：对于生成的每张全景影像,确定其中视盘和黄斑的位置；选择一张全景影像作为全景目标图T,其它全景影像往全景目标图T进行配准变换,所有变换后的图与全景目标图T进行等权值叠加,得到左眼和右眼对应的眼底影像图谱,具体为：全景目标图T的视盘和黄斑坐标分别为[x1,y1],[x2,y2],准备配准的全景图I’的视盘和黄斑坐标分别为[X1,Y1],[X2,Y2],计算由全景图I’向全景目标图T的变换关系M：                                                                        S0＝((X1-X2)*(x1-x2)+(Y1-Y2)*(y1-y2))*dS1＝((Y1-Y2)*(x1-x2)-(X1-X2)*(y1-y2))*dS2＝((Y1-Y2)*(x1y2-x2y1)-(X1y2-X2y1)*(y1-y2)-(X1*x2-X2*x1)*(x1-x2))*dS3＝(-(X1-X2)*(x1y2-x1y1)-(Y1x2-Y2*x1)*(x1-x2)-(Y1y2-Y2y1)*(y1-y2))*d得到变换关系后,利用仿射变换将所有待配准的图配准到全景目标图T中,并进行像素值的叠加,最终叠加后的像素值除以叠加的图像数,得到平均眼图像,变换关系M的求解方法是基于两组坐标进行4自由度转换矩阵的估计,可以通过增加标注的坐标数量进行更多自由度的计算包括6自由度矩阵或9自由度矩阵的估计,估计的方法包括两点估计、三点估计或奇异值求解估计。</td>   <td>G06T7/00;G06T7/11;G06T5/50;G06N3/08;G06N3/04;G06V10/82;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁北辰;              樊天慧;              黄庆庆;              冯国栋;                   陈超核       </td>   <td>中山大学;华南理工大学</td>   <td>一种水下机器人作业环境与状态的评估方法</td>   <td>广东省</td>   <td>CN115761464B</td>   <td>2023-09-19</td>   <td>本发明公开了一种水下机器人作业环境与状态的评估方法,方法包括：通过水下相机实时获取周围环境信息；对所述周围环境信息进行视频流分解,获取逐帧图像；对所述逐帧图像进行图像增强处理,确定每帧图像中的目标物；对所述目标物进行识别,确定每帧图像中的目标物的初步空间状态；获取任意相邻帧的图像中的目标物的初始空间状态,采用均值法对所述初步空间状态进行优化处理,得到每个目标物的最终空间状态。本发明能够提高图像对比度和清晰度,获取水下工作环境信息,可广泛应用于计算机技术领域。</td>   <td>1.一种水下机器人作业环境与状态的评估方法,其特征在于,包括：通过水下相机实时获取周围环境信息；对所述周围环境信息进行视频流分解,获取逐帧图像；对所述逐帧图像进行图像增强处理,确定每帧图像中的目标物；对所述目标物进行识别,确定每帧图像中的目标物的初步空间状态；获取任意相邻帧的图像中的目标物的初始空间状态,采用均值法对所述初步空间状态进行优化处理,得到每个目标物的最终空间状态；所述通过水下相机实时获取周围环境信息,包括：通过水下相机的左目相机和右目相机采集水下机器人周围环境信息；所述对所述逐帧图像进行图像增强处理,确定每帧图像中的目标物,包括：对所述逐帧图像进行高斯滤波处理,得到第一图像集和第二图像集；其中,第一图像集为水下相机的左目相机采集的图像,第二图像集为水下相机的右目相机采集的图像；对所述第一图像集进行色彩校正处理,得到第三图像集,以及对所述第二图像集进行色彩校正处理,得到第四图像集；对所述第一图像集进行对比度增强处理,得到第五图像集,以及对所述第二图像集进行对比度增强处理,得到第六图像集；将所述第三图像集与所述第五图像集进行加权平均融合处理,得到第七图像集,以及将所述第四图像集与所述第六图像集进行加权平均融合处理,得到第八图像集；将所述第七图像集与所述第八图像集与目标库进行对比,匹配得到目标参考物,并确定目标参考物在所述第七图像集与所述第八图像集中的坐标信息。</td>   <td>G06V20/05;G06V20/40;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         裴杰;              刘鹏宇;                   方华军       </td>   <td>中山大学;中科吉安生态环境研究院</td>   <td>一种臭氧污染对作物减产风险评估方法和装置</td>   <td>广东省</td>   <td>CN116485174B</td>   <td>2023-09-19</td>   <td>本发明公开了一种臭氧污染对作物减产风险评估方法和装置,方法包括：获取第一区域的环境数据,生成第一模型指标数值；将第一区域划分为若干个第一子区域,生成每个第一子区域对应的第二模型指标数值；将所有第一子区域的中心地理位置坐标、第二模型指标数值和在第一时间范围的农作物单位面积产量输入到时空地理加权回归模型,生成回归系数；根据回归系数和单位面积产量,生成当前第一子区域的臭氧污染响应敏感值和农作物产量；根据农作物产量和无臭氧污染条件下的农作物产量,生成每个第一子区域在第一时间范围内的臭氧污染对农作物的减产结果,在区域臭氧减产风险评估模型中纳入时间与空间特征,提高区域臭氧减产风险评估模型的评估精度。</td>   <td>1.一种臭氧污染对作物减产风险评估方法,其特征在于,包括：获取第一区域在第一时间范围内的环境数据,生成若干个第一模型指标数值；将所述第一区域划分为若干个第一子区域,将所述第一模型指标数值进行计算处理,生成每个所述第一子区域对应的第二模型指标数值；将所有第一子区域的中心地理位置坐标、第二模型指标数值和在第一时间范围的农作物单位面积产量输入到时空地理加权回归模型,生成每个第一子区域的农作物产量与第二模型指标数值之间的回归系数；根据每个第一子区域的第一回归系数和所述农作物单位面积产量,生成当前第一子区域的农作物在第一时间范围内对于近地面臭氧污染的响应敏感值和第一农作物产量；所述第一回归系数为农作物产量与臭氧指标数值之间的回归系数；根据所述第一农作物产量和对应无臭氧污染条件下的第二农作物产量,生成每个第一子区域在第一时间范围内的臭氧污染对农作物的减产结果。</td>   <td>G06Q10/0635;G06Q10/0639;G06F16/29;G06F16/26;G06F16/2458;G06F17/16;G06F17/11;G06Q50/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         路永和;              陈红玉;              赵蕊洁;              张悦韵;                   朱侯       </td>   <td>中山大学</td>   <td>一种面向中文医学文本的实体关系抽取方法及系统</td>   <td>广东省</td>   <td>CN116775801A</td>   <td>2023-09-19</td>   <td>本发明涉及语言数据处理技术领域,提出一种面向中文医学文本的实体关系抽取方法及系统,包括：获取中文医学文本数据并对其进行预处理,得到文本向量；将所述文本向量分别输入CasRel模型和TPLinker模型中,并对所述CasRel模型和TPLinker模型分别进行训练；选择至少一个预训练模型作为编码层分别对经过训练的所述CasRel模型和TPLinker模型进行编码优化,得到若干实体关系抽取模型；比较不同实体关系抽取模型分别对所述中文医学文本数据的实体抽取效果,选择满足预设的评估指标的目标实体关系抽取模型输出；根据满足评估指标的目标实体关系抽取模型对待处理的中文医学文本数据处理,以获取最终的抽取关系。</td>   <td>1.一种面向中文医学文本的实体关系抽取方法,其特征在于,包括：获取中文医学文本数据并对其进行预处理,得到文本向量；将所述文本向量分别输入CasRel模型和TPLinker模型中,并对所述CasRel模型和TPLinker模型分别进行训练；选择至少一个预训练模型作为编码层分别对经过训练的所述CasRel模型和TPLinker模型进行编码优化,得到若干实体关系抽取模型；比较不同实体关系抽取模型分别对所述中文医学文本数据的实体抽取效果,选择满足预设的评估指标的目标实体关系抽取模型输出；根据满足评估指标的目标实体关系抽取模型对待处理的中文医学文本数据处理,以获取最终的抽取关系。</td>   <td>G06F16/31;G06F40/126;G06F40/289;G06F40/216;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;              黄泽青;              郭成超;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种综合降水情势与时间要素的洪涝灾害评估方法及系统</td>   <td>广东省</td>   <td>CN116776601A</td>   <td>2023-09-19</td>   <td>本发明涉及水文数据处理技术领域,提出一种综合降水情势与时间要素的洪涝灾害评估方法及系统,其中包括：获取待评估区域的降水样本数据,并对其进行标准化处理；以经过标准化处理的降水样本数据作为致灾要素,并基于随时间线性变化的时变特征构建Gompertz函数族,得到用于表征降水情势与洪涝灾害损失关系的洪涝灾害评估模型；对所述洪涝灾害评估模型进行参数拟合,并从Gompertz函数族中选择参数拟合收敛率最高的函数进行洪涝灾害评估,得到洪涝灾害评估结果。本发明以经过标准化处理的降水样本数据作为致灾要素,并引入随时间线性变化的时变特征,从而完成综合降水情势与时间要素的模型构建,有利于对洪涝灾害损失开展动态分析,有效提高评估结果的准确度。</td>   <td>1.一种综合降水情势与时间要素的洪涝灾害评估方法,其特征在于,包括以下步骤：获取待评估区域的降水样本数据,并对其进行标准化处理；以经过标准化处理的降水样本数据作为致灾要素,并基于随时间线性变化的时变特征构建Gompertz函数族,得到用于表征降水情势与洪涝灾害损失关系的洪涝灾害评估模型；对所述洪涝灾害评估模型进行参数拟合,并从Gompertz函数族中选择参数拟合收敛率最高的函数进行洪涝灾害评估,得到洪涝灾害评估结果。</td>   <td>G06F30/20;G06Q50/26;G06Q10/0639</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;              黎晓东;              郭成超;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种面向观测站点数据的极端降水事件分析方法及系统</td>   <td>广东省</td>   <td>CN116776602A</td>   <td>2023-09-19</td>   <td>本发明涉及水文水资源分析技术领域,提出一种面向观测站点数据的极端降水事件分析方法及系统,其中包括以下步骤：获取各个站点的逐日降水数据和降水发生时间；根据所述逐日降水数据进行筛选,得到极端降水事件；根据任意两个站点发生的极端降水事件之间的延迟是否超出预设的延迟阈值,判断极端降水事件是否同步；对于被判定为同步的极端降水事件,基于事件的同步强度量化相应极端降水事件的总体时空连接,并基于所述显著延迟强度表征极端降水事件的总体传播方向,对极端降水事件的同步进行显著性检验,得到通过显著性检验的显著同步强度矩阵和显著延迟强度矩阵,构成极端降水事件的无向网络和有向网络,并将其作为极端降水事件分析结果输出。</td>   <td>1.一种面向观测站点数据的极端降水事件分析方法,其特征在于,包括：获取各个站点的逐日降水数据和降水发生时间；根据所述逐日降水数据进行筛选,得到极端降水事件；根据任意两个站点发生的极端降水事件之间的延迟是否超出预设的延迟阈值,判断极端降水事件是否同步；对于被判定为同步的极端降水事件,基于事件的同步强度量化相应极端降水事件的总体时空连接,并基于所述显著延迟强度表征极端降水事件的总体传播方向,对极端降水事件的同步进行显著性检验,得到通过显著性检验的显著同步强度矩阵和显著延迟强度矩阵；根据所述显著同步强度矩阵和显著延迟强度矩阵分别构成极端降水事件的无向网络和有向网络,并将其作为极端降水事件分析结果输出。</td>   <td>G06F30/20;G06F17/16;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         路永和;              陈红玉;              佟昕瑀;                   陈明红       </td>   <td>中山大学</td>   <td>一种用于医学命名实体识别的数据增强方法及系统</td>   <td>广东省</td>   <td>CN116776884A</td>   <td>2023-09-19</td>   <td>本发明涉及语言数据处理技术领域,提出一种用于医学命名实体识别的数据增强方法及系统,包括以下步骤：采集医学数据并对其进行预处理,构建医学数据集；统计所述医学数据集中不同类型实体数量分布情况；对所述医学数据集进行基于Word2Vec的上下文随机替换增强处理,并与所述医学数据集进行融合,得到AUG-CTT融合增强数据集；和/或,根据所述医学数据集的不同类型实体数量分布情况,选择特定实体类型对所述医学数据集进行针对性随机实体替换增强处理,并与所述医学数据集进行融合,得到AUG-ENT融合增强数据集。本发明采用AUG-CTT增强方法和AUG-ENT增强方法实现数据增强,具有显著增加训练集数量,增加文本特征,平衡数据集中各类别实体分布等特点。</td>   <td>1.一种用于医学命名实体识别的数据增强方法,其特征在于,包括：S1、采集医学数据并对其进行预处理,构建医学数据集；S2、统计所述医学数据集中不同类型实体数量分布情况；S3、对所述医学数据集进行基于Word2Vec的上下文随机替换增强处理,并与所述医学数据集进行融合,得到AUG-CTT融合增强数据集；和/或,根据所述医学数据集的不同类型实体数量分布情况,选择特定实体类型对所述医学数据集进行针对性随机实体替换增强处理,并与所述医学数据集进行融合,得到AUG-ENT融合增强数据集。</td>   <td>G06F40/295;G06F40/216;G06F18/25;G06F18/214;G06F40/289;G06F40/247;G06F16/35;G06N3/0442;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         耿静;              吕俊伟;                   方华军       </td>   <td>中山大学;中科吉安生态环境研究院</td>   <td>一种基于FOD与最优波段组合的监测土壤有机碳的方法</td>   <td>广东省</td>   <td>CN116778228A</td>   <td>2023-09-19</td>   <td>本申请属于环境监测技术领域,公开了一种基于FOD与最优波段组合的监测土壤有机碳的方法。对卫星高光谱影像进行影像校正得到卫星高光谱数据,进行分数阶微分处理得到高光谱分数阶微分数据,再对高光谱分数阶微分数据利用最优波段组合方法进行光谱特征的提取,得到光谱指数与高光谱分数阶微分数据结合形成高光谱数据集；再利用上述获得的数据对随机森林模型进行训练,得到最优随机森林模型；利用最优随机森林模型预测有机碳含量,生成土壤有机碳空间分布图。将分数阶微分和最优波段组合方法结合,有效提高了卫星高光谱反演土壤有机碳的精度,提高了大范围监测土壤有机碳含量的能力,并且可以在空间上进行可视化分析。</td>   <td>1.一种基于FOD与最优波段组合的监测土壤有机碳的方法,其特征在于,所述方法包括：获取研究区域的土壤采集点数据和卫星高光谱影像,并对所述卫星高光谱影像进行影像校正得到卫星高光谱数据；对所述卫星高光谱数据进行分数阶微分处理,得到n组高光谱分数阶微分数据,n为大于1的自然数；利用最优波段组合方法对所述n组高光谱分数阶微分数据进行特征提取,得到若干个二维光谱指数和若干个三维光谱指数,将所述n组高光谱分数阶微分数据分别与所述二维光谱指数和三维光谱指数进行组合,得到2n组高光谱数据集；将所述n组高光谱分数阶微分数据、所述2n组高光谱数据集以及土壤采集点数据均输入到随机森林模型中采用自助法进行有放回抽样训练,构建3n个随机森林模型,按照预设评价指标对所述随机森林模型进行精度分析,得到最优随机森林模型；将待监测区域的卫星高光谱数据输入到所述最优随机森林模型中,得到所述待监测区域的预测有机碳含量,基于所述预测有机碳含量生成土壤有机碳空间分布图。</td>   <td>G06V10/764;G06V10/58;G06V20/13;G06V20/10;G06F17/13;G01N21/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张兴宇;              潘炎;              印鉴;                   潘文杰       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司</td>   <td>一种无监督关键词提取方法</td>   <td>广东省</td>   <td>CN110472005B</td>   <td>2023-09-15</td>   <td>本发明提供一种无监督关键词提取方法,该方法利用LDA主题模型得到部分主题关联度较高的主题单词,和候选短语一起作为节点去构建phrase-word图；利用这些主题单词去筛选和促进主题关联度更高的候选短语,间接抑制了噪音候选短语对结果的影响；另一方面,针对短文本候选短语不足的情况,这些主题单词作为语义信息的补充,使得算法图结构的语义信息更加丰富；针对长文本候选短语过大,其中夹杂过多噪音的情况,这些主题单词起到了一定的筛选作用；本专利的基于phrase-word图的方法使得关键词提取对文章长度不再那么敏感,效果得到了进一步的提升。</td>   <td>1.一种无监督关键词提取方法,其特征在于,包括以下步骤：S1：对文档数据进行预处理,得到一个单词集合W；S2：采用模式匹配结合句法规则来进行名词短语分块,具体利用词性标注和“形容词+名词”模式得到一系列候选关键短语；S3：利用LDA主题模型计算S1得到的单词集合W中每个单词的word salience分数,根据该分数进行降序排序,取前k个作为这篇文档的主题单词集合；S4：利用S2得到的候选关键短语和S3得到的主题单词,构建phrase-word图；所述步骤S4的具体过程是：S41：利用sent2vec模型计算候选关键短语之间的相似度,以候选关键短语作为图的节点,以短语之间的相似度作为边权,构造完全图phrase图；S42：利用sent2vec模型计算主题单词之间的相似度,以主题单词作为图的节点,以单词之间的相似度作为边权,构造完全图word图；S43：如果phrase图中的某个短语包括word图中某个单词,便在该phrase图的节点与该word图的节点之间构造一条phrase-word边,边权为phrase长度的倒数；利用这种构造边的方式,将phrase图与word图结合,构造出phrase-word图；S44：对phrase-word图中每个边的边权进行归一化处理；S5：根据S4构建的图结构,进行PageRank算法迭代得到每个候选短语的分数,降序排序之后,排名靠前的候选短语即是需要提取的关键词结果。</td>   <td>G06F16/33;G06F16/34;G06F40/289;G06F40/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   杨振华       </td>   <td>中山大学</td>   <td>面向数字高程模型的任意断面集水区边界与河网提取方法</td>   <td>广东省</td>   <td>CN112017282B</td>   <td>2023-09-15</td>   <td>本发明提供的一种面向数字高程模型的任意断面集水区边界与河网提取方法,通过考虑断面所在空间网格单元与其他网格单元的流向隶属关系,划分断面上游和空间网格边界,在剔除目标水域覆盖区的基础上,以此为边界提取集水区河网系,能根据认为设定的河流、湖泊、水库目标水域断面,灵活地提取断面上游的集水边界和河网,明确断面水文影响方位；同时借助Python3语言的开发环境,代码结构简单,操作方便,是自动化提取指点断面集水区河网水系,划分集水单元的一种有效方法。</td>   <td>1.面向数字高程模型的任意断面集水区边界与河网提取方法,其特征在于,包括：S1：将栅格DEM文件.GIFf和矢量shape文件.shp为输入数据,利用开源的python语言包库分别读取DEM数据和矢量计算区域矩形边界以及目标水域数据；S2：统一输入数据的坐标系统,对所有输入数据设置成WGS84地理坐标系；S3：读取目标水域数据的矩形边界后设置缓冲区距离,得到目标水域粗略的集水区范围；所述目标水域数据的矩形边界的计算公式具体为：                  式中,p-x和p-y分别代表所有边界点x和y的坐标集合；S4：采用格网化方法对其进行填洼计算、流向计算、累积流量计算过程,设置流量阈值,提取完整的水系和各集水单元边界,初步计算出流域水系栅格,并划分出多个集水单元；所述填洼计算具体计算过程为：                  式中,W(c)为修正后的高程值；Z(c)为原始值；ε(c,n)为中心网格与临近网格高差最小的正值；W(n)为临近网格的最小值；所述流向计算采用D8算法,具体为：在3×3窗口中,计算中心格网C与邻域八格网i(i＝1,2,…8)之间的距离落差P,流向为具有最大P值的邻域格网方向；所述累积流量计算具体为：经过流向计算后,将依据流向的隶属关系,把相同流向和交叉流向进行合并,赋予单元网格统一的单位产流量后,计算出每个网格的累积流量,具体计算公式为：                  式中,F(c)为中心网格的累积流量值,flow(i)为隶属于中心网格的第i个网格流量；S5：通过流域水系栅格、集水单元和目标水域进行空间叠加与融合,将目标水域属性赋给重叠的栅格水系,依据属性字段将目标水域剔除,以生成不包含目标水域的水系和集水单元；所述空间叠加与融合的计算公式具体为：                  式中x-i,y-j计算区域内第i行第j列栅格坐标值,T(x-m,y-n)为与计算区域空间位置重叠的属性值,属性值判断依据为对应网格坐标未超出计算区域坐标最大值；S6：利用不含目标水域的栅格河网、集水单元与指定断面上游集水区进行空间裁剪,最终得到准确的指定断面集水单元和河网水系；S7：将指定断面集水单元和河网水系进行制图输出,实现对集水区河网、边界特征提取的处理。</td>   <td>G06T17/05;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              李家振;              张永东;                   杜云飞       </td>   <td>中山大学</td>   <td>一种基于CPU的生物分子可视化光线追踪渲染方法</td>   <td>广东省</td>   <td>CN112116693B</td>   <td>2023-09-15</td>   <td>本发明为生物分子可视化光线追踪渲染方法,构建三维场景、生物分子的空间填充表达模型；将模型实例化为可变换实例,将可变换实例绑定加入到三维场景中；通过光线从摄像机出发经过像素点射向三维场景中,若光线与原子没有相交则结束追踪,以背景颜色作为像素颜色；若光线与原子发生相交则计算生成反射光线,并设置多个光源分别从多个不同方向射向模型以继续追踪反射光线,若反射光线与多个光源中的光线相交则加入光照贡献值；最后采用渲染方程,根据原子自身颜色和光照度贡献值计算像素的颜色值。本发明使分子结构获得高质量渲染结果的同时实现实时交互帧率,可用于超级计算机上进行生物分子可视化工作。</td>   <td>1.一种基于CPU的生物分子可视化光线追踪渲染方法,其特征在于：构建三维场景,并根据原子信息构建生物分子的空间填充表达模型；将空间填充表达模型实例化为可变换实例,将可变换实例绑定加入到所构建的三维场景中；通过光线从摄像机出发经过像素点射向构建好的三维场景中,若光线与三维场景中的原子没有相交,则结束追踪,以背景颜色作为像素颜色；若光线与三维场景中的原子发生相交,则计算生成反射光线,并设置多个光源分别从多个不同方向射向生物分子的空间填充表达模型以继续追踪反射光线,若反射光线与所设置的多个光源中的光线相交,则加入光照贡献值,否则不加入光照贡献值；最后采用渲染方程,根据原子自身颜色和光照度贡献值计算像素的颜色值；所述方法通过本地光线追踪实现,包括步骤：步骤S11、解析分子文件,获取原子信息；步骤S12、利用所获得取的原子信息,遍历所有原子,并用不同类型原子对应的范德华半径作为半径的球体代表原子,构建生物分子的空间填充表达模型,并将生物分子的空间填充表达模型实例化为可变换实例；步骤S13、构建三维场景,将可变换实例绑定加入到所构建的三维场景中,根据生物分子的空间填充表达模型的大小定义摄像机的初始位置；步骤S14、通过交互动作对摄像机进行控制,实现生物分子的空间填充表达模型旋转变换,生成每帧交互信息并更新摄像机位置参数和变换生物分子的空间填充表达模型；然后利用光线追踪渲染算法计算每个像素点的颜色值,存入帧缓存完成每帧画面渲染。</td>   <td>G06T15/06;G06T1/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         万海;              张漫榕;              刘亚男;              黄佳莉;              曾娟;                   范科峰       </td>   <td>中山大学</td>   <td>一种面向社交平台表情包的多模态情感分析方法</td>   <td>广东省</td>   <td>CN112651448B</td>   <td>2023-09-15</td>   <td>本发明提供一种面向社交平台表情包的多模态情感分析方法,包括以下步骤：S1：使用爬虫工具从社交平台爬取表情包图片,并对表情包图片进行情感标注后,进行预处理；S2：获取步骤S1爬取到的表情包图片的语义信息,得到每张表情包图片对应的文本信息特征向量表示；S3：获取步骤S1爬取到的表情包图片的视觉特征,得到每张表情包图片对应的视觉特征向量表示；S4：所述文本信息特征向量表示和视觉特征向量表示经多模态融合,得到多模态融合特征向量表示；S5：所述多模态融合特征向量表示经过分类器得到情感识别结果,选取置信度最高的情感识别结果作为预测的情感,本发明引入了图片的文本语义特征,能够更好地捕获表情包中的隐含语义信息。</td>   <td>1.一种面向社交平台表情包的多模态情感分析方法,其特征在于,包括以下步骤：S1：使用爬虫工具从社交平台爬取表情包图片,并对表情包图片进行情感标注后,进行预处理；S2：获取步骤S1爬取到的表情包图片的语义信息,得到每张表情包图片对应的文本信息特征向量表示；S3：获取步骤S1爬取到的表情包图片的视觉特征,得到每张表情包图片对应的视觉特征向量表示；S4：所述文本信息特征向量表示和视觉特征向量表示经多模态融合,得到多模态融合特征向量表示；S5：所述多模态融合特征向量表示经过分类器得到情感识别结果,选取置信度最高的情感识别结果作为预测的情感；步骤S2中获取步骤S1爬取到的表情包图片的语义信息,得到每张表情包图片对应的文本信息特征向量表示,具体为：对图文表情包使用OCR技术识别表情包上的文本；对图片表情包使用图片描述文本生成模型生成图片表情包对应的文本描述,所述图片描述文本生成模型基于图文表情包数据集训练,用于为图片表情包数据集中的每一张图片生成一句文本描述；将图文表情包上的文本和图片表情包的文本描述经过预训练语言模型,得到每张表情包图片对应的文本信息特征向量表示；所述图片描述文本生成模型为图片表情包数据集中的每一张图片生成一句描述文本,具体为：划分图文表情包数据集为训练集和测试集,其中训练集占70％,测试集占30％,为了抽取图文表情包的文字信息,利用OCR文本识别技术识别图文表情包中包含的文本内容,为了避免图文表情包中文字信息对图像信息的干扰,为图文表情包中的文字部分添加水印；图片描述文本生成模型采用编码器-解码器结构,编码器部分采用预训练深层卷积模型,将预训练深层卷积模型的全连接层替换为卷积层,输入图片经过预训练深层卷积模型后得到L个向量表示,对应图片中不同区域的视觉特征,记为a{a-1,…,a-L},解码器部分为循环神经网络,并引入了注意力机制以捕捉图片中的重要区域；训练模型时,采用负对数似然损失函数作为损失函数,采用BLEU作为评价指标,使用随机梯度下降的方式更新参数；选取在测试集上BLEU得分最高的模型作为训练好的图片描述文本生成模型,将图片表情包数据集中的每一张图片输入图片描述文本生成模型,生成图片对应的文本描述；所述循环神经网络用于预测当前单词的分布概率,同时引入了注意力机制用以捕捉图片中的重要区域,具体为：对于解码器时刻t的输入,解码器将上一个时刻的隐藏层状态h-(t-1)和视觉特征a{a-1,…,a-L}映射为z-t:                  z-t＝φ({a-i},α-(ti)})其中,h-(t-1)为循环神经网络输出的上一个时刻的隐藏层状态,α-(ti)为t时刻视觉特征a-i对应的权重,f-(att)和φ为注意力层,利用z-t、循环神经网络在t时刻的隐藏层状态h-t及t-1时刻单词y-(t-1)计算t时刻预测单词的概率分布                  其中,L-1、E、L-h、L-z均为学习的参数,为开始时刻至t-1时刻的单词序列。</td>   <td>G06V10/80;G06F16/951;G06V20/62;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林琪璇;              李愚;              邵嘉桢;              覃荣琛;                   徐政基       </td>   <td>中山大学</td>   <td>一种提高偏振红外热成像仪图像质量的方法及系统</td>   <td>广东省</td>   <td>CN112837312B</td>   <td>2023-09-15</td>   <td>本发明公开了一种提高偏振红外热成像仪图像质量的方法及系统,该方法包括：基于商品级红外热成像仪和偏振片拍摄不同偏振方向的图像；对不同偏振方向的图像进行融合,得到融合图像；基于图像质量评价函数评价融合前后的图像并定量判断图像质量的提升结果。该系统包括：拍摄模块、融合模块和评价模块。通过使用本发明,利用偏振成像技术,通过图像融合对红外热成像仪的图像进行修正,从而在不大幅度提升成本的情况下提高图像质量。本发明作为一种提高偏振红外热成像仪图像质量的方法及系统,可广泛应用于图像质量提升技术领域。</td>   <td>1.一种提高偏振红外热成像仪图像质量的方法,其特征在于,包括以下步骤：基于红外热成像仪和偏振片拍摄不同偏振方向的图像；对不同偏振方向的图像进行融合,得到融合图像；基于图像质量评价函数评价融合前后的图像并定量判断图像质量的提升结果；所述基于红外热成像仪和偏振片拍摄不同偏振方向的图像这一步骤,其具体包括：不加偏振片并基于商品级红外热成像仪拍摄无偏振图像；添加偏振片并按照预设角度逐次旋转偏振片后基于商品级红外热成像仪拍摄不同偏振方向的图像；得到多个不同偏振方向的图像；所述对不同偏振方向的图像进行融合,得到融合图像这一步骤,其具体包括：将不同偏振方向的图像分别进行多尺度分解,得到对应数量的分量图像；将分量图像按层进行融合,得到分量的融合图像；对分量的融合图像进行逆变换,得到融合图像；所述将不同偏振方向的图像分别进行多尺度分解,得到对应数量的分量图像这一步骤,其具体包括：对不同偏振方向的图像进行非下采样金字塔分解,得到不同频段的图像；基于多方向滤波器对各层中的高频图像进行多方向滤波,分解得到各层图像的高频方向图像；根据各层图像的高频方向图像得到分量图像；所述将分量图像按层进行融合,得到分量的融合图像这一步骤,其具体包括：计算分量图像中各层图像的显著性值,并得到图像的显著性值矩阵F；对于每一张图像,将其每个像素点的显著性值定义为：                  其中g(x,y)为图像中坐标为(x,y)的像素点所具有的灰度值；对所有显著性值矩阵F按照预设规则处理,使得显著性值矩阵F中每个元素的值均在区间[0,1]中；对所有显著性值矩阵F进行一定的数学处理：依次取k组图像中对应层的两张图像的显著性值矩阵F-1、F-2……F-k,比较这k个矩阵的所有元素并找出最大值f-(max),对k个显著性值矩阵进行操作：F-1＝F-1÷f-(max)F-2＝F-2÷f-(max)F-k＝F-k÷f-(max)记k张对应图像的灰度值矩阵为G-1、G-2……G-k,显著性值矩阵为F-1、F-2……F-k,令G-(sum)＝G-1+G-2+……+G-k,融合后图像的灰度值矩阵为G’,则有：                  根据显著性值矩阵F将分量图像中对应层的图像分别进行融合；对各层图像完成融合后,得到一组新的分量的融合图像。</td>   <td>G06T7/00;G06T5/30;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              吴梓溢;              颜鹏翔;              刘梦梦;                   林倞       </td>   <td>中山大学</td>   <td>基于无监督学习的显著性物体检测方法及系统</td>   <td>广东省</td>   <td>CN113326886B</td>   <td>2023-09-15</td>   <td>本发明公开了一种基于无监督学习的显著性物体检测方法及系统,所述方法包括：获取目标域样本,所述目标域样本的标签为使用上一轮迭代得到的模型在目标域图像进行预测得到的伪标签；对所述伪标签进行不确定性评估,并进行不确定性排序；根据排序结果,对所述伪标签进行图片级筛选,得到伪标签不确定性低于预设阈值的目标域样本；对所述目标域样本进行像素级伪标签重加权处理,得到用于下一个迭代训练的目标域样本。本发明提供的基于无监督学习的显著性物体检测方法,可以在不依赖人工标签的情况下,在多个显著性物体检测数据集上取得优异的性能,并达到与全监督显著性检测方法相匹敌的能力,大大减轻了显著性物体检测方法对像素级人工标签的依赖性。</td>   <td>1.一种基于无监督学习的显著性物体检测方法,其特征在于,包括：获取目标域样本,所述目标域样本的标签为使用上一轮迭代得到的模型在目标域图像进行预测得到的伪标签；利用方差评估所述目标域图像在不同数据增强下的显著性预测概率图的一致性,对所述伪标签进行不确定性评估,并根据每个目标域样本的不确定性得分进行不确定性排序；其中,在不同的数据增强下产生的显著性预测概率图的公式为：                            表示目标域图像的显著性预测图；I-t表示目标域图像；α-j(·)表示第j种数据增强方式；/&gt;表示α-j(·)的逆变换操作；/&gt;表示生成目标域图像伪标签的模型操作；利用方差评估显著性概率图的一致性的公式为：                            表示目标域图像的方差图；E表示平均运算；/&gt;表示目标域图像的显著性预测图；N表示数据增强次数；每个目标域样本的不确定性得分由以下公式获取：                            表示目标域图像的不确定性得分；H表示目标域图像的高度；W表示目标域图像的宽度；h表示目标域图像垂直方向的坐标值；w表示目标域图像水平方向的坐标值；表示目标域图像的方差图在坐标(h,w)处的取值；根据排序结果,对所述伪标签进行图片级筛选,得到伪标签不确定性低于预设阈值的目标域样本；对所述目标域样本进行像素级伪标签重加权处理,得到用于下一个迭代训练的目标域样本；其中,目标域样本的像素级伪标签重加权权重由以下公式获取：                            表示目标域图像的像素级伪标签重加权权重；k表示目标域图像的像素级伪标签重加权权重下降幅度；/&gt;表示目标域图像的方差图。</td>   <td>G06V10/774;G06N20/00;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>              姚军艇       </td>   <td>中山大学</td>   <td>一种基于数据库的人脸搜索方法</td>   <td>广东省</td>   <td>CN113377984B</td>   <td>2023-09-15</td>   <td>本发明公开了一种基于数据库的人脸搜索方法,属于人脸搜索技术领域,该搜索方法具体步骤如下：(1)构建信息数据库；(2)图像聚类；(3)待验证人脸视频获取及关键帧处理；(4)待验证人脸图像预处理；(5)待验证人脸图像类别匹配；(6)人脸图像搜索；本发明相较于整个数据库逐一比对方式,通过图像聚类模型划分出多个可疑人员的人脸图像聚类集合,并通过类别匹配得到某一可疑人员的人脸图像聚类集合；最后将待验证人脸图像与某一可疑人员的人脸图像聚类集合中的所有可疑人员人脸图像转换为字符串形式,之后通过汉明距离公式进行相似度计算,得到人脸图像搜索结果,从而有利于降低系统负担,提高系统的反应速度。</td>   <td>1.一种基于数据库的人脸搜索方法,其特征在于,该搜索方法具体步骤如下：(1)构建信息数据库：构建一个包含有可疑人员人脸图像集合以及对应可疑人员文本信息的信息数据库；(2)图像聚类：构建一个图像聚类模型,并利用其对步骤(1)所述可疑人员人脸图像集合进行聚类,划分出多个可疑人员人脸图像聚类集合；(3)待验证人脸视频获取及关键帧处理：通过设置于公共场合的各类监控设施来获取人脸视频,同时对其进行关键帧处理,形成待验证人脸图像；(4)待验证人脸图像预处理：对步骤(3)所述待验证人脸图像进行预处理；(5)待验证人脸图像类别匹配：利用步骤(2)所述图像聚类模型对经过步骤(4)预处理过后的待验证人脸图像与步骤(2)所述多个可疑人员人脸图像聚类集合进行类别匹配,得到某一可疑人员人脸图像聚类集合；(6)人脸图像搜索：采用图像相似度计算法对步骤(4)预处理后的待验证人脸图像进行人脸图像搜索,获取待验证人脸图像在步骤(5)所述某一可疑人员人脸图像聚类集合中的相似图像,同时提取相似图像的对应可疑人员文本信息,即得到人脸图像搜索结果；其中,步骤(1)所述对应可疑人员文本信息包括姓名、年龄、性别、家庭住址、身高、体重和不良记录；步骤(2)所述图像聚类模型的具体构建如下：S1：首先,获取信息数据库中的可疑人员人脸图像集合和可疑人员文本信息；S2：然后,提取步骤S1所述可疑人员文本信息的年龄和性别数据,并确定年龄周期,接着获取对应年龄周期和性别的可疑人员人脸图像集合,并将其作为样本集；S3：最后,构建一个SVM分类器,将步骤S2样本集输入该SVM分类器中进行训练,即得到图像聚类模型；所述年龄取值周期为6岁；步骤(5)所述人脸图像搜索具体过程如下：SS1：首先,获取待验证人脸图像,并提取经过待验证人脸图像类别匹配后得到的某一可疑人员人脸图像聚类集合；SS2：然后,将待验证人脸图像和某一可疑人员人脸图像聚类集合进行字符串转换；SS3：接着,利用汉明距离公式将步骤SS2经过字符串转换后的验证待验证人脸图像和某一可疑人员人脸图像聚类集合进行逐一相似度计算,同时设置汉明距离为5；SS4：最后输出汉明距离小于5的若干个相似度图像；同时输出汉明距离小于5的若干个相似度图像在信息数据库中的对应可疑人员文本信息,即得到人脸图像搜索结果；所述汉明距离公式具体如下：                      (1)式中：a表示待验证人脸图像的字符串；b表示某一可疑人员人脸图像聚类集合中的某一可疑人员人脸图像的字符串；k表示某一可疑人员人脸图像聚类集合；表示为按位异或运算。</td>   <td>G06F16/55;G06F16/532;G06F16/583;G06V10/774;G06V10/764;G06V10/762;G06V10/74;G06V10/75;G06V40/16;G06Q50/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         秦宗;              邹国伟;              罗青云;              杨文超;              邱志光;              吴梓毅;                   杨柏儒       </td>   <td>中山大学</td>   <td>一种基于深度学习的色序型显示器控制方法及装置</td>   <td>广东省</td>   <td>CN113408655B</td>   <td>2023-09-15</td>   <td>本申请公开了一种基于深度学习的色序型显示器控制方法及装置,包括：对输入的单帧图像,基于所述单帧图像的图像特征以及色序型显示器的刷新率,确定与其匹配的驱动算法；采用所述驱动算法计算得到所述单帧图像在各个场中的理想背光分布；根据所述理想背光分布,结合所述色序型显示器的光扩散特性,计算出所述单帧图像在各个场中的模拟背光分布和透射率；根据所述模拟背光分布和透射率,计算出各个场的图像。本申请针对每一帧图像,根据图像内容中所包含的具体图像特征,一一为其确定相匹配的驱动算法,以抑制图像在色序型显示器中所产生的色分离现象,降低了图像的色分离程度,使得每一帧图像在色序型显示器中均能获得较好的色分离抑制效果。</td>   <td>1.一种基于深度学习的色序型显示器控制方法,其特征在于,包括：对输入的单帧图像,基于所述单帧图像的图像特征以及色序型显示器的刷新率,采用深度学习的方法确定与所述单帧图像匹配的驱动算法；采用所述驱动算法计算得到所述单帧图像在各个场中的理想背光分布；根据所述理想背光分布,结合所述色序型显示器的光扩散特性,计算出所述单帧图像在各个场中的模拟背光分布和透射率；根据所述模拟背光分布和透射率,计算出各个场的图像；其中,利用下述方程式计算得到所述透射率：                  利用下述方程式计算所述模拟背光分布：          T-(min)＝min(T-R,T-G,T-B)          和I-i表示图像亮度；/&gt;和BL-i分别表示使用局部彩色背光调光技术时,传统全开启背光和模糊背光图像的强度,T-R、T-G和T-B分别表示液晶像素的红、绿、蓝分量,T′-R、T′-G和T′-B分别表示所述模拟背光分布的红、绿、蓝分量。</td>   <td>G06V10/774;G06V10/82;G06N3/0464;G06N3/08;G09G3/34;G09G3/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>              蒋弥       </td>   <td>中山大学</td>   <td>一种时序SAR图形的变化检测方法及装置</td>   <td>广东省</td>   <td>CN113610781B</td>   <td>2023-09-15</td>   <td>本发明公开了一种时序SAR图形的变化检测方法及装置,所述方法包括：获取SAR数据集,对所述SAR数据集进行取模与估计操作得到序列数据；对所述强度序列进行假设检验得到变化类样本,以及对所述相干性序列进行干涉对筛选得到稳定类样本；分别拟合所述变化类样本的变化特征与所述稳定类样本的稳定特征,得到条件分布参数；获取预设的滤波系数图,以所述条件分布参数为似然项并利用预设的图割算法将预设的滤波系数图进行阈值化,得到变化检测结果。本发明可以将时序SAR决策阈值转变为二分类并利用二分类进行变化检测,不但顾及变化的空间关联性,也避免了复杂的统计建模和聚类过程,缩短处理时间,区分数据中的微弱变化和噪声,以提高决策阈值的准确率。</td>   <td>1.一种时序SAR图形的变化检测方法,其特征在于,所述方法包括：获取SAR数据集,对所述SAR数据集进行取模与估计操作得到序列数据,其中,所述序列数据包括强度序列与相干性序列；对所述强度序列进行假设检验得到变化类样本,以及对所述相干性序列进行干涉对筛选得到稳定类样本；分别拟合所述变化类样本的变化特征与所述稳定类样本的稳定特征,得到条件分布参数；获取预设的滤波系数图,以所述条件分布参数为似然项并利用预设的图割算法将预设的滤波系数图进行阈值化,得到变化检测结果；所述获取预设的滤波系数图,包括：对所述SAR数据集进行配准,得到配准数据集；计算所述配准数据集的变异系数得到变异系数图；对所述变异系数图进行滤波得到进行滤波得到滤波系数图；所述计算所述配准数据集的变异系数得到变异系数图,包括：采用下式逐像素p计算所述配准数据集的变异系数得到变异系数图；                  上式中,其中,cv(p)表示位置p的变异系数,和/&gt;分别表示时间样本的方差和均值,I-t(p)表示位置p在时刻t的强度样本,N表示所述SAR数据集的影像数量。</td>   <td>G06T7/00;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈俊周;              赵楠;                   韦艳宏       </td>   <td>中山大学</td>   <td>一种斑马鱼荧光图像的分割方法及装置</td>   <td>广东省</td>   <td>CN113706570B</td>   <td>2023-09-15</td>   <td>本发明公开了一种斑马鱼荧光图像的分割方法及装置,所述方法包括：先获取多通道的斑马鱼荧光图像；再将多通道斑马鱼荧光图像输入至斑马鱼血管分割模型中,以使斑马鱼血管分割模型进行分割最终输出分割结果。其中,斑马鱼血管分割模型用于根据ECA注意力机制对多通道斑马鱼荧光图像进行图像增强处理后,进行降维处理并生成单通道的斑马鱼荧光图像,继而根据单通道的斑马鱼荧光图像进行分割。采用本发明实施例能提高对斑马鱼荧光图像的分割精度。</td>   <td>1.一种斑马鱼荧光图像的分割方法,其特征在于,包括：获取多通道的斑马鱼荧光图像；将所述多通道斑马鱼荧光图像输入至斑马鱼血管分割模型中,以使所述斑马鱼血管分割模型进行分割最终输出分割结果；其中,所述斑马鱼血管分割模型用于根据ECA注意力机制对所述多通道斑马鱼荧光图像进行图像增强处理后,进行降维处理并生成单通道的斑马鱼荧光图像,继而根据所述单通道的斑马鱼荧光图像进行分割；其中,所述斑马鱼血管分割模型包括：自适应增强部分和网络分割部分；其中,所述自适应增强部分用于根据所述ECA注意力机制对所述多通道斑马鱼荧光图像进行图像增强处理后,进行降维处理并生成所述单通道的斑马鱼荧光图像；所述网络分割部分用于根据所述单通道的斑马鱼荧光图像进行分割；其中,所述自适应增强部分用于根据所述ECA注意力机制对所述多通道斑马鱼荧光图像进行图像增强处理后,进行降维处理并生成所述单通道的斑马鱼荧光图像,具体为：所述自适应增强部分包括：第一卷积层、ECA层、第一跳跃连接层和第二卷积层；其中,所述第一卷积层用于对所述多通道斑马鱼荧光图像进行升维处理并进行增加网络非线性处理之后,生成第一图像；所述ECA层用于使用所述ECA注意力机制获取所述第一图像的重要程度,并根据所述重要程度进行图像增强处理后,生成第二图像；其中,所述第一图像和所述第二图像的维度均为第一维度；所述第一跳跃连接层用于将所述第二图像与所述多通道斑马鱼荧光图像拼接后生成第三图像；其中,所述第三图像的维度为第二维度；所述第二卷积层用于将所述第三图像进行降维处理,生成所述单通道的斑马鱼荧光图像；其中,所述网络分割部分用于根据所述单通道的斑马鱼荧光图像进行分割,具体为：所述网络分割部分包括：编码器、金字塔池化层、第二跳跃连接层和第三卷积层；其中,所述编码器用于将所述单通道的斑马鱼荧光图像进行特征提取,得到感兴趣特征图；所述金字塔池化层用于使用N个不同尺寸的卷积核进行池化操作得到N个池化结果后,对N个所述池化结果进行上采样,得到多个相同尺寸的采样特征图；其中,N为正整数；所述采样特征图的尺寸和所述感兴趣特征图的尺寸大小相同；所述第二跳跃连接层用于将所述感兴趣特征图和所述采样特征图进行拼接后,生成拼接特征图；所述第三卷积层用于对所述拼接特征图进行分割,得到分割结果。</td>   <td>G06T7/174;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄华威;              叶光;              彭肖文;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于中间人账户激励的区块链交易方法、装置及系统</td>   <td>广东省</td>   <td>CN115797070B</td>   <td>2023-09-15</td>   <td>本发明涉及区块链技术领域,公开了一种基于中间人账户激励的区块链交易方法、装置及系统。本发明的区块链由主链和基于分片机制的侧链构成,侧链通过智能合约与主链桥接,侧链上各分片中的节点仅存储所在分片内的账户状态信息；当需要从第一账户向第二账户转入通证且该两账户所属分片不同时,通过目标中间人账户执行相应跨分片交易,目标中间人账户在完成跨分片交易时得到相应的交易中转服务收益；该目标中间人账户同属于第一分片和所述第二分片,为由目标智能合约验证通过的用于提供交易中转服务的所述侧链上的账户,且转入目标智能合约的通证数量满足预置通证数量条件。本发明实现了侧链上的跨分片交易,能够有效提高区块链的可扩展性。</td>   <td>1.一种基于中间人账户激励的区块链交易方法,其特征在于,区块链由主链和基于分片机制的侧链构成,所述侧链通过智能合约与所述主链桥接,所述侧链上各分片中的节点仅存储所在分片内的账户状态信息,所述方法包括：接收从第一账户向第二账户转入第一目标通证数量的通证的转账指令；所述第一账户和第二账户均为所述侧链上的账户；确定所述第一账户所属的第一分片及所述第二账户所属的第二分片；若所述第一分片和所述第二分片属于不同分片,从各中间人账户中确定目标中间人账户；所述中间人账户为由目标智能合约验证通过的用于提供交易中转服务的所述侧链上的账户,且所述中间人账户转入所述目标智能合约的通证数量满足预置通证数量条件；所述目标中间人账户同属于所述第一分片和所述第二分片；向所述目标中间人账户发送与所述转账指令对应的交易请求,以通过所述目标中间人账户执行与所述交易请求相应的跨分片交易；所述目标中间人账户在完成所述跨分片交易时得到相应的交易中转服务收益；所述从各中间人账户中确定目标中间人账户,包括：将同时属于所述第一分片和所述第二分片的中间人账户作为预选账户；所述预选账户为多个时,从各所述预选账户选取一个预选账户作为目标中间人账户,包括以下任意方式：根据各预选账户转入所述目标智能合约的通证数量由大到小的顺序对各预选账户排序,选取排序第一的预选账户作为目标中间人账户；或者,统计基于预选账户实现跨分片交易的成功次数和失败次数,基于所述成功次数和失败次数确定预选账户的信任值,选取信任值最大的预选账户作为目标中间人账户；或者,基于各预选账户转入所述目标智能合约的通证数量,结合预选账户实现跨分片交易的成功次数和失败次数,确定预选账户的信任值,选取信任值最大的预选账户作为目标中间人账户。</td>   <td>G06Q40/04;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄袁;              黄进波;              陈湘萍;                   郑子彬       </td>   <td>中山大学</td>   <td>一种源代码注释生成方法、装置、存储介质及计算机设备</td>   <td>广东省</td>   <td>CN116755769A</td>   <td>2023-09-15</td>   <td>本申请提供的一种源代码注释生成方法、装置、存储介质及计算机设备,在对源代码进行自动注释时,可以先获取待注释源代码,以及该待注释源代码的字节码,这里的字节码可以标识功能作用相同但实现方式不同的源代码,接着可以基于预设的词嵌入矩阵分别确定待注释源代码的文本词向量和字节码的字节码词向量,此处词向量可以捕捉待注释源代码各个字符串之间的语义和语法信息,在确定文本词向量和字节码词向量后,可以将文本词向量和字节码词向量进行拼接后形成拼接词向量,并利用拼接词向量生成待注释源代码的注释结果,这样可以在对功能作用相同但实现方式不同的代码生成注释时进行约束,避免出现混淆和歧义,从而提高注释结果的准确性。</td>   <td>1.一种源代码注释生成方法,其特征在于,所述方法包括：获取待注释源代码,以及所述待注释源代码的字节码；基于第一预设词嵌入矩阵确定所述待注释源代码的文本词向量,以及基于第二预设词嵌入矩阵确定所述字节码的字节码词向量；将所述文本词向量和所述字节码词向量进行拼接后形成拼接词向量,并利用所述拼接词向量生成所述待注释源代码的注释结果。</td>   <td>G06F8/73</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄进;              陈鹏飞;                   张涛       </td>   <td>中山大学</td>   <td>基于事件分析的故障定位方法、装置、电子设备及介质</td>   <td>广东省</td>   <td>CN116756021A</td>   <td>2023-09-15</td>   <td>本发明公开了一种基于事件分析的故障定位方法、装置、电子设备及介质,方法包括：在目标系统模拟故障注入；其中,目标系统基于分布式运行时搭建得到；获取故障注入产生的事件数据,对事件数据进行持久化保存；对事件数据进行分组排序,得到若干不同的事件序列；对事件序列中的每条事件进行解析,生成事件模板；通过无监督方法对事件模板进行异常检测,得到变化故障；变化故障包括导致事件序列顺序变化的序列事件异常和导致事件时间间隔变化的性能问题；基于变化故障进行故障定位,确定异常事件序列,进而定位目标系统的异常部分。本发明能够基于事件分析进行准确的故障定位,可广泛应用于计算机技术领域。</td>   <td>1.一种基于事件分析的故障定位方法,其特征在于,包括：在目标系统模拟故障注入；其中,所述目标系统基于分布式运行时搭建得到；获取所述故障注入产生的事件数据,对所述事件数据进行持久化保存；对所述事件数据进行分组排序,得到若干不同的事件序列；对所述事件序列中的每条事件进行解析,生成事件模板；通过无监督方法对所述事件模板进行异常检测,得到变化故障；所述变化故障包括导致事件序列顺序变化的序列事件异常和导致事件时间间隔变化的性能问题；基于所述变化故障进行故障定位,确定异常事件序列,进而定位所述目标系统的异常部分。</td>   <td>G06F11/36;G06F11/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄袁;              徐福仁;              陈湘萍;                   郑子彬       </td>   <td>中山大学</td>   <td>代码缺陷预测与定位方法、装置、存储介质及计算机设备</td>   <td>广东省</td>   <td>CN116756041A</td>   <td>2023-09-15</td>   <td>本申请提供了代码缺陷预测与定位方法、装置、存储介质及计算机设备,方法包括：获取待检测变更代码数据；获取目标代码缺陷预测与定位模型；将待检测变更代码数据输入目标代码缺陷预测与定位模型,根据待检测变更代码数据,得到变更代码语义特征,以及利用目标代码缺陷定位器对待检测变更代码数据进行缺陷定位处理,得到每个变更代码行的缺陷概率,并根据各个变更代码行的缺陷概率,得到变更代码结构特征,通过目标代码缺陷预测器对统计类特征、变更代码语义特征和变更代码结构特征进行缺陷预测处理,得到缺陷预测结果,当缺陷预测结果为存在缺陷变更时,根据各个变更代码行的缺陷概率,确定缺陷定位结果。如此,可以提高缺陷预测与定位模型性能。</td>   <td>1.一种代码缺陷预测与定位方法,其特征在于,所述方法包括：获取待检测变更代码数据,所述待检测变更代码数据包括多个变更代码行；获取预先训练的目标代码缺陷预测与定位模型,所述目标代码缺陷预测与定位模型包括目标代码缺陷预测器与目标代码缺陷定位器；将所述待检测变更代码数据输入至所述目标代码缺陷预测与定位模型,对所述待检测变更代码数据进行代码语义特征提取处理,得到变更代码语义特征,以及利用所述目标代码缺陷定位器对所述待检测变更代码数据进行缺陷定位处理,得到每个所述变更代码行的缺陷概率,并根据各个所述变更代码行的缺陷概率,得到变更代码结构特征,通过所述目标代码缺陷预测器对预设的统计类特征、所述变更代码语义特征和所述变更代码结构特征进行缺陷预测处理,得到所述待检测变更代码数据的缺陷预测结果,当所述缺陷预测结果为存在缺陷变更时,根据各个所述变更代码行的缺陷概率,将存在缺陷变更的目标代码行作为缺陷定位结果,以输出所述待检测变更代码数据的代码缺陷预测与定位结果。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨俊杰;              周翠英;                   刘镇       </td>   <td>中山大学</td>   <td>一种多层次TIN地质模型的连续剖切面实时渲染封闭的方法</td>   <td>广东省</td>   <td>CN116758199A</td>   <td>2023-09-15</td>   <td>本发明涉及三维地质建模模型可视化应用技术领域,尤其是一种多层次TIN地质模型的连续剖切面实时渲染封闭的方法。主要是通过多层次TIN模型建模模块及程序设计模型可视化模块实现于可视化环境中渲染多层次TIN地质模型并对模型进行可视化操作。具体而言,通过程序设计模块中的裁剪属性设置可对模型进行连续剖切；通过程序设计模块中的双重模板测试功能可获取剖切断面位置处的像素并分层设置各地层材质属性,随后实时渲染于该剖面位置处,由此综合实现连续剖切TIN地质模型并实时渲染剖切断面的效果；最后再添加外表面模型组合成完整模型,进而实现实时封闭断面缺口的连续剖切,由此尝试解决多层次TIN地质模型的剖切可视化分析中剖切面空心显示的问题。本发明省去了繁多的空间线段与平面求交点运算及求取交线的运算过程,而是在面这一尺度中直接分层渲染各断面材质,计算量大为减少,能实现实时剖切；同时本方法能实时渲染剖切填充面,能实现空心模型的封闭剖切。</td>   <td>1.一种多层次TIN地质模型的连续剖切面实时渲染封闭的方法,其特征在于,包括如下步骤：首先,依据钻孔数据建立多层次TIN三维地质模型；然后,采用裁剪平面切割地质模型,实现模型的连续切割进而得到剖切面空心的地质模型；其次,基于模板测试功能获取剖切模板断面位置处的像素,再在该位置分层设置各地层材质并实时渲染剖面,实现空心模型的封闭；最后,添加外表面模型组合成实时封闭的完整模型。</td>   <td>G06T15/00;G06T17/05;G06T17/20;G06T19/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              林彬;              王扬洋;              叶雪辀;              甘叔玮;                   杨夏       </td>   <td>中山大学</td>   <td>芯片气泡的检测方法、装置及存储介质</td>   <td>广东省</td>   <td>CN110097542B</td>   <td>2023-09-12</td>   <td>本发明公开了一种芯片气泡的检测方法,包括以下步骤：根据获取待测芯片的结构信息进行多层结构建模,再获取芯片图像,基于芯片结构轮廓对图像进行多区自动分割,识别出各目标区域,对所述芯片图像进行图像二值化处理,得到二值化图像,识别所述二值化图像中各目标区域的灰度值非零的像素点,并根据所述灰度值非零的像素点确定各目标区域的气泡轮廓,对所有区域的气泡进行相应的气泡大小以及气泡位置的统计。本发明还公开了一种芯片气泡的检测装置以及计算机可读存储介质。本发明提高了芯片气泡检测的效率。</td>   <td>1.一种芯片气泡的检测方法,其特征在于,所述芯片气泡的检测方法包括以下步骤：获取芯片图像,所述芯片图像通过X射线检测设备拍摄待检测芯片得到；对所述芯片图像进行图像二值化处理,得到二值化图像；根据所述二值化图像中灰度值非零的像素点,确定所述芯片图像中的气泡；所述对所述芯片图像进行图像二值化处理,得到二值化图像的步骤之前,还包括：提取所述芯片图像的预设区域图像,根据所述待检测芯片的层次结构信息在芯片图像中识别出目标区域,并将目标区域识别后的所述预设区域图像作为用于进行图像二值化处理的芯片图像,所述预设区域根据为芯片图像和模板图像重叠时,确认得到的芯片的外边缘和芯片的内腔区域的边缘之间的区域,所述模板图像为芯片内腔区域图像；所述层次结构信息包括芯片各个物理结构层的结构信息和层间位置；所述根据所述二值化图像中灰度值非零的像素点,确定所述芯片图像中的气泡的步骤包括：识别所述二值化图像各个目标区域的灰度值非零的像素点,并根据灰度值非零的像素点在每个目标区域像素范围内搜索疑似同一气泡的气泡轮廓,将全图搜索到的所有目标区域的气泡的气泡轮廓进行轮廓不良修复；基于修复后的所述气泡轮廓确定各个目标区域中的气泡数量；对所有所述目标区域的气泡数量进行求和运算,以得到所述芯片图像中的气泡数量；所述将全图搜索到的所有目标区域的气泡的气泡轮廓进行轮廓不良修复的步骤包括：将全图搜索到的所有气泡轮廓中疑似同一气泡的气泡轮廓相互连接,使其成为完整的气泡,或者,使用插值的方法使气泡轮廓完整。</td>   <td>G06T7/00;G06T3/60;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              姬进财;              杨凌娜;              苗建明;              罗向欣;                   牛丽霞       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种海岛遥感影像集获得方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113129248B</td>   <td>2023-09-12</td>   <td>本发明公开了一种海岛遥感影像集获得方法、装置、设备及介质,方法包括：本发明获取初始海岛遥感影像集；对所述初始海岛遥感影像集进行筛选处理,确定第一海岛遥感影像集；对所述第一海岛遥感影像集进行预处理,确定第二海岛遥感影像集；将所述第二海岛遥感影像集输入到深度残差网络中,确定第三海岛遥感影像集；获取初始无人机-艇海岛遥感影像集；对所述初始无人机-艇海岛遥感影像集进行编辑处理,确定目标无人机-艇海岛遥感影像集；将所述第三海岛遥感影像集以及所述目标无人机-艇海岛遥感影像集输入到所述深度残差网络中,确定目标海岛遥感影像集；能够获得更加完备的、准确的、实时的海岛遥感影像集,能广泛应用于影像融合技术领域。</td>   <td>1.一种海岛遥感影像集获得方法,其特征在于,包括：获取初始海岛遥感影像集；对所述初始海岛遥感影像集进行筛选处理,确定第一海岛遥感影像集；对所述第一海岛遥感影像集进行预处理,确定第二海岛遥感影像集；将所述第二海岛遥感影像集输入到深度残差网络中,确定第三海岛遥感影像集；所述将所述第二海岛遥感影像集输入到深度残差网络中,确定第三海岛遥感影像集,包括：将所述第二海岛遥感影像集输入到所述深度残差网络中,提取所述第二海岛遥感影像集的图像特征向量,确定图像特征列向量；将所述图像特征列向量与参数矩阵相乘,并通过加权相加的方式向验证集的地面实况标签拟合,确定概率矩阵；根据所述概率矩阵,输出图像特征融合分类标签,对所述第二海岛遥感影像集进行分类,确定所述第三海岛遥感影像集；其中,所述深度残差网络包含输入层、隐含层以及分类层；在所述深度残差网络中,向所述输入层输入特征,经过所述隐含层进行深度特征提取,获得提取后的深度特征向量,将所述深度特征向量输入所述分类层,Softmax回归分类器经过矩阵相乘计算,输出属于所述输入特征的概率,进而映射到样本的类别标签上；将所述第二海岛遥感影像集中高光谱图像和激光雷达图像中的被标定过的所有样本分为三组,得到训练样本集,验证样本集和测试样本集；利用训练样本集分别从高光谱图像和激光雷达图像中提取空间特征；高光谱图像的空间特征包含纹理和形状信息,激光雷达图像的空间特征包括高程,纹理和形状信息；高光谱图像的空间特征被提取出来作为深度残差网络的一个输入；提取出的激光雷达图像空间特征作为深度残差网络的另一输入；提取空间特征后,可以得到三种特征,包括高光谱图像光谱特征,高光谱图像空间特征和激光雷达图像空间特征；将每种特征的训练样本及其地面真实情况标签分别输入深度残差网络模型,并且通过多次迭代更新深度残差网络模型的参数；通过计算验证集在临时模型的分类精度,使用验证集样本及其相应的标签来监督训练过程；选择在验证集上具有最高分类精度的深度残差网络中间模型作为最终选择的模型；在训练部分结束时,获得三个深度残差网络模型,分别对应于高光谱图像光谱特征、高光谱图像空间特征和激光雷达图像空间特征；将高光谱图像光谱特征,高光谱图像空间特征和激光雷达图像空间特征测试样本分别输入三个对应的深度残差网络模型,获得每种特征对应的概率矩阵,并通过加权求和的方式重构三个概率矩阵；并使用验证集样本的融合特征和验证集标签用来计算测试集样本的重构参数,得到三个最终的深度残差网络模型；将海岛所有的高光谱图像光谱特征、高光谱图像空间特征和激光雷达图像空间特征样本分别输入到三个最终的深度残差网络模型中,获得三个概率矩阵,并通过加权相加的方式向验证集的地面实况标签拟合；所获得的加权参数用于重构三个测试样本的概率矩阵；利用测试集重构后的概率矩阵来输出最终的图像特征融合分类标签,对海岛所有高光谱图像和激光雷达图像数据样本进行融合分类,确定所述第三海岛遥感影像集；获取初始无人机-艇海岛遥感影像集；对所述初始无人机-艇海岛遥感影像集进行编辑处理,确定目标无人机-艇海岛遥感影像集；将所述第三海岛遥感影像集以及所述目标无人机-艇海岛遥感影像集输入到所述深度残差网络中,确定目标海岛遥感影像集。</td>   <td>G06T5/50;G06V10/764;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王帅;              陈明昊;                   张佳钟       </td>   <td>中山大学</td>   <td>一种结构受损情况下网络综合性能优化的多任务进化算法</td>   <td>广东省</td>   <td>CN116739035A</td>   <td>2023-09-12</td>   <td>本发明公开了一种结构受损情况下网络综合性能优化的多任务进化方法,该方法包括：S1、根据种子集鲁棒影响力评估指标和网络鲁棒性评估指标,确定优化任务；S2、基于优化任务,执行初始化算子,生成初始种群；S3、对初始种群依次执行交叉算子、变异算子、面向任务的学习算子、面向结构的学习算子；S4、循环步骤S2-S3,直至满足预设条件,输出最优解,得到网络结构。使用本方法获得的网络结构可以在受损的情况下保持更好的性能。本发明可广泛应用于计算机应用领域。</td>   <td>1.一种结构受损情况下网络综合性能优化的多任务进化算法,其特征在于,包括以下步骤：S1、根据种子集鲁棒影响力评估指标和网络鲁棒性评估指标,确定优化任务；S2、基于优化任务,执行初始化算子,生成初始种群；S3、对初始种群依次执行交叉算子、变异算子、面向任务的学习算子、面向结构的学习算子和选择算子；S4、循环步骤S2-S3,直至满足预设条件,输出最优解,得到网络结构。</td>   <td>G06N3/006;G06N3/126</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈志广;              王永康;                   卢宇彤       </td>   <td>中山大学</td>   <td>文件系统的元数据管理方法、终端设备及计算机存储介质</td>   <td>广东省</td>   <td>CN116737659A</td>   <td>2023-09-12</td>   <td>本申请公开了一种文件系统的元数据管理方法、终端设备及计算机可读存储介质,涉及数据处理技术领域,本申请数据文件的管理方法包括：获取需要存储的文件对应的路径名,并基于所述路径名进行编码得到所述文件对应的初始键值格式；通过预设的预分配索引管理空间进行预分配操作以为初始键值格式分配对应的预分配索引数值从而得到预分配键值格式；基于预分配键值格式对预分配索引管理空间和预分配键值格式对应的父目录索引管理空间执行合并操作得到目标索引管理空间；按照目标索引管理空间内包含的索引数值为初始键值格式分配对应的目标索引数值以得到目标键值格式,并基于目标键值格式将文件存储在目标存储结构内。</td>   <td>1.一种文件系统的元数据管理方法,其特征在于,所述文件系统的元数据管理方法包括以下步骤：获取需要存储的文件对应的路径名,并基于所述路径名进行编码得到所述文件对应的初始键值格式；通过预设的预分配索引管理空间进行预分配操作以为所述初始键值格式分配对应的预分配索引数值从而得到预分配键值格式；基于所述预分配键值格式对所述预分配索引管理空间和所述预分配键值格式对应的父目录索引管理空间执行合并操作得到目标索引管理空间；按照所述目标索引管理空间内包含的索引数值为所述初始键值格式分配对应的目标索引数值以得到目标键值格式,并基于所述目标键值格式将所述文件存储在目标存储结构内。</td>   <td>G06F16/11;G06F16/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄袁;              李阳姿;              陈湘萍;                   郑子彬       </td>   <td>中山大学</td>   <td>模型训练方法、代码提交注释生成方法、装置及电子设备</td>   <td>广东省</td>   <td>CN116737228A</td>   <td>2023-09-12</td>   <td>本申请公开一种模型训练方法、代码提交注释生成方法、装置及电子设备,其中的模型训练方法从代码更改文本中提取代码的语义信息,并从基于抽象语法树的代码编辑序列中提取结构信息来捕捉代码的更改意图,模型采用双编码器结构,分别处理代码更改文本和代码编辑序列,训练得到的预测模型能够生成更高质量、准确度更高、可读性更强的代码提交注释。</td>   <td>1.一种模型训练方法,其特征在于,所述方法训练得到的模型用于生成代码提交注释,包括第一编码器、第二编码器和解码器,所述方法包括：获取代码更改文本和代码编辑序列,所述代码编辑序列表征代码结构信息；把所述代码更改文本和代码编辑序列分别输入所述第一编码器和第二编码器进行特征计算；所述解码器根据所述第一编码器和第二编码器的输出生成单词序列组成代码提交注释；利用优化算法优化模型参数得到用于生成代码提交注释的预测模型。</td>   <td>G06F8/73;G06N3/0455;G06N3/0442;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              汪瀚;              沈智华;              林彬;              覃军友;              杨夏;                   陈思洋       </td>   <td>中山大学</td>   <td>基于多特征融合的空间目标跟踪方法及系统</td>   <td>广东省</td>   <td>CN116740132A</td>   <td>2023-09-12</td>   <td>本发明公开了基于多特征融合的空间目标跟踪方法及系统,该方法包括：根据空间目标的轨道运动,得到空间目标运动模型；对单帧星图进行空间目标特征提取,得到高阶特征信息；结合空间目标运动模型与基于逻辑的轨迹起始方法对空间目标的轨迹进行初始化,得到初始疑似轨迹；根据高阶特征信息对初始疑似轨迹进行约束,得到初始目标轨迹。该系统包括：模型构建模块、特征提取模块、初始化模块和约束模块。通过使用本发明,提升算法整体实时性、准确性和鲁棒性,实现更短帧的目标真实轨迹确。本发明作为基于多特征融合的空间目标跟踪方法及系统,可广泛应用于天文观测领域。</td>   <td>1.基于多特征融合的空间目标跟踪方法,其特征在于,包括以下步骤：根据空间目标的轨道运动,得到空间目标运动模型；对单帧星图进行空间目标特征提取,得到高阶特征信息；结合空间目标运动模型与基于逻辑的轨迹起始方法对空间目标点进行初始化,得到初始疑似轨迹；根据高阶特征信息对初始疑似轨迹进行约束,得到初始目标轨迹。</td>   <td>G06T7/246</td>  </tr>        <tr>   <td>中国专利</td>   <td>         匡铭;              翁宗鹏;              肖晗;              翁伟祥;              陈淑玲;                   彭穗       </td>   <td>中山大学附属第一医院</td>   <td>一种病理图像patches提取与深度学习建模方法</td>   <td>广东省</td>   <td>CN116741347A</td>   <td>2023-09-12</td>   <td>本发明涉及计算机辅助病理诊断技术领域,具体公开一种病理图像patches提取与深度学习建模方法,包括以下步骤：步骤一：选取一张病理WSI图像,结合注意力机制,随机确定n个Patches作为采样中心；步骤二：在中心Patch的邻域中再随机抽取k张与中心Patch邻近的Patches；步骤三：将以上n*(k+1)张Patches作为n个Patch簇输入模型进行建模,通过本发明在采样过程中使用中心-近邻簇状采样方法,能够有效表征Patches之间的空间结构关系,同时,由于簇状采样视野范围广,能够覆盖一些大尺度病理结构,可表征更丰富的信息。</td>   <td>1.一种病理图像patches提取与深度学习建模方法,其特征在于,包括以下步骤：步骤一：选取一张病理WSI图像,进行网格划分,将其分割成Patches的集合,在Patches集合中,随机确定n个Patches作为n个簇状结构的采样中心；步骤二：在中心Patch的5*5的Patches网格邻域中再随机抽取k张与中心Patch邻近的Patches；步骤三：将以上n*(k+1)张Patches作为n个Patch簇输入模型进行建模。</td>   <td>G16H30/00;G16H50/20;G16H50/50;G06V10/40;G06V10/82;G06N3/045;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢晓华;              彭其阳;              杨凌霄;              赖剑煌;                   冯展祥       </td>   <td>中山大学</td>   <td>基于弱监督和度量学习的行人属性识别方法</td>   <td>广东省</td>   <td>CN113705439B</td>   <td>2023-09-08</td>   <td>本发明公开了一种基于弱监督和度量学习的行人属性识别方法,包括：获取原始数据集；基于原始数据集中的属性标签信息训练属性感兴趣区域定位网络,得到训练完成的属性感兴趣区域定位网络；以训练完成的属性感兴趣区域定位网络的参数作为行人属性识别网络预训练参数,基于原始数据集对行人属性识别网络进行训练,得到训练完成的属性识别网络；输入待测图像并基于训练完成的属性识别网络进行属性识别,得到属性识别结果。本发明在行人属性识别上具备较好的性能。本发明可广泛应用于图像属性识别领域。</td>   <td>1.一种基于弱监督和度量学习的行人属性识别方法,其特征在于,包括以下步骤：获取原始数据集；基于原始数据集中的属性标签信息训练属性感兴趣区域定位网络,得到训练完成的属性感兴趣区域定位网络；以训练完成的属性感兴趣区域定位网络的参数作为行人属性识别网络预训练参数,基于原始数据集对行人属性识别网络进行训练,得到训练完成的属性识别网络；输入待测图像并基于训练完成的属性识别网络进行属性识别,得到属性识别结果；所述属性感兴趣区域定位网络为多层级网络结构,各个层级均包括残差模块、属性预测模块和池化层,所述残差模块的网络结构采用残差网络resnet的残差结构,所述属性预测模块包括卷积层和批量归一化层；所述以训练完成的属性感兴趣区域定位网络的参数作为行人属性识别网络预训练参数,基于原始数据集对行人属性识别网络进行训练,得到训练完成的属性识别网络这一步骤,其具体包括：以训练完成的属性感兴趣区域定位网络的参数作为行人属性识别网络中特征提取器的预训练参数；将原始数据集中的行人图像输入至特征提取器；基于特征提取器的残差模块进行特征提取,得到特征X-l,l表示层级信息；将特征X-l输入至特征提取器的属性预测模块,得到预测属性特征A-l；所述预测属性特征A-l的维度为n×w×h,n为属性的个数,w和h分别为特征图的宽和高；将预测属性特征A-l输入至特征提取器的池化层,获取属性n在特征图的最大响应位置和/&gt;根据最大响应位置对特征X-l进行采样得到特征/&gt;代表第l层第n个属性对应的特征表达；对最后一层特征提取器的残差模块的输出进行平均池化操作得到行人全局特征f-(gobal)；将各个层级采样得到的特征与行人全局特征f-(gobal)进行拼接,得到融合特征f～n；将融合特征f～n输入至分类器,得到属性预测分数；基于属性预测分数、原始数据集中的真实标签和对比损失函数约束分类器,得到训练完成的属性识别网络。</td>   <td>G06V40/10;G06V10/25;G06V10/774;G06V10/80;G06V10/764;G06V10/82;G06N3/0895;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         况丽娟;                   戴宪华       </td>   <td>中山大学</td>   <td>一种基于多任务学习的目标抽取与极性分类模型</td>   <td>广东省</td>   <td>CN116719928A</td>   <td>2023-09-08</td>   <td>本发明涉及一种基于多任务学习的目标抽取与极性分类模型,在目标抽取子任务中引入多粒度卷积网络,并通过门控机制和注意力机制进行两个子任务的特征交互。多粒度卷积网络能保证抽取多个目标不遗漏,交互机制使得目标的极性不会混淆,加强了抽取与极性分类的关联。此外,由于目前对中文的细粒度情感分析研究也比较少,清洗了四个中文数据集,针对中英文数据集引入了中英文的BERT预训练模型作为词嵌入对模型进行训练,最后在八个数据集上的实验表明改进的模型在评估指标比原有模型有所提升。</td>   <td>1.一种基于多任务学习的目标抽取与极性分类模型MIAEPC,其特征在于,所述方法包括BERT词嵌入层、目标抽取子任务所加入的多粒度卷积网络、极性分类的局部上下文聚焦网络、特征交互层以及分类层,所述方法包括：BERT输入层中使用两个相同的BERT模型作为词嵌入和浅层特征共享层,分别提取局部信息和全局信息。每个BERT有12个编码层,每个输入句子都会在开头插入[CLS],结尾插入[SEP]。BERT先将每个单词用单词嵌入、句子嵌入和位置嵌入三种词嵌入相加得到初始词向量,再由12个编码层得到含有整个上下文语义信息的动态向量表示。</td>   <td>G06F16/35;G06F18/25;G06N3/0442;G06N3/0464;G06N3/047;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘天健;              周凡;              林谋广;                   刘宇       </td>   <td>中山大学</td>   <td>一种基于数据聚类识别虚假新闻的方法与系统</td>   <td>广东省</td>   <td>CN116719941A</td>   <td>2023-09-08</td>   <td>本发明公开了一种基于数据聚类识别虚假新闻的方法。包括：采集媒体上的新闻数据,形成一个包含真实新闻与虚假新闻的新闻数据集；提取前述新闻数据集中每个新闻的传播特征,生成每个新闻的传播特征向量；利用前述每个新闻的传播特征向量,对新闻数据集进行聚类,生成虚假新闻识别模型；将待检测新闻数据输入到前述虚假新闻识别模型中,输出新闻的真实性得分。本发明还公开了一种基于数据聚类识别虚假新闻的系统。本发明借助虚假新闻的传播特征构造相应的向量和模型,较传统的内容特征,传播特征容易量化、数量较少,存在稳定,因而本发明较其他发明成本低、效率高、识别更加稳定,能够实现跨模态、跨语言的虚假新闻检测。</td>   <td>1.一种基于数据聚类识别虚假新闻的方法,其特征在于,所述方法包括：构建新闻数据集,设计媒体网络爬虫,对媒体上的新闻数据进行采集,并存储采集的数据,将每个新闻的数据进行分类、清洗,并通过人工标注区分出数据集中每个新闻的真实性,最终形成一个包含真实新闻与虚假新闻的新闻数据集；在所述新闻数据集中,提取每个新闻的传播特征,提取的传播特征包括：传播时序特征、传播用户特征、传播反馈特征、传播热度特征,之后利用此四种特征,构建每个新闻的传播特征向量；构建新闻检测模型,采用K-means的方法对所述新闻数据集进行聚类,包括将所述每个新闻的传播特征向量作为一个点,选取数据集中的一个真实新闻和虚假新闻,作为两个聚簇各自的中心点,对需要进行聚类的每个样本新闻,分别计算其到两个中心点的距离,根据每个样本新闻到两个中心点的距离,将每个样本新闻分配到距离最短的中心点对应的类别中,并重新计算每个类别的中心点,将新的中心点作为类别的新中心点,反复迭代上述过程,直至达到最小误差变化,最终获得新闻检测模型；输入待检测的新闻数据,通过特征提取,获取待检测新闻的传播特征向量,并将这些传播特征向量导入到所述新闻检测模型中,计算新闻的真实性得分后,输出新闻检测结果。</td>   <td>G06F16/35;G06F18/23213;G06F18/213;G06F40/289</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王帅;              蔡顺;                   区兆熙       </td>   <td>中山大学</td>   <td>一种鲁棒影响力优化方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN116720293A</td>   <td>2023-09-08</td>   <td>本发明公开了一种鲁棒影响力优化方法、装置、电子设备及存储介质,本发明能够对候选节点的影响力性能进行有效评估,并具有计算代价小、数值在不同网络规模下可比较以及为候选节点集的选取提供指导意义等优点。其次,本发明还设计了一个综合评估网络节点鲁棒性和影响力性能的指标,该指标能够在网络发生级联故障的条件下,综合评价网络节点抵抗级联故障传播的能力和影响力传播性能。最后,本发明采用Memetic算法设计了一种解决级联故障下的鲁棒影响力最大化问题的方法。相对于现有方法,该方法具有快速收敛至全局最优解、解的质量优于其他方法、高效率和高质量等优点,可广泛应用于计算机技术领域。</td>   <td>1.一种鲁棒影响力优化方法,其特征在于,包括：基于目标网络中各个节点的鲁棒性水平,获得各个所述节点的结构影响力；根据所述结构影响力,基于所述目标网络的各个所述节点生成初始种群；以所述初始种群作为第一种群,对所述第一种群进行交叉操作,获得第二种群；对所述第二种群进行变异操作,获得第三种群,并对所述第三种群进行搜索操作；其中,所述初始种群、所述第一种群、所述第二种群和所述第三种群均包括若干个体,各所述个体包括若干所述节点；对所述第一种群和所述第三种群进行适应度评估处理,获得所述第一种群和所述第三种群中各所述个体的鲁棒影响力；基于所述鲁棒影响力从所述第一种群和所述第三种群选择个体进行种群迭代,以迭代后的种群作为第一种群,然后返回所述对所述第一种群进行交叉操作,获得第二种群这一步骤,直至达到预设迭代次数,以最后一次迭代后的种群作为目标种群；对所述目标种群进行适应度评估处理,获得所述目标种群中所述鲁棒影响力最大的个体作为种群最优解。</td>   <td>G06F30/18;G06F30/27;G06F111/06;G06F119/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>              肖凡       </td>   <td>中山大学</td>   <td>MVT型铅锌矿成矿预测方法、装置、计算机设备及存储介质</td>   <td>广东省</td>   <td>CN116720976A</td>   <td>2023-09-08</td>   <td>本申请适用于矿产资源预测技术领域,提供了一种MVT型铅锌矿成矿预测方法、装置、计算机设备及存储介质,其中方法包括：获取MVT型铅锌矿的地质构造信息,矿石的物理参数以及流体参数；根据经验模态分解方法对成矿系统进行分解,获得多个物理过程模型；根据物理过程模型构建多个数值模拟模块,并结合地质构造信息,矿石的物理参数以及流体参数进行成矿地质作用过程中的力-热-流-质-化学五场耦合多物理场数值模拟计算,得到多个成矿条件参数；根据多个成矿条件参数以及成矿预测模型确定MVT型铅锌矿的成矿预测结果,本申请通过经验模态分解的方法将复杂的成矿系统拆分成简单物理过程,通过机器学习对模拟参量进行分析,可以更加精确地划定找矿靶区。</td>   <td>1.一种MVT型铅锌矿成矿预测方法,其特征在于,包括：获取MVT型铅锌矿的地质构造信息,矿石的物理参数以及流体参数；根据经验模态分解方法对成矿系统进行分解,获得多个物理过程模型,所述物理过程模型至少包括力学模型、传热模型、流体运移模型；根据所述物理过程模型构建多个数值模拟模块,并结合所述地质构造信息,矿石的物理参数以及流体参数进行成矿地质作用过程中的力-热-流-质-化学五场耦合多物理场数值模拟计算,得到多个成矿条件参数,所述成矿条件参数至少包括应力场参数、温度场参数、流体场参数、质量传递场参数以及化学场参数；根据所述多个成矿条件参数以及成矿预测模型确定所述MVT型铅锌矿的成矿预测结果；其中,所述成矿预测模型是基于预设的机器学习算法训练生成的；所述力-热-流-质-化学五场耦合多物理场至少由基于MVT型铅锌矿的勘探资料所建立的MVT型铅锌矿几何模型与基于力、热、流、质、化学多物理场的动力学方程所建立的多个数值模拟模块结合组成。</td>   <td>G06Q50/02;G06Q10/04;G06F30/27;G06F30/28;G06F119/08;G06F119/14;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘新宇;              叶艺山;                   邓振淼       </td>   <td>中山大学</td>   <td>基于毫米波雷达与摄像头的自动标定方法及系统</td>   <td>广东省</td>   <td>CN116721160A</td>   <td>2023-09-08</td>   <td>本发明涉及传感器融合技术,为基于毫米波雷达与摄像头的自动标定方法及系统,其方法包括：通过雷达获得N个雷达检测目标,通过摄像头获得M个图像检测目标,并分别进行特征提取,获得相应的特征向量；根据雷达检测目标、图像检测目标的特征向量之间的匹配概率、欧式距离,求取雷达检测目标、图像检测目标的特征向量之间的对应关系,作为雷达检测目标与图像检测目标之间的匹配关联结果；根据所述匹配关联结果,估计摄像头参考坐标系和雷达参考坐标系之间的外部参数。本发明将毫米波雷达和摄像头的自动标定转化为求解最优传输问题,以估计出外参,无需特定的参照物；当雷达和的相机相对位置发生变化时,能够自动地适应调节外参。</td>   <td>1.一种基于毫米波雷达与摄像头的自动标定方法,其特征在于,包括步骤：通过雷达获得N个雷达检测目标,通过摄像头获得M个图像检测目标,分别对检测到的雷达检测目标和图像检测目标进行特征提取,获得相应的特征向量；根据雷达检测目标的特征向量和图像检测目标的特征向量之间的匹配概率、欧式距离,求取雷达检测目标的特征向量和图像检测目标的特征向量之间的对应关系,作为雷达检测目标与图像检测目标之间的匹配关联结果；根据雷达检测目标与图像检测目标之间的匹配关联结果,估计摄像头参考坐标系和雷达参考坐标系之间的外部参数,完成毫米波雷达和摄像头之间的自动标定。</td>   <td>G06T7/80;G06V10/75;G06V10/74;G01S7/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              孟浩;                   李博洋       </td>   <td>中山大学</td>   <td>一种高动态范围场景下基于RGB与DVS图像融合的视差图增强方法</td>   <td>广东省</td>   <td>CN112396562B</td>   <td>2023-09-05</td>   <td>本发明属于机器人感知领域,更具体地,涉及一种高动态范围场景下基于RGB与DVS图像融合的视差图增强方法。包括：S1.部署双目RGB相机以及DVS相机,并对双目RGB相机以及DVS相机进行标定；S2.采集场景中双目相机RGB图像以及DVS图像,经过配准之后进行多尺度加权融合；S3.为融合后的图像生成针对计算机视觉的HDR图像；S4.基于步骤S3生成的HDR图像使用改进后的双目立体匹配算法SGM生成视差图。在隧道这类成像动态范围较大的场景中,解决相机出现的欠曝光以及高曝光问题,提高生成图像的质量,同时针对图像边缘区域不连续、不稳定的问题,通过引入其他信息源的方式,尽可能丰富边缘细节信息,提高最终生成的视差图在图像边缘处的准确率。</td>   <td>1.一种高动态范围场景下基于RGB与DVS图像融合的视差图增强方法,其特征在于,包括以下步骤：S1.部署双目RGB相机以及DVS相机,并对双目RGB相机以及DVS相机进行标定；S2.采集场景中双目相机RGB图像以及DVS图像,经过配准之后进行多尺度加权融合；S3.为融合后的图像生成针对计算机视觉的HDR图像；由于光线条件变化剧烈出现的曝光过度以及曝光不足的问题会严重影响融合图像的质量,通过自动多曝光控制方法得到两组不同曝光程度的图像,然后在这两组图像上应用改进过像素权重计算公式的Mertens算法得到HDR图像；生成HDR图像具体包括以下步骤：计算每个像素的响应的测量值,公式如下：                  式中,k＝0表示低曝光图像,k＝1表示高曝光图像,I-(i,j)表示图像在(i,j)处的灰度值,δ是一个常数；然后计算低曝光以及高曝光图像每一个像素的初始权重,公式如下：W-(i,j,k)＝min{w-CC-(i,j,k)+w-EE-(i,j,k),1}其中,C-(i,j,k)表示低曝光或者高曝光在(i,j)处的Constrast权重,w-C以及w-E分别表示两者的权重系数；通过优化权重计算公式增强结果的数值稳定性,公式如下:                  其中,N表示不同曝光图像的数量；W-(i,j,k′)表示第k'种曝光图像在下标(i,j)处的初始权重；最后通过公式加权得到HDR图像,I-(i,j,k′)表示第k'种曝光图像在(i,j)处的灰度值；S4.基于步骤S3生成的HDR图像使用改进后的双目立体匹配算法SGM生成视差图；改进后的SGM算法中,首先使用具备光照不变性的Census变换代替原有SGM算法中的互信息MI去计算视差匹配代价,然后基于十字交叉邻域去进行代价聚合提高算法在灰度信息、深度信息不连续情况下的性能,最后按照SGM算法中的步骤进行视差计算以及视差优化。</td>   <td>G06T5/00;G06T5/50;G06T7/13;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马志浩;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于图结构数据的关系挖掘方法及系统</td>   <td>广东省</td>   <td>CN112396184B</td>   <td>2023-09-05</td>   <td>本发明公开了一种基于图结构数据的关系挖掘方法及系统,该方法包括：S1、获取图像并解析,得到图结构数据；S2、基于任务层对图结构数据进行处理,在图结构上做关系推理,得到子任务；S3、根据子任务完成与环境的交互,得到对应奖励；S4、将对应奖励反馈到任务层；S5、循环步骤S2-S4,直至完成得到最大奖励的子任务。该系统包括：物体及关系检测模块、任务层模块、动作层模块、反馈模块和循环模块。本发明直接建模并利用物体之间的关系,在达到同样的性能时能提供的解释性能。本发明作为一种基于图结构数据的关系挖掘方法及系统,可广泛应用于强化学习领域。</td>   <td>1.一种基于图结构数据的关系挖掘方法,其特征在于,包括以下步骤：S1、获取图像并解析,得到图结构数据；S2、基于任务层对图结构数据进行处理,在图结构上做关系推理,得到子任务；S3、根据子任务完成与环境的交互,得到对应奖励；S4、将对应奖励反馈到任务层；S5、循环步骤S2-S4,直至完成得到最大奖励的子任务；所述基于任务层对图结构数据进行处理,在图结构上做关系推理,得到子任务这一步骤,其具体包括：S201、根据图结构数据得到关系边注意力权重；S202、根据图结构数据得到路径注意力权重；S203、根据关系边注意力权重和路径注意力权重对关系路径进行加权聚合,得到路径聚合信息；S204、根据路径聚合信息生成动作策略,得到子任务；所述根据图结构数据得到关系边注意力权重这一步骤,其具体包括：S2011、将图结构数据展开得到二维矩阵；S2012、将二维矩阵输入到Transformer框架,得到第一步的关系边注意力权重和隐向量；S2013、将隐向量和二维矩阵重新输入到Transformer框架,得到下一步的关系边注意力权重和对应隐向量；S2014、循环步骤S2013直至重复次数达到最大关系路径长度；S2015、输出每一步的关系边注意力权重和对应隐向量；所述根据图结构数据得到路径注意力权重这一步骤,其具体包括：S2021、将每一步的对应隐向量拼接成整合向量；S2022、将整合向量和二维矩阵输入到Transformer框架,得到路径注意力权重；所述根据关系边注意力权重和路径注意力权重对关系路径进行加权聚合,得到路径聚合信息这一步骤,其具体包括：S2031、选定当前推理步并根据当前推理步的关系边注意力权重将所有关系边信息进行加权,得到当前推理步的关系边信息；S2032、选定当前路径长度,根据当前路径的每一推理步的关系边信息,得到当前长度的路径信息；S2033、根据路径注意力权重对所有路径信息进行加权平均,得到路径聚合信息。</td>   <td>G06N5/025;G06N5/046;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   余木建       </td>   <td>中山大学</td>   <td>一种半色调图像隐写方法</td>   <td>广东省</td>   <td>CN112001832B</td>   <td>2023-09-05</td>   <td>本发明公开了一种半色调图像隐写方法,该方法包括：确定模式块大小；得到密度变化矩阵；得到不确定性变化矩阵；得到纹理变化矩阵；结合密度变化矩阵、不确定性矩阵和纹理变化矩阵,得到失真分数矩阵；对原图和失真分数矩阵进行乱序处理并结合秘密信息输入编码器得到加密图像；对加密图像进行加扰处理并结合秘密信息长度输入解码器得到嵌入信息。通过使用本发明,综合图库和单图的统计信息,着重半色调图像的密度特性,提高安全性和视觉不可察性。本发明作为一种半色调图像隐写方法,可广泛应用于信息安全领域。</td>   <td>1.一种半色调图像隐写方法,其特征在于,包括以下步骤：获取原图并确定模式块大小；计算原图各点所在模式块的密度变化并得到密度变化矩阵；统计图库中所有图像不同密度的模式块的纹理分布并得到不确定性变化矩阵；提取原图纹理分布直方图信息,计算各点翻转前后相邻模式块的平均纹理变化并得到纹理变化矩阵；结合密度变化矩阵、不确定性矩阵和纹理变化矩阵,得到失真分数矩阵；对原图和失真分数矩阵进行乱序处理并结合秘密信息输入编码器得到加密图像；对加密图像进行加扰处理并结合秘密信息长度输入解码器得到嵌入信息；所述统计图库中所有图像不同密度的模式块的纹理分布并得到不确定性变化矩阵这一步骤,其具体包括：根据模式块内像素值矩阵和模式块卷积核对模式块进行编号,得到对应的模式块编号值；统计图库中所有图像不同密度的模式块的纹理分布并生成键值对数组；遍历图库中所有图像并计算其中模式块内像素值为0的点的个数,得到图库中所有图像的模式块的密度；根据模式块编号值对键值对数组进行修改；计算不同键值的模式块数量在键值集合的总模式块数下的占比,并得到密度的纹理特征的不确定性；计算图像模式块的翻转前块密度和翻转后块密度,并得到不确定性变化矩阵；所述计算图像模式块的翻转前块密度和翻转后块密度,并得到不确定性变化矩阵这一步骤,其具体包括：获取图像的所有模式块；以模式块的中心点对模式块进行翻转并计算翻转前块密度和翻转后块密度；根据翻转前块密度和翻转后块密度得到模式块翻转前后的不确定性变化；得到图像的不确定性变化矩阵；所述结合密度变化矩阵、不确定性矩阵和纹理变化矩阵,得到失真分数矩阵这一步骤,其具体包括：对不确定性变化矩阵作预处理,得到预处理后的不确定性变化矩阵；对密度变化矩阵和预处理后的不确定性变化矩阵的分数值做加和均值处理,得到密度失真矩阵；将纹理变化矩阵和密度失真矩阵做点乘运算处理,得到失真分数矩阵。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   黄日聪       </td>   <td>中山大学</td>   <td>用于自监督单目深度估计的自提升学习方法、装置及设备</td>   <td>广东省</td>   <td>CN113724155B</td>   <td>2023-09-05</td>   <td>本发明公开了用于自监督单目深度估计的自提升学习方法、装置及设备,本发明通过不断地迭代使得用于监督网络训练的伪标签中的噪声数据得到有效剔除,从而训练得到一个收敛的深度网络,进一步利用了深度网络对噪声数据的去噪能力,使得深度网络可以在其本身通过自监督方法产生的带有噪声的伪标签中进一步提升自我的性能,且与现有的自监督训练方法相结合构成用于自监督单目深度估计的自提升学习方法,从而能够进一步提升网络的输出性能。</td>   <td>1.一种用于自监督单目深度估计的自提升学习方法,其特征在于,包括：S1：将训练数据集输入到已训练好的深度网络中,输出相应的第一深度结果,根据所述第一深度结果生成伪标签；其中,训练数据集是单目相机拍摄的视频经过处理后得到的多幅RGB图像；S2：使用当前的伪标签对目标深度网络进行监督训练,并将所述训练数据集输入到训练好的目标深度网络中,输出相应的第二深度结果；S3：根据当前输出的第二深度结果作为新的伪标签,重复步骤S2,直至所述目标深度网络收敛；所述已训练好的深度网络通过改进的自监督训练方法训练得到,所述改进的自监督训练方法的训练步骤包括：选取目标帧与相邻帧获取的图像光度差的最小值建立第一损失函数,根据所述第一损失函数对深度网络进行训练,得到第一级深度网络；建立用于使得图像相似区域的深度趋于一致的第二损失函数,根据所述第二损失函数对第一级深度网络进行训练,得到第二级深度网络；建立用于使得深度网络能够对翻转图像输出一致深度结果的第三损失函数,根据所述第三损失函数对所述第二级深度网络进行训练,得到训练好的深度网络；所述使用当前的伪标签对目标深度网络进行监督训练,包括：引入一致性掩膜；采用Berhu损失算法计算监督损失,所述监督损失可表示为：                                                      式中,表示一致性掩膜,/&gt;表示深度网络的输出结果,/&gt;表示伪标签,x表示像素点的坐标位置,/&gt;是分别对深度图像中的每个像素点进行计算,计算结果看成一个矩阵,/&gt;是指选取这个矩阵所有元素中的最大值；通过监督损失来训练新的深度网络。</td>   <td>G06T5/00;G06T7/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         欧阳子臻;              杨煜基;                   成慧       </td>   <td>中山大学</td>   <td>一种用于室外无人机的单目稀疏光流算法</td>   <td>广东省</td>   <td>CN112529936B</td>   <td>2023-09-05</td>   <td>本发明涉及目标跟踪技术领域,更具体的是涉及一种用于室外无人机的单目稀疏光流算法,包括以下步骤：S1：提取跟踪相邻两帧灰度图像的特征点,记为原始样本点集合；S2：剔除原始样本点集合中的无效特征点,得到抽样样本点集合,并通过抽样样本点集合得到最优模型H-(best)；S3：根据最优模型H-(best),得到无人机在图像坐标系下的速度；S4：将图像坐标系下的速度转换为摄像机坐标系下的速度。本方案中通过对原始样本点集合中的无效特征点进行剔除,即可以消除无人机飞行过程中其自身影子产生的特征点影响,使得无人机在室外飞行时速度估算更加精准。</td>   <td>1.一种用于室外无人机的单目稀疏光流算法,其特征在于,包括以下步骤：S1：提取跟踪相邻两帧灰度图像的特征点,记为原始样本点集合；S2：剔除原始样本点集合中的无效特征点,得到抽样样本点集合,并通过抽样样本点集合得到最优模型H-(best)；运用随机抽样一致性算法得到最优模型H-(best),具体包括以下步骤：S21：在原始样本点集合中随机寻找m-i对样本点；S22：利用m-i对样本点求得模型H；利用齐次方程组求得模型H,具体公式为：                  其中,(x～([n]),y～([n]))和(x′～([n]),y′～([n]))为第n组样本对,x～([1])为相邻两帧灰度图像中前一帧第一个特征点在图像中的x轴位置,y～([1])为相邻两帧灰度图像中前一帧第一个特征点在图像中的y轴位置,x～([n])为相邻两帧灰度图像中前一帧第m个特征点在图像中的x轴位置,y～([n])为相邻两帧灰度图像中前一帧第n个特征点在图像中的y轴位置,x′～((1))为相邻两帧灰度图像中当前帧第一个特征点在图像中的x轴位置,y～(′(1])为相邻两帧灰度图像中当前帧第一个特征点在图像中的y轴位置,x′～([n])为相邻两帧灰度图像中当前帧第m个特征点在图像中的x轴位置,y′～([n])为相邻两帧灰度图像中前一帧第n个特征点在图像中的y轴位置；S23：根据模型H计算得到局内点集I-i,并根据局内点集I-i得到当前最优局内点集I-(best)；具体包括以下步骤：S231：设置最大循环次数N；S232：计算原始样本点集合中的所有样本对与模型H的误差J～([n])具体公式为：J～([n])＝||p～([n])′-Hp～([n])||-2；其中,p～([n])′为相邻两帧灰度图像中前一帧第n个特征点,p～([n])为相邻两帧灰度图像中当前帧第n个特征点；S233：判断J～([n])是否小于误差阈值e,若是,则将第n个特征点归入到最优局内点集I-(best),若否,则将第n个特征点归入到局外点集进行剔除；S234：重复执行步骤S232到步骤S233,得到局内点集I-i；S235：分别求得局内点集I-i和最优局内点集I-(best)中所有元素数量S-i和S-(best),判断s-i是否小于s-(best),若是,则使I-(best)＝I-(best),若否,则使I-(best)＝I-i；其中,i为循环执行次数,i≤N；S24：根据当前最优局内点集I-(best)更新模型H,记为当前最优模型H-(best)；S25：计算原始样本点集合内所有样本点对当前最优模型H-(best)的误差和J-(sum),判断J-(sum)是否小于总模型误差阈值E,若是,则输出当前最优模型H-(best),若否,则进入步骤S26；S26：设置最大循环次数K,循环执行步骤S21到步骤S25,得到并输出当前最优模型H-(best)；S3：根据最优模型H-(best),得到无人机在图像坐标系下的速度；S4：将图像坐标系下的速度转换为摄像机坐标系下的速度。</td>   <td>G06T7/246;G06T7/269;G06T7/277</td>  </tr>        <tr>   <td>中国专利</td>   <td>         戴冽;              马剑达;              张学培;                   莫颖倩       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种预测类风湿关节炎患者一年关节破坏进展的系统</td>   <td>广东省</td>   <td>CN112599243B</td>   <td>2023-09-05</td>   <td>本发明公开了一种预测类风湿关节炎患者一年关节破坏进展的系统,所述系统包括免疫病理学标记评分测定模块、优化的滑膜的细胞免疫学评分计算模块、关节破坏进展风险比对模块和风险结果显示模块。所述系统首次采用滑膜相关的免疫病理学标记构建而成的评估指标--优化的滑膜的细胞免疫学评分作为预测指标来预测类风湿关节炎患者一年关节破坏进展的情况,可提前一年精确地筛选出关节破坏进展的高危患者,使高危患者能够提前一年得到强化治疗,从而更有效地减少或阻断这些患者出现关节破坏进展,这对于RA的精准治疗、降低致残率具有重要的意义和临床价值。</td>   <td>1.一种滑膜的细胞免疫学评分在制备预测类风湿关节炎患者一年关节破坏进展的系统中的应用,所述滑膜的细胞免疫学评分等于CD90、CD3、CD20、SL-CD68、CD31、L-CD68和CD55的免疫病理学标记评分的加和,或者滑膜的细胞免疫学评分等于CD90、CD3、CD20、SL-CD68、CD31、CD15和CD55的免疫病理学标记评分的加和,或者滑膜的细胞免疫学评分等于CD90、CD3、CD20、SL-CD68、CD31、CD15和L-CD68的免疫病理学标记评分的加和,或者滑膜的细胞免疫学评分等于CD90、CD3、CD20、SL-CD68、CD31和CD55的免疫病理学标记评分的加和,或者滑膜的细胞免疫学评分等于CD90、CD3、CD20、SL-CD68、CD31和L-CD68的免疫病理学标记评分的加和；或者滑膜的细胞免疫学评分等于CD90、CD3、CD20、SL-CD68、CD31和CD15的免疫病理学标记评分的加和；或者滑膜的细胞免疫学评分等于CD90、CD3、CD20、SL-CD68和CD31的免疫病理学标记评分的加和,所述L-CD68为衬里层巨噬样滑膜细胞的评分,SL-CD68为衬里下层单核/巨噬细胞的评分,所述CD55、CD90、CD3、CD20、L-CD68、SL-CD68、CD15或CD31的免疫病理学标记评分按阳性细胞浸润程度/数量采用半定量法评定,0分：无浸润/无表达；1分：轻度浸润/少量；2分：中度浸润/中量；3分：重度浸润/大量。</td>   <td>G16H50/30;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺丰;              张小雨;              刘凌波;              林倞;                   王青       </td>   <td>中山大学</td>   <td>一种多模态密集预测的深度信息传输模型的构建方法</td>   <td>广东省</td>   <td>CN112396000B</td>   <td>2023-09-05</td>   <td>本发明提供一种多模态密集预测的深度信息传输模型的构建方法,该方法首先,构建多个子网络是用于RGB图或热图表征学习,再构建一个子网络用于为模式共享；然后,构建一个信息聚集-分布模块IADM,用于完成平移不变的信息提取以及信息聚合传输、信息分布传输。本发明通过学习多模态对齐表示,建立一个包含信息聚合分布模块的多模态密集预测框架,能够充分捕捉不同模态之间的互补信息,很好的完成信息整合。在各种多模态密度预测任务中,该方案显示出了有效性和通用性。</td>   <td>1.一种多模态密集预测的深度信息传输模型的构建方法,其特征在于,包括以下步骤：S1：构建多个子网络是用于RGB图或热图表征学习,再构建一个子网络用于为模式共享；S2：构建一个信息聚集-分布模块IADM,用于完成平移不变的信息提取以及信息聚合传输、信息分布传输；所述步骤S1中,所有的子网络采用CSRNet开发,CSRNet由前端块和后端块组成,前端块包含VGG16模型的前10个卷积层,后端块包含6个扩展的卷积层；用于RGB图或热图表征学习的子网络基于CSRNet前端块,用于模式共享的子网络基于CSRNet的最后14个卷积层；若第j个扩张卷积层重命名为Conv5-j,同时在Convi-j中的RGB图特征、热图特征、以及模式共享的特征分别表示为在特征提取后,应用信息聚集-分布模块IADM学习多模态对齐表示,以完整地利用多模态信息；IADM是分层嵌入在不同层之后的,Conv1-2、Conv2-2、Conv3-3和Conv4-3,提取并传递所有特征的平移不变信息,使其相互增强；该过程表述为公式(1)：                  其中分别是/&gt;的增强特征；增强的特征被送入下一层进行进一步的表征学习；由于信息聚集-分布模块IADM的存在,输入RGB图像和热图像的互补信息被逐步对齐并嵌入到模式共享特征中；增强的特性被提供给CSRNet结构的后端块。</td>   <td>G06V20/52;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王瑞轩;              陶婉莹;              庄嘉鑫;              邢剑飞;              石威;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于抑制不相关特征的神经网络可解释性方法</td>   <td>广东省</td>   <td>CN112418408B</td>   <td>2023-09-05</td>   <td>本发明涉及深度学习技术领域,公开了一种基于抑制不相关特征的神经网络可解释性方法,包括：获取预训练的卷积神经网络模型；获取输入图像X；根据所述输入图像X,获取最小化的损失函数,保持选中神经元的激活情况不变,并抑制同一层其他神经元的激活去抹除不相关的视觉特征,同时减少优化结果中产生的噪声,以得到优化后的输入图像所述损失函数的公式为α和β为权重系数。本发明能在输入图像中保留只和该神经元激活相关的视觉信息,多个优化后的输入图像中的一致特征信息,能够帮助使用者理解分类网络中特定神经元所关注的特征。</td>   <td>1.一种基于抑制不相关特征的神经网络可解释性方法,其特征在于,包括：获取预训练的卷积神经网络模型；获取输入图像X；根据所述输入图像X,获取最小化的损失函数,保持选中神经元的激活情况不变,并抑制同一层其他神经元的激活去抹除不相关的视觉特征,同时减少优化结果中产生的噪声,以得到优化后的输入图像；所述损失函数的公式为,其中,/&gt;和/&gt;为权重系数,/&gt;为了保留与选中神经元激活相关的特征,/&gt;为了去除与选中神经元k-i激活不相关的特征,/&gt;为了减噪；采用如下公式得到优化的输入图像,保留与选中神经元激活相关的特征：          ,其中,对于第i个要理解的神经元,F-i为原始输入图像对应这个神经元的输出特征图,该输出特征图的大小为H×W,为使用优化后的输入图像作为网络模型输入时,对应神经元的输出特征图；采用如下公式得到优化的输入图像,去除与选中神经元k-i激活不相关的特征：          ,其中,N为神经元的数量；采用如下公式得到减噪后的输入图像：          ,其中,W-(0)和H-(0)为优化后的输入图像的宽度和高度。</td>   <td>G06N3/0464;G06N3/06;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡跃新;              唐小武;              黄栋;              区永康;                   郑亿庆       </td>   <td>中山大学孙逸仙纪念医院;华南农业大学</td>   <td>基于深度学习具有智能分类诊断功能的外周性眩晕疾病诊断系统</td>   <td>广东省</td>   <td>CN116705287A</td>   <td>2023-09-05</td>   <td>本发明公开了一种基于深度学习的具有智能分类诊断功能的外周性眩晕疾病诊断系统,所述诊断系统应用于智能辅助诊断系统服务器中,所述服务器通过数据传输线与信息录入端、诊断终端相连接,所述信息录入端用于采集患者的数据,并且将上述采集的数据传输到智能辅助诊断系统服务器中,所述诊断系统包括构建模块、训练模块、验证模块和诊断模块。该辅助诊断系统可以通过患者病史资料、听力学检查以及前庭功能检查综合分析实现对于外周性眩晕疾病智能分类诊断。</td>   <td>1.一种基于深度学习的具有智能分类诊断功能的外周性眩晕疾病诊断系统,其特征在于：所述诊断系统应用于智能辅助诊断系统服务器中,所述服务器通过数据传输线与信息录入端、诊断终端相连接,所述信息录入端用于采集患者的数据,并且将上述采集的数据传输到智能辅助诊断系统服务器中,所述诊断系统包括构建模块、训练模块、验证模块和诊断模块,其中：所述构建模块：用于从医院病例数据库中采集数据集,将采集的数据集构建并划分为测试集以及训练集；所述训练模块：用于加载预训练的神经网络模型,在所得到的训练集上微调预训练的神经网络模型,获得训练后的神经网络模型；所述验证模块：用于在测试集上验证所述训练后的神经网络模型的性能,筛选出最优神经网络模型；所述诊断模块：通过所述验证模块获得的最优神经网络模型,用于对外周性眩晕患者疾病特征进行智能分类诊断,输出该外周性眩晕患者的分类诊断结果,通过显示屏将患者的分类诊断结果显示出来,从而实现外周性眩晕疾病智能分类诊断。</td>   <td>G16H50/20;G16H50/70;G16H10/60;G06F18/243;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              陈崴;              温静怡;              赵兰琴;              吴倩妮;              李剑波;                   刘冬       </td>   <td>中山大学中山眼科中心;中山大学附属第一医院</td>   <td>一种终末期肾病疗效评估与并发症风险预测系统</td>   <td>广东省</td>   <td>CN116705326A</td>   <td>2023-09-05</td>   <td>本发明公开了一种终末期肾病疗效评估与并发症风险预测系统,包括：数据输入准备模块,用于获取并预处理血液透析和腹部透析患者的眼部检查数据和元数据；模型训练评估模块,用于使用机器学习算法及经典统计回归来训练模型,使用交叉验证方法并结合模型的准确率来选择模型；预测结果输出模块,用于分别通过所述疗效评估模型、所述并发症及预后风险预测模型输出相应分类结果与预测概率。采用本发明提供的实施例,在治疗前、治疗过程以及长期随访中,对终末期患者治疗情况及长期预后做出全面评估。</td>   <td>1.一种终末期肾病疗效评估与并发症风险预测系统,其特征在于,包括：数据输入准备模块,用于获取并预处理血液透析和腹部透析患者的眼部检查数据和元数据；所述元数据包括患者病历信息、疗效评估指标、并发症及预后标准数据；所述数据输入准备模块包括图像处理单元和元数据处理单元；所述图像处理单元用于根据所述眼部检查数据采用的检查类型对所述眼部检查数据中的眼部检查图像进行标准化处理；所述元数据处理单元,用于根据格式化数据类型对所述元数据进行清洗处理与统一格式化；模型训练评估模块,用于使用机器学习算法及经典统计回归或者统计来训练模型,使用交叉验证方法并结合模型的准确性来选择模型；模型训练评估模块包括特征选择单元、模型训练单元、模型评估选择单元和模型调整单元；所述特征选择单元用于分别从眼部检查数据、元数据和多模态数据选取模型的输入特征变量；所述多模态数据是关于眼部检查数据和元数据的组合数据；所述模型训练单元用于结合所述输入特征变量使用机器学习算法或者统计算法进行模型训练；所述模型评估选择单元用于根据模型的准确率AUC值,对训练后的模型进行筛选；所述模型调整单元用于根据疗效评估目标和并发症风险预测目标分别对筛选后的模型,采用该模型所用的特征和算法,调整相关变量参数,在全部开发数据集上训练最终的模型,得到疗效评估模型、并发症及预后风险预测模型；预测结果输出模块,用于分别通过所述疗效评估模型、所述并发症及预后风险预测模型输出相应预测概率及分类结果。</td>   <td>G16H50/30;G06N20/00;G06F18/24;G06F18/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苗建明;              郑若晗;              张淏酥;              钟良靖;              邵金鑫;              孙兴宇;              王燕云;              刘文超;              马成;              李卓浩;                   陈启超       </td>   <td>中山大学</td>   <td>一种水下不均匀光照图像增强方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116681606A</td>   <td>2023-09-01</td>   <td>本发明涉及计算机视觉技术领域,尤其涉及一种水下不均匀光照图像增强方法、系统、设备及介质,包括：利用自适应伽马校正算法和光照分布图,对获取到的亮度通道标准图像进行校正,得到亮度校正图像；根据亮度校正图像合成彩色图像,获取彩色图像在YUV颜色空间下各个像素点处的UV通道值；根据所有像素点处的UV通道值和预设的UV亮点阈值,确定YUV颜色空间下的Y通道白点位置；对彩色图像在所述Y通道白点位置处的各个通道进行白平衡调整,得到增强图像；对增强图像进行小波去噪处理,得到去噪图像。本发明提出的方法有效地提高了水下光照不均匀图像的质量,可以适用于具有各种复杂的水下场景,提升了增强效果的可靠性和稳定性。</td>   <td>1.一种水下不均匀光照图像增强方法,其特征在于,包括以下步骤：根据采集到的原始光照图像,获取光照分布图和亮度通道标准图像；利用自适应伽马校正算法和所述光照分布图,对所述亮度通道标准图像进行校正,得到亮度校正图像；根据所述亮度校正图像获取彩色图像,将所述彩色图像转换至YUV颜色空间,并获取YUV颜色空间下各个像素点处的UV通道值；根据所有像素点处的UV通道值和预设的UV亮点阈值,确定YUV颜色空间下的Y通道白点位置；对所述彩色图像在所述Y通道白点位置处的各个通道进行白平衡调整,得到增强图像；对所述增强图像进行小波去噪处理,得到去噪图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张荣辉;                   苟万婷       </td>   <td>中山大学</td>   <td>一种低光照场景下车道线检测增强方法、装置及终端设备</td>   <td>广东省</td>   <td>CN113781374B</td>   <td>2023-09-01</td>   <td>本发明公开了一种低光照场景下车道线检测增强方法、装置及终端设备,该方法对原始图像和经过增强后的图像沿着通道数的维度进行拼接获得六通道图像,并将六通道图像输入车道检测网络中。该方法帮助车道检测线提取更多有效的车道特征,提高了低光照场景下的数据识别精度,且没有产生额外的数据标注工作量及网络推理开销。</td>   <td>1.一种低光照场景下车道线检测增强方法,其特征在于,包括：通过车道线图像增强网络对设备采集的车道线图像进行图像增强处理,得到第一图像；其中,所述通过车道线图像增强网络对设备采集的车道线图像进行图像增强处理,得到第一图像,具体为：通过Zero-DCE图像增强网络,学习出一组所述车道线图像最佳光增强曲线的参数；将所述光增强曲线的参数应用于所述车道线图像的RGB通道的所有像素,以获得所述第一图像；将所述车道线图像与所述第一图像进行拼接处理,获得六通道图像；将所述六通道图像输入到训练好的车道线模型中进行检测,获得含有车道线预测位置的第二图像；其中,将车道线样本图像输入LaneNet网络中训练得到所述车道线模型；所述将车道线样本图像输入LaneNet网络中训练得到所述车道线模型,具体为：所述车道线样本图像需要进行尺寸转换处理、所述图像增强处理与所述拼接处理获得车道线样本六通道图像；将所述车道线样本六通道图像输入到LaneNet网络中,设置网络模型的初始学习率、学习衰减方式、训练次数；优化网络参数,降低所述网络中损失函数的值并趋于稳定,获得车道线模型；其中,LaneNet网络,具体为：语义分割分支以及实例分割分支；语义分割分支使用标准交叉熵损失函数训练分割网络,输出二进制分割图区分像素是否属于车道；实例分割分支由分割部分和聚类部分组成,该分支通过使用聚类损失函数,将分割分支识别的车道像素输出为通道像素的聚类,将同一车道的像素聚集在一起；在获得车道实例后,使用最小二乘法拟合一条曲线获得车道的参数化表达；其中,损失函数公式,具体为：                                    式中,L-(var)表示方差损失,L-(dist)表示距离损失；C表示车道线的条数；N-c表示聚类C中的像素数量；μ-c为聚类C中的向量平均值；X-i为第i个像素的嵌入向量；δ-v和δ-d为超参数,当向量与其聚类中心大于δ-v或聚类中心间的距离小于δ-d时计算损失；[x]-+表示max(0,x)；下标A、B表示两个不同的车道线；方差损失L-(var)让同一车道线的像素之间嵌入向量更近,形成一个聚类中心；距离损失L-(dist)让不同车道线像素的向量之间距离变大。</td>   <td>G06T5/50;G06T3/40;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              李伊昕;                   苏卓       </td>   <td>中山大学</td>   <td>促进购买行为的会话推荐方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113641811B</td>   <td>2023-09-01</td>   <td>本发明公开了一种促进购买行为的会话推荐方法与系统。包括：收集会话数据集并进行预处理与数据增强；把数据增强后的数据集建模为图结构输入到GNN网络中,并且通过停留时间的注意力层得到初步会话表示并存储在历史会话表示内存中；在该内存中查找与待推荐的会话相似度最高的若干个邻域会话表示,之后和初步会话表示连接得到最终会话表示；再与会话数据集中的所有物品计算余弦相似度,相似度最高的物品为推荐结果。本发明利用历史购买会话作为协同信息,可以有效建模用户的购买行为,并且在给用户进行推荐时,考虑历史会话中和用户存在相同偏好的用户行为,使得推荐算法可以更有效地预测用户的真实需求,从而给出更加准确的推荐结果。</td>   <td>1.一种促进购买行为的会话推荐方法,其特征在于,所述方法包括：从公开的数据集中收集包含物品信息、用户停留时间、用户购买行为在内的用户在电商平台的会话数据集；对所述会话数据集进行预处理,包括：对会话数据进行时间上的排序得到按时间排列的会话序列,去除掉只有一次点击的会话、删除出现频率过低的点击项；将所述预处理后的会话数据集根据是否产生购买行为划分为两个部分,点击数据集和购买数据集；对所述点击数据集和所述购买数据集进行数据增强,方式是对每一个数据进行片段式截取；把所述数据增强后的点击数据集和购买数据集建模为图结构,之后输入到GNN网络中,并且通过一个停留时间的注意力层,得到初步会话向量化表示数据集；将所述初步会话向量化表示数据集中产生了购买行为的会话存储在历史会话向量化表示内存中；对于待推荐的会话,在所述历史会话向量化表示内存中查找相似度最高的若干个邻域会话向量化表示,并且将这些邻域会话向量化表示和初步会话向量化表示数据集通过一个融合层连接到一起,得到最终会话向量化表示；用所述最终会话向量化表示与所述会话数据集中的所有物品计算余弦相似度,将相似度最高的物品作为推荐结果；其中,所述会话数据集,其会话数据中的每一项还包含了物品的序号item-id和物品被点击的时间戳time-stamp；其中,所述对会话数据进行时间上的排序得到按时间排列的会话序列,具体为：从会话数据集中获取共N个会话数据,用s表示会话,v表示被点击的物品项,将会话中的所有物品项v按所述物品被点击的时间戳time-stamp进行排序,则一个会话序列可以表示为s＝&lt;v-1,v-2,v-3…v-t&gt;,其中v的下标表示点击的先后顺序,t表示当前时间；通过所述每一个物品被点击的时间戳,计算相邻相似点击的所述time-stamp之差,得到会话的停留时间sdwell＝&lt;t-1,t-2,t-3…0&gt;,由于最后一项点击的停留时间未知因此将其设置为0,sdwell中的各项与s中的各项一一对应；其中,所述把所述数据增强后的点击数据集和购买数据集建模为图结构,之后输入到GNN网络中,并且通过一个停留时间的注意力层,得到初步会话向量化表示数据集,具体为：把所述数据增强后的点击数据集和购买数据集建模为图结构,输入到GNN模型中,经过训练后得到会话图中每一个图节点的向量化表示；所述会话图中每一个图节点的向量化表示,代表了一个物品在综合了相邻物品特征后的向量表示X＝{x-1,x-2,…,x-n}；将所述会话图中每一个图节点的向量化表示通过停留时间注意力层,按照停留时间的相对大小为权重结合起来得到每一个会话的向量化表示,其中最后一次点击的向量化表示的权值设置为1,对于会话s＝&lt;v-1,v-2,v-3…v-(k-1),v-k&gt;,停留时间sdwell＝&lt;t-1,t-2,t-3…t-(k-1),0&gt;,其中k为会话s所包含的点击次数,其初步会话向量化表示为：</td>   <td>G06F16/332;G06F16/9535;G06Q30/0601;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李秋萍;                   吴飒莎       </td>   <td>中山大学</td>   <td>一种复杂环境下的行人移动轨迹在线预测方法及系统</td>   <td>广东省</td>   <td>CN113569980B</td>   <td>2023-09-01</td>   <td>本发明公开了一种复杂环境下的行人移动轨迹在线预测方法及系统,该方法包括：基于智能移动设备探测一定时间内的行人位置数据,得到行人历史轨迹；根据行人历史轨迹提取行人多维度移动特征；基于行人多维度移动特征和行人历史轨迹训练支持向量回归模型,得到轨迹预测模型；动态更新轨迹预测模型的参数并基于轨迹预测模型预测行人未来时刻的轨迹。该系统包括：数据获取模块、特征提取模块、模型训练模块和预测模块。通过使用本发明,能够提高轨迹预测的准确率,降低智能移动设备与周围行人碰撞的风险。本发明作为一种复杂环境下的行人移动轨迹在线预测方法及系统,可广泛应用于智能交通领域。</td>   <td>1.一种复杂环境下的行人移动轨迹在线预测方法,其特征在于,包括以下步骤：基于智能移动设备探测一定时间内的行人位置数据,得到行人历史轨迹；根据行人历史轨迹提取行人多维度移动特征；基于行人多维度移动特征和行人历史轨迹训练支持向量回归模型,得到轨迹预测模型；动态更新轨迹预测模型的参数并基于轨迹预测模型预测行人未来时刻的轨迹；所述行人多维度移动特征包括位置特征、速度特征、加速度特征和阻力特征；所述根据行人历史轨迹提取行人多维度移动特征这一步骤,其具体包括：根据行人历史轨迹提取位置特征、速度特征、加速度特征和阻力特征；所述位置特征包括行人当前位置的x坐标、行人当前位置的y坐标和对应的时刻t,所述速度特征包括行人当前运动速度大小和行人当前运动速度方向,所述加速度特征包括行人加速度大小和行人加速度方向,所述阻力特征包括行人运动阻力大小和行人运动阻力方向；根据位置特征中相邻位置点的距离和时间间隔计算行人运动速度大小；根据位置特征中相邻位置点的偏移计算行人运动速度方向；根据相邻位置点的行人运动速度大小和时间间隔计算行人运动加速度大小；根据行人运动速度大小和行人运动速度方向计算行人运动加速度方向；根据可视域内其他行人及障碍物与当前行人的距离计算行人运动阻力大小和行人运动阻力方向；所述基于行人多维度移动特征和行人历史轨迹训练支持向量回归模型,得到轨迹预测模型这一步骤,其具体包括：以行人多维度移动特征为特征集,行人历史轨迹中下一时刻位置为结果集,对支持向量回归模型进行训练,建立特征集和结果集之间的映射关系,并预测k+1时刻的行人位置,k表示训练窗口大小；计算每个目标行人在k+1时刻预测位置与真实位置的误差；基于网格搜索法选择最优训练窗口和参数组合,得到轨迹预测模型。</td>   <td>G06V20/58;G06V40/20;G06V10/764;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李容;                   毛晓群       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>远程教育控制方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN116661916A</td>   <td>2023-08-29</td>   <td>本发明属于计算机技术领域,公开了一种远程教育控制方法、装置、设备及存储介质。该方法包括：在接收到远程教育指令时,根据所述远程教育指令确定待参与远程端和远程教育数据；获取各待参与远程端的界面信息；根据各待参与远程端的界面信息确定各待参与远程端的控制模式；按照各待参与远程端的控制模式对各待参与远程端进行控制,并发送所述远程教育数据至各待参与远程端。通过上述方式,按照各待参与远程端的控制模式对各待参与远程端进行控制,并发送远程教育数据至各待参与远程端,保证了对各待参与远程端进行远程控制时的合理性、及时性及准确性,并实现了对各待参与远程端的远程教育的同步性,同时还提升了用户体验。</td>   <td>1.一种远程教育控制方法,其特征在于,所述远程教育控制方法,包括：在接收到远程教育指令时,根据所述远程教育指令确定待参与远程端和远程教育数据；获取各待参与远程端的界面信息；根据各待参与远程端的界面信息确定各待参与远程端的控制模式；按照各待参与远程端的控制模式对各待参与远程端进行控制,并发送所述远程教育数据至各待参与远程端。</td>   <td>G06F9/451;G06F9/54;G09B5/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              李楚君;              徐祥鹏;              诸葛盛;                   何雨薇       </td>   <td>中山大学</td>   <td>一种基于骨架混合特征的远距离无人机鲁棒位姿估计方法</td>   <td>广东省</td>   <td>CN116664676A</td>   <td>2023-08-29</td>   <td>本申请涉及一种基于骨架混合特征的远距离无人机鲁棒位姿估计方法。所述方法包括：通过人体骨架检测网络Kapao进行无人机部件检测和无人机骨架提取,根据无人机部件检测结果中的部件中点对无人机骨架提取结果中的骨架端点进行修正,得到修正后的无人机骨架模型；构建由骨架端点构成的点约束方程组,以及由两两骨架端点组合构成的线约束方程组,求解得到无人机位姿的最优初始解；通过GM鲁棒算法对最优初始解进行异常值修正,得到无人机位姿的最优解。本发明能实现视线远距离无人机鲁棒位姿估计,位姿估计准确率高,预测速度快,能够满足大范围无人机编队中个体相对位姿实时计算与后续编队保持与协同控制的需求。</td>   <td>1.一种基于骨架混合特征的远距离无人机鲁棒位姿估计方法,其特征在于,所述方法包括：通过编队中第一无人机上的相机获取第二无人机的远距离无人机图像；根据所述远距离无人机图像通过人体骨架检测网络Kapao进行无人机部件检测和无人机骨架提取,得到无人机部件检测结果和无人机骨架提取结果；根据所述无人机部件检测结果中的部件中点对所述无人机骨架提取结果中的骨架端点进行修正,得到修正后的无人机骨架模型；根据所述修正后的无人机骨架模型构建由骨架端点构成的点约束方程组,以及由两两骨架端点组合构成的线约束方程组,根据所述点约束方程组和所述线约束方程组求解得到无人机位姿的最优初始解；通过German-Mcclure鲁棒算法对所述最优初始解进行异常值修正,得到无人机位姿的最优解。</td>   <td>G06T7/73</td>  </tr>        <tr>   <td>中国专利</td>   <td>         靳舒婷;              王天星;              李同文;              郑小坡;                   郭舟       </td>   <td>中山大学</td>   <td>一种融合物理优化模型与深度学习的智能火点识别方法</td>   <td>广东省</td>   <td>CN116665043A</td>   <td>2023-08-29</td>   <td>本发明公开了一种融合物理优化模型与深度学习的智能火点识别方法,包括以下步骤：步骤1：根据物理机理的模型进行阈值动态化处理,得到优化后的自适应阈值物理机理模型；步骤2：构建基于U-Net网络模型；步骤3：引入YOLOv5模型检测高亮目标；步骤4：根据优化后的物理机理模型与U-Net网络模型决策识别火点,获取遥感火点初筛结果；步骤5：将YOLOv5模型识别出的高亮目标在遥感火点初筛结果上作为误差剔除,提高遥感火点初筛结果识别的整体精度；解决固定阈值导致的火点误检与漏检问题,剔除长期严重干扰火点检测的城区各类热源误差,进一步提高整体精度；克服传统单一思路算法固有系统误差导致的普适性差等问题。</td>   <td>1.一种融合物理优化模型与深度学习的智能火点识别方法,其特征在于,包括以下步骤：步骤1：根据物理机理的模型进行阈值动态化处理,得到自适应阈值以及优化后的物理机理模型；步骤2：构建基于U-Net网络模型；步骤3：引入YOLOv5模型检测高亮目标；步骤4：根据优化后的物理机理模型与U-Net网络模型决策识别火点,获取遥感火点初筛结果；步骤5：将YOLOv5模型识别出的高亮目标在遥感火点初筛结果上作误差剔除,提高遥感火点初筛结果识别的整体精度。</td>   <td>G06V20/10;G06V20/13;G06V10/82;G06V10/774;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         江明;                   龚俊荣       </td>   <td>中山大学</td>   <td>基于自适应超像素最大熵聚类分割的深度图空洞补偿方法及系统</td>   <td>广东省</td>   <td>CN116664647A</td>   <td>2023-08-29</td>   <td>本发明涉及空间图像处理技术领域,提出一种基于自适应超像素最大熵聚类分割的深度图空洞补偿方法及系统,其中包括：通过ToF相机获取RBG图、深度图和幅度图；对经过预处理的RBG图I-1依次经过下采样、梯度化处理、梯度重构和分水岭操作后,利用AISNS算法获得RBG图像的最佳分类数量n-c,最后采用SPMEC算法对图I-1进行n-c类的场景聚类分割,得到场景聚类分割图；利用滑动窗口遍历所述深度图及其对应的幅度图,结合场景聚类分割图中相应像素点的场景聚类分类结果,将各空洞像素点判定为孤立点、边缘点或内部点；根据各空洞像素点的类别选择适配的补偿策略,结合场景聚类分割图中的分类信息进行像素点深度值的估算,完成深度图空洞补偿。</td>   <td>1.基于自适应超像素最大熵聚类分割的深度图空洞补偿方法,其特征在于,包括以下步骤：通过ToF相机获取RBG图、深度图和幅度图；对RBG图进行预处理；对经过预处理的RBG图I-1依次经过下采样、梯度化处理、梯度重构和分水岭操作后,利用自适应图像分割数量选择算法获得RBG图像的最佳分类数量n-c,最后采用超像素最大熵聚类分割算法对图I-1进行n-c类的场景聚类分割,得到场景聚类分割图；利用滑动窗口遍历所述深度图及其对应的幅度图,结合场景聚类分割图中相应像素点的场景聚类分类结果,将各空洞像素点判定为孤立点、边缘点或内部点；根据各空洞像素点的类别选择适配的补偿策略,结合场景聚类分割图中的分类信息进行像素点深度值的估算,完成深度图空洞补偿。</td>   <td>G06T7/50;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>              欧阳普云       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于特征融合的局部复发鼻咽癌自动识别方法及系统</td>   <td>广东省</td>   <td>CN116664993A</td>   <td>2023-08-29</td>   <td>本发明公开了一种基于特征融合的局部复发鼻咽癌自动识别方法及系统,涉及MRI影像处理技术领域,包括以下步骤,步骤1：获取MRI影像数据,基于分水岭算法对医疗图像数据进行标记处理,步骤2：获取鼻咽影像参照数据,预设复发鼻咽癌识别模型,对标记处理后的MRI影像数据进行轮廓特征提取,采集轮廓特征中的若干角点特征作为第一特征集合,采集鼻咽影像参照数据中的若干角点特征作为第二特征集合；步骤3：将第一特征集合、第二特征集合代入所述复发鼻咽癌识别模型中,得出复发鼻咽癌识别结果；步骤4：将复发鼻咽癌识别结果与鼻咽影像参照数据输入预先设定的神经网络训练,生成新的鼻咽影像参照数据,返回步骤2,直到所有MRI影像数据识别完成。</td>   <td>1.一种基于特征融合的局部复发鼻咽癌自动识别方法,其特征在于,包括以下步骤：步骤1：获取MRI影像数据,基于分水岭算法对医疗图像数据进行标记处理；步骤2：获取鼻咽影像参照数据,预设复发鼻咽癌识别模型,对标记处理后的MRI影像数据进行轮廓特征提取,采集轮廓特征中的若干角点特征作为第一特征集合,采集鼻咽影像参照数据中的若干角点特征作为第二特征集合,其中,鼻咽影像参照数据为无鼻咽癌病变的影像数据；步骤3：将第一特征集合、第二特征集合代入所述复发鼻咽癌识别模型中,得出复发鼻咽癌识别结果；步骤4：将复发鼻咽癌识别结果与鼻咽影像参照数据输入预先设定的神经网络训练,生成新的鼻咽影像参照数据,返回步骤2,直到所有MRI影像数据识别完成。</td>   <td>G06V10/80;G06V10/26;G06V10/764;G06V10/82;G06N3/0464;G06N3/047;G06N3/084;G16H30/20;G16H30/40;G16H40/67</td>  </tr>        <tr>   <td>中国专利</td>   <td>         段博曦;              胡杰灵;                   戴宪华       </td>   <td>中山大学</td>   <td>一种基于符号函数的双极性一次幂可变激活单元</td>   <td>广东省</td>   <td>CN116663611A</td>   <td>2023-08-29</td>   <td>针对深度神经网络的非线性传递层,本发明提出了一种基于符号函数的双极性一次幂激活单元,将其命名为FPLUS。这是一种新式的网络特征激活方法,受启发于代数理论的求逆操作,并在形式上利用了初等幂运算和极性符号,被赋予较为直观的仿生学意义。理论层面,该公式经由一定的先验知识和预期性质推导而来,具有严谨的逻辑证明；实验层面,其可行性在一系列典型数据集上通过了基准测试,结果表明该方法在众多激活函数中具备更佳的竞争优势,同时在常见的CNN框架中也能够稳定地兼容。此外,通过引入两个可固定或可学习的参数因子,该发明进一步将所提出的激活单元推广成更一般的形式,称之为PFPLUS,以此来扩充它的表达能力,而且相同的实验设置其结果也验证了这种改进的有效性。因此,可以认为本发明在丰富激活函数种类的工作上具有一定价值。</td>   <td>1.根据权利要求,本发明是一种基于符号函数的双极性一次幂可变激活单元,将其命名为PFPLUS,在参数因子均取常值1的特殊情形下,可简称之FPLUS。</td>   <td>G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林柏洪;              林增荣;                   郭裕兰       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种RGB-T语义分割方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN116664829A</td>   <td>2023-08-29</td>   <td>本发明公开了一种RGB-T语义分割方法、系统、装置及存储介质,获取待识别场景的RGB图像和红外图像；通过编码器分别对RGB图像和红外图像进行特征提取,得到RGB模态特征和红外模态特征；充分提取利用每一模态的信息；将RGB模态特征和红外模态特征输入概率特征融合模块进行融合特征偏好计算,得到各层次的空间融合因子；基于空间融合因子,对RGB模态特征和红外模态特征进行偏好融合,得到各层次的融合特征；将融合特征的多种不同偏好的结果视为某概率分布的样本；将各层次的融合特征输入解码器进行解码处理,得到分割结果。本发明能够有效融合RGB图像和红外图像的信息实现高精度语义分割,可广泛应用于图像处理技术领域。</td>   <td>1.一种RGB-T语义分割方法,其特征在于,包括：获取待识别场景的RGB图像和红外图像；通过编码器分别对所述RGB图像和所述红外图像进行特征提取,得到RGB模态特征和红外模态特征；其中,所述RGB模态特征和所述红外模态特征均包括多层次的模态特征；将所述RGB模态特征和所述红外模态特征输入概率特征融合模块进行融合特征偏好计算,得到各层次的空间融合因子；基于所述空间融合因子,对所述RGB模态特征和所述红外模态特征进行偏好融合,得到各层次的融合特征；将各层次的所述融合特征输入解码器进行解码处理,得到分割结果。</td>   <td>G06V10/26;G06V10/80;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄海风;              卢宇豪;              邵雄景;              潘波;              王小青;              王青松;                   赖涛       </td>   <td>中山大学</td>   <td>海洋涡旋场景数据构建方法、装置、设备及可读存储介质</td>   <td>广东省</td>   <td>CN116663236A</td>   <td>2023-08-29</td>   <td>本申请属于海洋涡旋仿真研究的技术领域,公开了一种海洋涡旋场景数据构建方法、装置、设备及可读存储介质,该方法包括：获取全球洋流数据中预设时间段预设经纬度范围内的目标海洋数据,所述目标海洋数据包括海表面速度数据、海表面高度数据以及海表面温度数据；对所述目标海洋数据中的海表面速度数据、海表面高度数据以及海表面温度数据分别进行预处理后进行联合判决,得到目标涡旋信息；获取预设场景比值阈值以及预设分辨率；基于目标涡旋信息、预设场景比值阈值以及预设分辨率对目标海洋数据进行范围截取和插值处理,得到目标海洋涡旋场景数据。通过本申请可以构建出直接用于合成孔径雷达仿真研究的海洋涡旋场景数据。</td>   <td>1.一种海洋涡旋场景数据构建方法,其特征在于,所述方法包括：获取全球洋流数据中预设时间段预设经纬度范围内的目标海洋数据,所述目标海洋数据包括海表面速度数据、海表面高度数据以及海表面温度数据；对所述目标海洋数据中的海表面速度数据、海表面高度数据以及海表面温度数据分别进行预处理后进行联合判决,得到目标涡旋信息；获取预设场景比值阈值以及预设分辨率；基于目标涡旋信息、预设场景比值阈值以及预设分辨率对目标海洋数据进行范围截取和插值处理,得到目标海洋涡旋场景数据。</td>   <td>G06F30/20;G06F113/08;G06F119/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘懿梅;              彭应林;              陈美宁;              陈利;              邓小武;                   祁振宇       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于MR图像智能勾画方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN116258671B</td>   <td>2023-08-29</td>   <td>本发明公开了一种基于MR图像智能勾画方法、系统、设备及存储介质,包括：获取初始MR图像和初始CT图像,并分别进行划分,对应得到多组第一MRI图像和第一CT图像；并同时作为第一神经网络模型的输入,对应输出多组第一器官预测概率图；依次计算第一器官预测概率图中危及区域器官的中心位置坐标,对应得到危及器官所在的第一图像；依次对第一图像分类,并对应使用不同的分割方式,对应得到全部靶区和危及器官的第一分割结果；确定肿瘤分割的目标区域,并其对应的第一MRI图像、第一CT图像和各危及器官对应的第一分割结果作为第二神经网络模型的输入,输出对肿瘤的第二分割结果。本发明能够对基于MR图像进行多器官同时快速自动精细分割。</td>   <td>1.一种基于MR图像智能勾画方法,其特征在于,所述方法包括：获取初始MR图像和初始CT图像,并分别按照区域和阈值进行划分,对应得到多组第一MRI图像和第一CT图像；将所述多组第一MRI图像和所述第一CT图像同时作为第一神经网络模型的输入,对应输出多组第一器官预测概率图；依次计算第一器官预测概率图中危及区域器官的中心位置坐标,对应得到危及器官所在的第一图像；根据危及器官的体积和与周围组织的对比度,依次对第一图像分类,并对应使用不同的分割方式进行第一分割,对应得到全部靶区和危及器官的第一分割结果；根据临床先验知识,确定肿瘤分割的目标区域,并将所述目标区域对应的第一MRI图像、所述第一CT图像、所述多组第一器官预测概率图和各危及器官对应的第一分割结果作为第二神经网络模型的输入,输出对肿瘤的第二分割结果,以实现基于MR图像的肿瘤分割。</td>   <td>G06T7/00;G06T7/13;G06T7/11;G06T7/62;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;              黎炜驰;              曾雪兰;                   刘永红       </td>   <td>中山大学</td>   <td>一种碳排放配额分配技术的数据质量评价方法</td>   <td>广东省</td>   <td>CN113095678B</td>   <td>2023-08-29</td>   <td>本发明提供一种碳排放配额分配技术的数据质量评价方法,包括如下步骤：步骤一,建立包括数据类型需求和数据层级需求的碳排放配额分配技术的数据需求模型；步骤二,建立以准确性、可靠性和可比性为基础的碳排放配额分配技术的数据质量评价指标体系；步骤三,基于数据质量评价指标体系对碳排放配额分配技术的数据质量进行评价。本发明通过开发了一个面向配额分配技术的数据质量评价指标体系,填补了本领域中碳排放配额分配技术的数据层级需求和数据质量评价指标体系的空白。且该评价指标体系的结果为政府及相关支撑机构的碳市场机制设计提供支持,以及对碳市场的启动及改进具有指导意义。</td>   <td>1.一种碳排放配额分配技术的数据质量评价方法,其特征在于：包括以下步骤：步骤一,建立碳排放配额分配技术的数据需求模型；步骤二,建立碳排放配额分配技术的数据质量评价指标体系；步骤三,通过所述数据质量评价指标体系对碳排放配额分配技术的数据质量进行评价；所述碳排放配额分配技术的配额方案采用了历史排放法或历史强度法或基准法；所述碳排放配额分配技术的数据需求模型包括数据类型需求和数据层级需求；所述数据类型需求包括产量、碳排放量、活动数据和计算因子；所述数据层级需求指表征数据的边界范围,一个企业可以表征为一系列产品生产工序的集合,产品的特征包括产品类别的细分程度、某一细分程度下的产品种类、某一细分程度下产品在产业链中的位置；所述碳排放配额分配技术的数据质量评价指标体系包括数据质量评估指标和评价标准；针对碳排放配额分配技术的数据需求开展数据质量评价,评价指标包括碳排放配额分配技术及数据质量管理内涵相结合的准确性、可靠性和可比性指标；根据评价标准、权重及评价对象的数据质量管理情况,可得到评价对象采用不同的碳排放配额分配技术在数据质量方面获得的评分,支撑政府管理者配额分配的政策制定；所述活动数据包括能源、物料消耗量；所述计算因子包括热值、碳含量、氧化率；所述活动数据和所述计算因子通过计算获得碳排放量；所述数据层级需求指表征数据的边界范围,一个企业可以表征为一系列产品生产工序的集合,每一个产品生产工序的范围记为P-(xyz)；其中,x表示产品类别的细分程度,y表示在某一细分程度下的产品种类,z表示在某一细分程度下产品在产业链中的位置；所述数据质量评价指标设有一级指标、二级指标和三级指标；所述准确性、可靠性和可比性指标属于一级指标；所述准确性的对应的二级指标为监测准确度,所述监测准确度对应的三级指标为产量数据的计量仪器误差、产量数据的计量系统认证、活动数据的计量仪器误差、活动数据计量系统认证、计算因子的监测频次和计算因子的实验室资质认证；所述可靠性对应的二级指标为面向政府的数据透明度、第三方机构核查、来自独立贸易合作方的商业交易证据；所述面向政府的数据透明度对应的三级指标均分别包括产量数据、活动数据、计算因子的面向政府的数据透明度；所述第三方机构核查对应的三级指标均分别包括产量数据、活动数据、计算因子的第三方机构核查；所述来自独立贸易合作方的商业交易证据对应的三级指标均分别包括产量数据、活动数据、计算因子的来自独立贸易合作方的商业交易证据；所述可比性对应的二级指标为配额分配技术和排放计算方法之间的差异；所述配额分配技术和排放计算方法之间的差异的三级指标为产量数据、活动数据、计算因子；所述一级指标的评价分数为各对应二级指标评价分数的算术平均值；所述二级指标的评价分数为各对应三级指标评价分数的算术平均值；所述评价标准具体的评判方法为：(1)准确性对应的三级指标,即产量数据和活动数据的计量仪器误差的评判规则：                  其中,G表示分数,U表示计量仪器的误差,i表示一个三级指标,s表示产品排放所涉及的能源/材料,P表示产品层级P-(xyz),a表示纳入碳市场管理的企业,U-B表示已有碳市场的管理要求；(2)可比性三级指标的评分规则：                  其中,G表示分数,a代表企业,i表示一个可比性三级指标,P表示产品层级P-(xyz),R表示由于企业报告的数据和配额分配技术的不可比性而导致的差异,R-B表示评判标准；(3)企业某一产品涉及的每种能源/物料的某个三级指标得分汇总分数的规则：                  其中,E表示能源/物料产生的排放,a表示纳入碳市场管理的企业,i表示一个三级指标,P表示产品层级P-(xyz),s表示产品排放所涉及的能源/材料,n表示能源/材料的数量；由此产生的排放量是根据已有碳市场中的监测和报告指南计算的；如果计算因子不可用,则根据准则中提供的默认值和类似企业的条件估计由此产生的排放；为了正确反映产品的总体排放,使用电力和热量的间接排放以避免双重计数的计算方式；电力和热使用的间接排放量由电力/热消耗和电力/热排放系数计算；电力/热排放因素的计算如下：                  其中,EF-(e/h)表示使用电/热的排放因子,E-(e/h)表示电力/热生产的直接排放,不包括余热以及余热发电,σ-(e/h)表示电力/热发电效率,OP-(e/h)表示电力/热生产,包括余热和由余热产生的电力；在评分过程中,电力/热生产的排放量是E-(e/h)×(1-σ-(e/h))；(4)汇总所有企业的某一产品层级的某个三级指标分数的规则：                  其中,E表示某企业生产某产品产生的排放,a表示纳入碳市场管理的企业,i表示一个三级指标,P表示产品层级P-(xyz),s表示产品排放所涉及的能源/材料,m表示企业的数量；(5)根据计算方法,计算因子还可以指定为热值、碳含量、氧化因子和其他参数；如果参数是相乘关系,则总分是每个参数分数的算术平均值；如果参数是相加关系中,则总分是每个参数分数的加权平均值,权重为以此参数计算得到的排放量为准；(6)由于历史排放法的数据要求不涉及产量,因此对于历史排放法,其产量数据的分数将保持在100.0％；(7)如果根据产品分类,产品层级P-(xyz)细分至某一层次x后不能再细分,则此产品在细分级别x的分数将等于级别x-1的分数；(8)产量和活动数据根据产品、能源、物料在企业的输入/输出和库存变化进行计算确定,相应的分数也是由输入/输出和库存变化的分数进行确定；如果库存可以容纳的燃料或物料少于企业年使用量的5％,则库存变化的分数将不予考虑；(9)如果某些能源或材料的计算因子只允许使用默认值,那么此能源或物料的计算因子的分数为100.0％。</td>   <td>G06Q10/0639;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   高月       </td>   <td>中山大学</td>   <td>基于分类器预测不确定性的注意力增强分布外图像检测法</td>   <td>广东省</td>   <td>CN112668657B</td>   <td>2023-08-29</td>   <td>本发明提供一种基于分类器预测不确定性的注意力增强分布外图像检测法,该方法考虑了分类器的不确定性,使得分类结果更加可靠,并且利用不确定性对特征进行加权,使分类器更加关注样本对于分类有利的区域,忽略掉分布内样本固有噪声带来的影响,极大地提升了softmax最大分类概率值在分布外样本检测任务中的有效性,以及其在两类数据中的区分性。对于分布外样本,利用不确定性计算出的特征注意力图会让分类器关注更加错误的区域,导致更低的自信分数,进而提升检测效果；本方法不会过度局限于训练数据,对于边缘样本不容易产生误判,可以得到更好的检测效果。</td>   <td>1.一种基于分类器预测不确定性的注意力增强分布外图像检测法,其特征在于,包括以下步骤：S1：图像重构特征提取以及降维处理；S2：利用S1得到的低维数据进行多分类概率计算,提取有效的类别概率特征；S3：将S1和S2得到的数据作为一分类器的输入得到数据异常的概率值；所述步骤S1的具体过程是：获取图像数据,首先将其输入至特征提取器提取出特征,如公式(1),提取出的特征输入至分类器获取分类结果,如公式(2),同时将特征输入至分类器的不确定性估计器获取分类结果的不确定性,如公式(3)：h＝F(x)     (1)y＝Softmax(C(h))    (2)σ～2＝log(1+exp(U(h)))    (3)其中x表示输入的图像数据,σ表示分类结果的偶然不确定性,F表示特征提取器,C表示分类器,U表示不确定性估计器；所述步骤S2的具体过程是：将S2中获得的不确定性对特征进行求导并进行梯度反转,如公式(4)此时数值为正的区域表示对不确定性贡献小,也就是相对比较确定的区域；进一步保留确定的区域,这也是需要关注的区域,忽略不确定的区域,也就是令数值为负的区域为0,如公式(5),再进行softmax,即可获取特征的注意力图,如公式(6)：</td>   <td>G06V10/764;G06V10/82;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张冬傲;              郑培嘉;                   程梓岩       </td>   <td>中山大学</td>   <td>一种加密JPEG图像的可逆信息隐藏方法</td>   <td>广东省</td>   <td>CN112308756B</td>   <td>2023-08-29</td>   <td>本发明提出一种加密JPEG图像的可逆信息隐藏方法,涉及多媒体信息安全的技术领域,解决了当前对加密JPEG图像可逆信息隐藏的研究未兼顾隐私安全和信息嵌入前后文件大小维持度的问题,首先根据JPEG图像的ZRV值对,分离出待嵌入额外信息的块,从块中再随机挑选出m×n个块,并将挑选出的m×n个块进行置乱,更改了原JPEG的结构,然后进行格式兼容加密,充分利用其头部的APPn字段文件数据部分,降低了边信息泄露的风险,而且在额外信息嵌入后,进行信息提取和图像恢复操作,一方面保证了图片拥有者的信息安全,另一方面控制了文件大小的增长,使文件大小不受嵌入的数据大小的影响。</td>   <td>1.一种加密JPEG图像的可逆信息隐藏方法,其特征在于,包括：S1.图像拥有者根据JPEG图像的ZRV值对(ZR,VLI),分离出待嵌入额外信息的块BM和块BO,从块BM和块BO中分别随机挑选出m×n个块,并将挑选出的m×n个块进行置乱；S2.将m×n个块中每一个块ZRV值对的VLI部分加密,作为JPEG图像数据部分；S3.将除m×n个块之外剩余块的二进制流Bstream加密,并将加密后的二进制流Bstream及最后一位块BM的位置LM加入JPEG图像头部的APPn字段,与步骤S2所得的JPEG数据部分组成加密JPEG图像；S4.信息嵌入者在加密JPEG图像的JPEG数据部分进行额外信息的嵌入,得到嵌入数据的加密JPEG图像；S5.信息提取者获得步骤S4所述嵌入数据的加密JPEG图像,进行信息提取后将加密JPEG图像还原至额外信息嵌入前的状态；S6.将还原至额外信息嵌入前状态的加密JPEG图像进行解密,恢复JPEG图像。</td>   <td>G06T1/00;G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   高月       </td>   <td>中山大学</td>   <td>基于生成对抗网络不确定性注意力增强分布外图像检测法</td>   <td>广东省</td>   <td>CN112668655B</td>   <td>2023-08-29</td>   <td>本发明提供一种基于生成对抗网络不确定性注意力增强分布外图像检测法,该方法引入了生成对抗网络,使得分类器的分类结果更加可靠,并且考虑了判别器的不确定性,并且利用不确定性对特征进行加权,使分类器更加关注分布内样本不同于分布外样本的区域,忽略掉两种数据容易混淆的区域,极大地提升了softmax最大分类概率值在分布外样本检测任务中的有效性,以及其在两类数据中的区分性。对于分布外样本,利用不确定性计算出的特征注意力图会让分类器关注更加错误的区域,导致更低的自信分数,进而提升检测效果；本方法不会使用判别器作为分布外样本的检测手段,对于边缘样本不容易产生误判,可以得到更好的检测效果。</td>   <td>1.一种基于生成对抗网络不确定性注意力增强分布外图像检测法,其特征在于,包括以下步骤：S1：图像输入特征提取器获得特征,并将特征输入至判别器判别是否为分布内样本,同时将特征输入至判别器的不确定性估计器获取判别结果的不确定性；S2：利用S1得到的判别器不确定性进行注意力图的计算,并用该注意力图对S1获取的特征进行加权；S3：将S1和S2得到的加权后的特征作为分类器的输入得到数据分类的概率值；所述步骤S1的具体过程是：获取图像数据,首先将其输入至特征提取器提取出特征,如公式(1),提取出的特征输入至分类器获取分类结果,如公式(2),同时将特征输入至分类器的不确定性估计器获取分类结果的不确定性,如公式(2)h＝F(x)    (1)y＝SoftmaxCD(h))    (2)σ～2＝log(1+exp(U(h)))    (3)其中x表示输入的图像数据,σ表示分类结果的偶然不确定性,F表示特征提取器,D表示生成对抗网络中的判别器,U表示判别器的不确定性估计器；将S2中获得的不确定性对特征进行求导并进行梯度反转,如公式(4)此时数值为正的区域表示对不确定性贡献小,也就是相对比较确定的区域；进一步保留确定的区域,这也是需要关注的区域,忽略不确定的区域,也就是令数值为负的区域为0,如公式(5),再进行softmax,即可获取特征的注意力图,如公式(6)：</td>   <td>G06V10/764;G06V10/82;G06N3/0475;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈创荣;                   成慧       </td>   <td>中山大学</td>   <td>一种双目视觉系统高精度且无拖影的视差计算方法</td>   <td>广东省</td>   <td>CN109816710B</td>   <td>2023-08-29</td>   <td>本发明涉及双目视觉系统处理的技术领域,更具体地,涉及一种双目视觉系统高精度且无拖影的视差计算方法。本发明提供的方法用于在自然场景中,利用双目视觉系统计算出精确像素视差,并且不同于已有系统,本发计算得到的场景深度没有普遍存在的过度平滑现象,无需复杂的后处理,能直接用于下游任务。该方法首先对像素的视差进行分布建模,利用卷积神经网络模拟传统方法,并对每个像素点输出一个像素的视差分布。</td>   <td>1.一种双目视觉系统高精度且无拖影的视差计算方法,其特征在于,包括以下步骤：S1.对输入的左右两幅图像,提取特征,得到左右两幅图像在1/4分辨率下特征；S2.根据提取得到的左右图特征,构建4D的代价体V；S3.进行代价聚合,得到视差值的对数似然估计,并上采样到原图分辨率,得到每个像素的可能视差值的对数似然估计L；S4.对得到的对数似然估计,每个像素在视差维度上做归一化操作,得到每个像素的视差概率分布；得到每个像素的视差概率分布,如下：          其中N为视差枚举值；S5.找出概率值最大的峰,做进一步推断,得到更精确的视差概率分布；得到每个像素的视差概率分布P-i后,首先找出概率值最大的峰,由其视差值d-l和d-r界定,然后对P-i做进一步推断,得到更精确的视差概率分布,具体地：                  S6.基于得到的精确视差概率分布,通过加权平均操作得到每个像素视差的最终估计值；基于得到的精确视差概率分布通过加权平均操作得到每个像素视差的最终估计值：</td>   <td>G06T7/55</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋婷婷;              刘明林;              骆伟祺;                   郑培嘉       </td>   <td>中山大学</td>   <td>一种图像的空域隐写增强方法及装置</td>   <td>广东省</td>   <td>CN112037113B</td>   <td>2023-08-25</td>   <td>本发明公开一种图像的空域隐写增强方法及装置,通过根据隐写分析网络的损失函数对测试原图进行求导,以获得测试原图对应的梯度图；其中,隐写分析网络根据训练原图集及其经过初始化隐写后得到的载密训练图像集训练而成；然后对测试原图进行初始化隐写,以获得测试原图的初始代价图；以及,根据梯度图、多个预设参数和预设更新强度,对初始代价图的代价进行更新以获得多个目标代价图；最后按照多个目标代价图对测试原图进行隐写,以获得多个候选载密图像,并从多个候选载密图像中确定出一个候选载密图像作为目标载密图像,从而能够提升安全性能。</td>   <td>1.一种图像的空域隐写增强方法,其特征在于,包括以下步骤：S1：根据隐写分析网络的损失函数对测试原图进行求导,以获得所述测试原图对应的梯度图；其中,所述隐写分析网络根据训练原图集及其经过初始化隐写后得到的载密训练图像集训练而成；S2：对所述测试原图进行初始化隐写,以获得所述测试原图的初始代价图；S3：根据所述梯度图、多个预设参数和预设更新强度,对所述初始代价图的代价进行更新以获得多个目标代价图；每一个所述目标代价图对应一个所述预设参数；包括以下步骤：S3.1：将所述梯度图中的像素点按梯度绝对值从大到小进行排序,将所述初始代价图中的像素点按代价值从小到大进行排序；根据多个预设参数确定所述梯度图中排序在前若干位的像素点作为第一部分单元,以及,根据多个预设参数确定所述初始代价图中排序在前若干位的像素点作为第二部分单元；S3.2：将对应于相同的预设参数的所述第一部分单元和所述第二部分单元的交集作为修改单元,以获得多个修改单元,每一个所述修改单元对应一个所述预设参数；S3.3：根据所述多个修改单元和预设更新强度,对所述初始代价图的代价进行更新以获得多个目标代价图,所述目标代价图与所述修改单元一一对应；S4：按照所述多个目标代价图对所述测试原图进行隐写,以获得多个候选载密图像；所述候选载密图像与所述目标代价图一一对应；S5：从所述多个候选载密图像中确定出一个候选载密图像作为目标载密图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              王弘远;                   陈刚       </td>   <td>中山大学</td>   <td>一种基于并行化的类脑仿真编译的加速方法</td>   <td>广东省</td>   <td>CN112651504B</td>   <td>2023-08-25</td>   <td>本发明涉及神经网络仿真技术领域,具体涉及一种基于并行化的类脑仿真编译的加速方法,包括以下步骤：S1、构建神经网络时,创建若干个族群,每个族群包含上百万个神经元；S2、按照神经元族群并行构建神经元数组；S3、按照族群之间的连接并行构建突触数组以及神经元到突触数组的映射关系。本发明的基于并行化的类脑仿真编译的加速方法,通过并行算法加速仿真框架的速度,大大减少了用户的等待时间。</td>   <td>1.一种基于并行化的类脑仿真编译的加速方法,其特征在于,包括以下步骤：S1、构建神经网络时,创建若干个族群,每个族群包含上百万个神经元；S2、按照神经元族群并行构建神经元数组；在步骤S2中,先将所有族群的节点数进行并行前缀求和构建族群-数组映射表,确定总的神经元数以及各个族群在神经元大数组中第一个神经元的下标；为大数组的每个元素分配一个线程,然后并行地编译神经元数据；S3、按照族群之间的连接并行构建突触数组以及神经元到突触数组的映射关系；在步骤S3中,确定每个族群中单个神经元的总输出突触数,然后按照前面的族群-数组映射表并行地将每个神经元的输出突触数存放在一个数组中,然后对该数组进行前缀求和,从而得到神经元-输出突触映射表,最后为每一个神经元、每一个突触分配一个线程,并行地构建突触数组；在确定突触数组元素方面,根据神经元-输出突触映射表以及线程的编号。</td>   <td>G06N3/10;G06F8/41</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘建平;              任飞;              刘尊龙;                   郑剑锋       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种胰腺癌预后预测模型建立方法</td>   <td>广东省</td>   <td>CN116092664B</td>   <td>2023-08-25</td>   <td>本发明涉及一种胰腺癌预后预测模型建立方法,包括,步骤S1,第一计算单元对数据库存储的病例信息进行胰腺癌预后相关因素统计学分析,获取与胰腺癌患者长期生存情况相关的因素；步骤S2,第二计算单元将病例划分为建模组和验证组,对建模组病例的胰腺癌患者长期生存情况相关的因素进行多因素回归分析,筛选对胰腺癌患者预后存在影响的独立风险因素；步骤S3,模型构建单元将筛选的独立风险因素按比例转换为分数,构建胰腺癌患者预后预测模型；步骤S4,中控单元对构建的胰腺癌患者预后预测模型进行重复采样校正,并根据验证组的病例数据对胰腺癌患者预后预测模型进行验证,用于更为准确的获取胰腺癌预后生存寿命。</td>   <td>1.一种胰腺癌预后预测模型建立方法,其特征在于,包括：步骤S1,第一计算单元对数据库存储的病例信息进行胰腺癌预后相关因素统计学分析,获取与胰腺癌患者长期生存情况相关的因素；步骤S2,第二计算单元将病例划分为建模组和验证组,对建模组病例的胰腺癌患者长期生存情况相关的因素进行多因素回归分析,筛选对胰腺癌患者预后存在影响的独立风险因素；步骤S3,模型构建单元将筛选的独立风险因素按比例转换为分数,构建胰腺癌患者预后预测模型；步骤S4,中控单元对构建的胰腺癌患者预后预测模型进行重复采样校正,并根据验证组的病例数据对胰腺癌患者预后预测模型进行验证；在所述步骤S1中,所述第一计算单元通过单因素COX回归中的风险比HR将各因素划分为危险因素、中间因素和无关因素,将危险因素设为与胰腺癌患者长期生存情况相关的因素,其中,当HR小于第一预设风险比HR1,将当前因素划分为无关因素,当HR在第一预设风险比HR1和第二预设风险比HR2之间,将当前因素划分为中间因素,当HR大于第二预设风险比HR2,将当前因素划分为风险因素即为与胰腺癌患者长期生存情况相关的因素；在所述步骤S4中,所述中控单元将从建模组随机抽取M个样本,分别对构建的胰腺癌患者预后预测模型进行校验,所述中控单元将获取的M个样本预后预测准确率s,与预设准确率S比较,对随机抽样样本量及构建的胰腺癌患者预后预测模型准确性进行判定,其中,当s≤S1,所述中控单元判定构建的胰腺癌患者预后预测模型存在异常；当S1＜s＜S2,所述中控单元判定随机抽样样本量不足；当s≥S2,所述中控单元判定根据验证组数据对构建的胰腺癌患者预后预测模型进行再次验证；其中,所述中控单元预设准确率S,设定第一预设准确率S1,第二预设准确率S2；在第一预设条件下,所述中控单元根据建模组病例数量对建模组和验证组的比例进行调节,其中,当建模组病例数量m1≤M1,所述中控单元判定调节建模组和验证组的比例,当M1＜m1＜M2,所述中控单元判定调节建模组和验证组的比例,同时扩大病例数量；当m1≥M2,所述中控单元判定扩大病例数量,同时对所述第一计算单元设置的预设风险比进行调节；所述第一预设条件为s≤S1且建模组病例数量m1＞M10,M10为所述中控单元预设建模病例组数量标准值,其中,中控单元预设建模组病例数量M,设定第一预设建模组病例数量M1,第二预设建模组病例数量M2,且M0＜M1＜M2；在第二预设条件下,所述中控单元根据建模组和验证组的病例数比例ci与预设比例C0相比较,对随机抽取的样本量进行调节,其中,c≤C0,所述中控单元选取第一预设调节系数k1提高随机抽取的样本量M至M1,设定M1＝c×k1×(1+(C0-c)/C0)；c＞C0,所述中控单元选取第二预设调节系数k2提高随机抽取的样本量M至M2,设定M2＝c×k2×(1+(c-C0)/C0)；其中,所述第二预设条件为病例数量大于预设病例标准值M20,且S1＜s＜S2,k1＜k2,i＝0,1,2；当所述中控单元判定根据验证组数据对构建的胰腺癌患者预后预测模型进行再次验证时,中控单元计算建模组和验证组的C-index并绘制标准曲线,通过比对建模组和验证组标准曲线的吻合程度d对构建的模型进行确定,其中,当d≤D0,所述中控单元判定构建的模型符合标准；当d＞D0,所述中控单元判定构建的模型不符合标准；其中,D0为所述中控单元预设吻合程度标准值；所述中控单元通过建模组标准曲线与45°对角线的距离获取建模组一致性B1,设定B1＝(b11+b12+……b1n)/n,其中,b11为第一位点建模组标准曲线与45°对角线的距离,b12为第二位点建模组标准曲线与45°对角线的距离,……,b1n为第n位点建模组标准曲线与45°对角线的距离,通过验证组标准曲线与45°对角线的距离获取验证组一致性B2,设定B2＝(b21+b22+……b2n)/n,其中,b21为第一位点验证组标准曲线与45°对角线的距离,b22为第二位点验证组标准曲线与45°对角线的距离,……,b2n为第n位点验证组标准曲线与45°对角线的距离,中控单元根据建模组一致性B1与验证组一致性B2获取吻合程度d,设定d＝|B1-B2|/B0,其中,B0为预设一致性标准值；采用Lasso回归从危险因素中筛选预测因子,最终选取年龄、性别、人群类型、淋巴结阳性率、肿瘤大小、浸润深度、肿瘤分级、T、N、M分期、化疗、是否手术可作为多因素预测模型的预测因子；对上述变量进行多因素cox回归分析,选取年龄、淋巴结阳性比率、肿瘤大小、肿瘤分级、T分期、N分期、是否化疗、是否手术是影响胰腺癌患者预后的独立危险因素。</td>   <td>G16H50/20;G16H50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓锐;              刘海龙;              王士刚;              任航;              于祥;              莫潇越;              黄思翀;              罗富强;                   吴铁成       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种帆船速度预测方法</td>   <td>广东省</td>   <td>CN116227175B</td>   <td>2023-08-25</td>   <td>本发明公开了一种帆船速度预测方法,包括：根据帆船模型获取帆船参数,设置帆船航行时的预设风况；根据帆船参数和预设风况,利用数值计算软件分别计算帆船的风帆受力、船舶阻力、船舵受力、船体受力及稳向板受力；根据风帆受力、船舶阻力、船舵受力、船体受力及稳向板受力对帆船进行受力分析,建立帆船保持稳定姿态航行时的平衡方程组,平衡方程组包括纵向受力平衡方程、横向受力平衡方程和力矩平衡方程；利用数值计算软件求解平衡方程组,得到帆船在设风况下航行时的预测速度、预测舵角和预测航向角。本发明能在预设风况条件下,预测帆船在不同帆转角条件下的航向、航速和舵角,便于风帆操纵和自动控制。</td>   <td>1.一种帆船速度预测方法,其特征在于,包括：根据帆船模型获取帆船参数,设置所述帆船航行时的预设风况；根据所述帆船参数和所述预设风况,利用数值计算软件分别计算所述帆船的风帆受力、船舶阻力、船舵受力、船体受力及稳向板受力；所述风帆包括前帆和主帆,利用数值计算软件计算所述帆船的风帆受力包括：数值计算软件利用计算所述帆船的前帆受力,利用计算所述帆船的主帆受力；其中,F-(f1)为前帆受力；F-(f2)为主帆受力；C-S为形状系数；ρ-1为空气密度；A-1为前帆的面积,单位为m～2；A-2为主帆面积,单位为m～2；V为风速,单位为m/s；V-s为帆船速度,单位为m/s；α为航向角,θ为帆转角；利用数值计算软件计算所述帆船的船舶阻力包括：数值计算软件利用计算所述帆船的船舶阻力；其中,x-1、x-2、x-3为常系数；x-4为常数；所述船舵包括左舵和右舵,利用数值计算软件计算所述帆船的船舵受力包括：数值计算软件利用计算所述帆船的左舵受力、右舵受力；其中,F-(d1)、F-(d2)分别为帆船的左舵受力、右舵受力；C-d为阻力系数；ρ-2为海水密度；A-d为单个舵叶面积,单位为m～2；为舵角；所述船体包括左船体和右船体,利用数值计算软件计算所述帆船的船体受力包括：数值计算软件利用计算所述帆船的左船体受力、右船体受力；其中,F-(c1)、F-(c2)分别为帆船的左船体受力、右船体受力；A-c为水线以下船体侧投影面积,单位为m～2；所述稳向板包括左稳向板和右稳向板,利用数值计算软件计算所述帆船的稳向板受力包括：数值计算软件利用计算所述帆船的左稳向板、右稳向板受力；其中,F-(w1)、F-(w2)分别为帆船的左稳向板受力、右稳向板受力；A-w为单个稳向板侧投影面积,单位为m～2；根据所述风帆受力、所述船舶阻力、所述船舵受力、所述船体受力及所述稳向板受力对所述帆船进行受力分析,建立所述帆船保持稳定姿态航行时的平衡方程组,所述平衡方程组包括力矩平衡方程、纵向受力平衡方程和横向受力平衡方程；所述平衡方程组包括：帆转角大于预设角度时的第一平衡方程组和帆转角小于预设角度时的第二平衡方程组,所述预设角度为帆船的前帆力矩方向发生变化时的帆转角角度；其中,所述第一平衡方程组包括第一力矩平衡方程、第一纵向受力平衡方程和第一横向受力平衡方程,所述第二平衡方程组包括第二力矩平衡方程、第二纵向受力平衡方程和第二横向受力平衡方程；所述第一力矩平衡方程为：                  所述第一纵向受力平衡方程为：                  所述第一横向受力平衡方程为：                  其中,a-2为主帆压力中心与桅杆支点在甲板上的投影距离,单位为m；b-2为桅杆支点与重心在甲板上的投影距离,单位为m；a-3为左舵旋转支点与压力中心在甲板上的投影距离,单位为m；b-3为左舵旋转支点与重心在甲板上的投影距离,单位为m；L-5、L-6均为水面以下船体受力中心与重心投影距离,单位为m；所述第二力矩平衡方程为：                  所述第二纵向受力平衡方程为：                  所述第二横向受力平衡方程为：                  利用数值计算软件求解所述平衡方程组,得到所述帆船在所述预设风况下航行时的预测速度、预测舵角和预测航向角。</td>   <td>G06F30/20;G06F30/15;G06F17/12;B63B71/10;G06F119/14;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              叶铭熙;              南雨宏;                   吴东鹏       </td>   <td>中山大学</td>   <td>一种智能合约的漏洞检测方法和装置</td>   <td>广东省</td>   <td>CN116644435A</td>   <td>2023-08-25</td>   <td>本发明公开了一种智能合约的漏洞检测方法和装置,方法包括通过响应漏洞检测请求,采集智能合约在区块链上的历史交易中的历史调用函数、区块链状态和对应的关联地址；按照关联地址执行模糊测试以得到多个可调用函数,按顺序关联历史调用函数和各个可调用函数,构建多个更新交易序列；对更新交易序列分别进行变异,生成变异交易序列；在相同的区块链状态下分别执行更新交易序列和变异交易序列,根据执行后区块链状态是否相同判断智能合约是否出现漏洞,从而有效改善漏洞检测的高误报率或高漏报率的情况,提高智能合约的漏洞检测安全性。</td>   <td>1.一种智能合约的漏洞检测方法,其特征在于,包括：响应漏洞检测请求,采集智能合约在区块链上的区块链状态、历史调用函数和对应的关联地址；按照所述关联地址执行模糊测试,得到多个可调用函数,并关联所述历史调用函数,构建多个更新交易序列；对所述更新交易序列进行变异,生成变异交易序列；在所述区块链状态下分别执行所述更新交易序列和所述变异交易序列,根据执行后区块链状态判断所述智能合约是否出现漏洞。</td>   <td>G06F21/57;G06F21/56</td>  </tr>        <tr>   <td>中国专利</td>   <td>         饶彬;              曾舒雅;              周永坤;              王伟;              王涛;              周颖;              邹小海;              程旭;                   徐峰       </td>   <td>中山大学</td>   <td>一种基于动力学守恒定律的弹道目标关联方法</td>   <td>广东省</td>   <td>CN116644563A</td>   <td>2023-08-25</td>   <td>本发明公开了一种基于动力学守恒定律的弹道目标关联方法,方法包括：采用航迹起始方法生成起始航迹；根据所述起始航迹以及目标对象在目标时刻的目标状态,预测对应的目标位置；利用关联门确定候选有效量测；通过动量矩和机械能的联合假设检验对所述候选有效量测进行筛选,得到目标有效量测；根据所述目标位置和所述目标有效量测,通过关联滤波确定所述目标对象的目标航迹。本发明的精度高,能够关联级解决抑制电假目标点迹干扰的问题,并提高真目标的跟踪精度,可广泛应用于计算机技术领域。</td>   <td>1.一种基于动力学守恒定律的弹道目标关联方法,其特征在于,包括：采用航迹起始方法生成起始航迹；根据所述起始航迹以及目标对象在目标时刻的目标状态,预测对应的目标位置；利用关联门确定候选有效量测；通过动量矩和机械能的联合假设检验对所述候选有效量测进行筛选,得到目标有效量测；根据所述目标位置和所述目标有效量测,通过关联滤波确定所述目标对象的目标航迹。</td>   <td>G06F30/20;G06F17/16;G06F17/18;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林越翔;              赖正首;              黄林冲;              马建军;                   梁禹       </td>   <td>中山大学</td>   <td>岩石的细观重构方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN116644646A</td>   <td>2023-08-25</td>   <td>本申请涉及岩石重构领域,提出了一种岩石的细观重构方法、装置、设备及存储介质。该方法包括：根据岩石晶粒的空间相关性参数确定具有空间相关性的随机场；确定所述随机场对应的晶格数量,根据所述晶格数量和所述随机场,确定所述随机场中的沃罗诺伊图的种子和所述种子对应的权重；根据所述种子和对应的权重,对几何域进行沃罗诺伊图的晶格划分,根据晶格的质心位置、所述种子的位置及随机场,更新种子位置、权重及所述晶格,通过多次迭代生成期望的岩石细观晶格结构。由于重构的晶格在呈现了晶粒尺寸信息的同时,还包括晶粒的空间相关性,从而能够更为准确的预测岩石的力学性质,确定岩石的力学强度和结构的稳定性等。</td>   <td>1.一种岩石的细观重构方法,其特征在于,所述方法包括：根据岩石晶粒的空间相关性参数确定具有空间相关性的随机场；确定所述随机场对应的晶格数量,根据所述晶格数量和所述随机场,确定所述随机场中的沃罗诺伊图的种子和所述种子对应的权重；根据所述种子和对应的权重,对几何域进行沃罗诺伊图的晶格划分,根据晶格的质心位置、所述种子的位置及随机场,更新种子位置、权重及所述晶格,通过多次迭代,生成期望的岩石细观晶格结构。</td>   <td>G06F30/25;G16C60/00;G01N15/00;G01N15/02;G01N33/24;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡杰灵;              段博曦;              李嘉豪;                   戴宪华       </td>   <td>中山大学</td>   <td>一种自适应动态社区发现算法DSCF-LFM</td>   <td>广东省</td>   <td>CN116645231A</td>   <td>2023-08-25</td>   <td>现实中的网络结构是不断变化的,时刻都有用户的加入与离开。本发明针对动态网络社区规模和网络空间随时间不断变化的特点,提出了基于增量扩展的自适应动态社区发现算法DSCF-LFM。该算法将网络结构分成四类,即节点的添加与删除、连边的添加与删除,针对这四类变化设计了四个函数,通过对四个函数的串行叠加,即可对网络的变化部分重新划分社区归属。对社区划分增量变化和上一个时间片社区划分取交集,即可实现动态网络的社区划分。</td>   <td>1.一种自适应动态社区发现算法DSCF-LFM,其特征在于,采用增量的方法更新动态网络的社区结构,实现方法是,在初始时刻使用静态社区发现方法SCF-LFM发现社区结构,在后续时间片网络对网络增量部分进行重新社区划分,并与上一时刻社区划分结果做交集,即可实现动态社区发现,降低了社区发现的运行时间成本。</td>   <td>G06Q50/00;H04L51/52;H04L41/142</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;              凌鹏;                   莫浩然       </td>   <td>中山大学</td>   <td>一种基于聚类的CAD草图全景分割方法及装置</td>   <td>广东省</td>   <td>CN116645510A</td>   <td>2023-08-25</td>   <td>本发明公开了一种基于聚类的CAD草图全景分割方法及装置,方法包括：获取CAD数据；通过图网络对所述CAD数据中的图节点特征进行强化处理,得到矢量节点特征；构造初始边特征,进而对所述矢量节点特征进行更新,得到目标节点特征；通过神经网络构造得到第一预测头和第二预测头；根据所述第一预测头对所述目标节点特征进行语义类别的预测,进而根据所述第二预测头对所述目标节点特征获取CAD矢量线稿的分配矩阵,得到全景分割结果。本发明的适用性强,去除繁杂的后处理操作,可通过分配矩阵得到全景分割结果,可广泛应用于计算机技术领域。</td>   <td>1.一种基于聚类的CAD草图全景分割方法,其特征在于,包括:获取CAD数据；通过图网络对所述CAD数据中的图节点特征进行强化处理,得到矢量节点特征；构造初始边特征,进而对所述矢量节点特征进行更新,得到目标节点特征；通过神经网络构造得到第一预测头和第二预测头；根据所述第一预测头对所述目标节点特征进行语义类别的预测,进而根据所述第二预测头对所述目标节点特征获取CAD矢量线稿的分配矩阵,得到全景分割结果。</td>   <td>G06V10/26;G06V10/44;G06V10/77;G06V10/762;G06V10/82;G06F30/10;G06T7/10;G06T7/13;G06N3/047;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙仕海;              梁晓琳;              朱祥维;              赖廷钦;              郭俊彬;              张思远;              李天赐;              田之宇;                   黄锦铨       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种双通道特征探索的视觉识别方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116645547A</td>   <td>2023-08-25</td>   <td>本发明公开了一种双通道特征探索的视觉识别方法、系统、设备及介质。将待识别图像分类为正常图像和非正常图像,并将非正常图像进行图像对比度调整,得到非正常增强图像；对正常图像和非正常增强图像进行特征提取,得到第一特征提取图；将第一特征提取图经过两路卷积通道的交叉卷积处理,并合并输出第二特征提取图；对第二特征提取图进行分类和定位处理,得到所述待识别图像的目标分类和定位结果。本发明的技术方案能够改善视觉识别模型在不同环境下的适应能力、降低对图像数据信息的依赖,保留更多图像潜在信息,提高检测的精度和效率。</td>   <td>1.一种双通道特征探索的视觉识别方法,其特征在于,所述方法包括：对待识别图像进行识别分类,分类为正常图像和非正常图像,并将所述非正常图像进行图像对比度调整,得到非正常增强图像；所述正常图像为晴天图像,所述非正常图像为晴天以外的所有天气的图像；对所述正常图像和非正常增强图像进行特征提取,得到第一特征提取图；将所述第一特征提取图经过两路卷积通道的交叉卷积处理,并合并输出第二特征提取图；对所述第二特征提取图分别进行分类和定位处理,得到所述待识别图像的目标分类和定位结果。</td>   <td>G06V10/764;G06V10/44;G06V10/82;G06N3/0464;G06N3/08;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐瑞华;              骆卉妍;              贺龙君;              李超峰;              邓一术;              经秉中;                   陈浩华       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>基于深度学习和状态转移的内窥镜检查质控方法及系统</td>   <td>广东省</td>   <td>CN116309605B</td>   <td>2023-08-22</td>   <td>本发明提供了一种基于深度学习和状态转移的内窥镜检查质控方法及系统,所述方法包括：根据内窥镜检查项目,得到部位检查逻辑集后,实时获取内窥镜的当前检查帧图像,并根据预设部位识别模型和部位检查逻辑集,对当前检查帧图像进行预测分析得到当前帧部位预测结果,再根据当前帧部位预测结果和部位检查逻辑集,得到当前帧部位识别结果,并根据当前帧部位识别结果更新检查记录,以及根据检查记录,进行相应的质控显示。本发明通过在内窥镜检查质控中引入解剖逻辑结构先验知识,实现科学有效地规范内窥镜检查流程,提高医生工作效率的同时,保证内窥镜的检查质量,避免误诊漏诊,提高病损的检出率,进而提高患者的生存质量。</td>   <td>1.一种基于深度学习和状态转移的内窥镜检查质控方法,其特征在于,所述方法包括以下步骤：根据内窥镜检查项目,得到部位检查逻辑集；所述部位检查逻辑集包括所述内窥镜检查项目中各个待检查部位的状态转移集；所述状态转移集基于各个待检查部位间的解剖逻辑结构生成；实时获取内窥镜的当前检查帧图像,并根据预设部位识别模型和所述部位检查逻辑集,对所述当前检查帧图像进行预测分析,得到当前帧部位预测结果；所述预设部位识别模型的损失函数为以所述部位检查逻辑集为约束条件构建的加权交叉熵损失函数；所述加权交叉熵损失函数表示为：                  式中,                  其中,Loss表示交叉熵损失；C表示总类别数；w-c、y-c和p-c分别表示类别c的权重、真实标签和预测概率；P表示预设部位识别模型输出的各类别预测概率；S-C-t表示检查部位C-t的状态转移集；w-1表示类别预测概率最大值所在类别在对应状态转移集内的权重,w-2表示类别预测概率最大值所在类别在对应状态转移集外的权重,且w-2&gt;w-1；根据所述当前帧部位预测结果和所述部位检查逻辑集,得到当前帧部位识别结果,并根据所述当前帧部位识别结果,更新检查记录；所述检查记录包括已检查部位、检查完成占比和下一步待检查部位；所述下一步待检查部位为所述当前帧部位识别结果对应的状态转移集；根据所述检查记录,判断是否完成所述内窥镜检查项目,并进行相应的质控显示；其中,所述根据所述当前帧部位预测结果和所述部位检查逻辑集,得到当前帧部位识别结果的步骤包括：获取前次登记帧部位识别结果,并根据所述前次登记帧部位识别结果和所述部位检查逻辑集,得到归属状态转移集；获取所述当前帧部位预测结果中预测概率最大值对应的部位类别作为预测类别；判断所述预测类别是否属于所述归属状态转移集,若是,则将所述预测类别作为所述当前帧部位识别结果,反之,则根据所述当前帧部位预测结果和所述归属状态转移集,确定所述当前帧部位识别结果。</td>   <td>G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              刘坤华;                   叶梓豪       </td>   <td>中山大学</td>   <td>一种基于GAN的带雾图像语义分割方法</td>   <td>广东省</td>   <td>CN112508025B</td>   <td>2023-08-22</td>   <td>本发明提供一种基于GAN的带雾图像语义分割方法,包括以下步骤：S1.建立边界生成器和边界判别器；S2.建立语义分割生成器和语义分割判别器；S3.对边界生成器和边界判别器进行训练；S4.对语义分割生成器和语义分割判别器进行训练；S5.将带雾图像输入完成训练的边界生成器中获得边界图像；S6.带雾图像与边界图像拼接后输入完成训练的语义分割生成器中获得语义分割图像。本发明能够直接对带雾图像进行语义分割,准确率高。</td>   <td>1.一种基于GAN的带雾图像语义分割方法,其特征在于：包括以下步骤：S1.建立边界生成器和边界判别器；所述步骤S1中,所述边界生成器包括十个依次连接的卷积层,其中边界生成器的第一卷积层、第二卷积层、第三卷积层、第八卷积层、第九卷积层和第十卷积层均为普通卷积层,边界生成器的第四卷积层、第五卷积层、第六卷积层和第七卷积层均为空洞卷积；所述边界判别器包括五个依次连接的卷积层,且均为普通卷积,其中边界判别器的第一卷积层、第二卷积层、第三卷积层和第四卷积层的激活函数为LeReLU,LeReLU的斜率为0.25；S2.建立语义分割生成器和语义分割判别器；所述语义分割判别器包括五个依次连接的卷积层,均为普通卷积,其中义分割判别器的第一卷积层、第二卷积层、第三卷积层和第四卷积层的激活函数为LeReLU,LeReLU的斜率为0.25；S3.对边界生成器和边界判别器进行训练；所述语义分割生成器包括十个依次连接的卷积层,其中语义分割生成器的第一卷积层、第二卷积层、第三卷积层、第八卷积层、第九卷积层和第十卷积层均为普通卷积层,语义分割生成器的第四卷积层、第五卷积层、第六卷积层和第七卷积层均为空洞卷积；S4.对语义分割生成器和语义分割判别器进行训练；S5.将带雾图像输入完成训练的边界生成器中获得边界图像；S6.带雾图像与边界图像拼接后输入完成训练的语义分割生成器中获得语义分割图像。</td>   <td>G06V10/26;G06V10/774;G06V10/82;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              陈兆棠;                   张亚琛       </td>   <td>中山大学</td>   <td>一种基于特征点检测与分割的语义地图增量更新方法</td>   <td>广东省</td>   <td>CN112396696B</td>   <td>2023-08-22</td>   <td>本发明提供一种基于特征点检测与分割的语义地图增量更新方法,包括以下步骤：S1.获取先前语义地图和室内外RGB图像,并对RGB图像进行预处理；S2.检测预处理后RGB图像的特征点,将采集的特征点与先前语义地图特征点进行匹配,并计算出相应的姿态变换矩阵；S3.计算预处理后RGB图像的语义分割结果；S4.根据姿态变换矩阵完成坐标变化,对比特征点在坐标变换前和变换后对应的语义标签是否一致,提取增量；S5.将提取的增量信息更新到先前语义地图中；S6.最后修复语义地图更新后出现的空缺区域,获得完整的语义地图。本发明在更新的过程中并不需要对没有改变的实物进行重新计算,节约了计算成本,加快了更新速度。</td>   <td>1.一种基于特征点检测与分割的语义地图增量更新方法,其特征在于：包括以下步骤：S1.获取先前语义地图和室内外RGB图像,并对RGB图像进行预处理；S2.检测预处理后RGB图像的特征点,将采集的特征点与先前语义地图特征点进行匹配,并计算出相应的姿态变换矩阵；S3.计算预处理后RGB图像的语义分割结果；S4.根据步骤S2的姿态变换矩阵完成坐标变化,对比特征点在坐标变换前和变换后对应的语义标签是否一致,从而提取增量；具体包括以下步骤：S41.记录当前图像特征点在语义分割结果中所对应的语义标签；S42.利用姿态变换矩阵将当前图像及其语义分割结果映射到与先前语义地图相同的坐标系中；S43.对比特征点在坐标变换前和变换后对应的语义标签是否一致,从而提取增量；步骤S43中包括以下提取增量的方式：a.对比当前图像变换前特征点的语义标签与变换后特征点在先前语义地图对应的语义标签是否一致,若不一致,是增量出现,只需提取与采集的特征点在当前图像有相同标签且处于同一连通域的像素所构成的掩膜；b.对比先前语义地图上特征点对应的语义标签与变换过来的语义分割上的语义标签是否一致,若不一致,是增量消失,只需提取与采集的特征点在先前语义地图上有相同标签且处于同一连通域的点构成的掩膜；c.在同一区域处出现增量出现和增量消失两种情况,提取增量出现和增量消失所对应的掩膜；S5.将提取的增量信息更新到先前语义地图中；包括以下增量更新方式：a.若存在增量出现,只需将提取的掩膜对应的语义信息替换到先前语义地图上；b.若存在增量消失或增量变换,就需要先将在先前语义地图上提取的掩膜对应的语义信息删除,并将在当前图像上提取的语义信息添加到先前语义地图上；S6.修复语义地图更新后出现的空缺区域,获得完整的语义地图。</td>   <td>G06T17/05;G06T7/73;G06T7/187;G06V10/26;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>              丁汝鑫       </td>   <td>中山大学</td>   <td>基于垂直剖面上裂变径迹长度分布的热史模拟方法及系统</td>   <td>广东省</td>   <td>CN113722917B</td>   <td>2023-08-22</td>   <td>本发明涉及一种基于垂直剖面上裂变径迹长度分布的热史模拟方法、系统及设备,该方法通过获取垂直剖面上不同高度的N个样品,对N个样品进行分析、处理,得到符合需求的样品,通过符合需求每个样品的热史曲线生成待模拟地质最终的热史模拟结果,该热史模拟结果准确率高；该基于垂直剖面上裂变径迹长度分布的热史模拟方法在地质的热史模拟中不受地质类型的限制,使用广泛,解决了现有采用裂变径迹方法获取的数据得到的热史模拟应用在能源勘探中存在局限性且模拟数据不准确的技术问题。</td>   <td>1.一种基于垂直剖面上裂变径迹长度分布的热史模拟方法,其特征在于,包括以下步骤：获取待模拟地质在垂直剖面上不同高度的N个样品以及N个所述样品的围限径迹长度分布；基于时间与温度接受范围内对其中一个所述样品假设若干条热史曲线,并采用蒙特卡洛方法从假设若干条热史曲线中搜索得到第一假设热史曲线；在所述第一假设热史曲线的基础上上移、下移或变形得到与其它N-1个所述样品对应的假设热史曲线；依据每个所述样品的所述假设热史曲线计算,得到对应所述样品的模拟长度分布；采用K-S检验技术对每个所述样品的模拟长度分布与围限径迹长度分布进行处理,得到对应所述样品的拟合优度；对所有所述样品的拟合优度进行处理,得到N个所述样品的总体拟合优度；依据所述总体拟合优度对每个所述样品的热史曲线进行筛选,得到筛选后每个所述样品的热史曲线；根据筛选后每个所述样品的热史曲线生成待模拟地质最终的热史模拟结果；对所有所述样品的拟合优度进行处理,得到N个所述样品的总体拟合优度的步骤包括：对每个所述样品的拟合优度进行标准误差倍数的转换,得到与所述样品对应的标准误差倍数；对所有所述样品的标准误差倍数进行求取平均数,得到所有所述样品的平均标准误差倍数；将所述平均标准误差倍数进行拟合优度转换,得到总体拟合优度；对每个所述样品的拟合优度采用第一转换公式进行标准误差倍数的转换,得到与所述样品对应的标准误差倍数；所述第一转换公式为：                  式中,GOF为样品的拟合优度,E为样品的标准误差倍数,V和σ分别为围限径迹长度分布的结果和误差,x为围限径迹长度分布中的围限径迹长度；将所述平均标准误差倍数采用第二转换公式进行拟合优度转换,得到总体拟合优度；所述第二转换公式为：                  式中,MGOF为样品的总体拟合优度,ME为平均标准误差倍数,V和σ分别为围限径迹长度分布的结果和误差,x为围限径迹长度分布中的围限径迹长度。</td>   <td>G06F30/20;G06F119/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吕星;              邓一术;              经秉中;              陈浩华;              柯梁汝;              李超峰;              谢传淼;                   孙颖       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>动态分析时序MR图像的方法、系统、设备和存储介质</td>   <td>广东省</td>   <td>CN116309604B</td>   <td>2023-08-22</td>   <td>本发明涉及医学影像处理技术领域,公开了动态分析时序MR图像的方法、系统、设备和存储介质,包括获取待测样本的时序MR图像,对所述时序MR图像进行图像融合,得到第一MR图像,所述时序MR图像包括在预设时间内顺序采集的多个原始MR图像；将所述第一MR图像输入预先训练好的卷积神经网络模型进行图像特征提取,得到图像特征图；将所述图像特征图按照最近邻原则划分为若干个特征块,对所述特征块进行特征融合,得到第二MR图像；将所述第二MR图像输入预先训练好的Transformer网络模型进行图像分类预测,得到对应的分类结果。本发明能够挖掘时间序列MR图像的图像特征,充分分析图像特征动态演变规律及整合全局图像信息。</td>   <td>1.一种动态分析时序MR图像的方法,其特征在于,包括：获取待测样本的时序MR图像,对所述时序MR图像进行图像融合,得到第一MR图像,所述时序MR图像包括在预设时间内顺序采集的多个原始MR图像；具体为：将多个所述原始MR图像由三维图像转变为二维图像,将各个所述原始MR图像在相同层面上的二维图像组合成三通道图像,并将所述三通道图像作为第一MR图像；所述三通道图像中各个通道图像的随访点均不相同,且每个所述通道图像由按照预设规则从所述时序MR图像中选择出的多个不同时间的所述原始MR图像构成；其中,所述将多个所述原始MR图像由三维图像转变为二维图像的步骤包括：对多个所述原始MR图像的三维图像进行深度切片,得到二维图像,所述二维图像的数量与所述三维图像的深度尺寸相对应,且在同一层面上的所述二维图像的数量与所述原始MR图像的数量一致；将所述第一MR图像输入预先训练好的卷积神经网络模型进行图像特征提取,得到图像特征图；将所述图像特征图按照最近邻原则划分为若干个特征块,对所述特征块进行特征融合,得到第二MR图像；将所述第二MR图像输入预先训练好的Transformer网络模型进行图像分类预测,得到对应的分类结果。</td>   <td>G06T7/00;G06V10/764;G06V10/774;G06V10/82;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐瑞华;              骆卉妍;              李超峰;              贺龙君;              徐国梁;              经秉中;              邓一术;                   陈浩华       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种上消化道内镜视频肿瘤诊断关键帧的提取方法及装置</td>   <td>广东省</td>   <td>CN116189050B</td>   <td>2023-08-22</td>   <td>本发明公开了一种上消化道内镜视频肿瘤诊断关键帧的提取方法及装置,包括：将待处理的内镜视频时序帧输入抖动消除模型,得到第一时序帧；将所述第一级时序帧输入至预设的肿瘤预测模型,最后输出得到包含预测结果的第二级时序帧；将所述预测结果连接成第一预测曲线,并将所述第一预测曲线输入至平滑模型,得到平滑后的第二预测曲线；根据第二预测曲线找出若干个符合预设条件的关键时间点,并从所述第二级时序帧中提取出所述若干个关键时间点对应的肿瘤关键帧图像以及对应的肿瘤预测概率和肿瘤区域。本发明能减少内镜视频中噪声对肿瘤诊断关键帧提取的干扰,提升内镜AI辅助诊断的可靠性。</td>   <td>1.一种上消化道内镜视频肿瘤诊断关键帧的提取方法,其特征在于,包括：将待处理的内镜视频时序帧输入抖动消除模型,得到消除抖动后的第一级时序帧；其中,所述抖动消除模型利用仿射变换原理构建而成；将所述第一级时序帧输入至预设的肿瘤预测模型,以使所述肿瘤预测模型依次对所述第一级时序帧进行异常区域检测、噪声去除、异常区域修复以及图像编码分割预测后,得到包含预测结果的第二级时序帧；其中,所述肿瘤预测模型由异常区域检测UNet模型、图像修复MAE模型和肿瘤预测Transformer模型组合而成,所述预测结果为所述第一级时序帧中的每一帧图像内含有肿瘤区域的预测概率值；将所述预测结果连接成第一预测曲线,将所述第一预测曲线输入至平滑模型以使所述第一预测曲线的拟合残差值最小化,得到平滑后的第二预测曲线；根据第二预测曲线找出若干个符合预设条件的关键时间点,并从所述第二级时序帧中提取出所述若干个符合预设条件的关键时间点对应的肿瘤关键帧图像以及对应的肿瘤预测概率和肿瘤区域；其中,所述肿瘤预测模型由异常区域检测UNet模型、图像修复MAE模型和肿瘤预测Transformer模型组合而成,具体为：训练一个异常区域检测UNet模型,预测图像异常区域,包含UNet编码器和UNet解码器；训练一个图像修复MAE模型,所述图像修复MAE模型是一个Transformer组成的自编码模型,用于修复图像异常区域,包含MAE编码器和MAE解码器；训练一个肿瘤预测Transformer模型,用于预测修复后图像的肿瘤区域以及概率,包含Transformer编码器和Transformer解码器；将所述Transformer模型与所述UNet编码器、UNet解码器和MAE编码器、MAE解码器模块结合,构建成肿瘤预测模型；所述根据第二预测曲线找出若干个符合预设条件的关键时间点,并从所述第二级时序帧中提取出所述若干个符合预设条件的关键时间点对应的肿瘤关键帧图像以及对应的肿瘤预测概率和肿瘤区域,具体包括：对所述第二预测曲线按预设时间长度进行分组,得到若干组预测数值；获取每组所述预测数值中的最大值,若所述最大值超过预设关键阈值,则记录所述最大值对应的时间点,作为关键时间点；根据所述关键时间点,从所述第二级时序帧中分别提取出所述若干个关键时间点对应的肿瘤关键帧图像以及对应的肿瘤预测概率和肿瘤区域。</td>   <td>G06V20/40;G06V10/62;G06V10/30;G06V10/34;G06V10/24;G06V10/82;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         官权学;              刘钦河;              胡嘉蓓;                   谭晓军       </td>   <td>中山大学</td>   <td>充电负荷预测方法</td>   <td>广东省</td>   <td>CN116629442A</td>   <td>2023-08-22</td>   <td>本申请公开了一种充电负荷预测方法,该方法可获取充电站的历史充电负荷序列；利用经过蛇优化算法训练得到的变分模态参数,将历史充电负荷根据不同的带宽和中心频率进行分解,得到每个频率对应的分解序列,从而有效降低分解序列中的随机性及波动性；将每个分解序列输入至长短期记忆网络,得到长短期记忆网络输出的各个频率对应的序列预测结果；将各个序列预测结果进行叠加,得到最终的充电站充电负荷预测结果,从而可以针对性地对不同频率下的分解序列进行分析预测,提高了预测精度。可见,本申请可以精确地预测每一充电站的充电负荷。</td>   <td>1.一种充电负荷预测方法,其特征在于,包括：获取充电站的历史充电负荷序列；利用经过蛇优化算法训练得到的变分模态参数,对所述历史充电负荷序列按照不同带宽和中心频率进行分解,得到每个频率对应的分解序列；将每个所述分解序列输入至对应的长短期记忆网络,得到所述长短期记忆网络输出的所述分解序列对应的序列预测结果；将各个所述序列预测结果进行叠加,得到最终的充电站充电负荷预测结果。</td>   <td>G06Q10/04;G06N3/0442;G06Q50/06;G06N3/086</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任江涛;                   郑居武       </td>   <td>中山大学</td>   <td>一种道路病害检测方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116630268A</td>   <td>2023-08-22</td>   <td>本发明提供了一种道路病害检测方法、系统、设备及介质,所述方法包括：获取道路病害巡检图像,并将所述道路病害巡检图像构成病害数据集；将所述病害数据集输入检测模型进行训练；所述检测模型包括卷积神经网络、特征融合网络和对比学习模块；所述病害数据集依次经由所述卷积神经网络进行特征提取、由所述特征融合网络进行特征融合,以及由所述对比学习模块进行对比学习；将待检测道路病害巡检图像输入训练后的检测模型,得到道路病害检测结果。本申请优化了对比学习训练过程,能够有效地检测识别不同的道路病害目标。</td>   <td>1.一种道路病害检测方法,其特征在于,所述方法包括：获取道路病害巡检图像,并将所述道路病害巡检图像构成病害数据集；将所述病害数据集输入检测模型进行训练；所述检测模型包括卷积神经网络、特征融合网络和对比学习模块；所述病害数据集依次经由所述卷积神经网络进行特征提取、由所述特征融合网络进行特征融合,以及由所述对比学习模块进行对比学习；将待检测道路病害巡检图像输入训练后的检测模型,得到道路病害检测结果。</td>   <td>G06T7/00;E01C23/01;G06N3/0464;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;              谢卓;                   莫浩然       </td>   <td>中山大学</td>   <td>一种草图角色动画生成方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN116630496A</td>   <td>2023-08-22</td>   <td>本发明公开了一种草图角色动画生成方法、装置、电子设备及存储介质,本发明方法首先通过边缘提取或线稿提取的方法构造成对的草图角色动画数据集；其次基于预训练模型提取的结构表示或自监督任务学习的结构表示,构建动作估计模块；然后利用生成对抗网络构建动画生成模块；最后结合用户输入的目标角色草图和驱动视频,利用训练完毕的模型生成连续的草图角色动画。本发明实施例可以通过用户输入的一段驱动视频和目标角色的草图,生成在时序上连续的草图角色动画。本发明方法提供的草图角色动画生成方法,不仅能降低纯手绘动画创作模式带来的时间开销,同时也能为无技术背景的普通用户提供一种创作动画的渠道,可广泛应用于动画数据处理技术领域。</td>   <td>1.一种草图角色动画生成方法,其特征在于,包括：对获取的角色动画数据集进行草图提取,获得角色草图动画数据集,基于所述角色动画数据集和所述角色草图动画数据集构建得到成对角色动画数据集；设置动作估计模块和动画生成模块,利用所述成对角色动画数据集对所述动作估计模块和所述动画生成模块进行迭代训练,获得训练完成的动作估计模块和动画生成模块；其中,所述动作估计模块包括结构表示提取模型、稀疏动作估计模块和稠密动作估计模块；所述动画生成模块包括编码器和解码器；获取目标草图和驱动视频；基于训练完成的所述动作估计模块,提取所述目标草图到所述驱动视频中各驱动帧的动作参数,获得所述目标草图到所述驱动视频中各驱动帧的运动信息；基于训练完成的所述动画生成模块,根据所述目标草图到所述驱动视频中各驱动帧的运动信息,对所述目标草图逐帧进行几何扭曲,得到连续的草图动画帧；根据连续的所述草图动画帧,生成目标草图角色动画视频。</td>   <td>G06T13/80;G06T13/40;G06V20/40;G06V40/20;G06V10/80;G06V10/82;G06N3/0455;G06N3/0464;G06N3/0475;G06N3/084;G06N3/088;G06N3/0895;G06N3/094;G06N3/0985</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   黄日聪       </td>   <td>中山大学</td>   <td>一种说话人视频生成方法</td>   <td>广东省</td>   <td>CN116630501A</td>   <td>2023-08-22</td>   <td>本发明公开了一种说话人视频生成方法,包括：获取目标音频、目标视频以及目标视频对应的初始人脸图像；基于人脸3D形变统计模型,根据所述初始人脸图像得到对应的目标身份参数；将所述目标身份参数和目标音频输入到说话人视频生成模型中,生成所述目标音频对应的若干最终人脸图像；将若干最终人脸图像进行拼接,生成所述目标音频对应的视频。与现有技术相比,本发明可以针对不同的身份参数预测出到音频特征对应的表情参数,并在基于得到的每一表情参数后生成最终的若干最终人脸图像,从而生成所述目标音频对应的视频,相比现有技术的方法,本发明实现不同人物之间可以共有一个相同的说话人视频生成模型,减少了系统的占用资源。</td>   <td>1.一种说话人视频生成方法,其特征在于,包括：获取目标音频、目标视频以及目标视频对应的初始人脸图像；基于人脸3D形变统计模型,根据所述初始人脸图像得到对应的目标身份参数；将所述目标身份参数和目标音频输入到说话人视频生成模型中,生成所述目标音频对应的若干最终人脸图像；将若干最终人脸图像进行拼接,生成所述目标音频对应的视频；其中,所述说话人视频生成模型包括表情参数编码子模型、参数化隐式表达子模型和参数化隐式表达渲染子模型；所述表情参数编码子模型,用于提取目标音频中的若干目标音频特征,并生成每一目标音频特征对应的目标表情参数；其中,所述每一目标表情参数与所述目标身份参数对应；所述参数化隐式表达子模型,用于根据目标身份参数和每一目标表情参数,生成每一目标表情参数对应的目标人脸特征图；所述参数化隐式表达渲染子模型,用于获取所述初始人脸图像对应的初始人脸遮罩图像,并根据所述初始人脸遮罩图像和若干目标人脸特征图生成每一人脸特征图对应的最终人脸图像；其中,所述初始人脸遮罩图像的遮罩区域为初始人脸遮罩图像的嘴部区域。</td>   <td>G06T15/00;G10L25/48;G06T13/40;G06T7/80;G06T3/40;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   黄铎峻       </td>   <td>中山大学</td>   <td>基于主动领域自适应的图像分类方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116630708A</td>   <td>2023-08-22</td>   <td>本发明提供了一种基于主动领域自适应的图像分类方法、系统、设备及介质,所述方法包括：根据获取的源域图像数据集和目标域图像数据集分别初始化已标注数据集和未标注数据集,并根据已标注数据集对预设深度神经网络模型进行初始化训练得到目标域图像分类模型后,根据已标注数据集、未标注数据集和目标域图像分类模型建立信息评分模型和信息采样模型,并对目标域图像分类模型进行主动领域自适应学习迭代训练,更新已标注数据集和未标注数据集直至达到预设迭代停止条件,获取待分类图像输入至目标域图像分类模型进行分类预测得到图像分类结果。本发明基于样本差异的各异性设计采样和训练策略,有效提升模型的分类精度和泛化能力,具有较强的通用性。</td>   <td>1.一种基于主动领域自适应的图像分类方法,其特征在于,所述方法包括以下步骤：根据获取的源域图像数据集和目标域图像数据集分别初始化已标注数据集和未标注数据集；所述源域图像数据集为带标注的图像数据集；所述目标域图像数据集为未标注的图像数据集；根据所述已标注数据集对预设深度神经网络模型进行初始化训练,得到目标域图像分类模型；所述预设深度神经网络模型包括特征提取器和分类器；根据所述已标注数据集、所述未标注数据集和所述目标域图像分类模型,建立信息评分模型和信息采样模型；根据所述信息评分模型和所述信息采样模型,对所述目标域图像分类模型进行主动领域自适应学习迭代训练,更新所述已标注数据集和所述未标注数据集,直至达到预设迭代停止条件；获取待分类图像,并将所述待分类图像输入所述目标域图像分类模型进行分类预测,得到图像分类结果。</td>   <td>G06V10/764;G06V10/774;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         成慧;                   黄浩洸       </td>   <td>中山大学</td>   <td>一种基于彩色-深度相机的动态物体参数化建模方法</td>   <td>广东省</td>   <td>CN111862139B</td>   <td>2023-08-18</td>   <td>本发明涉及一种基于彩色-深度相机的动态物体参数化建模方法,包括以下步骤：S1、获得物体的彩色-深度图片序列；S2、获取像素级别保边的前景物体mask；S3、进行动作分析,得到目标物体的完整骨骼模型；S4、使用三维重建算法进行三维重建,得到三维重建模型；S5、使用绑定算法把三维重建模型上的每个面片都刚性绑定到骨骼模型上；S6、为已经绑定骨骼模型的三维重建模型生成关键帧动画。本发明的基于彩色-深度相机的动态物体参数化建模方法通过把重建模型刚性绑定到骨骼模型,实现赋予传感器所扫描物体参数化特性的目的,可高效地分析出视频中物体的关节信息,通过准确的稠密刚性绑定,为物体模型赋予运动学特性。</td>   <td>1.一种基于彩色-深度相机的动态物体参数化建模方法,其特征在于,包括以下步骤：S1：固定彩色-深度相机,扫描相机视野中的任意动态刚性物体,获得物体的彩色-深度图片序列；S2：使用前后景分割算法对彩色-深度图片序列进行前景物体分割,获取像素级别保边的前景物体mask；所述前后景分割算法包括以下步骤：S2.1：进行预处理,给定深度图序列D＝[D-1,...,D-L]和彩色图序列I＝[I-1,...,I-L]；S2.2：通过经典的物体追踪算法来获取指定物体的包围盒,然后基于包围盒内深度值的统计直方图,通过设置指定阈值来二值化包围盒内的每个像素位置,从而得到粗糙的物体分割结果M-0；S2.3：为M-0建立最小化能量优化模型：                  上式中,M为mask的优化结果,E-c和E-d分别为彩色和深度信息的能量函数,λ-m和λ-c和λ-d分别为可调参数,具体地,E-c和E-d分别是基于二维图像像素距离信息结合彩色图像或者深度图像的高斯卷积核的卷积结果,上述能量函数可通过雅克比近似的方式进行迭代求解；S2.4：优化得到的仅包含指定物体mask的深度图和颜色图,同样记为D＝[D-1,...,D-L]和I＝[I-1,...,I-L]；S3：进行动作分析,得到目标物体的完整骨骼模型；包括以下步骤：S3.1：把经过前景物体分割后的彩色-深度图序列按照所设定的步长s和长度l,划分为多个时间上重叠的子序列；S3.2：对每个子序列的l帧彩色图和深度图,执行4d ransac算法,得到每个子序列中所对应的关节图；S3.3：对于多个时间上重叠的关节图,依照关节图合并算法,合并多个关节图,得到目标物体的完整骨骼模型；所述关节图合并算法包括以下基本定义：关节模型被抽象为关节图来表示,其中每个关节定义为一条边,即edge,一个刚性分块定义为一个顶点,即node；顶点与顶点之间通过边来连接；在图模型中,除了基本的对顶点和边的增删查功能外,还定义了图模型与图模型之间的一些合并的操作,包括顶点与顶点的合并,边与边的合并,顶点与边的合并,边与顶点的合并；以及最后为了让每个顶点和每条边都拥有全序列生命而利用骨骼连接关系进行的动作变换传播操作；每个node包含起始帧start-frame,刚性分块序号node-id,每帧的node的位置集合centersSet,每帧的动作变换集合transformationsSet,以及表示当前node是否已被处理的状态变量state；每条edge包含起始帧frame,所连接的父分块parent-id和子分块son-id,关节类型jointType,每帧的edge的位置集合positionsSet,每帧的动作变换集合transformationsSet,以及表示当前edge是否已被处理的状态变量state；S4：使用三维重建算法进行三维重建,得到经过前景物体分割后的彩色-深度图序列中的动态物体的三维重建模型；S5：使用绑定算法把三维重建模型上的每个面片都刚性绑定到骨骼模型上；S6：为已经绑定骨骼模型的三维重建模型生成关键帧动画,验证三维重建模型的运动学特性。</td>   <td>G06T7/194;G06T7/215;G06T13/40;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖正首;              黄林冲;              黄帅;                   吴峰       </td>   <td>中山大学</td>   <td>一种不规则颗粒的形状模拟方法、装置及设备</td>   <td>广东省</td>   <td>CN112395712B</td>   <td>2023-08-18</td>   <td>本发明公开了一种不规则颗粒的形状模拟方法,所述模拟方法基于离散元计算方法,其包括如下步骤：a、利用贝塞尔曲线表征待分析颗粒材料的几何形态,并获得待分析颗粒材料的基于贝塞尔曲线的颗粒数学描述；b、对多个待分析颗粒材料进行接触判断,以确定颗粒材料相互之间的接触关系；c、对接触的颗粒材料进行接触特征分析,以获取颗粒材料之间的接触特征。本发明的一种不规则颗粒的形状模拟方法更易于实现对不规则粒子的建模工作,具备显著的可迁移性。相应地,本发明还提供了一种不规则颗粒的形状模拟装置及设备。</td>   <td>1.一种不规则颗粒的形状模拟方法,所述模拟方法基于离散元计算方法,其特征在于,包括如下步骤：a、利用贝塞尔曲线表征待分析颗粒材料的几何形态,通过N段贝塞尔曲线首尾相连形成闭合的颗粒边界,以获得待分析颗粒材料的颗粒数学描述,且N为大于1的自然数；b、对多个待分析颗粒材料进行接触判断,以确定颗粒材料相互之间的接触关系；c、对接触的颗粒材料进行接触特征分析,以获取颗粒材料之间的接触特征；获得待分析颗粒材料的基于贝塞尔曲线的颗粒数学描述,具体包括如下步骤：a1、将待分析的颗粒材料的几何表面分为N个部分,通过P-0、P-1、P-2……P-(N-1)这N个点连接,每个部分均分别用贝塞尔曲线进行表征,对于任一部分,连接点P-i和P-(i+1)同时也表征该段贝塞尔曲线首尾两个控制点；a2、采用三阶贝塞尔曲线对待分析的颗粒材料的几何形状进行表征,其表征的表达式为：B(t)＝(1-t)～3Q-0+3(1-t)～2tQ-1+3(1-t)t～2Q-2+t～3Q-3 0≤t≤1其中,B(t)表示贝塞尔曲线上的点,t表示控制参数,Q-0、Q-1、Q-2、Q-3表示控制点；a3、计算支持点的位置,所述支持点的计算方式如下：s-A(v)＝B(t-v)其中,t-v表示在支持方向为v时对应的控制参数；a4、计算基于贝塞尔曲线的待分析颗粒材料的颗粒质量m及惯性矩I,针对控制参数t进行扫描得到若干边界点,假定边界点的坐标为(x-0,y-0),(x-1,y-1)……(x-(n-1),y-(n-1)),则颗粒质量及惯性矩的求解如下：</td>   <td>G06F30/17;G06F30/25;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   陈佳星       </td>   <td>中山大学</td>   <td>一种基于局部特征关系探究的小样本图像分类方法</td>   <td>广东省</td>   <td>CN113076976B</td>   <td>2023-08-18</td>   <td>本发明提供一种基于局部特征关系探究的小样本图像分类方法,该方法采用了多层次的图神经网络,首先通过局部级图神经网络挖掘每个图像中局部特征之间的关系,提取出图像的更具代表性的局部语义特征；然后通过任务级图神经网络探究每个任务中所有样本的局部语义特征之间的关系,去学习更具区分性的任务级局部语义特征。相比之前的基于图神经网络的小样本学习方法,本发明方法通过多层次的局部关系挖掘,使得学习到的样本间的相似性更细粒度、更准确,从而提升了小样本图像分类的性能。</td>   <td>1.一种基于局部特征关系探究的小样本图像分类方法,其特征在于,包括以下步骤：S1：使用卷积神经网络提取图像的初始局部特征；S2：用S1得到的初始局部特征构造一个局部级图,通过局部级图神经网络提取图像的局部语义特征；S3：用S2得到的所有图像的局部语义特征构造一个任务级图,通过任务级图神经网络探究局部语义特征间的关系,并运用于小样本图像分类；所述步骤S2中,对于每张图像x-p,用步骤S1得到初始局部特征构造一个局部级图图中每个结点表示图像的一个局部特征,将每个结点与其最相似的前k-l结点连接起来,邻接矩阵/&gt;的计算方式如公式(3)(4)：                                    其中函数d(·,·)代表距离计算公式,表示与结点v-i与/&gt;的距离,/&gt;是与结点v-i第k-l近的结点；所述步骤S3中,在小样本图像分类中,每个任务包括N个类,每一类有K个有标签的训练样本和T个无标签的测试样本,对于每个任务,它包含的所有图像的全部局部语义特征表示为H,如公式(8),用每个任务中的所有局部语义特征构造一个任务级图将每个结点与其最相似的k-t个结点连接起来,任务级图的邻接矩阵计算方式如公式(9)(10),通过任务级图神经网络挖掘局部语义特征间的关系,得到任务级局部特征Z,如公式(11)：H＝{H-p | p＝1,…,N×K+T}＝{h～i | i＝1,…,(N×K+T)×r}   (8)                                    Z＝GNN～(task)(A～(task),H)＝ReLU(A～(task)HW～(task))   (11)其中,GNN～(task)(·)表示任务级图神经网络,W～(task)是网络参数。</td>   <td>G06V10/764;G06V10/774;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              夏志武;                   吴永波       </td>   <td>中山大学</td>   <td>一种基于注意力机制的图像描述方法、系统及装置</td>   <td>广东省</td>   <td>CN113095431B</td>   <td>2023-08-18</td>   <td>本发明公开了一种基于注意力机制的图像描述方法、系统及装置,该方法包括：基于编码器模块对图像特征进行处理,得到编码信息；基于解码器模块获取序列向量信息并对编码信息进行解码,得到单词概率分布；重复编码解码步骤直至达到预设次数,输出图像描述。该系统包括：编码器模块、解码器模块和循环模块。该装置包括存储器以及用于执行上述基于注意力机制的图像描述方法的处理器。通过使用本发明,能够充分挖掘出图像中对象之间隐藏的内在语义联系和空间位置关系,生成全面准确的图像描述。本发明作为一种基于注意力机制的图像描述方法、系统及装置,可广泛应用于图像描述生成检测。</td>   <td>1.一种基于注意力机制的图像描述方法,其特征在于,包括以下步骤：S1、获取输入图像的图像特征X并基于预设大小的权重矩阵W-q、W-k和W-v与图像特征X进行点乘,得到对应表示特征的向量集Q、K-1和V-1；S2、对向量集K-1和V-1中分别插入语义关联向量S-k、S-v,得到向量集K-2和V-2；S3、将向量集Q、K-2和V-2输入自注意力模块S,得到特征信息S(X)；S4、将特征表示S(X)经过前向传播和残差连接正则化,得到编码信息S5、获取前一时间步的序列向量信息Y并经过掩码自注意力模块处理得到问询向量Yq；S6、将编码信息经过线性变换得到向量集K-2和V-2；S7、将问询向量Yq、向量集K-2和V-2输入交叉注意力模块得到解码结果C并进一步残差连接和正则化更新解码结果C；S8、将解码结果C经过Sigmoid算子和前向传播,得到单词概率分布S9、以编码信息作为新的图像特征、单词概率分布/&gt;作为新的序列向量表示并返回步骤S1直至循环次数达到四次,输出图像描述。</td>   <td>G06V10/44;G06V10/84;G06V10/82;G06N3/048;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   陈佳星       </td>   <td>中山大学</td>   <td>一种基于拓扑感知文本表征的网络嵌入学习方法</td>   <td>广东省</td>   <td>CN113111224B</td>   <td>2023-08-18</td>   <td>本发明提供一种基于拓扑感知文本表征的网络嵌入学习方法,该方法利用结点的局部拓扑结构信息,自适应地生成拓扑感知滤波器,并用于文本表征的学习,从而得到拓扑感知的文本表征,更有效地将拓扑结构信息融入到文本表征的挖掘中；此外,本方法可以与现有的基于上下文感知的网络嵌入模型相结合,适用面更广,并且在链接预测、结点分类任务上取得了性能提升,体现了本方法学习到的网络结点表征的有效性。</td>   <td>1.一种基于拓扑感知文本表征的网络嵌入学习方法,其特征在于,包括以下步骤：S1：使用图神经网络提取文本网络中结点的局部拓扑结构信息,获取所有结点的拓扑结构表征；S2：将S1得到的结点的拓扑结构表征输入到滤波器生成模块,生成拓扑感知的滤波器,并将得到的拓扑感知滤波器和文本输入到卷积神经网络模块中,生成拓扑感知的文本表征；S3：通过已有的网络嵌入模型获取上下文感知的文本表征,与S2中得到的拓扑感知的文本表征结合起来,得到网络结点最终的文本表征；将拓扑结构表征和文本表征结合起来,得到最终的网络结点表征；所述步骤S1的具体过程包括：首先为网络中的每个结点随机初始化一个拓扑结构表征,结点的初始结构表征用/&gt;表示,根据输入的网络的邻接矩阵,从结点/&gt;的所有邻居结点中随机采样出多跳邻居,每一跳的邻居数量是固定的,对结点/&gt;采样/&gt;跳的邻居后,获得关于结点/&gt;的局部拓扑图；所述步骤S1的具体过程还包括：采样得到结点的局部拓扑图后,再利用图神经网络一层一层地由外往内学习结点的结构表征,如公式(1)(2)：                  其中, 是图神经网络的参数；/&gt;表示第/&gt;个结点在/&gt;层的邻居；用于将所有邻居结点的向量表征聚集起来,构成一个矩阵； /&gt;是激活函数；所述步骤S1的具体过程还包括：经过层后得到结点/&gt;的局部拓扑结构表征,如公式(3)所示：          (3)；所述步骤S2的具体过程包括：将步骤S1得到的拓扑结构表征输入到一个滤波器生成模块,生成拓扑感知的滤波器,如公式(4)：          (4)其中, 表示反卷积神经网络；所述步骤S2的具体过程还包括：将输入文本和拓扑感知滤波器/&gt;一起输入到卷积神经网络中,并通过非线性变换得到基于局部拓扑结构信息的文本表征/&gt;,称为拓扑感知的文本表征,如公式(5)(6)：                  其中, 是卷积神经网络,b是卷积层中的偏置项；/&gt;是非线性激活函数；代表平均池化操作；所述步骤S3的具体过程包括：将文本输入到已有的上下文感知的网络嵌入模型中,获取上下文本感知的文本表征；所述步骤S3的具体过程还包括：将上下文本感知的文本表征与步骤S2中得到的拓扑感知的文本表征/&gt;进行线性加权,得到网络结点最终的文本表征/&gt;,如公式(7)：          (7)其中, 是模型的一个参数；所述步骤S3的具体过程还包括：将步骤S1得到的拓扑结构表征和步骤S3得到的文本表征/&gt;拼接起来,获取最终的网络结点表征/&gt;,如公式(8)：          (8)。</td>   <td>G06F16/901;G06F16/906;G06F16/34;G06N3/042</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              宋日辉;              谭志东;                   凌晔华       </td>   <td>中山大学</td>   <td>一种用于单目内窥镜手术中的多基线融合的深度估计方法</td>   <td>广东省</td>   <td>CN113610908B</td>   <td>2023-08-18</td>   <td>本发明属于深度估计领域和医学图像处理技术领域,更具体地,涉及一种用于单目内窥镜手术中的多基线融合的深度估计方法。能够应用到临床中,起到在术中辅助手术的作用。通过水平移动小段距离对当前手术画面获取两张不同视角的照片,可以对组织纹理较少的手术画面估计出较为准确的深度信息。本发明还提出了一种多基线深度图融合的方法,针对不同的深度范围在合适的基线附近选择多个基线,将不同基线得到的深度图进行融合,保证在不同深度范围时都能生成准确的深度图。</td>   <td>1.一种用于单目内窥镜手术中的多基线融合的深度估计方法,其特征在于,包括以下步骤：S1.采集内窥镜拍摄的照片；S2.根据内窥镜的内参矩阵和畸变系数对照片进行校正；S3.对校正后的照片进行深度估计；S4.用基线选取方法选出当前内窥镜画面中物体所处的深度范围下的最优基线；对每对左右图进行深度估计,深度估计的具体步骤包括：S41.计算每对左右图中两张照片的匹配代价；对两张照片进行水平Sobel处理,之后计算得到BT代价值1,对水平Sobel处理前的两张照片直接计算BT代价值2；将BT代价值1和BT代价值2计算得到的代价值进行相加融合；S42.对融合后的代价值进行成块计算；对每个像素的代价值用周围领域代价值的总和来代替,提高匹配的鲁棒性；S43.对代价值进行SGM优化；对每个像素点P都进行多个路径像素代价的聚合,聚合公式如下：                  S44.计算两张照片的视差；用胜者为王算法,选择代价最优的点作为对应的匹配点；S45.进行视差后处理；包括置信度检测和左右一致性检测；S46.计算深度值z；根据内窥镜内参中的焦距f和外参矩阵[R|T]估算出内窥镜在拍摄两张图片之间移动的基线距离b,根据深度计算公式计算出深度值；深度计算公式如下：z＝f×b/d式中,f是内窥镜焦距,b是基线距离,d是视差值；S5.将最优基线附近的几个基线对应的深度图进行融合,得到最终的深度图；S6.根据融合后的深度图在照片中标注出每个物体的深度值；S7.将标注深度后的照片显示在屏幕上,根据照片中的深度信息判断画面中物体的位置。</td>   <td>G06T7/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴洋鑫;              高一鸣;              梁小丹;                   林倞       </td>   <td>中山大学</td>   <td>一种基于协同模块级搜索的全景分割网络及方法</td>   <td>广东省</td>   <td>CN111862140B</td>   <td>2023-08-18</td>   <td>本发明公开了一种基于协同模块级搜索的全景分割网络及方法,所述网络包括：前景分支模块,基于模块内搜索空间输出前景掩模；背景分支模块,对骨干网络输出的多层不同尺寸的特征图,基于模块内搜索空间搜索得到语义分割结果作为背景特征输出；模块间搜索空间建立单元,基于注意力机制设计模块间搜索空间,以对前景的RPN特征和背景特征进行融合,并根据特征的信息对前景和背景的通道信息进行动态的调整；训练及路径搜索单元,在训练时通过不放回采样对父网络中不同的子网络进行公平的训练,并于训练后采用路径优先的结构搜索方法对父网络进行搜索,得到最优的子网络。</td>   <td>1.一种基于协同模块级搜索的全景分割网络,包括：前景分支模块,用于基于模块内搜索空间寻求最佳的掩膜分支结构,并用搜索得到的最佳掩膜分支结构替换前景分支模块原本的前景掩模分支中的连续普通卷积层,输出前景掩模；背景分支模块,用于对骨干网络输出的多层不同尺寸的特征图,基于模块内搜索空间搜索出最佳的四层子模块结构替换原本的四层子模块,将具有多尺度的逐层特征通过每层的子模块进行提炼处理,最后进行融合得到语义分割结果作为背景特征输出；模块间搜索空间建立单元,用于基于注意力机制设计模块间搜索空间,以对前景的RPN特征和背景特征进行融合,并根据特征的信息对前景和背景的通道信息进行动态的调整；训练及路径搜索单元,用于在训练时通过不放回采样对父网络中不同的子网络进行公平的训练,并于训练后采用路径优先的结构搜索方法对父网络进行搜索,得到最优的子网络；所述模块间搜索空间建立单元基于注意力机制,通过搜索不同扩张系数对应的逐通道缩放的注意力向量来实现前景分支中区域建议网络特征与背景语义分割分支特征的融合；所述模块间搜索空间建立单元将前景分支中RPN基于的特征与背景语义分割分支特征进行逐层融合之后得到F′-l,然后将F′-l与语义分割分支中的背景特征S进行交互融合,所得到的注意力向量通过逐通道乘法动态地调整两者的通道特征；给定所述RPN所基于的第i层特征图对其进行逐层融合：                  其中f(·,·)是卷积及上采样操作,是卷积操作的参数,F′-(i+1)是第i+1层融合的前景特征,/&gt;代表逐元素的加法操作；给定融合特征及背景特征/&gt;其中H为输入图像的高,W为输入图像的宽,C-r为RPN特征通道数,C-s背景分支特征通道数,从前景特征到背景特征的注意力向量通过下式得到：                  其中δ-1和δ-2位非线性激活函数,是′F-l经过全局平均池化产生的逐通道信息,r是用以控制模型复杂度以及泛化性能的扩张系数,从背景特征到前景特征的注意力向量a-(b→f)采用与以上表达式同样的方法得到。</td>   <td>G06T7/194;G06T7/11;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁姗姗;              袁进;              钟培勋;              钟菁;              李新宇;                   张军       </td>   <td>中山大学</td>   <td>一种基于角膜共聚焦图像的菌丝筛查系统</td>   <td>广东省</td>   <td>CN111754457B</td>   <td>2023-08-18</td>   <td>本发明公开了一种基于角膜共聚焦图像的菌丝筛查系统,包括：图像获取模块、诊断模块和菌丝可视化模块；图像获取模块用于获取待检测角膜共聚焦图像；诊断模块用于将待检测角膜共聚焦图像输入至预设的菌丝诊断模型中,以使菌丝诊断模型,对待检测角膜共聚焦图像进行图像特征提取,并根据所提取的图像特征判断检测角膜共聚焦图像是否均在菌丝；菌丝可视化模块用于在判断待检测角膜共聚焦图像存在菌丝时,从待检测角膜共聚焦图像提取菌丝区域,生成包含菌丝区域的可视化图像。通过实施本发明实施例,能自动进行对角膜进行菌丝检测,并在有菌丝时进行可视化展示；一方面提高了检测效率,另一方面无需依赖医生经验,避免了由于经验不足造成的误诊。</td>   <td>1.一种基于角膜共聚焦图像的菌丝筛查系统,其特征在于,包括：图像获取模块、诊断模块和菌丝可视化模块；所述图像获取模块,用于获取待检测角膜共聚焦图像；所述诊断模块,用于将所述待检测角膜共聚焦图像输入至预设的菌丝诊断模型中,以使所述菌丝诊断模型,对所述待检测角膜共聚焦图像进行图像特征提取,并根据所提取的图像特征判断所述检测角膜共聚焦图像是否存在菌丝；所述菌丝可视化模块,用于在判断所述待检测角膜共聚焦图像存在菌丝时,从所述待检测角膜共聚焦图像提取菌丝区域,生成包含所述菌丝区域的可视化图像；所述菌丝可视化模块从所述待检测角膜共聚焦图像提取菌丝区域,生成包含所述菌丝区域的可视化图像,具体包括：所述菌丝可视化模块对所述待检测角膜共聚焦图像进行相干滤波,获得第一滤波图像；对所述第一滤波图像进行双边滤波,获得第二滤波图像；对所述第二滤波图像进行全局阈值二值化操作,生成二值图像,并对所述二值图像进行全局阈值分割,获得初始菌丝区域二值图像；对所述二值图像进行形态学操作,并将进行形态学操作后的二值图像与所述初始菌丝区域二值图像作差,获得细化菌丝区域二值图像；将所述细化菌丝区域二值图像进行颜色映射,获得彩色化菌丝区域图像；将所述彩色化菌丝区域图像与所述待检测角膜共聚焦图像进行叠加,生成包含所述菌丝区域的可视化图像；所述菌丝筛查系统还包括,菌丝占比计算模块和感染程度分级模块；所述菌丝占比计算模块,用于在判断所述待检测角膜共聚焦图像存在菌丝时,计算所述菌丝区域与所述待检测角膜共聚焦图像的面积比,生成菌丝占比；所述感染程度分级模块,用于根据所述菌丝占比确定角膜的感染程度等级。</td>   <td>G06T7/00;G06T7/11;G06T7/136;G06T5/30;G06N3/0464;G06N3/08;G16H15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         潘存雪;              王燕林;              陈剑;              张源;              秦培鑫;              鲁玲;              贾韬宇;                   扈锋       </td>   <td>中山大学附属第五医院</td>   <td>一种心肌局灶性瘢痕检测方法、风险预测方法和相关装置</td>   <td>广东省</td>   <td>CN116245878B</td>   <td>2023-08-18</td>   <td>本发明公开了一种心肌局灶性瘢痕检测方法、风险预测方法和相关装置,先基于预置左心室壁心肌自动分割模型对基于单能量CCTA或双能量CCTA扫描到的心肌图像进行体素二分类分割,得到左心室壁心肌图像,再基于预置心肌局灶性瘢痕定位模型对左心室壁心肌图像的低密度灶进行体素三分类分割,得到心肌局灶性瘢痕定位图像。解决了现有技术存在的操作技术难度大、检测耗时长、费用高、碘对比剂用量大和辐射剂量高的技术问题。</td>   <td>1.一种心肌局灶性瘢痕检测方法,其特征在于,包括：基于预置左心室壁心肌自动分割模型对基于单能量CCTA或双能量CCTA扫描到的心肌图像进行体素二分类分割,得到左心室壁心肌图像,其中,体素二分类分割结果包括左心室壁心肌组织和非左心室壁心肌组织,对于对双能量CCTA扫描到的心肌图像进行体素二分类分割得到的体素二分类分割结果,采用高级标准化工具进行配准与标准化处理,得到左心室壁心肌图像；基于预置心肌局灶性瘢痕定位模型对左心室壁心肌图像的低密度灶进行体素三分类分割,得到心肌局灶性瘢痕定位图像,其中,体素三分类分割结果包括心肌局灶性瘢痕、心肌射线硬化伪影和正常心肌；基于预置心肌局灶性瘢痕定位模型对左心室壁心肌图像的低密度灶进行体素三分类分割,得到心肌局灶性瘢痕定位图像,包括：基于预置心肌局灶性瘢痕定位模型对左心室壁心肌图像的低密度灶进行体素三分类分割,得到心肌局灶性瘢痕图像；对心肌局灶性瘢痕图像计算心肌局灶性瘢痕体积,得到心肌局灶性瘢痕定量信息；基于心肌局灶性瘢痕定量信息和心肌节段划分信息,对心肌局灶性瘢痕进行定位,得到心肌局灶性瘢痕定位图像。</td>   <td>G06T7/00;G06T7/70;G06V10/26;G06V10/764;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              张宏伟       </td>   <td>中山大学</td>   <td>时空因果映射驱动的混合重要性高斯滤波方法及装置</td>   <td>广东省</td>   <td>CN116611232A</td>   <td>2023-08-18</td>   <td>本发明公开了一种时空因果映射驱动的混合重要性高斯滤波方法及装置,包括建立多站纯方位跟踪系统模型；定义动态系统的状态演化和最新时刻空间测量之间的时空因果映射；基于稀疏结构正则化跟踪有效测量信息,近似截断先验概率密度函数；根据高斯埃尔米特法则从截断先验采样积分点和积分权值；对积分点集合进行重要性采样；通过瑞利熵衡量截断先验和原始先验对系统状态演化的修正和补偿作用,构建混合重要性函数,计算重要性权重因子。重构时空因果不变的预测和更新步骤,将混合重要性采样融入Hermite积分框架,通过重要性权重因子修正积分点权值,提升权值自适应性和状态滤波精度,提高目标跟踪系统中系统状态估计的准确性和鲁棒性。</td>   <td>1.一种时空因果映射驱动的混合重要性高斯滤波方法,其特征在于,包括如下步骤：步骤1,建立多站纯方位跟踪系统模型；步骤2,定义动态系统的状态演化和最新时刻空间测量之间的时空因果映射；步骤3,基于稀疏结构正则化跟踪有效测量信息,进而近似截断先验概率密度函数；步骤4,根据高斯埃尔米特法则从截断先验采样积分点和积分权值,并对积分点集合进行重要性采样,通过瑞利熵衡量截断先验和原始先验对系统状态演化的修正和补偿作用,据此构建混合重要性函数,计算重要性权重因子；步骤5,在预测和更新过程中通过重要性权重因子修正积分点权值,并输出滤波结果。</td>   <td>G06F30/20;G06F17/15</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张云鹏;              王帆;              韦立坚;              李杰;                   覃振杰       </td>   <td>中山大学;广州金融科技股份有限公司</td>   <td>地方金融机构的风险评估与多维度监测预警方法、系统</td>   <td>广东省</td>   <td>CN116611689A</td>   <td>2023-08-18</td>   <td>本发明提出一种地方金融机构的风险评估与多维度检测预警方法、系统,涉及数据挖掘与风险度量的技术领域,通过采集地方金融机构的经营管理数据,以构建针对地方金融机构的多维度风险指标体系,然后计算一级风险对应的各个二级风险指标的权重和地方金融机构的风险得分,实现对地方金融机构的整体风险评价,基于风险得分划分风险等级,为现场检查提供依据和指导,使现场检查更有针对性,从而有利于合理分配监管资源,发挥现场检查的最大效力。</td>   <td>1.一种地方金融机构的风险评估与多维度检测预警方法,其特征在于,S1.采集地方金融机构的经营管理数据；S2.基于经营管理数据,设计一级风险维度和一级风险维度对应的二级风险指标体系；S3.对采集到的经营管理数据进行预处理；S4.计算一级风险对应的各个二级风险指标的权重,基于各个二级风险指标的权重,计算地方金融机构的风险得分；S5.基于地方金融机构的风险得分,进行风险等级划分,根据风险等级分类结果进行预警。</td>   <td>G06Q10/0635;G06Q40/03</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖贤城;              谢晓华;                   赖剑煌       </td>   <td>中山大学</td>   <td>一种基于单阶段多任务协同学习的人像抠图方法及系统</td>   <td>广东省</td>   <td>CN112396598B</td>   <td>2023-08-15</td>   <td>本发明公开了一种基于单阶段多任务协同学习的人像抠图方法及系统,该方法包括：获取数据集并对数据集进行预处理,得到训练人像图、对应的透明度图和对应的三元图；将训练人像图输入到预构建抠图模型,生成训练的三元图和训练的透明度图；损失计算并更新预构建抠图模型的参数,得到训练完成的抠图模型；获取待测图像并输入到训练完成的抠图模型,得到人像前景图。该系统包括：数据预处理模块、训练模块、参数更新模块和预测模块。通过使用本发明,解决现有技术中抠图阶段容易由三元图阶段的错误导致抠图阶段的预测错误。本发明作为一种基于单阶段多任务协同学习的人像抠图方法及系统,可广泛应用于图像抠图领域。</td>   <td>1.一种基于单阶段多任务协同学习的人像抠图方法,其特征在于,包括以下步骤：获取数据集并对数据集进行预处理,得到训练人像图、对应的透明度图和对应的三元图；将训练人像图输入到预构建抠图模型,生成训练的三元图和训练的透明度图；将训练的三元图和训练的透明度图与数据集该训练人像图对应的三元图和对应的透明度图进行损失计算并更新预构建抠图模型的参数,得到训练完成的抠图模型；获取待测图像并输入到训练完成的抠图模型,得到人像前景图；所述将训练人像图输入到预构建抠图模型,生成训练的三元图和训练的透明度图这一步骤,其具体包括：将训练人像图输入到预构建抠图模型,经过三元图支路中的深层特征提取器生成特征图；将特征图经过三元图支路中的解码器生成训练的三元图；将特征图经过主体粗抠支路生成训练的主体透明度图；将训练人像图经过边缘精抠支路的无下采样的浅层编码器得到编码图；将特征图输入到边缘精抠支路并与编码图拼接,经过无下采样的解码器后生成训练的边缘透明度图；根据训练的主体透明度图和训练的边缘透明度图生成训练的最终透明度图；所述将训练的三元图和训练的透明度图与数据集该训练人像图对应的三元图和对应的透明度图进行损失计算并更新预构建抠图模型的参数,得到训练完成的抠图模型这一步骤,其具体包括：将训练的三元图与数据集中该训练人像图对应的三元图逐像素计算交叉熵损失,得到三元图损失；将训练的主体透明度图与数据集中该训练人像图对应的透明度图计算均方误差,得到主体透明度图均方误差；将训练的边缘透明度图与数据集中该训练人像图对应的透明度图计算均方误差,得到边缘透明度图均方误差；将训练的最终透明度图与数据集中该训练人像图对应的透明度图计算均方误差,得到最终透明度图均方误差；根据三元图损失、主体透明度图均方误差、边缘透明度图均方误差和最终透明度图均方误差,得到总损失函数；根据总损失函数对预构建扣图模型参数进行迭代更新,得到训练完成的抠图模型。</td>   <td>G06T7/00;G06T7/194;G06T5/30;G06T3/40;G06N3/0464;G06N3/08</td>  </tr> </table></body></html>