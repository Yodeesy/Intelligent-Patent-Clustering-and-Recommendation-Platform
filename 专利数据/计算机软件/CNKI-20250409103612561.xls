<html xmlns:o='urn:schemas-microsoft-com:office:office' xmlns:x='urn:schemas-microsoft-com:office:excel' xmlns='http://www.w3.org/TR/REC-html40'><head><style>table td,th{vnd.ms-excel.numberformat:@;text-align: center;} table th{color:red}</style><title></title><meta http-equiv='Content-Type' content="text/html; charset=utf-8"></head><body><table cellspacing='0' border='1'>     <tr>   <td style='vnd.ms-excel.numberformat:@'>SrcDatabase-来源库</td>   <td style='vnd.ms-excel.numberformat:@'>Author-作者</td>   <td style='vnd.ms-excel.numberformat:@'>Applicant-申请人</td>   <td style='vnd.ms-excel.numberformat:@'>Title-题名</td>   <td style='vnd.ms-excel.numberformat:@'>CountryName-国省名称</td>   <td style='vnd.ms-excel.numberformat:@'>PubNo-公开号</td>   <td style='vnd.ms-excel.numberformat:@'>PubTime-公开日期</td>   <td style='vnd.ms-excel.numberformat:@'>Summary-摘要</td>   <td style='vnd.ms-excel.numberformat:@'>Claims-主权项</td>   <td style='vnd.ms-excel.numberformat:@'>CLC-中图分类号</td>  </tr>  <tr>   <td>中国专利</td>   <td>         谢晓华;              林民钊;                   赖剑煌       </td>   <td>中山大学</td>   <td>基于垂直俯视角的行人标注、检测和性别识别方法</td>   <td>广东省</td>   <td>CN112668508B</td>   <td>2023-08-15</td>   <td>本发明公开了一种基于垂直俯视角的行人标注、检测和性别识别方法,包括：获取视频并基于视频得到视频帧的垂直俯视角图像；基于视频标注方法对垂直俯视角图像进行标注,得到行人旋转全身框；基于行人旋转全身框构建行人轨迹并对行人轨迹进行性别属性标注,得到带标签的行人旋转全身框；基于行人旋转全身框对预构建的行人检测网络进行训练,得到行人检测模型；基于带标签的行人旋转全身框对预构建的行人性别识别网络进行训练,得到行人性别识别模型。本发明基于垂直俯视角的情况下不会涉及行人的身份特征,能很好地保护行人隐私。本发明作为一种基于垂直俯视角的行人标注、检测和性别识别方法,可广泛应用于行人检测领域。</td>   <td>1.基于垂直俯视角的行人标注、检测和性别识别方法,其特征在于,包括以下步骤：获取视频并基于视频得到视频帧的垂直俯视角图像；基于视频标注方法对垂直俯视角图像进行标注,得到行人旋转全身框；基于行人旋转全身框构建行人轨迹并对行人轨迹进行性别属性标注,得到带标签的行人旋转全身框；基于行人旋转全身框对预构建的行人检测网络进行训练,得到行人检测模型；基于带标签的行人旋转全身框对预构建的行人性别识别网络进行训练,得到行人性别识别模型；所述基于行人旋转全身框对预构建的行人检测网络进行训练,得到行人检测模型这一步骤,其具体包括：将带有行人旋转全身框的垂直俯视角图像输入到预构建的行人检测网络,得到行人中心点结果图、行人中心点偏移量结果图、行人脚点相对于中心点偏移量结果图和行人全身框宽高结果图；基于行人中心点结果图、行人中心点偏移量结果图、行人脚点相对于中心点偏移量结果图和行人全身框宽高结果图构建行人中心点预测损失函数、行人中心点偏移量预测损失函数、行人脚点相对于中心点偏移量预测损失函数和行人宽高预测损失函数；将行人中心点预测损失函数、行人中心点偏移量预测损失函数、行人脚点相对于中心点偏移量预测损失函数和行人宽高预测损失函数进行加权处理得到行人检测最终损失函数；基于行人检测最终函数对预构建的行人检测网络的参数进行更新,得到行人检测模型；行人中心点预测损失函数如下式：                  其中,α和β是超参数,N是图像I的真实标签行人中心点数量,Y-(xyc)＝1时表示在结果图中(x,y,c)坐标下真实标签行人中心点位置,表示行人检测网络在结果图中(x,y,c)坐标下的预测值；行人中心点偏移量预测损失函数如下式：其中,p表示真实标签的在原图分辨率下的行人中心点,表示预测的在结果图分辨率下的行人中心点,/&gt;表示在p点的行人中心点偏移量预测值；行人宽高预测损失函数如下式：                  其中,s-k表示目标k在结果图分辨率下的真实宽高,表示目标k在结果图分辨率下的预测宽高。</td>   <td>G06V20/52;G06V10/25;G06V10/82;G06N3/0464;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;              陈志炜;                   黄俊源       </td>   <td>中山大学</td>   <td>EfficientNet的注意力机制的硬件计算方法</td>   <td>广东省</td>   <td>CN112862080B</td>   <td>2023-08-15</td>   <td>本发明提供一种EfficientNet的注意力机制的硬件计算方法,该方法对EfficientNet的注意力机制模块实现了硬件的计算,对深度卷积层后的注意力机制模块设计了硬件进行相应计算,减少注意力机制模块所需计算时间,加速得到在深度卷积后进行注意力机制模块运算的结果特征。有助于卷积层的流水式运行,减少卷积神经网络卷积块的计算延时。</td>   <td>1.一种EfficientNet的注意力机制的硬件计算方法,其特征在于,包括以下步骤：S1：通过深度卷积计算引擎和注意力机制硬件完成EfficientNet的深度卷积和注意力机制运算的计算；S2：通过深度卷积计算引擎和注意力机制硬件完成EfficientNet的MBconvBlock的运算；所述步骤S1中,在全局控制单元的控制下,从特征图缓冲区读取特征图,从权重缓冲区读取权重,进行深度卷积运算,进行Hswish函数激活；Hswish函数激活的硬件数量等于卷积计算阵列每个周期输出的结果的个数,深度卷积计算引擎并行输出的结果能立刻进行激活,实现输出数据流过Hswish函数激活硬件；所述步骤S1中,得到经过激活的结果送入注意力模块硬件,其过程为将激活的结果按同一个输出通道的安排送入加法树进行累加,同时每个周期的激活的结果以并行的数据读写方式写入深度卷积引擎输出特征缓冲区；步骤S1中,等到深度卷积阵列把该深度卷积层的运算算完后,此时同一个输出通道的激活结果也累加完,求平均数后得到了用于一维降维卷积的系数；当得到用于一维降维卷积的全部系数,在几个时钟周期内执行完一维降维卷积,其后执行一维升维卷积,得到全部的用于通道相乘的系数；步骤S1中,以并行数据流的方式从深度卷积引擎输出特征缓冲区读出特征送入乘法器完成每个通道的特征和对应每个通道的系数的相乘,此时得到的特征图即是经过注意力模块运算的特征图,以并行数据方式送去输入特征缓冲区；步骤S2中,实现深度卷积引擎的分时复用计算MBconvBlock块的第一层卷积,第二层深度卷积和第三层卷积；加载第一层卷积的输入特征和权重,正常启动卷积计算,但不启动注意力机制硬件；步骤S2中,等算完第一层卷积的时候,将输出特征缓冲区的结果送入特征缓冲区,开始进行深度卷积和注意力机制的运算工作；步骤S2中,深度卷积输出特征缓冲区的数据经过通道乘法器阵列送到输入特征缓冲区,开启第三层卷积的运算；步骤S2中,如果MBconvBlock块有输入特征残差项相加,则将MBconvBlock块的第一层逐点卷积的输入特征和第三层逐点卷积的输出特征图进行相加；步骤S2中,经过三个卷积层计算而完成了一个MBconvBlock块的计算,将特征结果送出到外部存储器。</td>   <td>G06N3/0464;G06N3/063;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;                   陈崇雨       </td>   <td>中山大学</td>   <td>一种基于稀疏正源分离模型的图像去模糊算法</td>   <td>广东省</td>   <td>CN110313016B</td>   <td>2023-08-15</td>   <td>一种基于稀疏正源分离模型的图像去模糊算法,用于对光学显微成像系统采集到的因衍射效应与光学偏差而产生的模糊图像进行处理,可以在单次感光成像并且不增加外部成像设备的情况下,将光学显微系统的空间分辨率提升到纳米量级。在所述方法中,显微成像的模糊过程被表示为成像系统点扩散函数的线性组合。将该过程嵌入正源分离的优化框架中,对其加入稀疏性约束并求解以去除模糊,从而实现高分辨显微成像。所述方法还包括对实际光学显微镜的预处理步骤,通过去除显微图像中的背景散射等干扰,使得输入的模糊图像更符合所提的成像模型。有关实验表明,将单个模糊显微图像作为输入,所述方法取得了比其他方法更好的细节解析性能。</td>   <td>1.一种基于稀疏正源分离模型的图像去模糊算法,其特征在于,包括以下步骤：S1：对光学系统进行标定；S2：将图像内容进行稀疏化；S3：建立成像矩阵A和求解稀疏正源分离优化模型；所述步骤S2中,当多张连续的显微图像可用时,图像内容稀疏化的主要目的就是去除背景干扰,感兴趣的稀疏结构看作是前景,而背景干扰看作是背景,使用稀疏低秩矩阵分解来对图像进行稀疏化；当只有一张模糊的显微图像可用时,图像内容稀疏化的主要目的就是去除图像中的直流分量,包括来自于成像设备在曝光过程中的自发性持续信号,或者由于背景反光/发光而得到的平滑图像内容,使用直流分量消除的方法来对图像进行稀疏化。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              王阔;              刘凌波;                   林倞       </td>   <td>中山大学</td>   <td>一种航空图像道路提取方法及设备</td>   <td>广东省</td>   <td>CN113076811B</td>   <td>2023-08-15</td>   <td>本发明公开了一种航空图像道路提取方法及设备,本发明通过在道路提取模型中对原始航空图像以及GPS热度图进行局部信息提取,将提取到的航空图像局部信息和所述GPS热度图局部信息进行融合,得到航空图像特征图以及GPS热度特征图,基于航空图像特征图以及GPS热度特征图,得到所述航空图像的道路提取结果。本发明通过将航空图像局部信息和GPS热度图局部信息进行融合,从而极大地提高了道路提取效果；航空图像中的遮挡问题以及铁路和道路的混淆问题,可以通过GPS轨迹很好地解决,而GPS轨迹数据中的偏移问题,噪声问题又能够通过航空图像信息来得到缓解,从而使得道路的提取结果准确率高,鲁棒性强。</td>   <td>1.一种航空图像道路提取方法,其特征在于,包括以下步骤：获取原始航空图像以及与所述原始航空图像相对应的GPS热度图；将所述原始航空图像以及所述GPS热度图输入到预先设置好的道路提取模型中,以使所述道路提取模型从所述原始航空图像中提取出航空图像局部信息,从所述GPS热度图中提取出GPS热度图局部信息,并对所述航空图像局部信息和所述GPS热度图局部信息进行融合,得到航空图像特征图以及GPS热度特征图,基于所述航空图像特征图以及所述GPS热度特征图,得到所述航空图像的道路提取结果；所述道路提取模型包括第一语义分割网络以及第二语义分割网络：所述第一语义分割网络从所述原始航空图像中提取出航空图像局部信息,所述第二语义分割网络从所述GPS热度图中提取出GPS热度图局部信息,继而所述道路提取模型将所述航空图像局部信息和所述GPS热度图局部信息进行融合,得到航空图像特征图和GPS热度特征图,所述第一语义分割网络基于所述航空图像特征图,输出最终航空图像特征图,所述第二语义分割网络基于所述GPS热度特征图,输出最终GPS热度图特征图,最终所述道路提取模型将所述最终航空图像特征图和所述最终GPS热度图特征图进行卷积,得到所述航空图像的道路提取结果；所述第一语义分割网络包括N层第一子网络,所述第二语义分割网络包括N层第二子网络,其中N为正整数；第i层第一子网络从第i-1航空图像中提取出第i航空图像局部信息,第i层第二子网络从第i GPS热度图中提取出第i GPS热度图局部信息,继而所述道路提取模型将所述第i航空图像局部信息和所述第i GPS热度图局部信息进行融合,得到第i航空图像特征图和第iGPS热度特征图,之后分别将所述第i航空图像特征图和所述第i GPS热度特征图发送到第i+1层第一子网络和第i+1层第二子网络中,遍历每一层第一子网络和每一层第二子网络直至i=N,得到第N层第一子网络输出的所述最终航空图像特征图和第N层第二子网络输出的所述最终GPS热度图特征图；其中,i∈[1,N],当i=1时,第i-1航空图像为所述原始航空图像,第i-1 GPS热度图为与所述原始航空图像相对应的GPS热度图；所述道路提取模型将所述第i航空图像局部信息和所述第i GPS热度图局部信息进行融合,得到第i航空图像特征图和第i GPS热度特征图的具体过程为：所述道路提取模型基于所述第i航空图像局部信息生成第i航空图像全局信息,基于所述第i GPS热度图局部信息生成第i GPS热度图全局信息；基于所述第i航空图像局部信息、第i航空图像全局信息以及所述第i GPS热度图局部信息生成第i GPS热度特征图；所述道路提取模型基于所述第i GPS热度图局部信息、第i GPS热度图全局信息以及所述第i航空图像局部信息,生成所述第i 航空图像特征图。</td>   <td>G06V20/10;G06V30/422;G06V10/80;G06V20/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   张权       </td>   <td>中山大学</td>   <td>一种基于多模态人脸训练的单模态人脸活体检测方法</td>   <td>广东省</td>   <td>CN113705400B</td>   <td>2023-08-15</td>   <td>本发明公开了一种基于多模态人脸训练的单模态人脸活体检测方法,包括：获取输入数据并基于输入数据训练预构建的生成对抗网络,得到训练完成的生成对抗网络,所述预构建的生成对抗网络包括生成器和判别器；基于训练完成的生成对抗网络合成数据集并训练类多模态人脸活体检测模型,得到训练完成的类多模态人脸活体检测模型；获取单模态待测图像；基于生成对抗网络将单模态待测图像扩展为多模态人脸图像,并输入至练完成的多模态人脸活体检测模型进行判别。本发明提高传统单模态人脸活体检测模型性能的同时,还降低了实际场景下的硬件成本。本发明作为一种基于多模态人脸训练的单模态人脸活体检测方法,可广泛应用于计算机视觉领域。</td>   <td>1.一种基于多模态人脸训练的单模态人脸活体检测方法,其特征在于,包括以下步骤：S1、获取输入数据并基于输入数据训练预构建的生成对抗网络,得到训练完成的生成对抗网络,所述预构建的生成对抗网络包括生成器和判别器；S2、基于训练完成的生成对抗网络合成数据集并训练类多模态人脸活体检测模型,得到训练完成的类多模态人脸活体检测模型；S3、获取单模态待测图像；S4、基于生成对抗网络将单模态待测图像扩展为多模态人脸图像,并输入至练完成的多模态人脸活体检测模型进行判别,得到检测结果；所述获取输入数据并基于输入数据训练预构建的生成对抗网络,得到训练完成的生成对抗网络这一步骤,其具体包括：获取输入数据并对输入数据中的原始人脸图片进行尺寸调整,所述输入数据中的原始人脸图片中可见光信息、近红外信息和深度信息的图片数量比设置为1:1:1；基于输入数据对生成对抗网络中的生成器和判别器进行交替训练；固定判别器,训练生成器,得到训练完成的生成器；固定生成器,训练判别器,得到训练完成的判别器；得到训练完成的生成对抗网络；所述生成器包括第一特征粗提取单元、下采样特征提取单元、隐层特征学习单元、上采样特征提取单元和目标图像生成单元,所述固定判别器,训练生成器,得到训练完成的生成器这一步骤,其具体包括：对于输入数据中的原始人脸图片及其原始模态标签,随机给定一个目标模态标签并以独热编码的形式编码；将目标模态标签重复拓展为原始人脸图片的尺寸大小,并与原始人脸图片进行拼接,得到整合数据；将整合数据经过特征粗提取单元处理,维持整合数据的大小尺寸不变,将通道数扩展为64维,得到第一特征图；基于下采样特征提取单元对第一特征图进行处理,扩展通道数,得到第二特征图；基于隐层特征学习单元对第二特征图进行处理,生成残差特征并相加,得到第三特征图；基于上采样特征提取单元对第三特征图进行处理,压缩通道数,得到第四特征图；基于目标图像生成单元对第四特征图进行处理,将通道数压缩为3维生成第五特征图并将第五特征图中的数值归一化,得到生成人脸；将生成人脸和原始模态标签送入生成器,得到生成人脸在原始模态标签下的重构人脸；采用L1正则化约束重构人脸和原始人脸图片的距离；基于判别器对生成人脸进行判别,得到判别结果；基于对抗损失函数优化生成器和判别器之间的损失误差,得到训练完成的生成器；所述类多模态人脸活体检测模型由三个结构相同的特征提取分支构成,每个特征提取分支中的卷积层均为深度拉普拉斯卷积层对于一个输入特征f-(in),其输出结果为：                  其中,为标准拉普拉斯算子,w-(kernel)代表当前/&gt;中的深度卷积核,/&gt;代表卷积操作,θ＝0.7代表两部分卷积操作所占的比重。</td>   <td>G06V40/16;G06V40/40;G06V10/80;G06V10/774;G06V10/82;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              庞礼铧;              王雅琦;              王和旭;              韦骏;              张淏酥;                   张晓鹤       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种三维流场重构方法、系统、电子设备及存储介质</td>   <td>广东省</td>   <td>CN116597085A</td>   <td>2023-08-15</td>   <td>本发明公开了一种三维流场重构方法、系统、电子设备及存储介质,包括：确定全球范围内的表层流场数据和深层流场数据,根据表层流场数据和深层流场数据确定整体尺度的第一流场数据；获取局部尺度中包括海域流速流向、温盐密压的参数,得到局部尺度的第二流场数据；构建初始重构模型,采用第二流场数据对初始重构模型进行训练,得到目标重构模型；进而对第一流场数据进行超分辨率重建,得到三维重构流场。本发明实施例能够对全球尺度的海洋进行多尺度的三维流场重构,并且通过超分辨率重建能够获得高精度、高分辨率的三维重构流场,该模型能够反映全球尺度的三维空间内任意海域的某一特定点位的流场数据。本发明可以广泛应用于流场重构技术领域。</td>   <td>1.一种三维流场重构方法,其特征在于,包括：确定全球范围内的表层流场数据和深层流场数据,根据所述表层流场数据和所述深层流场数据确定整体尺度的第一流场数据；获取局部尺度中包括海域流速流向、温度、盐度、密度和压力的参数,得到局部尺度的第二流场数据；构建初始重构模型,采用所述第二流场数据对所述初始重构模型进行训练,得到目标重构模型；通过所述目标重构模型对所述第一流场数据进行超分辨率重建,得到三维重构流场。</td>   <td>G06T17/00;G06N3/0475;G06N3/045;G01P5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任传贤;                   许耿鑫       </td>   <td>中山大学</td>   <td>一种受临床决策过程启发的鼻咽癌病灶分割方法</td>   <td>广东省</td>   <td>CN116596831A</td>   <td>2023-08-15</td>   <td>本发明提出一种受临床决策过程启发的鼻咽癌病灶分割方法,涉及鼻咽癌病灶分割的技术领域,解决了在当前鼻咽癌肿瘤区域分割方法中,鼻咽癌病灶分割效率低和鼻咽癌病灶分割结果的不可解释性的问题的问题,首先利用诊断模型对预处理的三维MRI影像进行诊断,诊断出癌变的三维MRI影像,然后利用病灶分割模型对癌变的三维MRI影像进行多尺度分割,逐步精细化得到癌变的三维MRI影像的病灶分割结果,有效地提高了鼻咽癌病灶分割效率,保证了鼻咽癌病灶结果的可解释性。</td>   <td>1.一种受临床决策过程启发的鼻咽癌病灶分割方法,其特征在于,包括以下步骤：S1.获取一定数量的鼻咽癌病人的三维MRI影像,组成三维MRI影像数据集；S2.对三维MRI影像数据集中的三维MRI影像进行预处理；S3.构建用于诊断癌变的三维MRI影像的癌变诊断模型；S4.将三维MRI影像数据集划分为训练集和测试集,利用训练集对癌变诊断模型进行训练,并利用测试集测试癌变诊断模型的有效性,得到训练好的癌变诊断模型；S5.将S2预处理后的三维MRI影像输入训练好的癌变诊断模型,输出癌变的三维MRI影像；S6.构建用于对癌变的三维MRI影像进行多尺度分割的病灶分割模型；S7.利用癌变的三维MRI影像训练病灶分割模型,得到训练好的病灶分割模型；S8.采集待预测MRI影像,将待预测MRI影像输入训练好的癌变诊断模型,输出癌变的待预测MRI影像,将诊断为癌变的待预测MRI影像输入训练好的病灶分割模型,输出癌变的待预测MRI影像的病灶分割结果。</td>   <td>G06T7/00;G06V10/26;G06V10/52;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵玮;                   古威丽       </td>   <td>中山大学;中山大学附属口腔医院</td>   <td>一种牙面病灶的识别方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN116596861A</td>   <td>2023-08-15</td>   <td>本申请属于图像识别技术领域,公开了一种牙面病灶的识别方法、系统、设备及存储介质。通过获取待识别者的口腔图像,口腔图像包含所述待识别者的若干种不同的牙面特征；将获取的口腔图像输入到由YOLOv5模型训练得到的牙体检测模型中,进行第一阶段的牙体目标识别,得到包含单颗牙体的牙体切片；将第一阶段得到的牙体切片输入到由YOLOv5+MASK R-CNN联合模型训练得到的病灶检测模型中,进行第二阶段的病灶目标识别,得到病灶识别结果,实现对于普通口腔图像中牙齿上着色病灶的精确识别。</td>   <td>1.一种牙面病灶的识别方法,其特征在于,所述识别方法包括：获取待识别者的口腔图像,所述口腔图像包含若干种不同的牙面特征；将所述获取的口腔图像输入到由YOLOv5模型训练得到的牙体检测模型中,进行第一阶段的牙体目标识别,得到包含单颗牙体的牙体切片；将所述第一阶段得到的牙体切片输入到由YOLOv5+MASK R-CNN联合模型训练得到的病灶检测模型中,进行第二阶段的病灶目标识别,得到病灶识别结果。</td>   <td>G06T7/00;G06V10/774;G06V10/82;G06N3/0464;G06N3/08;G06V10/764;G06V10/44;G06V10/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         柯晴青;              程春龙;                   龚小月       </td>   <td>中山大学</td>   <td>一种SAW应变传感器设计方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116595846A</td>   <td>2023-08-15</td>   <td>本发明提供了一种SAW应变传感器设计方法,所述方法包括：在有限元软件中建立SAW应变传感器的仿真模型和待测构件；选择第一参数的压电薄膜和第二参数的衬底,以配置所述仿真模型；通过对待测构件在第一方向上施加边界载荷及在反方向施加固定约束,检测所述压电薄膜的上表面所在应变测试区在第一方向上的第一应变值、以及待测构件所在应变测试区在第一方向上的第二应变值；根据所述第一应变值和第二应变值,计算所述仿真模型的应变传递率；通过调整第二参数中的衬底结构参数和衬底材料参数,使所述应变传递率达到第一预定值；输出所述仿真模型。本发明能够解决传统SAW应变传感器在设计时应变检测范围较小,难以调控的问题。</td>   <td>1.一种SAW应变传感器设计方法,其特征在于,所述方法包括：在有限元软件中建立SAW应变传感器的仿真模型和待测构件；所述仿真模型包括压电薄膜和衬底,所述压电薄膜上设置有应变测试区；选择第一参数的压电薄膜和第二参数的衬底,以配置所述仿真模型；所述第一参数包括压电薄膜密度-、相对介电常数、压电系数和弹性系数,所述第二参数包括衬底结构参数和衬底材料参数；通过对待测构件在第一方向上施加边界载荷及在反方向施加固定约束,检测所述压电薄膜的上表面所在应变测试区在第一方向上的第一应变值、以及所述待测构件所在应变测试区在第一方向上的第二应变值；根据所述第一应变值和第二应变值,计算所述仿真模型的应变传递率；通过调整第二参数中的衬底结构参数和衬底材料参数,使所述应变传递率达到第一预定值；输出所述仿真模型。</td>   <td>G06F30/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭舟;              温江天;                   许瑞       </td>   <td>中山大学</td>   <td>一种功能区制图方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN116580306A</td>   <td>2023-08-11</td>   <td>本发明公开了一种功能区制图方法、装置、终端设备及存储介质,所述方法包括：获取待制图区域的区域图像；将所述区域图像输入至功能区识别模型中,以使所述功能区识别模型对所述区域图像中的各个功能区类别进行识别；在识别后对所述区域图像中的各个功能区类别进行标识,生成待制图区域对应的功能区图像；其中,所述功能区识别模型的构建包括：获取待制图区域的各功能分区的区域样本图像；以各所述区域样本图像为输入,以各区域样本图像所对应的功能区类别为输出,对预设的神经网络模型进行训练,生成所述功能区识别模型。通过实施本发明能提高制图效率和准确性。</td>   <td>1.一种功能区制图方法,其特征在于,包括：获取待制图区域的区域图像；将所述区域图像输入至功能区识别模型中,以使所述功能区识别模型对所述区域图像中的各个功能区类别进行识别；在识别后对所述区域图像中的各个功能区类别进行标识,生成待制图区域对应的功能区图像；其中,所述功能区识别模型的构建包括：获取待制图区域的各功能分区的区域样本图像；以各所述区域样本图像为输入,以各区域样本图像所对应的功能区类别为输出,对预设的神经网络模型进行训练,生成所述功能区识别模型。</td>   <td>G06V20/10;G06V10/25;G06V10/52;G06V10/764;G06V10/774;G06V10/82;G06T11/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         裴杰;                   谭绍锋       </td>   <td>中山大学</td>   <td>产量预测时间窗口确定方法、装置、设备及可读存储介质</td>   <td>广东省</td>   <td>CN116579521A</td>   <td>2023-08-11</td>   <td>本申请属于农作物产量预测的技术领域,公开了一种产量预测时间窗口确定方法、装置、设备及可读存储介质,该方法包括：获取待预测作物在目标种植区域的第一环境数据；对待预测作物进行物候阶段划分,并基于第一环境数据与划分的物候阶段确定目标种植区域中待预测作物在不同物候阶段对应的第二环境数据；将第二环境数据作为自变量,目标种植区域中待预测作物的单位面积产量值作为因变量,构建得到目标种植区域中待预测作物在不同物候阶段的产量预测模型；对比各产量预测模型的精度,并筛选得到精度超过预设精度的目标产量预测模型；将目标产量预测模型中对应的最早物候阶段确定为最佳时间窗口。本申请可以确定作物产量预测精度高的最佳时间窗口。</td>   <td>1.一种产量预测时间窗口确定方法,其特征在于,所述方法包括：获取待预测作物在目标种植区域的第一环境数据；对待预测作物进行物候阶段划分,并基于第一环境数据与划分的物候阶段确定目标种植区域中待预测作物在不同物候阶段对应的第二环境数据；将第二环境数据作为自变量,目标种植区域中待预测作物的单位面积产量值作为因变量,构建得到目标种植区域中待预测作物在不同物候阶段的产量预测模型；对比待预测作物在不同物候阶段的产量预测模型的精度,并筛选得到精度超过预设精度的目标产量预测模型；将目标产量预测模型中对应的最早物候阶段确定为最佳时间窗口。</td>   <td>G06Q10/063;G06Q50/02;G06F18/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴大炜;              张燕丽;              黄林冲;              邱章龙;              芦朋飞;              李代有;              周戎钦;              蒲成泽;              刘世茂;                   库航航       </td>   <td>中铁七局集团武汉工程有限公司;中山大学</td>   <td>一种隧桥结构的安全评估方法、装置、设备以及存储介质</td>   <td>湖北省</td>   <td>CN116579602A</td>   <td>2023-08-11</td>   <td>本发明公开了一种隧桥结构的安全评估方法、装置、设备以及存储介质,所述方法包括：获取待评估隧桥结构的隧桥参数；根据所述各隧桥参数分别确定高架桥风险因素相对于每一预设安全等级的第一隶属度、隧道风险因素相对于每一预设安全等级的第二隶属度、以及隧桥结合整体结构风险因素相对于每一预设安全等级的第三隶属度；根据所述第一隶属度、所述第二隶属度以及所述第三隶属度,确定待评估隧桥结构相对于每一预设安全等级的第四隶属度；将各第四隶属度中最大隶属度所对应的预设安全等级作为待评估隧桥结构的安全等级。通过本发明可以提高隧桥结构安全评估结果的准确度。</td>   <td>1.一种隧桥结构的安全评估方法,其特征在于,包括：获取待评估隧桥结构的隧桥参数；其中,所述隧桥参数包括：高架桥的跨度、高架桥的高度、高架桥的施工缺损程度、隧道的纵向变形曲率、隧道的埋深、隧道的施工缺损程度、高架桥与隧道的距离、桥墩置于隧道的结构形式和隧桥的线型重合度；根据高架桥的跨度、高架桥的高度以及高架桥的施工缺损程度确定高架桥风险因素相对于每一预设安全等级的第一隶属度；根据隧道的纵向变形曲率、隧道的埋深以及隧道的施工缺损程度确定隧道风险因素相对于每一预设安全等级的第二隶属度；根据高架桥与隧道的距离、桥墩置于隧道的结构形式以及隧桥的线型重合度确定隧桥结合整体结构风险因素相对于每一预设安全等级的第三隶属度；根据所述第一隶属度、所述第二隶属度以及所述第三隶属度,确定待评估隧桥结构相对于每一预设安全等级的第四隶属度；将各第四隶属度中最大隶属度所对应的预设安全等级作为待评估隧桥结构的安全等级。</td>   <td>G06Q10/0635;G06Q50/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈刚;              王钰深;              杨洋;              郑圳毅;                   钱其正       </td>   <td>中山大学</td>   <td>一种基于鱼眼相机的全景感知方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN116579962A</td>   <td>2023-08-11</td>   <td>本发明公开了一种基于鱼眼相机的全景感知方法、装置、设备及介质,可广泛应用于实时环视深度估计领域,方法包括：通过四个鱼眼相机获取四张鱼眼图像；四个鱼眼相机分别放置在同一个正方形的四个顶点上,镜头朝向正方形的对角线外侧；每个鱼眼相机生成两个虚拟针孔相机,每个虚拟针孔相机与相邻鱼眼相机生成的虚拟针孔相机构成双目相机；根据预先由鱼眼相机的成像原理与虚拟针孔相机的参数生成的映射表,将每张鱼眼图像转换为对应双目相机的左图像和右图像；利用二值神经网络提取每个双目相机左图像的左图像特征和右图像的右图像特征；对每个双目相机对应的左图像特征和右图像特征进行视差计算,得到覆盖四个鱼眼相机所处位置全景的四张深度图。</td>   <td>1.一种基于鱼眼相机的全景感知方法,其特征在于,包括：通过四个鱼眼相机获取对应的四张鱼眼图像；其中,四个鱼眼相机分别放置在同一个正方形的四个顶点上,且镜头朝向正方形的对角线外侧；每个鱼眼相机生成两个虚拟针孔相机,每个虚拟针孔相机与相邻鱼眼相机生成的虚拟针孔相机构成双目相机；根据预先由鱼眼相机的成像原理与虚拟针孔相机的参数生成的映射表,将每张所述鱼眼图像转换为对应所述双目相机的左图像和右图像；利用二值神经网络提取每个所述双目相机左图像对应的左图像特征和右图像对应的右图像特征；对每个所述双目相机对应的左图像特征和右图像特征进行视差计算,得到覆盖四个所述鱼眼相机所处位置全景的四张深度图。</td>   <td>G06T5/50;G06T7/80;G06T5/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         耿静;                   谭秋园       </td>   <td>中山大学</td>   <td>作物覆盖区域的土壤养分反演方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN116580318A</td>   <td>2023-08-11</td>   <td>本申请属于农业遥感的技术领域,公开了一种作物覆盖区域的土壤养分反演方法、装置、设备及介质,该方法包括：获取原始多光谱卫星影像数据并进行预处理；基于拓展的超分辨率卷积神经网络融合预处理后的原始卫星多光谱影像数据,得到目标时空分辨率的融合遥感数据集,其中,目标时空分辨率高于原始多光谱卫星影像数据的时空分辨率；提取并计算目标时空分辨率的融合遥感数据集中的植被变量数据；获取土壤样本养分实测数据,并基于土壤样本养分实测数据与植被变量数据,使用极端梯度提升树算法与遗传算法确定基于植被变量反演土壤养分的目标预测模型；基于目标预测模型预测农作物覆盖区域的土壤养分。本申请可实现植被覆盖条件下土壤养分的精确估算。</td>   <td>1.一种作物覆盖区域的土壤养分反演方法,其特征在于,所述方法包括：获取原始多光谱卫星影像数据并进行预处理,得到预处理后的原始多光谱卫星影像数据；基于拓展的超分辨率卷积神经网络融合预处理后的原始多光谱卫星影像数据,得到目标时空分辨率的融合遥感数据集,其中,目标时空分辨率高于原始多光谱卫星影像数据的时空分辨率；提取并计算所述目标时空分辨率的融合遥感数据集中的植被变量数据；获取土壤样本养分实测数据,并基于土壤样本养分实测数据与植被变量数据,使用极端梯度提升树算法与遗传算法确定基于植被变量反演土壤养分的目标预测模型；基于所述目标预测模型预测农作物覆盖区域的土壤养分。</td>   <td>G06V20/13;G06V10/82;G06N3/0464;G06N3/08;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任江涛;                   陈腾扬       </td>   <td>中山大学</td>   <td>一种破损交通标志检测方法及装置</td>   <td>广东省</td>   <td>CN116580378A</td>   <td>2023-08-11</td>   <td>本申请涉及一种破损交通标志检测方法及装置,其方法包括采集若干破损交通标志与正常交通标志的数据,构建数据集；标注数据集,得到训练集；预设YOLOV5模型,并设计YOLOV5模型的细粒度损失函数模块,其中,细粒度损失函数模块包括判别性组件和多样性组件,判别性组件用于使不同层次的特征图包含充分的判别性信息,多样性组件用于保持不同层次特征图的多样性和交互性；将训练集输入YOLOV5模型中,结合细粒度损失函数模块进行模型训练,直至达到预设条件,输出训练好的模型作为目标检测模型。本申请具有捕捉更多局部细微的判别性特征,更好地将破损交通标志与正常交通标志区分开来,提高破损交通标志的检测精度的效果。</td>   <td>1.一种破损交通标志检测方法,其特征在于,包括以下步骤,采集若干破损交通标志与正常交通标志的数据,构建数据集；标注所述数据集,得到训练集；预设YOLOV5模型,并设计所述YOLOV5模型的细粒度损失函数模块,其中,所述细粒度损失函数模块包括判别性组件和多样性组件,判别性组件用于使不同层次的特征图包含充分的判别性信息,多样性组件用于保持不同层次特征图的多样性和交互性；将所述训练集输入所述YOLOV5模型中,结合所述细粒度损失函数模块进行模型训练,直至达到预设条件,输出训练好的模型作为目标检测模型；基于所述目标检测模型进行破损交通标志检测。</td>   <td>G06V20/58;G06V10/774;G06V10/82;G06V10/80;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;                   张镓伟       </td>   <td>中山大学</td>   <td>一种结合空间变换网络和多尺度特征提取的遮挡行人重识别方法</td>   <td>广东省</td>   <td>CN112396036B</td>   <td>2023-08-08</td>   <td>本发明公开了一种结合空间变换网络和多尺度特征提取的遮挡行人重识别方法,包括下述步骤：用模拟遮挡生成器构建有遮挡的行人图片集；将原始图片与有遮挡的行人图片组成数据集并输入到空间变换网络中进行空间变换纠正；通过卷积神经网络和空间金字塔池化层对纠正后的图进行多尺度特征提取并合并为定长一维特征向量；将定长一维特征向量通过全连接层得到一个包含K个元素的一维特征向量并进行身份分类训练,得到训练好的网络；用训练好的网络提取待查询的行人图像的特征并进行相似度匹配。本发明进行多尺度特征提取,通过结合不同尺度的特征图,使得模型更具鲁棒性；还引入了空间变换网络,可直接嵌入到任意深度网络模型中进行端到端的训练。</td>   <td>1.一种结合空间变换网络和多尺度特征提取的遮挡行人重识别方法,其特征在于,包括下述步骤：利用模拟遮挡生成器在一个行人数据集上构建有遮挡的行人图片；具体包括以下步骤：设原始图片img的大小为w*h,提取img的四个顶点的像素值img[0,0],img[0,h-1],img[w-1,0]以及img[w-1,h-1],求出所述四个顶点的平均像素值C,计算公式如下：C＝(img[0,0]+img[0,h-1]+img[w-1,0]+img[w-1,h-1])/4；随机选取一个矩形局域：AREA＝[X-(random),Y-(random),X-(random)+w′,Y-(random)+h′]；其中X-(random),Y-(random)表示矩形左上角坐标,X-(random)+w′,Y-(random)+h′表示矩形右下角坐标,满足w′＝min(w,50),h′＝min(h,50且矩形区域不超出原图的范围；使用C替换该矩形区域的像素值,得到一张有遮挡的行人图片；将原始行人图片与新生成的有遮挡的行人图片组成新的数据集,并将新的数据集输入到空间变换网络中进行空间变换纠正；所述空间变换网络用于对新的数据集中的图片进行自动裁剪、平移、缩放,使图片只保留人的部分,得到纠正后的图片；所述空间变换网络包括：定位网络、坐标生成器和采样器；所述定位网络利用一个小卷积神经网络提取图片特征,并将所述图片特征通过全连接回归层得到6个变换参数；所述坐标生成器用于根据所述变换参数构建采样网络,即得到一种映射关系T-θ,具体为：                  其中表示输入空间变换网络中的图片U的第i个像素点的坐标,/&gt;表示目标图像V的第i个像素点的坐标,θ为定位网络得到的6个变换参数；所述采样器用于根据采样网络所得的映射关系对输入空间变换网络中的图片U进行像素级采样复制得到目标图像V；所述采样器采用双线性采样,计算公式如下：                                    其中,H、W、C分别为输入空间变换网络中的图片U的高、宽和通道数,为输入空间变换网络中的图片U的第c个通道中坐标为(n,m)的像素点的值,H′、W′分别表示目标图像V的高和宽,V-i～c表示目标图像V第c个通道中第i个像素点的值；利用卷积神经网络和空间金字塔池化层对所述纠正后的图片进行多尺度特征提取并合成定长一维特征向量；将所述定长一维特征向量通过全连接层得到一个包含K个元素的一维特征向量,再进行行人图像的身份分类训练,得到训练好的网络；利用所述训练好的网络提取待查询的行人图像的特征并进行相似度匹配。</td>   <td>G06V20/52;G06V10/44;G06V10/764;G06V10/74;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王欣;              彭同艳;              黄松键;              王安琪;              陈泽森;                   姚清河       </td>   <td>中山大学</td>   <td>基于神经网络和自然对话的阿尔兹海默症风险预估方法</td>   <td>广东省</td>   <td>CN114596960B</td>   <td>2023-08-08</td>   <td>本发明公开一种基于神经网络和自然对话的阿尔兹海默症风险预估方法,属于人工智能识别、语言学分析领域。其包括采集测试者的有效自由表达,使用语言处理软件ELAN对语料进行转写、切分和标注；利用Token embedding将处理内容转化为数据并建立多模态语料库；利用CNN神经网络模型与LSTM神经网络模型进行文本分析,作为预估阿尔兹海默症的数据。本发明采用Token embedding方法实现语料信息的特征提取,为识别模型增加多模态的语言标志物和语言模式作为输入因素；因此具有较高的识别准确率和抗人为因素干扰的能力。本发明可减轻患者检查时的身体和心理负担,缩短检查周期,降低实验成本,有利于大规模推广。</td>   <td>1.基于神经网络和自然对话的阿尔兹海默症风险预估方法,其特征在于：采集阿尔兹海默症测试者的有效自由表达语料,使用语言处理软件ELAN对语料进行转写、切分和标注；利用目前通用的语音、图像识别文字转化系统和标记嵌入将文本内容转化为数据并建立多模态语料库；利用卷积神经网络模型与长短期记忆神经网络模型的复合模型进行文本分析,作为预估阿尔兹海默症的数据,包括以下步骤：S1.采集至少20名阿尔兹海默症测试者10分钟的有效自由表达语料,将语料载入ELAN,进行话语转写、切分和标注,利用标记嵌入将文本内容转化为数据,形成多模态语料库；S2.根据S1中的数据制成数据集,进行预处理及归一化得到特征数据集,将其按照3:1随机分配成训练数据集、测试数据集；其中特征数据集规模为E个的一维张量,E为整数,表示语言标志物和语言模式；S3.根据数据集规模和输出要求构建卷积神经网络模型,应用S2中的训练数据集进行训练,进一步应用测试数据集对此模型进行测试检验；S4.将S1中的数据进行随机处理,得到含有时间序列的训练样本数据集、测试样本数据集,其中,数据集规模为F个二维张量,其中F为整数,表示包含有时间序列的语言标志物和语言模式；S5.根据数据集规模和输出要求构建长短期记忆神经网络模型,应用S4中的训练样本数据集进行训练,进一步应用测试样本数据集对此模型进行测试检验；S6.将通过步骤S3中的卷积神经网络模型处理的输出值及通过步骤S5中的长短期记忆神经网络模型处理的输出值并列组成矩阵,作为输入值,进行一层全连接层处理,通过两层隐藏层,输出最终结果以热点分布形式表达,作为预估阿尔兹海默症的数据,辅助医生对阿尔兹海默症的诊断。</td>   <td>G16H50/30;G16H50/20;G06F16/33;G06N3/0442;G06N3/0464;G06N3/08;G06F40/216;G06F40/242</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵薛强;              陈洋波;              刘俊;                   孙怀张       </td>   <td>中山大学</td>   <td>一种融合遥感图像与点云数据的地理要素识别方法</td>   <td>广东省</td>   <td>CN116258970B</td>   <td>2023-08-08</td>   <td>本发明提供一种融合遥感图像与点云数据的地理要素识别方法,涉及图像数据处理的技术领域,首先采集图像数据和点云数据并进行类别标注,构建为样本数据集,再构建融合图像与点云数据的语义分割模型,提取图像数据的2D特征和点云数据的3D特征并融合得到图像和点云的分割预测值,利用样本数据集训练融合图像与点云数据的语义分割模型,最后将待识别遥感图像、待识别遥感图像对应的点云数据输入训练好的融合图像与点云数据的语义分割模型,输出图像分割结果和点云分割结果,利用不同的色彩对不同类别的点云分割结果进行标记,实现地理要素的识别,充分利用了2D图像信息的有序性以及3D点云数据的空间性,提高了地理要素的分割识别精度。</td>   <td>1.一种融合遥感图像与点云数据的地理要素识别方法,其特征在于,包括：S1.采集图像数据和点云数据,对图像数据和点云数据分别进行类别标注,分别作为图像数据和点云数据的真实标签,将带有类别标注的图像数据和点云数据构建为样本数据集,将样本数据集划分为训练集、验证集、测试集；S2.构建融合图像与点云数据的语义分割模型,融合图像与点云数据的语义分割模型包括用于提取图像数据的2D特征的2D分支2D Branch、用于提取点云数据的3D特征的3D分支3D Branch及融合结构Feature Fusion,所述2D分支2D Branch包括2D图像分割模块FastSCNN,输出2D特征E～(2D)；所述3D分支3D Branch包括3D点云数据分割模块PFTransformer,输出3D特征E～(3D)；融合结构Feature Fusion连接2D分支和3D分支,将2D特征和3D特征融合,过程如下：3D点云数据分割模块PFTransformer输出的3D特征E～(3D)经过第一共享感知机SharedMLP1后,输出为3D共享特征E～(3D′),令E～(3D′)与2D图像分割模块FastSCNN输出的2D特征E～(2D)通过Concat函数进行拼接,将拼接后的特征通过第二共享感知机Shared MLP2进行特征融合,得到融合特征E～(2D3D)；将融合特征E～(2D3D)通过第三共享感知机Shared MLP3后进行Sigmoid函数计算,得到注意力权重,注意力权重与融合特征E～(2D3D)进行Hadamard乘积,再以残差的方式与2D特征E～(3D)按位置相加,并通过共享感知机Shared MLP组成的2D分类器2D Classfier,获得2D特征的图像语义分割预测值；3D点云数据分割模块PFTransformer输出的3D特征E～(3D)与经过第一共享感知机SharedMLP1的得到的3D共享特征E～(3D′)进行融合,再通过3D分支3D Branch的3D分类器3DClassfier,获得3D点云的点云语义分割预测值；利用2D特征优化3D特征,得到图像分割预测值和点云分割预测值；S3.利用训练集对融合图像与点云数据的语义分割模型进行训练,训练过程中分别计算图像分割预测值和点云分割预测值与真实标签图之间的损失值,根据损失值调整融合图像与点云数据的语义分割模型的参数,直到融合图像与点云数据的语义分割模型收敛,然后利用验证集对训练过程中的融合图像与点云数据的语义分割模型进行评估,得出训练好的融合图像与点云数据的语义分割模型,并利用测试集测试融合图像与点云数据的语义分割模型的预测准确度；S4.将待识别遥感图像、待识别遥感图像对应的点云数据输入训练好的融合图像与点云数据的语义分割模型,输出图像分割结果和点云分割结果；S5.利用不同的色彩对不同类别的点云分割结果进行标记,展示分割结果,实现地理要素的识别。</td>   <td>G06V20/10;G06V20/70;G06V10/80;G06V10/26;G06N3/0464;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张能;              陈钦德;                   郑子彬       </td>   <td>中山大学</td>   <td>基于抽象语法树迭代映射的代码文件差异分析方法及装置</td>   <td>广东省</td>   <td>CN116560662A</td>   <td>2023-08-08</td>   <td>本发明公开了基于抽象语法树迭代映射的代码文件差异分析方法及装置,包括：利用抽象语法树即AST生成工具解析一个代码修订的原代码文件、目标代码文件分别得到第一、第二AST,并从每个AST中提取节点的类型和值并构建节点间的关联；将第一、第二AST中存在唯一对应关系的相等节点进行映射,并对相等节点在相同位置上的孩子节点进行映射；基于节点间的相似性度量对第一、第二AST中未被映射且类型相同的节点进行迭代映射直至没有新的节点映射；根据第一、第二AST间的节点映射结果生成代码编辑脚本,用于描述目标代码文件相对原代码文件的差异。本发明能提高节点映射的数量和准确性,生成的代码编辑脚本便于开发者理解代码文件修订。</td>   <td>1.基于抽象语法树迭代映射的代码文件差异分析方法,其特征在于,包括：利用抽象语法树即AST生成工具解析原代码文件得到第一AST、解析目标代码文件得到第二AST,分别从所述第一AST、所述第二AST中提取节点的类型和值并构建节点间的关联关系；其中,所述节点包括语句节点、内部语句节点和词节点,所述语句节点是与代码语句对应的节点,所述内部语句节点是所述语句节点的子孙节点中的非叶子节点,所述词节点为叶子节点,所述关联关系至少包括父子关系；对所述第一AST和所述第二AST中存在唯一对应关系的相等节点进行映射,并对所述相等节点在相同位置上的孩子节点进行映射,所述相等节点是指类型和值均相同的节点；基于节点间的相似性度量对所述第一AST和所述第二AST中未被映射且类型相同的节点进行迭代映射直至没有新的节点映射；根据所述第一AST和所述第二AST之间的节点映射结果生成代码编辑脚本,根据所述代码编辑脚本分析所述目标代码文件相对所述原代码文件的差异化信息,所述代码编辑脚本是将所述原代码文件转化为所述目标代码文件时对代码元素的编辑操作。</td>   <td>G06F8/41;G06F8/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚正安;                   施章灿       </td>   <td>中山大学</td>   <td>一种图数据集的流式图划分方法</td>   <td>广东省</td>   <td>CN116561377A</td>   <td>2023-08-08</td>   <td>本发明公开一种图数据集的流式图划分方法,包括以下步骤：S1：获取外部数据,所述外部数据形成大规模的图数据；S2：计算所述图数据中顶点的度,按照顶点的度的大小对顶点进行排序后,将顶点按照排序后的顺序输入至流式图划分算法；S3：利用流式图划分算法对输入的顶点进行划分,将顶点划分至目标区间。本发明对图流的顶点输入顺序进行改进,在保证流式图划分算法的运行速度前提下对其划分质量进行提升,另外还利用之前的分区结果信息对后续迭代进行改进。</td>   <td>1.一种图数据集的流式图划分方法,其特征在于,包括以下步骤：S1：获取外部数据,所述外部数据形成大规模的图数据；S2：计算所述图数据中顶点的度,按照顶点的度的大小对顶点进行排序后,将顶点按照排序后的顺序输入至流式图划分算法；S3：利用流式图划分算法对输入的顶点进行划分,将顶点划分至目标区间。</td>   <td>G06F16/901</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              林格;                   刘宇       </td>   <td>中山大学</td>   <td>基于联盟区块链账本智能合约的水样溯源管理方法与系统</td>   <td>广东省</td>   <td>CN116561815A</td>   <td>2023-08-08</td>   <td>本发明公开了一种基于联盟区块链账本智能合约的水样溯源管理方法。包括：采集水样数据并对其进行处理,输出水样数据的数据标识符；将数据标识符上传至联盟区块链账本中,生成对应的区块信息；设计智能合约程序,将智能合约部署到联盟区块链上,将区块信息输入至智能合约程序中,实现数据验证逻辑,输出智能合约验证信息；将智能合约验证信息记录在联盟区块链账本中,输出记录数据；访问联盟区块链账本中记录数据,分析记录数据,输出水质检测数据,并实现数据溯源。本发明还公开了基于联盟区块链账本智能合约的水样溯源管理系统。本发明采用联盟区块链账本和智能合约技术,实现去中心化管理,提高数据安全性,实现水样全程留痕和溯源管理。</td>   <td>1.一种基于联盟区块链账本智能合约的水样溯源管理方法,其特征在于,所述方法包括：输入水样数据至数据采集模块和数据处理模块,输出水样数据的数据标识符；将所述水样数据的数据标识符上传至联盟区块链账本中,生成对应的区块信息；设计智能合约程序,将智能合约部署到联盟区块链上,将所述区块信息输入至智能合约程序中,实现数据验证逻辑,输出智能合约验证信息；将所述智能合约验证信息记录在联盟区块链账本中,输出记录数据；访问联盟区块链账本中所述的记录数据,分析记录数据,输出水质检测数据,并实现数据溯源。</td>   <td>G06F21/64;G06F21/62;G06F21/60;G06F21/33;G06F16/23;G06F16/27;H04L9/40;H04L9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈刚;              黄谦;              严远星;              杨壹翔;                   郑佳宁       </td>   <td>中山大学</td>   <td>一种基于专用AI感知芯片的实时全景感知系统及方法</td>   <td>广东省</td>   <td>CN116563186A</td>   <td>2023-08-08</td>   <td>本发明公开了一种基于专用AI感知芯片的实时全景感知系统及方法,系统包括：鱼眼相机模块、异构运算平台以及专用AI感知芯片；所述鱼眼相机模块,用于采用横向布置方式采集鱼眼图像；所述异构运算平台,用于将所述鱼眼图像转化为双目立体图；将所述专用AI感知芯片计算得到的视差图和时钟信号解析为全景稠密深度图；所述专用AI感知芯片,用于根据所述双目立体图与预设的立体匹配参数计算得到定所述视差图和时钟信号。本发明可以减少视觉相机系统的体积并降低功耗,可广泛应用于实时环视深度估计领域。</td>   <td>1.一种基于专用AI感知芯片的实时全景感知系统,其特征在于,包括：鱼眼相机模块、异构运算平台以及专用AI感知芯片；所述鱼眼相机模块,用于采用横向布置方式采集鱼眼图像；所述异构运算平台,用于将所述鱼眼图像转化为双目立体图；将所述专用AI感知芯片计算得到的视差图和时钟信号解析为全景稠密深度图；所述专用AI感知芯片,用于根据所述双目立体图与预设的立体匹配参数计算得到所述视差图和时钟信号。</td>   <td>G06T5/50;G06T7/80;G06T5/00;G06T5/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余建兴;              王世祺;              董晓;              张宇锋;              崔岩;                   印鉴       </td>   <td>中山大学;珠海市四维时代网络科技有限公司</td>   <td>一种细粒度语义操控的场景渲染方法和装置</td>   <td>广东省</td>   <td>CN116563423A</td>   <td>2023-08-08</td>   <td>本发明涉及场景渲染技术领域,公开了一种细粒度语义操控的场景渲染方法,通过在语义理解单元构建依存句法树,能够描述需求文本细粒度语义,进而识别需求文本中细粒度信息,从而准确定位图片区域,实现渲染结果和需求文本的高匹配。此外,将需求文本转为依存句法树,并在树上装配推理模块,加强了场景图特征和文本特征的关联,定位更加准确。本发明还设计了一个正则器来约束场景生成模型,能够准确对目标区域的视觉信息进行修改,而不会影响其它无关区域。本发明无需人工圈定编辑区域,可以直接理解文本的需求,能够对原始场景图进行细粒度的局部编辑。用户可以以文本形式提出编辑需求,对场景图进行增加,删除和修改,实现便捷可操控的渲染。</td>   <td>1.一种细粒度语义操控的场景渲染方法,其特征在于,包括如下步骤：S1：将场景图I输入目标检测单元,目标检测单元对场景图I中各实体对象进行定位,并对实体所处区域的视觉信息进行编码,输出区域特征编码集合V＝{v-1,…,v-M},其中M为检测到的区域数量,V中元素描述了第i个区域中实体目标的视觉信息以及所属的实体类别,其中d-v为区域特征编码维度；S2：将需求文本Q＝{q-1,…,q-m}输入语义理解单元,语义理解单元利用语法解析器将需求文本Q＝{q-1,…,q-m}转换为依存句法树,对应的树节点的特征集合为它用于描述需求文本细粒度语义；在此基础上,获取需求文本全局特征编码/&gt;理解用户意图来生成相应的操控指令编码/&gt;其中,m为需求文本长度,d-q为需求文本特征编码维度,op维度与场景图目标检测单元输出的区域特征编码维度d-v一致,依存句法树节点特征集合H作为参考信息来辅助后置的定位单元来准确定位出待更新的区域；S3：将来自目标检测单元的区域特征编码集合V＝{v-1,…,v-M}和来自语义理解单元的需求文本的依存句法树节点特征编码集合输入定位推理单元,定位推理单元计算每个图像区域i关于/&gt;的定位评分S(v-i,H),从而确定得分最高的一项作为编辑区域,                  并且定位推理单元采用树形模块化网络,将视觉定位过程规范至依存句法树中,为树中每个节点装配一个计算区域临时定位评分的神经模块网络,通过自底向上整合这些临时评分来最终获得每个区域的定位评分,选取定位评分最高的区域l作为待编辑区域,待编辑区域l的特征编码为v-l；S4：将来自语义理解单元的文本中识别编辑操作op和来自定位推理单元确定的待编辑区域l的特征编码v-l输入内容渲染单元,内容渲染单元根据从文本中识别的编辑操作op来对待编辑区域l的特征编码v-l进行修改,并将修改后的特征输入到生成器中进行渲染；内容渲染单元以GAN网络作为生成器,并设计一个正则化器来对生成器进行训练,即将操控指令编码op添加进待编辑区域的特征编码v-l中,并将修改后的区域特征编码集合输入到GAN网络中输出渲染后的场景其中α为预设参数,</td>   <td>G06T11/60;G06F40/211;G06N3/0442;G06N3/0464;G06N3/094;G06N3/0475</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卓莉;              廖楚尧;              陶海燕;                   郭思颖       </td>   <td>中山大学</td>   <td>一种基于Landsat时间序列的建筑年份制图方法及系统</td>   <td>广东省</td>   <td>CN116563427A</td>   <td>2023-08-08</td>   <td>本发明公开了一种基于Landsat时间序列的建筑年份制图方法及系统,如下：构建遥感指数时间序列；提取城市空间中的建筑像元,结合城市扩张数据,生成建筑像元的初始建成年份分布图,并以此提取得到初始建成时间后的Landsat时间序列变化特征,输入随机森林算法将建筑像元分为更新区域和非更新区域；针对更新区域的建筑像元,提取末次原建筑用地转换为新建筑用地的结束时间,得到更新区域建筑建成年份,并以此与非更新区域的初始建成年份进行空间叠加,得到最终的建筑年份制图结果。本发明在时间序列指标选取与处理分割分析上进行了充分考虑,能够准确提取与建筑建成活动相关的特征与信息,得出以年为时间分辨率的制图结果,提升了建筑建成时间的估计精度。</td>   <td>1.一种基于Landsat时间序列的建筑年份制图方法,其特征在于：所述的方法包括步骤如下：对Landsat遥感影像时间序列数据进行预处理,构建遥感指数时间序列；提取城市空间中的建筑像元,结合城市扩张数据,生成建筑像元的初始建成年份分布图；根据建筑像元的初始建成年份分布图提取得到初始建成时间后的Landsat时间序列变化特征,然后输入随机森林算法将建筑像元分为更新区域和非更新区域；针对更新区域的建筑像元,进一步提取末次原建筑用地转换为新建筑用地的结束时间,得到更新区域建筑建成年份；将更新区域的建筑建成年份与非更新区域的初始建成年份进行空间叠加,得到最终的建筑年份制图结果。</td>   <td>G06T11/60;G06V20/10;G06V10/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              孙文钊       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>基于EPID影像的三维剂量重建方法及系统</td>   <td>广东省</td>   <td>CN116563456A</td>   <td>2023-08-08</td>   <td>本发明公开了基于EPID影像的三维剂量重建方法及系统,该方法包括：基于EPID影像装置,执行校准程序,获取EPID影像；获取预设计划治疗文件并基于EPID影像提取MLC叶片数据进行时间坐标对齐与修正处理,得到时间修正后的实测MLC叶片位置数据；将时间修正后的实测MLC叶片位置数据与治疗文件中的原始MLC叶片数据进行替换,构建基于EPID影像的三维剂量重建。该系统包括：获取模块、修正模块和重构模块。通过使用本发明,避免了加速器日志文件中记录MLC叶片位置不准确的问题,实现患者三维剂量的高精度重建。本发明作为基于EPID影像的三维剂量重建方法及系统,可广泛应用于辅助医疗技术领域。</td>   <td>1.基于EPID影像的三维剂量重建方法,其特征在于,包括以下步骤：基于EPID影像装置,执行校准程序,获取EPID影像；获取预设计划治疗文件并基于EPID影像提取MLC叶片数据进行时间坐标最小化差异修正处理,得到时间修正后的实测MLC叶片位置数据；将时间坐标修正后的实测MLC叶片位置数据与治疗文件中的原始MLC叶片数据进行替换,构建基于EPID影像的三维剂量重建。</td>   <td>G06T17/00;G06T7/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈泽涛;              刘海雯;              覃家祥;              段嘉旭;              施梦汝;              林义雄;                   龚卓弘       </td>   <td>中山大学附属口腔医院;中国电器科学研究院股份有限公司</td>   <td>口腔不规则解剖结构的自动测量方法、系统和计算机设备</td>   <td>广东省</td>   <td>CN116563545A</td>   <td>2023-08-08</td>   <td>本申请提出一种口腔不规则解剖结构的自动测量分析系统、方法和计算机设备,用以对微小的口腔不规则结构进行全定量自动测量分析,方法包括S1、根据患者的历史CBCT影像获取历史标准矢状截面；S2、构建影像数据库；S3、构建测量分析数据库；S4、基于语义分割网络构建智能网络模型,进行训练、验证和测试；S5、根据就诊人员的待测CBCT影像获取待测标准矢状截面,将待测标准矢状截面输入智能网络模型,获得待测标准矢状截面中的口腔不规则解剖结构的预测区域以及相关测量参考标志的坐标；S5、选取口腔亚专科测量方法并相应计算和输出口腔不规则结构的量化指标。本申请所述方法和设备适用于不同口腔亚专科的临床应用。</td>   <td>1.一种口腔不规则解剖结构的自动测量方法,其特征在于,自动测量方法包括：S1、收集多名患者的历史CBCT影像,根据历史CBCT影像获取历史标准矢状截面；S2、在历史标准矢状截面中对口腔不规则解剖结构以及相关测量参考标志进行标记,采用带有标记的历史标准矢状截面构建影像数据库；S3、采用不同口腔亚专科测量方法对影像数据库数据集中的口腔不规则解剖结构进行测量,获得口腔不规则解剖结构的量化指标,采用带有标记的历史标准矢状截面及口腔不规则解剖结构的量化指标构建测量分析数据库；S4、基于语义分割网络构建智能网络模型,利用影像数据库对智能网络模型进行训练和验证,利用影像数据库和测量分析数据库进行测试；S5、根据就诊人员的待测CBCT影像获取待测标准矢状截面,将待测标准矢状截面输入智能网络模型,获得待测标准矢状截面中的口腔不规则解剖结构的预测区域以及相关测量参考标志的坐标；S6、选取计算口腔不规则解剖结构的口腔亚专科测量方法,口腔亚专科测量方法包括参考点、参考线和测量位点,根据选取的口腔亚专科测量方法计算对应口腔不规则解剖结构的量化指标,量化指标包括厚度值、高度、面积。</td>   <td>G06V10/26;G06V10/80;G06V10/82;G06F16/50;G06N3/0464;G06N3/048;G06N3/084;G06N3/09;G16H30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田捷;              唐林泉;              董迪;              麦海强;              朱曼依;              钟连珍;                   刘丽婷       </td>   <td>中国科学院自动化研究所;中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>鼻咽癌预后特征确定方法、系统、装置及存储介质</td>   <td>北京市</td>   <td>CN116563651A</td>   <td>2023-08-08</td>   <td>本发明公开了一种鼻咽癌预后特征确定方法、系统、装置及存储介质,方法包括：病理图像预处理,通过基于染色分离的颜色归一化方法对病理图像进行染色标准化处理；通过分割网络对预处理后的病理图像的病灶区域进行自动分割,得到分割影像；对分割影像进行裁剪处理,得到目标图像块；通过主成分分析对目标图像块进行特征降维,得到降维数据；根据降维数据,通过聚类算法进行无监督自主学习得到病理图像特征；最终通过特征检验对所述病理图像特征进行筛选,确定预后病理特征集合。本发明能够从病理图像中获取和筛选出与鼻咽癌局部区域复发和远处转移密切相关的病理图像的关键图像特征,以辅助鼻咽癌的预后预测,可广泛应用于图像处理技术领域。</td>   <td>1.一种鼻咽癌预后特征确定方法,其特征在于,包括以下步骤：病理图像预处理,通过基于染色分离的颜色归一化方法对病理图像进行染色标准化处理；通过分割网络对预处理后的病理图像的病灶区域进行自动分割,得到分割影像；其中,所述分割网络包括深度神经网络和神经条件随机场,所述深度神经网络用于病灶区域的分割,所述神经条件随机场用于建模相邻图像块之间的空间相关性；对所述分割影像进行裁剪处理,得到目标图像块；通过主成分分析对所述目标图像块进行特征降维,得到降维数据；根据所述降维数据,通过聚类算法进行无监督自主学习得到病理图像特征；通过特征检验对所述病理图像特征进行筛选,确定预后病理特征集合。</td>   <td>G06V10/77;G06V10/771;G06V10/82;G06V10/764;G06V10/762;G06T7/11;G06N3/0464;G06N3/088;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         麦庆云;              李冠彬;              高峰;              周灿权;              颜鹏翔;              陈方莹;              谢翔;              丁晨晖;                   徐艳文       </td>   <td>中山大学附属第一医院</td>   <td>一种胚胎发育潜能预测方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113469958B</td>   <td>2023-08-04</td>   <td>本发明涉及医疗人工智能技术领域,尤其涉及一种胚胎发育潜能预测方法、系统、设备及存储介质,包括：将所述胚胎初始图像输入囊胚预测模型,得到胚胎特征向量；将所述胚胎特征向量输入双向长短期记忆网络,得到胚胎发育特征；基于跨模态特征融合机制,根据临床数据及所述胚胎发育特征,得到融合特征；将所述融合特征输入第一多层感知器,预测得到胚胎妊娠率。本发明通过分析早期拍摄的多焦段胚胎视频,利用多焦段选择模型以及时间转移模型得到具有时空特性的融合特征,从而实时预测体外培养的胚胎妊娠率,提高了预测的准确度；同时本发明通过预测囊胚形成概率以及整倍体概率,辅助医生进行早期胚胎筛选,从而减少人力成本。</td>   <td>1.一种胚胎发育潜能预测方法,其特征在于,包括以下步骤：对同一胚胎的多焦段的胚胎图像进行预处理,得到胚胎初始图像；将所述胚胎初始图像输入囊胚预测模型,得到胚胎特征向量；将所述胚胎特征向量输入双向长短期记忆网络,得到胚胎发育特征；基于跨模态特征融合机制,根据临床数据及所述胚胎发育特征,得到融合特征；将所述融合特征输入第一多层感知器,预测得到胚胎妊娠率；所述囊胚预测模型的网络结构包括依次连接的卷积层、第一残差块、多焦段特征选择模型、第二残差块、第三残差块、第四残差块、第一全连接层和第二全连接层；其中,所述第一至第四残差块均嵌入了时间转移模块,所述多焦段特征选择模型包括通道注意力模块、深度非局部模块；所述基于跨模态特征融合机制,根据临床数据及所述胚胎发育特征,得到融合特征,具体为：对采集到的临床数据进行预处理,得到初始临床特征向量；将所述初始临床特征向量输入嵌入层,得到临床嵌入向量；将所述临床嵌入向量进行融合,得到临床融合向量；将所述临床融合向量输入第二多层感知器,得到临床数据特征；将所述临床数据特征和所述胚胎发育特征输入跨模态特征融合机制,得到融合特征；其中,跨模态特征融合机制将张量分解为3个因子矩阵：/&gt;、/&gt;、以及一个核心张量/&gt;,即/&gt;,其中,/&gt;代表张量和向量的i模积,/&gt;表示向量i的维度,利用/&gt;、/&gt;、/&gt;、/&gt;融合胚胎发育的图片特征q和患者的临床数据特征v,即患者的融合特征/&gt;；所述方法还包括：将形成囊胚的胚胎对应的胚胎初始图像依次输入所述囊胚预测模型、所述双向长短期记忆网络,得到所述胚胎发育特征；将所述胚胎发育特征输入第三多层感知器,得到整倍体概率；根据所述整倍体概率筛选出囊胚为整倍体的胚胎。</td>   <td>G06T7/00;G06V10/764;G06V10/80;G06V10/82;G06N3/0442</td>  </tr>        <tr>   <td>中国专利</td>   <td>         叶华锋;              王明羽;              黄海秋;              杨泽旗;                   虞志益       </td>   <td>中山大学</td>   <td>一种适用于大卷积核的三维Winograd嵌套方法</td>   <td>广东省</td>   <td>CN116542294A</td>   <td>2023-08-04</td>   <td>本发明公开了一种适用于大卷积核的三维Winograd嵌套方法,包括：将三维的原始数据进行有重叠的重新排列,进行三维Winograd转换,得到重排数据；对重排数据逐行抽取数据,进行有重叠的重新排列,进行三维Winograd转换,得到二维的激活转换矩阵；将三维的卷积核数据重新排列,进行三维Winograd转换,得到二维的卷积核转换矩阵；将激活转换矩阵与卷积核转换矩阵相乘,得到二维矩阵,作为输出转换矩阵；将输出转换矩阵进行重新排列并进行三维Winograd转换,得到三维的卷积输出结果。本发明降低了大尺寸三维卷积的计算复杂度,提高了Winograd算法的数值稳定性,可广泛应用于卷积神经网络算法领域。</td>   <td>1.一种适用于大卷积核的三维Winograd嵌套方法,其特征在于,包括：将三维的原始数据每一面的数据进行有重叠的重新排列,并进行三维Winograd转换,得到重排数据；对所述重排数据逐行抽取数据,进行有重叠的重新排列,并进行三维Winograd转换,得到一个二维矩阵,作为激活转换矩阵；将三维的卷积核数据每一面的数据重新排列,并进行三维Winograd转换,得到一个二维矩阵,作为卷积核转换矩阵；将所述激活转换矩阵与所述卷积核转换矩阵相乘,得到一个二维矩阵,作为输出转换矩阵；将所述输出转换矩阵进行重新排列并进行三维Winograd转换,得到三维的卷积输出结果。</td>   <td>G06N3/0464;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪涛;              高子雄;              张翠卿;                   张序       </td>   <td>中山大学</td>   <td>一种基于张量分解的大规模神经网络参数压缩方法及系统</td>   <td>广东省</td>   <td>CN116542315A</td>   <td>2023-08-04</td>   <td>本发明公开了一种基于张量分解的大规模神经网络参数压缩方法及系统,涉及神经网络模型参数压缩的技术领域,包括获取已训练的大规模神经网络中的权重矩阵,设置权重矩阵的行秩和列秩；根据行秩和列秩,在权重矩阵中选取一组行序号集合和列序号集合；基于选取的行序号集合和列序号集合对权重矩阵进行CUR分解,获得压缩权重矩阵,并利用压缩权重矩阵替换权重矩阵；设定损失函数,对压缩权重矩阵调整,获得调整后的压缩权重矩阵,比较行秩和列秩的大小,根据比较结果对调整后的压缩权重矩阵进行简化,实现对大规模神经网络参数的压缩。本发明能够快速准确的分解和压缩参数,计算复杂度低,分解速度快,降低了压缩后的准确率丢失。</td>   <td>1.一种基于张量分解的大规模神经网络参数压缩方法,其特征在于,包括：S1：获取已训练的大规模神经网络中的权重矩阵；S2：分别在行维度和列维度,设置权重矩阵的行秩和列秩；S3：根据所述行秩和列秩,在权重矩阵中选取一组行序号集合和列序号集合；S4：基于选取的行序号集合和列序号集合对权重矩阵进行CUR分解,获得压缩权重矩阵,并利用压缩权重矩阵替换权重矩阵；S5：设定损失函数,对压缩权重矩阵调整,获得调整后的压缩权重矩阵；S6：比较行秩和列秩的大小,根据比较结果对调整后的压缩权重矩阵进行简化,实现对大规模神经网络参数的压缩。</td>   <td>G06N3/082</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              林格;                   孟小哲       </td>   <td>中山大学</td>   <td>基于解耦的无监督图像去雾增强方法与系统</td>   <td>广东省</td>   <td>CN116542867A</td>   <td>2023-08-04</td>   <td>本发明公开了一种基于解耦的无监督图像去雾增强方法。包括：将有雾图像输入到编码器中得到有雾特征图；然后将有雾特征图分别输入到去雾图网络层J-net中获取去雾图大气光网络层A-net网络中输出解藕后的大气光值输入到剩余系数网络层α-net中计算剩余系数和透射率图网络层t-net中得到透射率图根据和重新合成有雾图,通过合并雾的重建过程来指导层的解缠,训练改进后的大气光值散射模型得到去雾图像。本发明还公开了基于解耦的无监督图像去雾增强系统。本发明引入剩余系数,提出了新的解耦去雾模型,针对不同的子网络设计不同的损失,保证子网络输出符合物理规律,在真实数据上进行训练,避免了合成数据带来的域漂移问题。</td>   <td>1.一种基于解耦的无监督图像去雾增强方法,其特征在于,所述方法包括：将有雾图像输入到编码器得到有雾特征图z；将有雾特征图输入到去雾图网络层J-net中,获取去雾图将有雾特征图输入到大气光网络层A-net网络中,输出解藕后的大气光值将有雾特征图输入到剩余系数网络层α-net中,计算剩余系数将有雾特征图输入到透射率图网络层t-net中,得到透射率图根据所述去雾图所述大气光值/&gt;所述剩余系数/&gt;和所述透射率图/&gt;重新合成有雾图,通过合并雾的重建过程来指导层的解缠,训练网络得到去雾图像。</td>   <td>G06T5/00;G06N3/04;G06N3/088;G06F30/27;G06F111/04;G06F111/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张俭嘉;              毛海洋;              伍伟文;                   李沛汝       </td>   <td>中山大学</td>   <td>一种CT图像的金属伪影去除方法</td>   <td>广东省</td>   <td>CN116543063A</td>   <td>2023-08-04</td>   <td>本发明公开了一种CT图像的金属伪影去除方法,通过构建基于小波变换的初始自适应迭代学习模型,通过使用优化目标函数进行优化后的目标自适应迭代学习模型对CT图像进行分解,计算金属伪影的区域并去除CT图像中的金属伪影,得到金属伪影减少的CT图像；通过构建基于小波变换的初始自适应迭代学习模型进行伪影去除,能够充分利用金属伪影在不同域和分辨率下的空间分布特征,更好地进行伪影去除,可解释性高；此外,结合近端梯度下降算法和泰勒公式求解第一优化目标函数时,所得到的近端梯度算子能够用简单的网络模块进行替代,不仅能够更容易构建网络,而且也增强了网络的适应性。本发明可广泛应用于CT图像处理技术领域。</td>   <td>1.一种CT图像的金属伪影去除方法,其特征在于,包括：构建基于小波变换的初始自适应迭代学习模型；根据CT图像的纯净图像区域、二元非金属区域和金属伪影区域确定CT图像表达式；根据所述CT图像表达式、正则化项和图像小波变换构建第一优化目标函数；结合近端梯度下降算法和泰勒公式求解所述第一优化目标函数,得到第一计算结果；根据所述第一计算结果,结合L2输出损失和地面真实图像优化所述初始自适应迭代学习模型,获得目标自适应迭代学习模型；通过所述目标自适应迭代学习模型对所述CT图像进行图像分解和拼接以去除CT图像的金属伪影。</td>   <td>G06T11/00;G06T5/10;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              蒋维娜;                   刘宁       </td>   <td>中山大学</td>   <td>一种基于模糊数相似度的多因素舆情风险评估方法</td>   <td>广东省</td>   <td>CN112734154B</td>   <td>2023-08-01</td>   <td>本发明公开了一种基于模糊数相似度的多因素舆情风险评估方法。首先,使用扩展优劣解距离法得到风险因素的影响程度,同时使用层次分析法得到指标模型结构及各层元素的排列次序；其次,处理不同数据类型的输入得到风险因素事实系数评估值并进行融合；最后,基于模糊数相似度将评估综合值映射到风险等级与模糊数转换系统中,得到舆情风险等级。本发明可以多源融合工作流程中的风险因素,更加全面、综合地对当前舆情风险给出细粒度的评估；对负面话题和正面话题进行不同的统计策略,较传统方法更具合理性,能够较好的反映舆情倾向性,构建的指标模型有利于风险因素的细化,同时风险指标具有更客观的影响程度评价。</td>   <td>1.一种基于模糊数相似度的多因素舆情风险评估方法,其特征在于,所述方法包括：基于历史工作文书和工作流程规则库抽取舆情风险因素,构建风险因素集合,并组建专家组,由专家使用短语集合对该风险因素集合的影响程度进行表述,采集以上数据形成风险因素影响程度数据集；使用层次分析法构建初始舆情风险指标模型的三层结构以及定义各层级节点,该模型由目标层、准则层和指标层三部分组成,其中,目标层确定评估的主体是舆情风险,准则层基于对历史工作文书的鱼骨图分析定义决策者、当事人、案情属性、舆情状态四个标准准则,指标层由风险因素以及对应的影响程度所构成；基于所述风险因素影响程度数据集构建评价矩阵,使用扩展优劣解距离法综合多维评价矩阵计算得到各项风险因素的影响程度；基于所述各项风险因素的影响程度,使用层次分析法确定所述初始舆情风险指标模型中各层元素的排列次序,得到体系结构完整的最终舆情风险指标模型；收集分析当前所处理工作的相关舆情数据,对所述最终舆情风险指标模型中的风险因素进行评估得到模型指标层中每个风险指标的事实系数；融合所述最终舆情风险指标模型指标层中的风险因素影响程度与所述事实系数,得到基于多因素评估的舆情风险综合值；基于模糊数的图形特性,通过计算基于回转半径的模糊数相似度将所述基于多因素评估的舆情风险综合值映射到风险等级与模糊数转换系统中,从而得到当前所处理工作的舆情风险等级；如果所述舆情风险等级或其变化趋势满足触发预警条件,则按照风险预案执行相应的预警操作。</td>   <td>G06Q10/0635;G06F18/22;G06F18/23213;G06F18/2415;G06F40/216;G06F16/35;G06F16/36;G06Q50/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              孙峰;                   周凡       </td>   <td>中山大学</td>   <td>一种基于神经网络的二维虚拟试衣方法</td>   <td>广东省</td>   <td>CN110852941B</td>   <td>2023-08-01</td>   <td>本发明公开了一种基于神经网络的二维虚拟试衣方法。本发明输入原始人物图和目标服装图；提取人体外形图、人体关节点图和人体解析图；通过编解码器网络生成目标人体解析图；卷积神经网络生成变形服装图；编解码器网络生成粗略结果图和服装掩码图；粗略结果图与变形服装图通过服装掩码图进行重组生成最终效果图。本发明应用了二维图片深度学习算法,相比于昂贵的三维硬件采集设备和计算量较大的三维计算,成本低、效率高；使用神经网络方法,通过编码解码结构生成目标人体解析图,能最大限度指导神经网络保留原始图片中人的各部位特征,使用卷积神经网络对目标服装图进行服装变形,能够最大限度地保留目标服装图的纹理信息。</td>   <td>1.一种基于神经网络的二维虚拟试衣方法,其特征在于,所述方法包括：步骤一,从服装数据集筛选并输入原始人物图和目标服装图,并处理成统一尺寸；步骤二,对所述处理成统一尺寸的原始人物图进行进一步处理生成人体外形图、人体关节点图和人体解析图作为人体部分特征；步骤三,使用所述人体部分特征和步骤一得到的统一尺寸的目标服装图,使用卷积神经网络D中的编码解码结构输出目标人体解析图；步骤四,使用神经网络E对步骤一得到的统一尺寸的目标服装图按照所述目标人体解析图中的服装层进行变形,生成变形服装图；步骤五,使用所述变形服装图、目标人体解析图和步骤二得到的人体外形图、人体关节点图和人体解析图通过神经网络F中的编码解码结构进行训练,生成最终的效果图；步骤六,将步骤一中的目标服装图改为与原始人物图所穿着衣服不同的服装图,重复步骤二、三、四、五的过程,其中步骤三、四、五中的神经网络D、E、F不需要再训练,直接输出结果应用到之后的步骤；经过步骤五输出的最终效果图即为原始人物图中的人物换装之后的图片；其中,所述使用卷积神经网络D中的编码解码结构输出目标人体解析图,具体为：输入所述人体关节点图,包括7层二进制图,人体解析图,包括3层RGB图,以及所述人体外形图,包括1层二进制图；将上述所有图层在图层维度上进行组合,形成一个图层整体；将所述图层整体通过U-Net结构的编码解码神经网络D,编码器有6个卷积层,解码器有6个相对应的反卷积层,卷积核尺寸为4*4,在编码器和解码器之间增加跳变结构,除了编码器的最后一层和解码器的第一层,将编码器相应层生成的特征图和解码器相对应层生成的特征图进行组合,作为下一层卷积层的输入,最后一层生成代表原始人物图中的人物穿着目标服装之后的目标人体解析图,包括16个层,每个层代表人的一个部位,相应部位像素值用1表示,其他区域像素值用0表示；对每个解析部分的应用以下公式所示的交叉熵得到的像素级损失求和作为损失函数进行训练,直到损失函数的结果达到收敛；                  H和W表示图像的宽和高,i表示图像中的像素点,C表示划分部位的数量,c表示其中的一个部位,y-(ic)表示生成的像素值,表示真实的像素值；其中,所述通过神经网络F中的编码解码结构进行训练,生成最终的效果图,具体为：按照所述人体解析图中的人脸和头发部分图层像素值为1的区域分割原始人物图中的人脸和头发区域；将所述变形服装图、目标人体解析图和原始人物图中的人脸和头发区域在图层对应维度进行组合形成一个整体；将所述整体通过神经网络F中U-net结构的编码解码网络进行训练；编码器包含6个卷积层,解码器包含6个相对应的反卷积层,卷积核尺寸为4*4,除了编码器的最后一层和解码器的第一层,将编码器相应层生成的特征图和解码器相对应层生成的特征图进行组合,作为下一层卷积层的输入,最后一层卷积层生成四个图层,其中前三层称为粗略结果图,最后一层称为服装掩码图；将所述变形服装图与所述服装掩码图进行对应像素相乘,生成最终效果图的第一部分；新建一个图层,该图层每一层的值为1减去服装掩码图对应像素的值,该图层称为掩码互补图；将所述粗略结果图与掩码互补图进行对应像素相乘,生成最终结果图的第二部分；将生成结果图的第一部分与第二部分对应像素值进行相加,得到最终效果图；将所述最终效果图和统一尺寸的原始人物图通过神经网络G中的VGG19网络前五层卷积层分别输出两部分的对比结果图,对两部分的对比结果求L1损失,得到风格损失结果；对最终结果图和统一尺寸的原始人物图的对应像素值求L1损失,将风格损失和L1像素损失相加作为神经网络F最终的损失函数进行训练,直到损失函数的结果达到收敛。</td>   <td>G06T3/00;G06T5/50;G06T7/11;G06T7/40;G06Q30/0601;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王文宇;              赖韩江;                   潘炎       </td>   <td>中山大学</td>   <td>一种基于数据保护的图像增量学习方法</td>   <td>广东省</td>   <td>CN112115967B</td>   <td>2023-08-01</td>   <td>本发明提供一种基于数据保护的图像增量学习方法,该方法以深度卷积神经网络ResNet为基础,充分利用外部海量图像的信息,对其进行采样并加入训练过程,来缓解新旧样本不均衡所带来的偏差和灾难性遗忘,外部数据即采即用,训练后直接丢弃,不占用存储空间。同时加入针对于各个任务阶段的输出,提取关于任务的特征,提高模型的性能表现。本发明所提出的增量学习方法突破了传统方法的限制,能够灵活广泛地适应多种实际场景的需求,在计算机视觉领域具有重要的研究和应用价值。</td>   <td>1.一种基于数据保护的图像增量学习方法,其特征在于,包括以下步骤：S1：构造以ResNet网络为原型的图像特征提取器,然后添加全连接的任务预测层和图像分类层作为整体的网络架构；S2：为每个阶段的增量数据训练单独的图像分类模型,其中图像分类损失使用交叉熵函数,任务预测损失使用均方误差函数,使用SGD优化器训练网络；S3：对于不存储任何先前类别数据的场景,为避免灾难性遗忘和模型对于当前类别的预测偏向,使用先前模型对大量可用的外部数据进行采样；S4：使用采样数据以及当前类别的训练数据,对新旧两个模型进行融合,使用知识蒸馏引入KL相对熵函数,训练可识别当前所有类别的模型；S5：对于每一增量阶段,重复S2至S4步骤,评估模型时采用任务预测层和图像分类层输出结合的方式预测最终分类；所述步骤S2的具体过程是：S21：将训练集中的数据D-1关于图像分类层的输出通过softmax层,即根据原始的网络输出logits之间的相对大小关系,映射为关于各类别的预测概率,使用交叉熵函数作为图像分类损失,公式如下：                  其中x表示当前类别的输入图像,y表示对应类别0/1标签,θ为模型参数；将训练集数据及外部数据D-2关于任务预测层的输出通过sigmoid函数,映射为是否为当前任务的判断概率,使用均方误差函数作为任务预测损失,公式如下：                  其中y-t表示对应任务的0/1标签,即内部的训练数据标签为1,外部采样数据标签为0；S22：在此步骤中的外部数据随机选取OOD图像；若可选的增加置信度校准损失来训练模型,即外部数据在图像分类层的输出值越平均则损失越小,可使得模型在当前任务中的表现有小幅度提升；S23：使用SGD优化器训练关于当前任务的图像分类模型,学习率随训练epoch的增大而逐渐降低,同时加入关于模型参数的正则化项来防止过拟合,增强模型的泛化能力；所述步骤S4的具体过程是：S41：将步骤S3中的外部数据与当前类别的训练数据充分混合,组成当前完整的训练数据集D-3,其中外部数据集的采样数据量应与当前类别的训练数据量成一定比例,当数据量过大时,模型表现反而会下降,同时会增大训练的时间成本；S42：将步骤S2中关于当前任务的单独模型,与关于过去任务的模型融合,使得融合后的模型能够识别已有的全部图像类型；S43：由于训练集中只包含了关于新类的训练数据,将导致模型很容易将输入图像预测为新类别,为了缓解数据不均衡造成的预测偏差,为数据分配不同的权重,减小新类数据计算得到的梯度；S44：使用SGD优化器训练关于当前所有任务的融合模型,学习率随训练epoch的增大而逐渐降低,其中,此步骤中模型的初始化参数继承旧模型的参数；所述步骤S42的过程是：将步骤S2中关于当前任务的单独模型,与关于过去任务的模型融合,使得融合后的模型能够识别已有的全部图像类型；首先,对新类的训练数据使用交叉熵函数得到分类损失；其次,将所有数据D-3关于新/旧模型的分类层输出logits分别通过softmax层,得到关于旧类别和新类别的预测概率,作为融合后模型的“软标签”,对混合模型对应的新/旧类别输出分别通过softmax层,两个部分均使用KL散度函数进行知识蒸馏,来提取模型中过去的知识,公式如下：                  其中表示已训练好的新/旧模型的输出概率,即“软标签”；对所有数据关于新/旧模型的任务预测层输出直接合并后作为标签,对混合模型的任务预测层输出使用均方误差函数计算损失,提取关于输入图像所在任务阶段的信息。</td>   <td>G06V10/764;G06V10/774;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周雪雯;              辛秦川;                   戴永久       </td>   <td>中山大学</td>   <td>基于深度学习的植物关键物候期时间点预测方法及系统</td>   <td>广东省</td>   <td>CN112560633B</td>   <td>2023-08-01</td>   <td>本发明公开了一种基于深度学习的植物关键物候期时间点预测方法及系统,其方法包括：对采集到的相关气象数据进行归一化处理,并将处理后所形成的若干个特征变量划分至训练集与验证集中；搭建一维卷积神经网络回归模型,并将所述训练集中包含的所有特征变量时间序列导入网络结构进行训练,输出训练模型；以均方误差作为评估指标,将所述验证集中包含的所有特征变量导入所述训练模型进行验证,存储最优模型；将其他区域的气象数据导入所述最优模型进行预测,获取区域内的不同植被物候天数。本发明实施例可覆盖全球尺度下不同生长季节的植被物候,且保证输出结果的高准确率。</td>   <td>1.一种基于深度学习的植物关键物候期时间点预测方法,其特征在于,所述方法包括：对采集到的相关气象数据进行归一化处理,并将处理后所形成的若干个特征变量划分至训练集与验证集中；搭建一维卷积神经网络回归模型,并将所述训练集中包含的所有特征变量时间序列导入网络结构进行训练,输出训练模型；以均方误差作为评估指标,将所述验证集中包含的所有特征变量导入所述训练模型进行验证,存储最优模型；将其他区域的气象数据导入所述最优模型进行预测,获取区域内的不同植被物候天数；所述相关气象数据包括大气含量、降水量、太阳短波辐射量、最低温度、最高温度、平均温度、饱和蒸气压差、风速、土壤湿度和光照时长；所述一维卷积神经网络回归模型依次包括输入层、卷积层组、平均池化层组、Flatten层、Dropout层、全连接层与输出层,其中所述卷积层组包含有三个卷积层,所述平均池化层组包含有两个平均池化层；所述以均方误差作为评估指标,将所述验证集中包含的所有特征变量导入所述训练模型进行验证,存储最优模型包括：将所述验证集中包含的所有特征变量导入所述训练模型进行运算,输出预测结果；计算所述预测结果与真实结果之间的均方误差,并判断所述均方误差是否小于等于阈值；若是,则将所述训练模型指定为最优模型并进行存储；若否,则更新所述一维卷积神经网络回归模型的学习率,并返回将所述训练集中包含的所有特征变量时间序列导入更新后的一维卷积神经网络回归模型进行训练,输出新的训练模型。</td>   <td>G06V20/20;G06V10/44;G06V10/774;G06V10/82;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄寒砚;              熊梅;              朱瑞泓;              林佳陆;                   陈琳       </td>   <td>中山大学</td>   <td>基于量纲分析和最优设计的毁伤响应函数获取方法及装置</td>   <td>广东省</td>   <td>CN115510691B</td>   <td>2023-08-01</td>   <td>本发明涉及毁伤效能评估技术领域,公开了基于量纲分析和最优设计的毁伤响应函数获取方法及装置。本发明基于量纲分析对毁伤响应指标与对应毁伤影响因素的函数关系模型进行处理,采用单点交换算法获取所得到的毁伤响应函数模型中各自变量在取值范围为[0,1]的D-R-最优设计点,其中该算法基于岭回归的思想在信息矩阵的数学表达式中引入了正则化参数；将最优设计点转化为相应自变量所属取值范围内的对应设计点,并利用该对应设计点开展试验得到的试验响应值构建样本数据集,进而进行数据拟合求解回归系数,得到毁伤响应函数。本发明在试验样本量不足的情况下能够实现较高精度的毁伤响应函数的获取,达到较高的试验效费比。</td>   <td>1.一种基于量纲分析和最优设计的毁伤响应函数获取方法,其特征在于,包括：确定毁伤响应指标及对应的毁伤影响因素,获取各所述毁伤影响因素的量纲及取值范围；构建毁伤响应指标与对应毁伤影响因素的函数关系模型,根据所述量纲及取值范围,基于量纲分析对所述函数关系模型进行处理,得到毁伤响应函数模型；采用D-(R-)最优设计单点交换算法获取所述毁伤响应函数模型中各自变量在取值范围为[0,1]的最优设计点,所述D-(R-)最优设计单点交换算法为对D-最优化设计的单点交换算法改进得到,其改进之处为在信息矩阵的数学表达式中引入岭回归的正则化参数；将各所述最优设计点转化为所述毁伤响应函数模型中相应自变量所属取值范围内的对应设计点,以转化得到的对应设计点作为试验设计点,获取利用所述试验设计点开展试验所得到的试验响应值,根据所述试验设计点和所述试验响应值构建样本数据集；根据所述样本数据集进行数据拟合求解所述毁伤响应函数模型的回归系数,得到毁伤响应函数；所述采用D-(R-)最优设计单点交换算法获取所述毁伤响应函数模型中各自变量在取值范围为[0,1]的最优设计点,包括：步骤S31,利用拉丁超立方采样方法给定初始设计ξ-0,令迭代次数k＝1,并设置最大迭代次数；步骤S32,计算设计ξ-(k-1)的信息矩阵的行列式及信息矩阵的逆矩阵；步骤S33,寻找已有设计ξ-(k-1)中的一点x-0～((k-1))和试验域Ω中的任意点x-k,使其满足下式,并用点x-k替换ξ-(k-1)中的x-0～((k-1))后得到新的设计ξ-k：                  步骤S34,利用下列迭代公式更新设计ξ-k的信息矩阵行列式|M-R(ξ-k)|及其逆矩阵                  式中,f(x-k)是一个由回归模型的所有基函数在x-k处的取值组成的列向量,f(x-0～((k-1)))是一个由回归模型的所有基函数在x-0～((k-1))处的取值组成的列向量；步骤S35,给定足够小的可容性误差ε,若Δ(x-k,x-0～((k-1)))＜ε,或算法达到最大迭代次数,则停止迭代,进入步骤S36；否则,令k＝k+1,返回步骤S32；步骤S36,输出最优设计点；其中,Δ(x-k,x-i)和Δ(x-0～((k-1)),x-k)通过代入下式进行计算：                  式中,f(x-i)是一个由回归模型的所有基函数在x-i处的取值组成的列向量,f(x-j)是一个由回归模型的所有基函数在x-j处的取值组成的列向量,T表示转置,表示对应信息矩阵的逆矩阵；d(x-0～((k-1)))和d(x-k)通过代入式进行计算,d(x-0～((k-1)),x-k)通过代入式/&gt;进行计算；其中,按照下式计算信息矩阵：                  式中,M-R表示信息矩阵,f(x-k)为一个由回归模型的所有基函数在x-k处的取值组成的列向量,T表示转置,n为试验次数,λ为岭回归的正则化参数,I为单位矩阵。</td>   <td>G06F30/20;G06F17/18;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              张欢荣;              齐银鹤;                   庞雨贤       </td>   <td>中山大学</td>   <td>一种合成高仿真图像的方法</td>   <td>广东省</td>   <td>CN113160101B</td>   <td>2023-08-01</td>   <td>本发明提供的一种合成高仿真图像的方法,步骤包括：构建原始图像数据集和目标数据集,通过原始图像数据集和目标数据集训练得到非成对无监督风格转换网络模型；获取原始图像数据集中待处理图像,通过非成对无监督风格转换网络模型,生成具有目标数据集风格的目标图像；其中,模型训练步骤包括：获取原始图像数据集中的第一原图,将第一原图转换为目标数据集风格下的第一中间图像；将第一中间图像通过信息增长恢复或信息逆向更改得到第二原图；方法节省大量的时间成本及人力成本,并使得图像数据可用性更高,可广泛应用于图像处理技术领域。</td>   <td>1.一种合成高仿真图像的方法,其特征在于,包括以下步骤：构建原始图像数据集和目标数据集,通过所述原始图像数据集和所述目标数据集训练得到非成对无监督风格转换网络模型；获取原始图像数据集中待处理图像,通过所述非成对无监督风格转换网络模型,生成具有所述目标数据集风格的目标图像；所述通过所述原始图像数据集和所述目标数据集训练得到非成对无监督风格转换网络模型这一步骤,其包括：获取所述原始图像数据集中的第一原图,将所述第一原图转换为目标数据集风格下的第一中间图像；将所述第一中间图像通过信息增长恢复或信息逆向更改得到第二原图；所述通过所述原始图像数据集和所述目标数据集训练得到非成对无监督风格转换网络模型这一步骤,还包括：获取非成对风格转换网络模型的对抗损失、循环像素损失以及循环感知损失；根据对抗损失、循环像素损失以及循环感知损失优化非成对风格转换网络模型；在训练过程中采用了多重损失,包括对抗损失、循环像素损失和循环感知损失；生成器和判别器的总损失考虑了生成的仿真图像的真实性、输入的清晰明亮图像c与重建的清晰明亮图像/&gt;之间的在空间和特征域中的差异,公式如下所示：                                    其中,G代表生成器,D代表判别器；L-(total)代表总损失,L-(adv)代表对抗损失,L-(cycle-pix)代表循环像素损失,L-(cycle-per)代表循环感知损失；α、β、γ和δ是损失分量的相应平衡系数；对抗损失根据第一中间图像与第一原图之间差异得到；采用基于D-T的对抗性损失来减少生成的仿真图像与真实的恶劣视觉图像t之间的差异；生成器G-(C-T)和鉴别器D-T的对抗性损失如下：                                    其中,E是期望计算；循环像素损失根据第一原图与第二原图在空间域中的差异来确定；在Cycle-(C-T-C)中,重建的明亮图像接近输入原清新明亮图像c；用L1损失函数来约束这两种图像在空间域中的相似性；给定H、W和C作为c、的高度、宽度和通道数,循环像素损失如下：                  其中,c-(h,w,c)表示图像c中对应行、列和通道处的像素强度。</td>   <td>G06T5/50;G06T3/00;G06N3/0464;G06N3/088</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋尔卫;              姚和瑞;              余运芳;              任炜;              谭钰洁;              何子凡;              姚沁玥;              汪进;              陈李粮;              单玲政;                   陈睿       </td>   <td>中山大学孙逸仙纪念医院;赛维森(广州)医疗科技服务有限公司</td>   <td>肿瘤预后评估方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN116228753B</td>   <td>2023-08-01</td>   <td>本申请涉及一种肿瘤预后评估方法、装置、计算机设备和存储介质,该方法包括：获取目标对象的术前影像数据；所述术前影像数据包括若干影像序列；对各所述影像序列进行预处理,得到四维影像数据集合；分别获取所述四维影像数据集合中的各个四维影像数据对应的肿瘤靶区掩膜；根据各所述肿瘤靶区掩膜中符合预设条件的连通区域,形成所述四维影像数据集合对应的若干肿瘤靶区影像数据集合；基于各所述肿瘤靶区影像数据集合,确定所述目标对象的肿瘤预后评估结果。本申请不仅增加了肿瘤预后评估结果的评估维度,还有效提升了肿瘤预后评估结果的准确性。</td>   <td>1.一种肿瘤预后评估方法,其特征在于,所述方法包括：获取目标对象的术前影像数据；所述术前影像数据包括若干影像序列；对各所述影像序列进行预处理,得到四维影像数据集合；分别获取所述四维影像数据集合中的各个四维影像数据对应的肿瘤靶区掩膜；根据各所述肿瘤靶区掩膜中符合预设条件的连通区域,形成所述四维影像数据集合对应的若干肿瘤靶区影像数据集合；基于各所述肿瘤靶区影像数据集合,确定所述目标对象的肿瘤预后评估结果；所述肿瘤预后评估结果包括肿瘤影像预后评估系数；所述基于各所述肿瘤靶区影像数据集合,确定所述目标对象的肿瘤预后评估结果,包括：将各所述肿瘤靶区影像数据集合中的各个肿瘤靶区影像数据,输入至预训练好的第一深度生存模型,得到所述肿瘤影像预后评估系数；获取所述目标对象的临床数据；将所述肿瘤影像预后评估系数和所述临床数据,输入至预训练好的第二深度生存模型,得到所述目标对象的肿瘤预后整体评估结果；所述肿瘤预后整体评估结果包括肿瘤预后整体评估系数和肿瘤复发主要影响因素。</td>   <td>G06T7/00;G06T7/187;G06V10/82;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金舒原;              张允义;                   黄依婷       </td>   <td>中山大学</td>   <td>一种基于hacker搜索语法的钓鱼站点检测方法</td>   <td>广东省</td>   <td>CN113420239B</td>   <td>2023-08-01</td>   <td>本发明公开了一种基于hacker搜索语法的钓鱼站点检测方法,包括步骤如下：S1：获取链接,利用已有的数据进行判定,检测该链接是否已经进行过判定,若是,则警告用户访问站点为钓鱼站点,若不是,则执行下一步；S2：对链接的URL进行解析,生成不同的搜索字符串,并结合Hacks搜索语法生成搜索模式；S3：根据搜索模式进行Hacks搜索,获得搜索结果；S4：根据搜索结果依次进行索引策略和资源策略的判定；S5：根据判定做出响应,若判定目标URL为钓鱼站点,则将URL加入本地数据库,并向用户发出警告正在访问站点可能为钓鱼站点；否则不做响应。本发明结合启发式策略有效检出钓鱼站点,包括部署在失陷站点上的钓鱼站点。</td>   <td>1.一种基于hacker搜索语法的钓鱼站点检测方法,其特征在于：包括步骤如下：S1：获取链接,利用已有的数据进行判定,检测该链接是否已经进行过判定,若是,则警告用户访问站点为钓鱼站点,若不是,则执行下一步；S2：对于数据库中不存在的链接,对URL进行解析,生成不同的搜索字符串,并结合Hacks搜索语法生成搜索模式；S3：根据搜索模式进行Hacks搜索,获得搜索结果；S4：根据搜索结果依次进行索引策略和资源策略的判定；S5：根据判定做出响应,若判定目标URL为钓鱼站点,则将URL加入本地数据库,并向用户发出警告正在访问站点可能为钓鱼站点；否则不做响应；所述的搜索模式有两种,具体如下：对于URL中存在路径的,生成：site：域名inurl：起始路径；对于URL中不存在路径的,生成：site：域名；步骤S2中,还为每个链接的URL增加重定向标志位,若产生重定向,则将重定向标志位置1,同时获取重定向后的URL,并生成其对应的生成模式；步骤S3,根据搜索模式进行Hacks搜索,首先检查重定向标志位,若发生重定向,则对原始URL和重定向后URL进行Hacks搜索,否则仅对原始URL进行搜索,然后从搜索结果中提取目标数据最终的站点索引数和搜索结果的前N个URL；步骤S4,对索引策略的判定,具体如下：检测重定向标志位：a.若重定向标志位为1,则首先判定重定向前后URL的搜索结果检查索引数量是否一致性,若索引数量不一致,则判定为钓鱼站点且类型为重定向钓鱼；若索引数量一致,则检查是否为零,若为零,则判定为钓鱼且类型为普通钓鱼；b.若重定向标志位为0,则检查站点索引数是否为零,若为零,则判定为钓鱼且类型为普通钓鱼；所述资源策略包括资源类型一致性、资源路径相似度。</td>   <td>G06F16/955;G06F16/9535</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陆智超;              陈炫元;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的遥感图像分割方法及装置</td>   <td>广东省</td>   <td>CN116523935A</td>   <td>2023-08-01</td>   <td>本发明公开了一种基于卷积神经网络的遥感图像分割方法及装置,其中方法包括：利用地面站服务器根据遥感图像数据集训练卷积神经网络得到训练好的卷积神经网络；训练时对于每一层,根据随机种子生成的种子卷积核对输入数据进行卷积操作得到种子特征图,根据预设规则对种子特征图进行非线性变换得到多个映射特征图,将种子特征图和映射特征图作为下一层的输入数据；利用地面站服务器将训练好的卷积神经网络中各层对应的种子卷积核和保存非线性变换超参数的随机数发送给近地轨道卫星；利用近地轨道卫星根据种子卷积核和随机数部署训练好的卷积神经网络,并完成对遥感图像的分割任务。本发明减少了浮点计算量和参数量,简化卫星的模型部署和运算压力。</td>   <td>1.一种基于卷积神经网络的遥感图像分割方法,其特征在于,包括：利用地面站服务器根据遥感图像数据集训练卷积神经网络得到训练好的卷积神经网络；训练时,对于所述卷积神经网络的每一层,根据种子卷积核对输入数据进行卷积操作得到对应的种子特征图,根据预设规则对所述种子特征图进行非线性变换得到多个映射特征图,将所述种子特征图和所述映射特征图作为下一层的输入数据；其中,所述种子卷积核是利用随机种子生成的卷积核,所述种子特征图是利用所述种子卷积核生成的特征图,所述映射特征图是该层中除所述种子特征图外的其他特征图,所述非线性变换的超参数被随机初始化并保存在随机数中；利用地面站服务器将所述训练好的卷积神经网络中各层对应的所述种子卷积核和所述随机数发送给资源受限的近地轨道卫星；利用所述近地轨道卫星根据所述种子卷积核和所述随机数部署所述训练好的卷积神经网络,并根据所述训练好的卷积神经网络完成对所捕获的遥感图像的分割任务。</td>   <td>G06T7/11;G06N3/0464;G06V20/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         廖天驰;              褚学森;              陈川;              李晓丽;                   郑子彬       </td>   <td>中山大学;中国船舶科学研究中心;深海技术科学太湖实验室</td>   <td>一种基于区块链的联邦学习方法及相关装置</td>   <td>广东省</td>   <td>CN116523034A</td>   <td>2023-08-01</td>   <td>本申请公开了一种基于区块链的联邦学习方法及相关装置,包括：获取本地局部模型；将本地局部模型上传至对应的移动边缘计算服务器；获取其它移动边缘计算服务器广播的第一数据区块中对应客户端的局部模型；对本地局部模型和其它移动边缘计算服务器广播的第一数据区块中对应客户端的局部模型按照预设模型聚合规则进行聚合,得到本地初始全局模型；使用本地数据对所述本地初始全局模型进行训练,得到训练后的目标全局模型,本申请中使用的区块链技术具有分布式、不变性和可追溯性等特点,可以为基于联邦学习架构的训练及计算提供解决方案,有助于消除对中心服务器的需求,保证用户的隐私不被泄露,提供较好的安全性保障,有利于消除模型威胁。</td>   <td>1.一种基于区块链的联邦学习方法,应用于客户端,其特征在于,包括：获取本地局部模型,所述本地局部模型是由联邦学习架构中的客户端通过各自的本地数据对预设的初始局部模型进行训练后得到的,所述联邦学习架构包括多个客户端及与每一所述客户端对应的移动边缘计算服务器,且各个移动边缘计算服务器将其创建的区块以时间顺序相连后组合成区块链网络；将所述本地局部模型上传至对应的移动边缘计算服务器,使得所述移动边缘计算服务器依据所述本地局部模型创建第一数据区块,并将所述第一数据区块广播至所述区块链网络中的其它移动边缘计算服务器,以及接收所述其它移动边缘计算服务器广播的所述第一数据区块中对应客户端的局部模型；获取所述其它移动边缘计算服务器广播的第一数据区块中对应客户端的局部模型；对所述本地局部模型和所述其它移动边缘计算服务器广播的第一数据区块中对应客户端的局部模型按照预设模型聚合规则进行聚合,得到本地初始全局模型；使用所述本地数据对所述本地初始全局模型进行训练,得到训练后的目标全局模型。</td>   <td>G06N3/098;G06N3/0464;G06N3/0455;G06F16/27;H04L67/10;H04L67/06;H04L67/1097</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪涛;              吴敏毅;              高子雄;                   张文沁       </td>   <td>中山大学</td>   <td>一种基于改进响应面与信任技术的灾害控制策略优化方法及系统</td>   <td>广东省</td>   <td>CN116523340A</td>   <td>2023-08-01</td>   <td>本发明公开了一种基于改进响应面与信任技术的灾害控制策略优化方法及系统,涉及灾害控制的技术领域,包括：将隔离带的各边界点位置坐标作为决策变量,多维度评估后构建目标函数和约束条件；之后将目标函数和约束条件转化为无约束优化问题,利用改进响应面法对其进行求解,大幅度提高了局部最优解的求解质量和求解速度；然后利用信任技术,从一个局部最优解出发,获得全局最优解；最后,将全局最优解作为灾害控制最优策略,由于决策变量对应各边界点位置坐标,全局最优解具有确定性,即为隔离带的各边界点的最优位置。本发明能够高效求出森林火灾控制策略的全局最优解,即为森林防火隔离带确定性参数,有效为救灾措施的制定提出指导性意见。</td>   <td>1.一种基于改进响应面与信任技术的灾害控制策略优化方法,其特征在于,包括：S1：获取隔离带的各边界点位置坐标,组建灾害控制策略的决策变量；S2：对灾害控制策略的决策变量对应的隔离带进行多维度评估,获得对应的评估参数；S3：对所有评估参数加权后构建目标函数,并设置约束条件；S4：对目标函数和约束条件进行改写,获得灾害控制策略的无约束优化问题；S5：利用改进响应面法对灾害控制策略的无约束优化问题进行求解,获得无约束优化问题的局部最优解；S6：基于无约束优化问题的局部最优解,利用信任技术计算无约束优化问题的全局最优解；S7：将无约束优化问题的全局最优解作为灾害控制最优策略,完成隔离带的建设规划。</td>   <td>G06Q10/0637;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张荣辉;                   余炯泽       </td>   <td>中山大学</td>   <td>一种基于视觉的雾天烟雾检测方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN116524430A</td>   <td>2023-08-01</td>   <td>本申请属于烟雾检测技术领域,公开了一种基于视觉的雾天烟雾检测方法、装置、设备及介质,该方法包括：对获取到的雾天环境图像进行下采样,得到待检测图像；根据待检测图像的RGB颜色特征计算得到待检测图像的HSV颜色模型,根据待检测图像和暗通道先验计算得到待检测图像的暗通道映射；将待检测图像、HSV颜色模型和暗通道映射输入训练好的烟雾检测网络模型,得到待检测图像的烟雾检测结果。本申请可以达到有效提高在雾天环境下的烟雾检测的准确度和检测精度的效果。</td>   <td>1.一种基于视觉的雾天烟雾检测方法,其特征在于,所述方法包括：对获取到的雾天环境图像进行下采样,得到待检测图像；根据所述待检测图像的RGB颜色特征计算得到所述待检测图像的HSV颜色模型,根据所述待检测图像和暗通道先验计算得到所述待检测图像的暗通道映射；将所述待检测图像、所述HSV颜色模型和所述暗通道映射输入训练好的烟雾检测网络模型,得到所述待检测图像的烟雾检测结果。</td>   <td>G06V20/52;G06V10/56;G06V10/80;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>海外专利</td>   <td>         黄三益;              张家铭;              蔡易航;                   金淙杰       </td>   <td>国立中山大学</td>   <td>METHOD AND SYSTEM FOR PROVIDING EDITING OF TEXT MINING WORKFLOW</td>   <td></td>   <td>TWI811179</td>   <td>2023-08-01</td>   <td>A method for providing editing of a text mining workflow includes: defining the text mining workflow as a tuple including a set of data objects, a set of text mining tasks, a set of text mining links, and a set of gateways; defining the data object as a tuple of a primary key, attributes, and data; defining the text mining task as a tuple of an input, control variables, an output, execution states, and exception handling mechanisms; defining the text mining link as a tuple of a source and a target; defining the gateway as a tuple of an input, an output, and a type; and providing a user interface for editing the text mining workflow.</td>   <td></td>   <td>G06F16/332;G06F16/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;                   陈殷齐       </td>   <td>中山大学</td>   <td>一种面向视频拼接的透视畸变矫正方法</td>   <td>广东省</td>   <td>CN111127361B</td>   <td>2023-07-28</td>   <td>本发明公开一种面向视频拼接的透视畸变矫正方法,包括采集具有运动关系且不同时刻拍摄的数张图像；识别图像的特征点并在图像间进行2-近邻匹配生成特征点匹配对；构造无透视畸变的参考平面,以此建模坐标位置向量：定义特征点及其在特征点匹配对的位移矢量；构建坐标位置向量的能量函数,能量函数包括特征点在其特征点匹配对的位移矢量与所有特征点在各自特征点匹配对的位移矢量均值的平行约束、特征点在其特征点匹配对中X坐标位移差与Y坐标位移差总和的约束、特征点在其特征点匹配对中垂直自由度约束；采用稀疏线性解算器最小化能量函数得到矫正的坐标位置向量。本发明在视频拼接时矫正了图像中远处景物的失真现象。</td>   <td>1.一种面向视频拼接的透视畸变矫正方法,其特征在于,包括如下步骤：S10采集具有运动关系且不同时刻拍摄的数张图像；S20识别图像中的特征点并在图像间进行2-近邻匹配生成特征点匹配对；S30构造无透视畸变的参考平面,以此建模X0Y坐标位置向量v：定义图像中的特征点p＝w～Tv,其中p表示特征点,w为双线性插值权重,矫正后图像中的特征点位置为分别表示经过相同单应变换后的p和v；定义每个特征点在其特征点匹配对的位移矢量其中/&gt;表示参考图像上的第i个特征点的坐标位置,/&gt;表示源图像上的第i个特征点的坐标位置,以图像中第一张图像为参考图像,其他图像为源图像；S40构建图像坐标位置向量v的能量函数：E(v)＝E-p(v)+αE-d(v)+βE-a(v),其中E-p(v)为每个特征点在其特征点匹配对的位移矢量与所有特征点在各自特征点匹配对的位移矢量均值的平行约束,E-d(v)为每个特征点在其特征点匹配对中基于平面仿射坐标的X坐标位移差与Y坐标位移差总和的约束,E-a(v)为每个特征点在其特征点匹配对中垂直自由度约束,α为平衡E-d(v)的权重系数,β为平衡E-a(v)的权重系数；S50采用稀疏线性解算器最小化能量函数E(v),以优化v得到矫正坐标位置向量</td>   <td>G06T5/00;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏泳娴;              陈修治;              吴建平;                   刘礼杨       </td>   <td>广州地理研究所;中山大学;南方海洋科学与工程广东省实验室(广州)</td>   <td>具有生物物理意义的森林种植水资源效应评估方法及系统</td>   <td>广东省</td>   <td>CN111797493B</td>   <td>2023-07-28</td>   <td>本发明公开了一种具有生物物理意义的森林种植水资源效应评估方法及系统,涉及水资源评估领域,所述方法包括根据所述森林地表能量-陆地水量平衡模型和所述非森林地表能量-陆地水量平衡模型,构建具有生物物理意义的森林种植水资源效应定量评估模型,并获得水资源效应系数和利用所述水资源效应系数评估植被覆盖变化对区域森林水资源产生的影响,所述系统包括输入单元、第一处理单元、第二处理单元、第三处理单元和评估输出单元。本发明以更为全面、准确地定量评估不同区域植被覆盖变化下森林增减水资源效应,避免不科学的大规模植树造林活动削弱森林生态系统对气候变化的重要缓解作用。</td>   <td>1.一种具有生物物理意义的森林种植水资源效应评估方法,其特征在于,包括以下步骤：步骤1：构建三层森林地表能量平衡模型和构建陆地水量平衡模型；步骤2：根据所述三层森林地表能量平衡模型和所述陆地水量平衡模型,构建森林地表能量-陆地水量平衡模型和非森林地表能量-陆地水量平衡模型；步骤3：根据所述森林地表能量-陆地水量平衡模型和所述非森林地表能量-陆地水量平衡模型,构建具有生物物理意义的森林种植水资源效应定量评估模型,并获得水资源效应系数；步骤4：利用所述水资源效应系数评估植被覆盖变化对区域森林水资源产生的影响；所述三层森林地表能量平衡模型根据以下方法构建：                                    其中,a为地表反射率；为太阳向下短波辐射；LW为净长波辐射(W/m～2),LW＝LW-(in)-LW-(out),其中,LW-(in)为进入系统的长波辐射(W/m～2),LW-(out)为系统输出的长波辐射(W/m～2),LW-(in)＝R-(sky),其中,R-(sky)和R-(soil)分别为大气发射的长波辐射和土壤发射的向上长波辐射,R-(canopy)为冠层发射的长波辐射,/&gt;为传递系数,/&gt;表示林冠层对净辐射的截留率,LAI为叶面积指数；c是净辐射在植被冠层中的消减指数,u为太阳天顶角θ的余弦值；G-(soil)为土壤热通量；LE表示系统的潜热损失；ρ-a是空气密度；C-p是空气定压比热容量；r-s、r-(c,a)和r-(a,c)分别表示土壤层与林下空气层间显热传递阻力系数、冠层与林外空气层间显热传递阻力系数、林下空气层与冠层间显热传递阻力系数；T-(so)、T-(ao)和T-c分别表示林外土壤表层温度(K)、林外空气温度(K)、植被冠层温度(K)；ΔT-s表示的是林下土壤温度和林外土壤温度之间的差值；ΔT-a表示的是林下空气温度和林外空气温度之间的差值；所述陆地水量平衡模型根据以下方法构建：ET＝P-R-ΔS其中,ET为年蒸散量(mmyr～(-1))；P为年降雨量(mmyr～(-1))；R为年径流量(mmyr～(-1))；ΔS表示的是系统当年储水量和上一年储水量之间的差值(mmyr～(-1))；森林地表能量-陆地水量平衡模型和非森林地表能量-陆地水量平衡模型根据以下方法构建：根据系统的潜热损失LE和年蒸散量ET之间的关系,可以获得：LE＝λET其中,λ为转换系数；根据所述三层森林地表能量平衡模型和所述陆地水量平衡模型,联合潜热损失LE和年蒸散量ET之间的关系,获得：森林地表能量-陆地水量平衡模型：                  非森林地表能量-陆地水量平衡模型：                  其中,R为年径流量(mmyr～(-1))；ΔS表示的是系统当年储水量和上一年储水量之间的差值(mmyr～(-1))；P为年降雨量(mmyr～(-1))；ρ-a是空气密度；C-p是空气定压比热容量；λ为转换系数,取值为2500；r-s表示土壤层与林下空气层间显热传递阻力系数；T-(so)、T-(ao)和T-c分别表示林外土壤表层温度(K)、林外空气温度(K)、植被冠层温度(K)；r-(c,a)、r-(a,c)分别表示冠层与林外空气层间显热传递阻力系数、林下空气层与冠层间显热传递阻力系数；ΔT-s表示的是林下土壤温度和林外土壤温度之间的差值；ΔT-a表示的是林下空气温度和林外空气温度之间的差值；a为地表反射率；为太阳向下短波辐射；LW为净长波辐射(W/m～2),LW＝LW-(in)-LW-(out),其中,LW-(in)为进入系统的长波辐射(W/m～2),LW-(out)为系统输出的长波辐射(W/m～2),其中,R-(sky)和R-(soil)分别为大气发射的长波辐射和土壤发射的向上长波辐射,R-(canopy)为冠层发射的长波辐射,为传递系数,/&gt;表示林冠层对净辐射的截留率,LAI为叶面积指数；c是净辐射在植被冠层中的消减指数,u为太阳天顶角θ的余弦值；G-(soil)为土壤热通量；具有生物物理意义的森林种植水资源效应定量评估模型根据以下方法构建：将森林地表能量-陆地水量平衡模型与非森林地表能量-陆地水量平衡模型作差,获得：                  式中,为水资源效应系数；Δa表示的是森林地表反射率与非森林地表反射率之间的差值；T-c表示的是林冠层温度；T-(ao)表示林外空气温度；λ为转换系数,取值为2500；P为年降雨量；ρ-a是空气密度,取值1.25kg/m～3；C-p是空气定压比热容量,取值1004J/(kgK)；r-(c,a)、r-(a,c)分别表示冠层与林外空气层间显热传递阻力系数、林下空气层与冠层间显热传递阻力系数；/&gt;为太阳向下短波辐射；r-s表示土壤层与林下空气层间显热传递阻力系数；ΔT-a表示的是林下空气温度和林外空气温度之间的差值；ΔT-s表示的是林下土壤温度和林外土壤温度之间的差值。</td>   <td>G06F30/20;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡天江;              李铭慧;              郑勋臣;              潘亮;                   王勇       </td>   <td>中山大学</td>   <td>一种基于DenseHR-Net的无人机自主着陆目标提取方法及装置</td>   <td>广东省</td>   <td>CN112069997B</td>   <td>2023-07-28</td>   <td>本发明公开了一种基于DenseHR-Net的无人机自主着陆目标提取方法及装置,所述方法包括：通过地面摄像机拍摄无人机的RGB三通道图像后进行图像预处理,得到统一标准尺寸的RGB图像；通过搭建DenseHR-Net目标检测网络模型对RGB图像进行无人机的关键区域检测定位,识别图像中的若干个关键区域的最小外接矩形检测框；根据预设的优先级策略,从图像中的若干个关键区域选取其中一个作为关键点坐标区域,提取出关键点坐标区域的最小外接矩形检测框的中心点坐标,作为无人机着陆的关键点坐标。本发明采用深度学习网络DenseHR-Net对无人机各位置进行目标检测,能够有效提取无人机自主着陆目标,提高无人机各位置的定位精度,同时避免出现机头误检或漏检的情况,并增强了检测算法的鲁棒性。</td>   <td>1.一种基于DenseHR-Net的无人机自主着陆目标提取方法,其特征在于,至少包括如下步骤：在无人机着陆过程中,通过地面摄像机拍摄无人机的RGB三通道图像后进行图像预处理,得到统一标准尺寸的RGB图像；通过搭建DenseHR-Net目标检测网络模型对所述RGB图像进行无人机的关键区域检测定位,识别出所述RGB图像中的若干个关键区域的最小外接矩形检测框；其中,所述关键区域包括无人机机头、无人机机翼和无人机机体；其中,所述通过搭建DenseHR-Net目标检测网络模型对所述RGB图像进行无人机的关键区域检测定位,识别出所述RGB图像中的若干个关键区域的最小外接矩形检测框,具体包括：搭建DenseHR-Net目标检测网络模型的框架,将所述RGB图像输入至DenseHR-Net目标检测网络模型进行特征提取；采集无人机着陆的RGB图像,在构建所述DenseHR-Net目标检测网络模型的样本数据集后,对所述样本数据集进行扩充；通过扩充后的样本数据集对所述DenseHR-Net目标检测网络模型进行训练,训练完成后得到最终的DenseHR-Net目标检测网络模型；将所述RGB图像输入至所述最终的DenseHR-Net目标检测网络模型进行无人机的关键区域检测定位,识别出所述RGB图像中的若干个关键区域的最小外接矩形检测框；其中,所述将所述RGB图像输入至所述最终的DenseHR-Net目标检测网络模型进行无人机的关键区域检测定位,识别出所述RGB图像中的若干个关键区域的最小外接矩形检测框,具体为：将待测的RGB图像输入至经过训练的DenseHR-Net目标检测网络模型中,得到对应的预测张量,并根据所述预测张量确定对应的预测矩形框；其中,所述预测张量包括无人机目标区域的中心坐标值、宽值、高值、置信度和类别信息；采用非极大值抑制算法对若干个所述预测矩形框进行计算,得到每个关键区域的置信度最高的目标矩形框,转换得到原RGB图像上该目标的类别和位置；根据预设的优先级策略,从所述RGB图像中的若干个关键区域选取其中一个作为关键点坐标区域,提取出所述关键点坐标区域的最小外接矩形检测框的中心点坐标,作为无人机着陆的关键点坐标。</td>   <td>G06V20/17;G06V10/25;G06V10/52;G06V10/80;G06V10/764;G06V10/82;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡天江;              李铭慧;              郑勋臣;              张嘉榕;                   朱波       </td>   <td>中山大学</td>   <td>基于双级联深度网络的无人机多特征点检测方法及装置</td>   <td>广东省</td>   <td>CN112070085B</td>   <td>2023-07-28</td>   <td>本发明公开了一种基于双级联深度网络的无人机多特征点检测方法及装置。所述方法包括：在采集的每一无人机图像中对无人机的多个特征区域进行类别及边界框标注,得到对应的训练图像；将每一所述训练图像输入预先构建的边界框定位网络进行训练,使所述边界框定位网络输出多个特征区域预测框；根据每一所述特征区域预测框提取对应的感兴趣区域,将所有所述感兴趣区域输入预先构建的特征点回归网络进行训练；通过由训练后的所述边界框定位网络和所述特征点回归网络组成的双级联深度网络对待检测图像进行多特征点检测,得到多个特征点坐标。本发明能够实时稳定且准确地检测无人机的多个特征点。</td>   <td>1.一种基于双级联深度网络的无人机多特征点检测方法,其特征在于,包括：在采集的每一无人机图像中对无人机的多个特征区域进行类别及边界框标注,得到对应的训练图像；将每一所述训练图像输入预先构建的边界框定位网络进行训练,使所述边界框定位网络输出多个特征区域预测框；所述将每一所述训练图像输入预先构建的边界框定位网络进行训练,使所述边界框定位网络输出多个特征区域预测框,具体为：构建所述边界框定位网络,将一所述训练图像输入所述边界框定位网络进行训练,使所述边界框定位网络输出多个所述特征区域预测框；其中,所述特征区域预测框包括无人机机体、左机翼、右机翼、左尾翼、右尾翼、中脚架区域预测框；根据所述边界框定位网络的网络损失反向更新所述边界框定位网络的网络参数,并在所述边界框定位网络的网络损失小于第一预设阈值时结束训练所述边界框定位网络,否则继续将下一所述训练图像输入所述边界框定位网络进行训练；根据每一所述特征区域预测框提取对应的感兴趣区域,将所有所述感兴趣区域输入预先构建的特征点回归网络进行训练；所述根据每一所述特征区域预测框提取对应的感兴趣区域,具体为：基于所述特征区域预测框的中心点提取预设尺寸的图像区域,将所述图像区域作为对应的所述感兴趣区域；所述将所有所述感兴趣区域输入预先构建的特征点回归网络进行训练,具体为：构建所述特征点回归网络,将一所述训练图像对应的所有所述感兴趣区域输入所述特征点回归网络进行训练；根据所述特征点回归网络的网络损失反向更新所述特征点回归网络的网络参数,并在所述特征点回归网络的网络损失小于第二预设阈值时结束训练所述特征点回归网络,否则将下一所述训练图像对应的所有所述感兴趣区域输入所述特征点回归网络进行训练；通过由训练后的所述边界框定位网络和所述特征点回归网络组成的双级联深度网络对待检测图像进行多特征点检测,得到多个特征点坐标。</td>   <td>G06V20/17;G06V10/25;G06V10/40;G06V10/764;G06V10/82;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋明洋;                   桑应朋       </td>   <td>中山大学</td>   <td>一种基于区块链的全同态加密算法的安全外包方法及系统</td>   <td>广东省</td>   <td>CN112328699B</td>   <td>2023-07-28</td>   <td>本发明公开了一种基于区块链的全同态加密算法的安全外包方法及系统,该方法包括：在本地服务器生成参数并将计算任务发送到区块链网络执行,返回计算结果后生成密钥；对数据进行加密并通过区块链网络和本地服务器分别执行多项式乘法任务和多项式加法任务,得到加密后的数据；根据密钥对加密后的数据进行解密并将多项式乘法任务发送到区块链网络执行,返回计算结果后得到解密数据。该系统包括：本地服务器和区块链网络。通过使用本发明,降低全同态加密算法的本地运算复杂度,使其能在计算能力有限的设备上更具实用性。本发明作为一种基于区块链的全同态加密算法的安全外包方法及系统,可广泛应用于安全计算领域。</td>   <td>1.一种基于区块链的全同态加密算法的安全外包方法,其特征在于,包括以下步骤：在本地服务器生成参数并将计算任务发送到区块链网络执行,返回计算结果后生成密钥；对数据进行加密并通过区块链网络和本地服务器分别执行多项式乘法任务和多项式加法任务,得到加密后的数据；根据密钥对加密后的数据进行解密并将多项式乘法任务发送到区块链网络执行,返回计算结果后得到解密数据；所述在本地服务器生成参数并将计算任务发送到区块链网络执行,返回计算结果后生成密钥这一步骤,其具体包括：根据预设规则在本地服务器生成参数并发送数据至区块链网络；基于区块链网络对数据执行多项式乘法计算并返回第一计算结果；本地服务器对第一计算结果进行验证并将验证结果反馈给区块链；基于区块链网络对数据执行欧几里得算法计算并返回第二计算结果；本地服务器对第二计算结果进行验证并将验证结果反馈给区块链。</td>   <td>G06F16/27;G06F21/60;G06F21/64;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈刚;                   马发潮       </td>   <td>中山大学</td>   <td>一种深度图的生成方法、装置及存储介质</td>   <td>广东省</td>   <td>CN112419383B</td>   <td>2023-07-28</td>   <td>本发明公开了一种深度图的生成方法、装置及存储介质,其中,该方法主要包括ORB特征点提取和loss函数,可解决在校准后为了保持校准结果而无法进行图像拼接的问题,和可解决由于拼接无关于世界坐标变换,拼接后无法统一校准上下五组图像的问题；本发明使用光学相机传感器,与其他使用激光雷达传感器技术相比而言,本发明的设备成本十分低廉,且通过本发明所述的深度图的生成方法,获得的深度稠密度更高；同时本发明无须通过生成过渡拼接的图像,而是将图像拼接成全景图后直接生成深度图,可以减少计算时间；且本发明只需要校准一组图像,不需要对全部图像进行校准处理,且能够确保校准图像精确性。本发明可广泛应用于图像拼接技术领域。</td>   <td>1.一种深度图的生成方法,其特征在于,包括以下步骤：对多组原始图像进行校正,并进行分组得到第一组图像和第二组图像,所述第一组图像包括至少一组待校准图像,所述第二组图像包括至少一组无需校准的图像；对第一组图像进行校准处理,得到第三组图像；对第一图像集中的所有图像进行ORB特征点提取,获得ORB特征点点集,所述第一图像集包括第二组图像和第三组图像；根据所述ORB特征点点集,通过ransac算法得到初始化旋转矩阵；将所述初始化旋转矩阵通过梯度下降法得到拼接矩阵；将第一图像集中的所有图像通过所述拼接矩阵进行仿射和拼接,得到全景图；使用SAD算法从所述全景图中获得视差,并通过光学原理生成深度图；所述根据所述ORB特征点点集,通过ransac算法得到初始化旋转矩阵这一步骤,具体包括：根据损失函数,通过ransac算法,从所述ORB特征点点集得出最佳的特征点对；将最佳的特征点对对应的拼接矩阵作为初始化旋转矩阵；所述损失函数的具体表达式为：loss＝distance(pt1-M1*pt2)+distance(pt3-M2*pt4)；式中,从所述第一图像集中选取上下左右相邻的4幅图中的特征点,其中pt1为左上图中的特征点,pt2为右上图中的特征点,pt3为左下图中的特征点,pt4为右下图中的点；M1为特征点pt2对应特征点pt1的旋转矩阵；M2为特征点pt4对应特征点pt3的旋转矩阵,distance为一阶距离；所述将所述初始化旋转矩阵通过梯度下降法得到拼接矩阵这一步骤,是通过以下公式执行：loss＝distance(pt1-M1*pt2)+distance(pt3-M2*pt4)+x-distance(M1*pt2-M2*pt4)；式中,从所述第一图像集中选取上下左右相邻的4幅图中的特征点,其中pt1为左上图中的特征点,pt2为右上图中的特征点,pt3为左下图中的特征点,pt4为右下图中的点；M1为特征点pt2对应特征点pt1的旋转矩阵；M2为特征点pt4对应特征点pt3的旋转矩阵,distance为一阶距离,x-distance为x轴方向上的一阶距离。</td>   <td>G06T7/50;G06T3/40;G06T3/00;G06V10/44;G06V10/75</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   吴星       </td>   <td>中山大学</td>   <td>一种面向目标分类系统的通用目标攻击方法及装置</td>   <td>广东省</td>   <td>CN112836764B</td>   <td>2023-07-28</td>   <td>本发明公开了一种面向目标分类系统的通用目标攻击方法及装置。所述方法,包括步骤：S1、对随机生成的噪音矩阵进行初始化,得到初始噪音矩阵；S2、将所述初始噪音矩阵叠加至自然图像,得到伪装图像,并通过标签误导方法和特征误导方法误导所述目标分类系统,得到误导后的目标分类系统,以获取所述误导后的目标分类系统对所述伪装图像的分类结果；S3、对所述初始噪音矩阵进行更新得到更新噪音矩阵,并将所述初始噪音矩阵更新为所述更新噪音矩阵；S4、迭代执行步骤S2～S3直至满足预设停止条件,获取当前所述初始噪音矩阵和/或当前所述伪装图像。本发明能够实现定向攻击目标分类系统,获取具有最佳攻击效果的噪音矩阵和/或伪装图像。</td>   <td>1.一种面向目标分类系统的通用目标攻击方法,其特征在于,包括步骤：S1、对随机生成的噪音矩阵进行初始化,得到初始噪音矩阵；S2、将所述初始噪音矩阵叠加至自然图像,得到伪装图像,并通过标签误导方法和特征误导方法误导所述目标分类系统,得到误导后的目标分类系统,以获取所述误导后的目标分类系统对所述伪装图像的分类结果；所述标签误导方法的优化公式为：                  其中,I为可视化图像；C为目标分类系统,C(t*)为目标分类系统对自然图像t*的分类结果,C((t+z)*)为目标分类网络对伪装图像I～t＝(t+z)*的分类结果；所述特征误导方法的公式如下：                  其中,I为可视化图像；f为目标分类系统的卷积层,f((t+z)*)为目标分类系统对伪装图像I～t＝(t+z)*的特征提取结果,f(I)为目标分类系统对可视化图像I的特征提取结果；S3、对所述初始噪音矩阵进行更新得到更新噪音矩阵,并将所述初始噪音矩阵更新为所述更新噪音矩阵；S4、迭代执行步骤S2～S3直至满足预设停止条件,获取当前所述初始噪音矩阵和/或当前所述伪装图像。</td>   <td>G06V10/774;G06V10/764;G06F17/16;G06V10/82;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              周铭枝;              郑炎辉;                   康丽       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>基于元胞自动机的河口地区盐度预测方法、系统及设备</td>   <td>广东省</td>   <td>CN115081740B</td>   <td>2023-07-28</td>   <td>本发明涉及水环境监测技术领域,公开了基于元胞自动机的河口地区盐度预测方法、系统及设备。本发明根据目标河口地区的遥感图像及水域分布定义元胞大小及空间分布,根据该地区的盐度遥感反演结果设置各元胞的初始盐度,根据径流数据设置各元胞的各项属性,并基于水动力转换机制、盐度移流机制、盐度扩散机制及水位变化规律形成元胞自动机模型的演化规则；根据演化规则对模型中所有元胞的各项属性进行迭代计算,根据得到的盐度变化数据与对应的实测盐度变化数据的比对结果进行模型各项参数的率定,得到相应的盐度预测模型,进而根据该预测模型预测目标河口地区盐度。本发明能够有效实现河口区盐度的模拟预测,解决了盐度的时间连续性预测问题。</td>   <td>1.一种基于元胞自动机的河口地区盐度预测方法,其特征在于,包括：根据目标河口地区的遥感图像及水域分布数据,设置元胞自动机模型的元胞大小及邻居结构,并设置元胞空间的墙界、流入边界和流出边界；获取目标河口地区的盐度遥感反演结果,以所述盐度遥感反演结果作为元胞自动机模型的盐度初始分布数据,根据所述盐度初始分布数据对各所述元胞的盐度进行赋值,根据所述目标河口地区的径流数据设置各所述元胞的各项属性,所述各项属性包括水位、水深、河底高程及含盐总量；构建关于元胞间水流流向变化和转移水量变化的水动力转换机制,根据所述水动力转换机制构建盐度移流机制,根据费克第一定律构建盐度扩散机制,根据实测潮位数据和降雨数据采用线性插值法得到潮汐与降雨导致的水位变化规律,将所述水位变化规律嵌入到所述水动力转换机制中,并基于得到的水动力转换机制、所述盐度移流机制和所述盐度扩散机制形成所述元胞自动机模型的演化规则；根据所述演化规则对所述元胞自动机模型中的所有元胞的各项属性进行迭代计算,将得到的盐度变化数据与对应的实测盐度变化数据进行比对,根据得到的比对结果进行所述元胞自动机模型各项参数的率定,得到相应的河口地区盐度预测模型；根据所述河口地区盐度预测模型预测目标河口地区盐度；所述构建关于元胞间水流流向变化和转移水量变化的水动力转换机制,包括：以由最大水位坡度决定水流流向为原则建立元胞间水流流向计算规则；以由元胞间的水位差和水流流速决定转移水量为原则建立元胞间转移水量计算规则；根据所述元胞间水流流向计算规则和所述元胞间转移水量计算规则构建水动力转换机制；所述根据所述水动力转换机制构建盐度移流机制,包括：以所述水动力转换机制为基础,假定每个中心元胞仅与与其发生水量输送的邻居元胞存在盐度移流,设置元胞间关于盐分移流作用的盐度变化规律为：                  式中,Sal(i,j,t1)为t1时刻中心元胞(i,j)的含盐总量,Sal(i,j,t0)为t0时刻中心元胞(i,j)的含盐总量,t1为t0的下一时刻,f0为t0时刻中心元胞(i,j)损失的水量,R(i,j,t0)为t0时刻中心元胞(i,j)的盐度,R-k为t0时刻第k个邻居元胞的盐度,f-k～′为t0时刻第k个邻居元胞流向中心元胞(i,j)的水流量,n为与中心元胞(i,j)发生水量输送的邻居元胞的数量,depth(i,j,t0)为t0时刻中心元胞(i,j)的水深；假定在每一次迭代计算中,中心元胞从其他邻居元胞处获得的不同盐度的水团能够在预置的计算间隔时间内混合均匀,设置下一时刻中心元胞的盐度满足：                  式中,R(i,j,t1)为t1时刻中心元胞(i,j)的盐度,depth(i,j,t1)为t1时刻中心元胞(i,j)的水深；所述根据费克第一定律构建盐度扩散机制,包括：根据费克第一定律构建下列盐度扩散机制：                  式中,M-(mx)为分子扩散通量,Sal-(change)为任意两个邻近元胞发生盐度扩散交换的含盐总量,单位为mg,depth1和depth2为发生盐度扩散交换的两个元胞的水深,d为元胞自动机模型中元胞网格的大小,t为预置的计算间隔时间。</td>   <td>G06Q10/04;G06Q50/06;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青松;              石珂;              翁海松;              刘彬媛;              林明鑫;              赖涛;                   黄海风       </td>   <td>中山大学</td>   <td>一种SAR图像的校正方法及装置</td>   <td>广东省</td>   <td>CN116503269A</td>   <td>2023-07-28</td>   <td>本发明公开了一种SAR图像的校正方法及装置,所述方法包括：获取初始DEM数据后,将所述初始DEM数据分别与若干个位置偏移量相加,得到若干个偏移DEM数据；采用每个所述偏移DEM数据计算待校正SAR图像的偏移平均灰度值,得到若干个偏移平均灰度值；利用所述若干个偏移平均灰度值与预设的初始平均灰度值对待校正SAR图像进行偏移校正。本发明可以在获取待校正SAR图像对应的DEM数据后,将水平偏移量添加在DEM数据中,然后分别计算添加了水平偏移量的DEM数据的平均灰度以及未添加水平偏移量的DEM数据的平均灰度,通过两个灰度值的比较筛选出符合实际需求的水平偏移量并进行图像校正,从而减少相对位置偏差所带来的影响,提升图像校正的效果。</td>   <td>1.一种SAR图像的校正方法,其特征在于,所述方法包括：获取初始DEM数据后,将所述初始DEM数据分别与若干个位置偏移量相加,得到若干个偏移DEM数据,所述初始DEM数据为待校正SAR图像对应区域的DEM数据；采用每个所述偏移DEM数据计算待校正SAR图像的偏移平均灰度值,得到若干个偏移平均灰度值；利用所述若干个偏移平均灰度值与预设的初始平均灰度值对待校正SAR图像进行偏移校正,所述预设的初始平均灰度值是采用初始DEM数据计算的待校正SAR图像的平均灰度值。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘彬媛;              翁海松;              王青松;              石珂;              林明鑫;              赖涛;                   黄海风       </td>   <td>中山大学</td>   <td>一种基于图像重叠区域的图像匀色方法及装置</td>   <td>广东省</td>   <td>CN116503274A</td>   <td>2023-07-28</td>   <td>本发明公开了一种基于图像重叠区域的图像匀色方法、装置及计算机可读存储介质,所述方法包括：获取多张经过预处理的航带图像；基于预设的屏蔽水域掩膜在相邻的所述航带图像中提取重叠区域,以及提取相邻的所述航带图像的辐射特性曲线；根据所述重叠区域的像素和所述辐射特性曲线对相邻的所述航带图像进行第一匀色处理。本发明可以获取多张经过预处理的航带图像,基于预设的屏蔽水域掩膜在相邻的两张航带图像的重叠区域,根据重叠区域的像素信息和待匀色航带图像的辐射特性信息对两张航带图像进行匀色处理,以降低匀色的偏差,提升匀色效果。</td>   <td>1.一种基于图像重叠区域的图像匀色方法,其特征在于,所述方法包括：获取多张经过预处理的航带图像；基于预设的屏蔽水域掩膜在相邻的所述航带图像中提取重叠区域,以及提取相邻的所述航带图像的辐射特性曲线；根据所述重叠区域的像素和所述辐射特性曲线对相邻的所述航带图像进行第一匀色处理。</td>   <td>G06T5/00;G06T3/40;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵毓斌;              周和文;              杜雨阳;              渠松松;              游思遐;                   黄惠保       </td>   <td>中山大学;珠海一微半导体股份有限公司</td>   <td>基于矩形标签的视觉定位方法</td>   <td>广东省</td>   <td>CN116503477A</td>   <td>2023-07-28</td>   <td>本发明公开基于矩形标签的视觉定位方法,包括：步骤A、机器人对其摄像头采集的图像进行预处理,再在预处理后的图像内搜索出矩形标签的图形属性和矩形标签的顶点；步骤B、根据矩形标签的图形属性和矩形标签的顶点,利用单目测距原理计算矩形标签与摄像头之间的距离、矩形标签相对于摄像头的偏向角度、以及矩形标签所在平面的倾斜角度,以使在矩形标签所在平面与摄像头的针孔平面不平行的情况下,矩形标签与摄像头之间的距离是摄像头到矩形标签中与目标交线平行的边的距离；然后将矩形标签与摄像头之间的距离、以及矩形标签相对于摄像头的偏向角度设置为机器人对待定位装置或矩形标签的视觉定位结果。</td>   <td>1.基于矩形标签的视觉定位方法,其特征在于,视觉定位方法包括：步骤A、机器人对其摄像头采集的图像进行预处理,再在预处理后的图像内搜索出矩形标签的图形属性和矩形标签的顶点；步骤B、根据矩形标签的图形属性和矩形标签的顶点,利用单目测距原理计算矩形标签与摄像头之间的距离、矩形标签相对于摄像头的偏向角度、以及矩形标签所在平面的倾斜角度,以使在矩形标签所在平面与摄像头的针孔平面不平行的情况下,矩形标签与摄像头之间的距离是摄像头到矩形标签中与目标交线平行的边的距离；然后将矩形标签与摄像头之间的距离、以及矩形标签相对于摄像头的偏向角度设置为机器人对待定位装置或矩形标签的视觉定位结果；其中,矩形标签所在平面与摄像头的针孔平面的交线是记为目标交线；其中,矩形标签是设置在待定位装置的表面。</td>   <td>G06T7/73;G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘镇;              王静琪;                   周翠英       </td>   <td>中山大学</td>   <td>适于生态修复的植被种群实时分布辨识方法和相关装置</td>   <td>广东省</td>   <td>CN116503738A</td>   <td>2023-07-28</td>   <td>本发明涉及一种适于生态修复的植被种群实时分布辨识方法和相关装置。所述方法包括如下步骤：构建修复植被种群数据库；对无人机拍摄的图像进行裁剪,得出目标修复区域,并计算目标修复区域的像素点数量；提取目标修复区域中的各个植被种群的实时覆盖区域,并计算各个植被种群的实时覆盖区域的像素点数量；计算各个植被种群实时覆盖区域的像素点数量与目标修复区域的像素点数量的比值,获得生态修复过程中的各个植被种群的实时分布比例。本发明操作简单,结果可靠,提高了效率,提高了修复植被种群实时分布情况的辨识准确度。</td>   <td>1.一种适于生态修复的植被种群实时分布辨识方法,其特征在于,包括如下步骤：获取包括目标修复区域的第一图片；按照生态修复方案中修复区域的划分,对第一图片进行裁剪,得到目标修复区域的图像；对目标修复区域的像素点数量进行计算；依据生态修复方案中的修复植被种群的种类,识别目标修复区域的图像,并将识别结果与预先构建的修复植被种群数据库中的植被种群的种类进行特征匹配,得到目标修复区域中各个植被种群的种类及对应的实时覆盖区域；对各个植被种群实时覆盖区域的像素点数量进行计算；计算各个植被种群实时覆盖区域的像素点数量与目标修复区域的像素点数量的比值,获得生态修复过程中的各个植被种群的实时分布比例。</td>   <td>G06V20/10;G06V10/25;G06V10/26;G06V10/764;G06V10/40;G06V10/56;G06V20/17;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张正贵;              虞志益;                   肖山林       </td>   <td>中山大学</td>   <td>一种Transformer神经网络系统及其运算方法</td>   <td>广东省</td>   <td>CN116502675A</td>   <td>2023-07-28</td>   <td>本发明公开了一种Transformer神经网络系统及其运算方法,模型包括：序列特征提取算法模块、联合多头注意力算法模块、高效计算算法模块、Transformer硬件加速算法模块以及判断、控制及调度系统方法算法模块。本发明既能为设计终端应用的更优秀的AI处理核、SOC集成,或者在类似的平台上开发更新的算法模块带来的技术,也能为直接使用本发明的方法,使用到目前硬件资源中,发挥出Transformer的优势。本发明可以克服存储空间和计算时间的二次方的复杂性,并加快硬件运算速度,可广泛应用于人工智能领域。</td>   <td>1.一种Transformer神经网络系统,其特征在于,包括：序列特征提取算法模块,用于通过主干的神经网络对输入为信号的序列进行特征提取,并输出稀疏的N：M的神经网络权重；联合多头注意力算法模块,用于将输入的输入信号序列输出为经过稀疏神经网络后得到的动态注意力矩阵,所述动态注意力矩阵由Q、K、V注意力矩阵间的关联关系运算得到；高效计算算法模块,用于根据运算特征进行调度,组织运算,对输入的信号进行判断、调度及控制信号,根据密集计算引擎或者稀疏计算引擎进行复杂度降低的特征提取运算；还用于处理多头注意力,对输入的动态注意力矩阵Q、K、V,根据判断、调度及控制信号以及密集计算引擎或者稀疏计算引擎,进行复杂度降低的注意力N：M的稀疏运算；Transformer硬件加速算法模块,用于在硬件计算和数据搬移之间处理指令与作业调度；判断、控制及调度系统方法算法模块,用于根据各算法模块的系统状态,按照预设的规则对效率进行调度协调,输出对各算法模块的控制与调度等。</td>   <td>G06N3/0455;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵毓斌;              周和文;              杜雨阳;              渠松松;              游思遐;                   黄惠保       </td>   <td>中山大学;珠海一微半导体股份有限公司</td>   <td>基于标签图案的视觉定位控制方法</td>   <td>广东省</td>   <td>CN116503478A</td>   <td>2023-07-28</td>   <td>本发明公开基于标签图案的视觉定位控制方法,包括：步骤A、机器人对其摄像头采集的图像进行预处理,再在预处理后的图像内搜索出标签图案的图形属性和顶点；步骤B、基于标签图案的图形属性和顶点,利用单目测距原理计算标签图案与摄像头之间的距离、以及标签图案相对于摄像头的偏转角度；步骤C、判断标签图案与摄像头之间的距离、以及标签图案相对于摄像头的偏转角度是否都满足预设定位条件,是则确定完成对待定位装置的视觉定位,否则执行步骤D；步骤D、根据标签图案与摄像头之间的距离、以及标签图案相对于摄像头的偏转角度,机器人移动至预测位置点,再使用摄像头采集标签图案的图像,然后执行步骤A至步骤C。</td>   <td>1.基于标签图案的视觉定位控制方法,其特征在于,视觉定位控制方法包括：步骤A、机器人对其摄像头采集的图像进行预处理,再在预处理后的图像内搜索出标签图案的图形属性和顶点,其中,所述标签图案设置在待定位装置的表面；步骤B、基于标签图案的图形属性和顶点,利用单目测距原理计算标签图案与摄像头之间的距离、以及标签图案相对于摄像头的偏转角度；步骤C、判断标签图案与摄像头之间的距离、以及标签图案相对于摄像头的偏转角度是否都满足预设定位条件,是则确定完成对待定位装置的视觉定位,以使机器人对准或接触待定位装置中对应的标签图案,否则执行步骤D；步骤D、根据标签图案与摄像头之间的距离、以及标签图案相对于摄像头的偏转角度,机器人移动至预测位置点,再使用摄像头采集标签图案的图像,然后执行步骤A至步骤C。</td>   <td>G06T7/73;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭应林;              刘懿梅;              陈美宁;                   邓小武       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种CBCT图像的伪影去除方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN116503505A</td>   <td>2023-07-28</td>   <td>本申请属于图像处理技术领域,公开了一种CBCT图像的伪影去除方法、装置、设备及介质。通过获取包含若干种不同伪影类型的CBCT图像和配对的CT图像,将所述CBCT图像和配对的CT图像进行图像配准,得到配准后的CBCT图像和CT图像；构建一个伪影去除模型,基于量化矢量变分自编码器构建的伪影去除模型包括第一编码网络、第一解码网络、第二编码网络、第二解码网络以及特征字典；利用配准后的CBCT图像和CT图像对伪影去除模型进行训练,得到训练好的伪影去除模型；将待处理CBCT图像输入到所述训练好的伪影去除模型中,得到待处理CBCT图像的去除伪影的CT重建图像。该方法具有较高的使用范围,提高伪影去除效果。</td>   <td>1.一种CBCT图像的伪影去除方法,其特征在于,所述方法包括：获取包含若干种不同伪影类型的CBCT图像和配对的CT图像,将所述CBCT图像和配对的CT图像进行图像配准,得到配准后的CBCT图像和CT图像；构建一个伪影去除模型,所述伪影去除模型基于量化矢量变分自编码器构建,所述伪影去除模型包括第一编码网络、第一解码网络、第二编码网络、第二解码网络以及特征字典；利用所述配准后的CBCT图像和CT图像对所述伪影去除模型进行训练,得到训练好的伪影去除模型；将待处理CBCT图像输入到所述训练好的伪影去除模型中,得到所述待处理CBCT图像的去除伪影的CT重建图像。</td>   <td>G06T11/00;G06T5/00;G06T7/136;G06T7/33;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         叶志豪;              刘冶;              桂进军;              李宏浩;                   印鉴       </td>   <td>中山大学;广州赫炎大数据科技有限公司</td>   <td>一种多层次自然语言反垃圾文本方法及系统</td>   <td>广东省</td>   <td>CN109977416B</td>   <td>2023-07-25</td>   <td>本发明涉及一种多层次自然语言反垃圾文本方法及系统,通过获得待识别文本的敏感词识别结果、敏感词变形体识别结果,并结合对待识别文本进行文本分类得到其为垃圾文本的预判概率,基于对所述敏感词识别结果、敏感词变形体识别结果和预判概率进行综合评判,得出所述待识别文本为垃圾文本的最终概率。本发明能高效地识别垃圾文本,能避免垃圾文本对互联网健康交流环境的不利影响,有较高的稳健性,可广泛地适用于社交、评论等互联网产品。</td>   <td>1.一种多层次自然语言反垃圾文本方法,其特征在于,包括以下步骤：接收待识别文本；基于原始敏感词库,对所述待识别文本进行原始敏感词的匹配,识别出所述待识别文本中的原始敏感词,输出敏感词识别结果；其中,所述原始敏感词库包括原始敏感词；基于敏感词变形体库,对所述待识别文本进行敏感词变形体的匹配,并对匹配到的疑似词汇进行语义分析,验证所述疑似词汇是否属于敏感词,输出敏感词变形体识别结果；其中,所述敏感词变形体库根据所述原始敏感词库建立,所述敏感词变形体库包括所述原始敏感词对应的敏感词变形体；对所述待识别文本进行文本分类,得出所述待识别文本为垃圾文本的预判概率；对所述敏感词识别结果、敏感词变形体识别结果和预判概率进行加权计算,得出所述待识别文本为垃圾文本的最终概率；所述敏感词变形体库的建立,包括以下步骤：从所述原始敏感词库获取组成所述原始敏感词的关键字；对现有汉字与所述关键字在字音上进行比较,获取现有汉字与所述关键字的字音相似度；对现有汉字与所述关键字在字形上进行比较,获取现有汉字与所述关键字的字形相似度；根据所述字音相似度、字形相似度筛选出所述关键字的相似字；根据对应拆字的映射关系,获取所述关键字的拆字；根据所述关键字、所述关键字的相似字、拆字及其组合,得到敏感词变形体,建立敏感词变形体库。</td>   <td>G06F40/284;G06F40/30;G06F16/33;G06F16/35;G06F16/903</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘冶;              桂进军;              陈宇恒;              吕梦瑶;              杨泽锋;                   印鉴       </td>   <td>中山大学;广州赫炎大数据科技有限公司</td>   <td>一种游戏平台信息推送方法、系统、存储介质及设备</td>   <td>广东省</td>   <td>CN110222267B</td>   <td>2023-07-25</td>   <td>本发明涉及游戏平台信息推送方法、系统、存储介质及设备,通过对服务器中海量用户数据进行数据分析并建立相应的标签,可以帮助运营人员快速、精准地定位用户,全方位、多角度地掌握用户特征。相对于现有技术,本发明将通过对用户进行分群并根据已分配的用户群体进行信息推送,实现推送内容与用户需求之间的快速匹配,提高了匹配的准确性,节省了网络资源。</td>   <td>1.游戏平台信息推送方法,其特征在于,包括以下步骤：获取服务器中的用户数据；基于用户数据建立用户基础信息标签、用户消费预测标签、游戏偏好标签和流失用户标签；根据用户数据及标签对用户进行分群并根据已分配的用户群体进行信息推送；将用户基础信息标签、用户消费预测标签、游戏偏好标签和流失用户标签的标签名称作为键,标签下的用户转换为该键对应的值,将该键和值以相互对应的方式存储至数据库中；其中,该步骤具体包括：获取标签名称、最大用户标识及具有该标签的所有用户的唯一标识；将标签中所有用户的唯一标识通过位图算法转换为k位的位图数组；其中,k＝1+N/32,N为标签的用户个数；将位图数组转换为十六进制字符串,并以标签名称作为键,所述十六进制字符串作为该键对应的值,存储在数据库中；所述基于用户数据建立游戏偏好标签的步骤包括：统计用户在注册每种类型游戏前产生相关行为事件数,并以此计算获取对应类型游戏的初始喜爱度；统计用户在当前周期对每种类型游戏投入的时间以及在上一周期投入的时间,并以此计算出每种类型游戏时间的增长率；根据以下方式计算每种游戏类型的用户喜爱度：                  其中,α-i为用户游戏时间增长量的增长率,Δx为用户投入的游戏时间,T-j表示用户喜爱度的初始值,t-i-t-j表示时间间隔,M表示用户在某类游戏中的消费总额,λ为常量,表示消费额度对热度增长的比例,T-i表示用户在t-i周期对某类游戏的喜爱度；根据用户对周期内各游戏类型的喜爱度进行排序,根据喜爱度数值确定用户偏好的游戏类型。</td>   <td>G06F16/9535;G06F16/958;A63F13/79</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              李亮;              郭斌;              刘力;                   徐琰       </td>   <td>中山大学</td>   <td>一种医学图像预处理方法</td>   <td>广东省</td>   <td>CN110246567B</td>   <td>2023-07-25</td>   <td>本发明公开了一种医学图像预处理方法,包括以下步骤：标签信息语义图像化：预读取数字医学图像及其标签信息,应用判别算法将带格式的文本标签信息转换为多层次分类掩膜图像；兴趣区域提取：读取数字医学图像,移除透明度通道获取图像,提取当前切片图像中的组织区域轮廓,将图像划分为组织区域和背景区域；多掩膜样本分类提取：利用所生成的多层次分类掩膜,在所述组织区域中提取阳性样本和阴性样本,并将样本数据信息进行封装,形成可应用于神经网络模型训练和预测的结构化数据。通过本技术方案,可以实现更加高效以及更加精准的数据预处理。</td>   <td>1.一种医学图像预处理方法,其特征在于,包括以下步骤：标签信息语义图像化：预读取数字医学图像及其标签信息,应用判别算法将带格式的文本标签信息转换为多层次分类掩膜图像；其中,所述多层次分类掩膜图像包括标记掩膜和剔除掩膜；兴趣区域提取：读取数字医学图像,移除透明度通道获取图像,提取当前切片图像中的组织区域轮廓,将图像划分为组织区域和背景区域,以组织区域的外接限位框作为所述数字医学图像的兴趣识别区域；多掩膜样本分类提取：所述标记掩膜与所述剔除掩膜相减的结果作为病变区识别掩膜,利用滑窗扫描所述兴趣识别区域的限位框时,先根据组织区域识别掩膜去除所述背景区域及剔除掩膜所确定的剔除区域,然后根据病变区识别掩膜将组织区域划分为阳性和阴性,分别提取阳性样本和阴性样本,并将样本数据信息进行封装,形成应用于神经网络模型训练和预测的结构化数据。</td>   <td>G16H30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              陈凯鹏;                   王国倩       </td>   <td>中山大学</td>   <td>改进的低频UWB SAR叶簇隐蔽目标融合变化检测方法</td>   <td>广东省</td>   <td>CN113159157B</td>   <td>2023-07-25</td>   <td>本发明提供一种改进的低频UWB SAR叶簇隐蔽目标融合变化检测方法,该方法首先对检测图像和参考图像进行预处理,进行双方向的相对辐射校正处理；其次,求解基于改进杂波分布模型的图像分割差值法的检验量图像和检测阈值；将检测图像和参考图像相减得到差值检验量图像,并对差值检验量图像的杂波分布进行估计,设定虚警概率后得到检测阈值,即得到第一个子算法的检验量图像和检测阈值；然后,求解一维Edgeworth法以及广义Laguerre多项式法的检验量图像和检测阈值；最后,将三个检验量图像以及对应阈值输入到LE-SVDD空间中进行分类器的设计,从而实现低频UWB SAR图像的变化检测。</td>   <td>1.一种改进的低频UWB SAR叶簇隐蔽目标融合变化检测方法,其特征在于,包括以下步骤：S1：对检测图像和参考图像进行预处理；S2：求出基于改进杂波分布模型的图像分割差值法的检验量图像和检测阈值；基于改进杂波分布模型的图像分割差值法是一种像素级的变化检测方法,通过对不同时相的图像的同一点进行相减得到差值检验量图像,然后对差值检验量图像进行分割,并对分割后的图像非目标区域的概率密度分布进行估计,并设定一定的虚警概率值,在概率密度分布中得到对应的检测阈值,大于该检测阈值,则视为变化检测点,由此得到第一个子算法的检验量图像和检测阈值；S3：求出一维Edgeworth法和广义Laguerre多项式法的检验量图像和检测阈值；一维Edgeworth法中,先以观测区域的每一个像素点为中心,基于Edgeworth展开式对其邻域内的像素灰度值概率密度函数进行基于高斯概率密度分布模型的估计,在此基础上基于K-L散度理论对多时相图像间各点的概率密度函数差异大小进行分析,从而得到关于概率密度差异的检验量图像；广义Laguerre多项式法则以广义Laguerre多项式为基础,对其邻域内的像素灰度值概率密度函数进行基于伽马概率密度分布模型的估计,再通过K-L散度得到检验量图像；然后,对检验量图像进行图像灰度值统计,发现统计量的曲线在左侧出现骤降的趋势,采用骤降曲线中的拐点作为检验阈值；在检测时采用最小二乘法对密度曲线进行拟合,并取拟合曲线中竖轴等于0的横轴值近似为检测阈值,得到两个子算法的检验量图像和检测阈值；S4：将三个检验量图像和检测阈值都输入到LE-SVDD分类器中进行训练,并对测试样本进行目标与非目标判别,即为最终变化检测结果；SVDD分类器首先将变化区域和无变化区域的变化区域检测量记为目标类样本和外点样本,而后利用预先提取的目标类样本构成的训练样本集对SVDD进行训练,以期在核特征空间构建一个包含所有训练样本的最小超球体,并以此超球体为基础对观测场景中的变化检测量进行分类；LE-SVDD在SVDD的基础上,设定三个子算法检验量图像中一点都大于对应检验量图像的检测阈值和标准差为训练样本,三个子算法中存在一个或两个检验量图像对应点大于检测阈值和标准差为测试类样本,将训练样本输入到LE-SVDD分类器中进行训练,并对测试样本进行目标与非目标判别,即为最终变化检测结果。</td>   <td>G06V10/80;G06V10/26;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   祝恺蔓       </td>   <td>中山大学</td>   <td>基于关键帧人脸特征的人脸交换篡改视频检测方法、系统及介质</td>   <td>广东省</td>   <td>CN113469062B</td>   <td>2023-07-25</td>   <td>本发明公开了一种基于关键帧人脸特征的人脸交换篡改视频检测方法、系统及介质,方法包括：将视频数据集划分为训练集和测试集,对每个视频流提取一定的关键帧；对关键帧进行人脸定位,提取保留脸部边缘背景的人脸区域图像；再次检测与定位,获取紧密人脸区域图像；输入到神经网络模型中获取人脸图像的特征表示；使用训练集视频的多个关键帧上的人脸图像特征表示对长短期记忆网络和线性判别器进行训练；将测试集视频的多个关键帧上的人脸图像特征表示作为一组输入,输入到长短期记忆网络中,将最后一个图像对应的输出经过线性判别器,得到检测结果。本发明提供了与设备中现存人脸识别模块接入的可能性,检测用时短,对硬件要求低,可实时高效检测。</td>   <td>1.基于关键帧人脸特征的人脸交换篡改视频检测方法,其特征在于,包括下述步骤：将视频数据集划分为训练集和测试集,对每个视频流提取设定数量的关键帧；对提取的关键帧进行人脸定位,提取所有人脸区域图像并保留脸部边缘背景；对保留脸部边缘背景的人脸区域图像再次检测与定位,获取紧密人脸区域图像；将紧密人脸区域图像输入到人脸识别任务中训练好的神经网络中,获取人脸图像特征表示；将训练集视频的多个关键帧上的人脸图像特征表示作为一组输入,对长短期记忆网络和线性判别器进行训练,具体为：使用三层叠加的前向长短期记忆网络LSTM对特征进行聚合,其每一层的结构中包括一个输入门i-t、一个遗忘门f-t、一个记忆门g-t、一个输出门o-t,对输入序列中的每个成员计算隐藏状态h-t,记忆单元c-t,计算公式如下：i-t＝σ(w-(ii)x-t+b-(ii)+w-(hi)h-(t-1)+b-(hi))f-t＝σ(w-(if)x-t+b-(if)+w-(hf)h-(t-1)+b-(hf))o-t＝σ(w-(io)x-t+b-(io)+w-(ho)h-(t-1)+b-(ho))其中σ表示非线性激活函数sigmoid；x-t表示第t帧的人脸特征向量,w-(ii)、w-(if)、w-(io)分别表示输入门、遗忘门、输出门对x-t进行线性变换的权重矩阵,b-(ii)、b-(if)、b-(io)分别表示三个线性变换的偏置；h-(t-1)表示第t-1帧人脸特征向量经过LSTM计算后得到的隐藏向量,w-(hi)、w-(hf)、w-(ho)分别表示输入门、遗忘门、输出门对h-(t-1)进行线性变换的权重矩阵,b-(hi)、b-(hf)、b-(ho)分别表示三个线性变换的偏置；三个门控单元在计算的时候结合每个时刻的人脸特征上一时刻的隐藏状态,上一时刻的隐藏状态在初始化的时候设为全零向量；g-t＝Tanh(w-(ig)x-t+b-(ig)+w-(hg)h-(t-1)+b-(hg))c-t＝f-t⊙c-(t-1)+i-t⊙g-th-t＝o-t⊙tanh(c-t)其中,⊙表示哈达玛积,即两个向量中相同对应位置的元素进行相乘；w-(ig)、b-(ig)表示记忆门对x-t进行线性变换的权重矩阵和偏置,w-(hg)、b-(hg)表示记忆门对h-(t-1)进行线性变换的权重矩阵和偏置；c-(t-1)表示第t-1帧经过相同计算得到的保留信息向量；tanh()表示双曲正切激活函数；所述记忆单元c-t通过有选择性地使用当前人脸特征结合上一时刻的隐藏向量经过非线性激活函数的计算特征与上一时刻的记忆单元信息,保持长期的记忆功能；输出的隐藏状态h-t在记忆单元c-t的基础上经过进一步的非线性变换获得,输入给下一层的LSTM；获取最后一层LSTM的最后一个人脸特征对应的输出隐藏向量,先使用线性层映射到128维度,经过ReLU非线性激活函数后,再将其映射到2维的分类空间,并使用softmax进行归一化求得两个概率值；在训练集上,通过最小化交叉熵损失函数在训练集上对长短期记忆网络和线性判别器进行反向传播更新参数,对于一个样本的具体计算公式为：                  其中,L表示损失函数,y表示该人脸视频的真实标签,表示对应计算得到的概率值；将测试集视频的多个关键帧上的人脸图像特征表示作为一组输入,输入到长短期记忆网络中,将最后一个图像对应的输出经过线性判别器,得到检测结果并评估检测性能。</td>   <td>G06V40/16;G06V20/40;G06V10/25;G06V10/774;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘镇;              兰春晖;                   周翠英       </td>   <td>中山大学</td>   <td>基于地表图像的三维地质体模型的建模方法和相关装置</td>   <td>广东省</td>   <td>CN116486030A</td>   <td>2023-07-25</td>   <td>本发明实施例公开了一种基于地表图像的三维地质体模型的建模方法和相关装置。其中,方法包括：构建二维图像数据集；通过二维编码器,基于尺度不变特征转换算法,使用高斯金字塔对图像各个尺度的特征进行提取,得到二维特征；利用投影思路实现二维特征到三维的特征转换,并构建为三维特征供建模使用；基于通过转换而建立的三维特征,构建三维转码器,对三维顶点特征矩阵进行卷积计算,预测每个特征矩阵顶点的新位置和新三维特征；结合稀疏钻孔数据,运用隐式建模法建立地质体栅格单元,建立栅格单元与特征矩阵顶点位置及新三维特征之间的关联,得到目标三维地质体模型。可解决因相关钻孔或地质数据不足而造成的建模困难,提高地质模型精度。</td>   <td>1.一种基于地表图像的三维地质体模型的建模方法,其特征在于,包括：步骤1、将二维地表图像数据,通过生成对抗网络训练获得伪二维地表图像,构建二维图像数据集；步骤2、通过二维编码器,基于尺度不变特征转换算法,使用高斯金字塔对图像各个尺度的特征进行提取,得到二维特征；步骤3、利用投影思路实现二维特征到三维的特征转换,运用循环神经网络对提取的图像特征进行保留、整合,构建为三维特征供建模使用；步骤4、基于通过转换而建立的三维特征,构建三维转码器,对三维顶点特征矩阵进行卷积计算,预测每个特征矩阵顶点的新位置和新三维特征；步骤5、结合稀疏钻孔数据,运用隐式建模法建立地质体栅格单元,建立栅格单元与特征矩阵顶点位置及新三维特征之间的关联,得到目标三维地质体模型。</td>   <td>G06T17/05;G06N3/0464;G06N3/0475;G06N3/094;G06N3/044;G06V10/40;G06V10/46;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄方军;              万晨;              陈思;                   万丽       </td>   <td>中山大学;郑州信大先进技术研究院</td>   <td>一种针对深度神经网络图像分类器的对抗攻击方法</td>   <td>广东省</td>   <td>CN116486136A</td>   <td>2023-07-25</td>   <td>本发明公开了一种针对深度神经网络图像分类器的对抗攻击方法,该方法包括：通过深度神经网络分类器模型的损失函数对输入样本进行梯度计算,构建平均梯度；基于平均梯度对输入样本进行添加扰动处理,生成对抗样本；基于生成样本对深度神经网络分类器模型进行循环迭代训练,直至满足预设迭代次数,得到训练后的深度神经网络分类器模型。通过使用本发明,能够实现更高的攻击成功率与降低模型分类的准确率进一步提升深度神经网络分类器的鲁棒性。本发明作为一种针对深度神经网络图像分类器的对抗攻击方法,可广泛应用于深度神经网络应用技术领域。</td>   <td>1.一种针对深度神经网络图像分类器的对抗攻击方法,其特征在于,包括以下步骤：通过深度神经网络分类器模型的损失函数对输入样本进行梯度计算,构建平均梯度；基于平均梯度对输入样本进行添加扰动处理,生成对抗样本；基于生成样本对深度神经网络分类器模型进行循环迭代训练,直至满足预设迭代次数,得到训练后的深度神经网络分类器模型。</td>   <td>G06V10/764;G06V10/82;G06N3/0475;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王志斌;              陈嘉宏;                   陈坚       </td>   <td>中山大学</td>   <td>一种计算磁约束等离子体湍流特性的方法、系统、设备和存储介质</td>   <td>广东省</td>   <td>CN116484586A</td>   <td>2023-07-25</td>   <td>本发明公开了一种计算磁约束等离子体湍流特性的方法、系统、设备和存储介质,包括步骤如下：S1：设置模拟初值条件；S2：判断当前时间步数n是否小于时间步数N,若否,进入步骤S3；若是,进入步骤S6；S3：根据空间电磁场分布,对网格内的粒子运动进行计算,获得等离子体在各网格内的扩散系数；S4：步骤S3根据得到的扩散系数迭代求解磁流体方程组；S5：更新网格信息,n＝n+1,保存扩散系数、求解磁流体方程组的计算结果,返回步骤S2；S6：输出扩散系数、求解磁流体方程组的计算结果。本发明通过扩散系数与磁流体方程组相结合,在磁流体模型下更准确地计算湍流的效应。本发明能够在保持较高计算精度的同时有效地提升磁约束等离子体湍流的计算效率。</td>   <td>1.一种计算磁约束等离子体湍流特性的方法,其特征在于：所述的方法包括步骤如下：S1：设置模拟初值条件,包括模拟空间的尺寸、模拟空间的形状、时间步数N、时间步长、等离子体参数、初始条件、边界条件、网格尺寸；S2：判断当前时间步数n是否小于时间步数N,若否,进入步骤S3；若是,进入步骤S6；S3：根据空间电磁场分布,对网格内的粒子运动进行计算,获得等离子体在各网格内的扩散系数；S4：根据步骤S3得到的扩散系数迭代求解磁流体方程组；S5：更新网格信息,n＝n+1,保存扩散系数、求解磁流体方程组的计算结果,返回步骤S2；S6：输出扩散系数、求解磁流体方程组的计算结果。</td>   <td>G06F30/20;G06F111/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈娟;              刘智勇;              陈晓宏;              林凯荣;                   涂新军       </td>   <td>中山大学</td>   <td>一种模拟树干瞬态液流变化的方法及系统</td>   <td>广东省</td>   <td>CN116484624A</td>   <td>2023-07-25</td>   <td>本发明公开了一种模拟树干瞬态液流变化的方法及系统,该方法包括：根据太阳辐射与树干液流的变化关系,得到树干瞬态液流变化原始模型；考虑复杂环境因素,根据树干瞬态液流变化原始模型构建树干瞬态液流变化模型；求解树干瞬态液流变化模型,得到树干液流速率。本技术方案将随日照辐射增加时气孔部分关闭以及辐射降低时液流的滞后性这一因素考虑在内,重新构建了瞬态树干液流变化模型,通过解模型得到树干液流速率的变化率,进而可以通过曲线模拟进行任意时刻液流变化速率的预测。</td>   <td>1.一种模拟树干瞬态液流变化的方法,其特征在于,包括以下步骤：根据太阳辐射与树干液流的变化关系,得到树干瞬态液流变化原始模型；考虑复杂环境因素,根据树干瞬态液流变化原始模型构建树干瞬态液流变化模型；求解树干瞬态液流变化模型,得到树干液流速率。</td>   <td>G06F30/20;G06F18/214;G06Q10/04;G06F113/08;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高智凡;              刘毅;              薛晓飞;              谢佰洪;              张贺晔;                   刘修建       </td>   <td>中山大学</td>   <td>一种模型训练方法、血流储备分数计算方法、装置及设备</td>   <td>广东省</td>   <td>CN116486211A</td>   <td>2023-07-25</td>   <td>本申请提供了一种模型训练方法、血流储备分数计算方法、装置及设备。训练方法包括获取样本冠状动脉的样本断层扫描图像、测量压力场和测量血流速度；其中,测量血流速度包括在样本稀疏点处的样本稀疏点速度；依据样本断层扫描图像,确定样本冠状动脉的样本中心线图像；依据由样本中心线图像和样本稀疏点速度构成的样本数据,由测量压力场和测量血流速度构成的标签数据,以及预设的模型损失函数对初始冠状动脉血流模型进行训练,获得训练完成的冠状动脉血流模型。本申请直接在单一影像基础上进行计算,极大地简化了计算过程,缩短了计算耗时；并且,结合了深度学习方法,可以有效地融合各类保真数据,极大地提高了计算结果的准确性。</td>   <td>1.一种冠状动脉血流模型的训练方法,其特征在于,包括：获取样本冠状动脉的样本断层扫描图像、测量压力场和测量血流速度；其中,所述测量血流速度包括在样本稀疏点处的样本稀疏点速度；依据所述样本断层扫描图像,确定所述样本冠状动脉的样本中心线图像；依据由所述样本中心线图像和所述样本稀疏点速度构成的样本数据,由所述测量压力场和所述测量血流速度构成的标签数据,以及预设的模型损失函数对初始冠状动脉血流模型进行训练,获得训练完成的冠状动脉血流模型。</td>   <td>G06V10/774;A61B6/00;G06V10/82;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈一平;              张吴明;              张帅;                   朱厦       </td>   <td>中山大学</td>   <td>一种树木点云木质成分与叶片成分的分离方法及系统</td>   <td>广东省</td>   <td>CN116486261A</td>   <td>2023-07-25</td>   <td>本发明涉及树木点云枝叶分离技术,为树木点云木质成分与叶片成分的分离方法及系统,其方法包括步骤：计算原始点云的形态检测参数特征,包括确定针对形态检测参数的自适应邻域半径；计算原始点云的法向量变化量特征,包括确定针对法向量变化量的自适应邻域半径；将单木点云坐标与形态检测参数特征、法向量变化量特征相结合,把结合后的特征向量输入到深度学习网络进行训练；将深度学习网络得到的概率输出还原到点云标签,得到分类好的单木点云。本发明能将单木点云木质成分与叶片成分自动分离,适用于多个树种,且仅需要单木点云的坐标信息,能够适用于全波段的激光雷达,极大提高了树木点云枝叶分离的自动化程度。</td>   <td>1.一种树木点云木质成分与叶片成分的分离方法,其特征在于,包括以下步骤：S1、计算原始点云的形态检测参数特征,包括确定针对形态检测参数的自适应邻域半径r-(MDC)；S2、计算原始点云的法向量变化量特征,包括确定针对法向量变化量的自适应邻域半径r-(NDO)；S3、将单木点云坐标与形态检测参数特征、法向量变化量特征相结合,把结合后的特征向量输入到深度学习网络进行训练；S4、将深度学习网络得到的概率输出还原到点云标签,得到分类好的单木点云。</td>   <td>G06V20/10;G06V20/64;G06V10/80;G06V10/82;G06N3/045;G06N3/0464;G06N3/0495</td>  </tr>        <tr>   <td>中国专利</td>   <td>         裴杰;              刘鹏宇;                   方华军       </td>   <td>中山大学;中科吉安生态环境研究院</td>   <td>一种臭氧污染对作物减产风险评估方法和装置</td>   <td>广东省</td>   <td>CN116485174A</td>   <td>2023-07-25</td>   <td>本发明公开了一种臭氧污染对作物减产风险评估方法和装置,方法包括：获取第一区域的环境数据,生成第一模型指标数值；将第一区域划分为若干个第一子区域,生成每个第一子区域对应的第二模型指标数值；将所有第一子区域的中心地理位置坐标、第二模型指标数值和在第一时间范围的农作物单位面积产量输入到时空地理加权回归模型,生成回归系数；根据回归系数和单位面积产量,生成当前第一子区域的臭氧污染响应敏感值和农作物产量；根据农作物产量和无臭氧污染条件下的农作物产量,生成每个第一子区域在第一时间范围内的臭氧污染对农作物的减产结果,在区域臭氧减产风险评估模型中纳入时间与空间特征,提高区域臭氧减产风险评估模型的评估精度。</td>   <td>1.一种臭氧污染对作物减产风险评估方法,其特征在于,包括：获取第一区域在第一时间范围内的环境数据,生成若干个第一模型指标数值；将所述第一区域划分为若干个第一子区域,将所述第一模型指标数值进行计算处理,生成每个所述第一子区域对应的第二模型指标数值；将所有第一子区域的中心地理位置坐标、第二模型指标数值和在第一时间范围的农作物单位面积产量输入到时空地理加权回归模型,生成每个第一子区域的农作物产量与第二模型指标数值之间的回归系数；根据每个第一子区域的第一回归系数和所述农作物单位面积产量,生成当前第一子区域的农作物在第一时间范围内对于近地面臭氧污染的响应敏感值和第一农作物产量；所述第一回归系数为农作物产量与臭氧指标数值之间的回归系数；根据所述第一农作物产量和对应无臭氧污染条件下的第二农作物产量,生成每个第一子区域在第一时间范围内的臭氧污染对农作物的减产结果。</td>   <td>G06Q10/0635;G06Q10/0639;G06F16/29;G06F16/26;G06F16/2458;G06F17/16;G06F17/11;G06Q50/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚正安;              连祥凯;              潘嵘;              李嘉;              郭梓濠;              董喆;              刘念祖;              兰丽菊;                   李锐晨       </td>   <td>中山大学</td>   <td>一种用于裂缝检测的自适应canny方法</td>   <td>广东省</td>   <td>CN116485719A</td>   <td>2023-07-25</td>   <td>本发明公开一种用于裂缝检测的自适应canny方法,解决隧道墙体裂缝检测时遇到的噪点多,脏块多和检测效果不稳定的问题。该算法先通过对灰度图进行光照补偿的方法实现图像暗部亮度的有效提升；为去除图像中部分孤立亮点噪声的影响,对图片进行中值滤波处理,确保图像在保留裂缝的边缘特性的同时,降低脉冲式噪声；本发明通过最大化梯度幅值类间方差的方法寻找此阈值,并以此为基础通过Canny算子进行边缘检测；最后结合闭运算和连通性自动检测并去除图像中的噪声和脏块,得到较为干净的裂缝检测结果。本发明可广泛应用于隧道裂缝等病害检测问题。</td>   <td>1.一种用于裂缝检测的自适应canny方法,其特征在于,包括以下步骤：S1：获取包括裂缝的图像；S2：根据所述图像的尺寸进行光照补偿,得到亮度均匀的图像；S3：对所述亮度均匀的图像进行中值滤波,得到降噪图像；S4：计算所述降噪图像的梯度幅值,通过最大化梯度幅值类间方差的方法自动生成最佳分割阈值th；S5：根据所述最佳分割阈值th,得到Canny边缘检测算法的最低阈值和最高阈值,并使用该最低阈值和最高阈值进行边缘检测,获得第一图像；S6：对所述第一图像利用八连通域搜索计算连通部件,去除面积小于预设最小值的连通部件,获得第二图像；S7：对所述第二图像使用闭运算方法将断开的裂缝拼接起来,填充脏块的孔洞,得到第三图像；S8：对所述第三图像使用八连通域搜索计算连通部件,若连通部件的长乘宽面积大于原图面积的第一预设值且实际面积大于原图面积的第二预设值,则去除该连通部件,得到最后的裂缝图像。</td>   <td>G06T7/00;G06T7/136;G06T7/13;G06T7/187;G06T7/90;G06T5/00;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蒋弥;              张瑞宇;                   李刚       </td>   <td>中山大学</td>   <td>一种基于多源遥感数据的高时间分辨率冰川厚度反演方法</td>   <td>广东省</td>   <td>CN116485857A</td>   <td>2023-07-25</td>   <td>本发明公开了一种基于多源遥感数据的高时间分辨率冰川厚度反演方法,如下：融合第三SAR影像对、光学影像对的各方向偏移量、与冰川三维流速矢量建立冰川表面三维流速方程；求解冰川表面三维流速方程,通过引入L1范数最小法来探测粗差并确定第一次平差的残差值；对残差值进行赋权得到权值；结合权值利用最小二乘准则得到三维流速的最佳估计值；三维流速的最佳估计值包括东西向、南北和垂直向；将由垂直向位移量求取的垂直速率分解为表面平行流和非表面平行流分量；结合东西向位移量、南北向位移量计算得到的水平速度矢量,与某一高度空间分辨率DEM数据进行高斯平滑滤波得到的表面坡度,计算表面平行流和非表面平行流分量。</td>   <td>1.一种基于多源遥感数据的高时间分辨率冰川厚度反演方法,其特征在于：所述的方法包括步骤如下：融合第三SAR影像对、光学影像对的各方向偏移量、与冰川三维流速矢量建立冰川表面三维流速方程；所述的第三SAR影像与光学影像对的偏移量结果分辨率一致；求解冰川表面三维流速方程,具体通过引入L1范数最小法来探测粗差并确定第一次平差的残差值V；对得到的残差值V进行赋权得到权值P；结合权值P并利用最小二乘准则得到三维地表形变的最佳估计值；所述的三维地表形变的最佳估计值包括东西向位移量、南北向位移量、垂直向位移量；将由垂直向位移量求取的垂直速率分解为由沿着冰川表面斜坡运动引起的表面平行流和由于冰川表面高程变化引起的非表面平行流分量；结合东西向位移量、南北向位移量计算得到的水平速度矢量,与某一高度空间分辨率DEM数据进行高斯平滑滤波得到的表面坡度,计算表面平行流和非表面平行流分量。</td>   <td>G06T7/33;G01S13/86;G01S13/90;G01B21/08;G06T17/05;G06T5/20;G06T5/50;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;                   林会智       </td>   <td>中山大学</td>   <td>一种基于格的分布式重线性化公钥生成方法</td>   <td>广东省</td>   <td>CN112906020B</td>   <td>2023-07-21</td>   <td>本发明涉及基于全同态加密的安全多方计算技术领域,更具体地,涉及一种基于格的分布式重线性化公钥生成方法。在BFV提出的基于格的公私钥生成方法的基础上,提出了重线性化公钥生成初始化算法、重线性化公钥份额生成算法、重线性化公钥生成算法；首先基于解析多项式完成了用户私钥的分享,并通过数论变换完成用户关于重线性化公钥份额的计算。在最后要提交用户个人的重线性化公钥份额之前,利用两个相加后可抵消的噪声来保护用户份额,防止敌手收集重线性化公钥份额时,可以通过解析份额来获得私钥。本方法利用了更少的噪声,达到了安全的效果。</td>   <td>1.一种基于格的分布式重线性化公钥生成方法,其特征在于,包括以下步骤：S1.系统初始化：设置格密码体体制和重线性化公钥生成过程的初始参数；S2.用户密钥生成：通过混合加密体制生成用户个人的公私钥对；S3.重线性化公钥生成初始化：通过拆分私钥多项式的方式完成用户个人私钥份额的生成并分享；所述的重线性化公钥生成初始化具体包括：S31.输入系统参数params、用户u的私钥sk-(u0)和用户集合U中的公钥集合{pk-(v1)}-(v∈U),首先把最高次为d的私钥多项式sk-(u0)拆分成两个最高次为的子私钥多项式ask-(u0)和bsk-(u0),满足/&gt;设多项式中的自变量为x,此时ask-(u0)和bsk-(u0)的非0系数项最高次都为/&gt;最后/&gt;项的系数都为0；然后利用数论变换算法中的NTT.ToNtt()算法,分别输入系数表示法的多项式ask-(u0)和bsk-(u0),输出点值表示法的多项式nnask-(u0),nnbsk-(u0),此时nnask-(u0)和nnbsk-(u0)分别都有d+1项,最高次都为d；S32.将子私钥nnask-(u0)、nnbsk-(u0)按照用户的有序集合U分别拆分为m个子私钥份额,具体从多项式nnask-(u0)的第1项开始,将每项取出为1个份额,按顺序分配给有序集合U中的每一个用户,即分配为第1号用户的子私钥份额nnSa-(u1)为nnask-(u0)的前/&gt;项,以此类推,第m号用户的子私钥份额nnSa-(um)为nnask-(u0)的最后/&gt;项；同理,对子私钥nnbsk-(u0)的份额拆分与子私钥nnask-(u0)的拆分方式一样,最后满足/&gt;S33.将发送给用户v的份额打包为nnS-(uv)＝{nnSa-(uv),nnSb-(uv)}-(v∈U),同时利用用户v的公钥pk-(v1),运行混合加密体制的加密算法HPKE.Enc(pk-(v1),nnS-(uv))加密获得加密的秘密份额nnES-(uv)；输出为用户u分发给集合U中所有用户的加密份额集合{nnES-(uv)}-(v∈U),集合中一共有m个元素；S4.重线性化公钥份额生成：当用户收集完其他所有用户发送的私钥份额后,通过数论变换完成用户关于重线性化公钥份额的计算；在提交用户个人的重线性化公钥份额之前,利用两个相加后可抵消的噪声来保护用户份额；S5.重线性化公钥生成：服务器汇总各用户的重线性化公钥份额,合成并公开重线性化公钥。</td>   <td>G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         方译权;              文永明;                   成慧       </td>   <td>中山大学</td>   <td>一种物体6D位姿估计方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN112562001B</td>   <td>2023-07-21</td>   <td>本发明公开了一种物体6D位姿估计方法、装置、设备及介质,方法包括：对包含目标物体的RGB图像和深度图进行特征提取,得到颜色特征和几何特征；对目标物体的模型信息进行特征提取,得到模型的颜色特征和几何特征；将每个特征点的颜色特征和几何特征进行关联,得到场景的几何特征和模型的几何特征；根据场景的几何特征和模型的几何特征,确定相关图,并确定注意力响应图；根据颜色特征、几何特征、场景的几何特征和模型的几何特征,构建第一融合特征和第二融合特征；进而构建得到总体特征；根据总体特征,通过位姿估计网络确定目标物体的6D位姿。本发明提高了实时性和鲁棒性,可广泛应用于机器人环境感知技术领域。</td>   <td>1.一种物体6D位姿估计方法,其特征在于,包括：对包含目标物体的RGB图像和深度图进行特征提取,得到不同特征点的颜色特征和几何特征；对所述目标物体的模型信息进行特征提取,得到不同特征点的模型的颜色特征和模型的几何特征；将每个所述特征点的颜色特征和几何特征进行关联,得到场景的几何特征和模型的几何特征；根据所述场景的几何特征和所述模型的几何特征,确定所述目标物体的相关图；根据所述相关图确定注意力响应图；根据所述颜色特征、所述几何特征和所述场景的几何特征,构建第一融合特征；所述第一融合特征包含所述场景中的颜色信息和深度信息；根据所述颜色特征、所述几何特征和所述模型的几何特征,构建第二融合特征；所述第二融合特征包含所述模型中的颜色信息和深度信息；根据所述第一融合特征和所述第二融合特征,构建得到总体特征；根据所述总体特征,通过位姿估计网络确定所述目标物体的6D位姿；所述根据所述相关图确定注意力响应图,包括：将softmax函数应用于所述相关图的每一列来计算得到所述注意力响应图；其中,所述注意力响应图的计算公式为：                  其中,A中的每一列代表概率密度；A-(ij)表示物体模型中的第i个几何特征与场景信息中的第j个几何特征之间的相似度；E-(k,j)代表所述目标物体的相关图；所述根据所述相关图确定注意力响应图之后,还包括：将颜色特征确定为显式软约束；根据所述显式软约束,通过所述注意力响应图维持颜色特征与几何特征之间的注意力一致性；其中,所述注意力一致性的数学表达式为：                  其中,H-j代表重构的场景的颜色特征；A-(ij)物体模型中的第i个几何特征与场景信息中的第j个几何特征之间的相似度；φ-m(C-m)代表模型的颜色特征。</td>   <td>G06T7/73;G06V10/44;G06V10/80;G06V10/764;G06V10/74;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;                   苏志荣       </td>   <td>中山大学</td>   <td>一种基于顶视角的行人三维检测跟踪方法及系统</td>   <td>广东省</td>   <td>CN112767442B</td>   <td>2023-07-21</td>   <td>本发明公开了一种基于顶视角的行人三维检测跟踪方法及系统,该方法包括：对双目相机获取到的左右图像进行立体校正和立体匹配处理；空洞填充并转换得到高度图；对高度图进行建模处理得到二维高度前景图；投影并转换为顶视角下的二维平面点云投影图,检测得到行人头部三维坐标点；将行人头部三维坐标点映射回二维图像坐标系中,并定位出每个行人的边界框；结合行人头部三维坐标点和定位出的行人边界框,进行帧间行人匹配跟踪。通过使用本发明,能够有效克服行人间遮挡导致漏检的问题,提高行人检测召回率。本发明作为一种基于顶视角的行人三维检测跟踪方法及系统,可广泛应用于行人检测领域。</td>   <td>1.一种基于顶视角的行人三维检测跟踪方法,其特征在于,包括以下步骤：对双目相机获取到的左右图像进行立体校正和立体匹配处理,得到深度图；对深度图进行空洞填充,并转换得到高度图；基于MOG2背景建模方法对高度图进行建模处理,得到二维高度前景图；将二维高度前景图投影到三维高度前景点云图中并转换为顶视角下的二维平面点云投影图,检测得到行人头部三维坐标点；将行人头部三维坐标点映射回二维图像坐标系中,并结合该头部三维坐标点在二维图像中定位出每个行人的边界框；结合行人头部三维坐标点和定位出的行人边界框,利用行人中心点的帧间距离以及边界框中的颜色直方图特征进行帧间行人匹配跟踪；透视变换矩阵Q表达式如下：                  上式中,c-x和c-y分别表示双目相机左右镜头的主点坐标,f是归一化后的焦距,T是左右镜头光心间的基线距离；所述将二维高度前景图投影到三维高度前景点云图中并转换为顶视角下的二维平面点云投影图,检测得到行人头部三维坐标点这一步骤,其具体包括：基于透视变换矩阵将二维高度前景图投影出三维高度前景点云图,并建立二维像素坐标点与三维物理世界坐标点的映射关系表；将三维高度前景点云图转换为顶视角下的二维平面点云投影图并基于顶视角下的二维平面点云投影图进行行人头部的检测和定位,得到行人头部三维坐标点；所述将行人头部三维坐标点映射回二维图像坐标系中,并结合该头部三维坐标点在二维图像中定位出每个行人的边界框这一步骤,其具体包括：遍历全图,对每个像素点P,通过透视变换矩阵Q计算得到其三维物理世界坐标点W；假设已在顶视角二维点云投影图中定位到行人头部点集S＝{H-1,H-2,..,H-k},其中H-1,H-2,..,H-k表示k个行人头部的三维坐标；计算物理点W与每个头部三维点H-i(i∈[1,k])间的x轴和y轴组成的平面方向的距离,并对于所得距离小于设定距离阈值的点W,标记其二维像素点P属于第i个行人的边界框内,得到每个行人边界框像素点集；计算每个行人边界框像素点集的最小面积外接矩形,得到每个行人的边界框。</td>   <td>G06T7/246;G06T7/13;G06T7/194;G06T7/73;G06T7/80;G06V40/10;G06V10/50;G06V10/56</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              吴捷;                   陈宇洋       </td>   <td>中山大学</td>   <td>一种视频异常事件检测方法</td>   <td>广东省</td>   <td>CN112016403B</td>   <td>2023-07-21</td>   <td>本发明公开了一种视频异常事件检测方法,使用了管道-时间双支结构,在不同的粒度上反映了视频中的信息,一个分支可以把学习到的知识分享给另外一个分支,充当额外的监督作用,鼓励另外一个分支从不同的粒度学习异常事件的特征；从而减轻对人力资源依赖,提高检测效率,同时在只有时序标签的数据集上,利用不同粒度的信息,检测出视频中异常事件发生的事件和区域,并且探索区域之间的关系,提升准确率。</td>   <td>1.一种视频异常事件检测方法,其特征在于,包括：获取视频源文件,分别对所述视频源文件进行管道级别实例抽取和视频级别实例抽取,得到管道级别实例和视频级别实例；分别对所述管道级别实例和视频级别实例进行特征提取,得到管道级别特征和视频级别特征；分别将所述管道级别特征和视频级别特征输入至各自对应的关系建模中进行特征处理,得到管道高级特征和视频高级特征；分别将所述管道高级特征和视频高级特征输入至各自对应的全连接神经网络进行异常预测,得到管道预测数值和视频预测数值；根据所述管道预测数值和视频预测数值计算得到异常事件预测分数；所述对所述视频源文件进行管道级别实例抽取的步骤具体为：将所述视频源文件输入到深度学习模型中,输出得到每一帧中物体的区域；对所有区域中自信心最大的区域进行提取,并在自信心最大的所在区域的同一帧的其他区域中提取出IoU值大于预设阈值的区域,将所述IoU值大于预设阈值的区域合并入已提取的区域组成更大的区域；在当前帧的所有区域合并完毕之后,选择下一帧的扩展分数最高的区域并入此区域所属的管道,直至所述视频源文件中的所有帧处理完成；所述扩展分数定义为：；其中,表示区域,/&gt;为区域/&gt;的自信心,/&gt;为区域/&gt;和/&gt;的IoU分数；所述对所述视频源文件进行视频级别实例抽取的步骤具体为：将所述视频源文件切割为互不重合的多个视频片段,每个视频片段就是一个视频级别的实例。</td>   <td>G06V20/40;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;                   罗裴然       </td>   <td>中山大学</td>   <td>一种基于账户模型的高效数字法币交易方法</td>   <td>广东省</td>   <td>CN112419059B</td>   <td>2023-07-21</td>   <td>本发明涉及区块链金融技术领域,更具体地,涉及一种基于账户模型的高效数字资产交易方法。针对现有的AFCoin技术框架,引入区块链森林和背书节点选择方法,融入收据处理过程,给出该框架的完整实现步骤,并将其应用在数字资产交易的领域,进而获得了一种基于账户模型的高效数字资产交易方法。在AFCoin的语义框架下,区块链森林是央行维护的多个区块链结构,不同的商业银行具有不同的区块链,但是由央行统一发布；背书节点选择方法是确保商业银行无法选择特定的负责背书的商业银行,防止商业银行间作弊问题的出现。当把央行作为数字资产的发行方,商业银行看作数字资产的承销方,用户看成数字资产的持有人之后,就可以获得一个高效的数字资产交易方法。</td>   <td>1.一种基于账户模型的高效数字法币交易方法,其特征在于,包括资产发行方CB、资产承销方CMB-1,…,CMB-(nb)以及用户DU-1,…,DU-(nu),其中nb和nu是任意自然数,且随着区块链系统的运行,nb和nu的数值可以动态变化；资产承销方CMB-1,…,CMB-(nb)分别拥有公私钥对(bpk-1,bsk-1),…,(bpk-(nb),bsk-(nb))；用户DU-1,…,DU-(nu)可以在不同的资产承销方注册真实身份,以满足金融系统的监管需求,同时用户分别拥有公私钥对(upk-1,usk-1),…,(upk-(nu),usk-(nu)),用户的公钥进一步生成用户的账户地址；用户的数字资产交易包括以下步骤：S1. 创建与提交交易：用户DU-i获取用户DU-j的账户地址,设置数字资产的值v生成未签名的交易Tx',并通过用户DU-i的私钥usk-i生成交易签名Sig-(Tx),发送带签名的交易Tx到资产承销方CMB-s,其中,/&gt;；S2. 处理交易：资产承销方CMB-s接收来自用户DU-i的交易Tx,验证交易Tx是否满足交易条件,处理满足交易条件的交易Tx,并输出交易收据Recpt；S3. 交易上链：资产承销方CMB-s将交易Tx-1,,Tx-n的哈希值及交易收据Recpt-1,/&gt;,Recpt-n的哈希值打包,形成未签名未背书区块Blk',通过CMB-s的私钥bsk-s生成区块签名Sig-(Blk)并与区块Blk'组装得到未背书的区块Blk'',之后由负责背书的资产承销方CMB-p和CMB-q生成背书签名,并提交携带背书签名的区块Blk、交易Tx-1,/&gt;,Tx-n和收据Recpt-1,/&gt;,Recpt-n至资产发行方CB,资产发行方CB验证区块Blk的有效性并发布有效的区块至区块链森林中CMB-s的区块链Chain-s上,其中/&gt;,n是自然数。</td>   <td>G06Q40/04;G06Q20/36;G06Q20/38;G06Q20/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              惠晓璐;              陈添水;              许慕欣;                   王青       </td>   <td>中山大学</td>   <td>一种基于特定语义的图表示学习框架及其多标签分类方法</td>   <td>广东省</td>   <td>CN110084296B</td>   <td>2023-07-21</td>   <td>本发明公开了一种基于特定语义的图表示学习框架及其多标签分类方法,该框架包括：语义结耦模块,用于利用卷积神经网络对输入图像提取图像特征,将图像特征与语义特征相结合,并引入注意机制,利用语义特征引导图像特征权重的学习,并作用于图像特征,得到新的特征向量；语义交互模块,用于先通过构建知识图谱统计数据集中类别共存的关联性来构建大型知识图谱,再利用一个门图网络来对知识图谱进行特征表达,迭代的更新知识图谱得到知识图谱的特征表示；知识嵌入表达模块,用于将所述语义交互模块知识表达学习到的特征表示与所述语义结耦模块提取的图像特征学习相结合,以实现多标签分类。</td>   <td>1.一种基于特定语义的图表示学习框架,包括：语义结耦模块,用于利用卷积神经网络对输入图像提取图像特征,将图像特征与语义特征相结合,并引入注意机制,利用语义特征引导图像特征权重的学习,并作用于图像特征,得到新的特征向量；语义交互模块,用于先通过构建知识图谱统计数据集中类别共存的关联性来构建大型知识图谱,再利用一个门图网络来对知识图谱进行特征表达,迭代的更新知识图谱得到知识图谱的特征表示；知识嵌入表达模块,用于将所述语义交互模块知识表达学习到的特征表示与所述语义结耦模块提取的图像特征学习相结合,以实现多标签分类；所述语义结耦模块进一步包括：图像特征提取单元,用于利用卷积神经网络对输入图像提取图像特征；语义特征提取单元,用于利用预训练的GloVe模型提取所采用数据集所有类别的类别语义特征；特征向量获取单元,用于通过引入语义引导注意机制,利用所述语义特征提取单元获得的类别语义特征来引导学习特征权重,并作用于原图像特征形成新的特征向量；所述特征向量获取单元引入语义引导注意机制,其结合了通过所述语义特征提取单元获取的类别语义特征,以指导更多地关注语义感知区域,从而学习对应于该类别的特征向量,表示如下：                  其中tanh(·)为双曲正切函数,为可学习参数,⊙为元素点乘,d-1和d-2分别为联合特征嵌入和输出特征的维度,/&gt;为图像特征,d-s为语义向量的维度,x-c为类别语义特征,N为数据集中类别节点数目,R为实数空间；对于每个位置(w,h),所述特征向量获取单元首先使用低维双线性池化的方法将相应的图像特征和类别语义特征x-c进行融合,然后在所述类别语义特征x-c的引导下计算权重系数/&gt;并对每个位置重复该项操作,再进行正则化,对所有位置执行加权平均合并以获得特征向量f-c,所述特征向量获取单元对所有类别重复该过程,获得所有类别相关的特征向量{f-0,f-1,...,f-(C-1)}；所述语义交互模块进一步包括：知识图谱构建单元,用于统计数据集中类别标签和属性的关联性,构建大型知识图谱；门图网络构建单元,用于定义一个门图网络以对知识图谱进行特征表达,利用所述知识图谱构建单元获得的数据集节点共存的统计信息初始化门图网络GGNN中类别节点之间的连接值,并利用所述特征向量获取单元得到的特征向量来初始化门图网络GGNN类别节点特征；迭代更新单元,用于在所述门图网络中迭代地更新每个节点的信息；所述知识图谱构建单元根据数据集中类别节点之间的共存性得到类别节点之间共存的共存统计信息,该信息为N×N维矩阵,构成知识图谱；迭代更新单元的迭代过程如下：                                                                                          对于每个节点c∈V,在迭代次数t都有一个隐藏信息当t＝0时,/&gt;x-c,x-c为初始的特征向量,a-c表示节点c和其相邻节点关系的a的子矩阵,σ和tanh分别是激活函数和双曲正切函数,⊙表示向量点乘,W,U,W～z,/&gt;U～z,W～r,U～r为n＊n维度的可学习的卷积神经网络的训练参数；/&gt;是中间计算结果,表示GGNN网络中的部分周期性输出；/&gt;是中间计算结果,表示类别相关的隐藏信息；整个过程一共迭代T次,最终得到隐藏信息的集合/&gt;</td>   <td>G06V10/764;G06V10/774;G06V10/82;G06N3/042;G06N3/0442;G06N3/045;G06N3/0464;G06N3/048;G06N3/08;G06N5/022</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              廖泳贤;                   黄立峰       </td>   <td>中山大学</td>   <td>一种基于深度学习模型的对抗性训练方法</td>   <td>广东省</td>   <td>CN112016686B</td>   <td>2023-07-21</td>   <td>本发明公开了一种基于深度学习模型的对抗性训练方法,包括：通过自然进化策略生成第一对抗性示例以及通过平移不变攻击方法生成第二对抗性示例,将所述第一对抗性示例和所述第二对抗性示例作为扰动图像；获取干净图像,并将所述干净图像与所述扰动图像按照不同的比例进行混合,得到不同图像比例的训练集；将所述不同图像比例的训练集分别传输至深度学习模型中进行训练,确定使得深度学习模型鲁棒性最优的训练集；将所述使得深度学习模型鲁棒性最优的训练集作为训练数据输入至神经网络微调特定层中,对深度学习模型进行优化,得到对应的对抗性微调模型；本发明实现提高深度学习模型对于对抗样本的鲁棒性并减少运算负担,提高模型运算效率。</td>   <td>1.一种基于深度学习模型的对抗性训练方法,其特征在于,包括：通过自然进化策略生成第一对抗性示例以及通过平移不变攻击方法生成第二对抗性示例,将所述第一对抗性示例和所述第二对抗性示例作为扰动图像；所述通过平移不变攻击方法生成第二对抗性示例的公式为：                  其中,W-(i,j)是高斯核矩阵W的权重元素,k是内核大小,标准偏差e的(-i～2-j～2)/(2σ～2)次幂再乘以系数1/(2πσ～2)得到(i,j)位置上的高斯核权重,j代表平移的横坐标和纵坐标,取值范围为[0,k],k为常数；对所述第二对抗性示例进行更新；其中,更新公式为：                  其中,x-t代表对抗样本,y代表干净样本x的分类标签,J(x-t,)是白盒攻击情况下神经网络的损失函数,是对未进行变换的对抗性示例进行求梯度运算,由于神经网络的平移不变性,对各种平移和填充变换后的图像求梯度的和近似于经过高斯核矩阵W乘以得到的值；sign()为符号函数；α为小步长；-(t+1)为更新的对抗性示例；获取干净图像,并将所述干净图像与所述扰动图像按照不同的比例进行混合,得到不同图像比例的训练集；将所述不同图像比例的训练集分别传输至深度学习模型中进行训练,确定使得深度学习模型鲁棒性最优的训练集；将所述使得深度学习模型鲁棒性最优的训练集作为训练数据输入至神经网络调整层中,对深度学习模型进行优化,得到对应的对抗性微调模型。</td>   <td>G06N3/082;G06N3/0464;G06N3/063</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李仁杰;                   朝红阳       </td>   <td>中山大学</td>   <td>一种基于查找表加速点云分割的方法</td>   <td>广东省</td>   <td>CN112330680B</td>   <td>2023-07-21</td>   <td>本发明属于计算机视觉领域下的3D点云分割领域,更具体地,涉及一种基于查找表加速点云分割的方法,开拓性的将查找表的思想应用到点云分割的问题上来,利用访问查找表代替了神经网络的前向计算,极大的加速了点云分割的过程。本发明创新性的将主成分分析应用于点云分割处理上,让分割网络可以摆脱对空间变换网络模块的依赖,使点云分割网络具有旋转不变性的同时减少了计算量。</td>   <td>1.一种基于查找表加速点云分割的方法,其特征在于,包括以下步骤：S1.点云数据归一化处理,得到尺寸归一化的点云；具体包括：S11.利用重心平移实现点云平移归一化,首先依据公式计算点云的重心,然后使点云的每个点都跟随着重心移动,每个点平移后的坐标为P'-i＝P-i-P-(center)；S12.利用主成分分析方法实现点云旋转归一化；S13.利用轴对齐包围盒实现点云尺寸归一化；S2.搭建并训练点云分割网络PointNet,点云分割问题可以看作是对点云中每个点的分类问题；其中,网络的输入为N×3的点云数据,N为点云中包含的点的数量,每个点有三维坐标进行表示；网络输出为N×K,K为点云中每个点的分类标签；训练完毕后保存网络参数；具体包括：S21.去掉PointNet分割网络PointNet-Seg中的两个T-Net,仅保留最简单的PointNet-Seg-Basic网络结构；S22.利用训练集训练PointNet-Seg-Basic网络,并且保存最好分割准确率的网络参数；S3.建立特征查找表；具体包括：S31.点云经过尺寸归一化后其输入将被固定在空间V中,V＝[-1,1]～3；将V划分为S～3个不相交的相互独立的体素,每个体素的长度为δ＝2/S,体积为8/S～3；其中S是一个变量,可以根据需求选择不同的S值对空间V进行划分,随着S增大,准确率会略有提升,但V所占用的内存也会随之增大；S32.为了从V中划分出的S～3个体素编号,使用一个三维坐标(i,j,k)∈[0,S]～3来标识每一个体素,其中(0,0,0)表示V中左下角的体素,(S,S,S)表示右上角的体素；S33.构建特征查找表T[i][j][k][f],其中i,j,k为体素编号,f表示编号为i,j,k的体素对应的特征向量；S33具体包括：S331.构建特征提取网络,对PointNet-Seg-Basic点云分割网络进行拆分,拆分为PointNet-Seg-Basic-Features和PointNet-Seg-Basic-Cls两个部分,其中PointNet-Seg-Basic-Features仅包含PointNet-Seg-Basic中的特征提取部分的网络结构,PointNet-Seg-Basic-Cls仅包含对依据每个点的特征进行分类的网络结构；S332.将保存的PointNet-Seg-Basic-Features-Parameters恢复到PointNet-Seg-Basic-Features网络结构的参数中；S333.为V中的每一个体素(i,j,k)生成一个三维坐标点,点的坐标为(i×δ,j×δ,k×δ),其中δ为体素长度；将生成的点通过PointNet-Seg-Basic-Features网络结构,将得到该点的特征向量f；此特征向量f作为编号为i,j,k的体素对应的特征向量；公式表达为：T[i][j][k][f]＝pointnet-seg-basic-features(iδ,jδ,kδ)；S334.将得到的特征查找表T[i][j][k][f]保存下来；S4.对PointNet-Seg-Basic-Cls部分进行微调,进一步提升分割网络的分割准确率；S5.对点云进行快速分割,通过特征查找表,获取点云中每个点的特征并将每个点的特征输入到微调后的PointNet-Seg-Basic-Cls网络中获取该点的分类结果；综合每个点的分类情况,最后得到点云的分割结果。</td>   <td>G06V10/26;G06V10/764;G06V10/82;G06T7/66;G06T17/20;G06F16/901</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   祝一帆       </td>   <td>中山大学</td>   <td>一种面向地址场景识别的离线文字识别方法</td>   <td>广东省</td>   <td>CN112418225B</td>   <td>2023-07-21</td>   <td>本发明提供一种面向地址场景识别的离线文字识别方法,该方法对数据集进行预处理：去除数据集标注文本中无法识别的生僻字,以及该标注文本对应的图像,其中,数据集包括图像和图像对应的标注文本；使用ICDAR2017RCTW数据集对连接预选框网络CTPN进行训练；训练卷积循环神经网络CRNN模型；输入预处理后的图像,使用CTPN定位图像中所有文本的位置,并使用矩形框将文本框出,提供矩形的顶点坐标以及宽高；将输出的文本框坐标输入CRNN,对文本框中的文本进行识别,输出预测文本,提高了地址识别的准确率。</td>   <td>1.一种面向地址场景识别的离线文字识别方法,其特征在于,包括以下步骤：S1：对数据集进行预处理：去除数据集标注文本中无法识别的生僻字,以及该标注文本对应的图像,其中,数据集包括图像和图像对应的标注文本；S2：使用ICDAR2017RCTW数据集对连接预选框网络CTPN进行训练；S3：训练卷积循环神经网络CRNN模型；S4：输入预处理后的图像,使用CTPN定位图像中所有文本的位置,并使用矩形框将文本框出,提供矩形的顶点坐标以及宽高；S5：将步骤S4中输出的文本框坐标输入CRNN,对文本框中的文本进行识别,输出预测文本；所述步骤S5的具体过程是：S51：对步骤S4中输出的文本框,使用CNN提取其特征图；S52：将CNN提取出的特征转换为特征向量,特征向量的数量等于特征图的通道数,这些特征向量每一个关联一个感受野,整体构成一个特征序列；S53：将特征序列中的向量作为一个个时间步输入RNN中,RNN输出序列的得分矩阵；S54：使用CTC-loss处理文本序列对齐问题,场景文本由于拍照环境、印刷瑕疵问题,字体大小可能不统一,且文本可能不完全水平,因此需要处理序列的对齐问题；同时因为框的大小固定,而文字的大小不一,每个文字可能被多个框框中,从而有多个得分,需要将分数整合,去掉重复的文本框；还包括S6的具体过程是：S61：对于S5中输出的预测文本,将文本按照高德地图要求的格式加入请求URL中发出GET请求；S62：获取返回的建议地址结果；S63：将结果与识别的地址文本比对,文本重合度超过阈值时将建议地址结果作为最终的地址文本结果。</td>   <td>G06V30/148;G06V20/62;G06V30/19;G06N3/0442;G06N3/049;G06V10/82;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭晓军;              王锦萍;              张乐天;              陈楠杰;              黄佳健;                   王薛强       </td>   <td>中山大学;广州文远知行科技有限公司</td>   <td>一种Transformer多模态数据特征融合方法</td>   <td>广东省</td>   <td>CN116468978A</td>   <td>2023-07-21</td>   <td>本发明公开了一种Transformer多模态数据特征融合方法,方法包括：通过浅层空谱特征解译模块进行第一次上下文优化,根据从LiDAR数据获得的局部空间掩膜作为引导信息,从光谱信息到空间信息提取浅层多模态特征；通过中层自适应特征融合模块进行第二次上下文特征融合,使用自适应交叉Transformer融合多个数据源的CLS标记,得到协作抽象信息；根据浅层多模态特征和协作抽象信息,通过高层多阶段特征传递模块进行第三次交叉融合,得到最终全局特征融合结果。本发明更可靠更灵活,可广泛应用于计算机技术领域。</td>   <td>1.一种Transformer多模态数据特征融合方法,其特征在于,包括：通过浅层空谱特征解译模块进行第一次上下文优化,根据从LiDAR数据获得的局部空间掩膜作为引导信息,从光谱信息到空间信息提取浅层多模态特征；通过中层自适应特征融合模块进行第二次上下文特征融合,使用自适应交叉Transformer融合多个数据源的CLS标记,得到协作抽象信息；根据所述浅层多模态特征和所述协作抽象信息,通过高层多阶段特征传递模块进行第三次交叉融合,得到最终全局特征融合结果。</td>   <td>G06V10/80;G06V10/764;G06V10/77;G06V10/82;G06N3/047;G06N3/048;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卓莉;              李明月;              周素红;              史清丽;                   黄昱普       </td>   <td>中山大学</td>   <td>一种基于街景数据的村镇收缩模拟方法、系统和装置</td>   <td>广东省</td>   <td>CN116468994A</td>   <td>2023-07-21</td>   <td>本发明公开了一种基于街景数据的村镇收缩模拟方法、系统和装置,该方法包括：获取街景图像数据集；基于街景图像数据集提取地表要素分布并量化视觉景观品质,得到视觉景观指标；对街景图像数据集进行评分,得到情感评分结果；根据视觉景观指标和情感评分结果,基于随机森林模型进行村镇收缩驱动力分析,得到驱动力因素；根据驱动力因素,基于微观模拟模型元胞自动机,进行村镇收缩的模拟。本发明基于街景图像的村镇收缩表达,探究收缩关键驱动力因素,模拟村镇收缩演变趋势。本发明可广泛应用于发展趋势模拟领域。</td>   <td>1.一种基于街景数据的村镇收缩模拟方法,其特征在于,包括以下步骤：获取街景图像数据集；基于街景图像数据集提取地表要素分布并量化视觉景观品质,得到视觉景观指标；对街景图像数据集进行评分,得到情感评分结果；根据视觉景观指标和情感评分结果,基于随机森林模型进行村镇收缩驱动力分析,得到驱动力因素；根据驱动力因素,基于微观模拟模型元胞自动机,进行村镇收缩的模拟。</td>   <td>G06V20/00;G06V20/10;G06V10/774;G06V10/762;G06T3/40;G06Q10/0639;G06N5/01;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢宇彤;              沈逸仙;              杜云飞;              钟康游;              郭贵鑫;              李江;              杜量;              曹鹏;                   赵帅帅       </td>   <td>中山大学</td>   <td>一种面向科学大数据的索引生成方法和检索方法</td>   <td>广东省</td>   <td>CN110442575B</td>   <td>2023-07-18</td>   <td>本发明涉及一种面向科学大数据的索引生成方法和检索方法,包括以下步骤：根据各个数据块的热度确定其中若干个数据块为热点数据块；根据热点数据块的连续情况将热点数据块和与该热点数据块邻近的数据块进行合并；根据合并后的数据块生成数据索引或更新原有的数据索引。本发明既可以防止数据块太大而导致检索时过多冗余信息进入磁盘而增加数据过滤的开销,又可以防止数据块太小而导致检索时增加磁盘访存的开销,更加充分利用计算机的计算资源,大大提高了科学大数据的检索效率。</td>   <td>1.一种面向科学大数据的索引生成方法,其特征在于,包括以下步骤：根据各个数据块的热度确定其中若干个数据块为热点数据块；根据热点数据块的连续情况将热点数据块和与该热点数据块邻近的数据块进行合并；根据合并后的数据块生成数据索引或更新原有的数据索引；根据热点数据块的连续情况将热点数据块和与该热点数据块邻近的数据块进行合并,具体包括以下步骤：根据热点数据块的连续情况将热点数据块和该热点数据块的x个前置数据块和/或y个后置数据块进行合并；x的取值小于等于a-1与b-1的较小值,a-1为热点数据块的未进行合并的前置数据块数目,b-1为预设的前置数据块合并数目阈值；y的取值小于等于a-2与b-2的较小值,a-2为热点数据块的未进行合并的后置数据块数目,b-2为预设的后置数据块合并数目阈值；根据热点数据块的连续情况将热点数据块和该热点数据块的y个后置数据块进行合并,具体包括以下步骤：S1.设该热点数据块为第i个热点数据块；S2.判断第i个热点数据块的z个后置数据块中是否存在热点数据块,z为连续性参数且取值小于等于a-2,若否则执行步骤S3,若是则执行步骤S4；S3.将第i个热点数据块与第i个热点数据块的y个后置数据块进行合并,并停止步骤；S4.将第i个热点数据块至第i+1个热点数据块进行合并,令i＝i+1,若i小于等于热点数据块的个数则继续执行步骤S2,否则停止步骤。</td>   <td>G06F16/22;G06F16/23;G06F16/2455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              钟沈君;              谢舜道;                   陈荣军       </td>   <td>中山大学</td>   <td>一种双阶二维码的生成方法及其防复制验证方法</td>   <td>广东省</td>   <td>CN110633774B</td>   <td>2023-07-18</td>   <td>本发明提供的一种双阶二维码的生成方法,通过在普通二维码中嵌入S1纹理图案集,并同时嵌入S2纹理图案集,得到双阶二维码；本发明还提供一种双阶二维码的防复制验证方法,通过输入双阶二维码并进行纹理分类,得到图案匹配成纹理图案对；利用纹理图案对计算相关系数；将相关系数与验证阈值对比,完成双阶二维码的防复制验证。本发明提供的一种双阶二维码的生成方法及其防复制验证方法,充分利用了纹理二维码纹理图案对P&amp;S过程的敏感性,对普通二维码进行两个阶段的纹理图案嵌入而得到双阶二维码,通过相关系数的计算,直观准确地判断出所输入的二维码是真实或复制的,避免了印刷品在物理渠道被复制的可能性,且整个过程简单,容易进行推广。</td>   <td>1.一种双阶二维码的防复制验证方法,其特征在于,包括以下步骤：S21：选取双阶二维码扫描版本进行输入；选取的双阶二维码由以下步骤生成：S11：在普通二维码中嵌入S1纹理图案集,得到纹理二维码,具体为：使用S1纹理图案集,顺序替换普通矩阵式二维码数据区域中的所有暗模块；S12：在纹理二维码中嵌入S2纹理图案集,得到双阶二维码,具体为：使用S2纹理图案集替换纹理二维码数据区域中的部分暗模块；S22：对输入的双阶二维码进行纹理分类；S23：根据分类结果,将纹理相同的图案匹配成纹理图案对；具体为：                                                      其中,纹理图案是输入的双阶二维码I-k分类出来的S2纹理图案；纹理图案是输入的双阶二维码I-k分类出来的S1纹理图案；S24：利用纹理图案对计算相关系数；具体包括以下步骤：S241：设两个随机向量X＝(x-1,x-2,...,x-n)和Y＝(y-1,y-2,...,y-n),其中随机向量X为S1纹理图案,随机向量Y为S2纹理图案；S242：计算单个纹理图案的相关系数,具体公式为：                  其中,和/&gt;分别表示为{x-1,x-2,…,x-n}和{y-1,y-2,…,y-n}的均值,即：/&gt;S243：计算所有纹理图案对的相关系数的均值,具体公式为：                  其中,Corr(,)表示纹理图案对的相关系数,k＝1,2表示是真实二维码的扫描版本和复制二维码的扫描版本,R-(2S)是所有纹理图案对的相关系数的均值；S25：将相关系数与验证阈值对比,完成双阶二维码的防复制验证。</td>   <td>G06K19/06;G06Q30/018</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李梦婷;              李翔;              印鉴;              刘威;                   余建兴       </td>   <td>中山大学</td>   <td>一种基于人脸高维特征的性别预测方法</td>   <td>广东省</td>   <td>CN111753641B</td>   <td>2023-07-18</td>   <td>本发明提供一种基于人脸高维特征的性别预测方法,该方法基于ResNet100层的CNN网络结构的人脸识别模型衍生出的性别预测方法,首先通过对百万数量级人脸识别数据的训练,得到人脸高维特征表述的方式,再通过十万张标注性别的人脸照片,利用一个浅层的网络,训练出可以通过人脸照片就可以判断出性别的模型；本发明完全复用了人脸识别过程中的高维特征的计算结果,只需要很小的计算量就可以得到性别的预测结果,同时还可以保持非常高的预测精度。</td>   <td>1.一种基于人脸高维特征的性别预测方法,其特征在于,包括以下步骤：S1：采用100层的卷积神经网络ResNet作为主干网络,使用百万人脸数据集MS1M进行人脸识别模型的训练,生成一个可以使用的深度人脸模型,并把通过100层的参数权重固定,这样每张人脸照片在通过这100层的主干网络之后,都可以生成一个高维度的向量；所述步骤S1的具体过程是：S11：使用MTCNN模型将人脸数据集进行人脸提取和裁剪,输入的是原始的人脸照片数据,输出的是每张人脸对应的5个关键坐标点,包括两只眼睛、两个嘴角和一个鼻子,再把这5个点对应的人脸按照112×112的比例进行裁剪,其中使用到的margin值为16；S12：把裁剪后的人脸以及对应的身份标注输入到100层的卷积神经网络ResNet中,使用基于Arcface的损失函数进行模型的训练,直至学习率降为0.001为学习结束；S2：基于S1生成的主干网络,使用10万张带有性别标注的人脸照片输入到主干网络中,把通过主干网络生成的高维向量作为特征,训练一个两层的浅层网络,生成一个预测男女的二分类模型；所述步骤S2的具体过程是：S21：收集了10万张线上各个场景的人脸照片,并且人工对每张照片的性别进行标注,这样就有了10万张有标注信息的数据,将这些照片输入到S1生成的主干网络后,生成10万个512维的特征向量,每个特征向量都有对应的性别标注；S22：把10万个特征向量按照8:2的比例随机分为两部分,其中8万个作为训练集,使用浅层的两层网络,损失函数采用基于交叉熵的softmax函数,训练一个二分类的性别模型,训练结束后,使用剩下的2万张照片作为性别模型的测试数据；S3：将S1和S2生成的两个模型部署到服务器中,同时提供人脸识别服务和性别预测服务,实时返回人脸照片对应的身份以及性别属性；所述步骤S3的具体过程是：S31：对于S12生成的主干网络进行模型的量化优化,减少对应的计算量,由于当前主流的训练方式使用的是32位的浮点数,所以主要采用了是16位整型的量化方式,在对精度影响非常小的情况下,大幅度减少对应的计算量；S32：将S31和S22生成的模型部署在线上,当一张照片过来时,首先通过S31的模型得到一个512维的特征向量,通过比对人脸底库中已有人脸向量的相似度,判断其身份,同时把这个向量输入到S22的模型中,返回这张照片对应的性别,同时把识别到的身份信息和性别信息返回到客户端展示。</td>   <td>G06V40/16;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨雪榕;              张艳;              童鹏飞;              曲承志;              杨起帆;                   陈金涛       </td>   <td>中山大学</td>   <td>一种多传感器多目标协同探测信息融合方法、系统</td>   <td>广东省</td>   <td>CN111860589B</td>   <td>2023-07-18</td>   <td>本发明公开了一种多传感器多目标协同探测信息融合方法,包括：获取雷达测量设备的原始数据；对所述原始数据进行预处理,得到处理数据；根据时间配准算法及空间配准算法进行传感器信息配准,以使得所有传感器获得同一时刻及同一时空的观测信息；根据目标关联算法及机动目标模型进行点迹-航迹关联,以得到目标航迹；根据K-means算法进行航迹-航迹关联,以得到精确航迹；根据融合算法对所述处理数据进行融合处理,以得到追踪目标的精确航迹及实时运动参数。本发明提供的多目标协同探测信息融合方案,具备配置灵活、通用性强和可扩展性好的优点；通过机载数据处理单元进行数据实时处理,降低远程控制中心的任务负载,增加方案的时效性和安全性。</td>   <td>1.一种多传感器多目标协同探测信息融合方法,其特征在于,包括：获取雷达测量设备的原始数据；对所述原始数据进行预处理,得到处理数据；其中,所述预处理包括：根据光学望远镜的测角进行跟踪误差修正,根据时间插值对齐的方位角突变进行方位角跳点修正,根据雷达测量距离进行传播延时修正及时间插值对齐；根据时间配准算法进行传感器信息配准,以使得所有传感器获得同一时刻的观测信息；所述时间配准算法具体包括以下步骤：获取第一传感器与第二传感器的采样周期τ和T,其中τ:T＝n；计算第二传感器在k-1至k时刻内的n个观测值构成的集合：Z-n＝[z-1,z-2,…,z-n]～T其中,z-n与k时刻第一传感器的观测值同步；计算z-1,z-2,…,z-n融合后的观测值及其导数得到第二传感器的观测值可表示为其中v-i表示观测噪声；计算上式的向量形式：Z-n＝W-nU+V-n其中v-n＝[v-1,v-2,…,v-n]～T,其协方差阵为                  而为融合以前观测噪声的方差,同时有                  根据最小二乘准则有如下目标函数                  要使J最小,将J两边对求偏导,并使其为零,可得                  从而有                  相应的误差协方差阵为                  可得融合以后的观测值及其噪声方差为                                    其中c1＝-2/n；c2＝6/[n(n+1)]；根据空间配准算法进行传感器信息配准,以使得所有传感器获得同一空间的观测信息；根据目标关联算法及机动目标模型进行点迹-航迹关联,以得到目标航迹；所述目标关联算法通过以下步骤计算：通过新息协方差矩阵S(k)和新息向量d～t(k),确定新息向量g～t(k)＝[d～t(k)]～TS～(-1)(k)d～t(k)检测g～t(k)是否小于某一门限,g～t(k)≤γ～t其中,γ～t为第t个目标关联区域的大小；若满足条件,则满足该条件的回波是为关联区域内的有效回波；计算确定矩阵                  其中,ω-(jt)是二进制变量；ω-(jt)＝1表示第j个量测回波落入第t个目标的确认门内；ω-(jt)＝0表示第j个量测回波没有落入第t个目标的确认门内；下标符号j∈{1,2,...,m-k},t∈{0,1,...,T},确认矩阵第1列即t＝0的列表示回波不源于目标,该列对应的列元素ω-(j0)全部为1,因为每个量测都有可能源自杂波或是虚警；对确认矩阵Ω进行拆分,得到L个互联矩阵                  其中,θ～i表示第i个可行互联事件,对应第i个互联矩阵为第i个互联矩阵的元素,表示第j个量测与第t个目标的关联状态；计算每个互联矩阵对应事件的概率,从而得到每个有效回波与可能源自的目标互联的概率β-(jt)(k),其中β-(jt)(k)满足等式                  其中,m-k为有效回波个数；计算关联概率β-(jt)(k)的正式定义为条件概率：β-(jt)(k)＝Pr{θ-(jt)(k)|Z(k)},j＝1,2,...,m-k,t＝0,1,...,T其中,β-(jt)(k)代表k时刻目标t漏检的概率；在JPDA算法中,关联概率β-(jt)(k)的计算公式为                  其中,Pr{θ～i|Z～k}为第i个可行关联事件θ～i的后验概率,第i个可行关联事件θ～i对应为确认矩阵拆分后得到第i个互联矩阵Z～k为到k时刻的累积量测集合；/&gt;为第i个可行关联事件θ～i所对应的互联矩阵/&gt;中量测j与目标t的关联状态；L为可行关联事件θ～i的总数,即确认矩阵Ω拆分后得到的互联矩阵/&gt;总数；所述机动目标模型通过以下步骤计算：获取r个运动模型,并得到状态方程式：X(k+1)＝F-jX(k)+W-j(k),j＝1,2,3…,r其中,X(k)为系统的状态向量,F-j为目标的状态转移矩阵,W-j(k)为均值为零,协方差为Q-j的高斯白噪声；模型中任意模型j的观测方程为：Z(k)＝H-jX(k)+V-j(k)其中,Z(k)为量测向量,H-j为模型j的观测矩阵,V-j(k)为均值为零且协方差为R-j的高斯白噪声；模型转换矩阵可以表示为：                  其中,p-(ij)表示模型i到模型j的转移矩阵；根据K-means算法进行航迹-航迹关联,以得到精确航迹；根据融合算法对所述处理数据进行融合处理,以得到追踪目标的精确航迹及实时运动参数。</td>   <td>G06V10/80;G06V10/762;G01S7/35;G01S13/58;G01S13/86</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;                   卢少豪       </td>   <td>中山大学</td>   <td>基于二阶段聚类的无监督车辆重识别方法、系统及存储介质</td>   <td>广东省</td>   <td>CN112597871B</td>   <td>2023-07-18</td>   <td>本发明公开了一种基于二阶段聚类的无监督车辆重识别方法、系统及存储介质。所述方法包括以下步骤：数据收集；预处理；相同车型下的局部聚类；进行簇合并并得到识别结果。本发明提出的二阶段聚类方法充分利用了车辆的特性,从网络上爬取大量的带粗粒度标签的数据,利用这些数据训练出来的分类器可以先将目标数据集的车辆分为N个部分,然后在每个部分单独进行聚类得到簇。第二阶段聚类则将上述得到簇再做一次相同的聚类,用于合并一些相似的簇,由于一开始的分类器并不可靠,合并相似的簇使得之前分错的簇得以合并,使得最终的伪类标更可信,时效性更高,从而达到更好的训练效果。实验结果证明该方法能在目前一些开源数据集中取得最优的水平。</td>   <td>1.一种基于二阶段聚类的无监督车辆重识别方法,其特征在于,包括以下步骤：数据收集,收集大量带车型标注的图片；预处理,用目标检测算法检测所述带车型标注的图片的车辆位置并做裁剪；相同车型下的局部聚类,利用裁剪后的图片训练车型分类器,所述车型分类器用于将目标数据分为若干个簇,然后基于密度的聚类算法在每个相同车型中聚类,当两张图片的距离小于距离阈值时,则认为这两张图片属于同一个簇,否则,不属于同一个簇；所述车型分类器提供了一个特征提取器,将不同的目标数据分成多个簇；所述车型分类器与特征提取器共享参数,在所述训练车型分类器过程中,更新特征提取器时所述车型分类器分类的结果随之动态变化；进行簇合并,将所述相同车型下的局部聚类阶段得到的簇定义为簇中心,计算簇内所有样本的特征的均值并作为所述簇中心的特征,如果两个簇的簇中心小于设定阈值,则利用聚类算法将两个簇合并；两次层次聚类后,得到多个簇,每个簇里面的样本属于同一辆车；在局部聚类的过程中,还包括设置簇的最小值；所述簇的最小值用于判断并舍去离群值：若一个簇内的样本数小于所述簇的最小值,则认为该簇是离群值；在进行簇合并的过程中,设置的簇的最小值为1,用于避免在进行簇合并时的任何簇作为离群值被舍去；在训练车型分类器时,还包括计算损失函数的步骤,所述损失函数由两部分组成,一部分是网络图片用到的交叉熵损失,一部分是目标数据集用到的三元组损失。</td>   <td>G06V20/54;G06V10/764;G06V10/762;G06V10/40;G06V10/74;G06V10/774;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李昊昕;              郑伟诗;                   胡海峰       </td>   <td>中山大学</td>   <td>第一人称视角动作识别方法、系统及存储介质</td>   <td>广东省</td>   <td>CN112686194B</td>   <td>2023-07-18</td>   <td>本发明公开了一种第一人称视角动作识别方法、系统及存储介质,所述方法包括以下步骤：定位视频中的关键区域；提取关键区域的特征和全局特征；将关键区域的特征划分为用于表示两种交互主体的两个组别；构建显式关系建模的长短时记忆网络；进行动作识别。本发明采用弱监督的关键区域定位的技术方案,能够自动地定位参与到动作中的人或物体,减少了人和物体位置标注的需求；本发明还通过设计不同类型的连接,能在长短时记忆网络的基础上进一步显式建模视频中的不同关系；本发明还通过网络结构自动搜索技术,实现了自动的网络结构设计,根据数据特征自动选择最优的结构,减少了人工设计网络的负担。</td>   <td>1.一种第一人称视角动作识别方法,包括以下步骤：使用动作类别作为监督,定位视频中的关键区域；通过所述关键区域的位置信息提取关键区域的特征；提取整个视频的特征作为全局特征；通过学习将所述关键区域的特征划分为用于表示两种交互主体的两个组别；所述两种交互主体包括摄像头穿戴者的身体部位,以及与摄像头穿戴者交互的人或物体；构建显式关系建模的长短时记忆网络,在基础的长短时记忆网络结构中设计候选连接；所述候选连接包括不同帧之间的时序关系,两个交互主体组别之间的交互关系,以及交互主体和全局特征之间的上下文关系；通过网络结构自动搜索的方法,以数据驱动的方式搜索最优的长短时记忆网络结构,并进行动作识别；所述显式关系建模的长短时记忆网络包含两个互相对称的ego子网络和exo子网络；所述ego子网络和exo子网络分别对应所述表示两种交互主体的两个组别；所述ego子网络和exo子网络的隐层状态增加多种候选连接,用于网络结构搜索并显式建模不同关系；t时刻的ego子网络的计算表达式如下：                                    h-t＝σ(o-t)⊙tanh(C-t),                  其中,f-t,i-t,o-t,s-t,h-t,C-t,分别表示遗忘门,输入门,输出门,共享状态门,隐层状态,单元状态和候选单元状态,S-t表示共享状态,/&gt;是累积共享状态,W-(ih),W-(hh)是可学习参数；/&gt;是候选连接的集合,w-i是第i个候选连接的权重,/&gt;是第i个候选连接的特征；所述显式关系建模的长短时记忆网络其他时刻和exo子网络的计算形式和以上计算具有一样的形式；所述候选连接的集合包含显式建模不同帧之间的时序关系,两个交互主体组别之间的交互关系,和交互主体和全局特征之间的上下文关系的连接；所述不同帧之间的时序关系利用t-2时刻和t+1时刻隐层状态和输入特征进行建模,如下式：                                    其中,W-(pt)和W-(ft)是可学习参数；所述两个交互主体组别之间的交互关系通过显式融合所述ego子网络和exo子网络的特征进行建模,如下式：                                                      其中,W-(pi),W-(ci)和W-(fi)为可学习参数；所述交互主体和全局特征之间的上下文关系通过在长短时记忆网络中融合全局特征进行建模,如下式：                  其中,W-c为可学习参数；z-t为每帧的全局特征空间平均池化后的特征。</td>   <td>G06V40/20;G06V10/46;G06V10/82;G06N3/0442;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨猛;              叶林彬;                   刘俊峰       </td>   <td>中山大学</td>   <td>一种基于内容特征和风格特征的人脸图像生成方法</td>   <td>广东省</td>   <td>CN112861805B</td>   <td>2023-07-18</td>   <td>本发明提供一种基于内容特征和风格特征的人脸图像生成方法,包括以下步骤：S1：获取人脸图像数据集,并构建双路径生成式对抗网络模型；S2：从原始域人脸图像中提取原始域的内容特征和风格特征,从目标域人脸图像中提取目标域的内容特征和风格特征；S3：通过对内容特征和风格特征进行监督学习建立特征关联损失函数；S4：根据特征关联损失函数建立双路径生成式对抗网络模型的价值函数；S5：通过对抗学习得到价值函数的全局最优解,从而得到优化好的双路径生成式对抗网络模型进行人脸图像生成。本发明提供一种基于内容特征和风格特征的人脸图像生成方法,解决了现有的人脸图像生成技术无法保证生成的人脸图像保持输入人脸图像的身份的问题。</td>   <td>1.一种基于内容特征和风格特征的人脸图像生成方法,其特征在于,包括以下步骤：S1：获取人脸图像数据集,并构建双路径生成式对抗网络模型,其中所述人脸图像数据集包括原始域人脸图像和目标域人脸图像；所述双路径生成式对抗网络模型包括原始域编码器、目标域编码器/&gt;、原始域生成器/&gt;、目标域生成器/&gt;、原始域鉴别器/&gt;、目标域鉴别器/&gt;和特征关联模型；其中,所述原始域编码器包括用于提取原始域/&gt;的内容特征/&gt;的编码器/&gt;和用于提取原始域/&gt;的风格特征/&gt;的编码器/&gt;,所述目标域编码器包括用于提取目标域/&gt;的内容特征/&gt;的编码器/&gt;和用于提取目标域/&gt;的风格特征/&gt;的编码器/&gt;,所述原始域生成器用于融合原始域/&gt;的内容特征和风格特征并生成原始域生成人脸图像,所述目标域生成器用于融合目标域/&gt;的内容特征和风格特征并生成目标域生成人脸图像,所述原始域鉴别器用于鉴别原始域/&gt;生成人脸图像的真假,所述目标域鉴别器用于鉴别目标域/&gt;生成人脸图像的真假,所述特征关联模型用于对内容特征和风格特征进行监督学习建立特征关联损失函数,并根据特征关联损失函数对内容特征进行预测得到相应的风格特征；S2：利用双路径生成式对抗网络模型从原始域人脸图像中提取原始域的内容特征和风格特征,从目标域人脸图像中提取目标域的内容特征和风格特征；S3：通过对内容特征和风格特征进行监督学习建立特征关联损失函数；S4：根据特征关联损失函数建立双路径生成式对抗网络模型的价值函数；在建立双路径生成式对抗网络模型的价值函数之前,还包括建立内容和风格特征双循环重建损失函数,所述内容和风格特征双循环重建损失函数为：                  其中,是正反循环重建损失的比例参数,/&gt;表示原始域再编码得到的风格特征,/&gt;表示目标域再编码得到的风格特征,/&gt;表示原始域再编码得到的内容特征,/&gt;表示目标域再编码得到的内容特征；所述双路径生成式对抗网络模型的价值函数为：                  其中,是对相应项的权重超参数,/&gt;表示双路径生成式对抗网络模型,/&gt;为生成式对抗网络的对抗损失函数,/&gt;为人脸内容重建损失函数,/&gt;为人脸风格重建损失函数,为图像自重建损失函数,/&gt;为内容和风格特征双循环重建损失函数,/&gt;为特征关联损失函数；S5：通过对抗学习得到价值函数的全局最优解,从而得到优化好的双路径生成式对抗网络模型进行人脸图像生成。</td>   <td>G06V40/16;G06V10/25;G06V10/80;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘康怀;                   陈林       </td>   <td>中山大学</td>   <td>一种基于平衡碰撞二叉树的大型RFID系统丢失标签识别方法</td>   <td>广东省</td>   <td>CN114330393B</td>   <td>2023-07-18</td>   <td>本发明针对现有技术的局限性,提出了一种基于平衡碰撞二叉树的大型RFID系统丢失标签识别方法,在本领域首次提出并使用了平衡碰撞二叉树的数据结构,通过对目标RFID系统构建一颗各个叶子结点高度较为均衡的二进制查询树,相较于传统碰撞树显著地降低了高度,并进一步极大地减少了读写器广播信息的时间开销；通过对曼彻斯特编码原理和CPT树结构进行结合,彻底避免了空时隙的使用,且可仅用一比特信息从一个时隙中同步检验两个标签是否丢失,从而极大地提高了帧和时隙的利用率。在确保相同识别准确率的前提下,相比现有技术,本发明在渐进开销上最大降低了一个近为log N的倍数因子,在各类参数环境下展现出较大的性能提升,兼具良好的鲁棒性和拓展性。</td>   <td>1.一种基于平衡碰撞二叉树的大型RFID系统丢失标签识别方法,其特征在于,包括以下步骤：S1,为目标RFID系统中的各标签分别构建伪ID；具体包括以下步骤：S11,获取标签的数量N以及各标签的源ID,S12,根据标签的数量N以及各标签的源ID,为各标签分别分配一个种子以及均匀哈希函数；S13,根据所述种子以及均匀哈希函数,对各标签进行哈希操作分别产生一个二进制形式的数字字符串,以所述数字字符串后L=2logN位作为对应标签的伪ID；重复所述步骤S12以及S13,直至各标签均获得一个长度为L=2logN且唯一的伪ID；S2,根据所述伪ID,构建出所述目标RFID系统的平衡碰撞二叉树；构建平衡碰撞二叉树的过程为从根结点开始,逐层通过以下方式对所述标签划分,直至所有标签都被分配到叶子结点中：以使由当前结点的标签划分得到的子集的大小相差最小为目标,对当前结点各标签的伪ID中的比特位进行遍历,获得当前结点的最大划分比特位；根据当前结点各标签的伪ID在所述最大划分比特位的值,将当前结点的标签划分为两个子集,将划分得到的两个子集分别存储在当前结点的左孩子结点以及右孩子结点中；若当前结点仅包含一个或者两个标签,则将当前结点归为叶子结点,并且停止当前结点的划分过程；其中,所述平衡碰撞二叉树由根节点、根节点以上出度为0的叶子结点以及出度为2的内部结点构成；所述叶子结点用于执行帧中的一个单例时隙或者是一个包含两个标签的碰撞时隙；所述内部结点仅用于存储数据,不执行标签响应和识别操作；S3,基于曼彻斯特编码原理以及RFID阅读器与标签之间的先听再对话机制,从所述根结点开始,逐层递进出发到更高一层,对所述平衡碰撞二叉树中的叶子节点进行遍历,识别出所述目标RFID系统中的丢失标签；其中,对于所述平衡碰撞二叉树高度最低的叶子结点,包括以下过程：S31,以根结点为出发点,根据从根结点/&gt;到叶子结点/&gt;的访问路径,使RFID读写器将第一帧的第一个指令信息/&gt;广播给目标RFID系统中的所有标签进行保存；其中,所述指令信息中封装有从根结点/&gt;到叶子结点/&gt;的访问路径中各层的最大划分比特位、最大划分比特位对应的取值以及叶子结点/&gt;中的标签所需要响应的比特位；S32,将各标签的伪ID的比特分布情况与所述指令信息中关于最大划分比特位的信息进行比较；使信息匹配的标签,即存储在所述叶子结点/&gt;的标签,在当前时隙以自身伪ID的第/&gt;位比特数值对RFID读写器进行响应回复；S33,采用曼彻斯特编码原理,通过让RFID读写器从时隙中解码出标签的回复信息,检验存储于所述叶子结点的标签是否丢失。</td>   <td>G06K7/10;G06N5/01;G06K17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         钟权;              陈志广;                   卢宇彤       </td>   <td>中山大学</td>   <td>基于八叉树的数据处理方法、装置及计算机可读存储介质</td>   <td>广东省</td>   <td>CN116452735A</td>   <td>2023-07-18</td>   <td>本发明涉及数据处理技术领域,尤其涉及一种基于八叉树的数据处理方法、装置及计算机可读存储介质,其中,所述方法包括：获取待存储体数据的最大数据分辨率；基于最大数据分辨率,自下而上递减待存储体数据中各个层级的数据分辨率,得到LOD体数据；将LOD体数据输入预设八叉树模型,并于八叉树模型的根节点处,逐层向下对LOD体数据作稀疏化处理至叶子层,得到LOD稀疏八叉树；在接收到针对LOD稀疏八叉树中目标节点的数据处理指令时,获取目标节点对应的节点编号,并根据节点编号跳转至目标节点执行数据处理操作。解决了如何提升系数八叉树在大规模的数据处理场景下的数据处理效率问题。</td>   <td>1.一种基于八叉树的数据处理方法,其特征在于,所述基于八叉树的数据处理方法包括：获取待存储体数据的最大数据分辨率；基于所述最大数据分辨率,自下而上递减所述待存储体数据中各个层级的数据分辨率,得到LOD体数据；将所述LOD体数据输入预设八叉树模型,并于所述八叉树模型的根节点处,逐层向下对LOD体数据作稀疏化处理至叶子层,得到LOD稀疏八叉树,其中,所述LOD稀疏八叉树中的各个非空节点带有不同的节点编号；在接收到针对所述LOD稀疏八叉树中目标节点的数据处理指令时,获取所述目标节点对应的所述节点编号,并根据所述节点编号跳转至所述目标节点执行数据处理操作。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨琦;              陈明远;              林超;                   黄国恒       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>病症分类模型的训练方法、装置、终端及可读存储介质</td>   <td>广东省</td>   <td>CN116452851A</td>   <td>2023-07-18</td>   <td>本申请实施例涉及人工智能技术领域,具体提供了一种病症分类模型的训练方法、装置、终端及可读存储介质。该方法包括：获得图像数据、结构化数据和类别标签；将图像数据输入至病症分类模型的特征提取网络获得第一特征向量；将结构化数据输入至病症分类模型的特征筛选网络获得第二特征向量；将第一特征向量和第二特征向量输入至病症分类模型的特征拼接网络,获得目标训练样本的第三特征向量；将第三特征向量输入至病症分类模型的特征分类网络获得预测类别和预测类别的预测概率,并根据预测类别、所述预测概率和类别标签构建损失函数；基于训练样本和损失函数对病症分类模型进行迭代更新,得到目标病症分类模型,提高了病症识别的准确率。</td>   <td>1.一种病症分类模型的训练方法,其特征在于,所述训练方法包括：获得目标训练样本,所述目标训练样本包括图像数据、结构化数据和类别标签,所述图像数据为样本患者的医学图像,所述结构化数据为样本患者的个人结构化数据；将所述图像数据输入至待训练的病症分类模型的特征提取网络,获得所述图像数据对应的第一特征向量；将所述结构化数据输入至所述病症分类模型的特征筛选网络,获得所述结构化数据对应的第二特征向量；将所述第一特征向量和所述第二特征向量输入至所述病症分类模型的特征拼接网络,获得所述目标训练样本的第三特征向量；将所述第三特征向量输入至所述病症分类模型的特征分类网络获得所述目标训练样本的预测类别和所述预测类别的预测概率,并根据所述预测类别、所述预测类别的预测概率和所述类别标签构建损失函数；基于所述训练样本和所述损失函数对所述病症分类模型进行迭代更新,得到目标病症分类模型。</td>   <td>G06V10/764;G06T7/00;G06N3/08;G06V10/44;G16H10/60;G06V10/80;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴思庆;              胡琳敏;              王春良;              苏凯;                   向建帮       </td>   <td>中山大学</td>   <td>基于计算机视觉的烹饪油烟空气污染特征表征方法及系统</td>   <td>广东省</td>   <td>CN116453052A</td>   <td>2023-07-18</td>   <td>本发明公开了基于计算机视觉的烹饪油烟空气污染特征表征方法及系统,该方法包括：获取烹饪画面视频信息并进行数据预处理,得到预处理后的烹饪信息；基于运动增强注意力机制的跨模态融合方法对预处理后的烹饪信息进行融合处理,得到烹饪特征信息；构建基于烹饪多周期性的二维时序模型并对烹饪特征信息进行预测,得到烹饪室内空气颗粒物污染水平。该系统包括：获取模块、融合模块和预测模块。通过使用本发明,提高预测烹饪的室内空气颗粒物污染水平。本发明作为基于计算机视觉的烹饪油烟空气污染特征表征方法及系统,可广泛应用于计算机视觉识别技术领域。</td>   <td>1.基于计算机视觉的烹饪油烟空气污染特征表征方法,其特征在于,包括以下步骤：获取烹饪画面视频信息并进行数据预处理,得到预处理后的烹饪信息；基于运动增强注意力机制的跨模态融合方法对预处理后的烹饪信息进行融合处理,得到烹饪特征信息；构建基于烹饪多周期性的二维时序模型并对烹饪特征信息进行预测,得到烹饪室内空气颗粒物污染水平。</td>   <td>G06V20/52;G06V20/40;G06V10/40;G06V10/26;G06V10/80;G06V10/82;G06N3/0464;G06N3/045;G06N3/0455;G10L15/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姜善成;              梁涵;              刘棋泽;              古博;                   韩瑜       </td>   <td>中山大学</td>   <td>一种盐湖化工产业资源配置优化方法、装置和存储介质</td>   <td>广东省</td>   <td>CN116452019A</td>   <td>2023-07-18</td>   <td>本发明公开了一种盐湖化工产业资源配置优化方法、计算机装置及存储介质,建立了一个能够合理制定盐湖化工产业中转站选址、定容方案的决策模型,可以解决产业由于运力的不确定性影响货运计划导致产品订单无法如期交货情况的出现,合理规划生产运输计划以保证所有订单顺利完成；本发明考虑了不确定性因素,给出了订单需求的不确定性集合,通过设定目标函数,基于订单历史数据的可变上下限的订单需求不确定集,通过调参控制订单历史数据的保守程度,并能保证通过网格搜索法寻找最优的参数,鲁棒优化模型能够对未来的生产规划和资源调配做出一个提前的预测和规划,在总成本和送达率的表现上能有出色的表现。本发明广泛应用于数据处理技术领域。</td>   <td>1.一种盐湖化工产业资源配置优化方法,其特征在于,所述盐湖化工产业资源配置优化方法包括：获取盐湖化工产业的中转站规划信息和货物经营信息；根据所述中转站规划信息和所述货物经营信息,建立确定性模型；所述确定性模型中包括若干个确定性参数；将所述确定性模型中的部分所述确定性参数替换成为不确定性参数,获得不确定性模型；对所述不确定性模型进行求解,获得中转站规划信息。</td>   <td>G06Q10/0637;G06Q10/0631;G06Q10/067</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴卓;              林斯颖;              刘海晴;              赵慧英;              宋益东;              杨跃东;                   麦思瑶       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>基于乳腺MR影像组学的乳腺癌分子分型变化预测装置</td>   <td>广东省</td>   <td>CN113034436B</td>   <td>2023-07-14</td>   <td>本发明公开了一种基于乳腺MR影像组学的乳腺癌分子分型变化预测装置,包括：采集模块,用于采集乳腺癌患者的MR图像；分割模块,用于提取MR图像中的增强图像,并对增强图像中的肿物边缘进行勾画,得到标注的病灶区域；第一预测模块,用于提取病灶区域得到待处理图像,并对待处理图像进行图像预处理后输入到深度学习模型中,得到乳腺癌分子分型的第一预测结果；第二预测模块,用于提取增强图像中的特征数据,基于特征数据进行分析得到乳腺癌分子分型的第二预测结果；验证模块,用于对第一预测结果和第二预测结果进行鲁棒性的验证。本发明实施例通过第一预测结果和第二结果进行鲁棒性验证,能够有效提高对乳腺癌分子分型预测的准确性。</td>   <td>1.一种基于乳腺MR影像组学的乳腺癌分子分型变化预测装置,其特征在于,包括：采集模块,用于采集通过纳入及排除标准的MR图像,其中,所述通过纳入及排除标准的MR图像包括病例纳入及排除标准和MR纳入及排除标准,病例纳入标准包括1)所有在医院进行新辅助治疗的患者；2)有基线的穿刺病理结果及标本,且进行了免疫组化检测；3)有新辅助治疗后的手术病理结果及标本,且进行了免疫组化检测；分割模块,用于提取所述MR图像中的增强图像,并对所述增强图像中的肿物边缘进行勾画,得到标注的病灶区域；第一预测模块,用于提取所述病灶区域得到待处理图像,并对所述待处理图像进行图像预处理后输入到深度学习模型中,得到乳腺癌分子分型的第一预测结果；第二预测模块,用于提取所述增强图像中的特征数据,基于所述特征数据进行分析得到乳腺癌分子分型的第二预测结果；验证模块,用于对所述第一预测结果和所述第二预测结果进行鲁棒性的验证,使得第一预测结果和第二预测结果能够相互验证,并根据验证结果确定最终的预测结果；所述提取所述病灶区域得到待处理图像,具体为：对DCE成像中的MR图像的所述病灶区域进行标注以及拷贝,并分别通过T1加权成像、T2加权成像、扩散加权成像提取所述病灶区域,得到待处理图像；所述特征数据包括肿瘤整体特征数据、3D特征数据和主要特征数据,所述提取所述增强图像中的特征数据,具体为：提取待处理图像中的无特异性标注的特征信息作为肿瘤整体特征数据；通过构建肿瘤3D模型提取所述3D特征数据；通过构建LASSO模型分析所述待处理图像中的特征系数,并根据所述特征系数筛选出主要特征,得到主要特征数据。</td>   <td>G06T7/00;G06V10/26;G06V10/774;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              陈荣聪;              王广润;                   王可泽       </td>   <td>中山大学</td>   <td>一种基于自适应连接神经网络的图像处理方法及装置</td>   <td>广东省</td>   <td>CN111079900B</td>   <td>2023-07-14</td>   <td>本发明公开了一种基于自适应连接神经网络的图像处理方法及装置,所述方法包括如下步骤：步骤S1,构建自适应连接神经网络,对输入的特征图,分别提取其像素级特征、局部特征以及全局特征,并自适应地融合像素级特征、局部特征、全局特征；步骤S2,于图像处理任务中,选择适用的深度卷积网络结构,将其中部分或全部卷积层替换成所述自适应连接神经网络的AC-Net模块,或直接使用所述自适应连接神经网络。</td>   <td>1.一种基于自适应连接神经网络的图像处理方法,包括如下步骤：步骤S1,构建自适应连接神经网络,对输入的特征图,分别提取其像素级特征、局部特征以及全局特征,并自适应地融合所述像素级特征、局部特征、全局特征；步骤S2,于图像处理任务中,选择适用的深度卷积网络结构,将其中部分或全部卷积层替换成所述自适应连接神经网络的AC-Net模块,或直接使用所述自适应连接神经网络；步骤S1进一步包括：步骤S100,使用自变换操作提取所输入的特征图的像素级特征；步骤S101,使用卷积操作提取所输入的特征图的局部特征；步骤S102,使用多层感知器操作提取所输入的特征图全局特征；步骤S103使用AC-Net模块融合自变换操作得到的像素级特征、使用卷积操作得到的局部特征,以及使用多层感知器操作得到的全局特征,生成局部与全局自适应的特征；步骤S103进一步包括：步骤S103a,对得到的像素级特征、局部特征、全局特征进行自适应的加权求和操作；具体地,x为输入信号,即上一层得到的特征图,也即为自变换操作、卷积操作以及多层感知器操作的输入,则AC-Net模块得到的输出为：                  其中y-i表示AC-Net网络结构中输出信号的第i个数据点的输出,j为与第i个数据点相关的数据点的索引；第j个数据点可属于三个不同的集合,包括{第i个数据点自身},{第i个数据点的领域N(i)},{所有x上的数据点}；u-(ij),v-(ij),w-(ij)为可学习的参数,其中α,β,γ满足以下约束：α+β+γ＝1                                                      λ-α,λ-β,λ-γ为控制参数,可通过学习确定,是自适应的,其所对应的模块即为AC-Net模块；步骤S103b,对经步骤S103a得到的局部与全局自适应的特征做非线性激活。</td>   <td>G06V10/82;G06V10/764;G06V10/80;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              蔡祎俊;              李昊昕;                   陈立       </td>   <td>中山大学</td>   <td>基于交互建模的第一人称视角视频交互行为识别方法</td>   <td>广东省</td>   <td>CN111241963B</td>   <td>2023-07-14</td>   <td>本发明公开了一种基于交互建模的第一人称视角视频交互行为识别方法,提出对摄像头佩戴者和交互者进行分离,分别学习其对应的静态外观和动态运动特征,再显式建模二者之间的交互关系。为了将交互者从背景中分离出来,利用一个注意力模型生成掩码,并用人体解析模型辅助注意力模型的学习；提出一个运动模块分别预测摄像头佩戴者对应和交互者对应的运动信息矩阵,并通过对下一帧的重构辅助运动模块的学习。最后,提出一个用于交互建模的对偶长短时记忆模块,并在此模块基础上显式地建模交互关系。本发明能很好地对第一人称视角的交互行为进行描述和识别,并在常用的第一人称视角交互行为研究数据集上取得当前较优的识别结果。</td>   <td>1.基于交互建模的第一人称视角视频交互行为识别方法,其特征在于,包括下述步骤：S1、将摄像头佩戴者和交互者显式分离,分别学习二者的行为特征,包括：S1.1、通过注意力模块将交互者从背景中分离出来；S1.2、分别提取和学习摄像头佩戴者和交互者的行为特征,所述行为特征包括静态外观特征和动态运动特征；所述静态外观特征为摄像头佩戴者看见的静态视觉内容的特征,即对应摄像头佩戴者的视频帧I-t的全局外观特征,以及对应交互者的视频帧I-t的局部外观特征；S1.3、运动特征学习,对于摄像头佩戴者,其运动信息即为摄像头运动信息,该运动信息对视频帧变化的影响是全局性的；对于交互者,其运动信息对视频帧变换的影响是局部的,通过一个密集的运动矩阵D∈R～(H x W)来表示交互者的运动信息,并通过和注意力模块生成的掩码M-t～((3))逐渐相乘,使运动矩阵D只作用于交互者而不作用于背景；S1.4、对于每一对相邻的视频帧I-(t-1),I-t,通过上述的注意力模块和运动矩阵分别得到摄像头佩戴者对应的全局静态外观特征f-t～(g,a)和运动特征f-t～(g,m),以及交互者对应的局部静态外观特征f-t～(1,a)和运动特征f-t～(1,m),摄像头佩戴者的行为特征定义为f-t～(ego)＝[f-t～(g,a),f-t～(g,m)],交互者的行为特征定义为f-t～(exo)＝[f-t～(1,a),f-t～(1,m)],这两个特征将用于摄像头佩戴者和交互者之间的交互关系建模；S2、对偶交互关系建模；S2.1、构建用于交互建模的长短时记忆模块；步骤S2.1中,构建用于交互建模的长短时记忆模块具体为：摄像头佩戴者和交互者的个体行为特征分别输入对应的长短时记忆模块,这两个模块互为对偶模块,采用对称的更新方式：[i-t；o-t；g-t；a-t]＝σ(Wf-t+UF-(t-1)+J-(t-1)+b)                  c-t＝i-ta-t+g-tc-(t-1)F-t＝o-ttanh(c-t)其中i-t,o-t,g-t,a-t分别是长短时记忆模块的输入门限值,输出门限值,遗忘门限值和输入特征,σ是非线性函数sigmoid函数,Φ是线性整流函数,f-t是摄像头佩戴者或交互者的个体行为特征,ct是长短时记忆模块的中间特征,F-t则是对应的长短时记忆模块的输出特征,F-t～*是对偶模块的输出特征,V、b为长短时记忆模块的可学习参数；S2.2、用于交互建模的长短时记忆模块通过把对偶模块在上一帧的输出作为当前帧的输入,显式建模了摄像头佩戴者和交互者的交互关系；步骤S2.2中,还包括下述步骤：将两个长短时记忆模块在视频的最后一帧N时的输出逐点相加并通过非线性操作得到融合后的特征：                  在R-N上添加一个线性分类器,并通过softmax函数可以得到对应于各个行为类别的概率：p(y|R-N)＝softmax(WR-N+b)使用交叉熵损失函数对分类结果进行优化：                  其中y-k为类别k的标签,即如果行为类别编号为k,则y-k＝1,否则y-k＝0；K为总的类别数。</td>   <td>G06V40/20;G06V20/40;G06V10/764;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雅美;                   潘嵘       </td>   <td>中山大学</td>   <td>基于强化学习的生成式文本摘要方法</td>   <td>广东省</td>   <td>CN109271629B</td>   <td>2023-07-14</td>   <td>本发明涉及人工智能自然语言处理的技术领域,更具体地,涉及基于强化学习的生成式文本摘要方法。基于强化学习的生成式文本摘要方法,包括Actor部分与Critic部分,其中,包括以下步骤：S1.Actor部分用Seq2Seq方法生成摘要序列,Seq2Seq由编码器和解码器组成,同时应用了Attention机制；S2.Critic部分通过监督学习的方式估计Actor部分的状态价值V(s)；S3.不断重复步骤S1和步骤S2,使得Actor部分与Critic部分的网络参数不断优化,直到收敛；S4.最终Actor部分的模型即为文本摘要生成模型。本发明将Rouge评估指标通过强化学习方法融入到训练目标中,即最终的训练目标是最大似然和Rouge指标的加权平均。</td>   <td>1.基于强化学习的生成式文本摘要方法,包括Actor部分与Critic部分,其特征在于,包括以下步骤：S1. Actor部分用Seq2Seq方法生成摘要序列,Seq2Seq由编码器和解码器组成,同时应用了Attention机制；S2. Critic部分通过监督学习的方式估计Actor部分的状态价值V(s)；所述的步骤S2的具体过程是：S21.输入State和Action,经过一个三层神经网络后,输出对状态评分结果即状态价值V(s)；S22.根据状态价值与即时Reward的综合计算结果,得到该状态下对该Action的评估结果,用该结果指导Actor部分的概率输出；S23. Reward的计算是最大似然和Rouge指标的加权平均；S3.不断重复步骤S1和步骤S2,使得Actor部分与Critic部分的网络参数不断优化,直到收敛；S4. 最终Actor部分的模型即为文本摘要生成模型。</td>   <td>G06F40/30;G06F40/216;G06N3/0455;G06N3/092</td>  </tr>        <tr>   <td>中国专利</td>   <td>         单云霄;              张彧;                   陈龙       </td>   <td>中山大学</td>   <td>一种基于激光雷达和PTZ摄像机的目标追踪方法</td>   <td>广东省</td>   <td>CN110517284B</td>   <td>2023-07-14</td>   <td>本发明涉及一种基于激光雷达和PTZ摄像机的目标追踪方法。包括人工标定PTZ摄像机在多个静态姿态下与激光雷达的不同转移矩阵,基于这些转移矩阵推导PTZ摄像机动态情况下姿态与转移矩阵的映射关系；在追踪中利用IMU和PTZ摄像机姿态查询获取PTZ摄像机的实时姿态,基于前述映射关系实时确定PTZ摄像机和激光雷达的转移矩阵；根据实时确定的转移矩阵将点云转换成稀疏深度图,与摄像机图像进行特征融合后使用KCF算法进行目标追踪；基于目标追踪的模块的反馈,实时调整PTZ摄像机的姿态,保持追踪目标始终在画面中。本方法采用PTZ摄像机进行目标追踪,克服了智能机器人所搭载传统摄像机观测方向与机器人运动方向高度耦合的缺陷,提升了目标追踪算法的鲁棒性和准确性。</td>   <td>1.一种基于激光雷达和PTZ摄像机的目标追踪方法,其特征在于,包括以下步骤：S1.采集PTZ摄像机在多个静态姿态下的图像与激光雷达对应的点云；S2.利用上述图像和点云,在PTZ摄像机每个静态姿态下进行联合标定确定雷达坐标系与图像坐标系的关系；S3.基于转移矩阵推导PTZ摄像机动态情况下姿态与转移矩阵的映射关系；确定动态姿态下姿态与转移矩阵的映射关系的方法包括以下步骤：S31.假定PTZ摄像机中图像投影平面的旋转中心为摄像机初始姿态下图像到点云的映射关系为T-0,姿态变化量为R-(cam),姿态变化后图像到点云的映射关系为T-1；摄像机第二次运动可以由欧式变换表述：                  上式为姿态与转移矩阵的映射关系,其中为待求解变量；S32.改变PTZ摄像机姿态,进行N次记录；记姿态变化后图像到点云的映射关系为T-i＝[R-it-i]其中i∈[1,N],将PTZ摄像机不同姿态下与激光雷达的转换关系代入式(1.3)中并提取关于位移的部分,得到多组方程,联立所得方程组得到一组超定方程；S33.求解该超定方程得到旋转中心即可确定PTZ摄像机姿态与点云到图像转移矩阵的映射关系；S4.在追踪中对IMU和PTZ摄像机姿态查询结果进行融合,获取PTZ摄像机的实时姿态,并基于上述映射关系实时确定PTZ摄像机和激光雷达的转移矩阵；S5.根据实时确定的转移矩阵将点云转换成稀疏深度图,与摄像机图像进行特征融合后使用KCF算法进行目标追踪；S6.根据目标追踪模块的反馈结果,实时调整PTZ摄像机的姿态,保持追踪目标在画面中心。</td>   <td>G06T7/20;G06V10/80;G06V10/77;G01S17/66;G01S7/497</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金舒原;                   邵鹏飞       </td>   <td>中山大学</td>   <td>一种云环境下的用户信任度量方法及系统</td>   <td>广东省</td>   <td>CN113392385B</td>   <td>2023-07-14</td>   <td>本发明公开了一种云环境下的用户信任度量方法及系统,该方法包括：获取用户的身份凭据并根据身份凭据进行身份信任量化,得到身份信任值；获取用户的恶意行为信息并根据恶意行为信息进行行为信任量化,得到行为信任值；获取用户的评价信息并根据评价信息进行信誉信任量化,得到信誉信任值；根据身份信任值、行为信任值和信誉信任值进行用户信任量化,确定用户信任值。该系统包括：身份信任量化模块、行为信任量化模块、信誉信任量化模块和用户信任量化模块。通过使用本发明,降低用户之间串通合谋骗取高信任值的可能性。本发明作为一种云环境下的用户信任度量方法及系统,可广泛应用于网络安全领域。</td>   <td>1.一种云环境下的用户信任度量方法,其特征在于,包括以下步骤：获取用户的身份凭据并根据身份凭据进行身份信任量化,得到身份信任值；获取用户的恶意行为信息并根据恶意行为信息进行行为信任量化,得到行为信任值；针对特定的用户u,计算前p次访问请求中,每一种恶意行为出现的次数的平均值,计算公式如下：                  为矩阵中的每一个恶意行为计算变异系数,计算公式如下：                  计算每一个恶意行为的变异系数的影响,其计算公式如下：                  每一个恶意行为的权重计算公式如下：                  所述行为信任值的计算公式如下：                  上式中,表示行为信任值,ω-j表示第j个恶意行为对应权重,q表示确定的恶意行为的总数,Be-value-n＝{b-1,b-2,b-3,...,b-q}表示某一用户第n次访问请求中含有的恶意行为,/&gt;为行为信任评估矩阵,表示针对系统选取的j个衡量标准,用户u发起此次访问请求的前i次访问请求中出现的恶意行为；获取用户前p次访问请求的整体评价；根据整体评价中的用户访问请求被允许次数和被拒绝次数计算信誉信任值；所述信誉信任值的计算公式如下：                  上式中,表示信誉信任值,/&gt;表示用户u在当前访问请求发起的前p次访问请求中请求被允许的数量,/&gt;表示用户u在当前访问请求发起的前p次访问请求中请求被拒绝的数量；根据身份信任值、行为信任值和信誉信任值进行用户信任量化,确定用户信任值。</td>   <td>G06F21/31</td>  </tr>        <tr>   <td>中国专利</td>   <td>         石茜;              李昊洋;              秦晓蕾;                   林浩媚       </td>   <td>中山大学</td>   <td>NDVI时序数据重建方法及系统</td>   <td>广东省</td>   <td>CN116434050A</td>   <td>2023-07-14</td>   <td>本发明涉及农业监测领域,公开了一种NDVI时序数据重建方法及系统,所述方法包括：收集目标区域的哨兵1号SAR数据、哨兵2号光学数据和初始NDVI时序数据；对数据进行时间节点匹配,得到初始数据集；将初始数据集输入训练好的基于Transformer架构的时序数据重建网络,对哨兵1号SAR数据和哨兵2号光学数据进行深度耦合,并将耦合结果映射到初始NDVI时序数据中,重建出NDVI时序数据。本发明增强了SAR和光学数据之间的学习,构建出完整SAR数据和缺失光学数据之间的关系,并将耦合结果的上下文信息映射到初始NDVI时序数据中,以重建NDVI时序数据,填补了光学观测数据的空白,能够得到高精度且完整的NDVI时序数据。</td>   <td>1.NDVI时序数据重建方法,其特征在于,包括：收集目标区域的哨兵1号SAR数据、哨兵2号光学数据和初始NDVI时序数据；对目标区域的哨兵1号SAR数据、哨兵2号光学数据和初始NDVI时序数据进行时间节点匹配,得到初始数据集,并将所述初始数据集划分为训练集、验证集和测试集；利用所述训练集和验证集分别对基于Transformer架构的时序数据重建网络进行训练和调参,直至所述网络的损失函数收敛,得到训练好的时序数据重建网络；将测试集输入训练好的时序数据重建网络,对哨兵1号SAR数据和哨兵2号光学数据进行深度耦合,并将耦合结果映射到初始NDVI时序数据中,重建出NDVI时序数据。</td>   <td>G06V20/10;G06V20/13;G06V10/62;G06V10/80;G06V10/82;G06N3/045</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘阳;              严鸿;              李冠彬;              王青;                   林倞       </td>   <td>中山大学</td>   <td>一种基于掩码图自编码器的骨架序列识别方法及系统</td>   <td>广东省</td>   <td>CN116434347A</td>   <td>2023-07-14</td>   <td>本发明公开了一种基于掩码图自编码器的骨架序列识别方法及系统,包括步骤如下：建立骨架动作识别模型,利用骨架动作识别模型识别骨架序列,实现预测动作类别；所述的骨架动作识别模型包括一个M层的空间-时间表示学习模型和一层分类器；所述的空间-时间表示学习模型包括两个并联连接的掩码图自编码器,且掩码图自编码器的输出端通过1×1卷积与输入端进行残差连接。本发明将一个M层的空间-时间表示学习模型和一层分类器构建骨架动作识别模型,其利用不同骨架关节之间的细粒度依赖关系来训练学习,是一个高效的骨架序列学习模型,可以在不同的数据集上很好地泛化。</td>   <td>1.一种基于掩码图自编码器的骨架序列识别方法,其特征在于：所述的方法包括步骤如下：建立骨架动作识别模型,利用骨架动作识别模型识别骨架序列,实现预测动作类别；所述的骨架动作识别模型包括一个M层的空间-时间表示学习模型和一层分类器；所述的空间-时间表示学习模型包括两个并联连接的掩码图自编码器,且掩码图自编码器的输出端通过1×1卷积与掩码图自编码器的输入端进行残差连接。</td>   <td>G06V40/20;G06N3/0455;G06N3/0464;G06N3/048;G06N3/08;G06V10/34;G06V10/44;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         裴杰;              刘一博;                   邹耀鹏       </td>   <td>中山大学</td>   <td>一种作物产量统计数据降尺度方法</td>   <td>广东省</td>   <td>CN116432859A</td>   <td>2023-07-14</td>   <td>本申请涉及一种作物产量统计数据降尺度方法,其包括在研究时间范围内获取遥感变量影像数据；使用农作物空间分布数据对所述遥感变量影像数据进行掩膜处理,提取待估产区域；求取所述待估产区域的像元在县级尺度行政单元中的平均值,并获取待估产区域内各县各年的作物单产统计数据,得到模型训练自变量和模型训练因变量；构建Cubist模型；将所述模型训练因变量和所述模型训练自变量输入所述Cubist模型进行训练,输出达到预设精度的Cubist模型,作为产量预估模型；采用所述产量预估模型反演研究区域内像素尺度的农作物产量,获取更高分辨率的作物产量网格数据集。本申请具有提高产量预估模型预测精度的技术效果。</td>   <td>1.一种作物产量统计数据降尺度方法,其特征在于,包括以下步骤,在研究时间范围内获取各期的气象数据、植被指数数据和土壤数据,以及一期高程数据,作为遥感变量影像数据；使用农作物空间分布数据对所述遥感变量影像数据进行掩膜处理,提取待估产区域；求取所述待估产区域的像元在县级尺度行政单元中的平均值,得到与每个县区、每一年相对应的多元变量的统计数据,作为模型训练自变量,以及,将各县区待预测年份的前若干年产量数据作为模型训练自变量,并获取待估产区域内各县各年的作物单产统计数据,作为模型训练因变量；基于M5模型树的拓展算法,预设模型树组的数量参数和最近邻样本的数量参数,构建Cubist模型；将所述模型训练因变量和所述模型训练自变量输入所述Cubist模型进行训练,并进行精度验证,直至验证结果满足预设条件,输出达到预设精度的Cubist模型,作为产量预估模型；采用所述产量预估模型反演研究区域内像素尺度的农作物产量,获取作物产量网格数据集。</td>   <td>G06Q10/04;G06Q50/02;G06F18/214;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈生;              庞盈;                   胡俊俊       </td>   <td>中国科学院西北生态环境资源研究院;中山大学</td>   <td>一种基于闪电资料同化的降水预报方法及系统</td>   <td>甘肃省</td>   <td>CN115511192B</td>   <td>2023-07-14</td>   <td>本发明公开了一种基于闪电资料同化的降水预报方法及系统,方法包括对当前时刻的闪电定位数据、风云四号卫星的云顶高度数据和地面气象站的云底高度数据进行网格化预处理,获得网格化观测资料；根据网格化观测资料和当前模式背景场,进行水汽观测资料反演；将伪水汽观测资料、地面站观测资料和当前模式背景场,进行三维变分同化,获得当前时刻的分析场；在该分析场的基础上进行模式预报,获得下一时刻的预报场；将该预报场作为下一时刻的模式背景场,重复上述操作进行闪电资料循环同化,最终获得逐小时的降水预报。本实施例实现了减少对模式背景场的依赖,提高模式初始场的精确度,提高临近时刻的降水预报效果。</td>   <td>1.一种基于闪电资料同化的降水预报方法,其特征在于,包括：对当前时刻的气象数据进行网格化预处理,获得网格化观测资料；其中,所述气象数据包括闪电定位数据、云顶高度数据和云底高度数据；根据所述网格化观测资料和当前模式背景场,反演出伪水汽观测资料；所述根据所述网格化观测资料和当前模式背景场,反演出伪水汽观测资料,具体为：根据所述当前模式背景场和数值模式网格,获得全部模式格点；根据网格化闪电资料、网格化云顶资料和网格化云底资料,将各模式格点进行闪电判断和预设湿度调整,获得各模式格点的伪相对湿度；根据所述各模式格点的伪相对湿度,形成所述伪水汽观测资料;所述根据网格化闪电资料、网格化云顶资料和网格化云底资料,将各模式格点进行闪电判断和预设湿度调整,获得各模式格点的伪相对湿度,具体为：根据所述网格化闪电资料、所述网格化云顶资料和所述网格化云底资料,判断当前模式格点是否存在闪电；若所述当前模式格点没有闪电,则判断下一个模式格点是否存在闪电；若所述当前模式格点有闪电,则判断所述当前模式格点的有效高度内相对湿度是否满足预设湿度条件；其中,所述有效高度是当前模式格点的高度位于网格化的云底到云顶高度观测资料之间；若是,则将所述当前模式格点的所述相对湿度反演为预设湿度值,获得所述当前模式格点的伪相对湿度；若否,则不调整所述当前模式格点的所述相对湿度;将所述伪水汽观测资料、地面站观测资料和所述当前模式背景场,进行三维变分同化,获得所述当前时刻的分析场；其中,所述地面站观测资料根据地面气象站的地面气象数据,进行预设格式调整所形成；所述地面气象数据包括风速、风向、气温和气压；根据所述当前时刻的所述分析场,进行模式预报,得到下一时刻的预报场,获得所述下一时刻的降水预报;根据所述当前时刻的所述分析场,进行模式预报,得到下一时刻的预报场,获得所述下一时刻的降水预报,具体为：将所述当前时刻的所述分析场和预设侧边界条件,进行数值天气预报,得到所述下一时刻的预报场,获得所述下一时刻的降水预报；当获得所述下一时刻的降水预报之后,将所述下一时刻的预报场作为下一时刻的模式背景场,根据所述模式背景场和所述下一时刻的所述气象数据,进行基于闪电资料同化,获得再下一时刻的所述预报场,根据预设时刻和所述再下一时刻的所述预报场,循环进行所述基于闪电资料同化,获得所述预设时刻的降水预报结果。</td>   <td>G06Q10/04;G06T17/05;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         凌青;              钟淑鑫;              蒙伟光;              文秋实;              曾宪欣;                   冯业荣       </td>   <td>中山大学;中国气象局广州热带海洋气象研究所(广东省气象科学研究所)</td>   <td>基于注意力机制的时空神经网络雷达回波外推预报方法</td>   <td>广东省</td>   <td>CN112446419B</td>   <td>2023-07-11</td>   <td>本发明为基于注意力机制的时空神经网络雷达回波外推预报方法,包括：对雷达回波图像数据去除部分噪声,并选择出有效数据段,对数据段归一化和拆分后,划分为训练序列样本集和测试序列样本集；构建及训练Att-ConvLSTM网络,对雷达回波序列样本的图像根据预设的切片因子进行切片,调整图像的维度,然后输入到基于注意力机制的时空预测神经网络,通过多层网络的前向传播,利用反向传播更新网络权重；利用训练好的Att-ConvLSTM网络以及测试序列样本集进行预测,得到最终的外推图像序列。本发明克服了现有技术对空间信息提取不足、预报时效短的缺点,实现了准确度更高的雷达回波外推预测。</td>   <td>1.基于注意力机制的时空神经网络雷达回波外推预报方法,其特征在于,包括以下步骤：步骤1、数据预处理,对雷达回波图像数据,去除部分噪声,并选择出有效数据段,然后将数据段转换为归一化的灰度数据；基于归一化的数据集,对数据段进行拆分,然后将拆分的数据集划分为训练序列样本集和测试序列样本集；步骤2、构建及训练Att-ConvLSTM网络,对雷达回波序列样本的图像根据预设的切片因子进行切片,调整图像的维度,然后输入到基于注意力机制的时空预测神经网络,通过多层网络的前向传播,利用反向传播更新网络权重；步骤3、利用训练好的Att-ConvLSTM网络以及测试序列样本集进行预测,得到最终的外推图像序列；步骤2包括以下步骤：步骤2-1、训练参数初始化,设置输入图像的高度、宽度、通道数、切片因子、ST-ConvLSTM网络模块堆叠层数L、卷积核大小、卷积核数量、步长、隐藏层数量、学习率λ、输入序列长度W/2、外推序列长度W/2、训练阶段每次输入的样本数量和训练最大轮次,并初始化网络中的各个卷积核参数和偏差；其中,W为步骤1中数据段拆分时设置的滑动窗口大小；步骤2-2、构建神经网络：首先构建第1层的卷积层网络,设置卷积核W-(init)的尺寸大小、数量及步长；然后,根据步骤2-1设置的ST-ConvLSTM网络模块堆叠层数L、卷积核大小、步长、隐藏层数量,构建L层ST-ConvLSTM并按顺序依次堆叠在第一层卷积层网络之后；最后,在第L层ST-ConvLSTM后堆叠一层卷积层网络,设置卷积核W-(predict)的尺寸大小、数量及步长；步骤2-3、读取训练样本：采用批训练的方式,每次训练时从训练序列样本集中读取batch-size个序列样本一同作为网络的输入；步骤2-4、训练样本切片：对读取到的batch-size个序列样本根据切片因子,对序列中每一张图像进行切片；将切片后的数据一同作为网络的输入I-t,其中t＝1,2,3,...,W/2；步骤2-5、将I-t输入初始化网络的第1层卷积网络,经卷积运算后得到第1层网络的输出X-t；步骤2-6、将当前时刻上一层网络输出的隐藏态和时空记忆/&gt;上一个时刻同层网络输出的隐藏态/&gt;和细胞态/&gt;输入到网络的第k层时空卷积长短记忆力网络,经前向传播后得到当前时刻第k层时空卷积长短记忆力网络输出的隐藏态/&gt;细胞态/&gt;时空记忆/&gt;其中k＝1,2,...,L,/&gt;和/&gt;参数值通过初始化设定；步骤2-7、把步骤2-6输出的隐藏态输入最后的卷积预测层,输出网络的预测结果图像/&gt;步骤2-8、将步骤2-7输出的预测结果图像还原至原图像尺寸大小,将图像的高度和宽度分别乘以切片因子,通道数除以切片因子的平方,进行维度的调整,得到调整后图像的高度、宽度和通道数为三元组,完成从输入I-t到的雷达回波外推；步骤2-9、当t≥W/2时,将步骤2-8输出的作为输入,重复执行步骤2-6至步骤2-8,直至t＝W-1,依次得到预测未来时刻的图像序列/&gt;完成雷达回波序列外推；步骤2-10、计算损失函数值,对步骤2-6至步骤2-9前向传播得到的预测序列和外推参照序列ground-truths＝{I-(W/2+1),I-(W/2+2),...,I-W}计算均方误差作为损失函数,根据损失函数所得数值计算网络参数梯度,并更新网络参数,完成反向传播。</td>   <td>G06V10/774;G06V10/80;G06V10/82;G06N3/0442;G06N3/0464;G06N3/049;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              刘明阳;              陈小燕;                   林格       </td>   <td>中山大学</td>   <td>一种基于可定制语义的外观专利图像检索方法与系统</td>   <td>广东省</td>   <td>CN116415021A</td>   <td>2023-07-11</td>   <td>本发明公开了一种基于可定制语义的外观专利图像检索方法与系统。包括：从外观专利数据库中筛选并获取文本-专利对,并生成每个专利的外观专利图像所对应的手绘草图；利用ResNet方法对所述外观专利图像进行语义编码,构建语义特征库；构建并训练外观专利初次筛选模型；构建并训练外观专利最终筛选模型；用户输入待检索的关键词文本以及手绘草图,以关键词文本作为输入进行初次筛选,以可定制的手绘草图作为输入进行最终筛选,从而得到精准的外观专利检索结果。本发明基于人工智能的方式,混合使用文本和图像到专利的混合映射,同时实现外观专利检索的效率和精度,通过可定制语义的手绘草图搜图,更加有效地降低图像搜索的难度,提升检索细节的能力。</td>   <td>1.一种基于可定制语义的外观专利图像检索方法,其特征在于,所述方法包括：从外观专利数据库中筛选并获取文本(t)-专利(p)对,并生成每个专利(p)的外观专利图像所对应的手绘草图；利用ResNet方法对所述外观专利图像进行语义编码,使用预训练的卷积神经网络ResNet来获取所述外观专利图像p的语义特征并存储,构建语义特征库；构建并训练外观专利初次筛选模型,首先利用Glove词编码器对文本进行编码获得t′,然后利用长短期记忆网络方法对文本进行语义编码,得到文本语义特征再使用卷积神经网络将所述外观专利图像语义特征/&gt;和所述文本语义特征/&gt;映射到相同的语义子空间,分别得到/&gt;和/&gt;最后使用损失函数对网络模型进行训练,并形成外观专利初次筛选模型；构建并训练外观专利最终筛选模型,利用ResNet方法获取外观手绘草图s的语义特征然后将所述外观专利图像语义特征/&gt;和所述草图语义特征/&gt;映射到相同的语义子空间,分别获取/&gt;和/&gt;最后利用所述获取的/&gt;作为目标向量,使得/&gt;和/&gt;能够保留语义标签,并训练形成外观专利最终筛选模型；用户输入待检索的关键词文本,以及待检索的手绘草图,首先以关键词文本作为所述外观专利初次筛选模型的输入,进行检索以初次筛选外观专利,然后以可定制语义的手绘草图作为所述外观专利最终筛选模型的输入,在初次筛选出的外观专利的范围内进行检索以完成对外观专利的最终筛选,从而得到精准的外观专利检索结果。</td>   <td>G06F16/583;G06F40/30;G06F16/55;G06F40/126;G06F16/35;G06Q50/18;G06V10/764;G06V10/766;G06V10/82;G06N3/0464;G06N3/0442;G06N3/0475;G06N3/0499;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   许博智       </td>   <td>中山大学</td>   <td>一种基于纹理特征的深度伪造视频检测方法</td>   <td>广东省</td>   <td>CN112001429B</td>   <td>2023-07-11</td>   <td>本发明公开了一种基于纹理特征的深度伪造视频检测方法,该方法包括：将数据集进行视频分帧,得到训练集和测试集；对训练集和测试集中的视频帧图像进行人脸区域捕获并进行预处理,得到视频帧人脸区域图像训练集和视频帧人脸区域图像测试集；对训练集进行人脸子区域划分,提取训练人脸图像特征向量并训练分类模型,得到训练后的分类模型；对测试集进行人脸子区域划分,提取测试视频帧人脸图像特征向量,输入到训练后的分类模型得到分类结果。通过使用本发明,缩短对视频帧图像检测模型的训练时间的同时,保证较高的检测准确率。本发明作为一种基于纹理特征的深度伪造视频检测方法,可广泛应用于视频检测领域。</td>   <td>1.一种基于纹理特征的深度伪造视频检测方法,其特征在于,包括以下步骤：将含有真实人脸视频和深度伪造人脸视频的数据集进行视频分帧,得到视频帧图像并划分为训练集和测试集；对训练集和测试集中的视频帧图像进行人脸区域捕获并进行预处理,得到视频帧人脸区域图像训练集和视频帧人脸区域图像测试集；对视频帧人脸区域图像训练集进行人脸子区域划分,提取训练人脸图像特征向量并输入到SVM训练分类模型,得到训练后的分类模型；对视频帧人脸区域图像测试集进行人脸子区域划分,提取测试视频帧人脸图像特征向量,输入到经过训练后的分类模型得到测试视频帧分类结果；所述对视频帧人脸区域图像训练集进行人脸子区域划分,提取训练人脸图像特征向量并输入到SVM训练分类模型,得到训练后的分类模型这一步骤,其具体包括：对视频帧人脸区域图像训练集中的视频帧人脸区域图像进行人脸子区域划分,得到训练集人脸子区域；提取训练集人脸子区域的基于梯度域及标准差的纹理特征、基于灰度共生矩阵的纹理特征、基于小波变换的纹理特征,结合得到纹理特征向量；对纹理特征向量归一化,得到归一化后的纹理特征向量；将归一化后的纹理特征向量输入到SVM训练分类模型,得到训练后的分类模型；所述人脸子区域划分具体包括：对视频帧人脸区域图像,确定其子区域数量,获取人脸区域图像长度和人脸区域图像宽度,计算子区域图像长度和子区域图像宽度,将人脸区域图像平均划分为与子区域数量一致的、长度与子区域图像长度相等的且宽度与子区域图像宽度相等的视频帧人脸子区域图像；所述基于梯度域及标准差的纹理特征的提取方法具体为：对视频帧人脸子区域图像逐个像素点计算水平方向梯度和垂直方向梯度,利用水平方向和垂直方向梯度计算梯度幅值,对梯度幅值计算均值、标准差、峰度和偏度,对视频帧人脸子区域图像计算标准差,构成基于梯度域及标准差的纹理特征；所述基于灰度共生矩阵的纹理特征的提取方法具体为：对视频帧人脸子区域图像,计算得到多方向的灰度共生矩阵,对多方向的灰度共生矩阵的灰度共生矩阵分别计算对比度特征、相关性特征、能量特征、同质性特征和熵特征,最后对特征分别计算均值,构成基于灰度共生矩阵的纹理特征。</td>   <td>G06V10/75;G06V40/16;G06V10/30;G06V10/44;G06V10/764;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李水生;              王志威;              张勇;              张晋;              魏千皓;              张思琦;                   林浩然       </td>   <td>中山大学</td>   <td>一种石斑鱼图像分类识别方法</td>   <td>广东省</td>   <td>CN116416475A</td>   <td>2023-07-11</td>   <td>本发明公开了一种石斑鱼图像分类识别方法,其结合了Transformer和CNN,在其步骤一、二中,在采集不同环境中不同状态下的石斑鱼图像基础上,并应用数据增强,以扩增数据集；在步骤三构建模型中,分别利用CNN善于提取邻近像素点关系的特点和Transformer善于提取相距较远像素的关系的特点,能更好的获取石斑鱼的斑点分布情况,以对抗石斑鱼应激变色时,体色对于识别的影响。此外,在局部增强前馈网络模块中,对参数矩阵进行降维后,应用卷积进行采样,可以得到更多的信息,有利于提取不同品种的特点。本发明可更准确地识别不同的石斑鱼类品种,为石斑鱼类辨别、种质鉴定、保护和改良提供可靠的方法。</td>   <td>1.一种石斑鱼图像分类识别方法,其特征在于,包括以下步骤：步骤一、采集石斑鱼的图像,构建为数据集；步骤二、采用数据增强的方式扩充石斑鱼图像的数量,通过数据增强的方式将单张图片扩增成多个图像副本,增加训练样本量,进而提高网络的泛化性,减少过拟合；步骤三、构建模型,所述模型包括以下数据处理过程：将步骤二中经过数据增强扩增的图像通过运算模块,将运算模块输出的结果等分成2x2共四块,再转换成patchtokens向量,准备作为Transformer的输入；将得到的patchtokens向量,连续通过三组数据处理模块的处理,每组所述数据处理模块中依次包括标准化处理模块、多头自注意力模块、残差连接和标准化处理模块、局部增强前馈网络模块；步骤四、训练步骤三中的模型,将训练好的模型部署为后端服务。</td>   <td>G06V10/764;G06V20/05;G06V10/774;G06V10/82;G06V10/77;G06N3/0464;G06N3/048;G06N3/0499;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张式鸿;              王东;              方菲;              郑晓和;              陈少谦;              何宇婷;                   江晓冰       </td>   <td>中山大学附属第一医院</td>   <td>真空采血管签收装置及设备</td>   <td>广东省</td>   <td>CN219329024U</td>   <td>2023-07-11</td>   <td>本实用新型公开了一种真空采血管签收装置及设备,其装置包括电机驱动的用于传送真空采血管的传送皮带,在皮带的传送移动方向上,传送皮带一端上方设置视窗挡板；真空采血管和条码扫描仪位于视窗挡板的两侧,转动的传送皮带和视窗挡板形成一个夹角,真空采血管在夹角内转动；条码扫描仪透过视窗挡板扫描读取到转动的真空采血管管身圆周各个方向上条码信息。其设备包括框架和支撑架,框架与支撑架之间通过支撑转轴机构转动连接,支撑架上放置所述装置；条码扫描仪通过连接件固定安装在支撑架上,支撑架的底板底面通过曲柄摇摆机构带动支撑架围绕支撑转轴机构转动摇摆。本实用新型实现自动化扫描真空采血管的信息,提高工作效率,降低错误率。</td>   <td>1.真空采血管签收装置,包括皮带电机驱动的用于传送真空采血管的传送皮带,其特征在于,在传送皮带的传送移动方向上,传送皮带一端上方设置的视窗挡板；真空采血管和条码扫描仪位于视窗挡板的两侧,转动的传送皮带和视窗挡板形成一个夹角,真空采血管在夹角内转动；条码扫描仪透过视窗挡板扫描读取到转动的真空采血管管身圆周各个方向上条码信息。</td>   <td>G06K7/10;B65G15/00;G06K17/00</td>  </tr>        <tr>   <td>海外专利</td>   <td>         林韦至;              黎 邓庆泠;              范 功准;              阮 如湘安;                   吴东亿       </td>   <td>国立中山大学</td>   <td>METHOD FOR DECIDING OPTIMAL SPRAYING PARAMETERS</td>   <td></td>   <td>TWI808913</td>   <td>2023-07-11</td>   <td>A method for deciding optimal spraying parameters includes the following steps. A spraying system uses multiple spraying parameter groups to spray a crop with a water test paper disposed thereon. An image analysis is performed on droplets on the water test paper to obtain droplet counts respectively corresponding to the spray parameter groups and to obtain droplet coverage areas respectively corresponding to the spray parameter groups. A grey relational analysis (GRA) is performed on the droplet counts and the droplet coverage areas to obtain grey relational grades (GRG) respectively corresponding to the spray parameter groups. The grey relational grades are sorted to obtain an optimal spray parameter group corresponding to the largest one of the grey relational grades.</td>   <td></td>   <td>G06Q10/04;A01G25/00;G06Q50/02;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭晓军;              冯大鹏;              梁小丹;              王焕宇;              杨陈如诗;                   杨梦雨       </td>   <td>中山大学</td>   <td>一种基于多源数据知识迁移的三维物体检测框架</td>   <td>广东省</td>   <td>CN111507222B</td>   <td>2023-07-07</td>   <td>本发明提供了一种基于多源数据知识迁移的三维物体检测框架,通过将图像特征提取单元所提取处的图像特征输出,使感兴趣目标选择单元根据图像特征,输出感兴趣目标的点云数据至点云特征提取单元,由点云特征所从点云数据中提取点云特征,然后,在知识迁移单元中,使图像特征学习点云特征并更新图像特征提取单元的参数,而三维目标参数预测单元根据所述图像特征和点云特征更新所述图像特征提取单元和点云特征提取单元的参数,最后,由更新后的图像特征提取单元重新提取图像特征至三维目标参数预测单元,由三维目标参数预测单元根据所述图像特征,推算并输入三维参数,由此,提供了基于二维图像的三维物体检测的检测精度。</td>   <td>1.一种基于多源数据知识迁移的三维物体检测框架,其特征在于,包括以下步骤：S1、图像特征提取单元从图像中提取第一图像特征,并将所述第一图像特征输出至感兴趣目标选择单元、知识迁移单元和三维目标参数预测单元；S2、所述感兴趣目标选择单元根据所述第一图像特征,生成一系列的感兴趣目标的二维包围盒,以从点数空间中提取相应区域的点云数据以输出至点云特征单元；S3、所述点云特征提取单元从所述点云数据中提取点云特征,并将所述点云特征输出至所述知识迁移单元和三维目标参数预测单元；S4、所述知识迁移单元计算所述图像特征与所述点云特征两者之间的余弦相似度,并对所述余弦相似度进行处理,以更新所述图像特征提取单元的参数；S5、所述三维目标参数预测单元根据所述图像特征、所述点云特征生成三维包围盒,并输出所述三维包围盒的九个自由度参数,之后还通过反向传播更新所述图像特征提取单元、所述点云特征提取单元的参数；S6、二维检测器从所述图像中提取目标的候选边界框,并将所述候选边界框发送至所述图像特征提取单元；S7、所述图像特征提取单元从所述候选边界框中提取第二图像特征,并将所述第二图像特征输出至所述感兴趣目标选择单元、以及所述三维目标参数预测单元；S8、所述感兴趣目标选择单元根据所述第二图像特征,生成相应的二维包围盒,并输出所述相应的二维包围盒的中心坐标至所述三维目标参数预测单元；S9、所述三维目标参数预测单元根据所述第二图像特征、以及所述相应的二维包围盒的中心点坐标,生成相应的三维包围盒,并输出所述相应的三维包围盒的九个自由度参数。</td>   <td>G06V20/64;G06V10/25;G06V10/44;G06V10/82;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余伟江;              梁小丹;                   林倞       </td>   <td>中山大学</td>   <td>一种视觉问答任务实现方法及系统</td>   <td>广东省</td>   <td>CN111598118B</td>   <td>2023-07-07</td>   <td>本发明公开了一种视觉问答任务实现方法及系统,该方法包括：步骤S1,对输入图片提取视觉特征X-o,对输入的已知语句以及输入的候选回答语句进行特征提取,得到已知语言特征X-q和候选答案特征X-c；步骤S2,基于视觉因果关系推理更新每一个视觉特征,得到更新后的视觉实体特征X-g；步骤S3,将更新后的视觉实体特征X-g作为引导特征,对候选的候选答案特征X-c进行引导选择出视觉敏感的回答特征X-V；步骤S4,将已知语言特征X-q作为引导特征,对候选答案特征X-c进行引导选择出语言敏感的回答特征X-L；步骤S5,将步骤S3和步骤S4产生的两种特征进行融合,进而预测最后的模型结果,输出正确的回答。</td>   <td>1.一种视觉问答任务实现方法,包括如下步骤：步骤S1,对输入图片提取视觉特征X-o,对输入的已知语句以及输入的候选回答语句进行特征提取,得到已知语言特征X-q和候选答案特征X-c；步骤S2,基于视觉因果关系推理更新每一个视觉特征,得到更新后的视觉实体特征X-g；步骤S3,将更新后的视觉实体特征X-g作为引导特征,对候选的候选答案特征X-c进行引导选择出视觉敏感的回答特征X-V；步骤S4,将已知语言特征X-q作为引导特征,对候选答案特征X-c进行引导选择出语言敏感的回答特征X-L；步骤S5,将步骤S3和步骤S4产生的两种特征进行融合,进而预测最后的模型结果,输出正确的回答；步骤S2进一步包括：步骤S200,初步构建视觉特征间的语义关联关系；步骤S201,基于视觉特征X-o、已知语言特征X-q和候选答案特征X-c,利用语言层面的问答因果关系生成视觉因果关系；步骤S202,根据生成的视觉因果关系,采用视觉因果关系推理来更新每一个视觉特征；步骤S201进一步包括：将已知语言特征X-q和候选答案特征X-c进行串联,通过长短期记忆网络对语言问答特征间的因果关系进行建模,得到初步的问答因果关系表征X-(qc)；利用该问答因果关系表征X-(qc)嵌入到视觉特征X-o,构建每一个视觉实体和对应问答因果关系间的关联X-(oqc),搭建起视觉实体和语言因果关系的桥梁；利用自注意力机制的操作结合矩阵乘法的操作,进一步生成视觉因果关系A-g；步骤S3进一步包括：融合更新后的视觉实体特征X-g和候选答案特征X-c,得到一个中间特征X-(gc)；利用归一化表征进行投票学习得到和候选答案相关性强的若干视觉实体表征的关系X-(Vα)；利用该关系X-(Vα)作用于更新后的视觉实体特征X-g得到最终的视觉敏感的回答特征X-V。</td>   <td>G06F16/332;G06V10/40;G06V10/80;G06N5/04;G06N3/0442;G06N3/0455;G06N3/084;G06N3/042</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              陈炳成;                   林倞       </td>   <td>中山大学</td>   <td>一种对话系统中的句子多样性生成方法及系统</td>   <td>广东省</td>   <td>CN110866103B</td>   <td>2023-07-07</td>   <td>本发明公开了一种对话系统中的句子多样性生成方法及系统,所述方法包括如下步骤：步骤S1,提取回答句子的依存树,并将所述依存树转为无向图；步骤S2,将所述回答句子和步骤S1获得的无向图输入图结构转换器,得到所述回答句子的特征向量；步骤S3,使用所述序列结构转换器提取所述回答句子的对话历史的特征向量；步骤S4,将步骤S2获得的所述回答句子的特征向量和步骤S3获得的对话历史的特征向量输入条件变分自动编码器,得到所述对话历史的新的回答句子,本发明可提高对话系统中句子生成的多样性。</td>   <td>1.一种对话系统中的句子多样性生成方法,包括如下步骤：步骤S1,提取回答句子的依存树,并将所述依存树转为无向图；步骤S2,将所述回答句子和步骤S1获得的无向图输入图结构转换器,得到所述回答句子的特征向量；步骤S3,使用序列结构转换器提取所述回答句子的对话历史的特征向量；步骤S4,将步骤S2获得的所述回答句子的特征向量和步骤S3获得的对话历史的特征向量输入条件变分自动编码器,得到所述对话历史的新的回答句子；若所述回答句子有n个单词,则所述回答句子的邻接矩阵为维度为n*n的矩阵M,所述邻接矩阵M中第i行第j列的值M-(ij)由以下条件决定：                  步骤S2进一步包括：步骤S200,对所述回答句子的特征V和无向图的邻接矩阵M进行Graph Attention操作；对于第i个单词的特征向量V-i,Graph Attention对其进行如下计算：                                    其中M-(ij)是步骤S1中的邻接矩阵M的第i行第j列的值；步骤S201,将Graph Attention操作的结果与特征V相加,进行层归一化操作；步骤S202,将步骤S201的结输入一层前馈神经网络,并再进行层归一化操作,进而得到所述回答句子的特征向量。</td>   <td>G06F16/332;G06F16/35;G06F18/2411</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭素素;              谢晓华;                   龚文勇       </td>   <td>中山大学</td>   <td>一种猴脸多属性联合识别方法</td>   <td>广东省</td>   <td>CN110414298B</td>   <td>2023-07-07</td>   <td>本发明公开一种猴脸多属性联合识别方法,包括：构建猴脸样本数据库：采集猴子视频和图片资料进行处理,基于Matlab生成猴脸样本数据库,且所有样本都具有猴属性类别的人工标记；生成人脸属性识别预训练模型：根据恒等映射的扰动的学习建立人脸属性识别预训练模型的ResNet50；训练猴脸多属性联合识别模型：基于MXNet平台,在人脸属性识别预训练模型的基础上,再利用猴脸样本数据库进行调优训练,获得猴脸多属性联合识别模型。本发明可以根据年龄和性别属性的共同特征实现同时识别两个属性的目标。</td>   <td>1.一种猴脸多属性联合识别方法,其特征在于,包括如下步骤：S10构建猴脸样本数据库：采集猴子视频和图片资料进行处理,基于Matlab生成猴脸样本数据库,且所有样本都具有猴属性类别的人工标记；对采集的猴子视频和图片资料进行处理的步骤包括：S101每隔5帧读取一次视频资料,在所读取的帧中,找到存在猴脸的帧,使用矩形框截取猴脸图像,将其名字、帧索引、坐标信息记录其记录文档；S102保存所截取的猴脸图像及其记录文档；S20生成人脸属性识别预训练模型：根据恒等映射的扰动的学习建立人脸属性识别预训练模型ResNet50；S30训练猴脸多属性联合识别模型：基于MXNet平台,在人脸属性识别预训练模型的基础上,再利用猴脸样本数据库进行调优训练,获得猴脸多属性联合识别模型；具体包括：S301训练集和测试集的准备：将用于年龄和性别联合识别训练的总样本按5:1的比例分为训练集和测试集,并确定训练集和测试集的记录文档为记录数据集的路径和类标清单的.lst格式文档,通过DOS操作系统将记录文档的.lst格式文档转化为.rec格式文档；S302导入人脸属性识别预训练模型的resnet-50-0000.params文件,并其flatten层后面添加用于年龄识别的fc1层以及其对应的softmax1层,及在flatten层后面并行添加用于性别识别的fc2层以及其对应的softmax2层,及将softmax1层和softmax2层组合成一个最终的softmax层,用于最终识别结果的输出；S303根据猴脸样本数据库设定猴脸多属性联合识别模型的调优训练参数；S304数次迭代训练,获得猴脸多属性联合识别模型。</td>   <td>G06V40/10;G06V10/774;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         冯诗睿;              吴恙;              李冠彬;                   林倞       </td>   <td>中山大学</td>   <td>一种用于具现化场景问答任务的动作决策模型及方法</td>   <td>广东省</td>   <td>CN111539292B</td>   <td>2023-07-07</td>   <td>本发明公开了一种用于具现化场景问答任务的动作决策模型及方法,所述模型包括：预训练特征提取模组单元,用于对当前时间节点下的多模态输入特征分别进行提取；特征融合单元,用于将由多模态中提取出来的各个特征进行融合形成融合特征；融合特征解码单元,用于将当前时间节点融合特征向量解码为动作空间下的概率分布序列；时序融合动作决策单元,用于将当前及先前时间节点所获得的动作空间下的概率分布序列进行融合,根据融合得到的动作决策向量中的最大值对应的动作做出当前的动作决策。</td>   <td>1.一种用于具现化场景问答任务的动作决策模型,包括：预训练特征提取模组单元,用于对当前时间节点下的多模态输入特征分别进行提取；特征融合单元,用于将由多模态中提取出来的各个特征进行融合形成融合特征；融合特征解码单元,用于将当前时间节点融合特征向量解码为动作空间下的概率分布序列；时序融合动作决策单元,用于将当前及先前时间节点所获得的动作空间下的概率分布序列进行融合,根据融合得到的动作决策向量中的最大值对应的动作做出当前的动作决策；视觉特征提取模组进一步包括：视觉感知信息提取模块,用于使用预训练多任务卷积神经网络提取输入图像中的语义信息、深度信息,编码为所述感知信息向量；视觉启发信息提取模块,用于使用预训练启发卷积神经网络提取输入图像中的启发信息,编码为所述启发信息向量；所述视觉感知信息提取模块与视觉启发信息提取模块均选用U-Net结构的卷积神经网络模型,利用在House3D环境中图像分割和深度信息预训练得到的模型参数作为所述视觉感知信息提取模块的模型参数,利用在EQA-v1数据集上使用路径信息生成的路径掩膜训练得到的模型参数作为所述视觉启发信息提取模块的模型参数；所述特征融合单元利用串接的方式将所述预训练特征提取模组单元所提取的特征向量进行连接,形成当前时间节点下的融合特征向量；所述融合特征解码单元利用双层长短期记忆网络,通过复制所述融合特征向量作为每一层长短期记忆网络的隐藏层初始值,然后以一个开始标识符作为初始输入,由长短期记忆网络执行解码过程,当前长短期记忆网络单元的输出作为下一长短期记忆网络单元的输入,直至长短期记忆网络单元的输出为终止符或者达到解码长度上限,以将当前时间节点融合特征向量解码为动作空间下的概率分布序列。</td>   <td>G06V20/70;G06V10/26;G06V10/80;G06V10/82;G06F16/332;G06N3/0464;G06N3/0455;G06N3/0985</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              刘梦梦;              刘凌波;                   林倞       </td>   <td>中山大学</td>   <td>一种城市道路交通流量图生成方法、系统及设备</td>   <td>广东省</td>   <td>CN113094422B</td>   <td>2023-07-07</td>   <td>本发明公开了一种城市道路交通流量图生成方法、系统及设备。本发明通过将第一编码器生成交通路网特征图以及第二编码器生成的第二交通流量特征图输入到解码器中进行解码,生成第三交通流量特征图,并基于第一交通流量特征图以及第三交通流量特征图,生成细粒度交通流量图。本发明通过将第一编码器生成交通路网特征图作为生成细粒度交通流量图的先验知识,并在解码器中显式编码先验知识,充分发挥了先验知识在生成细粒度交通流量图中的指导作用,充分发掘了城市交通流量分布模式,在高清晰度的城市交通流量图生成任务上能取得优越的性能和准确度。</td>   <td>1.一种城市道路交通流量图生成方法,其特征在于,包括以下步骤：获取目标区域的粗粒度交通流量图、目标区域的环境数据以及目标区域的交通地图；将所述粗粒度交通流量图以及所述交通地图输入到第一编码器中进行编码,生成交通路网特征图；所述将所述粗粒度交通流量图以及所述交通地图输入到第一编码器中进行编码,生成交通路网特征图的具体过程为：基于所述交通地图,生成交通路网图；将所述交通路网图与所述粗粒度交通流量图进行加权,得到加权后的第一交通路网图,将所述第一交通路网图输入到第一编码器中,以使所述第一编码器对所述第一交通路网图中的道路特征进行编码,得到交通路网特征图；所述第一编码器对所述第一交通路网图中的道路特征进行编码,得到交通路网特征图的具体过程为:所述第一编码器分别对所述第一交通路网图进行水平卷积、垂直卷积、正对角卷积以及反对角卷积,生成水平特征、垂直特征、正对角特征以及反对角特征,基于所述水平特征、所述垂直特征、所述正对角特征以及所述反对角特征得到交通路网特征图；基于所述交通路网特征图、所述环境数据以及粗粒度交通流量图,生成第一交通流量特征图；将所述第一交通流量特征图输入到第二编码器中进行编码,生成第二交通流量特征图；将所述第二交通流量特征图以及所述交通路网特征图输入到解码器中进行解码,生成第三交通流量特征图；基于所述第一交通流量特征图以及所述第三交通流量特征图,生成细粒度交通流量图。</td>   <td>G06F16/26;G06F16/29;G06N3/0455;G06N3/042;G06N3/0464;G06N3/048;G06N3/084;G06N5/04;G06F18/25;G06Q50/26;G08G1/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;                   朱坤鑫       </td>   <td>中山大学</td>   <td>一种基于证据融合理论的室内地标更新方法及装置</td>   <td>广东省</td>   <td>CN112766122B</td>   <td>2023-07-07</td>   <td>本发明公开了一种基于证据融合理论的室内地标更新方法及装置,该方法包括：获取用户上传的地标视频,从地标视频中提取视频序列帧,并将视频序列帧转换成视频分数值；将视频分数值代入用户预设的猜想场景函数式,得到猜想场景概率值；对猜想场景概率值进行一阶融合计算和二阶融合计算,得到二阶猜想场景概率值,采用猜想场景概率值进行二阶数据冲突计算得到二阶数据冲突指标值；当二阶猜想场景概率值满足预设的变化值要求且二阶数据冲突指标值满足预设的冲突指标值时,确定用户达到的待更新的室内地标发生变化；将视频序列帧替换预存的序列帧,完成室内地标更新的操作。本发明可以根据地标视频实现地标的自动更新,从而减少更新所需的时间和成本。</td>   <td>1.一种基于证据融合理论的室内地标更新方法,其特征在于,所述方法包括：获取用户上传的地标视频,从所述地标视频中提取视频序列帧,并将所述视频序列帧转换成视频分数值,其中,所述地标视频为用户达到待更新的室内地标后拍摄的视频；将所述视频分数值代入用户预设的猜想场景函数式,得到猜想场景概率值；对所述猜想场景概率值进行一阶融合计算和二阶融合计算,得到二阶猜想场景概率值,采用所述猜想场景概率值进行二阶数据冲突计算得到二阶数据冲突指标值；当所述二阶猜想场景概率值满足预设的变化值要求且所述二阶数据冲突指标值满足预设的冲突指标值时,确定用户达到的待更新的室内地标发生变化；将所述视频序列帧替换预存的序列帧,完成室内地标更新的操作；用户定义的猜想场景包括不变场景、变化场景和无法识别场景；所述猜想场景概率值包括：不变场景概率值、变化场景概率值/&gt;和无法识别概率值/&gt;；不变场景概率值、变化场景概率值/&gt;和无法识别概率值/&gt;[SH1]相加等于1；具体计算如下式所示：          ；          ；          ；其中,n为地标,l为用户,为视频分数值；所述对所述猜想场景概率值进行一阶融合计算和二阶融合计算,得到二阶猜想场景概率值,包括：采用预设的最大冲突值分别与所述变化场景概率值和所述无法识别概率值进行一阶融合计算,得到一阶猜想场景概率值；采用预设的平均置信度、预设的冲突减函数值和一阶融合概率值进行二阶融合计算,得到二阶猜想场景概率值；其中所述一阶融合计算的公式如下所示：          [SH2]其中,为一阶猜想场景概率值,/&gt;为预设的最大冲突值表示所有用户数据的最大冲突值；所述二阶融合计算的公式如下所示：                            为二阶猜想场景概率值,/&gt;为预设的平均置信度,/&gt;为冲突减函数值。</td>   <td>G06V20/40;G06V10/80;G06F16/29;G06F16/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘小平;              赵林峰;                   曾莉       </td>   <td>中山大学</td>   <td>一种基于FLUS模型和生物多样性模型的变化情景模拟方法</td>   <td>广东省</td>   <td>CN113222316B</td>   <td>2023-07-07</td>   <td>本发明公开了一种基于FLUS模型和生物多样性模型的变化情景模拟方法,本发明集成了旧土地利用模拟模型的优势,消除了误差传递、改良了模型的内部的现实意义不明确的参数；FLUS模型中引入的神经网络算法计算各类用地的分布概率,再使用轮盘赌机制引入土地利用类型的竞争,实现了智能算法和不确定性机制的结合并同时应用于未来土地利用情景预测中；最终用更少的数据、更少的参数、更快的速度获取了精确度比旧土地利用模拟模型更高的模拟结果；生物多样性模型中的生态系统服务模型、物种分布模型和生物多样性指数模型计算各指标,能定量评估未来情景下的土地利用对生物多样性的影响；设置不同情景下的目标要求,能模拟获得符合情景目标的土地利用。</td>   <td>1.一种基于FLUS模型和生物多样性模型的变化情景模拟方法,其特征在于,所述方法包括两个阶段：使用土地利用模拟模块模拟土地利用阶段；通过生物多样性变化定量评估模块评估土地利用对生物多样性影响阶段；具体步骤为：使用土地利用模拟模块模拟土地利用阶段：S1：获取初始土地高分影像并进行预处理,对预处理后的高分影像解译得到分类后的影像,从分类后的影像获取初始土地利用数据；之后选取若干影响土地利用变化的驱动力因子组成驱动力数据；S2：对初始土地利用数据规定好模拟区域的范围与标准栅格影像大小,用欧式距离公式计算模拟区域内栅格到土地利用变化驱动因子的距离,生成与标准栅格影像图幅大小一致的栅格距离数据；S3：在驱动力数据与初始土地利用数据上进行随机点采样,获得采样数据；S4：使用采样数据对参数自适应神经网络算法进行训练；S5：将全部的驱动力数据输入训练好的神经网络,通过神经网络计算获得每种土地利用类型在模拟区域内的分布概率；S6：将S5输出的分布概率与S1中的初始土地利用数据在土地利用模拟模块中进行迭代；迭代前设定好邻域大小、转换限制矩阵和每种用地类型的像元个数；S7：迭代扫描初始土地利用数据的像元,计算每个像元在邻域内包含的土地利用类型和在邻域内所占的比例,与S5输出的分布概率、转换限制矩阵共同合成每个像元上各类土地利用类型的总分布概率；S8：将每个像元上的各类土地利用类型的总分布概率构成轮盘,通过轮盘赌的方法,使区域内各种土地利用类型在像元上竞争,竞争获胜的土地利用类型占据该像元；S9：转到步骤S7,直至迭代完一幅影像的全部有效像元,所述有效像元即土地利用数据中像元值不为空值的像元,然后返回S6刷新初始影像进入下一次迭代,计算到目标像元数目的差值；到达迭代次数R或者达到目标像元数目后,停止迭代输出模拟的土地利用结果；通过生物多样性变化定量评估模块评估土地利用对生物多样性影响阶段：S10：对模拟的土地利用结果和初始土地利用数据进行计算,获得土地利用转换矩阵；S11.将模拟的土地利用结果和生态系统服务数据输入生态系统服务模型,计算获得固碳释氧和水源涵养价值；生态系统服务模型中的固碳释氧价值是固碳和释氧价值的总和,公式表示为：                  其中V-(co)为固碳释氧价值；P-(NP,i)为第i种植被类型的净初级生产力；P-c为市场固定二氧化碳价格,采用造林成本法和碳税法成本价的平均值753元·t～(-1)；P-o为市场固定氧气价格,采用造林成本法和工业制氧法成本价的平均值330元·t～(-1)；水源涵养价值用来评估生态系统水源涵养服务价值,公式表示为：WR＝NPP×F-(sic)×F-(pre)×(1-F-(slo))×P其中WR为生态系统水源涵养服务价值；NPP为植被净初级生产力；F-(sic)为土壤渗流因子；F-(pre)为多年平均降水量因子；F-(slo)为坡度因子；P为水库库容建设成本,取为0.67元/m～3；S12.将模拟的土地利用结果和物种分布数据输入物种分布模型,计算获得生境适宜性和生境破碎化指数；S13.将模拟的土地利用结果和生物多样性指数数据输入生物多样性指数模型,计算获得生物丰度和平均物种丰度指数；S14.将S10中的土地利用转换矩阵、S11中的固碳释氧和水源涵养价值、S12中的生境适宜性和生境破碎化指数、S13中的生物丰度和平均物种丰度指数组成生物多样性指标定量评估结果,在评估前设定好情景方案,根据不同情景输出对于的情景模拟结果：若为驱动力情景,不受其他条件约束,评估结果直接输出作为生物多样性情景模拟结果；若为保护目标情景,受生物多样性保护目标的约束,未达到目标要求则转到S6重新进行土地利用迭代模拟,满足目标要求后则输出情景模拟结果；若为多目标情景,受城市发展目标和生物多样性保护目标的共同约束,未达到目标要求则转到S6重新进行土地利用迭代模拟,满足目标要求后则输出情景模拟结果。</td>   <td>G06Q10/063;G06Q50/26;G06V10/764;G06V10/82;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;              庄博伟;                   胡淼       </td>   <td>中山大学</td>   <td>一种用于边缘视频分析的分布式神经网络模型划分方法</td>   <td>广东省</td>   <td>CN112434789B</td>   <td>2023-07-07</td>   <td>本发明提供一种用于边缘视频分析的分布式神经网络模型划分方法,包括以下步骤：S1：构建异构边缘视频分析模型；S2：通过异构边缘视频分析模型接收视频分析任务,并对所接收的视频分析任务进行解析得到视频特征值；S3：根据视频分析任务选择执行视频分析任务的深度神经网络模型,并根据所选的深度神经网络模型对当前环境进行测量,得到环境特征值；S4：将视频特征值和环境特征值输入深度强化学习模型中,得到输出结果；S5：根据输出结果得到任务调度与模型划分的决策。本发明提供一种用于边缘视频分析的分布式神经网络模型划分方法,通过深度强化学习模型得到任务调度与模型划分的决策,解决了目前利用边缘计算进行视频分析的效率不够高的问题。</td>   <td>1.一种用于边缘视频分析的分布式神经网络模型划分方法,其特征在于,包括以下步骤：S1：构建异构边缘视频分析模型；所述异构边缘视频分析模型包括深度神经网络模型和深度强化学习模型；S2：通过异构边缘视频分析模型接收视频分析任务,并对所接收的视频分析任务进行解析得到视频特征值；S3：根据视频分析任务选择执行视频分析任务的深度神经网络模型,并根据所选的深度神经网络模型对当前环境进行测量,得到环境特征值；S4：将视频特征值和环境特征值输入深度强化学习模型中,得到输出结果,并根据输出结果设置奖励对智能体进行训练；其中,通过以下公式设置奖励：τ＝ω-T·τ-T+ω-P·τ-Pτ-T＝T-(local)-T-(all)τ-P＝P-(local)-P-(all)其中,τ表示智能体通过行动获得的奖励,τ-T表示在延迟方面的奖励,τ-P表示在能耗方面的奖励,ω-T表示在延迟方面的奖励权重,ω-P表示在能耗方面的奖励权重,且ω-T+ω-P＝1；T-(local)＝T(ES-i,L-0)为仅在边缘端执行的延迟,L-0表示不进行模型划分；T-(all)为实际行动后算得的总延迟,即T(ES-i,L-j)；P-(local)＝P(ES-i,L-0)为仅在边缘端执行的资源消耗；P-(all)为实际行动后算得的总资源消耗,即P(ES-i,L-j)；通过以下步骤计算得到总延迟T(ES-i,L-j)和总资源消耗P(ES-i,L-j)：最小化视频分析任务的代价函数,表示为：                  其中,代价函数由总延迟与总资源消耗两部分组成,表示为：C-J(ES-i,L-j)＝T-J(ES-i,L-j)+P-J(ES-i,L-j)总延迟包含在边缘服务器ES-i处理任务的时间t-(es),边缘服务器将中间输出数据传输到云服务器,加上云服务器将运行结果返回给边缘服务器所需要的时间t-(trans),以及在云服务器处理剩余任务步骤的时间t-(cs),另外,总延迟还包括在边缘端或云端等待发送或等待接收的时间t-(wait)；因此,总延迟表示为：                  其中,L-j为模型划分点；传输时间为t-(trans)＝S-j/B+S′/B′,S′为云服务器返回结果的数据大小,B和B′分别为边缘端与云端来回传输时的网络带宽状况；假设云服务器有着丰富的计算资源且资源消耗不计入计算成本,因此对于边缘服务器,使用每帧的平均GPU处理时间t-(avg-gpu)作为资源消耗的度量标准,则总资源消耗表示为：P(ES-i,L-j)＝K·t-(avg-gpu)；S5：根据输出结果得到任务调度与模型划分的决策。</td>   <td>G06N3/0464;H04N7/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁朝峰;              欧云谋;              徐达政;              龚瑾;              张保豫;              吴登军;                   郭英       </td>   <td>中山大学附属第三医院</td>   <td>一种数字化颅脑标本血管模型重建方法</td>   <td>广东省</td>   <td>CN116402948A</td>   <td>2023-07-07</td>   <td>本发明公开了一种数字化颅脑标本血管模型重建方法,该方法包括以下步骤：获取离体的颅脑标本,将该颅脑标本的血管与体外循环灌注系统连接,启动体外循环灌注系统将造影剂灌注至颅脑标本的血管内形成闭环循环；采用扫描成像模块获取该颅脑标本的图像数据,并将该图像数据输入至数字化建模模块中,重建出含有血管信息的数字化颅脑标本三维模型,再对颅脑标本进行封存；将数字化颅脑标本三维模型导入手术导航模块进行处理,得到含有血管信息的数字化颅脑标本模型与离体的颅脑标本的一致性结果。本发明具有能够实现离体的颅脑标本的体外造影剂灌注循环以便于对该颅脑标本进行血管成像、进而得到含有血管信息的数字化颅脑标本模型的优点。</td>   <td>1.一种数字化颅脑标本血管模型重建方法,其特征在于,该方法包括以下步骤：S1、获取离体的颅脑标本,将该颅脑标本的颈总动脉和椎动脉与体外循环灌注系统(1)的输出端连接,将该颅脑标本的血管的颈内静脉与体外循环灌注系统(1)的输入端连接,启动体外循环灌注系统(1)工作将造影剂灌注至颅脑标本的血管内形成闭环循环以实现离体的颅脑标本的体外造影剂灌注循环；S2、在颅脑标本的体外造影剂灌注循环的作用下使造影剂在血管内正常流动,采用扫描成像模块(2)获取该颅脑标本的图像数据并将该图像数据输入至数字化建模模块(3)中重建出含有血管信息的数字化颅脑标本三维模型,再对颅脑标本的血管的颈总动脉以及椎动脉、颈内静脉分别灌注预设比例的不同染料的乳胶悬液进行封存；S3、将重建得到的数字化颅脑标本三维模型导入手术导航模块(4)中,利用手术导航模块(4)显示数字化颅脑标本三维模型,同时指引数字化颅脑标本三维模型的血管位置并将该血管位置与解剖的血管的实际空间位置按照预设的标准进行对比,从而得到对比的偏移结果,当偏移结果不符合预设的对比标准时,则数字化颅脑标本三维模型的血管与真实血管实际空间位置不吻合,反之,则数字化颅脑标本三维模型的血管与真实血管实际空间位置相吻合,进而得到含有血管信息的数字化颅脑标本三维模型与离体的颅脑标本的一致性结果。</td>   <td>G06T17/00;G06T19/20;G16H30/40;G09B23/30;G09B23/28</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王嘉辉;              孙梓瀚;              郭祥;              江灏;                   蔡志岗       </td>   <td>中山大学</td>   <td>一种基于前后融合成像的三维重建系统及方法</td>   <td>广东省</td>   <td>CN111652967B</td>   <td>2023-07-04</td>   <td>本发明公开一种基于前后融合成像的三维重建系统,包括框体、融合成像模块、三维重建模块,框体存在承载空间,所述的承载空间用于放置物品；融合成像模块拍摄物品的前景图像和物品的后景图像,融合成像模块设置在框体的内侧,融合成像模块与框体连接；三维重建模块通过物品的前景图像和物品的后景图像,结合得到物品的三维模型,三维重建模块与融合成像模块电连接。本发明还公开了一种基于前后融合成像的三维重建方法,包括以下步骤：S1：在承载空间中放置标定物,根据标定物调整融合成像模块的内参数和外参数以及调整三维重建模块的坐标变换矩阵；S2：取出标定物,在标定物的位置上放置目标物品,通过调整后三维重建系统形成物品的三维模型。</td>   <td>1.一种基于前后融合成像的三维重建系统,用于形成物品的三维模型,其特征在于,包括框体、融合成像模块、三维重建模块,其中,所述的框体存在承载空间,所述的承载空间用于放置物品；所述的融合成像模块拍摄物品的前景图像和物品的后景图像,融合成像模块设置在框体的内侧,融合成像模块与框体连接；所述的三维重建模块通过物品的前景图像和物品的后景图像,结合得到物品的三维模型,三维重建模块与融合成像模块电连接；所述三维重建系统应用的一种基于前后融合成像的三维重建方法,包括以下步骤：S1：在承载空间中放置标定物,根据标定物调整融合成像模块的内参数和外参数以及调整三维重建模块的坐标变换矩阵；S2：取出标定物,在标定物的位置上放置目标物品,通过调整后三维重建系统形成物品的三维模型；所述的S2包括以下子步骤：S2.1：取出标定物,在标定物的位置上放置目标物品,融合成像模块获取目标物品的前景图像和后景图像,将前景图像和后景图像输入至三维重建模块进行算法重建,获取目标物品的前景图像的三维重建点云数据和目标物品的后景图像的三维重建点云数据；S2.2：在重建过程中,输入的图像通过调整后的融合成像模块的内参数对图像进行畸变矫正,消除镜头畸变带来的误差；S2.3：通过调整后的融合成像模块的外参数进行坐标变换,将二维图像坐标转换为三维点云坐标；S2.4：通过点云滤波算法过滤三维点云坐标转换过程中错误的匹配点；S2.5：将拼接后的完整点云数据进行封装,形成三维模型。</td>   <td>G06T17/00;H04N13/239;H04N23/743;H04N23/74</td>  </tr>        <tr>   <td>中国专利</td>   <td>         莫颖倩;              戴冽;              杨泽宏;              沈君;              马剑达;                   郑东辉       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种用于分析类风湿性关节炎的系统</td>   <td>广东省</td>   <td>CN110148465B</td>   <td>2023-07-04</td>   <td>本发明提供了一种用于分析类风湿关节炎(RA)的系统,本发明系统包括患者数据获取模块、数据输入模块和分析模块,以及时了解RA患者关节破坏进展,监测疾病的治疗效果；本发明核磁共振仪采用的是3.0T whole-body扫描系统以八通道头线圈,通过提高信噪比而使图像更加清晰；平均扫描时间仅为24分钟,为今后临床推广普及打下坚实的基础。</td>   <td>1.一种用于分析类风湿关节炎的系统,其特征在于,包括：患者数据获取模块,所述患者数据获取模块包括核磁共振仪,用于获取患者双手近端指间关节的滑膜炎、骨炎、腱鞘炎、骨侵蚀、关节间隙狭窄的图像信息；数据输入模块,用于读取所述患者数据获取模块中图像信息,并依据评分标准给予滑膜炎、骨炎、腱鞘炎、骨侵蚀、关节间隙狭窄的评分；分析模块,采用回归模型计算总分,根据总分评估类风湿关节炎的发展状况；所述回归模型生成单元采用R语言RMS运算包实现列线图的构建；所述评分标准为如下：在滑膜炎评判中,0分为正常,1分为强化范围达滑膜总体积或厚度的1/3,2分为强化范围达滑膜总体积或厚度的2/3,3分为强化范围达滑膜总体积或厚度的全层；在骨炎评判中,0分为无水肿,1分为水肿范围在0～1/3,2分为水肿范围在1/3～2/3,3分为水肿范围超过2/3；在腱鞘炎评判中,根据肌腱周围积液或造影剂强化的滑膜增厚进行评分：0分为无积液或增厚；1分为腱鞘积液或增厚&lt;1.5mm；2分为腱鞘积液或增厚≥1.5mm但&lt;3mm；3分为腱鞘积液或增厚≥3mm；在骨侵蚀评判中,0分为无侵蚀,1分为骨侵蚀体积是0％～10％,2分为骨侵蚀体积是11％～20％,3分为骨侵蚀体积是20％～30％,4分为骨侵蚀体积是30％～40％,5分为骨侵蚀体积是40％～50％,6分为骨侵蚀体积是50％～60％,7分为骨侵蚀体积是60％～70％,8分为骨侵蚀体积是70％～80％,9分为骨侵蚀体积是80％～90％,10分为骨侵蚀体积是90％～100％；在关节间隙狭窄评判中,0分为无狭窄,1分为局灶或轻度狭窄即&lt;33％,2分为中度狭窄即34％～66％,3分为中度到重度狭窄即67％～99％,4分为关节强直；在滑膜炎评判中,评判的部位为拇指间关节,以及食指、中指、无名指和尾指的近端指间关节；在骨炎评判中,评判的部位为拇指间关节并含远节指骨基底部和近节指骨头,以及食指、中指、无名指和尾指的近端指间关节并含中节指骨基底部和近节指骨头；在腱鞘炎评判中,评判的部位为拇指间关节、食指、中指、无名指和尾指的近端指间关节水平在近侧1厘米至远侧1厘米的范围中指屈肌肌腱；在骨侵蚀评判中,评判的部位为拇指间关节并含远节指骨基底部和近节指骨头,以及食指、中指、无名指和尾指的近端指间关节并含中节指骨基底部和近节指骨头；在关节间隙狭窄评判中,评判的部位为拇指间关节,以及食指、中指、无名指和尾指的近端指间关节。</td>   <td>G16H50/20;G16H10/40;G16H30/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张贺晔;                   张冬       </td>   <td>中山大学</td>   <td>冠状动脉狭窄的量化方法及装置</td>   <td>广东省</td>   <td>CN111340794B</td>   <td>2023-07-04</td>   <td>本申请提供了一种冠状动脉狭窄的量化方法及装置,包括：利用人工神经网络的自学习能力,建立冠状动脉多视角医学图像的多视角图像特征与冠状动脉狭窄的形态学参数之间的对应关系；获取患者的当前冠状动脉多视角医学图像的当前多视角图像特征；通过所述对应关系,确定与所述当前多视角图像特征对应的当前冠状动脉狭窄的形态学参数；具体地,确定与所述多视角图像特征对应的当前冠状动脉狭窄的形态学参数,包括：将所述对应关系中与所述当前多视角图像特征相同的多视角图像特征所对应的冠状动脉狭窄的形态学参数,确定为所述当前冠状动脉狭窄的形态学参数。基于多视角预测冠状动脉狭窄的形态学参数,缓解狭窄与其他血管重叠给狭窄量化带来的影响。</td>   <td>1.一种冠状动脉狭窄的量化方法,其特征在于,包括：利用人工神经网络的自学习能力,建立冠状动脉多视角医学图像的多视角图像特征与冠状动脉狭窄的形态学参数之间的对应关系；其中,所述多视角至少包括三个位置不同的视角；具体地,通过1x1x1的卷积操作将3D卷积特征F-(3D)转换为三种矩阵,分别为Q,K,V；对于图像序列中的第t帧特征x～t,                                    其中,是注意力权重,表示第t帧特征x～t中第j个像素区域和第i个像素区域的交互关系；冠脉狭窄相关的注意力特征为/&gt;由下式计算而得,其中/&gt;为1x1x1卷积参数,                  对于一个包括T帧的冠脉造影X-ray图像序列,其注意力特征为F-A；引入残差网络层,生成一个加权注意力特征公式如下：                  F-A＝concat(A～1,A～2,…,A～t,…,A～T)                  获取患者的当前冠状动脉多视角医学图像的当前多视角图像特征；通过所述对应关系,确定与所述当前多视角图像特征对应的当前冠状动脉狭窄的形态学参数；具体地,确定与所述多视角图像特征对应的当前冠状动脉狭窄的形态学参数,包括：将所述对应关系中与所述当前多视角图像特征相同的多视角图像特征所对应的冠状动脉狭窄的形态学参数,确定为所述当前冠状动脉狭窄的形态学参数。</td>   <td>G06T7/00;G06V10/40;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄定帮;                   潘嵘       </td>   <td>中山大学</td>   <td>一种多任务模型生成词向量的方法</td>   <td>广东省</td>   <td>CN109325231B</td>   <td>2023-07-04</td>   <td>本发明涉及计算机领域中的自然语言处理的技术领域,更具体地,涉及一种多任务模型生成词向量的方法。该方法通过集成无监督任务,分类任务,词性标注等多个任务模型的信息,增强其产生的词向量所蕴涵的信息。同时在多任务集成上使用高效且足够优秀的模型,以便能在大规模数据集上进行使用。该方法通过GloVe模型(基于全局信息的词向量,Global vectors for word representation)训练无监督任务,获取语言模型相关的信息。通过Fasttext模型训练分类任务,来获取文本中的类别信息。通过逻辑回归模型训练词性任务,获取词性相关信息。该方法能够在大规模数据集上快速得到蕴含丰富词义的优质词向量,从而应用于自然语言处理任务场景中。</td>   <td>1.一种多任务模型生成词向量的方法,其特征在于,包括以下步骤：S1.数据预处理与词向量初始化；所述的步骤S1中：将每个词与某个向量关联起来,即需要实现这一个转换函数,将一个词映射到一个n维的向量中：                  在此之后的模型训练优化时,更新对应的向量的值即为对该词向量进行更新；具体实现方法是先以正态分布的方法先随机初始化一个V×n维的矩阵其中V表示语料的词汇量；然后通过词典的方法对每个词进行编号,从而每个词w～((i))都对应一个编号i,以矩阵E的第i行的向量E-i作为词w～((i))的词向量：                  所以在模型中,矩阵E便可认为是由所有的词向量拼接组成的矩阵,对矩阵E的第i行进行更新也就对应于对词w～((i))的词向量进行更新；而模型收敛时,矩阵E也做作为模型的词向量结果；在w～((i))中使用的上标i表示其在字典中的编号顺序；同理,当使用(v～((i)),y～((i)))时,其分别表示数据集中第i个样本的词向量矩阵v～((i)),及其标注y～((i)),而则表示第i个样本中第j个词对应的词向量,/&gt;则表示第i个样本中第j个词对应的标注信息,/&gt;的表示只在词性标注需要使用；S2.分类任务；其中,选择以Fasttext模型作为分类算法；S3.词性任务,其中,使用多分类的逻辑回归算法作为词性任务的模型算法；S4.无监督任务；其中,在无监督任务中使用GloVe模型进行描述；S5.优化目标与参数优化。</td>   <td>G06F40/284;G06F40/268;G06F16/35;G06F18/2415;G06F18/2431;G06F18/27;G06N3/084;G06N3/088;G06N3/0985</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              李辉忠;              李卫;              南雨宏;              莫楠;              张开翔;              范瑞彬;              白兴强;                   李成博       </td>   <td>深圳前海微众银行股份有限公司;中山大学</td>   <td>区块链的合约验证方法、服务器和存储介质</td>   <td>广东省</td>   <td>CN116382757A</td>   <td>2023-07-04</td>   <td>本申请提供一种区块链的合约验证方法、服务器和存储介质,涉及金融科技领域。该方法包括：当服务器确定存在待验证合约时,服务器可以获取该待验证合约的合约信息。合约信息中至少包括合约代码和合约意图。服务器可以根据合约代码确定函数调用关系图。服务器可以根据合约意图和合约调用关系图,从待验证合约的全部函数中选择部分相关函数。服务器可以使用这些相关函数构建合约模型。服务器可以将合约意图转化为断言语句。服务器可以根据合约模型和断言语句验证待验证合约的合约代码与合约意图的一致性,并得到验证结果。本申请的方法,降低了复杂合约的建模复杂度,实现了复杂智能合约的分析及验证。</td>   <td>1.一种区块链的合约验证方法,其特征在于,所述方法包括：获取待验证合约的合约信息,所述合约信息中包括所述待验证合约的合约代码和合约意图；根据所述合约代码和所述合约意图,构建待验证合约的合约模型,以及至少一条待验证的断言语句；根据所述合约模型和所述断言语句验证所述待验证合约的所述合约代码与所述合约意图的一致性,并得到验证结果。</td>   <td>G06F8/70;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈川;              李越承;              林昊;              郑子彬;              邬稳;                   王福海       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>社群检测方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN116383441A</td>   <td>2023-07-04</td>   <td>本申请涉及一种社群检测方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取对邻接矩阵进行分解得到的第一分解矩阵、以及对节点属性矩阵进行分解得到的第二分解矩阵；基于邻接矩阵、节点属性矩阵、第一分解矩阵以及第二分解矩阵,确定与图网络对应的目标函数和对比损失函数；对第一分解矩阵中的元素进行筛选处理,得到每一节点各自的伪社群标签；基于目标函数和对比损失函数,确定伪社群标签的损失值,并根据损失值对第一分解矩阵所匹配的分解参数进行参数优化,以得到优化后的第一分解矩阵；对优化后的第一分解矩阵中的元素进行筛选处理,确定每一节点各自的社群检测结果。采用本方法能提高社群检测准确率。</td>   <td>1.一种社群检测方法,其特征在于,所述方法包括：获取对邻接矩阵进行分解得到的第一分解矩阵、以及对节点属性矩阵进行分解得到的第二分解矩阵；所述邻接矩阵用于表示图网络中各节点之间的连接关系,所述节点属性矩阵用于表示所述图网络中各节点的特征；基于所述邻接矩阵、所述节点属性矩阵、所述第一分解矩阵以及所述第二分解矩阵,确定与所述图网络对应的目标函数和对比损失函数；对所述第一分解矩阵中的元素进行筛选处理,得到每一所述节点各自的伪社群标签；基于所述目标函数和所述对比损失函数,确定所述伪社群标签的损失值,并根据所述损失值对所述第一分解矩阵所匹配的分解参数进行参数优化,以得到优化后的第一分解矩阵；对所述优化后的第一分解矩阵中的元素进行筛选处理,确定每一所述节点各自的社群检测结果。</td>   <td>G06F16/901;G06F16/903</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              林格;              李朴;                   陈夏煜       </td>   <td>中山大学</td>   <td>基于最优化的时空尺度多层次水体毒害污染物溯源方法</td>   <td>广东省</td>   <td>CN116384147A</td>   <td>2023-07-04</td>   <td>本发明公开了一种基于最优化的时空尺度多层次水体毒害污染物溯源方法。包括：选取目标流域水文参数,确定目标污染物类别；建立二维水质模型,模拟各种河道的污染物浓度时-空分布状况；随机数值作为初始值,或利用推断污染源信息部分替代随机数值,将初始值输入二维水质模型求得初始污染物浓度-时间序列,选取对应的模拟的浓度-时间序列数值；设定期望值E,将模拟浓度-时间序列与监测站实测浓度值对比得到残差Q,当Q值小于等于E,模拟浓度-时间序列为最终输出结果；若Q值大于E,对模型拟合结果进行优化。本发明选用二维离散水质模型可以满足大多数水体污染物的溯源需求,使得模型计算结果与实际结果更加吻合。</td>   <td>1.一种基于最优化的时空尺度多层次水体毒害污染物溯源方法,其特征在于,所述方法包括：从水文信息数据集中选取目标流域水文参数,同时确定目标污染物类别；基于二维水动力学以及污染物在水体中的扩散、降解等过程概化成数学模型,建立二维水质模型,二维水质模型可模拟单河道或多河道交汇、多个污染源同时或不同时、间断或连续排放时,污染物浓度在水体中时-空分布状况；根据实际约束生成的随机数值作为初始值,初始值是污染源的位置、时间、浓度参数,将初始值输入二维水质模型求得初始污染物浓度-时间序列,根据监测站位置分布,选取所述初始污染物浓度-时间序列中网格位置上对应的模拟的浓度-时间序列数值；根据现实需求和参数精度设定期望值E,将模拟浓度-时间序列与监测站实测浓度值进行对比得到残差Q,当Q值小于等于期望值E,模拟浓度-时间序列为最优化输出结果,并输出包括污染源相关参数项以及水体污染物分布情况的溯源结果；若Q值大于E,则采用盆地跳跃算法全局优化方法对模型进行优化。</td>   <td>G06F30/20;G06F17/13;G06Q30/018;G06Q50/26;G06F113/08;G06F111/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杜圆;              李海超;              孙国仓;              高聪;              庞福振;              李玉慧;              马勇;              倪问池;              李硕;              赵喆;              王逸纯;                   秦正昊       </td>   <td>中山大学;哈尔滨工程大学;中国船舶集团有限公司第七一九研究所</td>   <td>一种海洋平台局部共振区域分布式动力吸振设计方法</td>   <td>广东省</td>   <td>CN116384194A</td>   <td>2023-07-04</td>   <td>本发明提出了一种海洋平台局部共振区域分布式动力吸振设计方法,能够根据海洋平台局部共振区域振动响应,以超标的振动线谱为控制目标,将局部共振待控制区域等效为复杂边界数值模型,快速确定分布式动力吸振参数,并快速评估分布式动力吸振装置的吸振效果,从而实现对海洋平台局部共振区域多线谱振动的有效控制。本发明通过基于能量法构造平台局部共振区域数值等效模型,有效提高了局部待控制区域等价质量求解效率,与最优同调设计原理相互结合,实现了动力吸振参数的快速确定,最后通过有限元法验证动力吸振效果,避免了基于平台大型有限元数值模型反复迭代计算,可大幅提高海洋平台局部共振区域线谱振动的控制效率。</td>   <td>1.一种海洋平台局部共振区域分布式动力吸振设计方法,其特征在于：包括以下步骤：(1)根据设计阶段有限元分析结果或实船测试阶段结果,确定平台局部共振区域及待控制线谱；(2)构造平台局部共振区域数值模型,通过调整数值模型边界弹簧刚度实现局部共振区域数值等效模型的建立；(3)基于平台局部共振区域数值等效模型进行待控制模态等价质量的快速求解,基于该等价质量与最优同调设计原理相结合,实现动力吸振参数的快速确定；(4)基于局部共振区域数值等效模型,对布放分布式动力吸振后海洋平台共振结构的振动响应进行求解,实现分布式动力吸振效果的快速评估；(5)根据分布式动力吸振布放前后的吸振效果,调整动力吸振参数,直至吸振效果满足设计要求,形成海洋平台局部共振区域分布式动力吸振设计方案。</td>   <td>G06F30/23;G06F119/14;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王雪鹤;                   卢子奕       </td>   <td>中山大学</td>   <td>基于动态奖励机制及众包的无人机车辆协同配送规划方法</td>   <td>广东省</td>   <td>CN116384872A</td>   <td>2023-07-04</td>   <td>本发明公开了基于动态奖励机制及众包的无人机车辆协同配送规划方法,该方法包括：基于无人机总数、包裹送货地址集合、仓库地址集合和换乘站节点地址集合构建基础交通网络物流系统；根据基础交通网络物流系统获取基本信息,并根据基本信息进行决策处理,获取决策信息；基于获取的基本信息与决策信息,以配送时间最小化为原则,结合路径搜索算法,生成配送任务并发送至无人机进行执行。本发明能够通过将路面车辆加进无人机配送网络中,并设计动态激励机制以达到无人机平台奖励支出和任务完成时间的最优平衡。本发明作为基于动态奖励机制及众包的无人机车辆协同配送规划方法,可广泛应用于无人机配送技术领域。</td>   <td>1.基于动态奖励机制及众包的无人机车辆协同配送规划方法,其特征在于,包括以下步骤：构建基础交通网络物流系统,所述基础交通网络物流系统包括无人机总数、包裹送货地址集合、仓库地址集合和换乘站节点地址集合；根据基础交通网络物流系统获取基本信息,并根据基本信息进行决策处理,获取决策信息,所述基本信息包括时刻t任一换乘站节点的交通流信息flow(t)、时刻t任一换乘站节点的平均车速v(t)和时刻t任一换乘站节点的等待路面车辆提供搭载服务的最大等待时间W(t),所述决策信息包括无人机的最大飞行时间T、无人机在任意边e∈E上从一端节点移动到另一端节点的飞行能耗c和交通时间t；基于获取的基本信息与决策信息,以配送时间最小化为原则,结合路径搜索算法,生成配送任务并发送至无人机进行执行。</td>   <td>G06Q10/0835;G06Q10/0834;G06Q30/0207;G06Q10/047</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              何雨薇;              诸葛盛;              徐祥鹏;              李楚君;                   杨夏       </td>   <td>中山大学</td>   <td>一种基于结构光的多动平台主动式基准自构建方法</td>   <td>广东省</td>   <td>CN116385544A</td>   <td>2023-07-04</td>   <td>本发明提出一种基于结构光的多动平台主动式基准自构建方法,通过在基准动平台上搭载投射器和相机,通过投影仪主动向目标投射结构光,通过结构光的方法获得光斑在基准坐标系下的空间坐标。在多个观测动平台上搭载相机,获得结构光图像数据,再通过PnP位姿估计得到其在基准坐标系下的位姿信息,实现多动平台主动式基准自构建。本发明提出的方法通过主动投射结构光的方式弥补了传统的基于特征的位姿估计方法在弱纹理场景中精度下降或失效的缺陷,可应用于纹理信息较弱的大型结构形貌重建于测量,是一种兼具灵活性与适用性的多动平台基准自构建方法。</td>   <td>1.一种基于结构光的多动平台主动式基准自构建方法,其特征在于,包括：基准动平台上的投射器向物体表面投射结构光,包括基准动平台、观测动平台在内的多个动平台上的相机采集物体表面结构光图像；对各动平台采集的物体表面结构光图像进行结构光特征点提取,并计算每个结构光特征点对应的特征描述符；基于结构光特征点提取得到的结构光特征点在物体表面结构光图像中的二维图像坐标,结合标定的投射器与相机的相对位姿,通过结构光三角测量得到结构光特征点的三维空间坐标；利用结构光特征点的三维空间坐标以及每个结构光特征点对应的特征描述符对观测动平台进行位姿估计,得到观测动平台与基准动平台的相对位姿,实现观测动平台向基准动平台的空间对齐；基于初始时刻基准动平台获得的场景中的固定不变特征点形成场景点云,利用所述场景点云对基准动平台进行位姿估计,进而获得任意时刻基准动平台与初始时刻基准动平台的相对位姿关系,实现基准动平台的时间对齐。</td>   <td>G06T7/73;G06V10/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              何雨薇;              诸葛盛;              徐祥鹏;              李楚君;                   杨夏       </td>   <td>中山大学</td>   <td>一种基于场景特征的动平台被动式基准自构建方法</td>   <td>广东省</td>   <td>CN116385563A</td>   <td>2023-07-04</td>   <td>本发明提出一种基于场景特征的动平台被动式基准自构建方法,包括基于两幅图像中各合作标志对应的二维图像坐标以及基准坐标系下各合作标志的三维世界坐标,完成两幅图像对应的初步相机外参估计；结合两幅图像的初步相机外参估计结果,对两幅图像中所有的同名特征点对进行三角测量,估计得到各同名特征点对所对应的三维空间特征点的初步估计三维坐标,生成场景的初始三维点云；基于三维空间特征点的初步估计三维坐标以及三维空间特征点在所述两幅图像像平面中的图像坐标构建重投影误差目标函数并求解,得到优化后的相机外参估计结果和场景点云；基于优化后的场景点云进行位姿估计,实现动平台基准对齐。</td>   <td>1.一种基于场景特征的动平台被动式基准自构建方法,其特征在于,包括：根据场景中已知世界坐标的合作标志建立基准坐标系,获得基准坐标系下各合作标志的三维世界坐标；获取动平台采集到的包含合作标志的两幅图像,得到两幅图像中各合作标志对应的二维图像坐标；基于所述两幅图像中各合作标志对应的二维图像坐标以及基准坐标系下各合作标志的三维世界坐标,求解所述两幅图像对应的基准坐标系下的令重投影误差最小的相机外参,完成两幅图像对应的初步相机外参估计；对所述两幅图像进行特征提取与匹配,得到所述两幅图像中所有的同名特征点对；结合所述两幅图像对应的初步相机外参估计结果,对所述两幅图像中所有的同名特征点对进行三角测量,估计得到两幅图像中的各同名特征点对所对应的三维空间特征点的初步估计三维坐标,生成场景的初始三维点云；基于三维空间特征点的初步估计三维坐标以及三维空间特征点在所述两幅图像像平面中的图像坐标构建重投影误差目标函数,求解使重投影误差达到最小值的相机外参以及三维空间特征点的三维坐标,得到优化后的相机外参估计结果和场景点云；基于优化后的场景点云进行位姿估计,实现动平台基准对齐。</td>   <td>G06T7/80;G06T7/73;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘晓春;              王同;              杨扬;              蒙子宁;              蔡金泉;              蔡四川;              陈艺斌;              蔡建顺;              蔡春有;              陈猛猛;                   吴光灿       </td>   <td>中山大学;海南晨海水产有限公司</td>   <td>石斑鱼种类辨别方法、装置、设备及可读存储介质</td>   <td>广东省</td>   <td>CN116386015A</td>   <td>2023-07-04</td>   <td>本申请公开了一种石斑鱼种类辨别方法、装置、设备及可读存储介质,该方法包括：确定区分棕点石斑鱼、清水石斑鱼及杂交石斑鱼的参数类型集合；杂交石斑鱼为棕点石斑鱼及清水石斑鱼杂交得到的石斑鱼,参数类型集合中包含多个用于辨别棕点石斑鱼、清水石斑鱼及杂交石斑鱼的鱼体外部形态参数类型；测量待辨别石斑鱼的每一鱼体外部形态参数类型对应的参数值；利用各个鱼体外部形态参数类型对应的参数值,确定待辨别石斑鱼的种类,种类为棕点石斑鱼、清水石斑鱼或杂交石斑鱼。可见,本申请可以在花费较低成本的情况下,简单方便地辨别石斑鱼的种类。此外,本申请可以辨别石斑鱼的种类,为我国石斑鱼类的种类鉴定提供了一个简单快捷的有力手段。</td>   <td>1.一种石斑鱼种类辨别方法,其特征在于,包括：确定区分棕点石斑鱼、清水石斑鱼及杂交石斑鱼的参数类型集合；其中,所述杂交石斑鱼为所述棕点石斑鱼及所述清水石斑鱼杂交得到的石斑鱼,参数类型集合中包含有多个用于辨别所述棕点石斑鱼、所述清水石斑鱼及所述杂交石斑鱼的鱼体外部形态参数类型；测量待辨别石斑鱼的参数类型集合中每一所述鱼体外部形态参数类型对应的参数值；利用各个所述鱼体外部形态参数类型对应的参数值,确定所述待辨别石斑鱼的种类,所述种类为棕点石斑鱼、清水石斑鱼或杂交石斑鱼。</td>   <td>G06V20/60;G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   刘先进       </td>   <td>中山大学</td>   <td>一种JPEG图像下采样因子估计方法</td>   <td>广东省</td>   <td>CN109544502B</td>   <td>2023-06-30</td>   <td>本发明涉及数字图像取证技术领域,更具体地,涉及一种基于频谱分析和差分图像极值点距离分布的JPEG图像下采样因子估计方法。本发明首先计算差分图像的局部极值点,并获取其相邻极值点距离的分布。通过秩统计分析以及大量实验表明原始未压缩图像的差分极值点距离分布服从几何分布,而JPEG图像分布存在周期性峰值。因此该分布可用于检验图像是否存在JPEG块效应并获取其下采样因子的区间估计。对差分图像计算2D傅里叶变换并通过极大值滤波器定位频谱峰值点。结合差分图像极值点距离分布方法和频谱分析方法获取最终下采样因子估计。</td>   <td>1.一种JPEG图像下采样因子估计方法,其特征在于,包括以下步骤：S1.对待测图像进行色彩通道选择：如果待测图像是灰度图像则直接进行S2步骤,如果待测图像是彩色图像,则首先选择绿色G通道再进行S2步骤；S2.对S1步骤得到的图像计算其差分的局部极值点,并获取其相邻极值点距离的分布：对差分图像进行局部极值滤波,并计算相邻极值点的距离分布；S3.获取下采样因子区间估计：对经过S2步骤得到的相邻极值点的距离分布并计算峰值周期T,得到区间估计S4.计算差分频谱；对S1步骤得到的图像计算其差分的平方,再计算傅里叶变换并得到频谱图；S5.获取下采样峰值点：结合S3得到的区间估计和S4的频谱图,选择满足估计区间的最高峰值点；S6.估计下采样因子：S5得到的下采样峰值位置为P,则下采样因子估计值为                  根据下采样因子估计值确定所述JPEG图像是否经过篡改。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡延庆;              左攀星;              黄怡文;              袁悠悠;                   孟凡辉       </td>   <td>中山大学</td>   <td>基于信息非均匀传播特征的社交媒体关键用户识别方法</td>   <td>广东省</td>   <td>CN111080462B</td>   <td>2023-06-30</td>   <td>本发明公开了基于信息非均匀传播特征的社交媒体关键用户识别方法,该关键用户识别方法为基于模拟传播的方法,并采用非均匀SIR模型作为信息传播模型的关键用户识别方法；非均匀SIR模型基于信息的非均匀传播特征对标准SIR模型进行改进得到,其中非均匀SIR模型中每条边的感染概率是不同的。本发明首先针对标准SIR模型中假设任两者之间的感染概率是相同的,不考虑邻居的异质性的不足之处进行改进,使其符合信息非均匀传播的特性,从而对信息传播能力进行正确估计,并在此基础之上结合基于渗流的贪婪算法,提出了一种基于信息非均匀传播特征的社交媒体关键用户识别方法,使得依赖于信息传播模型的关键用户识别方法的性能得到优化。</td>   <td>1.基于信息非均匀传播特征的社交媒体关键用户识别方法,其特征在于,所述关键用户识别方法为基于模拟传播的方法,并采用非均匀SIR模型作为信息传播模型的关键用户识别方法；所述非均匀SIR模型基于信息的非均匀传播对标准SIR模型进行改进得到,所述非均匀SIR模型中每条边的感染概率不同；其中,所述非均匀SIR模型基于信息的非均匀传播对标准SIR模型进行改进得到具体包括以下步骤：给定在线社交媒体网络G,其网络边数为|E|,设定全局感染概率为β；选定所述在线社交媒体网络G中的初始感染者集合S；所述初始感染者集合S由粉丝数量接近社交媒体粉丝数量均值的平凡用户组成；计算所述在线社交媒体网络G中每条边的感染概率；以所述初始感染者集合S为起点在在线社交媒体网络G上按照每条边的感染概率进行SIR信息传播,得到一个信息传播网络G″,所述信息传播网络G″上的所有节点即为信息传播范围；所述的计算所述在线社交媒体网络G中每条边的感染概率的具体步骤包括：计算边ei→j的感染概率P-(ei→j)：                  其中P-(ei→j)表示节点j被节点i感染的概率,即边ei→j的感染概率,i为感染者,j为敏感者,k～(in)表示节点的入度,k～(out)表示节点的出度,α表示根据在线社交媒体网络中每个用户的发文频率s以及出度k～(out)计算得到的活跃度系数,用于衡量出度对感染概率的影响强弱；所述在线社交媒体网络G中所有边的感染概率的均值为β,即：                  P-e表示边e的感染概率,|E|为网络边数；则：                  所述关键用户识别方法具体包括以下步骤：a.给定在线社交媒体网络G,候选用户集M,关键用户个数k,设定传播阈值m；其中k≤|M|；b.对于候选用户集M,基于所述非均匀SIR模型模拟信息传播,对于候选用户集M中的任一候选用户,除自然消亡外,当所述候选用户的感染范围大于或等于预设阈值m时停止传播,并将所述候选用户加入集合A-i；c.判断当前步骤a是否已执行K次,若是则得到最终集合A-i,i＝1,2,...,K并进行下一步；若否则返回步骤a；d.找到在K个集合中出现次数最多的候选用户v-1,加入关键用户集V-o,从集合/&gt;中删除所有包含v-1的用户集后赋值给/&gt;找到在集合/&gt;中出现次数最多的候选用户v-2,从集合/&gt;中删除所有包含v-2的候选用户集后赋值给/&gt;以此类推,直至得到k个关键用户V＝{v-1,v-2,...,v-k},即为关键用户的识别结果,并将所述关键用户作为信息传播源使信息传播范围最大的用户。</td>   <td>G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;                   张岩森       </td>   <td>中山大学</td>   <td>一种构建序列推荐模型的方法和序列推荐方法</td>   <td>广东省</td>   <td>CN113762477B</td>   <td>2023-06-30</td>   <td>本申请公开了一种构建序列推荐模型的方法和序列推荐方法,包括：构建输入序列的自适应邻接矩阵,基于自适应邻接矩阵构建项目第一嵌入；基于图神经网络的邻接矩阵构建项目第二嵌入；根据项目第一嵌入和项目第二嵌入,通过注意力机制构建用户的局部兴趣模型；构建用户的全局兴趣模型和目标序列的嵌入,并根据目标序列的嵌入、用户的局部兴趣模型和全局兴趣模型构建序列推荐模型；基于梯度下降及贝叶斯个性化排序构建序列推荐模型的损失函数。该序列推荐模型无需依赖于现有的构图方式以及先验知识,通过自动学习边与边的权重,避免噪音点带来的不合适的影响,从而学习到更精准的项目嵌入以及更精确的局部兴趣,可以较为有效且可靠地实现序列推荐。</td>   <td>1.一种构建序列推荐模型的方法,其特征在于,包括：构建输入序列的自适应邻接矩阵,基于所述自适应邻接矩阵构建项目第一嵌入；所述自适应邻接矩阵用于以端到端的方式学习输入序列中各个项目之间的关系；基于图神经网络构建输入序列的邻接矩阵,基于所述邻接矩阵构建项目第二嵌入；所述邻接矩阵用于聚合所述输入序列的相邻信息；根据所述项目第一嵌入和所述项目第二嵌入,通过注意力机制构建用户的局部兴趣模型；构建用户的全局兴趣模型和目标序列的嵌入,并根据目标序列的嵌入、用户的局部兴趣模型和全局兴趣模型构建序列推荐模型；基于梯度下降及贝叶斯个性化排序构建所述序列推荐模型的损失函数；所述基于所述自适应邻接矩阵构建项目第一嵌入的过程,包括：初始化自适应邻接矩阵其中,/&gt;具有可学习参数；通过tanh激活函数将的值限制在-1到1之间；基于自适应邻接矩阵构建项目的第一逐层传播规则,并基于所述第一逐层传播规则获取项目第一嵌入/&gt;其中,项目第一嵌入的数学式为：                  其中,用于控制图神经网络的权重,d为对项目进行嵌入的维度,为所述输入序列经过r个传播步骤后的最终隐藏状态；所述基于所述邻接矩阵构建项目第二嵌入的过程,包括：基于所述邻接矩阵A∈R～((L+R)×(L+R))构建项目的第二逐层传播规则,并基于所述第二逐层传播规则获取项目第二嵌入其中,项目第二嵌入的数学式为：                  其中,用于控制图神经网络的权重,d为对项目进行嵌入的维度。</td>   <td>G06N3/042;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              甘叔玮;              叶雪辀;              杨夏;                   林彬       </td>   <td>中山大学</td>   <td>一种运动员人体姿态测量方法</td>   <td>广东省</td>   <td>CN112183316B</td>   <td>2023-06-30</td>   <td>本发明公开一种运动员人体姿态测量方法,包括如下步骤：获取待测运动员在运动过程中按时间排序的多方位视图,作为待测图像组序列；基于待测图像组序列得到待测运动员各关节点的二维图像坐标序列；基于待测运动员各关节点的二维图像坐标序列得到待测运动员各关节点的初步三维空间坐标序列；基于待测运动员各关节点的初步三维空间坐标序列构建待测运动员的人体三维骨架模板；基于骨架各关节点之间的运动链关系驱动人体三维骨架模板,并与待测运动员各关节点的初步三维空间坐标序列进行匹配优化,得到待测运动员各关节点的实际三维空间坐标序列。能够有效的对运动员运动过程中的姿态进行测量,具有测量过程简单、成本低、实时性高等特点。</td>   <td>1.一种运动员人体姿态测量方法,其特征在于,包括如下步骤：步骤1,获取待测运动员在运动过程中按时间排序的多方位视图,作为待测图像组序列；步骤2,基于待测图像组序列得到待测运动员各关节点的二维图像坐标序列；步骤3,基于待测运动员各关节点的二维图像坐标序列得到待测运动员各关节点的初步三维空间坐标序列；步骤4,基于待测运动员各关节点的初步三维空间坐标序列构建待测运动员的人体三维骨架模板,具体包括：步骤4.1,对待测运动员各关节点的初步三维空间坐标序列进行时序平滑,具体为：采用经验模态分解待测图像中每个运动员关节点的三维空间坐标的时间序列x-t,y-t,z-t,得到待测图像中运动员关节点的三维空间坐标的时间序列x-t,y-t,z-t在各模态下的本征模态函数,并剔除其中的高频分量；步骤4.2,通过时序平滑后的待测运动员各关节点的初步三维空间坐标序列对运动员人体的骨骼长度进行统计,将其统计均值作为约束初始化人体模板,即得到待测运动员的人体三维骨架模板；；步骤5,基于骨架各关节点之间的运动链关系驱动人体三维骨架模板,并与待测运动员各关节点的初步三维空间坐标序列进行匹配优化,得到待测运动员各关节点的实际三维空间坐标序列,具体包括：步骤5.1,构建人体运动链模型：                  式中,T-i表示人体中第i个关节点的运动变换矩阵,θ-k表示第k个关节点的运动角度参数,K表示关节点个数,δ-(ki)为指示函数,δ-(ki)＝1表示关节点k是关节点i的父节点,δ-(ki)＝0表示关节点k不是关节点i的父节点,和/&gt;分别代表关节点的全局变换关系和局部关节点k处的变换关系；步骤5.2,将时序平滑后的待测运动员各关节点的初步三维空间坐标序列作为人体运动链模型的参照值获取人体运动链模型参数为x-t时的待测运动员各关节点的实际三维空间坐标序列作为实际值P-t(x-t)；步骤5.3,基于参照值与实际值P-t(x-t)建立匹配误差模型：                  式中,e(x-t)表示关节点在三维空间中的匹配误差,K表示关节点个数；步骤5.4,基于匹配误差模型进行迭代优化,得到人体运动链模型参数xt的最优取值,并通过该人体运动链模型参数x-t的最优取值与待测运动员各关节点的初步三维空间坐标序列得到待测运动员各关节点的实际三维空间坐标序列。</td>   <td>G06V40/20;G06V10/75;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              周明杰;                   周凡       </td>   <td>中山大学</td>   <td>一种基于多特征融合和随机森林模型的新闻故事分割方法</td>   <td>广东省</td>   <td>CN112633241B</td>   <td>2023-06-30</td>   <td>本发明公开了一种基于多特征融合和随机森林模型的新闻故事分割方法。首先以新闻视频作为输入源,进行视觉特征提取和听觉特征提取,包括新闻主题字幕特征提取、直播间特征提取、镜头切换特征提取和静音区特征提取；其次对新闻视频进行语音识别,获得语音识别结果,确定具体候选边界点；接着将语音识别结果作为输入,进行语义特征提取,包括概要匹配特征提取、语义相似度特征提取和文本深度特征提取；再次手动标注新闻视频特征对随机森林模型进行训练,将提取的视频特征值和具体候选边界输入训练好的模型进行目标视频的二分类任务,归类结果为新闻故事单元边界和非边界；最后以归类结果对目标视频进行分割,获得最终的新闻视频故事单元。</td>   <td>1.一种基于多特征融合和随机森林模型的新闻故事分割方法,其特征在于,所述方法包括：以新闻视频作为输入源,进行视觉特征提取包括新闻主题字幕特征提取、直播间切换特征提取和镜头切换特征提取,进行听觉特征提取包括静音区特征提取；以新闻主题字幕帧的时间节点作为输入源,确定候选边界范围,以所述新闻视频作为输入源进行语音识别,获得语音识别结果,确定具体候选边界点；以所述语音识别结果作为输入,进行语义特征提取,包括概要匹配特征提取、语义相似度特征提取和文本深度特征提取；使用手动标注出新闻故事单元边界点和边界点处特征后的视频作为训练集,对随机森林模型进行训练,将所述新闻视频已提取的视频特征值和所述具体候选边界点输入训练好的随机森林模型进行二分类任务,归类结果为新闻故事单元边界和非边界两类；以所述归类结果对目标视频进行分割,获得最终结果即新闻视频的故事单元；其中,所述新闻主题字幕特征提取,具体为：以所述新闻视频作为输入源,主题字幕出现在(96,310)与(432,336)两个点构成的矩形区域内,此区域为处理的目标区域,将目标区域图像转化为HSV色彩模型,统计矩形区域内H(色调)值为90与103的点的数量,V(明度)大于等于200的点的数量,分别记为f-1,f-2,f-3；若f-1&gt;200∧f-2&gt;300∧f-3&gt;3000,则目标区域可能出现主题字幕,进行下一步判断；从当前帧起每秒取一帧,分别计算连续三帧f-1,f-2,f-3变化量绝对值的累加和,记为Δf-1,Δf-2,Δf-3,若Δf-1&gt;800∧Δf-2&gt;500∧Δf-3&gt;400,则认为目标帧为主题字幕帧；将目标帧的目标区域与上一个主题字幕帧的目标区域进行二值图的逐点比较,记像素值不相等的像素点的数量为dif,若dif&gt;1000则认为当前主题字幕为首次出现,记录当前帧的时间节点,即新闻主题字幕帧的时间节点；完成对整个视频的遍历,结果作为新闻主题字幕特征；其中,所述镜头切换特征提取,具体为：以所述新闻视频作为输入源,对所述新闻视频每秒取1帧,使用连续两帧的颜色直方图差异作为镜头切换的衡量标准；首先,分段对图像的RGB值进行映射减少计算量,R＝R-0/32,G＝G-0/32,B＝B-0/32,其中R-0,G-0,B-0分别为原始RGB各个分量的值；然后,将RGB颜色映射为一个标量v＝R*64+B*8+G,共512种颜色,v∈[0,512)；使用局部像素重采样对图像进行缩放,长宽均缩放至原来的的1/4；计算缩放后的当前帧图像的颜色直方图,即计算v∈[0,512),每个v值对应的像素的个数,与前一帧(每秒取一帧)v值对应的像素的个数逐值相减,取绝对值后加和,记为dif,若dif&gt;10000,则认为当前帧出现了镜头切换,记录当前帧的时间节点；完成对整个视频的遍历,结果作为镜头切换特征；其中,所述静音区特征提取,具体为：以所述新闻视频作为输入源,将视频文件转换为音频文件；然后获取音频的信息,得到每个采样点的能量,以256个采样点为一帧,计算每一帧的短时能量和过零率；计算每一秒(25帧/秒)平均短时能量和平均过零率,分别记为f-1,f-2,若f-1&gt;1000000∧f-2&gt;0.05,则标记当前时间点为静音点；剔除孤立的静音点,结果作为静音区特征。</td>   <td>G06V20/40;G06V10/25;G06V10/774;G06V10/764;G06V10/80;G06F40/289</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张志勇;              黎厚枫;              丘昌镇;              王鲁平;                   王亮       </td>   <td>中山大学</td>   <td>一种单目标跟踪方法和装置</td>   <td>广东省</td>   <td>CN112802060B</td>   <td>2023-06-30</td>   <td>本申请公开了一种单目标跟踪方法和装置,将获取的可见光模板图像、可见光搜索图像、红外光模板图像和红外光搜索图像输入至目标跟踪模型进行特征提取；并通过目标跟踪模型对可见光模板特征向量和可见光模板特征向量进行模板特征融合得到融合模板特征,对可见光搜索特征向量和红外光搜索特征向量进行搜索特征融合得到融合搜索特征,然后对融合模板特征和融合搜索特征进行互相关计算得到融合响应图,并根据融合响应图获取目标的位置,直至可见光视频或红外光视频结束,得到目标的跟踪结果。本申请解决了现有的目标跟踪方法基于可见光图像进行目标跟踪,容易受到恶劣的照明、雾气和恶劣天气等恶劣条件的影响,导致目标跟踪结果准确性较低的技术问题。</td>   <td>1.一种单目标跟踪方法,其特征在于,包括：获取可见光视频和红外光视频的第n帧图像,得到可见光搜索图像和红外光搜索图像,其中,n&gt;1,所述可见光视频和所述红外光视频的第一帧图像用于获取可见光模板图像和红外光模板图像；将所述可见光模板图像、所述可见光搜索图像、所述红外光模板图像和所述红外光搜索图像输入至目标跟踪模型；通过所述目标跟踪模型对所述可见光模板图像、所述可见光搜索图像、所述红外光模板图像和所述红外光搜索图像进行特征提取,分别得到可见光模板特征向量、可见光搜索特征向量、红外光模板特征向量和红外光搜索特征向量；通过所述目标跟踪模型对所述可见光模板特征向量和所述红外光模板特征向量进行模板特征融合得到融合模板特征,以及对所述可见光搜索特征向量和所述红外光搜索特征向量进行搜索特征融合得到融合搜索特征；其中,对所述可见光搜索特征向量和所述红外光搜索特征向量进行搜索特征融合得到融合搜索特征包括：通过所述目标跟踪模型根据所述可见光模板特征向量和所述可见光搜索特征向量进行互相关计算得到可见光响应图,并基于所述可见光响应图获取可见光权重；通过所述目标跟踪模型根据所述红外光模板特征向量和所述红外光搜索特征向量进行互相关计算得到红外光响应图,并基于所述红外光响应图获取红外光权重；通过所述目标跟踪模型根据所述可见光权重和所述红外光权重对所述可见光搜索特征向量和所述红外光搜索特征向量进行向量拼接,得到融合搜索特征；通过所述目标跟踪模型对所述融合模板特征和所述融合搜索特征进行互相关计算得到融合响应图,并根据所述融合响应图获取目标的位置；设n=n+1,并返回所述获取可见光视频和红外光视频的第n帧图像,得到可见光搜索图像和红外光搜索图像的步骤,直至所述可见光视频或所述红外光视频结束,得到所述目标的跟踪结果。</td>   <td>G06T7/246;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              杨明健;                   周凡       </td>   <td>中山大学</td>   <td>一种基于图注意力网络的服装属性识别方法与系统</td>   <td>广东省</td>   <td>CN113378962B</td>   <td>2023-06-30</td>   <td>本发明公开了一种基于图注意力网络的服装属性识别方法与系统。包括：对服装数据集的属性关系进行分析,构建属性关系邻接矩阵,从数据集中筛选出输入图像和对应的服装属性标签,进行数据增强处理,其次提取特征,包括提取服装图像的整体视觉特征、属性值视觉特征和属性的关系特征,最后将属性值视觉特征与属性的关系特征进行特征融合,输入至全接网络,输出属性类别预测得分,即属性识别分类结果,计算属性关系图注意力网络最终的输出结果与服装属性标签交叉熵损失函数,利用梯度下降的方法训练整个属性关系图注意力网络。本发明基于计算机视觉的服装属性识别技术,使用图注意力网络充分挖掘属性的内在联系,提高网络识别准确率。</td>   <td>1.一种基于图注意力网络的服装属性识别方法,其特征在于,所述方法包括：对服装数据集的属性关系进行分析,为每个不同的属性组构建属性关系邻接矩阵；从所述服装数据集中筛选出输入图像与其对应的服装属性标签,并将输入图像进行统一尺寸和数据增强处理；将所述输入图像输入到在图像分类数据集ImageNet上预训练好的ResNet模型中,提取服装图像的整体视觉特征；将所述整体视觉特征再分别经过M个全连接层,为M个所述属性组提取对应的属性视觉特征,分出的每一个分支就是一个属性识别网络；将所述属性视觉特征进行转化、切片分割,得到属性值视觉特征；将所述属性值视觉特征输入至属性关系图注意力网络中,得到属性的关系特征；将所述属性值视觉特征与所述属性的关系特征进行特征融合后,输入至属性分类器中,输出最终的属性识别分类结果；计算所述属性关系图注意力网络最终的输出结果与所述服装属性标签交叉熵损失函数,利用梯度下降的方法训练整个所述属性关系图注意力网络,得到训练好的属性关系图注意力网络；输入待处理的服装图像到所述训练好的属性关系图注意力网络,获得需要的服装属性识别结果；其中,所述对服装数据集的属性关系进行分析,为每个不同的属性组构建属性关系邻接矩阵,具体为：服装数据集来源于服装购物网站；选用从属关系以及相似关系作为影响服装属性识别结果的主要属性；相似关系表示为：                  从属关系表示为：                  式中v-i,u-j表示不同属性值,V,U分别表示v-i,u-j从属的属性集合,T表示相似变换系数；构建属性关系邻接矩阵,定性地建立属性之间的关系,如果这两个属性存在联系,则邻接矩阵的值设为1,否则设为0；为相似关系以及从属关系分别构建邻接矩阵,将这两个邻接矩阵进行与操作得到最终的属性关系邻接矩阵。</td>   <td>G06V10/764;G06V10/80;G06V10/74;G06V10/774;G06V10/82;G06N3/045;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              王冠;                   周凡       </td>   <td>中山大学</td>   <td>一种基于人体身形特征的服装推荐方法</td>   <td>广东省</td>   <td>CN112270354B</td>   <td>2023-06-30</td>   <td>本发明公开了一种基于人体身形特征的服装推荐方法。定义身形特征类型标签,对服装数据集和人体数据集进行标签化处理；利用标签化服装数据集对服装身形特征提取模型进行训练,输出服装身形特征；利用标签化人体数据集对人体身形特征提取模型进行训练,输出人体身形特征；并利用服装身形特征和人体身形特征对服装人体身形匹配网络模型进行训练,输出服装与人体身形匹配概率；最后按照匹配概率降序排列推荐给用户。本发明可以提取到更为丰富的用户身形和服装的隐语义信息,而不是单纯的将用户或者服装进行分类,将匹配规则简化为在隐语义空间内的“距离计算”,从而实现了为用户推荐距离最近的服装商品,提高了推荐的准确度。</td>   <td>1.一种基于人体身形特征的服装推荐方法,其特征在于,所述方法包括：预先定义身形特征类型标签,之后搜集服装数据集和人体数据集,并利用身形特征类型标签对两个数据集进行标签化处理,得到标签化服装数据集和标签化人体数据集；采用深度神经网络建立服装身形特征提取模型,并利用所述标签化服装数据集对该模型进行训练,训练好的模型输出结果为服装身形特征；采用深度神经网络建立人体身形特征提取模型,并利用所述标签化人体数据集对该模型进行训练,训练好的模型输出结果为人体身形特征；采用多层感知神经网络建立服装人体身形匹配网络模型,并利用所述服装身形特征和所述人体身形特征进行训练,训练好的模型输出结果为服装与人体身形匹配概率；用户输入自己的个人图片和候选服装图片,利用所述服装人体身形匹配网络模型计算出候选服装与该用户身形的匹配概率,并设置一个匹配阈值,当匹配概率大于匹配阈值时,符合条件的候选服装按照匹配概率降序排列推荐给用户；其中,所述采用深度神经网络建立服装身形特征提取模型,并利用所述标签化服装数据集对该模型进行训练,训练好的模型输出结果为服装身形特征,具体为：将所述服装数据集中的某一件服装a的图片,利用预训练完成的RESNET34网络模型,进行视觉特征提取,得到服装图片的视觉特征向量v1；将所述服装数据集中的某一件服装a所具有的所有所述服装属性词向量相加并求平均,求出所述服装属性词向量的中心点,获得文本特征向量t1；把所述视觉特征向量v1和所述文本特征向量t1输入服装身形特征提取模型,该模型拥有6层,其中包括输入层1层,隐层感知层5层,输出层1层,隐层的感知节点数量与输入层相等,设置为所述视觉特征向量v1和所述文本特征向量t1的长度相加,在输入层以及各个隐层之间采用3个跳跃链接,将隐层的输出链接到一个多分类层中,采用softmax方法,计算出各个分类的概率,输出层的节点数量为身形特征类型数量,该模型的输出结果为所述服装a属于各个身形特征的概率,选取概率最高的一个作为最终的输出结果；所述服装身形特征提取模型的训练策略为：其损失函数采用多类别交叉熵损失函数,计算损失函数得到当前结果的误差,通过反向传播算法修改服装身形特征提取模型中各层节点的参数,进而减小误差,获得最终误差较小时的最好模型；根据上述模型设计与训练策略,输入所述标签化服装数据集,对所述服装身形特征提取模型进行训练,训练完成后,将所述服装身形特征提取模型的最后一层舍去不用,取最后一层的隐层输出,作为所述服装a的服装身形特征I-(cloth)；其中,所述采用深度神经网络建立人体身形特征提取模型,并利用所述标签化人体数据集对该模型进行训练,训练好的模型输出结果为人体身形特征,具体为：将所述人体数据集中的某一人体b的图片,利用预训练完成的RESNET34网络模型,进行视觉特征提取,得到人体图片的视觉特征向量v2；把所述视觉特征向量v2输入人体身形特征提取模型,该模型拥有6层,其中包括输入层1层,隐层感知层5层,输出层1层,隐层的感知节点数量与输入层相等,即为所述视觉特征向量的长度|v2|,在输入层以及各个隐层之间采用3个跳跃链接,将隐层的输出链接到一个多分类层中,采用softmax方法,计算出各个分类的概率,输出层的节点数量为身形特征类型数量,该模型的输出结果为所述人体b属于各个身形特征的概率,选取概率最高的一个作为最终的输出结果；所述人体身形特征提取模型的训练策略为：其损失函数采用多类别交叉熵损失函数,计算损失函数得到当前结果的误差,通过反向传播算法修改人体身形特征提取模型中各层节点的参数,进而减小误差,获得最终误差较小时的最好模型；根据上述模型设计与训练策略,输入所述标签化人体数据集,对所述人体身形特征提取模型进行训练,训练完成后,将所述人体身形特征提取模型的最后一层舍去不用,取最后一层的隐层输出,作为所述人体b的人体身形特征I-(user)；其中,所述采用多层感知神经网络建立服装人体身形匹配网络模型,并利用所述服装身形特征和所述人体身形特征进行训练,训练好的模型输出结果为服装与人体身形匹配概率,具体为：把所述服装身形特征I-(cloth)和所述人体身形特征I-(user)输入服装人体身形匹配网络模型,该模型采用4层结构,1层输入层,2层隐层,以及1层输出层,输入层与隐层的节点长度均设置为|I-(cloth)|+|I-(user)|,输出层只有一个节点,该节点的激活层,采用sigmoid激活函数,服装与人体的匹配概率取值范围为(0,1)；所述服装人体身形匹配网络模型的训练策略为：其损失函数采用二分类交叉熵损失函数,计算损失函数得到当前结果的误差,通过反向传播算法修改人体身形特征提取模型中各层节点的参数,进而减小误差,获得最终误差较小时的最好模型；根据上述模型设计与训练策略,利用所述标签化服装数据集通过所述服装身形特征提取模型提取到的所有服装身形特征,以及利用所述标签化人体数据集通过所述人体身形特征提取模型提取到的所有人体身形特征,对模型进行训练,得到最终的服装人体身形匹配网络模型,其输出结果为服装与人体身形匹配概率。</td>   <td>G06V10/774;G06V10/764;G06V10/82;G06N3/0464;G06N3/048;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余晨韵;              李凯;                   谭光       </td>   <td>中山大学</td>   <td>一种基于层次化对比学习的商品推荐方法及系统</td>   <td>广东省</td>   <td>CN116362833A</td>   <td>2023-06-30</td>   <td>本发明公开了一种基于层次化对比学习的商品推荐方法及系统,该方法包括：基于Auto-Encoder架构,引入全局对比和自身对比学习策略,对用户与商品的交互序列进行优化学习,输出用户的高层兴趣表征与重构后的用户与商品的交互序列并进行融合处理并通过高层对比学习策略进行优化,得到用户的综合表征向量；对重构后的用户与商品的交互序列与用户的综合表征向量进行点乘计算；选取下一时刻用户与候选商品交互的概率对应最大的商品作为下一项推荐商品。通过使用本发明,通过改进用户行为表征的学习以及推荐算法过程以提升商品序列推荐的准确性。本发明作为一种基于层次化对比学习的商品推荐方法及系统,可广泛应用于用户商品推荐技术领域。</td>   <td>1.一种基于层次化对比学习的商品推荐方法,其特征在于,包括以下步骤：基于Auto-Encoder架构,引入全局对比和自身对比学习策略,对用户与商品的交互序列进行优化学习,输出用户的高层兴趣表征与重构后的用户与商品的交互序列；将用户的高层兴趣表征与用户的低层兴趣表征进行融合处理并通过高层对比学习策略对融合过程进行优化,得到用户的综合表征向量；对重构后的用户与商品的交互序列与用户的综合表征向量进行点乘计算,得到下一时刻用户与候选商品交互的概率；选取下一时刻用户与候选商品交互的概率对应最大的商品作为下一项推荐商品。</td>   <td>G06Q30/0601;G06F16/9535;G06F16/9537;G06F17/16;G06F17/18;G06N3/047;G06N3/0499;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              沈智华;              汪瀚;              覃军友;              林彬;                   张小虎       </td>   <td>中山大学</td>   <td>一种基于三角形的星图配准方法及系统</td>   <td>广东省</td>   <td>CN116363180A</td>   <td>2023-06-30</td>   <td>本发明公开了一种基于三角形的星图配准方法及系统,该方法包括：对星图进行预处理,得到星图前景层；采用分区域恒星遴选算法对星图前景层进行恒星遴选,得到恒星目标点；基于三角距离约束对恒星目标点进行同名恒星点配准,得到同名恒星点配准矩阵；基于同名恒星点配准矩阵,采用仿射变换进行星图运动背景补偿,完成星图配准。该系统包括：预处理模块,遴选模块,配准模块,补偿模块。本方案在减少计算复杂度的基础上大大提高了星图配准的精确度,适用于卫星图像处理领域。</td>   <td>1.一种基于三角形的星图配准方法,其特征在于,包括以下步骤：步骤S1、对星图进行预处理,得到星图前景层；步骤S2、采用分区域恒星遴选算法对星图前景层进行恒星遴选,得到恒星目标点；步骤S3、基于三角距离约束对恒星目标点进行同名恒星点配准,得到同名恒星点配准矩阵；步骤S4、基于同名恒星点配准矩阵,采用仿射变换进行星图运动背景补偿,完成星图配准。</td>   <td>G06T7/33;G06T7/187</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              苏卓;                   谭宇帝       </td>   <td>中山大学</td>   <td>一种特征保持的多源协同融合几何建模方法与系统</td>   <td>广东省</td>   <td>CN116363317A</td>   <td>2023-06-30</td>   <td>本发明公开了一种特征保持的多源协同融合几何建模方法与系统。输入点云未标注数据集,训练预测头MLP-α；输入带有语义分割标签的点云数据集,微调MAE参数并训练预测头MLP-β；预测头MLP-α与预测头MLP-β连同已固定参数的MAE得到点云编码模型；利用对偶图卷积网络构建网格编码模型；输入带有语义标注的三维网格,利用上述两模型生成网格编码与点云编码；拼接网格编码和点云编码,基于网格语义标签与交叉熵损失训练网格编码模型和预测头MLP-γ形成语义分割预测模型；用户输入待处理网格到语义分割预测模型,获取其预测的面片语义分割结果用于几何建模。本发明能有效理解网格数据中的结构特征和空间特征,在几何建模任务上达到更优秀的分割准确率和边界清晰度。</td>   <td>1.一种特征保持的多源协同融合几何建模方法,其特征在于,所述方法包括：输入点云未标注数据集,并用点云重建任务训练编码点云特征的MAE模型的Transformer编码器和预测头MLP-α；输入带有语义分割标签的点云数据集,设置更小的学习率微调所述MAE模型的Transformer编码器的网络参数,并训练预测头MLP-β；构建点云编码模型：根据所述训练完成的预测头MLP-α与预测头MLP-β,并连同已固定参数的所述MAE模型的Transformer编码器,得到用于生成三维网格表面采样点的点云编码的编码模型；构建网格编码模型：对三维网格进行切片操作,以保证每个输入网格的面片数量相同；将切片后的待处理三维网格转化为重心对偶图,即选取每个网格面片的重心为图节点,面片相邻的对应节点构成一条边；通过重心对偶图卷积网络的局部模块、全局模块和门控融合编码切片网格数据,以形成能保留三维网格结构信息的网格编码；输入带有语义标注的三维网格数据集,利用所述网格编码模型生成网格编码；对带有语义标注的三维网格采样后生成覆盖于模型表面的稀疏点云,再利用所述点云编码模型生成点云编码；拼接所述网格编码和所述点云编码,拼接后的多模态编码通过预测头MLP-γ生成每个面片重心的语义预测值；之后固定所述点云编码模型与所述网格编码模型的参数,基于网格语义标签与交叉熵损失训练所述网格编码模型和预测头MLP-γ直至收敛,最终形成语义分割预测模型；用户输入待处理网格到所述语义分割预测模型,获取其预测的面片语义分割结果用于几何建模。</td>   <td>G06T17/00;G06V10/26;G06V10/774;G06V10/80;G06V10/82;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王学孟;                   吴洲华       </td>   <td>顺德中山大学太阳能研究院</td>   <td>光伏组件热流计算方法及装置</td>   <td>广东省</td>   <td>CN109284566B</td>   <td>2023-06-27</td>   <td>本申请实施例提供一种光伏组件热流计算方法及装置,通过获取采集到的光伏组件所在区域的实时气象数据和所述光伏组件的安装参数,并根据所述实时气象数据和所述安装参数,计算所述光伏组件的温度分布信息。由此,可以准确地获得光伏组件在实际运行过程中的温度分布信息,从而更加全面地了解温度对于光伏组件的影响,有效地提高光伏组件评估工作的准确性,进一步帮助电站运维人员分析组件受热情况,从而针对性地改进评估、运维方式,提升电站整体发电性能,增加收益。</td>   <td>1.一种光伏组件热流计算方法,其特征在于,所述方法包括：获取采集到的光伏组件所在区域的实时气象数据和所述光伏组件的安装参数,其中,所述实时气象数据包括辐照度数据、风向数据、风速数据、湿度数据、气压数据、环境温度数据,所述安装参数包括组件安装倾角、安装方位角、安装海拔、组件材料属性；根据所述实时气象数据和所述安装参数,计算所述光伏组件的温度分布信息；所述根据所述实时气象数据和所述安装参数,计算所述光伏组件的温度分布信息的步骤,包括：根据所述安装参数计算所述光伏组件在所述实时气象数据的影响下任意位置的实时温度,并将所述任意位置的实时温度作为所述光伏组件的温度分布信息；所述根据所述安装参数计算所述光伏组件在所述实时气象数据的影响下任意位置的实时温度,并将所述任意位置的实时温度作为所述光伏组件的温度分布信息的步骤,包括：建立所述实时气象数据中的辐照数据光伏组件的等效热模型；基于所述等效热模型并根据所述光伏组件的安装参数和所述实时气象数据,计算所述光伏组件的组件材料与所在区域环境之间的热关联关系,所述热关联关系包括热传递关系、热对流关系以及热辐射关系,所述光伏组件的组件材料包括EVA、前盖板玻璃、太阳电池、铝边框、背板、密封胶、接线盒；根据所述热关联关系计算所述光伏组件在所述实时气象数据的影响下任意位置的实时温度,并将所述任意位置的实时温度作为所述光伏组件的温度分布信息；所述建立所述光伏组件的等效热模型的步骤,包括：根据所述实时气象数据中的辐照度数据建立光学模型；根据建立的所述光学模型建立生热模型；根据所述实时气象数据建立流体模型；根据建立的所述生热模型和所述安装参数中的组件材料属性建立传热学模型；将建立的传热学模型、光学模块、生热模块以及流体模型进行耦合,以建立所述光伏组件的等效热模型；所述传热学模型的计算公式包括：                  其中,ρ为密度,kg/m3；Cp为常压热容,J/(kg·K)；T为绝对温度,K；u-(trans)为扩散速度,m/s；q为导体热通量,W/m2；q-r为辐射热通量,W/m2；α为热膨胀系数,1/K；s为第二应力张量,Pa；Q为额外的热源,W/m3；运算符“：”表示双点积。</td>   <td>G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周毅;              张亮军;                   蔡瑞昇       </td>   <td>中山大学</td>   <td>一种视网膜眼底彩色照片图像筛选方法</td>   <td>广东省</td>   <td>CN110459299B</td>   <td>2023-06-27</td>   <td>本发明属于医学图像处理技术领域,涉及到使用自动化的脚本处理大规模视网膜眼底彩色照片图像,将视网膜眼底彩色照片图像从含有大量眼外观图像中筛选出来。本发明利用图像数据筛选方法从大规模视网膜眼底彩色照片图像数据中筛选出高质量的眼底图像,允许用户修改图像相似度计算区域以及是否选择切分图像,最终得到可用于临床诊断以及人工智能算法开发的高质量视网膜眼底彩色照片图像数据。</td>   <td>1.一种视网膜眼底彩色照片图像筛选方法,其特征在于,包括以下步骤：S1.对不同设备采集的视网膜眼底彩色照片图像数据进行批量预处理；S2.从预处理后的图像数据中选择一张图像作为标准模板图像,将待筛选图像与标准模板图像进行图像相似度计算；S3.根据图像相似度计算结果设置相似度阈值,根据相似度阈值筛选出符合要求的图像并获得图像的属性信息；S4.使用符合相似度阈值的图像的属性信息与所有的图像数据的属性信息进行匹配,完成视网膜眼底彩色照片图像的筛选；所述S1的具体步骤如下：所述视网膜眼底彩色照片图像数据依次进行图像灰度转换、z-score标准化、限制对比度自适应直方图均衡、Gamma校正、数据归一化；所述S2的具体步骤如下：S21.从预处理后的所有图像中,允许用户从中选择一张图像作为标准模板图像,对图像相似度计算区域进行设定；同时,用户在选择进行图像相似度对比时,判断是否需要对设定范围内的图像进行切割并生成相应的切割信息,即将计算区域分成不同大小的图像块；S22.根据用户对图像相似度计算区域的设定,同时将对计算区域进行切割的切割信息运用到待筛选的图像中,将计算区域切割分成不同大小的图像块,依次进行待筛选图像的图像块与标准模板图像的图像块的图像相似度的计算,得到待筛选的图像的相似度指数；所述S3的具体步骤如下：基于图像相似度的计算结果,设定相似度阈值,图像的相似度指数大于相似度阈值的图像为需要筛选的图像,将符合相似度阈值的图像进行筛选,获得符合相似度阈值的图像的属性信息；所述图像的属性信息包括：图像的名称、格式信息；所述S4的具体步骤如下：使用符合相似度阈值的图像的属性信息与所有的图像数据的属性信息进行匹配,抽取与符合相似度阈值的图像的属性信息相同的图像,完成对视网膜眼底彩色照片图像的筛选。</td>   <td>G16H30/20;G06T7/00;G06V10/74;A61B3/14;A61B3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李中华;                   何冠男       </td>   <td>中山大学</td>   <td>一种RFID阅读器防碰撞协议的性能评估方法</td>   <td>广东省</td>   <td>CN110532823B</td>   <td>2023-06-27</td>   <td>本发明涉及RFID射频识别领域,更具体地,涉及一种RFID阅读器防碰撞协议的性能评估方法。首先,RFID阅读器在服务器的控制下,发送指定信号探测与周围阅读器的碰撞情况。然后,服务器根据所有阅读器的碰撞信息进行图论建模,计算最大独立集。与此同时,所有RFID阅读器安装同一个RFID阅读器防碰撞协议,同时开始执行并记录状态信息。最后,服务器将所有阅读器的状态信息和最大独立集进行比对,计算状态信息和最大独立集的接近程度。根据接近程度,选择出性能最优的RFID阅读器防碰撞协议。本发明从简易部署,快速评估的角度出发,根据图论原理和RFID系统特点,能够针对众多的RFID阅读器防碰撞协议进行性能评估,并能选择出性能最优的协议。</td>   <td>1.一种RFID阅读器防碰撞协议的性能评估方法,其特征在于,包括以下阶段：RFID阅读器碰撞信息收集阶段、RFID服务器图论建模阶段、RFID阅读器防碰撞协议测试阶段以及比对与选择阶段；RFID阅读器碰撞信息收集阶段：所有RFID阅读器在RFID服务器的统一协调下,每个RFID阅读器根据读取RFID标签功率向周围发送碰撞侦测信号,接收到碰撞侦测信号的RFID阅读器根据碰撞侦测信号的信号强度,判断与发送碰撞侦测信号的RFID阅读器同时读取标签时是否会发生碰撞,并将碰撞信息发送到RFID服务器；RFID服务器图论建模阶段：RFID服务器汇总所有RFID阅读器的碰撞信息,根据图论知识进行建模,并计算得到当前碰撞信息下的最大独立集；RFID阅读器防碰撞协议测试阶段：每个RFID阅读器安装相同的防碰撞协议,并同时开始运行,每个RFID阅读器根据RFID阅读器防碰撞协议进行状态转换,状态包括读取标签成功状态、静默状态以及读取标签失败状态,并记录相关状态信息,当测试时间到后,每个RFID阅读器将状态信息上传至RFID服务器,同时每个RFID阅读器安装新的防碰撞协议,重新开始测试；比对与选择阶段：RFID服务器汇总所有RFID阅读器的状态信息,并与最大独立集进行比对,计算每个协议接近最大独立集的程度,根据接近程度的大小选择出性能最优的RFID阅读器防碰撞协议。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张琳;                   叶家豪       </td>   <td>中山大学</td>   <td>一种基于边缘信息和语义信息的句子相似度计算方法</td>   <td>广东省</td>   <td>CN110990537B</td>   <td>2023-06-27</td>   <td>本发明提供的一种基于边缘信息和语义信息的句子相似度计算方法,包括：输入待处理的比较语句,计算句子长度差值；对待处理的比较语句进行文本预处理,动态生成单词对向量；基于边缘信息和语义信息计算单词对向量相似度,得到混合相似度；利用相似度整体变量修正相似度向量；通过依赖模型,根据单词对向量计算句子依赖变量；利用句子依赖变量、句子长度差值对修正后的向量继续进一步修正,输出最终的相似度得分。本发明提供的相似度计算方法,综合提高单词相似度计算精度,利用句子整体相似度变量降低句子长度对句子相似度计算精度的影响,利用依赖变量和句子长度差值综合修正句子整体相似度,提高句子相似度计算精度。</td>   <td>1.一种基于边缘信息和语义信息的句子相似度计算方法,其特征在于：包括以下步骤：S1：输入待处理的比较语句,计算句子长度差值；S2：对待处理的比较语句进行文本预处理,动态生成第一单词对向量和第二单词对向量；S3：基于边缘信息和语义信息计算第一单词对向量、第二单词对向量相似度,得到混合相似度；具体包括以下步骤：S31：根据单词对在WordNet中的边缘信息,将第一单词对向量与第二单词对向量进行对比,计算WordNet相似度；包括以下步骤：S311：将第一单词对向量与第二单词对向量进行一一对比；S312：将第一单词对向量与第二单词对向量的对比的单词分别输入到WordNet中,利用单词对在WordNet中的边缘信息,即子概念最短路径长度和父节点最浅深度两个特征量化单词相似度,其中：子概念相似度计算公式具体为：f(l)＝e～(-al)其中,f(l)表示子概念相似度,l为子概念间最短路径长度,a为路径修正系数；父节点深度计算公式具体为：                  其中,g(h)表示父节点深度,h为子概念间父节点最浅深度,β为父节点修正系数,至此得到多组子概念相似程度、父节点深度；S313：取最大相似度作为该项单词在WordNet相似度得分,最终得到第一单词对向量与第二单词对向量的WordNet相似度,其中,子概念之间的最大相似度得分具体计算公式为：                  其中,Sim(word1,word2)为word1在WordNet的相似度；S32：根据Spacy模型中基于语义信息,计算第一单词对向量与第二单词对向量的Spacy相似度；S33：将WordNet相似度和Spacy相似度进行加权结合,得到混合相似度向量；S4：利用相似度整体变量修正相似度向量,得到修正后的向量；具体为：S41：根据R&amp;G的定义,当单词相似度值大于0.8025,单词对可对定义为近义词,因此统计两个混合相似度向量中超出0.8025值的数据数量,计算相似度整体变量,具体为：ω＝sum(C1,C2)/γ其中,C-1、C-2分别表示第一单词对向量V-1与第二单词对向量V-2中混合相似度大于0.8025的数据个数,γ为相似度整体变量修正系数；S42：根据相似度整体变量对句子相似度进行修正,具体计算公式为：Sim(text1,text2)-second＝||V1||*||V2||/ω其中,Sim(text1,text2)-second表示修正后的向量；S5：通过依赖模型,根据第一单词对向量、第二单词对向量计算句子依赖变量；S6：利用句子依赖变量、句子长度差值对修正后的向量继续进一步修正,输出最终的相似度得分。</td>   <td>G06F16/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李中华;                   何冠男       </td>   <td>中山大学</td>   <td>基于标签数量的防撞资源竞争方法、移动阅读器、可读存储介质</td>   <td>广东省</td>   <td>CN111339794B</td>   <td>2023-06-27</td>   <td>本发明公开了一种基于标签数量的防撞资源竞争方法、移动阅读器、可读存储介质,其中所述的方法轮回执行以下阶段：竞争权值确定阶段、竞争权值交换阶段、通信资源竞争阶段。本发明从RFID系统通信资源最优化分配的角度出发,阅读器根据询问范围内的标签数量来确定竞争权值,通过与邻居阅读器的竞争权值比较来确定是否参与对通信资源的竞争,参与竞争的阅读器再通过一定的规则对通信资源进行竞争,以提升通信资源的利用效率,最大化RFID系统的标签询问效率。</td>   <td>1.一种基于标签数量的防碰撞资源竞争方法,其特征在于：所述的方法轮回执行以下阶段：竞争权值确定阶段、竞争权值交换阶段、通信资源竞争阶段；其中,所述的竞争权值确定阶段：每一个RFID移动阅读器对询问范围内的RFID电子标签数量进行估计；并根据估计的RFID电子标签数量设定阅读器的竞争权值；所述的竞争权值交换阶段：RFID移动阅读器在轮询服务器广播竞争权值交换信号的条件下,RFID移动阅读器通过竞争规则与邻居RFID移动阅读器交换和比较权值信息；并根据竞争权值的比较结果来判断阅读器是否进入通信资源竞争阶段；确定不进入通信资源竞争阶段的RFID移动阅读器本轮保持静默,下一轮接收到轮信号后,再重新参与竞争；所述的通信资源竞争阶段：RFID移动阅读器在轮询服务器广播竞争同步信号的条件下,对通信资源进行竞争,获得通信资源的RFID移动阅读器开始询问RFID电子标签,没有获得通信资源的RFID移动阅读器本轮保持静默,下一轮接收到轮信号后,再重新参与竞争；在RFID移动阅读器的竞争权值交换阶段,每一个RFID移动阅读器根据轮询服务器的竞争权值交换信号,随机地选择一个竞争权值交换时隙向邻居RFID移动阅读器发送竞争权值信息,在其他竞争权值交换时隙中,每一个RFID移动阅读器侦听来自邻居RFID移动阅读器发送的竞争权值信息；在RFID移动阅读器的竞争权值交换阶段,每一个RFID移动阅读器通过竞争规则与所有邻居RFID移动阅读器的竞争权值进行比较,根据比较结果来判断阅读器是否进入通信资源竞争阶段。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伍俊妍;              邱凯锋;              余晓霞;              何志超;              任丽军;                   刘鹏       </td>   <td>中山大学孙逸仙纪念医院;润泽安泰(北京)科技有限公司</td>   <td>关键信息提取方法、装置、电子设备和存储介质</td>   <td>广东省</td>   <td>CN112784601B</td>   <td>2023-06-27</td>   <td>本发明提供一种关键信息提取方法、装置、电子设备和存储介质,其中方法包括：对待处理的医学文献进行分句,得到所述医学文献中的各个分句；将各个分句输入至关键信息提取模型中,得到所述关键信息提取模型输出的各个分句的关键信息分类结果；其中,所述关键信息提取模型用于提取任一分句中各个分词的上下文语义向量,并基于所述任一分句中各个分词的上下文语义向量,对所述任一分句进行关键信息分类；任一分词的上下文语义向量是同时基于所述任一分词的上文信息和下文信息提取得到的。本发明提供的关键信息提取方法、装置、电子设备和存储介质,提高了语义提取的准确性,进而提高了关键信息提取的准确性。</td>   <td>1.一种关键信息提取方法,其特征在于,包括：对待处理的医学文献进行分句,得到所述医学文献中的各个分句；将各个分句输入至关键信息提取模型中,得到所述关键信息提取模型输出的各个分句的关键信息分类结果；其中,所述关键信息提取模型用于提取任一分句中各个分词的上下文语义向量,并基于所述任一分句中各个分词的上下文语义向量,对所述任一分句进行关键信息分类；任一分词的上下文语义向量是同时基于所述任一分词的上文信息和下文信息提取得到的；所述将各个分句输入至关键信息提取模型中,之前还包括：对各个分句进行格式处理,并对格式处理后的各个分句中的未登录词进行切分,使得切分后的元素存在于词表中；所述将各个分句输入至关键信息提取模型中,得到所述关键信息提取模型输出的各个分句的关键信息分类结果,具体包括：将任一分句输入至所述关键信息提取模型的输入向量编码层,得到所述输入向量编码层输出的所述任一分句的输入向量；将所述输入向量输入至所述关键信息提取模型的语义提取层,得到所述语义提取层输出的所述任一分句中各个分词的上下文语义向量；其中,所述语义提取层是基于MobileBert模型的前6块构建得到的；将所述任一分句中各个分词的上下文语义向量输入至所述关键信息提取模型的句向量提取层,得到所述句向量提取层输出的所述任一分句的句向量；将所述任一分句的句向量输入至所述关键信息提取模型的分类层,得到所述分类层输出的所述任一分句的关键信息分类结果；所述将所述任一分句中各个分词的上下文语义向量输入至所述关键信息提取模型的句向量提取层,得到所述句向量提取层输出的所述任一分句的句向量,具体包括：将所述任一分句中各个分词的上下文语义向量输入至所述句向量提取层的均值池化层,得到所述均值池化层输出的所述任一分句的均值池化向量；将所述任一分句中各个分词的上下文语义向量输入至所述句向量提取层的最大值池化层,得到所述最大值池化层输出的所述任一分句的最大值池化向量；将所述任一分句的均值池化向量和最大值池化向量输入至所述句向量提取层的融合层,得到所述融合层输出的所述任一分句的句向量。</td>   <td>G06F40/289;G06F40/30;G06F16/35;G06N3/049;G06N3/048;G06N3/08;G06N3/045</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              高凌霄;                   刘坤华       </td>   <td>中山大学</td>   <td>一种基于分支定界法的自动切图方法</td>   <td>广东省</td>   <td>CN112883290B</td>   <td>2023-06-27</td>   <td>本发明涉及机器人自主导航的技术领域,更具体地,涉及一种基于分支定界法的自动切图方法。一种基于分支定界法的自动切图方法,其中,包括切图触发器,离线处理和分支定界法三个部分。该自动切图方法致力于解决上述提出的人工干预的问题,本方法的定位是一个辅助算法,在实际应用中一般会随定位算法一起启动。此外,该方法不仅能够确定当前定位应该使用哪一个先验地图,同时也可以解决重定位的问题。</td>   <td>1.一种基于分支定界法的自动切图方法,其特征在于,包括切图触发器,离线处理和分支定界法三个部分,其中,首先,进行离线处理,用户输入某一地图关联的地图,随后算法通过简单的逻辑,将地图关系更新到数据库中；然后,通过切图触发器进行判断是否需要切图,一部分是判断定位数据是否超出地图边界,若超出,则需要切图,进入下一步；另一部分是判断当前点云数据的占据栅格地图与定位所属子图间的匹配得分,若得分低于设定的阈值,则需要切图,也进入下一步；最后,通过分支界定法寻找当前激光雷达采集到的点云属于哪个占据栅格地图,直到寻找到所属的占据栅格地图后,则进行切图；具体步骤包括：首先,将下界定义为用户提供的一个阈值,同时将搜索空间构造为树形结构,内部节点代表一个子搜索空间,叶子节点代表一个精确的结果；开始搜索时从顶层节点开始往下搜索,当遇到一个节点时,根据该节点位姿变换矩阵旋转当前帧占据栅格地图得到新地图,遍历新地图所有点,根据载入的子图占据值更新当前子图旧的占据值,将占据值进行加和,若小于下界,说明结果太差,该分支被剪枝,返回顶层重新查找；若大于上界,继续往下搜索,直到叶子节点,抵达叶子节点后,使用叶子节点占据值得分更新下界,返回顶层重新查找,直到查找到适配的子图。</td>   <td>G06F16/9537;G06F16/53;G06F16/56;G01S7/48</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              陈小燕;                   陈丽娜       </td>   <td>中山大学</td>   <td>语义分割的人脸完整度度量方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113111817B</td>   <td>2023-06-27</td>   <td>本发明公开了语义分割的人脸完整度度量方法。包括：训练人脸检测深度神经网络模型与人脸语义分割深度神经网络模型,之后把待检测图像输入到人脸检测深度神经网络模型,得到待检测图像人脸区域；将人脸区域输入到人脸语义分割深度神经网络模型,得到人脸区域中每个像素的语义分类结果,并进行统计,用未遮挡人脸的像素点总数和遮挡物的像素点总数计算出人脸完整度。本发明还公开了语义分割的人脸完整度度量系统、计算机设备及计算机可读存储介质。本发明使用深度学习和图像语义分割技术,能够得到人脸部分图像精确的、像素级别的分类结果,使人脸遮挡检测结果更加准确,计算得到的遮挡比例能够很好地度量人脸完整度。</td>   <td>1.一种语义分割的人脸完整度度量方法,其特征在于,所述方法包括：组织人脸检测数据集,并利用人脸检测数据集训练得到人脸检测深度神经网络模型,该模型的输出为图像中人脸区域的外接矩形坐标；利用所述图像中人脸区域的外接矩形坐标组织人脸语义分割数据集,并利用人脸语义分割数据集训练得到人脸语义分割深度神经网络模型,该模型的输出为将图像的人脸区域中每个像素分类为背景、未遮挡的人脸和遮挡物的结果；将待检测图像进行预处理,输入到所述人脸检测深度神经网络模型,得到待检测图像中人脸区域的外接矩形坐标；将所述待检测图像中人脸区域的外接矩形坐标输入到所述人脸语义分割深度神经网络模型,得到待检测图像的人脸区域中每个像素的语义分类结果,即把每个像素分类为背景、未遮挡人脸和遮挡物；对所述每个像素的语义分类结果进行统计,得到分类为所述未遮挡人脸类别的像素点总数和所述遮挡物类别的像素点总数,从而得到人脸遮挡比例,若遮挡比例为0,则表示无遮挡,否则为有遮挡,遮挡比例用于衡量遮挡的严重程度,即人脸完整度；其中,所述利用所述图像中人脸区域的外接矩形坐标组织人脸语义分割数据集,并利用人脸语义分割数据集训练得到人脸语义分割深度神经网络模型,该模型的输出为将图像的人脸区域中每个像素分类为背景、未遮挡的人脸和遮挡物的结果,具体为：人脸语义分割数据集是从人脸检测数据集的图片中裁剪出人脸图像,并对人脸图像进行标注生成；首先根据人脸检测数据集图像中人脸区域的外接矩形坐标,从原始图像中裁剪出人脸图像,组成人脸图像数据集；然后对人脸图像进行像素级的分类标注,总共有三个类别：背景、未遮挡人脸和遮挡物,将图像中每个像素标注为其中的一个类别,便得到用于训练人脸语义分割深度神经网络模型的人脸语义分割数据集；使用分层多尺度注意力机制进行语义分割,对每个尺度学习一个密集的掩模,通过在掩模之间进行像素乘法,然后在不同尺度之间进行像素求和,将这些多尺度预测结合起来,得到最终结果；在训练过程中,给定的输入图像按r因子进行缩放,将r＝1和r＝0.5的两幅图像通过共享网络中继发送,对于每个尺度生成语义logit L和用于合并尺度间的logit L的注意力掩码(α)；对于两个尺度的训练和推理,方程形式化为：L-((r＝1))＝U(L-((r＝0.5))*α-((r＝0.5)))+((1-U(α-((r＝0.5))))L-((r＝1)))其中U表示双线性上采样操作,*和+分别表示像素级的乘法和加法；使用标注完成的人脸语义分割数据集对人脸语义分割深度神经网络模型进行训练,得到对人脸图像进行3个类别语义分割的模型；该模型能够对输入的人脸图像进行处理,输出对图像中每个像素进行分类的结果。</td>   <td>G06V40/16;G06V10/26;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              欧锐植;                   周凡       </td>   <td>中山大学</td>   <td>基于稀疏采样进行端到端训练的视频问答方法与系统</td>   <td>广东省</td>   <td>CN113807222B</td>   <td>2023-06-27</td>   <td>本发明公开了一种基于稀疏采样进行端到端训练的视频问答方法。包括：对输入的视频进行稀疏采样得到相同时长的N个视频片段；将采样得到的每一个视频片段进行视觉编码、时间融合、位置嵌入,生成该视频片段的视频特征序列；对文本信息编码得到词向量序列,并对其进行位置嵌入；将N个视频片段特征序列和词向量序列进行交叉模型融合和预测,得到N个预测结果,最后再将N个预测结果融合得到最终答案；输入视频和问题到模型中预测问题答案。本发明也公开了一种基于稀疏采样进行端到端训练的视频问答的系统、设备及存储介质。本发明通过稀疏采样解决视频问答任务的方法,相对于基于注意力模型视频问答方法,本发明模型收敛更快,预测准确性更高。</td>   <td>1.一种基于稀疏采样进行端到端训练的视频问答方法与系统,其特征在于,所述方法包括：收集视频片段数据集,将完整视频进行稀疏采样,选取其中注意力权重高的N个视频片段；利用所述采样得到的每一个视频片段进行预处理,对其视觉编码、时间融合、位置嵌入,生成该视频片段的视频特征序列；利用可训练的词嵌入网络对问题文本信息进行编码,进行位置嵌入操作,得到文本词向量序列；将所述N个视频片段得到的N个视频特征序列分别与所述文本词向量序列进行交叉模型融合和预测,得到N个预测结果,再将N个预测结果进行融合得到最终预测答案；初始化神经网络模型结构中的权重参数,进行端到端训练,至损失函数的结果收敛到合适阈值,训练完成后得到视频问答模型；输入待处理问题和对应的视频到所述训练后的视频问答模型中,利用其生成预测答案；其中,所述利用采样得到的每一个视频片段进行预处理,对其视觉编码、时间融合、位置嵌入,生成该视频片段的视频特征序列,具体为：在视频片段中均匀采样T个帧,使用卷积神经网络对每一帧进行视觉编码,利用卷积层减小特征长度,利用最大池化层进行空间下采样,使用平均池化将帧层次的特征图按时间顺序聚合成一张视频片段层次的特征图,再基于特征图中的特征向量的2维位置,添加行位置嵌入向量和列位置嵌入向量,对所述特征图进行位置嵌入；其中,所述利用可训练的词嵌入网络对问题文本信息进行编码,进行位置嵌入操作,得到文本词向量序列,具体为：利用词嵌入网络中可训练的神经网络将问题文本中的词转换成向量,将所有词向量结合得到一个词向量序列,再根据词的位置信息,添加可训练的位置嵌入向量到每个词向量中,对所述词向量序列进行位置嵌入；其中,所述将所述N个视频片段得到的N个视频特征序列分别与所述文本词向量序列进行交叉模型融合和预测,得到N个预测结果,再将N个预测结果进行融合得到最终预测答案,具体为：将所述每一个视频特征序列与文本词向量序列连接起来输入12层的Transformer模型进行交叉融合和预测,共得到N个预测预测结果,P-i为预测结果：P-i＝Trans(F-v(c-i),F-l(S))其中,Trans表示12层Transformer模型,F-v表示视觉编码器,F-l表示语言编码器,c-i表示第i个采样的视频片段,S表示问题文本序列；使用平均池化对N个预测结果进行融合,得到整个视频的最终预测答案；其损失函数l-(task)具体为：l-(task)＝L(G(P-1,P-2,…,P-N),q),其中,G表示预测答案的聚合函数,q表示问题的正确答案。</td>   <td>G06V20/40;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              孟小哲;              林格;                   苏卓       </td>   <td>中山大学</td>   <td>基于高斯过程映射的迁移学习去雾方法与系统</td>   <td>广东省</td>   <td>CN113808039B</td>   <td>2023-06-27</td>   <td>本发明公开了基于高斯过程映射的迁移学习去雾方法与系统。包括：数据集收集和处理,搭建去雾网络包括编码器模块和解码器模块,通过将有雾图和无雾图输入,获得相应的编码器、解码器参数,进行高斯迁移计算,得到预测值,最终得到去雾图。本发明提供一种能够通过基于高斯过程的迁移学习进行去雾的框架,解决数据域漂移带来的在合成数据上训练模型存在偏差的问题,同时通过迁移学习以及在隐空间中建立函数关系来实现有雾图和无雾图在神经网络上的重建,神经网络的参数可以视为将两个数据域参数化,同时将隐空间中的特征以向量形式储存。在隐空间中建立映射,解决卷积的特征空间难以建立函数关系的问题。</td>   <td>1.基于高斯过程映射的迁移学习去雾方法,其特征在于,所述方法包括：数据收集和预处理,将数据集统一裁剪尺寸,得到的每个有雾图对应一张无雾图；搭建重建网络包括编码器和解码器,解码器与编码器对称,各包含五个模块；将所述有雾图和所述有雾图对应的无雾图输入所述重建网络,所述编码器将输入图像压缩至固定维度,所述解码器负责重建图像,获得有雾图矩阵和无雾图矩阵,保存训练结束后重建损失最小时的有雾图数据集对应的模型参数和无雾图数据集对应的模型参数；迁移所述编码器,记为新编码器,添加一个滤除模块,加载所述有雾图数据集对应的模型参数中编码器部分,保持该参数固定不更新；从真实有雾图数据集中选取新的有雾图,输入所述新编码器中,得到一个新编码器输出结果,变换维度后得到一维向量；迁移所述有雾图矩阵和所述无雾图矩阵,进行降维操作,得到降维后的有雾图矩阵和降维后的无雾图矩阵；将所述新编码器输出结果、所述降维后的有雾图矩阵和所述降维后的无雾图矩阵,进行矩阵变换,输入高斯过程GPM模块,计算得到最终预测值；迁移所述解码器,加载所述无雾图数据集对应的模型参数中解码器部分,保持该参数固定不更新,将所述预测值输入到解码器中,输出所述新的有雾图对应的去雾图；其中,所述将所述有雾图和所述有雾图对应的无雾图输入所述重建网络,所述编码器将输入图像压缩至固定维度,所述解码器负责重建图像,获得有雾图矩阵和无雾图矩阵,保存训练结束后重建损失最小时的有雾图数据集对应的模型参数和无雾图数据集对应的模型参数,具体为：对于所述数据集中任一有雾图,其通道大小为3,尺寸为256*256,其重建流程为：将其输入到所述编码器,输出特征图维度变换成一维向量进行保存；所述数据集中的有雾图共有N张,迭代将所有有雾图全部重建,最终得到维度为(N,32,32,32)的输出,变换为矩阵,其大小为N×32768,记为Z-x,训练结束后保存重建损失最小时的有雾图数据集对应的模型参数w-x；无雾图重建输入为无雾图,与有雾图重建过程一致,输入、中间和输出过程的维度变化也一致,得到矩阵记为Z-y,训练结束后保存重建损失最小时的无雾图数据集对应的模型参数w-y；其中,所述从真实有雾图数据集中选取新的有雾图,输入所述新编码器中,得到一个新编码器输出结果,变换维度后得到一维向量,具体为：从真实有雾图数据集中选取新的有雾图,输入新编码器,得到一个维度为(32,32,32)的输出,记为z-u；将z-u变换成一维向量记为z-(uv),维度为(1,32768)；其中,所述迁移所述有雾图矩阵和所述无雾图矩阵,进行降维操作,得到降维后的有雾图矩阵和降维后的无雾图矩阵,具体为：所述有雾图矩阵Z-x的每一行使用高斯核计算一个相似度,Z-x有N行,所以可得到N个相似度值,将该相似度值排序,选择最大的前32个值,反向计算出这32个值在Z-x的行号,记为n；从Z-x中根据行号n选择出对应的数据构成降维后的有雾图矩阵Z′-x,维度为(32,32768)；所述有无雾图矩阵Z-y进行相同降维操作,根据行号n选择出对应的数据构成降维后的无雾图矩阵Z′-y,维度为(32,32768)；其中,所述将所述新编码器输出结果、所述降维后的有雾图矩阵和所述降维后的无雾图矩阵,进行矩阵变换,输入高斯过程GPM模块,计算得到最终预测值,具体为：将新编码器输出结果z-u变换为(32,1024)的矩阵,记为将Z′-x和Z′-y变换为(1024,1024)的矩阵；将高斯过程GPM模块引入,依据如下公式进行计算：                                    其中K表示核计算,为超参数,核函数使用高斯核,高斯核的计算公式如下为：                  其中l为超参数,则输出维度为(32,1024),/&gt;表示先求核函数K(Z′-x,Z′-x),再对K(Z′-x,Z′-x)的对角线上加上/&gt;然后再求逆,计算输出维度为(1024,1024),/&gt;是三个矩阵相乘,输出的预测值z-(pre)维度为(32,1024),cov为方差,/&gt;计算输出维度为(32,32),的输出维度为(32,32),所以cov的维度为(32,32)。</td>   <td>G06T5/00;G06N3/0464;G06N3/0455;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              银磊;              刘智勇;              赵铜铁钢;              涂新军;              康丽;              林岚;              田世拓;                   孙姗珍       </td>   <td>中山大学</td>   <td>基于向量自回归模型的降雨量-气温关系分析方法及装置</td>   <td>广东省</td>   <td>CN116340441A</td>   <td>2023-06-27</td>   <td>本发明涉及生态水文技术领域,公开了基于向量自回归模型的降雨量-气温关系分析方法及装置。本发明获取包括日尺度上的降雨量序列及气温序列在内的目标地区的历史水文数据,对数据进行平稳性检验以确定其中的平稳序列和非平稳序列；对各所述平稳序列进行格兰杰因果检验,以筛选出存在因果关系的降雨量-气温序列；基于筛选出的降雨量-气温序列,构建向量自回归模型并进行模型稳定性验证,基于得到的目标向量自回归模型,通过脉冲响应与方差分解分析降雨量与气温间的双向作用机理。本发明实现了短时间尺度的降雨量-气温相关性分析,能够深入揭示降雨与气温两大水文主要要素间的双向作用机理。</td>   <td>1.一种基于向量自回归模型的降雨量-气温关系分析方法,其特征在于,包括：获取目标地区的历史水文数据；所述历史水文数据包括各目标水文站点测量的在日尺度上的降雨量序列及气温序列；对所述历史水文数据进行平稳性检验,以确定所述历史水文数据中的平稳序列和非平稳序列；对各所述平稳序列进行格兰杰因果检验,以筛选出存在因果关系的降雨量-气温序列；基于筛选出的降雨量-气温序列,构建向量自回归模型并进行模型稳定性验证,得到目标向量自回归模型；基于所述目标向量自回归模型,通过脉冲响应与方差分解分析降雨量与气温间的双向作用机理。</td>   <td>G06F16/28;G06F16/21;G06F16/2458;G06F16/9537;G06F17/10;G06F17/15;G06F17/18;G01W1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         左晟;              刘垚;              王明羽;                   虞志益       </td>   <td>中山大学</td>   <td>一种存储安全与加固系统及其实现方法</td>   <td>广东省</td>   <td>CN116341028A</td>   <td>2023-06-27</td>   <td>本发明公开了一种存储安全与加固系统及其实现方法,通过对待运行程序进行进制转换和文件分离得到指令部分和数据部分,将指令部分进行加密后与数据部分合并后进行汉明码编码并存储,当取指时,处理器从存储器查找出指令部分并依次进行汉明码译码和解密得到待执行指令,当访存时,处理器从存储器查找出数据部分并进行译码得到待访问数据,同时还可以对待访问数据进行汉明码编码后重新存入存储器。本发明克服了传统指令随机化方法性能损失大、容易遭到破坏、对内存中的指令没有实际保护以及传统汉明码纠错能力不足的问题,提高了存储器中指令与数据的安全性和可靠性,可广泛应用于数据处理技术领域。</td>   <td>1.一种存储安全与加固系统,其特征在于,包括指令加密模块、汉明码编码模块、汉明码译码模块、指令解密模块、存储器以及处理器,其中：所述指令加密模块用于将待运行程序转换为二进制文件,并将所述二进制文件的指令部分与数据部分分离,进而对所述二进制文件的指令部分进行加密后得到加密指令,再将所述加密指令与所述二进制文件的数据部分合并,生成加密文件；所述汉明码编码模块用于对所述加密文件进行汉明码编码得到编码加密文件,并将所述编码加密文件存入所述存储器中；在取指阶段,所述处理器用于向所述存储器的对应地址查找指令,取出所述编码加密文件的指令部分,并通过所述汉明码译码模块对所述编码加密文件的指令部分进行译码和校验得到所述加密指令,进而通过指令解密模块对所述加密指令进行解密得到待执行指令；在访存阶段,所述处理器用于向所述存储器的对应地址查找数据,取出所述编码加密文件的数据部分,并通过所述汉明码译码模块对所述编码加密文件的数据部分进行译码和校验得到待访问数据,还用于通过所述汉明码编码模块对所述待访问数据进行编码得到所述编码加密文件的数据部分,并将所述编码加密文件的数据部分存入所述存储器中。</td>   <td>G06F21/78;G06F21/60;H04L9/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         南玥;                   胡嘉镗       </td>   <td>中山大学</td>   <td>一种耦合泥沙过程的河流河口一体化水质模型建立方法</td>   <td>广东省</td>   <td>CN116341264A</td>   <td>2023-06-27</td>   <td>本发明属于水文水质模型技术领域,具体涉及一种耦合泥沙过程的河流河口一体化水质模型建立方法,解决了现有技术中存在操作复杂、模拟失真以及缺乏真实性的问题,包括如下步骤：S1、建立完整一维河网水文水质模型；S2、建立完整三维河口水文水质模型,本发明提供一种耦合了泥沙模块的河网河口水文水质模型一体化的操作,以解决上述操作复杂和模拟失真的缺点,添加贴近真实的泥沙模块来增加模拟真实性,在建立一体化模型的基础上,加入了泥沙模块实现更真实的河网河口一体化模型,实现了河流到河口一体、泥沙对水质影响、简化模型输入、削减模拟时长以及模拟次数等功能。</td>   <td>1.一种耦合泥沙过程的河流河口一体化水质模型建立方法,其特征在于,包括如下步骤：S1、建立完整一维河网水文水质模型,模型必要文件由包括河道数、断面数、上游边界点、与河口连接的边界点以及节点数组成；S2、建立完整三维河口水文水质模型,模型必要文件由包括河口网格、地形、与河网连接的边界点以及与海水连接的边界点组成；S3、在步骤S1和步骤S2中获取到的连接边界,采用显式耦合交替计算连接一维河网水文水质模型和三维水文水质模型,使在连接断面上三维河口水文水质模型供给一维河网水文水质模型的变化,一维河网水文水质模型供给三维河口水文水质模型的变化；S4、在步骤S2中添加河口泥沙模块；S5、将步骤S4中的泥沙模块引入富营养化,步骤S4中的工作使一体化模型中水质的模块拥有计算的泥沙结果,将泥沙结果连接进入富营养化模块；在河口区实现泥沙对水质的控制；S6、构建河网河口一体化模型,构建包含可执行程序的耦合模型库。</td>   <td>G06F30/20;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              汪洁;              林昊;              蔡倬;              赵山河;              张文锋;                   纳颖泉       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>异常检测方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN116342242A</td>   <td>2023-06-27</td>   <td>本申请涉及一种异常检测方法、装置、计算机设备、存储介质和计算机程序产品。方法包括：确定待检测的目标对象的对象信息,得到目标对象信息；将当前参考信息输入到已训练的信息生成网络中进行信息生成,得到当前生成信息；已训练的信息生成网络具有生成正常的对象信息的功能；基于目标对象信息与当前生成信息之间的信息差异值更新当前参考信息；返回将当前参考信息输入到已训练的信息生成网络中进行信息生成,得到当前生成信息的步骤,直到满足返回停止条件为止,将当前生成信息确定为目标生成信息；基于目标生成信息和目标对象信息,对目标对象进行异常检测。采用本方法能够提高异常检测的效率。</td>   <td>1.一种异常检测方法,其特征在于,所述方法包括：确定待检测的目标对象的对象信息,得到目标对象信息；将当前参考信息输入到已训练的信息生成网络中进行信息生成,得到当前生成信息；所述已训练的信息生成网络具有生成正常的对象信息的功能；基于所述目标对象信息与所述当前生成信息之间的信息差异值更新所述当前参考信息；返回所述将当前参考信息输入到已训练的信息生成网络中进行信息生成,得到当前生成信息的步骤,直到满足返回停止条件为止,将当前生成信息确定为目标生成信息；基于所述目标生成信息和所述目标对象信息,对所述目标对象进行异常检测。</td>   <td>G06Q40/03;G06F18/241;G06N3/0475;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭键清;              张弛;                   韩瑜       </td>   <td>中山大学</td>   <td>基于空间运动目标三维重构的几何参数辨识方法及系统</td>   <td>广东省</td>   <td>CN116342621A</td>   <td>2023-06-27</td>   <td>本发明公开了基于空间运动目标三维重构的几何参数辨识方法及系统,该方法包括：获取单目视觉图像数据和稀疏点云数据；对单目视觉图像数据进行像素级分割与拟合,构建空间运动目标的光学模型；基于视觉映射方法将稀疏雷达的稀疏点云数据与光学模型进行融合,得到点云粗提取结果；基于迭代匹配多视角点云融合方法对点云粗提取结果进行融合处理；基于特征和学习混合法对点云融合结果进行三维重构并对空间运动目标的几何参数进行自主辨识。通过使用本发明,能够提高空间运动目标三维重构和几何参数自主辨识的精确性、稳定性以及时效性。本发明作为基于空间运动目标三维重构的几何参数辨识方法及系统,可广泛应用于计算机视觉领域。</td>   <td>1.基于空间运动目标三维重构的几何参数辨识方法,其特征在于,包括以下步骤：通过单目摄像头与多线激光雷达对空间运动目标进行视觉图像数据与激光点云数据的采集,且基于不同视角进行多次采集,得到单目视觉的图像数据和稀疏点云数据；通过自主视觉区域分割法对单目视觉的图像数据进行像素级分割与拟合,构建空间运动目标的光学模型；基于视觉映射方法将稀疏雷达的稀疏点云数据与空间运动目标的光学模型进行融合,得到空间运动目标的点云粗提取结果；基于迭代匹配空间运动目标多视角点云融合方法对空间运动目标的点云粗提取结果进行融合处理,得到空间运动目标的点云融合结果；基于特征和学习混合的方法对空间运动目标的点云融合结果进行三维重构并根据重构结果对空间运动目标的几何参数进行自主辨识,得到辨识结果。</td>   <td>G06T7/11;G06T7/215;G06T5/50;G06T5/30;G06T7/207;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              池浩鑫;              林昊;              蔡倬;              赵山河;              邬稳;                   梁万山       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>图像处理加速方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN116343013A</td>   <td>2023-06-27</td>   <td>本申请涉及一种图像处理加速方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：将同一网络层对应的输出尺寸和输入尺寸分别输入对应的终端回归模型和服务器端回归模型,得到各个网络层分别对应的预测终端时延和预测服务器端时延；基于各个网络层分别对应的输出尺寸和目标带宽,计算各个网络层分别对应的上传时延；融合当前网络层的各个前向网络层分别对应的预测终端时延、当前网络层对应的预测终端时延、当前网络层的各个后向网络层分别对应的预测服务器端时延、以及当前网络层对应的上传时延,得到当前网络层对应的总时延；基于各个网络层分别对应的总时延,从各个网络层中确定目标层。采用本方法能够提高图像处理效率。</td>   <td>1.一种图像处理加速方法,其特征在于,所述方法包括：获取图像处理网络中各个网络层类型分别对应的终端回归模型和服务器端回归模型、以及所述图像处理网络中各个网络层分别对应的输出尺寸和输入尺寸,获取目标带宽；将同一网络层对应的输出尺寸和输入尺寸分别输入对应的终端回归模型和服务器端回归模型,得到所述各个网络层分别对应的预测终端时延和预测服务器端时延；基于所述各个网络层分别对应的输出尺寸和所述目标带宽,计算所述各个网络层分别对应的上传时延；融合当前网络层的各个前向网络层分别对应的预测终端时延、当前网络层对应的预测终端时延、当前网络层的各个后向网络层分别对应的预测服务器端时延、以及当前网络层对应的上传时延,得到当前网络层对应的总时延；基于所述各个网络层分别对应的总时延,从所述各个网络层中确定目标层；所述目标层和所述目标层对应的各个前向网络层用于在终端进行数据处理,所述目标层对应的各个后向网络层用于在服务器中进行数据处理。</td>   <td>G06V10/96;G06V10/94;G06V30/19;G06V10/766;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚顺;              王宗明;              谭奕珩;              罗玉;                   王海军       </td>   <td>中山大学附属第一医院;广东工业大学</td>   <td>基于对比学习的医学影像模态转换方法、系统和存储介质</td>   <td>广东省</td>   <td>CN116344003A</td>   <td>2023-06-27</td>   <td>本发明公开的基于对比学习的医学影像模态转换方法、系统和存储介质,所述方法包括：获取源目标影像数据；根据所述源目标影像数据进行分析,得到所述源目标影像数据的内容特征和模态特征；将所述源目标影像数据的模态特征转换为目标模态特征；将所述目标模态特征与所述源目标影像数据的内容特征进行合并解码,得到目标模态影像。本发明通过一种基于对比学习的方法从源模态影像转换到目标模态影像,从而避免了同一个体的同一解剖结构反复扫描。本发明专利在模态空间进行转换,能够避免以往方法在图像空间转换下的歧义性,能够进一步提高转换效率和精度。</td>   <td>1.基于对比学习的医学影像模态转换方法,其特征在于,包括：获取源目标影像数据；根据所述源目标影像数据进行分析,得到所述源目标影像数据的内容特征和模态特征；将所述源目标影像数据的模态特征转换为目标模态特征；将所述目标模态特征与所述源目标影像数据的内容特征进行合并解码,得到目标模态影像。</td>   <td>G16H30/40;G06T3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         秦启元;              郭佶睿;              邓艳红;              曹务腾;                   胡华斌       </td>   <td>中山大学附属第六医院</td>   <td>一种MSI分型确定方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN116344037A</td>   <td>2023-06-27</td>   <td>本发明公开了一种MSI分型确定方法、装置、电子设备及存储介质,用途解决现有的MSI分型确定方法存在对患者造成损伤的风险,且诊断流程复杂,患者的就诊时间长和经济负担大的技术问题。本发明包括：获取结直肠癌的历史病例影像学检查数据；对所述历史病例影像学检查数据进行标注,得到标注区域；根据所述标注区域确定裁剪尺寸；按照所述裁剪尺寸对所述历史病例影像学检查数据和所述标注区域进行裁剪,得到裁剪图像；采用所述裁剪图像生成训练样本；采用所述训练样本训练深度学习模型；将待分析图像输入已训练的深度学习模型,得到图像判别结果；获取诊断所需临床数据；根据所述图像判别结果和所述诊断所需临床数据确定MSI分型。</td>   <td>1.一种MSI分型确定方法,其特征在于,包括：获取结直肠癌的历史病例影像学检查数据；对所述历史病例影像学检查数据进行标注,得到标注区域；根据所述标注区域确定裁剪尺寸；按照所述裁剪尺寸对所述历史病例影像学检查数据和所述标注区域进行裁剪,得到裁剪图像；采用所述裁剪图像生成训练样本；采用所述训练样本训练深度学习模型；将待分析图像输入已训练的深度学习模型,得到图像判别结果；获取诊断所需临床数据；根据所述图像判别结果和所述诊断所需临床数据确定MSI分型。</td>   <td>G16H50/20;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杜向军;              唐静;              韩婧琳;              魏杰;              王奕涵;              林毅珊;              唐康;              曾金锋;              邱泽凯;              陈绎霖;                   程佩文       </td>   <td>中山大学·深圳;中山大学</td>   <td>流感易感标志物和基于该标志物的流感高危人群预测模型的构建方法与应用</td>   <td>广东省</td>   <td>CN116344067A</td>   <td>2023-06-27</td>   <td>本发明公开了流感易感标志物和基于该标志物的流感高危人群预测模型的构建方法与应用,该流感易感标志物为“AMFR”、“HBQ1”、“DHRS9”、“SLC35E2A”、“BANK1”、“CD79A”、“TXNDC5”、“H2BC5”和“PRKY”的组合。该标志物和基于其建立的流感风险预测模型是基于健康成年人基线水平转录组的数据得到的,能够用于筛选健康成年人中甲型流感H3N2易感个体,AUC为0.94、准确度为0.91、精确度为1、召回率为0.75、F1评分为0.86,具有较好的准确度。</td>   <td>1.一组流感易感标志物,其特征在于,所述流感易感标志物为ADORA3、CD36、ANXA3、PPP1R15A、ABHD2、ANKRD11、RPS23、UQCRH、ACOX1和DSC1；所述流感优选包括H3N2。</td>   <td>G16H50/80;G16B20/00;G16B40/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;              黄柳红;                   李熙莹       </td>   <td>中山大学</td>   <td>一种车辆所在车道快速划分方法</td>   <td>广东省</td>   <td>CN111079668B</td>   <td>2023-06-23</td>   <td>本发明公开一种车辆所在车道快速划分方法,适用于直线车道区域,包括以下步骤：根据图像中的直线车道区域,得到各个车道线与各个车辆关键点的交点差值；计算相邻车道线之间的交点差值的乘积；根据交点差值的乘积判断各个车辆的所属车道。本发明通过矩阵运算,获取所有车辆所在车道信息的方法,仅通过三次矩阵运算,便可获取道路面内所有车辆的所在车道信息,计算量不大,整体运算速度快。</td>   <td>1.一种车辆所在车道快速划分方法,适用于直线车道区域,其特征在于,包括以下步骤：根据图像中的直线车道区域,得到各个车道线与各个车辆关键点的交点差值；若存在车道线的斜率k＝0的情况,通过下式计算交点差值：                  上式中,所述的O-(0,0),O-(0,1),…,O-(m-1,n-1)为各个车道线在各个车辆关键点下的交点差值；所述的k-0,k-1,…,k-(m-1)为各个车道线的斜率；所述的b-0,b-1,…,b-(m-1)为各个车道线的截距值；所述的y-0,y-1,…,y-(n-1)为各个车辆的关键点纵坐标值；所述的x-0,x-1,…,x-(n-1)为各个车辆的关键点的横坐标值；                  若不存在车道线的斜率k＝0的情况,通过下式计算交点差值：其中,          if k-j＝∞ and X-j＝a上式中,所述的k-j表示第j条车道线的斜率；所述的b-j表示第j条车道线的截距值；所述的X-j＝a为第j条车道线的表达式；计算相邻车道线之间的交点差值的乘积；根据交点差值的乘积判断各个车辆的所属车道。</td>   <td>G06V20/54</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱金汉;                   陈立新       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种注量谱分布计算建模、注量谱分布计算方法及装置</td>   <td>广东省</td>   <td>CN115270588B</td>   <td>2023-06-23</td>   <td>本发明公开了一种注量谱分布计算建模、注量谱分布计算方法及装置,包括：搜集图像数据,根据图像数据完成蒙特卡罗模拟计算,获得训练数据,所述训练数据包括粒子的入射注量谱分布和出射注量谱分布；根据所述入射注量谱分布,对所述图像数据进行预处理,生成训练输入数据；基于图形处理器构建初始神经网络模型,并根据训练输入数据和训练数据对所述初始神经网络模型进行重复训练和评估,并更新模型参数；直至达到预设条件后,停止训练迭代,保存模型参数,以完成神经网络模型的构建。本发明通过以蒙特卡罗模拟计算作为神经网络模型训练目标,保证了注量谱分布计算的精度和效率。</td>   <td>1.一种注量谱分布计算建模方法,其特征在于,包括：搜集图像数据,根据图像数据完成蒙特卡罗模拟计算,获得训练数据,所述训练数据包括粒子的入射注量谱分布和出射注量谱分布；根据所述入射注量谱分布,对所述图像数据进行预处理,生成训练输入数据；将所述图像数据转换为电子密度分布图,并根据粒子的入射注量谱分布,构建入射注量谱分布矩阵；基于电子密度分布图,构建空间物理距离矩阵；将所述电子密度分布图、空间物理距离矩阵和入射注量谱分布矩阵进行连接整合,得到训练输入数据；所述基于电子密度分布图,构建空间物理距离矩阵,具体为：根据电子密度分布图获取电子密度网格每个网格点对应的物理坐标,计算每个网格点与放射源的距离和放射源归一化距离,并构建源距离平方反比因子矩阵；根据电子密度分布图获取电子密度网格每个网格点对应的物理坐标,计算每个网格点到放射源所在中心轴的垂直距离,构建离轴距离矩阵；将所述源距离平方反比因子矩阵和所述离轴距离矩阵进行连接整合,获得空间物理距离矩阵；基于图形处理器构建初始神经网络模型,并根据训练输入数据和训练数据对所述初始神经网络模型进行重复训练和评估,并更新模型参数；直至达到预设条件后,停止训练迭代,保存模型参数,以完成神经网络模型的构建。</td>   <td>G06F30/25;G06F30/27;G06T1/40;G06N3/006;G06N3/0455;G06N3/048;G06N3/08;G06N7/01;G06F111/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;              曾世豪;              黄文津;                   陈清坤       </td>   <td>中山大学</td>   <td>关于二值权重DenseNet模型的混合流水式加速架构及加速方法</td>   <td>广东省</td>   <td>CN112001492B</td>   <td>2023-06-23</td>   <td>本发明公开了一种关于二值权重DenseNet模型的混合流水式加速架构及加速方法,其中所述的加速系统包括控制单元,用于根据各个模块的状态指示信号,协调顶层模块的流水线工作,控制数据的输入输出；片上存储模块,用于存储网络参数；设有7个顶层模块,顶层模块之间通过插入ping-pong缓存结构实现流水式并行工作,7个顶层模块分别为首层、第一密集块、第一过渡层、第二密集块、第二过渡层、第三密集块、分类层；对DenseNet的第一密集块、第二密集块、第三密集块分别设置一个可复用卷积计算单元对其进行处理；所述的首层是一个卷积层,对来自片外存储的输入图片数据进行处理；所述的分类层,用于将产生分类结果存储到片外存储模块。本发明降低了深层网络模型的实现难度,并且提高了计算效率和吞吐量。</td>   <td>1.一种关于二值权重DenseNet模型的混合流水式加速架构,其特征在于：包括控制单元,片上存储模块,顶层模块；所述的控制单元,用于根据各个模块的状态指示信号,协调顶层模块的流水线工作,控制数据的输入输出；所述的片上存储模块,用于存储网络参数；所述的顶层模块设有7个,顶层模块之间通过插入ping-pong缓存结构实现流水式并行工作,7个所述的顶层模块分别为首层、第一密集块、第一过渡层、第二密集块、第二过渡层、第三密集块、分类层；对DenseNet的第一密集块、第二密集块、第三密集块分别设置一个可复用卷积计算单元对其进行处理；所述的首层是一个卷积层,对来自片外存储的输入图片数据进行处理,将数据依次输入第一密集块、第一过渡层、第二密集块、第二过渡层、第三密集块、分类层进行处理；所述的分类层,用于将产生分类结果存储到片外存储模块；所述的顶层模块之间通过插入ping-pong缓存结构实现流水式并行工作,具体如下：在密集块处理过程中,输入特征图和输出特征图共用一个存储空间,当前级的输出特征图有效并且当前密集块的“缓存A”或“缓存B”空闲时,前级模块即可将输出特征图转移到密集块的缓存空间,此时前级模块的缓存得到释放；为了提高数据的访问效率,对网络特征图和二值卷积设置相应的存储格式,具体如下：对于网络特征图存储格式：假设特征图尺寸为(C,H,W),C表示特征图的通道数量,H和W则分别表示单通道特征图的高和宽；通过采用的CHWT-i格式将C维度的T-i表示输入并行度个数据组合为一个新的数据,其中T-i表示输入并行度,将特征图被分成ceil(C/T-i)个部分,并指定顺序在存储空间连续存放；T-i表示当前密集块的输入并行度；对于二值卷积参数的存储格式,假设卷积核尺寸为(N,C,K,K),N表示输出特征图,C表示输出特征图的数量,K表示卷积核的大小；每个地址存储K*K*Ti bits的组合参数,用于Ti个输入特征图的部分卷积；而每组卷积核可分成ceil(C/T-i)个组合参数,并且按照指定顺序在存储空间连续存放；根据以上数据存储格式,对典型卷积层数据流进行优化,并结合密集块的输入输出并行度和顶层模块的ping-pong缓存结构,设置与之相应的计算单元的并行度系数,从而提高计算效率。</td>   <td>G06N3/082;G06N3/0464;G06F9/38</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗洁;                   张亮军       </td>   <td>中山大学</td>   <td>一种基于磁共振T1增强图像的脑血管图像分割方法</td>   <td>广东省</td>   <td>CN109949322B</td>   <td>2023-06-23</td>   <td>本发明涉及医学影像处理技术领域,涉及一种基于T1增强图像的脑血管图像分割方法,该方法包括：1.对头部磁共振T1增强图像数据进行预处理；2.对脑血管进行自动分割,可利用交互式方法对自动分割结果进行修正；3.根据分割结果自动标记出动脉和静脉；4.交互式对血管进行颜色渲染。本发明利用T1增强图像数据对脑血管进行全体或局部提取,并区分出其中的动脉和静脉,最后进行三维重构,允许用户交互式的对提取过程以及展示效果进行修改,全面的展示出脑血管三维分布状态。</td>   <td>1.一种基于T1增强图像的脑血管图像分割方法,其特征在于,包括以下步骤：S1.对头部磁共振T1增强图像数据进行预处理；S2.对预处理后的脑血管图像进行自动分割,利用交互式方法对自动分割结果进行修正,得到修正分割结果；具体为：根据T1增强图像的脑血管图像与其他组织的灰度差异进行脑血管的自动分割,分割结果是以体素为基本元素的影像数据；交互式方法对自动分割结果进行修正是：基于参数的修正和基于标记点或控制点的修正；S3.根据修正分割结果自动标记出动脉和静脉；具体包括：首先识别出具有明显特征的动脉和静脉区域,然后将这些区域作为种子点进行区域生长并对动脉和静脉进行建模,建模结果是以顶点为基本元素的图形学数据；所述建模是对分割出的动脉和静脉血管进行面绘制,所述面绘制是将血管表面用细小网格进行划分,形成密布于血管表面的顶点,相邻顶点连接成边,由此形成非常多三角形的面；S4.对血管用不同颜色进行渲染。</td>   <td>G06T7/11;G06T7/187;G06T17/20;G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              王弘焌;              王广润;                   张冬雨       </td>   <td>中山大学</td>   <td>一种行人重识别系统对抗样本生成方法及系统</td>   <td>广东省</td>   <td>CN111160217B</td>   <td>2023-06-23</td>   <td>本发明公开了一种行人重识别系统对抗样本生成方法及系统,该方法包括：S1,将原始图片输入至基于残差网络的生成器中,生成对抗扰动；S2,将对抗扰动按位加至原始图片,生成粗对抗样本I′,并将其与原始图片作特征连接,输入多阶段判别器以生成可控制对抗扰动点数量的二元掩模图；S3,将二元掩模图与对抗扰动按位乘法,并添加到原始图片中,生成扰动点数量可控的对抗样本S4,将对抗样本输入至待攻击的行人重识别模型将模型的返回值作为特征混淆损失函数、对抗学习损失函数、经平滑的分类混淆函数及多尺度结构相似损失函数的输入；S5,多次迭代式地进行S1-S4的训练过程,更新生成器与多阶段判别器的参数。</td>   <td>1.一种行人重识别系统对抗样本生成方法,包括如下步骤：步骤S1,将原始输入图片I输入至基于残差网络的生成器中,生成对抗扰动/&gt;步骤S2,将步骤S1中生成的对抗扰动按位加至原始输入图片I,生成粗对抗样本I～′,并将其与原始输入作特征连接,输入至多阶段判别器/&gt;以生成可控制对抗扰动点数量的二元掩模图/&gt;步骤S3,将所述二元掩模图与所述对抗扰动/&gt;施以按位乘法,并添加到原始输入图片I中,生成扰动点数量可控的对抗样本/&gt;步骤S4,将步骤S3中生成的对抗样本输入至待攻击的行人重识别模型/&gt;将模型的返回值作为特征混淆损失函数/&gt;对抗学习损失函数/&gt;经平滑的分类混淆函数及多尺度结构相似损失函数/&gt;的输入；步骤S5,多次迭代式地进行步骤S1-S4的训练过程,更新所述生成器与多阶段判别器/&gt;的参数,步骤S3中最后生成的对抗样本/&gt;即为经过优化的可欺骗行人重识别系统的对抗样本；于步骤S2中,所述多阶段判别器由图像金字塔阶段及阶段金字塔阶段构成,在图像金字塔阶段生成多种分辨率的特征图集/&gt;在阶段金字塔阶段,根据图像金字塔阶段的特征图集/&gt;生成可控制对抗扰动点数量的二元掩模图/&gt;步骤S2进一步包括：步骤S200,在图像金字塔阶段,采用并列、结构相同但互不共享参数的三个卷积神经网络将步骤S1中生成的对抗扰动拷贝三份,每一个子网络接收不同尺度的图像输入,经过五次卷积及三次降采样后,分别输出三张具有不同感受野的高维特征图每个特征特图再以均方误差作为损失函数监督；步骤S201,在阶段金字塔阶段挑选出所有同分辨率的特征图,将其作按位加法,然后不断将低分辨率的特征图进行上采样,逐步按位加到后一层更大分辨率的特征图上,最后通过一次反卷积操作生成与原图大小一致的预掩模图步骤S202,以所述预掩模图作为Gumbel softmax的输入,使得所述预掩模图/&gt;二值化,并通过一个超参数τ控制掩模图中置1的数量,从而生成最终的掩模图/&gt;</td>   <td>G06V40/10;G06V10/764;G06V10/82;G06N3/0475;G06N3/0464;G06N3/048;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              张穗安;                   卢泽丰       </td>   <td>中山大学</td>   <td>一种基于聚类生成伪标签的无监督行人重识别方法及系统</td>   <td>广东省</td>   <td>CN112836675B</td>   <td>2023-06-23</td>   <td>本发明公开了一种基于聚类生成伪标签的无监督行人重识别方法及系统,该方法包括：构建浅层网络A、深层网络B和浅层网络C并对网络进行训练,得到训练完成的浅层网络C；基于训练完成的浅层网络C对待查行人图像和数据库行人图像进行特征提取并计算特征距离,得到相似度列表。该系统包括：训练模块和识别模块。通过使用本发明,能够很好的减少伪标签噪声带来的对无监督行人重识别的影响,提高识别性能。本发明作为一种基于聚类生成伪标签的无监督行人重识别方法及系统,可广泛应用于行人重识别领域。</td>   <td>1.一种基于聚类生成伪标签的无监督行人重识别方法,其特征在于,包括以下步骤：获取带标签的行人图像训练集并对特征提取网络进行初步训练,得到浅层网络A和深层网络B；将行人图像经过数据增强后分别输入到浅层网络A和深层网络B,得到对应的特征向量f-A和f-B；将特征向量f-A和f-B进行拼接融合,得到融合后特征向量f-(cat)；基于融合后特征向量f-(cat)对行人图像数据集的特征向量进行聚类,并为行人图像数据集中的行人图像赋予伪标签；基于伪标签对浅层网络A和深层网络B进行训练并根据浅层网络A的参数对浅层网络C进行更新,得到训练完成的浅层网络C；将待查行人图像和数据库行人图像输入到训练完成的浅层网络C,得到待查行人图像特征和数据库行人图像特征集合；对待查行人图像特征和数据库行人图像特征集合进行特征距离计算,得到相似度列表；所述浅层网络A和深层网络B设有引导机制,所述浅层网络C与浅层网络A结构一致,所述浅层网络C处于浅层网络A、深层网络B和聚类的环外；根据浅层网络A的参数对浅层网络C进行更新,具体采用动量更新的方式,每一轮对浅层网络A的更新后,根据浅层网络A的现有参数,对浅层网络C进行更新,直至浅层网络A的参数不再变更；所述根据浅层网络A的参数对浅层网络C进行更新具体用公式表示为：C-t＝λC-(t-1)+(1-λ)A-t其中,C-t表示的是t时刻浅层网络C的参数,A-t表示的是t时刻浅层网络A的参数,λ是平衡因子。</td>   <td>G06V20/52;G06V10/44;G06V10/80;G06V10/774;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              吴捷;                   林倞       </td>   <td>中山大学</td>   <td>一种语言描述引导的视频时序定位方法</td>   <td>广东省</td>   <td>CN111274438B</td>   <td>2023-06-23</td>   <td>本发明公开了一种语言描述引导的视频时序定位方法,包括如下步骤：步骤S1,提取跨模态特征的多模态特征编码网络,以用于学习视频和自然语言的跨模态信息,获得所输入的语言和视觉模态的多模态融合表征；步骤S2,采用层次化的树状结构策略,对跨模态信息进行层次化分解；步骤S3,采用渐进强化学习机制,通过两个任务导向的奖励来提供正确的学分分配,鼓励树状结构中的不同策略的相互促进,本发明通过基于树结构的渐进强化学习框架来模拟人类由粗到精的决策过程,可以有效地分解复杂的动作策略,在增加搜索空间的同时减少搜索步骤的数量,以更合理的方式获得更令人印象深刻的结果。</td>   <td>1.一种语言描述引导的视频时序定位方法,包括如下步骤：步骤S1,提取跨模态特征的多模态特征编码网络,以用于学习视频和自然语言的跨模态信息,获得所输入的语言和视觉模态的多模态融合表征；步骤S2,采用层次化的树状结构策略,对跨模态信息进行层次化分解；步骤S3,采用渐进强化学习机制,通过两个任务导向的奖励来提供正确的学分分配,鼓励树状结构中的不同策略的相互促进；于步骤S2中,所述树状结构策略包含根策略和叶策略,所述根策略决定主要依赖哪个子叶策略,叶策略对应于五个高级语义分支,所选的语义分支通过相应的子网络推理一个该分支下更加精炼的动作；所述五个高级语义分支分别为尺度变化,左显著移动,右显著移动,左精细调整以及右精细调整；步骤S3进一步包括：步骤S300,利用外部奖赏训练叶策略的actor分支；步骤S301,用MSE损失函数训练叶策略的critic分支；步骤S302,利用外部奖赏和内部奖赏相结合的方法来训练根策略的actor分支；步骤S303,利用MSE损失函数训练根策略的critic分支；步骤S304,基于渐进强化学习机制,根据迭代次数计算目前选择的策略并训练；于步骤S300中,所述叶策略的奖励函数揭示了原始动作/&gt;对当前环境的影响,其在外部环境中直接获得:                  其中ε代表的是奖励系数,U-t代表的是当前时刻的IoU大小,U-(t-1)代表的是上一时刻的IoU大小；所述根策略的奖励函数设计如下:                            为遍历所有可能的分支,并将相应的原始操作推理到环境中,生成5个不同的IoU中的最大IoU。</td>   <td>G06F16/73;G06N3/0464;G06N3/048;G06N3/08;G06V10/80;G06V20/40;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田珂珂;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于自注意力的生成式文本摘要方法</td>   <td>广东省</td>   <td>CN110597979B</td>   <td>2023-06-23</td>   <td>本发明提供一种基于自注意力的生成式文本摘要方法,该方法抛弃了以往文本摘要方法中常用的循环神经网络结构,转而采用了基于自注意力机制的方法,避免了循环神经网络结构的低效性。此外对于自注意力机制方法在生成摘要效果不佳的缺点,本发明对其该方法进行了改进,简化了其结构,最终实现了高效、准确的文本摘要生成。</td>   <td>1.一种基于自注意力的生成式文本摘要方法,其特征在于,包括以下步骤：S1：建立基于自注意力机制的文本摘要模型,模型包括基于自注意力机制的编码器和基于注意力机制的解码器,其中编码器的参数被解码器共享；所述步骤S1的具体过程是：S11：构建字词的向量表示层：先将文字转换成数字表示,即用向量表示层来完成；S12：构建基于自注意力机制的编码器,编码器包括多头注意力层和全连接层,接收来自于向量表示层的向量,并提取其中隐藏的特征,以向量形式输出；S13：构建基于注意力机制的解码器,解码器包括多头注意力层和全连接层,接收来自于编码器的特征,并根据此特征来生成摘要文本；S2：建立文本摘要模型的对应的损失函数；所述步骤S2的具体过程是：文本摘要模型的损失函数由负对数似然函数给出：                  其中,为输入原文文本,/&gt;为摘要序列,m&lt;n,似然函数表示在当前模型参数下,得到摘要序列的概率,而该概率,即在当前模型参数下,得到摘要序列中每个词的概率相乘：          ；S3：进行文本摘要模型的训练,并在目标文本数据集上测试；所述步骤S3的具体过程是：S31：对于训练集中的输入原文文本,对其进行分词,每个词输入到向量表示层得到其对应的向量,并输入到编码器,编码器提取每个词的特征,对每个词产生一个向量/&gt;,则对于原文序列有矩阵/&gt;,对于训练集中的摘要序列/&gt;,做相同的处理,得到矩阵表示/&gt;；S32：将S31得到的向量表示H和S,共同输入到解码器中,解码器来预测一个摘要序列；S33：将和/&gt;作为损失函数的输入,计算损失值,并进行梯度回传,以更新文本摘要模型参数,训练文本摘要模型；S34：对于训练集中的所有数据,重复S31-S33,迭代10次左右,即可完成文本摘要模型的训练,将训练好的文本摘要模型保存。</td>   <td>G06F16/34;G06F40/284</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏泳娴;              陈修治;              吴建平;                   刘礼杨       </td>   <td>广州地理研究所;中山大学</td>   <td>不同气候区下城市绿地降温效应定量评估方法与系统</td>   <td>广东省</td>   <td>CN110750896B</td>   <td>2023-06-23</td>   <td>本发明公开了一种不同气候区下城市绿地降温效应定量评估方法及系统,涉及城市绿地降温评估技术领域,其基于干旱指数,将全球观测样点划分为干旱区、半干旱半湿润区、中度湿润区和极度湿润区,结合实地观测与卫星遥感技术,在此基础上分析不同气候区内蒸散量与不同植被类型降温效应之间的关系、叶面积指数与不同植被类型降温效应之间的关系,全面构建了以蒸散量和/或叶面积指数为表征参数的草地类型、灌丛类型、乔木类型和乔灌草复合结构类型分别在干旱区、半干旱半湿润区、中度湿润区和极度湿润区内的降温效应评估模型。</td>   <td>1.一种不同气候区下城市绿地降温效应定量评估方法,其特征在于,包括：步骤1：获取待评估样地的月平均温度、归一化植被指数、年均降雨量、月均降雨量和月实际日照时数；步骤2：根据年均降雨量、月实际日照时数和月平均温度计算获得植被干旱指数；步骤3：根据植被干旱指数将全球划分为干旱区、半干旱半湿润区、中度湿润区和极度湿润区四种气候区,并判断待评估样地所属的气候区；步骤4：根据归一化植被指数计算获得叶面积指数,根据月均降雨量、月平均温度和月实际日照时数计算获得蒸散量；步骤5：根据叶面积指数和/或蒸散量建立待评估样地的降温效应评估模型,通过降温效应评估模型获得待评估样地植被类型的降温效应量；步骤6：当降温效应量大于或等于0℃,此处绿地植被对周围环境产生增温或无影响的效果；当降温效应量小于0℃,此处绿地植被对周围环境产生降温的效果；根据年均降雨量、月实际日照时数和月平均温度计算获得植被干旱指数为：AI＝P-aPET式中,P-a表示年均降雨量,单位为mm,PET表示潜在蒸散量,单位为mm,潜在蒸散量为：                  式中,T为月平均温度,单位为℃,S为月实际日照时数,单位为小时,I为热量指数：                  a为经验常数：a＝(0.675×I～3-77.1×I～2+17920×I+492390)×10～(-6)；根据叶面积指数建立干旱区内不同植被类型的降温效应评估模型为：草地植被类型：                  灌丛类型植被类型：                  乔木植被类型：                  乔灌草复合结构植被类型：                  式中：LAI表示叶面积指数,表示干旱区中草地类型的降温效应；/&gt;表示干旱区中灌丛类型的降温效应；/&gt;表示干旱区中乔木类型的降温效应；/&gt;表示干旱区中乔灌草复合结构类型的降温效应；根据蒸散量和叶面积指数建立半干旱半湿润区不同植被类型的降温效应评估模型为：草地植被类型：                                    灌丛类型植被类型：                  乔木植被类型：                  乔灌草复合结构植被类型：                  式中,LAI表示叶面积指数,ET表示蒸散量；表示当温度T&gt;30℃且蒸散量ET&gt;697.4mm时,半干旱半湿润区内草地类型的降温效应；/&gt;表示其他状态下,半干旱半湿润区内草地类型的降温效应；/&gt;半干旱半湿润区内灌丛类型的降温效应；/&gt;表示半干旱半湿润区内乔木类型的降温效应,/&gt;半干旱半湿润区内乔灌草复合结构类型的降温效应；根据蒸散量和叶面积指数建立中度湿润区内不同植被类型的降温效应评估模型为：草地植被类型：                  灌丛类型植被类型：                  乔灌草复合结构植被类型：                  式中,LAI表示叶面积指数；ET表示蒸散量；表示中度湿润区内草地类型的降温效应；/&gt;表示中度湿润区内灌丛类型的降温效应；/&gt;表示中度湿润区内乔灌草复合结构类型的降温效应；根据蒸散量建立极度湿润区内不同植被类型的降温效应评估模型为：草地植被类型：                  乔木植被类型：                  乔灌草复合结构植被类型：                  式中,ET表示蒸散量；表示极度湿润区内草地类型的降温效应；/&gt;表示极度湿润区内乔木类型的降温效应,/&gt;表示极度湿润区内乔灌草复合结构类型的降温效应。</td>   <td>G06F30/20;G01N21/17;G01W1/00;G06F119/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐萌;              蔡敏;              程芷兰;              陈宣亦;              李佩;              王毅豪;              谭汝铿;                   李自立       </td>   <td>中山大学附属口腔医院</td>   <td>一种基于Unity 3D的三维牙体模型构建方法及系统</td>   <td>广东省</td>   <td>CN109920047B</td>   <td>2023-06-23</td>   <td>本发明公开了一种基于Unity 3D的三维牙体模型构建方法及系统,该方法包括如下步骤：步骤S1,扫描牙体获取图像数据,并对牙体图像数据进行图像处理,通过三维重建技术根据牙体图像对牙体进行三维重建,得到牙体的三维模型；步骤S2,制作牙磨片,并通过采集各牙磨片的镜下结构建立数字化牙磨片图库；步骤S3,利用Unity 3D,于所述Unity 3D中导入牙体三维模型,调整所述牙体三维模型,得到最终的三维牙体模型,根据所述最终的三维牙体模型,以实现牙体的任意旋转、缩放并显示具体结构信息,并提供牙体内外结构,通过本发明,可解决实验室缺乏牙体模型以及学生难以收集牙位齐全、结构典型的牙体的问题。</td>   <td>1.一种基于Unity 3D的三维牙体模型构建方法,包括如下步骤：步骤S1,扫描牙体获取牙体图像数据,并对牙体图像数据进行图像处理,通过三维重建技术根据牙体图像数据对牙体进行三维重建,得到牙体的三维模型；步骤S1进一步包括：步骤S100,进行牙体收集；步骤S101,利用CT扫描牙体,获取由CT扫描的牙体图像数据,并对牙体图像进行灰度处理；步骤S102,根据获得的牙体图像数据,利用三维重建技术对牙体进行三维重建,得到牙体的三维模型；步骤S101中,利用CT扫描获得所述牙体的若干截面图像；步骤S102进一步包括：步骤S102a,对获得的牙体图像数据进行分割；步骤S102b,基于分割后的牙体图像数据,应用Matlab对图像相减,提取出牙髓；步骤S102c,根据获得的牙体的图像序列,建立掩模,取合适的门限,对每张断层图像掩模正确后,采用三维重建技术,得到牙体的三维模型；步骤S2,制作牙磨片,并通过采集各牙磨片的镜下结构建立数字化牙磨片图库；步骤S3,利用Unity 3D,于所述Unity 3D中导入牙体数据三维模型及其对应各牙磨片的镜下结构,调整并实现所述牙体的三维模型,得到最终的三维牙体模型,根据所述最终的三维牙体模型,以实现牙体的任意旋转、缩放并显示具体结构信息,并提供牙体内外结构。</td>   <td>G06T17/00;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘芳;              郑伟诗;              邝嘉健;              关杰鸿;                   张青       </td>   <td>中山大学</td>   <td>基于三维重建技术的虚拟数据集开发方法、系统及存储介质</td>   <td>广东省</td>   <td>CN112669448B</td>   <td>2023-06-23</td>   <td>本发明公开了一种基于三维重建技术的虚拟数据集开发方法、系统及存储介质,所述方法包括以下步骤：批量建模人物模型；重建三维真实场景模型；构建虚拟数据集。本发明主要目的在于克服真实数据集的隐私问题以及采集周期长,成本高等问题,提供一种基于三维重建技术的虚拟数据集开发方法、系统及存储介质,通过开发一种结合人物建模技术以及三维场景重建技术的虚拟场景仿真平台,实现重建三维真实场景模型,批量建模人物模型和批量生成大量视角、空间位置、姿态、性别、肤色、年龄、着装风格各异的行人图像。</td>   <td>1.一种基于三维重建技术的虚拟数据集开发方法,其特征在于,包括以下步骤：批量建模人物模型,所述人物模型包括肤色、身高、体重、性别及着装；重建三维真实场景模型,利用无人机拍摄采集真实场景多视角全覆盖RGB图像,从多张多视角2D图像中推算3D信息,实现三维真实场景模型的重建；所述重建三维真实场景模型的过程具体为：对无人机检测系统的摄像头进行标定,确定世界坐标系中某一点与像素坐标系中该点的坐标对应关系；利用无人机检测系统对现实场景进行环绕拍摄,获得多视角全覆盖RGB图像；利用三维重建算法从所述多视角全覆盖RGB图像中提取并匹配特征点,恢复图像方位信息,根据射影几何计算特征点的空间三维坐标,实现三维真实场景模型的重建；所述实现三维真实场景模型的重建的过程具体为：使用尺度不变特征变换法提取任意两张图像中的特征点并进行匹配,确定图像之间的位置关系,计算图像方位信息；使用光束平差法恢复特征点的空间三维坐标；通过插值算法加密特征点组成的点云；将所述点云网格化,生成并贴上纹理,得到三维真实场景模型；构建虚拟数据集,基于人物模型和三维真实场景模型进行虚拟场景仿真平台仿真,在场景中的不同位置标定摄像机,采集不同摄像机角度,同一行人不同角度、不同动作的图像,得到虚拟数据集；构建虚拟数据集的过程具体为：模拟真实场景中摄像机的位置,在重建的三维真实场景模型中添加摄像机；实时加载人物模型；切换仿真过程中摄像机观察视角；设计人物模型状态转换机,并实现人物动作的切换；改变人物模型在场景中的位置和角度,实现人物模型的移动及旋转,用于收集同一摄像机视角下同一行人不同角度的图像；人物模型图像的采集,具体为：将每个摄像机视角的图像保存在一个单独的文件夹中,根据预先设置的时间间隔保存当前摄像机视角下的图像到对应文件夹中。</td>   <td>G06T17/00;G06T13/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈汉嵘;              谢晓华;                   韦宝典       </td>   <td>中山大学</td>   <td>一种基于双摄头的列车车厢人群密度估计方法</td>   <td>广东省</td>   <td>CN110414301B</td>   <td>2023-06-23</td>   <td>本发明公开一种基于双摄头的列车车厢人群密度估计方法,包括：提出多视角人群密度估计网络,该网络由两部分组成,一部分是参数共享的卷积神经网络,另一部分是全连接层,该网络能区分当前列车车厢的人群密度等级。模型训练阶段,使用具有5类密度等级的样本进行迭代优化；模型应用阶段,依照地铁实际运行情况有规律抽样估计。本发明基于深度学习方法估计人群密度,采用卷积神经网络自动学习特征来取代以往手工设计的特征,以提高人群密度估计的准确率和鲁棒性。</td>   <td>1.一种基于双摄头的列车车厢人群密度估计方法,其特征在于,包括如下步骤：S10准备训练样本：建立包含4个参数共享的卷积层和5个全连接层的神经网络,输入同一车厢内相同时刻的两个不同视角的视频帧,训练具有密度等级的标签的样本,其中卷积层用于提取视频的特征向量,全连接层用于将卷积层所提取出的特征向量按密度等级进行分类；所述5个全连接层包括FC5、FC6、FC7、FC8和Softmax层,第四个Conv层输出双摄头的两张36×58×8的特征图,分别输入到全连接层FC5-0和FC5-1,得到两组1024维的特征向量；两组向量分别输入到FC6-0层和FC6-1层得到两组512维的特征向量,接着两组512维的特征向量进行相加操作得到新的一组512维特征向量；该新的一组512维特征向量输入到FC7层得到256维的特征向量；再将该256维的特征向量输入到FC8层得到128维的特征向量；最后将该128维的特征向量输入到Softmax层得到一组5维的概率向量；S20神经网络训练：数次迭代优化训练神经网络；S30应用阶段：截取双摄头拍摄的当前列车车厢的视频帧分别输入至优化后的神经网络,将两视频帧进行加权融合,得到当前列车车厢的图像分类结果,计算公式如下：class＝argmax{[F(X-1；θ)+F(X-2；θ)]/2}其中F(X-i；θ)为网络模型的输出,X-1,X-2分别为两个摄像头输入的图像,θ为收敛模型的参数。</td>   <td>G06V20/52;G06V10/764;G06V10/82;G06N3/0464;G06N3/047;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         文译辉;              龙宇栋;              项毅帆;              文卫平;              雷文斌;              林浩添;              肖钧;                   郭翀       </td>   <td>中山大学附属第一医院;中山大学中山眼科中心</td>   <td>一种鼻咽癌辅助诊断模型构建和辅助诊断方法及系统</td>   <td>广东省</td>   <td>CN111653365B</td>   <td>2023-06-23</td>   <td>本发明公开了一种鼻咽癌辅助诊断模型构建和辅助诊断方法及系统,涉及医疗数据处理技术领域。其中鼻咽癌辅助诊断模型构建方法,包括：样本获取：获取鼻内镜图像,所述鼻内镜图像包含鼻咽癌组和非鼻咽癌组；预处理：对所述鼻内镜图像进行预处理；模型训练：将预处理后的鼻内镜图像输入卷积神经网络中,对所述卷积神经网络进行训练,获得鼻咽癌辅助诊断模型。本发明能对鼻内镜图像进行分析并实时输出预测患病概率以辅助医师进行鼻咽癌诊断,可有效提高鼻咽癌诊断的准确率,提高活检的检出率,从而实现鼻咽癌早筛早诊早治,改善患者的治疗效果和预后的目的。</td>   <td>1.一种鼻咽癌辅助诊断模型构建方法,其特征在于,包括以下步骤：S01、样本获取：获取鼻内镜图像,所述鼻内镜图像包含鼻咽癌组和非鼻咽癌组；S02、预处理：对所述鼻内镜图像进行预处理；S03、模型训练：将预处理后的鼻内镜图像输入卷积神经网络中,对所述卷积神经网络进行训练,获得鼻咽癌辅助诊断模型；所述步骤S02预处理中,包括以下步骤：S021、对鼻内镜图像进行筛选,剔除失焦、模糊或过曝光的不合格图像,保留显像清晰的合格图像；S022、将所述合格图像进行旋转、平移、剪切、放缩和通道转移的操作进行数据扩增,以增加样本量；S023、将所述合格图像分为训练数据集和验证数据集；所述步骤S03模型训练中,所述卷积神经网络为InceptionResNetv2,所述InceptionResNetv2包括stem模块、InceptionResNet模块、Reduction模块、AveragePooling层、Dropout层和Softmax层；所述步骤S03模型训练包括以下步骤：S031、将所述训练数据集中的某张鼻内镜图像输入所述stem模块中,通过所述stem模块对所述鼻内镜图像进行卷积计算、最大池化操作和特征拼接,以初步提取所述鼻内镜图像的特征获得特征图像Y；S032、将所述特征图像Y输入所述InceptionResNet模块和所述Reduction模块中,通过所述InceptionResNet模块对所述特征图像Y进行Relu激活、卷积计算、线性卷积激活、特征拼接操作进一步提取特征,通过所述Reduction模块减小图像尺寸,将所述特征图像Y转化为图像特征矩阵Z；S033、将所述图像特征矩阵Z输入所述AveragePooling层进行均值池化操作抽象为特征向量F；将所述特征向量F依次通过所述Dropout层进行随机失活操作、所述Softmax层进行逻辑回归操作,使所述特征向量F转化为二分类输出P,所述二分类输出P∈(0,1),用于表示预测患病概率；S034、通过交叉熵计算公式计算所述二分类输出P与该鼻内镜图像真实标签之间的交叉熵损失；将所述交叉熵损失通过梯度下降算法反向传播至所述卷积神经网络,用于更新所述卷积神经网络的网络参数；S035、将所述验证数据集中的某张鼻内镜图像输入所述卷积神经网络中,根据输出的预测患病概率计算分类结果评价指标对本轮模型训练效果进行内部测试；S036、依次输入多张不同的鼻内镜图像,重复所述步骤S031-S35,不断更新优化所述卷积神经网络的网络参数,使所述卷积神经网络的二分类输出P不断逼近真实标签；在完成指定的迭代周期后,或者当内部测试的分类结果评价指标在指定的迭代周期内不再上升时,所述鼻咽癌辅助诊断模型训练完成；所述步骤S03模型训练之后还包括步骤S04外部测试,所述步骤S04外部测试具体为：将所述验证数据集中的某张鼻内镜图像输入所述鼻咽癌辅助诊断模型中,根据输出的预测患病概率计算分类结果评价指标来反映该鼻咽癌辅助诊断模型预测的准确性。</td>   <td>G16H50/50;G16H30/40;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              张瓅丹;              吴攀;              蔡承志;              郑炎辉;              康丽;              林岚;              孙姗珍;                   田世拓       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种基于DEM数据的坡面产汇流简易计算方法及装置</td>   <td>广东省</td>   <td>CN116305933A</td>   <td>2023-06-23</td>   <td>本发明涉及水文模拟技术领域,公开了一种基于DEM数据的坡面产汇流简易计算方法及装置。本发明以DEM数据栅格对目标区域进行划分并构建分布式水文模型,对该模型进行调整以使其所模拟的产流过程考虑因洼地滞水导致的净雨损失；该模型在进行汇流计算时基于Dijkstra算法计算各栅格的产流按流向汇至流域出口的最短路径,基于谢才公式计算属于河涌的栅格的水流流经时间,基于Kerby方程计算属于地表坡面的栅格的水流流经时间,以简化计算且保证计算精度,并基于Chapman-Maxwell滤波法从总流量中分割出地面径流以得到更好的分割效果。本发明实现了在进行坡面产汇流计算时同时兼顾高计算效率与高模拟精细度。</td>   <td>1.一种基于DEM数据的坡面产汇流简易计算方法,其特征在于,包括：获取目标区域的用于坡面产汇流计算的基础数据；所述基础数据包括地形DEM数据、子汇水区划分结果及对应倾泻点分布数据；对所述基础数据进行包括插值处理在内的预处理,得到目标基础数据；以DEM数据栅格对所述目标区域进行划分,并根据所述目标基础数据构建所述目标区域的分布式水文模型；构建洼地向外产流条件；所述洼地向外产流条件假设洼地向外产流时下垫面的土壤含水量达到最大潜在蓄水能力；根据所述洼地向外产流条件调整所述分布式水文模型,使得调整后的分布式水文模型所模拟的产流过程考虑因洼地滞水导致的净雨损失；对所述调整后的分布式水文模型进行率定和验证,得到满足预置模拟精度要求的目标分布式水文模型；基于所述目标分布式水文模型进行所述目标区域的坡面产汇流预报。</td>   <td>G06F30/20;G06Q10/047</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李庆军;              杨广;              沈昊;              麦仰维;              夏竹叶;                   孙志阳       </td>   <td>中山大学</td>   <td>基于绝对节点坐标法的太空粘弹性梁响应预测方法</td>   <td>广东省</td>   <td>CN116305978A</td>   <td>2023-06-23</td>   <td>本发明公开了基于绝对节点坐标法的太空粘弹性梁响应预测方法,该方法包括：构建考虑梁单元阻尼力的太空仿真环境；基于控制变量法计算不同梁单元参数影响下的阻尼比；对不同梁单元参数下的阻尼比进行曲线拟合,得到梁单元的拟合阻尼比公式；根据预期阻尼比和梁单元参数通过拟合阻尼比公式得到梁单元的阻尼系数；根据梁单元的阻尼系数选择合适的梁单元材料,实现对梁单元振动的有效抑制。通过使用本发明,能够在拟合出阻尼比公式之后,基于预期阻尼比和梁单元参数快速求解出对应的阻尼系数,从而实现对梁单元振动的减缓效果。</td>   <td>1.一种基于绝对节点坐标法的太空粘弹性梁响应预测方法,其特征在于,包括以下步骤：构建考虑梁单元阻尼力的太空仿真环境；基于控制变量法计算不同梁单元参数影响下的阻尼比；对不同梁单元参数下的阻尼比进行曲线拟合,得到梁单元的拟合阻尼比公式；根据预期阻尼比和梁单元参数通过拟合阻尼比公式得到梁单元的阻尼系数；根据梁单元的阻尼系数选择合适的梁单元材料,实现对梁单元振动的有效抑制。</td>   <td>G06F30/20;G06F30/13;G06F17/16;G06F111/10;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢鹏;              廖佳华;              陈昇琳;              易明月;                   尹家栋       </td>   <td>中山大学</td>   <td>基于数字孪生的吊机监测方法、计算机设备及存储介质</td>   <td>广东省</td>   <td>CN116306114A</td>   <td>2023-06-23</td>   <td>本发明公开了一种基于数字孪生的吊机监测方法、计算机设备及存储介质,涉及吊机技术领域,方法包括：构建吊机机臂网格模型；将实时动态数据输入预先训练好的RBF代理模型,以输出粗网格节点的实时粗网格变形数据及实时粗网格应力数据；根据实时粗网格变形数据或实时粗网格应力数据对吊机机臂网格模型进行上色处理,以生成含有云图效果的吊机机臂模型；根据实时部件关系对预先构建好的吊机机臂等比例三维模型进行处理,以生成不含云图效果的样机模型；根据吊机机臂模型及样机模型,构建吊机机臂的应力-应变数字孪生模型。采用本发明,可准确了解吊机在运作过程中几何形态和应力-应变状态变化,保障吊机安全运行,降低施工过程中的安全隐患。</td>   <td>1.一种基于数字孪生的吊机监测方法,其特征在于,包括：根据预设粗网格节点的粗网格节点位置数据构建目标吊机的吊机机臂网格模型；获取物理空间中目标吊机的实时动态数据,并将所述实时动态数据输入预先训练好的RBF代理模型,以输出所述粗网格节点的实时粗网格变形数据及实时粗网格应力数据；根据所述实时粗网格变形数据或实时粗网格应力数据对所述吊机机臂网格模型进行上色处理,以生成含有云图效果的吊机机臂模型；获取目标吊机的实时部件关系,并根据所述实时部件关系对预先构建好的吊机机臂等比例三维模型进行处理,以生成不含云图效果的样机模型；根据所述吊机机臂模型及样机模型,构建吊机机臂的应力-应变数字孪生模型。</td>   <td>G06F30/23;G06F30/27;G06N3/0499;G06N3/08;B66C13/16;G06F111/10;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张冬雨;              贾德成;              林倞;                   文英鹏       </td>   <td>中山大学</td>   <td>一种分布式深度学习模型更新方法及装置</td>   <td>广东省</td>   <td>CN116306913A</td>   <td>2023-06-23</td>   <td>本发明公开一种分布式深度学习模型更新方法及装置,通过获取分布式深度学习模型的真实梯度值,根据所述真实梯度值及公式进行计算得到预测梯度值,利用所述预测梯度值更新所述分布式深度学习模型的模型参数。本发明通过预测梯度值实现对分布式深度学习模型的模型参数的更新,减少了模型不断迭代的训练时间,且通过预测梯度值的训练结果与标准同步的随机梯度下降SGD相当,进一步的提高了模型训练的效率及弱可拓展性。</td>   <td>1.一种分布式深度学习模型更新方法,其特征在于,包括：获取分布式深度学习模型的真实梯度值g-t；根据所述真实梯度值g-t及如下公式计算得到预测梯度值D-t＝(1-β-t)D-(t-1)+β-tg-(t-1)                                    其中,D-t表示第t次迭代的平滑梯度指数,β-t表示第一惩罚系数,D-(t-1)表示第t-1次迭代的平滑梯度指数,g-(t-1)表示第t-1次迭代的真实梯度值,v-t表示第t次迭代的平滑梯度指数D-t与真实梯度值g-t之间的预测误差,α表示第二惩罚系数,表示第t-1次迭代中真实梯度值与预测梯度值之间的误差,/&gt;表示第t次迭代的预测梯度值；利用所述预测梯度值更新所述分布式深度学习模型的模型参数。</td>   <td>G06N3/098;G06N3/04;G06V20/52;G06V20/54;G06V20/58;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郝迈;              由林麟;              陈振武;              梁晨;                   蔡铭       </td>   <td>中山大学;深圳市城市交通规划设计研究中心股份有限公司</td>   <td>一种面向多版本知识图谱的实体匹配方法、装置及介质</td>   <td>广东省</td>   <td>CN116306933A</td>   <td>2023-06-23</td>   <td>本发明公开了一种面向多版本知识图谱的实体匹配方法、装置及介质,方法包括：获取历史版本的知识图谱数据,构建知识图谱版本库；确定各版本知识图谱内的实体编号及实体标签；计算各个实体的文本属性特征向量；构建包含各个实体及邻近实体的实体集；提取每一实体集的特征矩阵,得到数据集；计算每一实体的节点特征；计算每一实体的特征值与损失；将每一实体的损失进行共享以及反向传播,计算版本间实体的相似度,完成实体匹配。本发明基于孪生-图卷积神经网络,能够精确提取实体的节点特征,可以完成在多版本、不同尺寸知识图谱间的实体匹配。本发明降低了复杂度,提高了准确率及效率,可广泛应用于计算机技术领域。</td>   <td>1.一种面向多版本知识图谱的实体匹配方法,其特征在于,包括：获取历史版本的知识图谱数据,构建知识图谱版本库；确定所述知识图谱版本库中各版本知识图谱内的实体编号及实体标签；计算各个实体的文本属性特征向量；根据图结构搜索每一实体的邻近实体,构建包含各个实体及邻近实体的实体集；根据所述文本属性特征向量和所述实体集之间的连接属性,提取每一实体集的特征矩阵,得到数据集；根据孪生神经网络,按照不同版本分别将实体输入图卷积子网络,计算每一实体的节点特征；根据相似度评价函数、损失函数以及所述知识图谱版本库中各版本知识图谱内的实体编号和实体标签,计算每一实体的特征值与损失；将每一实体的损失进行共享以及反向传播,根据所述孪生神经网络计算的每一实体的节点特征,计算版本间实体的相似度,完成实体匹配。</td>   <td>G06N5/022;G06F18/22;G06F16/36;G06F16/21;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄殷旎;              周檬;                   李伊帆       </td>   <td>中山大学</td>   <td>一种基于贝叶斯网络的人口合成方法</td>   <td>广东省</td>   <td>CN116308947A</td>   <td>2023-06-23</td>   <td>本发明公开了一种基于贝叶斯网络的人口合成方法,包括：获取研究区域内的微观人口样本信息与关键社会经济属性的统计分布信息；得到样本数据后,根据对家庭成员的年龄跨度计算家庭结构类型,并将个人信息与家庭信息进行匹配,得到样本数据；获取每个家庭结构下家庭层和个人层包含各属性之间联合概率的最优的贝叶斯网络；根据贝叶斯网络对样本数据进行随机采样,得到符合人口总量的初步合成人口；根据社会经济属性的统计分布信息,通过迭代比例拟合方法对初步合成人口进行边缘控制调整,得到符合社会经济属性统计分布的目标合成人口。本发明利用微观样本生成符合关键社会经济属性的人口信息,降低了计算复杂度,可广泛应用于计算机技术领域。</td>   <td>1.一种基于贝叶斯网络的人口合成方法,其特征在于,包括：获取研究区域内的微观人口样本信息与关键社会经济属性的统计分布信息；对所述微观人口样本信息和所述统计分布信息进行预处理,得到样本数据；根据对家庭成员的年龄跨度计算家庭结构类型,并将个人信息与家庭信息进行匹配,得到具有家庭结构的样本数据；根据具有家庭结构的样本数据,利用爬山算法和赤池信息量准则获取每个家庭结构下家庭层和个人层包含各属性之间联合概率的最优的贝叶斯网络；根据所述贝叶斯网络对所述样本数据进行随机采样,得到符合人口总量的初步合成人口；根据所述关键社会经济属性的统计分布信息,通过迭代比例拟合方法对所述初步合成人口进行边缘控制调整,得到符合社会经济属性统计分布的目标合成人口。</td>   <td>G06Q50/26;G06F17/18;G06N7/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              蔡庆玲;                   黄载裕       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于三维感知全局对应性学习的虚拟换衣方法及系统</td>   <td>广东省</td>   <td>CN116309024A</td>   <td>2023-06-23</td>   <td>本发明提出一种基于三维感知全局对应性学习的虚拟换衣方法,涉及图像生成的技术领域,采集成对的原始人像-目标人像图并生成目标衣服图、原始人像IUV图和目标人像IUV图,输入平行双支路编码器,将输出的特征数据构建为特征金字塔,利用特征金字塔的顶层特征构建相关性矩阵,然后将相关性矩阵变换为初级流估计,结合特征金字塔各层级的特征逐层生成不同层级的光流估计,直到得到最终流估计,再将最终流估计结果应用于目标衣服图,得到变形衣服图,最后将变形衣服图与目标人像图同时输入条件式生成器,得到虚拟换衣结果,有效结合了三维人体先验信息,使得在不同人体姿态和视角条件下生成更加准确的虚拟换衣结果。</td>   <td>1.一种基于三维感知全局对应性学习的虚拟换衣方法,其特征在于,包括：S1.采集成对的原始人像-目标人像图,从原始人像图中提取目标衣服图并生成原始人像IUV图,根据目标人像图生成目标人像IUV图；S2.将目标衣服图、原始人像IUV图和目标人像IUV图分别输入平行双支路编码器,将输出的特征数据构建为特征金字塔,利用特征金字塔的顶层特征构建相关性矩阵；S3.将相关性矩阵变换为初级流估计,结合特征金字塔各层级的特征逐层生成不同层级的光流估计,直到得到最终流估计；S4.将最终流估计结果应用于目标衣服图,得到变形衣服图,将变形衣服图与目标人像图同时输入条件式生成器,得到虚拟换衣结果。</td>   <td>G06T3/00;G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吕星;              邓一术;              经秉中;              陈浩华;              柯梁汝;              李超峰;              谢传淼;                   孙颖       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>动态分析时序MR图像的方法、系统、设备和存储介质</td>   <td>广东省</td>   <td>CN116309604A</td>   <td>2023-06-23</td>   <td>本发明涉及医学影像处理技术领域,公开了动态分析时序MR图像的方法、系统、设备和存储介质,包括获取待测样本的时序MR图像,对所述时序MR图像进行图像融合,得到第一MR图像,所述时序MR图像包括在预设时间内顺序采集的多个原始MR图像；将所述第一MR图像输入预先训练好的卷积神经网络模型进行图像特征提取,得到图像特征图；将所述图像特征图按照最近邻原则划分为若干个特征块,对所述特征块进行特征融合,得到第二MR图像；将所述第二MR图像输入预先训练好的Transformer网络模型进行图像分类预测,得到对应的分类结果。本发明能够挖掘时间序列MR图像的图像特征,充分分析图像特征动态演变规律及整合全局图像信息。</td>   <td>1.一种动态分析时序MR图像的方法,其特征在于,包括：获取待测样本的时序MR图像,对所述时序MR图像进行图像融合,得到第一MR图像,所述时序MR图像包括在预设时间内顺序采集的多个原始MR图像；将所述第一MR图像输入预先训练好的卷积神经网络模型进行图像特征提取,得到图像特征图；将所述图像特征图按照最近邻原则划分为若干个特征块,对所述特征块进行特征融合,得到第二MR图像；将所述第二MR图像输入预先训练好的Transformer网络模型进行图像分类预测,得到对应的分类结果。</td>   <td>G06T7/00;G06V10/764;G06V10/774;G06V10/82;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐瑞华;              骆卉妍;              贺龙君;              李超峰;              邓一术;              经秉中;                   陈浩华       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>基于深度学习和状态转移的内窥镜检查质控方法及系统</td>   <td>广东省</td>   <td>CN116309605A</td>   <td>2023-06-23</td>   <td>本发明提供了一种基于深度学习和状态转移的内窥镜检查质控方法及系统,所述方法包括：根据内窥镜检查项目,得到部位检查逻辑集后,实时获取内窥镜的当前检查帧图像,并根据预设部位识别模型和部位检查逻辑集,对当前检查帧图像进行预测分析得到当前帧部位预测结果,再根据当前帧部位预测结果和部位检查逻辑集,得到当前帧部位识别结果,并根据当前帧部位识别结果更新检查记录,以及根据检查记录,进行相应的质控显示。本发明通过在内窥镜检查质控中引入解剖逻辑结构先验知识,实现科学有效地规范内窥镜检查流程,提高医生工作效率的同时,保证内窥镜的检查质量,避免误诊漏诊,提高病损的检出率,进而提高患者的生存质量。</td>   <td>1.一种基于深度学习和状态转移的内窥镜检查质控方法,其特征在于,所述方法包括以下步骤：根据内窥镜检查项目,得到部位检查逻辑集；所述部位检查逻辑集包括所述内窥镜检查项目中各个待检查部位的状态转移集；实时获取内窥镜的当前检查帧图像,并根据预设部位识别模型和所述部位检查逻辑集,对所述当前检查帧图像进行预测分析,得到当前帧部位预测结果；根据所述当前帧部位预测结果和所述部位检查逻辑集,得到当前帧部位识别结果,并根据所述当前帧部位识别结果,更新检查记录；所述检查记录包括已检查部位、检查完成占比和下一步待检查部位；根据所述检查记录,判断是否完成所述内窥镜检查项目,并进行相应的质控显示。</td>   <td>G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑颖丰;                   刘奕志       </td>   <td>中山大学中山眼科中心</td>   <td>眼科OCT图像的高清快速配准方法</td>   <td>广东省</td>   <td>CN116309753A</td>   <td>2023-06-23</td>   <td>本发明涉及一种眼科OCT图像的高清快速配准方法,尤其涉及OCT技术领域,包括：数据分析模块根据数据获取模块获取的OCT图像的信噪比以判定参考图像和浮动图像；数据分析模块确定数据获取模块获取的第一像素坐标值以根据第一像素坐标值所处坐标水平判定第一像素坐标值是否为最优像素坐标值；在判定第一像素坐标值处于第一坐标水平或第三坐标水平时,根据第一像素坐标值与最小像素坐标值的第一坐标差值或第一像素坐标值与最大像素坐标值的第二坐标差值对浮动图像进行调整；数据分析模块确定数据获取模块获取的第二像素坐标值是否为整数,若不为整数则数据分析模块对浮动图像进行插值以使第二像素坐标值符合标准；提高了对眼科OCT图像的配准精度。</td>   <td>1.一种眼科OCT图像的高清快速配准方法,其特征在于,包括：步骤S1、数据分析模块根据数据获取模块获取的OCT图像的信噪比以判定参考图像和浮动图像；步骤S2、所述数据分析模块确定所述数据获取模块获取的第一像素坐标值,以根据所述第一像素坐标值所处坐标水平判定所述第一像素坐标值是否为最优像素坐标值；步骤S3、在判定所述第一像素坐标值处于第一坐标水平或第三坐标水平时,根据所述第一像素坐标值与最小像素坐标值的第一坐标差值或所述第一像素坐标值与最大像素坐标值的第二坐标差值对所述浮动图像进行调整；步骤S4、所述数据分析模块确定所述数据获取模块获取的第二像素坐标值是否为整数,若所述第二像素坐标值不为整数,则所述数据分析模块对所述浮动图像进行插值以使所述第二像素坐标值符合标准；其中,所述数据分析模块确定所述第二像素坐标值与距离所述第二像素坐标值最近的整数的数值的数值差值,将所述数值差值与数值差值阈值进行比对,根据比对结果确定对所述浮动图像的插值数量。</td>   <td>G06T7/33;G06T7/73;G06T7/00;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭晓军;              介璐;              张乐天;              吴加学;                   任杰       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种基于连续运动模型的激光SLAM方法及系统</td>   <td>广东省</td>   <td>CN116309809A</td>   <td>2023-06-23</td>   <td>本发明公开了一种基于连续运动模型的激光SLAM方法及系统,该方法包括：获取激光点云数据并提取特征点；基于捆绑调整对特征点进行特征关联,得到地标特征；基于连续运动模型对地标特征进行观测与计算,得到地标特征的观测残差；构建平滑残差并与地标特征的观测残差进行联合优化,得到地标特征的位姿与速度；基于滑动窗口选取关键帧和对地标特征的观测残差进行计算优化,并结合地标特征的位姿与速度构建地图。该系统包括：特征点提取模块、地标关联模块、残差构建模块、联合优化模块和建图模块。通过使用本发明,能够降低建图过程中的累积误差且减少计算量。本发明作为一种基于连续运动模型的激光SLAM方法及系统,可广泛应用于同步定位与建图领域。</td>   <td>1.一种基于连续运动模型的激光SLAM方法,其特征在于,包括以下步骤：获取激光点云数据并进行特征提取,得到特征点；基于捆绑调整对特征点进行特征关联,得到地标特征；基于连续运动模型对地标特征进行观测与计算,得到地标特征的观测残差；构建平滑残差并与地标特征的观测残差进行联合优化,得到地标特征的位姿与速度；基于滑动窗口选取关键帧和对地标特征的观测残差进行计算优化,并结合地标特征的位姿与速度构建地图。</td>   <td>G06T7/73;G06T7/246;G06T17/05;G06T7/207;G06F16/29</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖正首;              黄林冲;              黄帅;                   吴峰       </td>   <td>中山大学</td>   <td>岩石颗粒的接触特征确定方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN116310200A</td>   <td>2023-06-23</td>   <td>本申请涉及岩石力学领域,尤其涉及一种岩石颗粒的接触特征确定方法、装置、设备及存储介质。该方法包括：确定颗粒表面的点云；确定所述颗粒表面对应的球谐系数；确定颗粒表面点用于重采样的权值函数,根据所述权值函数结合球面沃罗诺伊剖分对参数空间重新采样,获得球面沃罗诺伊种子作为参数空间新的采样点,得到新的网格拓扑；将所述采样点、球谐系数代入球谐函数拟合,确定颗粒表面点的坐标,根据所述颗粒表面点的坐标和所述网格拓扑得到简化网格后的重构的颗粒表面,以确定所述岩石颗粒的接触特征。本申请可以满足不同网格特征的颗粒表面离散或重构的需求,能够更为高效准确的确定岩石颗粒的接触特征,降低工程应用的风险。</td>   <td>1.一种岩石颗粒的接触特征确定方法,其特征在于,所述方法包括：通过扫描获取所述岩石颗粒的颗粒形态,确定颗粒表面的点云；将所述颗粒表面的点云代入预设的球谐函数,确定所述颗粒表面对应的球谐系数；确定颗粒表面点用于重采样的权值函数,根据所述权值函数结合球面沃罗诺伊剖分对参数空间重新采样,获得球面沃罗诺伊种子作为参数空间新的采样点,通过凸包算法生成沃罗诺伊种子的德洛内三角剖分,得到新的网格拓扑；将所述采样点、球谐系数代入球谐函数拟合,得到拟合后的采样点的径向距离,根据所述径向距离确定颗粒表面点的坐标,根据所述颗粒表面点的坐标和所述网格拓扑得到简化网格后的重构的颗粒表面；根据重构的颗粒表面确定所述岩石颗粒的接触特征。</td>   <td>G06T17/20;G06T7/66;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         石茜;              刘梦曦;                   陈安琪       </td>   <td>中山大学</td>   <td>一种基于令牌掩码机制的大尺度城中村提取方法</td>   <td>广东省</td>   <td>CN116310628A</td>   <td>2023-06-23</td>   <td>本发明公开了一种基于令牌掩码机制的大尺度城中村提取方法及系统,涉及遥感地理信息系统的技术领域,包括：获取高分辨率遥感影像数据集,进行城中村区域标注,获得城中村标注数据集；对城中村标注数据集进行数据增广操作,获得增广后的城中村标注数据集,迭代训练构建的城中村提取模型,设置训练参数,对城中村提取模型的模型参数进行更新,获得训练好的城中村提取模型；获取待检测区域的高分辨率遥感影像,输入训练好的城中村提取模型,提取出待检测区域中的城中村范围。本发明能够快速准确的从高分辨率遥感影像中识别出城中村区域,提取准确率和效率高,应用范围广,实现了高精度、鲁棒性的大尺度城中村制图应用。</td>   <td>1.一种基于令牌掩码机制的大尺度城中村提取方法,其特征在于,包括：S1：获取高分辨率遥感影像数据集；S2：对高分辨率遥感影像数据集中的遥感影像进行城中村区域标注,获得城中村标注数据集；S3：对城中村标注数据集进行数据增广操作,获得增广后的城中村标注数据集；S4：利用增广后的城中村标注数据集迭代训练构建的城中村提取模型,设置训练参数,对城中村提取模型的模型参数进行更新,获得训练好的城中村提取模型；S5：获取待检测区域的高分辨率遥感影像,输入训练好的城中村提取模型,提取出待检测区域中的城中村范围。</td>   <td>G06V10/774;G06V10/764;G06V10/80;G06V20/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丛玉来;              陈元嘉;                   张磊       </td>   <td>中山大学</td>   <td>一种SAR飞机检测方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN116310795A</td>   <td>2023-06-23</td>   <td>本发明公开了一种SAR飞机检测方法、系统、装置及存储介质,方法包括：获取输入的SAR图像；利用飞机检测模型,对输入的SAR图像进行分析,获得飞机检测结果；飞机检测模型通过已标注飞机类别和目标边框的SAR图像数据集训练生成的；飞机检测模型包括分类分支和回归分支,分类分支具有可变形区域关联模块,可变形区域关联模块通过可变形卷积分支和常规卷积分支进行特征加权整合。本发明通过可变形关联模块构建分类分支,显著提升特征关联能力,并通过已标注飞机类别和目标边框的SAR图像数据集进行模型训练,充分利用SAR飞机散射特征信息的先验知识。本发明提高了在复杂的SAR图像中检测飞机的性能,实现了精确的飞机检测识别。</td>   <td>1.一种SAR飞机检测方法,其特征在于,包括：获取输入的SAR图像；利用飞机检测模型,对所述输入的SAR图像进行分析,获得飞机检测结果；其中,所述飞机检测结果包括至少一个目标边框回归结果以及对应的飞机的类别置信度分数；所述飞机检测模型通过已标注飞机类别和目标边框的SAR图像数据集训练生成的；所述飞机检测模型包括分类分支和回归分支,所述分类分支具有可变形区域关联模块,所述可变形区域关联模块通过可变形卷积分支和常规卷积分支进行特征加权整合。</td>   <td>G06V20/10;G06V10/764;G06V10/82;G06N3/084;G06N3/0464;G06N3/0455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈剑辉;              方丛;              梁晓燕;              孙鹏;                   贾磊       </td>   <td>中山大学附属第六医院</td>   <td>用于图像识别的卵母细胞图像素材采集方法、装置及设备</td>   <td>广东省</td>   <td>CN116311239A</td>   <td>2023-06-23</td>   <td>本申请公开了一种用于图像识别的卵母细胞图像素材采集方法、装置、设备及存储介质,获取捡卵显微镜中显示的第一图像数据和各个第一图像数据对应的第一时间戳；检测操作人员是否存在拾卵操作,当确定操作人员存在拾卵操作,获取操作人员使用的吸管的吸管图像数据和各个吸管图像数据对应的第二时间戳；根据吸管图像数据和第二时间戳,确定操作人员开始进行拾卵操作的起始时间节点；获取第一时间戳在起始时间节点之前的预定时间段的第一图像数据,得到用于图像识别的卵母细胞的图像素材。该方法可以自动化实现卵母细胞的图像素材的提取,方便用于训练搭建机器学习模型辅助检测采集卵母细胞。本申请可广泛应用于图像采集技术领域内。</td>   <td>1.一种用于图像识别的卵母细胞图像素材采集方法,其特征在于,所述方法包括：获取捡卵显微镜中显示的第一图像数据和各个所述第一图像数据对应的第一时间戳；检测操作人员是否存在拾卵操作,当确定所述操作人员存在拾卵操作,获取所述操作人员使用的吸管的吸管图像数据和各个所述吸管图像数据对应的第二时间戳；根据所述吸管图像数据和所述第二时间戳,确定所述操作人员开始进行拾卵操作的起始时间节点；获取所述第一时间戳在所述起始时间节点之前的预定时间段的第一图像数据,得到用于图像识别的卵母细胞的图像素材。</td>   <td>G06V20/69;G06V40/20;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陶宇;              郑伟诗;                   胡建芳       </td>   <td>中山大学</td>   <td>一种利用时空信息的快速视频目标物体分割方法</td>   <td>广东省</td>   <td>CN111291663B</td>   <td>2023-06-20</td>   <td>本发明公开了一种利用时空信息的快速视频目标物体分割方法,包括下述步骤：建立一个神经网络系统,在最前部为深度卷积神经网络CNN,对图像进行基本的特征提取,得到每一帧对应的特征图；连接一个循环神经网络RNN,该循环神经网络RNN用以充分利用视频每一帧空间上的相关性包含的信息,以及视频在每一帧时间相关性上所包含的信息,并将这些隐含信息提取到特征中,从而得到视频对应每一帧包含时空信息的新的特征图；连接一个用以进行二分类的神经网络层,对特征图进行二分类,得到前景部分和背景部分,从而实现对视频每一帧的目标物体分割。</td>   <td>1.一种利用时空信息的快速视频目标物体分割方法,其特征在于,包括下述步骤：建立一个神经网络系统,在最前部为深度卷积神经网络CNN,对图像进行基本的特征提取,得到每一帧对应的特征图；连接一个循环神经网络RNN,该循环神经网络RNN用以充分利用视频每一帧空间上的相关性包含的信息,以及视频在每一帧时间相关性上所包含的信息,并将这些隐含信息提取到特征中,从而得到视频对应每一帧包含时空信息的新的特征图；连接一个用以进行二分类的神经网络层,对特征图进行二分类,得到前景部分和背景部分,从而实现对视频每一帧的目标物体分割；在连接一个循环神经网络RNN的步骤前,还包括下述步骤：建立无向的循环信息传播图,所述无向的循环信息传播图可近似为4个方向信息传播图的合集G～u＝{G-(se),G-(sw),G-(ne),G-(nw)}；在无向的循环信息传播图的基础上,循环神经网络RNN的公式化表示如下：                                    其中,分别代表第t帧的特征图中某像素v-(i,t)在RNN中对应的连接顶点的输入和输出特征,/&gt;代表在第t帧的特征图中某像素v-(i,t)在RNN中对应的隐含层状态,K代表RNN中时间方向的传播参数,K-d代表RNN中空间方向的传播参数,U-d,V-d是转换输入特征和隐含层特征的参数,b-d,c是偏置参数,/&gt;表示组成局部传播图的顶点的合集,f是激活函数；在所述的无向的循环信息传播图中,将原来空间上各方向相邻节点之间连接,改为各方向每隔N-1个节点相互连接,即将空间上的传播距离由原始的一个单位扩展到N个单位。</td>   <td>G06V10/26;G06V10/40;G06V20/40;G06V10/764;G06V10/82;G06N3/0464;G06N3/044;G06N3/045;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈庆;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于强化学习的完形填空型阅读理解分析模型及方法</td>   <td>广东省</td>   <td>CN109840322B</td>   <td>2023-06-20</td>   <td>本发明公开了一种基于强化学习的完形填空型阅读理解分析模型及方法,该模型包括：编码层,将原始文本的单词进行向量化,对单词进行编码,取各句子最后一个单词的隐向量输出作为句子向量,将文本编码成句子向量的序列传递给语句抽取层；语句抽取层,对句子向量选择,将得到的句子作为当前给定文段,对其进行编码；分类层,把每个待填的空位视为一问题,将得到的文段编码和四个候选单词的词向量作为输入,通过多特征分类网络进行计算输出概率；预测层,将上层得到的概率值与语言模型的概率值归一化,得到最终四个选项的概率；输出层,计算上一层得到的概率与实际概率的交叉熵并优化分类网络,将损失值作为延迟奖励对网络进行参数更新。</td>   <td>1.一种基于强化学习的完形填空型阅读理解分析模型,包括：编码层,用于将原始文本的单词进行向量化,然后对单词进行编码,取每个句子最后一个单词的隐向量输出作为句子向量,从而将文本编码成一个句子向量的序列,并将此句子向量的序列传递给语句抽取层；语句抽取层,用于利用语句向量抽取网络对句子向量进行选择,只对一部分的句子进行保留,将得到的句子作为当前新的给定文段,并对获得的文段进行编码；分类层,用于把每一个待填的空位视为一个问题,将上一层得到的文段编码和四个候选单词的词向量作为输入,通过多特征分类网络进行计算,输出四个选项各自的概率；预测层,用于将所述分类层得到的概率值与语言模型的概率值[p-(lA),p-(lB),p-(lC),p-(lD)]相加并进行归一化,得到最终四个选项的概率输出；输出层,用于计算所述预测层得到的概率与实际概率间的交叉熵,并通过最小化交叉熵优化分类模型,并将损失值作为延迟奖励提供给所述语句向量抽取网络和多特征分类网络进行参数更新；所述语句抽取层用于对完形填空需要填写的每个空格,使用强化学习的方法从文段中抽取有用的句子组成子文段,从而减少无关信息的干扰并减少分类层的计算量；在所述语句向量抽取网络中,动作的集合包含1和0两种,1表示选择该句子,0表示不选择,动作集合如下：A＝{1,0}所述语句向量抽取网络设定当前状态S由三部分组成,分别为1)已选择的句子构成的上文向量,记为c-(t-1)；2)下一个待选择的句子向量,记为S-t；3)当前处理的空格对应的4个候选单词的词向量,记为e-i,i∈[1,4]；当前状态下采取不同动作的概率由策略函数π(α-t|s-t；θ)决定,所述策略函数的具体定义如下述公式所示,其中s-t为当前状态[c-(t-1)；S-t；e-1；e-2；e-3；e-4]π(α-t|s-t；θ)＝σ(W*s-t+b)其中,a-t为策略函数的输出,表示选择的动作,θ＝{W,b},W、b为待训练的参数；所述语句向量抽取网络的训练方法如下：对于每一个问题,都对文段进行多次重复采样,将采样得到的句子通过BiGRU网络编码成段落级别的向量,通过所述多特征分类网络得到最后的概率结果P(yX),并计算出对应的损失函数Loss,利用损失函数Loss的值,使用梯度下降的方法来更新所述语句向量抽取网络的参数。</td>   <td>G06F16/35;G06F40/284;G06N3/0464;G06N3/0442;G06N3/0455;G06N3/047;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              黄旭;              郭雪梅;                   李中华       </td>   <td>中山大学</td>   <td>一种显微镜图像的处理方法</td>   <td>广东省</td>   <td>CN111435529B</td>   <td>2023-06-20</td>   <td>本发明公开了一种显微镜图像的处理方法,包括：从显微镜图像中提取具有有效信息的图像块；训练生成对抗网络重构具有有效信息的图像块,包括训练生成对抗网络模型、保存训练所训练好的模型及重构具有有效信息的图像块成为重构后的具有有效信息的图像块；以及拼接重构后的具有有效信息的图像块,成为处理后的显微镜图像。本发明所公开的显微镜图像的处理方法提供了一種医学显微镜图像超分辨问题的整体解决方案,可以加快网络的训练和整个显微镜图像重构的效率、可以将重构的误差最小化,可有效的提升操作者(例如是医生)的工作效率,且具有较强的鲁棒性和稳健性。</td>   <td>1.一种显微镜图像的处理方法,其特征在于,包括：从所述显微镜图像中提取具有有效信息的图像块；训练生成对抗网络重构所述具有有效信息的图像块,包括：训练所述生成对抗网络模型；保存所述训练所述生成对抗网络模型的步骤所训练好的生成对抗网络模型；及所述训练好的生成对抗网络模型以第一重构倍数放大重构所述具有有效信息的图像块,成为重构后的具有有效信息的图像块；以及拼接所述重构后的具有有效信息的图像块,成为处理后的显微镜图像,其中,所述的训练所述生成对抗网络模型包括：取得高分辨率标签图像块；将所述高分辨率标签图像块进行下采样,得到低分辨率图像块；将所述低分辨率图像块输入所述生成对抗网络；通过所述生成对抗网络生成高分辨率图像块；计算所述高分辨率图像块相对于所述高分辨率标签图像块的损失函数；最小化所述损失函数；以及优化所述生成对抗网络中,生成网络的网络参数,产生优化后的生成网络参数；且其中,所述损失函数由内容损失和对抗损失组成,并由以下公式计算而成：f-(loss)＝l-(Content)+k·l-(Gen)；l-(Content)＝l-(MSE)+l-(VGG/i,j)；                            及                  其中,f-(loss)为所述损失函数,l-(Content)为所述内容损失,l-(Gen)为所述对抗损失,k为对抗损失的权重,l-(MSE)为像素空间的最小均方差即l-(VGG/i,j)基于特征空间的最小均方差,I～(LR)为所述低分辨率图像块,I～(HR)为所述高分辨率标签图像块,G-(θG)(I～(LR))为所述高分辨率图像块,W为所述低分辨率图像块的宽,H为所述低分辨率图像块的高,C为所述低分辨率图像块的通道数,r为所述生成对抗网络的重构倍率,D-(θD)(I)为所述生成对抗网络的鉴别网络所判断的图像I属于真实的所述高分辨率标签图像块的概率,φ是代表VGG 19网络中的特征映射,i,j是第i最大池化层之前的激活后第j卷积,N为训练样本总数。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李军;              叶威;                   屈颢颢       </td>   <td>中山大学</td>   <td>快速高效的停车场占有率短时预测方法、系统及存储介质</td>   <td>广东省</td>   <td>CN113821547B</td>   <td>2023-06-20</td>   <td>本发明属于停车诱导泊位预测领域,为停车场占有率短时预测方法、系统及存储介质,其方法包括：采集多个不同类型的停车场数据,并处理得到每个停车场占有率的时间序列,筛选出用于元学习训练的任务集；构建循环神经网络预测模型,并进行元学习训练以优化模型；从停车场占有率的时间序列中提取停车场占有率变化的趋势特征得到趋势项序列,分析停车场占有率变化的周期性特征拟合得到周期项序列,将两序列差值作为效应项序列,将三个序列作为预测模型的输入,得到目标停车场占有率的预测值。本发明利用循环神经网络处理多维特征在时间维度的非线性变化来进行预测,提高预测模型的训练速度和学习性能,从而提高预测精度的准确性及稳定性。</td>   <td>1.快速高效的停车场占有率短时预测方法,其特征在于,包括以下步骤：S1、采集多个不同类型的停车场数据,对停车场数据处理得到每个停车场占有率的时间序列；S2、根据每个停车场占有率的时间序列,筛选出用于元学习训练的训练任务集和测试任务集；S3、构建循环神经网络预测模型；S4、对循环神经网络预测模型进行元学习训练,得到预测模型优化后的初始化参数,并对预测模型进行初始化,得到优化后的预测模型；S5、采用优化后的预测模型对目标停车场占有率进行预测,从停车场占有率的时间序列中提取停车场占有率变化的趋势特征,得到趋势项序列；分析停车场占有率变化的周期性特征,并拟合得到周期项序列；将趋势项序列和周期项序列的差值作为效应项序列,将趋势项序列、周期项序列及效应项序列作为循环神经网络的输入,得到下一个时刻的预测值作为目标停车场占有率的预测值；步骤S5利用循环神经网络LSTM或GRU从停车场占有率的时间序列X(t)中提取停车场占有率变化的趋势特征,得到趋势项序列g(t)；分析停车场占有率变化的周期性特征,并用傅里叶级数进行拟合得到周期项序列s(t)；步骤S5利用停车场占有率的时间序列X(t)前n个时刻的数据预测下一时刻的数据,将{i-n+1,……i-2,i-1,i}时刻的停车场占有率作为参考,输入循环神经网络LSTM或GRU中,预测出i+1时刻的数据,将预测值作为趋势项序列g(t)；步骤S5中周期序列s(t)为：                  其中,C为常数,T为周期；傅里叶级数的系数[a-1,b-1,...a-n,b-n]～T按照服从均值为0的正态分布进行初始化,采用批量梯度下降法来训练参数,进行拟合。</td>   <td>G06F16/2458;G06N3/044;G06N3/0985;G08G1/01;G08G1/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         戎利民;              范国鑫;              刘华清;              庞卯;              刘斌;              张良明;              黄桂芳;                   韩蓝青       </td>   <td>中山大学附属第三医院(中山大学肝脏病医院);清华珠三角研究院</td>   <td>重症脊髓损伤预后的预测模型系统及存储介质</td>   <td>广东省</td>   <td>CN112992368B</td>   <td>2023-06-20</td>   <td>本发明公开了重症脊髓损伤预后的预测模型系统,包括：建立脊髓损伤的患者病例的临床特征数据库；构建重症脊髓损伤预后的预测模型；依据所述最终的预测模型预测出患者出院终点为死亡、继续专业康复护理治疗、回家的概率数值,将所述概率数值输入给公式1,给出最终的预测概率值,所述公式1：本发明还公开了及计算机可读的记录媒体。本发明是基于临床病史计算出院终点的概率,并查明对重症脊髓损伤患者的临床结果产生影响的重要临床特征。</td>   <td>1.一种重症脊髓损伤预后的预测模型系统,其特征在于包括：建立脊髓损伤的患者病例的临床特征数据库；构建重症脊髓损伤预后的预测模型：从临床特征数据库提取临床特征,根据提取临床特征的类型,通过不同的填补方法处理缺失的数据,连续变量特征运用预测均值匹配方法填补,二元变量特征运用逻辑回归方法填补,多分类变量特征运用多项式回归方法填补,最终获得不同的特征并按照合理的比例,随机划分为训练数据集、验证数据集和测试数据集；纳入特征选择方法*机器学习分类算法构建算法组合模型,特征选择方法用于筛选具有显著预测价值的临床特征,将选定的临床特征用于训练机器学习分类算法；从所述算法组合模型中选出预测患者出院终点的micro平均曲线下面积AUC最佳的算法组合模型,利用集成算法堆叠法构建最终的预测模型,所述患者出院终点为在家休养、继续专业康复护理治疗、死亡三个类别；依据所述算法组合模型预测的患者出院终点为死亡、继续专业康复护理治疗、在家休养的概率数值,将所述概率数值输入给公式1,给出最终的预测概率值,所述公式1                  在上述公式中,P-θ(X)表示出院终点类别概率,其中p(y＝1|X；θ)表示死亡概率,p(y＝2|X；θ)表示继续专业康复护理治疗的概率,p(y＝3|X；θ)表示在家休养的概率；          表示系数,其中j＝1,2,3；n表示基分类器的数量；                                                      其中的θ-(i,j)是预训练的集成预测模型的系数,i＝1,2,3；j＝1,2,3,...,3n；X＝[x-1 x-2 x-3 … x-(3n-2) x-(3n-1) x-(3n)]表示n个基分类器预测的出院终点概率,其中x-(3k-2)表示第k个基分类器预测的出院终点为死亡的概率,k＝1,2,..,n；x-(3k-1)表示第k个基分类器预测的出院终点为继续专业康复护理治疗的概率,k＝1,2,..,n；x-(3k)表示第k个基分类器预测的出院终点为在家休养的概率,k＝1,2,..,n；y＝1|X；θ表示输入的患者各项特征；y＝1,算法预测该患者的出院终点类别1为死亡；其中y＝2,算法预测该患者的出院终点类别2为继续专业康复护理治疗；y＝3,算法预测该患者的出院终点类别3为在家休养；T表示向量的转置；          表示列向量θ-1转置后,和向量X相乘；/&gt;表示列向量θ-j转置为行向量；θ表示系数,通过训练获得具体的取值；Λ与L均表示省略符号。</td>   <td>G16H50/70;G16H50/50;G06F18/214;G06F18/241;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘仲奇;              曹铭辉;              纪风涛;              文金钡;              郭明炎;                   黄景萱       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种术后不良事件预测模型的构建方法、系统和预测装置</td>   <td>广东省</td>   <td>CN115083604B</td>   <td>2023-06-20</td>   <td>本发明公开了一种术后不良事件预测模型的构建方法、系统和预测装置,包括：获取多个患者对应的患者基本资料、围术期检查结果、术中循环数据和术中管理数据,并通过机器学习工具,对术中循环数据进行量化处理,获得对应的术中循环数据特征；将所有患者对应的患者基本资料、围术期检查结果、术中管理数据和术中循环数据特征分为训练数据集和验证数据集；根据训练数据集,确定若干种与术后不良事件相关联的特征指标,并根据所有特征指标,构建术后不良事件预测模型。本发明通过对术中循环数据进行量化处理,使得模型能够充分探索量化后的术中循环数据的规律,并对训练集数据进行筛选,以提升构建的术后不良事件预测模型的预测准确性。</td>   <td>1.一种术后不良事件预测模型的构建方法,其特征在于,包括：获取多个患者对应的患者基本资料、围术期检查结果、术中循环数据和术中管理数据,并通过机器学习工具,对所述术中循环数据进行量化处理,获得对应的术中循环数据特征；其中,所述机器学习工具,包括傅里叶转换和小波分析；将所有所述患者对应的所述患者基本资料、所述围术期检查结果、所述术中管理数据和所述术中循环数据特征分为训练数据集和验证数据集；根据所述训练数据集,确定若干种与术后不良事件相关联的特征指标,并根据所有所述特征指标,构建术后不良事件预测模型；其中,所述根据所述训练数据集,确定若干种与术后不良事件相关联的特征指标,并根据所有所述特征指标,构建术后不良事件预测模型,具体为：通过XGBoost算法,结合所述训练数据集,构建初始预测模型,并基于所述初始预测模型,计算所述训练数据集中各指标的SHAP值；其中,所述患者基本资料、所述围术期检查结果、所述术中管理数据和所述术中循环数据特征都各自包括至少两个所述指标；按照预设的规则,根据所有所述指标的SHAP值,从所述训练数据集的所有所述指标中,选取若干种与术后不良事件相关联的所述特征指标；根据所有所述特征指标,构建所述术后不良事件预测模型；其中,所述按照预设的规则,根据所有所述指标的SHAP值,从所述训练数据集的所有所述指标中,选取若干种与术后不良事件相关联的所述特征指标,具体为：从所述训练数据集的所有所述指标中,选取大于预设阈值的所述SHAP值对应的所述指标,作为与术后不良事件相关联的所述特征指标；或者,根据各所述SHAP值从大到小的顺序,对所述训练数据集的所有所述指标进行排列,并选取排列结果中前M个所述指标,作为与术后不良事件相关联的所述特征指标。</td>   <td>G16H50/30;G16H10/60;G06F18/214;G06N5/01;G06N20/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张艳;              张鑫;              曲承志;                   苏东       </td>   <td>中山大学</td>   <td>一种点云全局运动优化方法及设备</td>   <td>广东省</td>   <td>CN111862311B</td>   <td>2023-06-20</td>   <td>本发明公开了一种点云全局运动优化方法,根据各视角运动矩阵初值,将其重构为低秩稀疏矩阵再进行矩阵恢复；在已知任意两视角运动情况下,提出通用的约束条件加入迭代过程,有效限制迭代次数,提高算法效率,降低随机噪声带来的影响；提出加入柯西权重项衡量两两视角测量的可靠性,有效降低离群点的影响,提高算法的鲁棒性；适用于已知多视角点云相对运动初值和任意两视角变化的真实值求解精确的全局运动问题,以解决维重构中多视角点云全局优化方法过度依赖配准初值、鲁棒性不高、效率低的缺陷问题,剔除初始运动中的随机噪声和异常值,提高点云全局运动恢复精度,获得更精确的重构模型。</td>   <td>1.一种点云全局运动优化方法,其特征在于,包括：通过配准算法获取任意两个点云之间的相对运动初始值；其中,所述相对运动初始值包括N个视角中任意两视角i,j之间刚性变换的旋转矩阵R-(ij)和平移向量T-(ij)；所述相对运动初始值的表达形式为：                  根据所述相对运动初始值建立相对运动的低秩稀疏矩阵,所述相对运动的低秩稀疏矩阵表达式为：                  其中,I-4为4×4的单位矩阵；获取的不同视角点云,根据由第i个视角变换到第j个视角的旋转角θ和旋转轴生成视角约束条件表达方程,包括：获取的不同视角点云1,2,…,N是按照一定顺序扫描旋转物体得到的,已知相机由第i个视角变换到第j个视角的旋转角θ和旋转轴/&gt;以第i个视角建立坐标系(X,Y,Z),刚性物体旋转矩阵/&gt;的表达式如下：                  则通用的第i组到第j组点云的视角约束条件表达式如下：                  其中,R-i为第i个视角以第一个视角为参考系的全局运动的旋转矩阵,包括：根据加权无向图表示的所有点云组间的关系,建立对称邻接矩阵A,其表达式为A＝[w-(ij)],其中,w-(ij)为视角点云i,j的非负权值；根据旋转分量定义残差r-(ij)来更新权重w-(ij),柯西权函数表达式如下：                  其中,残差r-(ij)＝||R-(ij)-R-i～(-1)R-j||-F；参数c＝1.482med(|r-med(r)|)·θ,其中,med()是中值算子,r是残差r的向量化,θ＝2是调节常数；根据邻接矩阵A建立权重矩阵W表达式如下：                  其中,为克罗内克积,/&gt;表示一个各元素为1的4×4矩阵；根据不同视角点云之间的关系,建立邻接矩阵和权重矩阵并在每次迭代中通过柯西权函数更新权重矩阵；根据所述视角约束条件表达方程、相对运动的低秩稀疏矩阵和更新后的权重矩阵,建立全局运动最优化问题的数学模型,包括：建立块矩阵U和块矩阵V,其中,块矩阵V表示每组点云全局运动重构成的块矩阵,块矩阵U表示为块矩阵V的逆矩阵；                  建立全局运动最优化问题的数学模型：                  其中,β∈[0,1]为引入的约束项系数；对所述全局运动最优化问题的数学模型进行凸松弛处理,得到最优化问题表达式；通过拉格朗日乘子法对所述最优化问题表达式进行求解,直到满足所有迭代停止条件后输出求解结果；判断当前是否满足视角约束条件,若不满足则更新相对运动初始值,对权重矩阵进行更新迭代；若满足则根据输出的求解结果计算各视角全局运动矩阵。</td>   <td>G06T17/00;G06T15/00;G06T7/30;G06F17/16;G06F17/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陆遥;                   余丹填       </td>   <td>中山大学</td>   <td>一种基于引用关系的科技文献高关注度句子提取方法</td>   <td>广东省</td>   <td>CN109241521B</td>   <td>2023-06-20</td>   <td>本发明涉及句子级知识抽取的技术领域,更具体地,涉及一种基于引用关系的科技文献高关注度句子提取方法。本发明的主要步骤包括：对领域文档集预处理工作、统计高被引文章、提取高关注度句子以及CNN句子分类器训练。本发明提出一种更具客观性和适用性的科技论文高关注度句子提取方法,以所要研究的某一学科领域的大量科技文献为对象,基于引文分析研究方法,统计高被引文献,从中进行相应引证句子的相似度匹配,提取出相似度高的句子组成高关注度句子集；接着,对高关注度句子进行词性标注,使用标注序列集作为训练语料,通过CNN的训练,得到能自动识别论文中创新点句子的分类器。</td>   <td>1.一种基于引用关系的科技文献高关注度句子提取方法,其特征在于,包括以下步骤：S1：对领域文档集做相关预处理工作,所述预处理工作包括核对以及统一正文中的引用标注,保证领域文档集与参考文献一一匹配,同时便于后续试验的统一处理,所述预处理工作还包括对领域文档集中论文进行分句处理；S2：根据参考文献列表对文章被引次数进行统计,根据被引次数分布情况确定一个被引量阈值,取被引量大于阈值的高被引文章作为进一步抽取高关注度句子的文本对象；同时提取出高被引文章对应的引述句子,用于下一步高被引文章中高关注度句子的提取；S3：基于LSI潜在语义索引模型训练文本并计算句子的相似度,设定相似度阈值,从高被引文章中找出与对应引述句子有最高句子相似度且该相似度达到相似度阈值的句子,加入到高关注度句子训练集；S4：利用自然语言处理工具包NLTK中的词性标注器对高关注度句子和非高关注度句子进行词性标注,对高关注句子和非高关注句子分别加以标签1和0；输入词性符号序列和对应标签,进行CNN训练得到高关注度句子的分类器。</td>   <td>G06F40/279;G06F16/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>              蔡昆京       </td>   <td>中山大学</td>   <td>一种基于人体头部特征的考场偷窥作弊检测系统</td>   <td>广东省</td>   <td>CN110837784B</td>   <td>2023-06-20</td>   <td>本发明公开了一种基于人体头部特征的考场偷窥作弊检测系统,包括RGB-D数据采集模块,采集关于考生的RGB彩色视频和深度信息数据；头部特征提取模块,由头部位置轨迹计算单元、头部姿态估计单元、眼神方向估计单元以及人脸识别单元组成,根据RGB-D视频数据分析头部位置轨迹、头部姿态、眼神注视方向和人脸身份等各种人体头部特征；作弊行为判定分类模块,对提取的头部特征按照多条规则分别判断是否作弊,再加权综合每条规则分类的结果得到最终是否偷窥作弊的结论。</td>   <td>1.一种基于人体头部特征的考场偷窥作弊检测系统,其特征在于,包括：RGB-D数据采集模块,用于实时记录考场中监考人员及考生的RGB彩色视频和深度信息数据；头部特征提取模块,用于逐帧对采集到的RGB-D视频数据进行分析,获取头部位置、头部姿态、头部运动轨迹、人脸身份以及眼神注视方向的等各种人体头部特征；作弊行为判定分类模块,用于对RGB-D视频数据提取的特征按照若干条规则进行判断分类,再综合每条规则判断的结果给出最后是否偷窥作弊的结论；其中,所述头部特征提取模块包括头部位置轨迹计算单元、头部姿态估计单元、人脸识别单元和眼神方向估计单元；所述头部位置轨迹计算单元用深度学习脸部检测框架获取视频中每个考生的脸部矩形框,根据矩形框中点位置(u,v)找出对应深度图中的深度d,结合摄像头内参光心位置c-x、c-y以及焦距f-x、f-x,根据以下公式可以计算头部的空间位置坐标(x,y,z),                                    z＝d在整个视频上用同样方法可以计算头部的运动轨迹以及热点位置区域；所述头部姿态估计单元将脸部检测得到的矩形框图片输入到深度卷积神经网络模型中,输出得到三个转向角的分类class-Pitch、class-Yaw、class-Roll,最后根据以下公式准确计算头部在三维空间的三个转向角：Pitch、Yaw、Roll,Pitch＝(class-Pitch×2–90)°Yaw＝(class-Yaw×2–90)°Roll＝(class-Roll×2–90)°。</td>   <td>G06V40/20;G06V40/16;G06V20/40;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         熊宸;              邓卓琳;              蔡铭;                   苟超       </td>   <td>中山大学</td>   <td>一种自主式交通系统物理架构的构建方法及系统</td>   <td>广东省</td>   <td>CN113792409B</td>   <td>2023-06-20</td>   <td>本发明公开了一种自主式交通系统物理架构的构建方法及系统,方法包括：首先配置物理架构的物理对象；根据自主式交通系统服务集,对系统功能进行解构,得到系统功能的交通实体,所述交通实体包括但不限于系统功能的提供者和服务对象；根据所述系统功能和交通实体,构建物理对象集；根据所述物理对象集中各个物理对象与系统功能之间的映射关系,确定物理对象之间的交互关系；获取所述系统功能之间传递的数据流,根据不同数据流之间的相似度生成信息交互对；根据所述物理对象以及所述信息交互对,根据逻辑架构构建自主式交通系统的物理架构。本发明提高了效率,能够融合形成面向不同交通场景的系统物理架构,可广泛应用于数据处理技术领域。</td>   <td>1.一种自主式交通系统物理架构的构建方法,其特征在于,包括：配置物理架构的物理对象；根据自主式交通系统服务集,对系统功能进行解构,得到系统功能的交通实体,所述交通实体包括系统功能的提供者和服务对象；根据所述系统功能和交通实体,构建物理对象集；根据所述物理对象集中各个物理对象与系统功能之间的映射关系,确定物理对象之间的交互关系；获取所述系统功能之间传递的数据流,根据不同数据流之间的相似度生成信息交互对；根据所述物理对象以及所述信息交互对,根据逻辑架构构建自主式交通系统的物理架构；所述获取所述系统功能之间传递的数据流,根据不同数据流之间的相似度生成信息交互对,包括：获取各个系统功能涉及的数据流,并确定各条数据流的来源、去向以及各条数据流的组成,将相同来源以及相同去向的数据流作为待聚合数据流；将待聚合数据流的名称和组成作为输入文本,对所述输入文本进行分词处理,得到数据流相关词语库；通过word2vec将所述词语库中的词语映射至向量空间,生成词向量；根据任意两条数据流的词向量计算文本相似度矩阵；根据所述文本相似度矩阵,计算数据流相似度；根据所述数据流相似度,将相似度满足阈值要求的两条数据流合并得到信息交互对；所述根据所述数据流相似度,将相似度满足阈值要求的两条数据流合并得到信息交互对,包括：判断任意两条数据流之间的相似度是否大于阈值,若是,则确定所述两条数据流相似,若否,则确定所述两条数据流不相似；将数据流作为节点,按照数据流相似性构造边,将每个待合并数据流集合生成一个无向图；搜索所述无向图中的所有完全连接子图,将所述完全连接子图中的数据流合并；根据物理对象与功能之间的映射关系,将合并得到的数据流映射到物理空间中,生成信息流；查找所述信息流的起点物理对象和终点物理对象,生成信息交互对。</td>   <td>G06F30/20;G08G1/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张冬雨;              成奕彬;                   林倞       </td>   <td>中山大学</td>   <td>一种自监督学习与骨骼信息的行为识别方法</td>   <td>广东省</td>   <td>CN112668492B</td>   <td>2023-06-20</td>   <td>本发明公开了一种自监督学习与骨骼信息的行为识别方法,涉及计算机视觉技术领域。方法包括以下步骤：S1、构建可配置的深度模型；S2、在网络预训练阶段,根据预设的光流预测任务获取预训练样本；其中,预训练样本包括骨骼视频以及机器自动生成的光流预测任务的标签；利用预训练样本对变换网络进行训练,获取变换器网络的初始参数θ′；S3、在网络微调阶段,根据初始参数θ′对变换器网络进行初始化,结合初始化后的变换器网络与进行随机初始化的微调分类网络,构建微调深度模型；S4、将待识别的骨骼视频输入训练完成的微调深度模型中,由微调分类网络输出分类预测结果。本发明在保证较高精度的前提下,实现了效果、鲁棒性和泛化性更好的人体行为识别。</td>   <td>1.一种基于自监督学习与骨骼信息的行为识别方法,其特征在于,包括以下步骤：S1、构建可配置的深度模型,所述深度模型包括变换器网络、预训练分类网络和微调分类网络；其中,变换器网络和预训练分类网络作用于网络预训练阶段,变换器网络和微调分类网络作用于网络微调阶段；S2、在网络预训练阶段,根据预设的光流预测任务获取预训练样本；其中,所述预训练样本包括骨骼视频以及机器自动生成的光流预测任务的标签；利用所述预训练样本对变换网络进行训练,获取所述变换器网络的初始参数θ′；S3、在网络微调阶段,根据所述初始参数θ′对变换器网络进行初始化,结合初始化后的变换器网络与进行随机初始化的微调分类网络,构建微调深度模型；S4、将待识别的骨骼视频输入训练完成的微调深度模型中,由微调分类网络输出分类预测结果；其中,预训练样本中骨骼视频的表达式为X＝(x-1,x-2,…,x-N)；其中x-i为视频X中的第i帧骨骼图像,N为视频的总帧数；在网络预训练阶段,选择骨骼视频中15％的视频帧进行随机掩码,得到掩码后的骨骼视频表达式：X-\＝(x-1,…,x-(i-1),MASK,x-(i+1)…,x-N)；其中,MASK为掩码帧；计算掩码帧与下一帧之间的光流运动方向作为该任务的标签；其中,光流运动方向的表达式为Y＝{y-i|i＝1,2,…,M},M为运动方向的离散个数；预训练样本中骨骼视频通过深度模型后获得的输出表达式为f＝Ψ-(flow)[T-θ(X-\)]；其中,T-θ代表变换器网络的函数,Ψ-(flow)代表预训练分类网络的函数；其中,在网络微调阶段,输入的骨骼视频的表达式为X＝(x-1,x-2,…,x-N),无需经过掩码处理；骨骼视频通过网络微调阶段的变换器网络后得到的视频特征的表达式为f～′＝-θ(X)；再经过微调分类网络后,输出行为类别的预测结果的表达式为p＝Ψ-(cls)(f～′)；其中,Ψ-(cls)代表微调分类网络的函数。</td>   <td>G06V40/20;G06V10/764;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         侯剑华;                   王东毅       </td>   <td>中山大学</td>   <td>基于SAO-ADV结构的论文创新性的测度方法</td>   <td>广东省</td>   <td>CN111597793B</td>   <td>2023-06-16</td>   <td>本发明提供基于SAO-ADV结构的论文创新性的测度方法,包括：构建待评价对比的论文背景库；去除论文背景库及待评价论文中引言性或介绍性的句子,对剩余文本进行分词处理并进行词性标注和句法分析,提取出论文背景库和待评价论文的SAO-ADV结构；构建Word2Vec语义相似度模型；采用语义相似度模型计算每一个构成SAO-ADV结构的内部短语的创新度,得到SAO-ADV结构以及待评价论文的创新度,完成论文创新性的测度。本发明提供的基于SAO-ADV结构的论文创新性的测度方法,采用了改进的SAO-ADV模型完整地提取论文内容,将论文的主题词用语法结构完整串联起来,使评价结果更加全面；同时利用语义相似度模型,能够直接地评价论文内容,不用借助外界计量指标例如引文来评价,更能反映论文内容的质量。</td>   <td>1.基于SAO-ADV结构的论文创新性的测度方法,其特征在于,包括以下步骤：S1：根据所需评价的论文和学科/主题在数据源平台上选择该学科/主题的所有文献并进行筛选,得到待评价对比的论文背景库；S2：去除论文背景库及待评价论文中引言性或介绍性的句子,对剩余文本进行分词处理并进行词性标注,并对句子的结果特征进行句法分析,提取出论文背景库和待评价论文的SAO-ADV结构；S3：构建Word2Vec语义相似度模型；S4：采用语义相似度模型计算每一个构成SAO-ADV结构的内部短语的创新度,从而得到SAO-ADV结构以及待评价论文的创新度,完成论文创新性的测度；短语P的创新度(Innovation)如公式(1)所示：                  其中,w-o-i为其他论文文本集O中的SAO-ADV结构中的单词,max(Sim(w-i,w-o-i))为短语P与其他论文SAO-ADV结构中的短语的相似度最高的单词对的相似度,num为短语内词汇数量,min()为与短语P计算得到的创新度中最低的那个值；公式(1)将一个短语作为一个整体,该短语的单词作为部分,短语与短语之间进行相似度计算,两个短语之间的对应单词的相似度的平均数即为短语与短语之间的相似度；整个SAO-ADV结构S的创新度则如公式(2)所示：                  其中,num为S的短语数量；公式(2)将构成SAO-ADV结构的短语的创新度的平均数作为结构的创新度；整篇学术论文A的创新度如公式(3)所示：                  其中,num为学术论文A中SAO-ADV结构的数量。</td>   <td>G06F40/211;G06F40/289;G06F40/30;G06F40/253</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖义明;              郭正辉;              彭圣萌;              吴宛桦;              范辉阳;              雷震;              李嘉路;              华芮;              张游龙;                   李骁       </td>   <td>中山大学孙逸仙纪念医院;深圳市华嘉生物智能科技有限公司</td>   <td>前列腺癌病理图像中上皮细胞核的分割方法、装置和终端</td>   <td>广东省</td>   <td>CN111402267B</td>   <td>2023-06-16</td>   <td>本发明实施例公开了一种前列腺癌病理图像中上皮细胞核的分割方法、装置和终端,该方法包括：对获取的病理染色图像进行色彩空间转换,并基于转换后的彩色图像的一单通道图像进行细胞核分割；对细胞核分割彩色图像的每一单通道图像中的每一细胞核进行的初始尺寸图像和缩放图像进行区域分割以得到单通道区域图像,并对各单通道区域图像进行特征提取；将获取的该细胞核的单通道图像特征和多通道图像特征输入细胞核分类模型中进行细胞核分类,并根据分类结果确定病理染色图像中的上皮细胞核。本发明的技术方案可以很好地解决现有技术中很难对前列腺中的上皮细胞核进行准确分割的难题,从而提高对前列腺癌的病理诊断及严重程度等判断的准确性等。</td>   <td>1.一种前列腺癌病理图像中上皮细胞核的分割方法,其特征在于,包括：对获取的病理染色图像进行色彩空间转换,并基于所述转换得到的彩色图像的一单通道图像进行细胞核分割之后获取细胞核分割彩色图像；对所述细胞核分割彩色图像的每一单通道图像中的每一细胞核的初始尺寸图像和缩放至预设固定尺寸后的缩放图像分别进行区域分割以得到相应的单通道区域图像,并对所述单通道区域图像进行特征提取以获取对应细胞核的单通道图像特征,以及基于所述单通道图像特征获取对应的多通道图像特征；将所述对应细胞核的所述单通道图像特征和所述多通道图像特征输入细胞核分类模型中进行细胞核分类,并根据所述分类的结果确定所述病理染色图像中的上皮细胞核；其中,每一细胞核分割得到的区域包括细胞核的内部区域、内外邻域、外部区域和包含所述外部区域的最小矩形区域,所述单通道区域图像包括对应于所述初始尺寸图像的未缩放的内部区域、内外邻域、外部区域和最小矩形区域各自的三个单通道区域图像,以及对应于所述缩放图像的缩放后的内部区域、内外邻域、外部区域和最小矩形区域各自的三个单通道区域图像；所述对所述单通道区域图像进行特征提取以获取对应细胞核的单通道图像特征,以及基于所述单通道图像特征获取对应的多通道图像特征包括：对所述未缩放的内部区域、内外邻域、外部区域各自的三个单通道区域图像和所述缩放后的内部区域、内外邻域、外部区域各自的三个单通道区域图像进行一类特征提取,并对缩放后的最小矩形区域的三个单通道区域图像进行二类特征提取,得到所述细胞核的各单通道图像特征；将任意两个单通道图像特征的元素对应相乘以得到第一类多通道图像特征,将三个单通道图像特征的元素对应相乘以得到第二类多通道图像特征,合并所述第一类多通道图像特征和所述第二类多通道图像特征以得到所述细胞核的所述多通道图像特征。</td>   <td>G06T7/11;G06T7/136;G06T7/45;G06T7/62;G06T7/90;G06V10/764;G06V10/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马艳阳;              单云霄;                   陈龙       </td>   <td>中山大学</td>   <td>一种三维空间中移动机器人定位系统及方法</td>   <td>广东省</td>   <td>CN110689572B</td>   <td>2023-06-16</td>   <td>本发明涉及一种三维空间中移动机器人定位系统及方法。其中,事件信息处理模块从事件相机读取事件流,并将事件流中的光照强度变化事件按照一定的时间窗组成事件图像帧；深度图像采集模块从深度相机中读取深度图像,并对其进行去噪等处理,从而生成深度图像帧；处理后的图像帧传输到信息融合模块,信息融合模块根据两个相机的内参以及它们之间的外参,计算出事件图像帧中每一个事件的深度信息,从而得到带深度的事件图像帧；VO模块利用带深度的事件图像帧实现三维空间中的定位。本发明利用事件相机的特性,可以适应黑暗环境、高动态范围环境等极端环境,并且该系统中传感器体积小、功耗低、易于安装等优点,适合搭载到移动机器人或自动驾驶系统上。</td>   <td>1.一种三维空间中移动机器人定位系统,其特征在于,包括：事件信息处理模块：按照滑动时间窗口的方法,累计一定时间间隔内每个像素位置发生事件的次数,形成初始事件图像帧；随后使用预先标定的事件相机内参对初始事件图像帧进行畸变矫正,矫正完成后使用高斯滤波对事件图像帧进行平滑处理,形成可用的事件图像帧,输出给信息融合模块；深度图像采集模块：用于实时从深度相机读取深度图,使用预先标定的深度相机内参进行畸变矫正,然后使用像素滤波的方法对深度图中的无效点进行深度恢复,处理完成后得到可用的深度图像帧,输出给信息融合模块；信息融合模块：用于从事件信息处理模块和深度图像处理模块获取可用的事件图像帧和深度图像帧,按照时间戳进行匹配,随后利用预先标定好的两个相机之间的外参,将深度图像帧中的像素投影到事件相机的像素坐标系,形成深度映射；根据生成的深度映射,事件图像帧中的事件结合深度信息生成带深度的事件图像帧,输出给VO模块；VO模块：用于在获取带深度的事件图像帧后,使用FAST特征点算法提取图像中的特征点,并利用LK光流法计算出上一个事件图像帧与当前事件图像帧中的特征点的对应关系；利用事件图像帧中的深度信息,计算出特征点在相机坐标系下的三维坐标,进而使用PnP算法求解出当前事件图像帧相对于上一个事件图像帧的相机相对位姿。</td>   <td>G06T7/73;G06T7/80;G06T7/55;G06T5/00;G01C21/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   张锐斐       </td>   <td>中山大学</td>   <td>一种息肉分割方法、装置及存储介质</td>   <td>广东省</td>   <td>CN111986204B</td>   <td>2023-06-16</td>   <td>本发明公开了一种息肉分割方法、装置及存储介质,所述方法首先提取待检测者的影像数据,然后将其输入至预设的息肉分割模型,得到最终的息肉分割图像；上述息肉分割模型在对待检测影像数据记性识别时,先提取全局特征以及局部特征,然后根据全局特征和局部特征确定息肉的尺寸,紧接着根据息肉的尺寸分别计算全局特征和局部特征的注意力权重,根据注意力权重进行特征融合,生成与息肉尺寸对应的自适应特征,最后根据自适应特征生成最终的息肉分割图像,在整个息肉的自动化分割过程中,基于息肉的尺寸进行自适应分割,从而提高了息肉分割的准确性。</td>   <td>1.一种息肉分割方法,其特征在于,包括：提取待检测者病变部位的影像数据,获得待检测影像数据；将所述待检测影像数据输入至预设的息肉分割模型中,以使所述息肉分割模型对所述待检测影像数据进行识别,生成与所述待检测影像数据对应的息肉分割图像；其中,所述息肉分割模型对所述待检测影像数据的识别,生成与所述待检测影像数据对应的息肉分割图像,具体包括：从所述待检测影像数据中提取全局特征以及局部特征,并根据所述全局特征以及所述局部特征确定所述待检测影像数据所对应的息肉尺寸,继而根据所述息肉尺寸,确定所述全局特征的注意力权重以及所述局部特征的注意力权重；根据所述全局特征、所述全局特征的注意力权重、所述局部特征以及所述局部特征的注意力权重,生成自适应特征；根据所述自适应特征生成与所述待检测影像数据对应的息肉分割图像；其中,所述息肉分割模型,包括：不同层级的编码模块、不同层级的局部语义注意力模块、不同层级的解码模块、不同层级的自适应选择模块以及全局语义模块；每一所述局部语义注意力模块,用于根据由同一层级的编码模块所提取的特征信息,以及根据上一层级的解码模块的预设结果所生成的注意力图,提取每一层级的局部特征；每一所述全局语义模块,用于根据最后一层级的编码模块所提取的特征信息,提全局特征,并将所述全局特征输入至各个层级的自适应选择模块；每一所述自适应选择模块,用于根据由同一层级的局部语义注意力模块提取的局部语义特征、由所述全局语义模块提取的全局特征、由上一层级的解码模块传输的特征信息以及所述息肉的尺寸生成每一层级的自适应特征；其中,局部语义注意模块位于每一级编码器和解码器之间,用于向解码器传递局部语义信息,同时根据上一级解码器模块的预测结果生成注意图,再将注意力图与原有特征相乘；pred指的是上一级解码器模块的预测结果；0.5判断是否为息肉的概率阈值；全局语义模块位于编码器的顶端,其输入为编码器提取的特征,输出为经过进一步增强后的全局语义特征,并被送入每一级解码器前的自适应选择模块；全局语义模块包括4个分支,分别为全局平均池化,3×3自适应池化,5×5自适应池化和恒等映射模块,恒等映射模块通过非局部操作为每个像素点特征计算其与其他位置特征的长距离依赖关系；卷积处理后的各个分支的特征再经由上采样恢复到原始输入尺寸并拼接在一起,构成增强后的全局特征；自适应选择模块位于每一个解码器模块之前,通过全局语义模块、局部语义模块所解析的特征,对息肉的尺寸进行识别,解析息肉尺寸,然后根据所解析的息肉尺寸选择和融合来自局部语义注意力模块,全局语义模块和上一级解码器模块的特征；其中,在选择和融合时,将三种特征拼接在一起后经压缩和扩张完成特征选择；在压缩和扩张时,通过全局平均池化操作,将输入特征图转为特征向量后送入全连接层学习各个维度的注意力权重,并通过Sigmoid函数将权重限制于0到1之间,通过注意力权重和原本特征相乘,完成对全局或局部特征的自适应选择,生成自适应特征。</td>   <td>G06T7/10;G06V10/40;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;                   黄楚茵       </td>   <td>中山大学</td>   <td>一种长短期交通预测方法</td>   <td>广东省</td>   <td>CN112668797B</td>   <td>2023-06-16</td>   <td>本申请公开了一种长短期交通预测方法,获取构建的交通路网图中的节点的第一历史交通数据,通过预置交通预测模型中的第一卷积层对第一历史交通数据进行卷积处理；通过模型中的第一个迭代RNN算子对卷积处理后的第一历史交通数据进行交通预测,输出第一个时间步的交通预测结果,将第一个时间步的交通预测结果输入到下一个迭代RNN算子进行交通预测,直至第T-p个迭代RNN算子输出第T-p个时间步的交通预测结果,通过模型中的拼接模块将T-p个时间步的交通预测结果拼接后输入到第二卷积层进行卷积处理,输出最终的交通预测结果。本申请解决了现有的交通预测方法存在预测误差累计较高,以及不能同时兼顾长短期预测精度的技术问题。</td>   <td>1.一种长短期交通预测方法,其特征在于,包括：将交通路网构建为图结构,得到交通路网图；获取所述交通路网图中的节点的第一历史交通数据；将所述第一历史交通数据输入到包含第一卷积层、T-p个迭代RNN算子、拼接模块和第二卷积层的预置交通预测模型,使得所述第一卷积层对所述第一历史交通数据进行卷积处理,第一个迭代RNN算子对卷积处理后的所述第一历史交通数据进行交通预测,输出第一个时间步的交通预测结果,将所述第一个时间步的交通预测结果输入到下一个迭代RNN算子进行交通预测,直至第T-p个迭代RNN算子输出第T-p个时间步的交通预测结果,所述拼接模块对T-p个时间步的交通预测结果进行拼接,所述第二卷积层对拼接后的交通预测结果进行卷积处理,输出最终的交通预测结果；所述迭代RNN算子包括门控线性单元、扩散卷积层和全连接层；所述第一个迭代RNN算子对卷积处理后的所述第一历史交通数据进行交通预测,输出第一个时间步的交通预测结果,包括：所述门控线性单元提取卷积处理后的所述第一历史交通数据的时间依赖关系,输出第一特征；所述扩散卷积层提取所述第一特征的空间依赖关系,输出第二特征；所述全连接层对所述第二特征进行交通预测,输出第一个时间步的交通预测结果。</td>   <td>G06Q10/04;G06F17/16;G06N3/0464;G06N3/049;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁海朝;              王剑颖;              李明儒;              张亮;              李智;              伍元培;              罗云皓;                   车浩晖       </td>   <td>中山大学</td>   <td>一种火星大气电离层穿刺探测轨迹优化方法、装置及设备</td>   <td>广东省</td>   <td>CN114139277B</td>   <td>2023-06-16</td>   <td>本申请涉及一种火星大气电离层穿刺探测轨迹优化方法、装置及设备,其方法包括构建多次改变近地点幅角的升力体飞行器运动方程；建立弹道参数与轨道参数的转换关系；构建近地点幅角方程,并得到近地点幅角ω和弹道参数的关系；对近地点幅角ω进行局部敏感度分析,将使近地点幅角ω的敏感度最大的参数作为优化变量,使升力体飞行器每次飞出大气层时的速度达到最大,并通过选定不同的飞出点纬度φ,明确升体力飞行器飞出大气层时的位置；基于Gauss伪谱法对穿刺探测飞行轨迹进行优化,得到需要的再入轨迹。解决了现有的火星大气电离层探测方式存在探测区域片面、可探测范围受限的问题。本申请具有对火星大气电离层进行更全面地探测的效果。</td>   <td>1.一种火星大气电离层穿刺探测轨迹优化方法,其特征在于,包括以下步骤,构建多次改变近地点幅角的升力体飞行器运动方程；基于所述升力体飞行器运动方程,建立弹道参数与轨道参数的转换关系；基于所述弹道参数与轨道参数的转换关系,构建近地点幅角方程,并得到近地点幅角ω和弹道参数的关系；基于近地点幅角ω和弹道参数的关系,对所述近地点幅角ω进行局部敏感度分析,将使近地点幅角ω的敏感度最大所对应的弹道参数作为优化变量,同时,使升力体飞行器每次飞出大气层时的速度达到最大,并通过选定不同的飞出点纬度φ,明确升体力飞行器飞出大气层时的位置；基于Gauss伪谱法对穿刺探测飞行轨迹进行优化,得到需要的再入轨迹。</td>   <td>G06F30/15;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁雪林;              李媛;              朱祥维;              徐奕禹;                   李杜       </td>   <td>中山大学</td>   <td>一种基于深度学习与毫米波雷达的行为预测方法及系统</td>   <td>广东省</td>   <td>CN116258922A</td>   <td>2023-06-13</td>   <td>本申请属于人体行为识别技术领域,公开了一种基于深度学习与毫米波雷达的行为预测方法及系统。通过采集目标范围内不同受试者的不同行为动作的原始雷达数据；对原始雷达数据进行预处理,生成微多普勒图像,将微多普勒图像划分为训练集数据和测试集数据；构建VIT模型,获取公开数据集对VIT模型进行预训练,得到预训练的VIT模型；将训练集数据输入到预训练的VIT模型中进行训练,基于快照集成方法按照预设周期得到若干个不同参数的VIT模型；将测试集数据输入到不同参数的VIT模型中,得到不同行为动作的预测概率,基于预测概率使用集成策略得到最终行为预测结果。实现提高人体行为动作的识别精度。</td>   <td>1.一种基于深度学习与毫米波雷达的行为预测方法,其特征在于,所述方法包括：采集目标范围内不同受试者的不同行为动作的原始雷达数据；对所述原始雷达数据进行预处理,生成微多普勒图像,将所述微多普勒图像划分为训练集数据和测试集数据；构建VIT模型,获取公开数据集对VIT模型进行预训练,训练到所述VIT模型的准确率得到预设阈值,得到预训练的VIT模型；将所述训练集数据输入到预训练的VIT模型中进行训练,基于快照集成方法按照预设周期得到若干个不同参数的VIT模型；将测试集数据输入到若干个所述不同参数的VIT模型中,得到所述不同行为动作的预测概率,基于所述预测概率使用集成策略得到最终行为预测结果。</td>   <td>G06V10/774;G06N3/006;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;              廖琼华;                   何兆成       </td>   <td>中山大学</td>   <td>一种基于卡口数据的Paramics精准交通仿真场景构建方法</td>   <td>广东省</td>   <td>CN109711026B</td>   <td>2023-06-13</td>   <td>本发明公开了一种基于卡口数据的Paramics精准交通仿真场景构建方法,该方法通过对Paramics插件二次开发构建精准仿真插件,其包括用于消除Paramics随机发车的缺陷,使得仿真车辆的发车指令符合车辆出行路径表中的发车指令的精准发车模块、用于消除Paramics随机指定车辆出行路径选择行为的缺陷,使得仿真车辆的出行路径选择行为符合车辆出行路径表中的出行路径exit序列的精准出行路径选择行为模块。同时和卡口数据提取处理实现精准交通仿真场景构建,该仿真场景具有精准车辆个体生成和路径选择行为的优点,消除了现有技术中模拟交通生成和出行路径选择行为的随机性,提高了交通仿真精度。</td>   <td>1.一种基于卡口数据的Paramics精准交通仿真场景构建方法,其特征在于：该方法步骤如下：S1：采集目标路网参数信息,利用Paramics软件,建立Paramics仿真路网模型；所述的目标路网参数信息为卡口数据；S2：获取车辆出行路径exit序列,获取发车指令,所述的发车指令包括发车小区、发车时刻和消失小区；结合车辆出行路径exit序列、发车指令建立基于卡口数据的车辆出行路径表；S3：利用Paramics向用户开放的API函数,对Paramics插件进行二次开发获得精准仿真插件；所述精准仿真插件包括精准发车模块、精准出行路径选择行为模块；所述精准发车模块根据车辆出行路径表中的发车指令设置仿真车的发车小区、发车时刻和消失小区；所述精准发车模块用于消除Paramics随机发车的缺陷,使得仿真车辆的发车小区、发车时刻和消失小区符合车辆出行路径表中的发车指令；所述的精准出行路径选择行为模块用于消除Paramics随机指定车辆出行路径选择行为的缺陷,使得仿真车辆的出行路径选择行为符合车辆出行路径表中的出行路径exit序列；S4：将精准仿真插件编译成动态链接库,设置成Paramics仿真路网加载的插件,保存在步骤S1中的Paramics仿真路网模型的文件夹中,实现在Paramics仿真路网模型中能加载精准仿真插件；运行加载精准仿真插件的Paramics路网模型,实现构建Paramics精准交通仿真场景；所述精准发车模块通过调用可供获取的Paramics API函数,为被赋予和未被赋予发车指令的车辆分别设置“True”标签和“False”标签,以区分被赋予和未被赋予发车指令的仿真车辆；令具有“False”标签的车辆不能离开zone元素进入目标路网,仅具有“True”标签的车辆才允许离开所在zone元素进入目标路网,实现精准交通仿真场景的精准发车功能；所述精准发车模块在仿真路网中具体运行操作步骤如下：F1：设置具有“False”标签的车辆保持“hold”状态和“braking”状态：对于路网中被设置为“False”标签的车辆,令其保持“hold”状态,使其不能离开当前zone元素；并且,令其保持“braking”状态,使其处于停车排队状态；F2：从车辆出行路径表中读取下一条发车指令；F3：获取当前仿真步长对应的仿真时间；判断当前仿真时间是否等于发车指令中的发车时刻：若是,则根据当前发车指令的发车小区,指定发车小区zone元素中具有“False”标签的第一辆车作为接收当前发车指令的待发车；设置待发车为“True”标签,使其解除“hold”状态从而可以离开当前zone元素；根据当前发车指令的消失小区,设置待发车离开路网的zone元素；将待发车的位置设在当前zone元素对应的link元素下游,以符合卡口检测位置；根据交通流参数信息中的路段平均行驶车速信息设置待发车的初始车速,使其解除“braking”状态并驶离zone元素进入路网,成为一辆已发车；使得该已发车的发车小区、发车时刻和消失小区均符合当前发车指令；将当前发车指令对应的车辆出行路径表中的出行路径exit序列赋给该已发车,设置精准出行路径选择行为的依据；返回上述步骤F2；F4：若不是,则当前仿真步长不作处理；进入下一个仿真步长,判断是否到达仿真时段内的最后一个仿真步长；若不是,则返回上述步骤F3；F5：若是,则仿真结束；所述精准出行路径选择行为模块通过调用可供获取的Paramics API函数,判断车辆是否具有不同转向行为选择；车辆位于下游出口为交叉口的link元素上会面临转向选择行为,首先判断车辆是否位于下游出口数大于1的link元素上；为避免对位于同一个link的同一辆车重复设置转向选择行为,需判断车辆前后两个仿真步长所在的link元素是否不同,即判断车辆在当前仿真步长是否位于一个新的link元素；已发车位于一个新的link元素且下游出口数大于1会面临不同转向行为选择,根据其被赋予的出行路径exit序列设置转向选择行为；所述精准出行路径选择行为模块在仿真路网中运行步骤如下：H1：获取路网上一辆在当前仿真步长未被遍历的已发车；所述已发车具有“True”标识；H2：获取该已发车当前所在link元素名称；查询该link元素下游出口数；判断该已发车是否位于一个新的link元素且下游出口数大于1；若不是,则返回步骤H1；H3：若是,则根据该已发车的仿真车辆标识获取其对应的出行路径exit序列,查询该已发车在当前link元素下游交叉口的exit标识；根据该exit标识设置该已发车在下游交叉口的转向选择行为；判断当前仿真步长是否已经遍历完所有已发车：若是,则当前仿真步长不作处理；进入下一个仿真步长,判断是否到达仿真时段内的最后一个仿真步长：若不是,则返回步骤H1；若是,则仿真结束。</td>   <td>G06F30/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何兆成;                   钟嘉明       </td>   <td>中山大学</td>   <td>一种基于蚁群算法的响应式公交服务规划方法</td>   <td>广东省</td>   <td>CN110598971B</td>   <td>2023-06-13</td>   <td>本发明涉及一种基于蚁群算法的响应式公交服务规划方法,通过以区域内出行者的出行时间、出行起终点等出行信息为基础,利用蚁群算法这一效果优、解释性强的启发式算法,规划包括发班时间、服务车型及途径站点在内的响应式公交服务方案,实现公交资源供给与公交出行需求的最优适配。本发明提出的方法具有数据驱动性,可规划得到稳定、优质的响应式公交服务方案；并且本发明提出具有良好的可解释性,便于使用者根据实际情况,理解、复现与改造方法,适用性广,可推广性强。</td>   <td>1.一种基于蚁群算法的响应式公交服务规划方法,其特征在于,包括以下步骤：步骤S1：获取用户公交出行的需求数据；步骤S2：基于需求数据构建响应式公交服务模型；步骤S3：基于蚁群算法对响应式公交服务模型进行优化,得到响应式公交的服务方案；步骤S4：根据响应式公交的服务方案求得响应式公交的服务方案的成本；求得响应式公交的服务方案的具体步骤如下：利用蚁群算法中关于局部感知信息和全局指引信息的架构思想,将服务求解策略分为短期策略η及长期策略τ,其策略设计方式分别如下：对于短期策略η,其作用是为单辆公交车在当前站点及当下系统状态中,选择最为合适的下一公交站点,以k表示公交车当前站点,k～*表示下一站点,根据短期策略即式(5),计算公交车j在任意下一站点k～*的表现：                  其中,Board-(k*)为站点k～*的上车人数,通过需求端信息获得；Aligh-(k*)为站点k～*的下车人数,通过需求端信息获得；Δt-(k,k*)为公交车在站点k及k～*间的行驶时间,由实测获得；对于长期策略τ,其作用是结合以往公交车服务方案经验,为当下公交车生成服务方案提供支持的策略；对于以往每一辆服务的公交车,依据其车辆运营成本,在其所经过的站点区段上会留下成本信息,以指引后续公交车进行服务路线规划,计算方法如式(6)所示,表示公交车j从站点k开往站点k～*的次数,/&gt;为公交车j的运营总成本：                  长短期策略的结合方法如式(7)所示,其中代表公交车j在站点k时,选择开往站点k～*的概率,α为在每一次选择时长期策略τ的重要程度,β为在每一次选择时短期策略η的重要程度,通过/&gt;公交车j就能够在站点k时,做出下一站点的行驶选择,直至最终完成服务                  步骤S5：判断响应式公交的服务方案的成本是否收敛,若是,以该方案作为最优响应式公交服务方案进行输出,若否,重新调整蚁群算法,返回步骤S3。</td>   <td>G06Q10/0631;G06Q10/047;G06Q50/30;G06N3/006</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;                   罗京       </td>   <td>中山大学</td>   <td>基于弱监督学习的用户定制化目标检测方法、系统和存储介质</td>   <td>广东省</td>   <td>CN112613548B</td>   <td>2023-06-13</td>   <td>本发明公开了一种基于弱监督学习的用户定制化目标检测方法、系统及存储介质,方法包括下述步骤：构建目标检测架构,包括客户端和服务端；在客户端上传训练所需的图像数据和图像类别标注数据,服务端根据标注类别数构建WSDDN-PCL弱监督目标检测模型；服务端使用用户上传的图像和标注数据训练弱监督目标检测模型,训练好的模型保存在服务端；在客户端上传需要检测的图像数据,服务端加载训练好的目标检测模型,并对用户上传的图像数据进行检测,将检测结果存储在服务端；用户从服务端下载检测结果,完成目标检测任务。本发明的方法可以定制化地从线上图库中爬取数据并训练目标检测模型,并将复杂的计算过程放到服务器进行,同时满足易用性和快速性的要求。</td>   <td>1.基于弱监督学习的用户定制化目标检测方法,其特征在于,包括下述步骤：构建目标检测架构,所述目标检测架构包括客户端和服务端,所述客户端采用PyQT设计,用于与服务端交互、采集网络数据及过滤不良数据；所述服务端使用tornado搭建,用于接收用户上传数据、创建目标检测模型、训练模型、存储模型、存储训练数据和检测结果,所述服务端数据库使用MySQL管理,用于图像数据、标注数据和模型的存储,所述目标检测模型使用Pytorch搭建；所述客户端采用PyQT设计,具体为：项目设计,所述项目设计包括创建项目和打开项目,若选择创建项目,则服务端生成项目文件夹用于管理新项目；若选择打开项目,则选择要打开某一具体项目；模型检测,所述模型检测包括模型训练和目标检测；当选择模型训练,服务端自动生成模型并进行训练,训练好的模型被保存到服务端并由用户命名；当选择目标检测,则选择已经训练好的模型版本,并选择一个测试集,最终服务端会将测试集的图像数据输入所选模型进行目标检测,并输出结果到服务端；数据传输,所述数据传输包括上传训练集、上传测试集和下载检测结果；若选择上传训练集,则用户从本地文件中选择训练集后上传,上传的数据集将被合并到该项目的训练集中,一个项目只能有一个训练集；若选择上传测试集,则用户从本地文件中选择测试集,命名后上传,一个项目可有多个测试集；若选择下载检测结果,则用户从服务端中下载模型的检测结果；数据爬取,输入检测和爬取数量,自动从网络图库中爬取相关图像,爬取结果将展示在界面中,过滤数据之后,并输入该数据集的分类标签并为数据集命名,将数据集上传至服务端；所述服务端使用tornado搭建,所述服务端用于训练模型和目标检测；训练模型时,服务端分配GPU和内存资源,导入客户端指定的训练集,生成模型并训练,训练好的模型将保存于服务端并由相应项目管理；进行目标检测时,服务端分配GPU和内存资源,导入客户端指定的模型和测试集并执行目标检测,目标检测的结果将保存于服务端并由相应项目管理；在客户端上传训练所需的图像数据和图像类别标注数据,服务端根据标注类别数构建WSDDN-PCL弱监督目标检测模型；所述WSDDN-PCL弱监督目标检测模型的损失函数由两部分组成：                  其中L-(WSDDN)是WSDDN模型的多元交叉熵损失函数,是第i层自训练网络的损失函数；服务端使用用户上传的图像和标注数据训练弱监督目标检测模型,训练好的模型保存在服务端；在客户端上传需要检测的图像数据,服务端加载训练好的目标检测模型,并对用户上传的图像数据进行检测,将检测结果存储在服务端；用户从服务端下载检测结果,完成目标检测任务。</td>   <td>G06V10/82;G06V10/764;G06V10/40;G06N3/0464;G06N3/0895</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李岱峰;              林凯欣;              李栩婷;              李鑫;              古风云;              江涛;                   廖健斌       </td>   <td>中山大学</td>   <td>一种多模态融合技术的图书宣传摘要生成方法和系统</td>   <td>广东省</td>   <td>CN114281982B</td>   <td>2023-06-13</td>   <td>本发明公开了一种多模态融合技术的图书宣传摘要生成方法和系统,方法包括以下步骤：S1：获取包括图书信息的文本信息；S2：根据所述文本信息,基于TextRank的抽取式摘要生成,生成第一摘要；S3：根据所述文本信息,基于多模态指针生成网络,生成第二摘要；S4：取第一摘要和第二摘要的并集为最终的图书宣传摘要。本发明结合抽取式与生成式模型的优点,并取并集,克服了两者的缺陷得到更加完整的营销文本。</td>   <td>1.一种多模态融合技术的图书宣传摘要生成方法,其特征在于,包括以下步骤：S1：获取包括图书信息的文本信息；S2：根据所述文本信息,基于TextRank的抽取式摘要生成,生成第一摘要；S3：根据所述文本信息,基于多模态指针生成网络,生成第二摘要；S4：取第一摘要和第二摘要的并集为最终的图书宣传摘要；所述基于多模态指针生成网络,生成第二摘要,具体为：对于文本特征,利用Seq2Seq模型得到一个文本嵌入向量；对于图像特征,利用基于模型隐藏状态初始化的视觉特征提取策略,得到视觉上下文向量；将所述文本嵌入向量和视觉上下文向量结合,计算得到多模态上下文向量；利用所述多模态上下文向量更新指针生成网络,所述指针生成网络用来预测单词,得到第二摘要；对于文本特征,所述Seq2Seq模型的结构为Encoder-Decoder模型,先用Encoder将原文本编码成一个中间层的隐藏状态,然后用Decoder来将该隐藏状态解码成为另一个文本,Seq2Seq模型在Encoder端是一个双向的LSTM,这个双向的LSTM可以捕捉原文本的长距离依赖关系以及位置信息,编码时词嵌入经过双向LSTM后得到编码状态,在Decoder端,解码器是一个单向的LSTM,训练阶段时参考摘要词依次输入,在时间步t得到解码状态,使用编码状态和解码状态得到该时间步原文第i个词注意力权重,编码状态h-i与解码状态s-t如下所示：h-i＝f-(enc)(x-i,h-(i-1))s-t＝f-(dec)(s-(t-1),y-(t-1),c-t)其中,f-(enc)为编码函数,f-(dec)为解码,y-(t-1)为t-1步的生成词,c-t是一个上下文向量,它由基于注意力的编码器隐藏状态的加权和生成,其分布如下：                  α-t＝softmax(e-t)c-t＝∑-iα-(t,i)h-i式中,e-(t,i)指t阶段第i个词注意力权重、W-a、V-a、b-a均为学习权重,e-t指的是t阶段的隐藏层权重；对于图像特征,输入一个给定的图书封面或海报图像,使用Resnet-101的最后一个池化层中提取预先训练的ImageNet的全局的可视化向量q,并用它来初始化编码器和解码器：                                                      式中,W-(e1)、b-(e1)、W-(e2)、b-(e2)、W-f、V-w、b-f为学习参数；为了利用局部视觉特征增强上下文表征,提取目标特征v-i作为局部的视觉特征,使用ResNet-101初始化的Mask R-CNN,然后使用可视化基因组数据集对其进行再训练,来自Region Proposal Network的RoIAlign层；/&gt;除了对输入句子的单词的注意外,多模态指针生成模型还可以对图像的不同区域进行权重提取,应用了分层注意力机制,使模型对文本信息和视觉信息进行了不同的注意,我们使用跨模态注意策略计算视觉上下文向量                                                      其中,W-l、V-l、b-l为学习参数；将所述文本嵌入向量和视觉上下文向量结合,计算得到多模态上下文向量,具体为：                                                                                          式中,W-g、V-g、b-g、W-h、V-h、W-m、V-m为学习参数,σ为sigmoid函数,/&gt;通过激活函数映射后的文本向量,/&gt;通过激活函数映射后的视觉图像向量,I-α为通过激活函数映射后的融合上下文信息的视觉特征向量；所述指针生成网络根据两个模块的概率分布来预测单词,即生成器和指针,生成器如下所示：                  其中,W-b、V-b、b-b为学习参数,P-(gen)(w)为预测词汇w分布；指针则是从源序列中复制一个字y-t：                  其中,P-(copy)(w)指的是单词是从源序列中复制而来的概率,w为预测单词；最后的分布是词汇量分布和注意力分布的加权和：P(w)＝λ-tP-(gen)(w)+(1-λ-t)P-(copy)(w)其中,λ-t∈[0,1]是时间序列的生成概率：                  其中,b-d、/&gt;为学习参数,y-(t-1)指的是t-1时间步的目标词；损失函数L是每个时间步长t中真实目标词y-t的负对数似然：                  其中,T表示总的时间长度,P(y-t)指的是真实目标词的概率分布；所述取第一摘要和第二摘要的交集为最终的图书宣传摘要,具体为：使用python对两个模型的输出结果取并集,代码如下：all-union＝list(set(s1).union(set(s2)))其中s1为TextRank的输出结果,s2为多模态指针模型的输出结果,并针对最终结果all-union去更新多模态指针生成网络。</td>   <td>G06F16/34;G06N3/0455;G06N3/0442;G06N3/048;G06N3/0464;G06N3/088</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵薛强;              陈洋波;              刘俊;                   孙怀张       </td>   <td>中山大学</td>   <td>一种融合遥感图像与点云数据的地理要素识别方法</td>   <td>广东省</td>   <td>CN116258970A</td>   <td>2023-06-13</td>   <td>本发明提供一种融合遥感图像与点云数据的地理要素识别方法,涉及图像数据处理的技术领域,首先采集图像数据和点云数据并进行类别标注,构建为样本数据集,再构建融合图像与点云数据的语义分割模型,提取图像数据的2D特征和点云数据的3D特征并融合得到图像和点云的分割预测值,利用样本数据集训练融合图像与点云数据的语义分割模型,最后将待识别遥感图像、待识别遥感图像对应的点云数据输入训练好的融合图像与点云数据的语义分割模型,输出图像分割结果和点云分割结果,利用不同的色彩对不同类别的点云分割结果进行标记,实现地理要素的识别,充分利用了2D图像信息的有序性以及3D点云数据的空间性,提高了地理要素的分割识别精度。</td>   <td>1.一种融合遥感图像与点云数据的地理要素识别方法,其特征在于,包括：S1.采集图像数据和点云数据,对图像数据和点云数据分别进行类别标注,分别作为图像数据和点云数据的真实标签,将带有类别标注的图像数据和点云数据构建为样本数据集,将样本数据集划分为训练集、验证集、测试集；S2.构建融合图像与点云数据的语义分割模型,融合图像与点云数据的语义分割模型包括用于提取图像数据的2D特征的2D分支2D Branch、用于提取点云数据的3D特征的3D分支3D Branch及融合结构Feature Fusion,融合结构Feature Fusion连接2D分支和3D分支,将2D特征和3D特征融合,利用2D特征优化3D特征,得到图像分割预测值和点云分割预测值；S3.利用训练集对融合图像与点云数据的语义分割模型进行训练,训练过程中分别计算图像分割预测值和点云分割预测值与真实标签图之间的损失值,根据损失值调整融合图像与点云数据的语义分割模型的参数,直到融合图像与点云数据的语义分割模型收敛,然后利用验证集对训练过程中的融合图像与点云数据的语义分割模型进行评估,得出训练好的融合图像与点云数据的语义分割模型,并利用测试集测试融合图像与点云数据的语义分割模型的预测准确度；S4.将待识别遥感图像、待识别遥感图像对应的点云数据输入训练好的融合图像与点云数据的语义分割模型,输出图像分割结果和点云分割结果；S5.利用不同的色彩对不同类别的点云分割结果进行标记,展示分割结果,实现地理要素的识别。</td>   <td>G06V20/10;G06V20/70;G06V10/80;G06V10/26;G06N3/0464;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              苏卓;                   谭宇帝       </td>   <td>中山大学</td>   <td>基于高性能并行计算的特征保持的网格处理方法与系统</td>   <td>广东省</td>   <td>CN116258862A</td>   <td>2023-06-13</td>   <td>本发明公开了一种基于高性能并行计算的特征保持的网格处理方法与系统。输入点云未标注数据集,训练点云特征生成器和预测头MLP-α；输入带有语义分割标签的网格数据集,对网格表面进行采样以生成稀疏点云,以及对网格加入噪声以表示网格几何裁剪任务的冗余结构,之后通过去除训练后的所述预测头MLP-α,分别训练预测头MLP-β与MLP-γ；用户输入待处理网格,将所有顶点转为稀疏点云,利用点云特征生成器与预测头MLP-β、MLP-γ,分别生成该稀疏点云的语义分割标签以及冗余结构类别标签；最后对标记为冗余结构的点执行剔除操作,完成网格的裁剪。本发明能有效理解网格数据中的特征,语义分割结果更为准确。本发明加噪声过程采用CUDA并行计算架构保证了整个计算过程的高效性。</td>   <td>1.一种基于高性能并行计算的特征保持的网格处理方法,其特征在于,所述方法包括：输入点云未标注数据集,并用点云重建任务训练编码点云特征的MAE模型的Transformer点云特征生成器和预测头MLP-α；输入带有语义分割标签的网格数据集,对数据集中的网格表面进行采样以生成稀疏点云,之后通过去除训练后的所述预测头MLP-α,冻结所述MAE模型的Transformer点云特征生成器部分的参数,训练预测头MLP-β；根据所述带有语义分割标签的网格数据集,对数据集中的网格加入噪声以表示网格几何裁剪任务的冗余结构,之后训练新增冗余结构类别后的预测头MLP-γ；用户输入待处理网格,首先将其所有顶点转为稀疏点云,之后利用所述MAE模型的Transformer点云特征生成器与所述训练完成的预测头MLP-β,生成该稀疏点云每个点的语义分割标签；然后利用所述MAE模型的Transformer点云特征生成器与所述训练完成的预测头MLP-γ,生成该稀疏点云每个点的语义分割标签以及冗余结构类别标签；最后对标记为冗余结构的点执行剔除操作,其邻接顶点构成新的网格面片,完成网格的裁剪。</td>   <td>G06V10/26;G06V10/764;G06V10/774;G06T7/10;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭晓军;              安亚松;              张晓飞;              刘群铭;                   石艳丽       </td>   <td>中山大学</td>   <td>一种车云协同的智能3D多目标跟踪方法及系统</td>   <td>广东省</td>   <td>CN116259015A</td>   <td>2023-06-13</td>   <td>本发明公开了一种车云协同的智能3D多目标跟踪方法及系统,方法包括：对车辆目标进行检测,获取初始时刻场景下各个车辆的检测状态,建立初始轨迹信息；根据初始时刻场景下的跟踪结果的目标信息,通过卡尔曼滤波算法预测目标时刻的状态；对车辆对象进行检测,获取各个车辆的检测状态,进而计算目标时刻下所有检测对象的检测框信息与初始时刻下目标的预测状态之间的数据关联度；根据数据关联度,对所有检测对象和预测对象进行相似度匹配,得到匹配结果；对匹配结果进行目标状态管理,直至完成跟踪目标。本发明能够快速完成对多个目标车辆的跟踪确认,基于车云协同的车辆数据,提高了跟踪预测的准确性,可广泛应用于车云协同控制技术领域。</td>   <td>1.一种车云协同的智能3D多目标跟踪方法,其特征在于,包括：对车辆目标进行检测,获取初始时刻场景下各个车辆的检测状态,进而根据所述检测状态和车辆身份建立初始轨迹信息；其中,所述检测状态包括车辆检测框信息、检测置信度分数；根据所述初始时刻场景下的跟踪结果的目标信息,通过卡尔曼滤波算法预测目标时刻的状态；对车辆对象进行检测,获取目标时刻场景下各个车辆的检测状态,进而计算目标时刻下所有检测对象的检测框信息与初始时刻下目标的预测状态之间的数据关联度；根据所述数据关联度,对所有检测对象和预测对象进行相似度匹配,得到匹配结果；对所述匹配结果进行目标状态管理,直至完成跟踪目标。</td>   <td>G06V20/54;G06V20/64;G06V10/74</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              庞健宇;              罗明杰;              吴晓航;                   陈睛晶       </td>   <td>中山大学中山眼科中心</td>   <td>一种虚拟专家医师的人机互动方法及装置</td>   <td>广东省</td>   <td>CN116257614A</td>   <td>2023-06-13</td>   <td>本发明涉及人工智能技术领域,公开了一种虚拟专家医师的人机互动方法及装置。该方法可以应用在病前咨询和就医后的结果咨询,当用户输入用于病前咨询的信息时,可以通过医疗语境对话模型,生成解答用户问题的第一文字结果,并通过语言风格转换模型将专业程度高的第一文字结果转换为容易被患者理解、通俗易懂的第二文字结果,再将第二文字结果转换为专家医师讲述医嘱以及解释医疗诊断的虚拟解答视频；当用户输入诊断结果进行咨询时,无需经过医疗语境对话模型,可以直接采用语言风格转换模型,再生成虚拟解答视频。本发明可以营造专家医师面对面耐心讲解诊断结果与进行医疗嘱咐的医疗场景,提高了问诊的效率、也提高了看病体验和医患关系。</td>   <td>1.一种虚拟专家医师的人机互动方法,其特征在于,包括：识别用户输入的信息,并将用户输入的信息转化为输入向量；在预设的医疗语境对话模型中识别所述输入向量,并搜索与所述输入向量对应的第一文字结果；根据预设的语言风格转换模型,自动修饰所述第一文字结果,生成第二文字结果；将第二文字结果进行文字转视频处理,并结合AI换脸技术生成虚拟解答视频。</td>   <td>G06F16/332;G16H80/00;G06F16/33;G06F40/35;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘懿梅;              彭应林;              陈美宁;              陈利;              邓小武;                   祁振宇       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种基于MR图像智能勾画方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN116258671A</td>   <td>2023-06-13</td>   <td>本发明公开了一种基于MR图像智能勾画方法、系统、设备及存储介质,包括：获取初始MR图像和初始CT图像,并分别进行划分,对应得到多组第一MRI图像和第一CT图像；并同时作为第一神经网络模型的输入,对应输出多组第一器官预测概率图；依次计算第一器官预测概率图中危及区域器官的中心位置坐标,对应得到危及器官所在的第一图像；依次对第一图像分类,并对应使用不同的分割方式,对应得到全部靶区和危及器官的第一分割结果；确定肿瘤分割的目标区域,并其对应的第一MRI图像、第一CT图像和各危及器官对应的第一分割结果作为第二神经网络模型的输入,输出对肿瘤的第二分割结果。本发明能够对基于MR图像进行多器官同时快速自动精细分割。</td>   <td>1.一种基于MR图像智能勾画方法,其特征在于,所述方法包括：获取初始MR图像和初始CT图像,并分别按照区域和阈值进行划分,对应得到多组第一MRI图像和第一CT图像；将所述多组第一MRI图像和所述第一CT图像同时作为第一神经网络模型的输入,对应输出多组第一器官预测概率图；依次计算第一器官预测概率图中危及区域器官的中心位置坐标,对应得到危及器官所在的第一图像；根据危及器官的体积和与周围组织的对比度,依次对第一图像分类,并对应使用不同的分割方式进行第一分割,对应得到全部靶区和危及器官的第一分割结果；根据临床先验知识,确定肿瘤分割的目标区域,并将所述目标区域对应的第一MRI图像、所述第一CT图像、所述多组第一器官预测概率图和各危及器官对应的第一分割结果作为第二神经网络模型的输入,输出对肿瘤的第二分割结果,以实现基于MR图像的肿瘤分割。</td>   <td>G06T7/00;G06T7/13;G06T7/11;G06T7/62;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              李兆文;                   林淑金       </td>   <td>中山大学</td>   <td>基于手绘草图语义的外观专利图像检索方法与系统</td>   <td>广东省</td>   <td>CN115878833B</td>   <td>2023-06-13</td>   <td>本发明提出一种基于手绘草图语义的外观专利图像检索方法与系统,涉及深度学习与图像检索的技术领域,选取外观专利图像数据集后处理,形成图像-草图-简化草图配对的图像数据集,构建图像检索模型对图像、草图、简化草图分别进行特征提取,得到低层、中层和高层的特征图,并将低层、中层和高层的特征图按通道维相接,利用卷积和全连接层获得图像语义特征编码,从而实现图像或者草图的编码到的信息能够既观察到局部细节,也能观察到全局的特征,进一步提升了检索的精度；以对比损失函数来替代三元组损失,降低数据选取的随机性,从而避免了挖掘三元组的问题。利用对比学习在草图图像检索中应用,加快了训练收敛速度,提高了检索的精度。</td>   <td>1.一种基于手绘草图语义的外观专利图像检索方法,其特征在于,所述方法包括以下步骤：S1.选取外观专利图像数据集,对外观专利图像数据集中的图像数据进行处理,形成图像-草图-简化草图配对的图像数据集；在步骤S1中,将外观专利图像数据集中每个外观专利图像生成配对的手绘草图、彩色图像和草图笔画坐标信息；设草图笔画坐标信息为,其中,/&gt;为草图笔画的数量,将草图笔画坐标信息输入到预训练好的笔画子集选择器中,通过一个局部长短期记忆网络LSTM和一个全局长短期记忆网络LSTM,得到简化后的有效检索笔画的坐标信息/&gt;,其中,/&gt;为简化后的草图的笔画数量,/&gt;&lt;/&gt;,简化后的草图笔画坐标信息通过光栅化形成新的像素简化草图,最终形成图像-草图-简化草图配对的图像数据集；S2.构建图像检索模型,图像检索模型对图像数据集中的图像、草图、简化草图分别进行特征提取,得到低层、中层和高层的特征图,并将低层、中层和高层的特征图按通道维相接,利用卷积和全连接层获得图像语义特征编码；在步骤S2中,构建的图像检索模型为VGG16网络的前13层网络,由五个卷积块组成,其中,第一个卷积块由两个卷积层和一个maxpooling层组成,第二个卷积块到第五个卷积块均由三个卷积层和一个maxpooling层组成,卷积层使用的卷积核均为33大小,五个卷积块的卷积通道数分别为64、128、256、512及512；图像、草图、简化草图中的每一种图均通过第一个卷积块、第三个卷积块、第五个卷积块进行特征提取,得到第一特征图、第二特征图及第三特征图,然后利用双线性插值公式对第一特征图、第二特征图进行插值,得到第一插值特征图及第二插值特征图,第一插值特征图、第二插值特征图与第三特征图在通道维进行结合,得到第四特征图,再经过一个512通道的11卷积层,得到融合特征图,最后使用两个全连接层得到图像语义特征编码；S3.将图像数据集划分为训练集、验证集和测试集；S4.利用图像检索模型对训练集中的图像、草图、简化草图分别进行图像语义特征编码,得到图像编码、草图编码及简化草图编码；S5.分别构建图像-草图对比损失函数、草图-简化草图对比损失函数、图像-简化草图对比损失函数；S6.基于S5构建的三个对比损失函数计算最终的损失函数,利用优化器优化训练图像检索模型,并利用验证集验证,得到训练好的图像检索模型；S7.利用训练好的图像检索模型对数据库中的外观专利图像进行预编码,得到图像预编码数据库；S8.对测试集中手绘的外观专利图像草图进行预处理,利用训练好的图像检索模型对预处理后的草图进行语义特征编码,将编码结果与图像预编码数据库对比,返回图像检索结果；在步骤S7中,将数据库中的外观专利图像输入到训练好的图像检索模型中,得到对应的图像编码,i=1,2,…,n,n为数据库图像的数量；对测试集中手绘的外观专利图像草图进行预处理时,手绘的外观专利图像草图首先以笔画坐标信息方式存储,然后通过预训练好的笔画子集选择器,提取出简化后的草图笔画坐标信息,原始的手绘外观专利图像草图笔画和简化后的草图笔画分别通过光栅化形成像素草图和像素简化草图；像素草图和像素简化草图分别通过训练好的图像检索模型进行语义特征编码,分别得到草图编码和简化草图编码/&gt;,得到的草图编码/&gt;和简化草图编码/&gt;分别与步骤S7中得到的所有图像编码进行相似度计算,分别得到草图相似度/&gt;和简化草图相似度/&gt;,最终相似度设为：                  其中,为最终相似度,/&gt;,/&gt;为相似度权重,相似度权重能被手动调整以优化图像检索结果；根据相似度/&gt;的大小进行检索排序,/&gt;越大的相似度越高,排名越靠前；根据排序好的相似度,提取相似度对应的图像,返回检索结果。</td>   <td>G06F16/583;G06V10/44;G06V10/74;G06V10/774;G06V10/82;G06Q50/18;G06N3/0442;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              李辉忠;              郝偲成;              南雨宏;              叶铭熙;              白兴强;              张开翔;                   范瑞彬       </td>   <td>深圳前海微众银行股份有限公司;中山大学</td>   <td>文本信息的验证方法和装置</td>   <td>广东省</td>   <td>CN116257251A</td>   <td>2023-06-13</td>   <td>本申请提供了一种文本信息的验证方法和装置,属于金融科技(Fintech)领域,该方法包括：获取待验证的智能合约,所述智能合约中包括有至少一个结构体,所述结构体包括有至少一个数据类型为用户定义的变量；对所述智能合约中的结构体进行拆分,确定该结构体的结构体信息,所述结构体信息至少包括该结构体的结构体名称、该结构体所处的合约的合约名、结构体中变量的数据类型和变量名；根据所述结构体信息,翻译所述智能合约得到中间验证语言表示的智能合约；获取形式规约并根据所述形式规约对所述中间验证语言进行验证。该技术方案可以将智能合约中的任意数据类型的变量翻译到中间验证语言,并基于中间验证语言和规约实现了对智能合约的验证。</td>   <td>1.一种文本信息的验证方法,其特征在于,包括：获取待验证的智能合约,所述智能合约中包括有至少一个结构体,所述结构体包括有至少一个数据类型为用户定义的变量；对所述智能合约中的结构体进行拆分,确定该结构体的结构体信息,所述结构体信息至少包括该结构体的结构体名称、该结构体所处的合约的合约名、结构体中变量的数据类型和变量名；根据所述结构体信息,翻译所述智能合约得到中间验证语言表示的智能合约；获取形式规约并根据所述形式规约对所述中间验证语言表示的智能合约进行验证。</td>   <td>G06F8/41;G06F21/44</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈泽涛;              王瑞轩;              龚卓弘;              李晓晖;              施梦汝;                   蔡耿彬       </td>   <td>中山大学附属口腔医院</td>   <td>一种基于细粒度网络毫微米级别影像精细解剖结构量化分析工具</td>   <td>广东省</td>   <td>CN116246755A</td>   <td>2023-06-09</td>   <td>本发明提供了一种基于细粒度网络的毫米-微米级别影像精细解剖结构分析工具,其通过构建标准化影像精细解剖结构数据库,基于细粒度图像量化分析网络,开发适配于不同专科的毫米-微米级精细解剖结构人工智能分析模式,整合为医学影像毫米-微米级别精细影像结构结构智能分析系统,本发明通过深度学习技术无需消耗大量人力时间成本进行数据集注释,可以实现对影像精细解剖结构的高效、自动化、量化分析,解决人工智能难以定位影像学中精细解剖结构、充分提取微小区域内的图像特征和量化分析图像特征的问题,有效减轻临床医生工作负担,提高医疗工作效率。</td>   <td>1.一种基于细粒度网络的毫米-微米级别影像精细解剖结构分析工具,其特征在于,包含以下步骤：S1、构建标准化影像精细解剖结构数据库S1.1、医学影像的标准化收集收集各专科在疾病诊治中所需的影像学资料,在影像学资料收集过程中,需要由专业人员进行影像图片的质量控制,筛除模糊、存在伪影的影像学资料,确保所收集影像学资料能准确反映相应精细解剖结构的定量及半定量特征；S1.2、构建标准化精细解剖结构影像资料库根据所属影像学资料来源及类型,将步骤S1.1所收集的标准化影像学资料进行归类和存储,按照不同专科对相应精细解剖结构的分析需要,选取最有利于诊断及特征观察的剖面,进行图像截取,获取精细解剖结构的标准二维图像；S1.3、精细解剖结构的提取、测量、标注模块将步骤S1.2所获取的精细解剖结构的标准二维图像导入数据量化分析软件中,由受过系统性训练的人员进行指标提取、测量、标注,得到精细解剖结构的定量化数据；根据定量化数据及临床语义,赋予精细解剖结构相应的半定量类别标签；S1.4、构建标准化影像精细解剖结构数据库将步骤S1.2中获得的精细解剖结构的标准二维图像与步骤S1.3中获得的定量化数据、半定量标签与进行匹配,以图像所来源的患者信息为主键,关联该所属于该患者的标准二维图像、定量化数据及半定量标签,构建标准化影像精细解剖结构数据库；S2、构建搭载细粒度图像识别网络的影像精细解剖结构量化分析模块构建细粒度图像识别网络模型的精细解剖结构量化分析模块,细粒度图像识别网络主要由以下部分组成,包括：数据输入单元、特征提取单元、特征融合单元及数据量化分析单元；S2.1、构建数据输入单元采用采用计算机语句自动读取步骤S1.4所构建的标准化影像精细解剖结构数据库中的二维图像及对应数据,数据输入单元将标准化精细解剖结构数据库中的二维图像转化为矩阵信息输入特征提取单元中；S2.2、构建特征提取单元采用以卷积神经网络主干作为特征提取单元,将步骤S2.1所述数据输入单元中的矩阵信息输入到卷积神经网络主干中,获得包含精细解剖结构量化信息特征图；S2.3、构建特征融合单元特征融合单元包括双线性池化层、梯度提升损失函数和/或全连接层,将步骤S2.2中所获得的精细解剖结构量化信息特征图输入到特征融合单元中进行特征融合及降维操作,确保重要特征不丢失；S2.4、构建数据量化分析单元采用softmax层作为数据量化分析单元：将步骤S2.3所获得融合特征输入到softmax层,softmax层将上述单元的输出映射到(0,1)区间,计算所选loss函数,获得不同类别的预测概率,通过给定阈值T,得到多个精细解剖结构的量化分析结果,包括定量化数据及半定量数据；S3、训练具备影像精细解剖结构量化分析能力的细粒度图像识别模块S3.1、构建精细解剖结构量化分析模块训练样本集投入步骤S2中所述的搭载细粒度图像识别网络的影像精细解剖结构量化分析模块进行训练及验证,构建影像精细解剖结构量化分析模块；S3.2、精细解剖结构量化分析模块性能评估将测试数据集输入步骤S3.1所述的影像精细解剖结构量化分析模块,评估输出的量化分析结果；S4、构建毫米-微米级别精细影像结构智能分析系统在步骤S3获得的影像精细解剖结构量化分析模块的基础上,构建毫米-微米级别精细影像结构智能分析系统。</td>   <td>G16H30/00;G06F16/51;G06F16/532;G16H50/20;G06V20/70;G06V10/82;G06V10/80;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余世孝;              乔雪婷;              黄子健;                   张娟娟       </td>   <td>中山大学深圳研究院</td>   <td>一种亚热带海洋岛屿遥感影像的植被类型识别方法</td>   <td>广东省</td>   <td>CN116246167A</td>   <td>2023-06-09</td>   <td>本发明公开了一种亚热带海洋岛屿遥感影像的植被类型识别方法,该方法包括以下步骤：获取亚热带海洋岛屿的遥感图像；构建亚热带海洋岛屿植物光谱信息库；基于计算机软件平台,将亚热带海洋岛屿的遥感影像与亚热带海洋岛屿植物光谱信息库进行比对,实现对岛屿植被类型的识别。本发明的方法能够准确、快速对亚热带海洋岛屿遥感影像的植被类型进行识别。</td>   <td>1.一种亚热带海洋岛屿遥感影像的植被类型识别方法,其包括以下步骤：(1)获取亚热带海洋岛屿的遥感图像；(2)构建亚热带海洋岛屿植物光谱信息库；(3)基于计算机软件平台,将所述亚热带海洋岛屿的遥感影像与所述亚热带海洋岛屿植物光谱信息库进行比对,实现对亚热带海洋岛屿植被类型的识别。</td>   <td>G06V20/10;G06V10/44</td>  </tr>        <tr>   <td>中国专利</td>   <td>         潘存雪;              王燕林;              陈剑;              张源;              秦培鑫;              鲁玲;              贾韬宇;                   扈锋       </td>   <td>中山大学附属第五医院</td>   <td>一种心肌局灶性瘢痕检测方法、风险预测方法和相关装置</td>   <td>广东省</td>   <td>CN116245878A</td>   <td>2023-06-09</td>   <td>本发明公开了一种心肌局灶性瘢痕检测方法、风险预测方法和相关装置,先基于预置左心室壁心肌自动分割模型对基于单能量CCTA或双能量CCTA扫描到的心肌图像进行体素二分类分割,得到左心室壁心肌图像,再基于预置心肌局灶性瘢痕定位模型对左心室壁心肌图像的低密度灶进行体素三分类分割,得到心肌局灶性瘢痕定位图像。解决了现有技术存在的操作技术难度大、检测耗时长、费用高、碘对比剂用量大和辐射剂量高的技术问题。</td>   <td>1.一种心肌局灶性瘢痕检测方法,其特征在于,包括：基于预置左心室壁心肌自动分割模型对基于单能量CCTA或双能量CCTA扫描到的心肌图像进行体素二分类分割,得到左心室壁心肌图像,其中,体素二分类分割结果包括左心室壁心肌组织和非左心室壁心肌组织；基于预置心肌局灶性瘢痕定位模型对左心室壁心肌图像的低密度灶进行体素三分类分割,得到心肌局灶性瘢痕定位图像,其中,体素三分类分割结果包括心肌局灶性瘢痕、心肌射线硬化伪影和正常心肌。</td>   <td>G06T7/00;G06T7/70;G06V10/26;G06V10/764;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任志凤;              刘建坤;              牛巍崴;                   张奕杭       </td>   <td>中山大学</td>   <td>一种超低温非饱和冻土导热系数预测方法及装置</td>   <td>广东省</td>   <td>CN116244920A</td>   <td>2023-06-09</td>   <td>本申请涉及一种超低温非饱和冻土导热系数预测方法及装置,其方法包括将冻土视为由土壤骨架、冰晶、未冻水、空气构成的四相复合材料；测量土壤骨架、冰晶、未冻水和空气的总体积占比；设置土壤骨架、冰晶、未冻水和空气的形状,定义冻土尺寸,逐次放置土壤骨架、冰晶、未冻水和空气的总体积份额,确定土壤骨架、冰晶、未冻水和空气的投放坐标,得到冻土四相模型；将冻土四相模型导入有限元仿真软件；设置冻土四相模型的导热的边界条件和初始温度条件,可视化生成冻土三维导热系数模型；基于冻土三维导热系数模型,结合传热公式,预测冻土导热系数。本申请具有低难度实现超低温非饱和冻土导热系数预测,预测速度更快,预测精度更高的效果。</td>   <td>1.一种超低温非饱和冻土导热系数预测方法,其特征在于,包括以下步骤,将冻土视为由土壤骨架、冰晶、未冻水、空气构成的四相复合材料；测量土壤骨架、冰晶、未冻水和空气的总体积占比；设置土壤骨架、冰晶、未冻水和空气的形状,定义冻土尺寸,逐次放置土壤骨架、冰晶、未冻水和空气的总体积份额,确定土壤骨架、冰晶、未冻水和空气的投放坐标,得到冻土四相模型；将所述冻土四相模型导入有限元仿真软件；设置所述冻土四相模型的导热的边界条件和初始温度条件,可视化生成冻土三维导热系数模型；基于所述冻土三维导热系数模型,结合传热公式,预测冻土导热系数。</td>   <td>G06F30/20;G06F119/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈剑辉;              方丛;              梁晓燕;              孙鹏;                   贾磊       </td>   <td>中山大学附属第六医院</td>   <td>一种卵母细胞的辅助收集方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN116246271A</td>   <td>2023-06-09</td>   <td>本申请公开了一种卵母细胞的辅助收集方法、装置、设备及介质,该方法在操作人员采集卵母细胞的过程中,获取操作人员使用的捡卵显微镜中显示的第一图像数据,基于第一图像数据,辅助判断当前视野内是否含有细胞团块,当发现存在细胞团块后,发出第一提示音指引操作人员关注细胞团块的图像内容。并且,还继续对细胞团块的图像数据进行进一步的识别检测,判断其中是否存在卵母细胞,并基于判断结果来提示操作人员进行相关作业。通过两阶段的检测判断,能够更好地提高卵母细胞的检测精度,帮助操作人员高效、准确地实现卵母细胞的收集,有利于减轻操作人员的工作负担。本申请可广泛应用于人工智能技术领域内。</td>   <td>1.一种卵母细胞的辅助收集方法,其特征在于,所述方法包括：获取捡卵显微镜中显示的第一图像数据；对所述第一图像数据进行图像识别处理,检测所述第一图像数据中是否包含细胞团块的图像内容；当确定所述第一图像数据中包括细胞团块的图像内容,输出第一提示音,并将所述细胞团块的图像内容确定为目标图像数据；所述第一提示音用于提醒操作人员关注所述目标图像数据；对所述目标图像数据进行图像识别处理,检测所述目标图像数据中是否包含卵母细胞的图像内容；当确定所述目标图像数据中包括卵母细胞的图像内容,输出第二提示音；所述第二提示音用于提醒所述操作人员对所述卵母细胞进行收集作业。</td>   <td>G06V20/69;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              魏兆基;              陈寒阳;                   郭珊珊       </td>   <td>中山大学</td>   <td>一种基于神经网络的水下视频鱼类识别方法</td>   <td>广东省</td>   <td>CN112418087B</td>   <td>2023-06-09</td>   <td>本发明为基于神经网络的水下视频鱼类识别方法,包括步骤：训练神经网络模型,模型包括依次连接的输入层、第一卷积层、第二卷积层、第三卷积层、最大池化层、全连接层和输出层,第一卷积层对输入层中的每个通道各有一层卷积层对不同通道的信息进行不同的特征提取后进行特征图融合,第二卷积层采用多重卷积的方法对不同尺度的目标提取到不同感受野的尺度,再进行特征图融合、批归一化处理；将水下视频数据中彩色图像的每个通道及其灰度图像作为模型的输入；模型输出多个目标定位框及其置信度,根据置信度进行目标筛除。该方法可以满足实时视频鱼类识别的要求的同时,降低对摄像机拍摄图像的质量要求。</td>   <td>1.一种基于神经网络的水下视频鱼类识别方法,其特征在于,包括以下步骤：(1)、训练神经网络模型；得到的神经网络模型包括依次连接的输入层、第一卷积层、第二卷积层、第三卷积层、最大池化层、全连接层和输出层,输入层针对每个输入图像的每个通道各有一个输入层输出到第一卷积层；第一卷积层针对输入层中的每个通道,各有一层卷积层对不同通道的信息进行不同的特征提取后,进行特征图融合,再输出到第二卷积层；第二卷积层采用多重卷积的方法对不同尺度的目标提取到不同感受野的尺度,然后进行特征图融合、批归一化处理,输出到第三卷积层；第三卷积层采用卷积权重复用的方法,进行下采样和特征提取,最后输出至最大池化层；(2)、将水下视频数据中彩色图像的每个通道及其灰度图像作为神经网络模型的输入数据；(3)、在神经网络模型的输出端输出多个目标定位框及其置信度,根据置信度进行目标筛除；步骤(1)中的训练包括：S11、对学习率进行微调；S12、输入当前帧图像的RGB三个通道以及灰度图通道,对这4个输入通道分别进行处理后再融合；S13、对于不同通道的输入设置不同的卷积核大小；S14、在训练时灰度图通道的输出权重高于RGB三个彩色图像通道的输出权重；S15、设置浅卷积层和深卷积层信息相融合的层；S16、使用视频抽帧训练。</td>   <td>G06V40/10;G06V20/40;G06V20/05;G06V10/82;G06N3/0464;G06N3/048;G06N3/096;G06T5/00;G06T7/11;G06T7/194</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              吴岸聪;              范志鸿;              庞恺;              胡建芳;              许昂驰;              李炫琪;              付盛豪;                   姚语涵       </td>   <td>中山大学;广州像素数据技术股份有限公司</td>   <td>实验仪器标准操作评分方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN116245405A</td>   <td>2023-06-09</td>   <td>本发明公开了一种实验仪器标准操作评分方法、系统、设备及存储介质,包括：标注待评分实验考试视频的数据并检测评分点,确定评分点；通过预先设立的YOLOX检测器检测关键物体与手部和预先设立的MediaPipe检测器检测手部姿态,得到YOLOX检测器与MediaPipe检测器的检测结果；对评分点内的动作和状态集构建有限状态机模型,依序检测应出现的状态或动作；根据评分点类别使用不同评分方案,对评分点进行正误判断,以获取评分点的每个操作的完成情况；根据评分方案,结合不同视角判断评分点每个操作的完成情况,对考试视频作出评分。本发明通过建立有限状态机模型,通过检测评分点标志来确定评分点的开始和结束,能对评分点进行准确的划分。</td>   <td>1.实验仪器标准操作评分方法,其特征在于,包括下述步骤：标注待评分实验考试视频的数据和检测评分点标志,并确定评分点；判断所述评分点的类别；所述评分点的类别包括物体呈现的状态、物体和物体间具有特定位置关系、考生的手部与物体具有特定位置关系以及考生执行序列动作；通过预先设立的YOLOX检测器检测关键物体与手部以及通过预先设立的MediaPipe检测器检测手部姿态,得到YOLOX检测器与MediaPipe检测器的检测结果；根据所述YOLOX检测器与MediaPipe检测器的检测结果以及所述评分点的类别,对每个评分点内的动作和状态集构建用来进行对象行为建模的有限状态机模型,依序检测应出现的状态或动作,并进行正误判断,以获取评分点每个操作的完成情况；结合不同视角判断评分点每个操作的完成情况,得到评分结果。</td>   <td>G06Q10/0639;G06Q50/20;G06V10/25;G06V40/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓楚富;              陈志广;              瞿毅力;              苏琬琪;                   卢宇彤       </td>   <td>中山大学</td>   <td>一种基于距离对抗生成网络的领域自适应方法及系统</td>   <td>广东省</td>   <td>CN111476771B</td>   <td>2023-06-09</td>   <td>本发明公开了一种基于距离对抗生成网络的领域自适应方法及系统,本发明方法包括获取目标域的医学图像x-T；将目标域的医学图像x-T输入预先训练好的距离对抗生成网络,通过距离对抗生成网络中的目标域转换器G-T将目标域的医学图像x-T投影成中间表示m-T；通过距离对抗生成网络中的分割器Seg对中间表示m-T进行分割得到分割图l-(T,f)；将得到的分割图l-(T,f)作为目标域的医学图像x-T的目标域分割标签输出。本发明能够解决不同医学图像模态的域自适应问题,使得在任意模态训练完成的数据集可以很好地运用在其他模态上,从而极大地提高医学图像处理模型的泛化能力,减轻图像处理模型对数据集的模态依赖。</td>   <td>1.一种基于距离对抗生成网络的领域自适应方法,其特征在于实施步骤包括：获取目标域的医学图像x-T；将目标域的医学图像x-T输入预先训练好的距离对抗生成网络,通过距离对抗生成网络中的目标域转换器G-T将目标域的医学图像x-T投影成中间表示m-T；通过距离对抗生成网络中的分割器Seg对中间表示m-T进行分割得到分割图l-(T,f)；将得到的分割图l-(T,f)作为目标域的医学图像x-T的目标域分割标签输出；所述距离对抗生成网络包括：转换器,包括将源域的医学图像x-S转换成到中间表示m-S的源域转换器G-S、将目标的医学图像x-T转换成到中间表示m-T的目标域转换器G-T以及鉴别器D,源域转换器G-S、目标域转换器G-T的目的使中间表示m-S与m-T的分布趋于一致,鉴别器D的输入为中间表示,它将中间表示m-S判别为真,将中间表示m-T判别为假；分割器Seg,用于对中间表示进行分割,所述分割器Seg它包括一个下采样路径和一个上采样路径,最终输出一个与源数据同样大小的分割图；切片预测器Predictor,用于信息建模,所述切片预测器Predictor为改进的双向LSTM,所述改进的双向LSTM是指利用两端的切片,对正向和反向的序列信息进行建模,完成对中间的切片进行预测；所述将目标域的医学图像x-T输入预先训练好的距离对抗生成网络之前包括训练距离对抗生成网络的步骤,所述训练距离对抗生成网络的步骤中包括训练源域转换器G-S和分割器Seg的步骤：A1)输入源数据集中的任意一张源域的医学图像x-S及其分割标签l-S；A2)利用源域转换器G-S将源域的医学图像x-S转换成到中间表示m-S；A3)将中间表示m-S输入分割器Seg得到分割图l-(S,f)；计算源域的医学图像x-S、中间表示m-S间的差值矩阵D-(slice)(x-S)、D-(slice)(m-S)；计算分割器Seg的分割损失loss-(seg)；A4)对分割损失loss-(seg)求导,反向传播计算出各层参数的梯度值,根据梯度值更新源域转换器G-S和分割器Seg的参数完成本轮迭代；A5)判断是否满足预设的迭代退出条件,如果满足预设的迭代退出条件则结束训练并退出,否则跳转执行步骤A1)进入下一轮迭代。</td>   <td>G06T7/00;G06T7/10;G06N3/0442;G06N3/045;G06N3/0475;G06N3/094;G06N3/084;G06N3/088</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张恺成;              陈泽林;                   郑伟诗       </td>   <td>中山大学</td>   <td>无监督的动作迁移和发现方法、系统、设备和介质</td>   <td>广东省</td>   <td>CN115861902B</td>   <td>2023-06-09</td>   <td>本发明公开了一种无监督的动作迁移和发现方法、系统、设备和介质,方法包括：获取无标签的目标数据集；构建分解动作流的卷积网络模型,对所有视频都做切片处理,用聚类算法计算出所有切片的聚类中心作为切片动作的伪标签,并以这些伪标签学习视频切片表达的分解动作；构建完整动作流的卷积网络模型,用聚类算法计算出所有完整视频的聚类中心作为视频动作的伪标签,并以这些伪标签学习完整视频表达的完整动作；分解动作流的卷积网络模型和完整动作流的卷积网络模型相互学习,使得模型能发现新的动作类型并学习到更精确的分解动作信息。本发明可以在无监督条件下完成动作识别任务,并利用迁移学习方法提高动作识别准确率和整体算法效率。</td>   <td>1.无监督的动作迁移和发现方法,其特征在于,包括下述步骤：获取无标签的目标数据集,所述目标数据集为采集到的视频；构建分解动作与完整动作双向学习MUSIC模型,所述MUSIC模型包括分解动作流的卷积网络模型和完整动作流的卷积网络模型；所述分解动作流的卷积网络模型是对所有视频都做切片处理,用聚类算法计算出所有切片的聚类中心作为切片动作的伪标签,并以这些伪标签学习视频切片表达的分解动作；所述完整动作流的卷积网络模型是用聚类算法计算出所有完整视频的聚类中心作为视频动作的伪标签,并以这些伪标签学习完整视频表达的完整动作；分解动作流的卷积网络模型和完整动作流的卷积网络模型相互学习,得到训练好的MUSIC模型；在相互学习过程中,给分解动作流和完整动作流之间添加完整性约束,使得完整动作的表达是由已被学习到的分解动作构造而成,并采用相似完整动作区分策略对相似性完整动作进行区分,所述相似完整动作区分策略是如果分解动作不同,则其所属的完整动作被划分到不同的类别中,最后引入分解动作对齐策略,使得分解动作流的卷积网络模型和完整动作流的卷积网络模型都学习共享的分解动作；所述分解动作流的卷积网络模型的动作学习包括分解动作流的聚类步骤和分解动作流的学习步骤；在分解动作流的聚类步骤中,提取全部视频切片的特征,并将全部视频切片的特征用聚类算法聚类成多个分解动作,得到分解动作特征集合A,所述分解动作特征集合A的提取方法如下所示：          ,          ,其中,N表示视频总数,是并集操作,/&gt;表示第/&gt;个视频的第/&gt;个切片所提取到的分解动作特征,/&gt;是第i个视频的第b帧到第b+l-1帧所构成的视频切片,/&gt;表示分解动作流的卷积网络模型,/&gt;表示分解动作流的卷积网络的参数,/&gt;表示切片长度,/&gt;是视频切片起始帧构成的集合,/&gt;表示每隔/&gt;帧对视频进行切片采样,/&gt;表示第/&gt;个视频的总帧数,则/&gt;表示一个视频的总切片数量；用聚类算法对分解动作特征集合A做聚类,得到所有切片分解动作的伪标签集合和聚类中心集合/&gt;,其中/&gt;表示第/&gt;个视频的第b个切片的伪标签,/&gt;表示第/&gt;个视频,/&gt;,N表示视频总数,/&gt;表示第b个切片,/&gt;表示一个视频的总切片数量,T-i表示第/&gt;个视频的总帧数,δ表示第δ帧,/&gt;表示第/&gt;个聚类的聚类中心特征,/&gt;表示分解动作聚类簇的下标序号,/&gt;表示分解动作聚类簇的总数；所述完整动作流的卷积网络模型的动作学习包括完整动作流的聚类步骤和完整动作流的学习步骤；在完整动作流的聚类步骤中,完整动作的特征提取如下：          ,          ,其中,表示第i个视频的完整特征,/&gt;是任何类型的聚合函数,/&gt;表示第i个视频第m个片段提取到的部分特征,/&gt;表示第m个视频片段的起始帧,/&gt;表示视频片段综述,是第i个视频的第/&gt;帧到第/&gt;帧构成的视频片段,l表示视频片段长度,示完整动作流的卷积网络,/&gt;是完整动作流卷积网络的参数,并令V表示所有视频的完整动作特征集合；用聚类算法对完整动作特征集合V做聚类,得到所有视频完整动作的伪标签集合,其中/&gt;表示第/&gt;个视频的伪标签,/&gt;表示第/&gt;个视频, /&gt;,N表示视频总数；所述分解动作对齐策略具体为：强制分解动作流和完整动作流学习共享的分解动作,通过最小化损失函数来对齐完整动作流中的分解动作/&gt;和分解动作流中的/&gt;,具体损失函数如下：          ,其中,是任何表示两个分布之间距离的函数,/&gt;表示分解动作/&gt;在完整动作流的分布,/&gt;表示分解动作/&gt;在分解动作流中的分布,考虑到计算的有效性和简便性,采用简化2-Wasserstein距离计算分布的损失函数/&gt;：          ,其中,表示期望,/&gt;表示方差；最终,MUSIC模型的学习步骤损失函数表达为：          ,其中,、/&gt;是分解动作流和完整动作流伪标签指导的分类损失函数,/&gt;是完整性约束损失函数,/&gt;是分解动作对齐损失函数,/&gt;和/&gt;是平衡各个损失的权重；所述完整性约束的实现如下：          ,          ,其中,表示完整特征对各个聚类簇的预测概率向量,/&gt;表示训练后得到的softmax参数且每次迭代重置；利用学习好的MUSIC模型在无监督条件下完成动作识别任务。</td>   <td>G06V20/40;G06V10/762;G06V10/82;G06N3/0464;G06N3/088;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨跃东;              邓幽扬;              宋颖;                   郑双佳       </td>   <td>中山大学</td>   <td>一种增强图神经网络点边交互的方法</td>   <td>广东省</td>   <td>CN111860768B</td>   <td>2023-06-09</td>   <td>本发明提供一种增强图神经网络点边交互的方法,步骤包括：获取有向分子图G及其图结构数据,根据图结构数据获取和根据所有创建所有根据所有所述与所有更新得到所有根据所有与所有所述创建所有根据所有所述和所有所述得到所有利用所有所有和所述图结构数据中的节点原始特征X-v,将所述图神经网络迭代至第K层,得到所述有向分子图的最终节点表示形式h(v),所述k≥1,K＞k；利用每个任意节点v的相邻节点w到任意节点v的边的隐藏表示,即创建任意节点v在第k层的消息向量使边的信息与节点信息进行关联和传递,在神经网络训练过程中更新了节点和边的嵌入,关注了节点与边之间信息的可传递性。</td>   <td>1.一种增强图神经网络点边交互的方法,其特征在于,步骤包括：获取应用对象的有向图G,提取所述有向图G的图结构数据,所述有向图G包括若干个节点v和若干条边e,所述节点v为所述应用对象中的任意元素,所述边e为所述应用对象中任意相连的两个元素之间的关联关系；根据所述图结构数据获取所有和所有/&gt;所述v表示所述所有节点中的任意一个节点,所述w表示所述节点v任意相邻节点,所述相邻节点为所述应用对象中与任意元素相连的任意元素,所述/&gt;为任意一条所述节点v到其任意相邻节点w的边e-(v,w)在第0层的隐藏表示,所述/&gt;为任意一个所述节点v在第0层的隐藏表示,任何所述边e隐藏表示为所述应用对象中任意相连的两个元素之间的关联关系在某一层的抽象化表示,任何所述节点v的隐藏表示为所述应用对象中任意元素在某一层的抽象化表示；根据所有创建所有/&gt;所述/&gt;为任意一条所述节点v的任意相邻节点w到节点v的边e-(w,v)在第k-1层的隐藏表示,所述/&gt;为所述节点v在第k层的消息向量,任何所述节点v的消息向量为所述应用对象中任意元素在某一层所接收到的信息；根据所有所述与所有/&gt;更新得到所有/&gt;所述/&gt;为所述节点v在第k-1层的隐藏表示,所述/&gt;为所述节点v在第k层的隐藏表示；根据所有所述与所有所述/&gt;创建所有/&gt;根据所有所述/&gt;和所有所述/&gt;得到所有/&gt;所述/&gt;为任意一条所述节点v到其任意相邻节点w的边e-(v,w)在第k层的消息向量,所述/&gt;为任意一条所述节点v到其任意相邻节点w的边e-(v,w)在第k层的隐藏表示；任何所述边e的消息向量为所述应用对象中任意相连的两个元素之间的关联关系在某一层所接收到的信息；利用所有所述所有所述/&gt;和所述图结构数据中的节点原始特征X-v,将所述图神经网络迭代至第K层,得到所述有向图G的最终节点表示形式h(v),所述节点原始特征X-v为所提取的所述应用对象的任意元素的原始特征,所述最终节点表示形式为所述元素的核心特征；所述k≥1,K＞k。</td>   <td>G06N3/0499;G06N3/08;G06F18/24;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              余浩强;              吴箫;                   林鹏       </td>   <td>中山大学;广东海启星海洋科技有限公司</td>   <td>一种基于IoU的水下多目标跟踪方法</td>   <td>广东省</td>   <td>CN110796678B</td>   <td>2023-06-09</td>   <td>本发明涉及计算机视觉和水下目标跟踪技术,为基于IoU的水下多目标跟踪方法,获取水下感兴趣目标的数据集；训练并获得收敛的目标检测模型；对输入的当前图像帧进行图像增强；使用训练好的目标检测模型对增强后的图像帧进行目标检测,得到该帧的所有检测框信息和检测得分；通过场景拥挤检测算法,自适应调整目标检测的得分阈值,筛选部分检测目标,对检测目标集合划分为高、低得分检测目标集合；计算各检测目标与各运动轨迹之间的IoU得分,对检测目标与运动轨迹进行分集匹配；根据匹配结果对所有检测目标与运动轨迹进行状态转移处理,以保持检测目标ID的一致性。本发明可自适应调整检测目标的得分阈值,能有效地提高水下多目标跟踪的实时性。</td>   <td>1.一种基于IoU的水下多目标跟踪方法,其特征在于,包括以下步骤：S1、获取水下感兴趣目标的数据集,进行图像预处理、图像增强；S2、将数据集划分为训练集、测试集与验证集,训练并获得收敛的目标检测模型；S3、对输入的当前图像帧进行图像增强；S4、使用训练好的目标检测模型对S3进行增强后的图像帧进行目标检测,得到该帧的所有检测框信息和该帧的检测得分；S5、通过场景拥挤检测算法,自适应调整目标检测的得分阈值,筛选部分检测目标,同时根据检测得分对检测目标集合划分为高、低得分检测目标集合；S6、计算各检测目标与各运动轨迹之间的IoU得分；S7、根据IoU得分,对检测目标与运动轨迹进行分集匹配；S8、根据步骤S7的匹配结果对所有检测目标与运动轨迹进行状态转移处理,以保持检测目标ID的一致性；步骤S1、S3中使用基于加权L1正则化的水下图像清晰化算法来进行图像增强；步骤S5中场景拥挤检测算法对第t帧的场景拥挤检测计算公式为：                  其中,ρ-d表示检测得分阈值,α表示预设得分阈值偏移值,num-r表示检测框与轨迹框发生重叠的个数,num表示检测框总数,β表示预设的最低检测框总数值；步骤S6中计算各检测目标与各运动轨迹之间的IoU得分时,计算第t帧的检测目标d与运动轨迹k之间的IoU的公式为：                  其中,S-(d∩k)和S-(d∪k)分别表示检测目标d这一检测框与运动轨迹k这一轨迹框之间的相交区域面积和并集区域面积,D和K分别表示检测目标总集合与运动轨迹集合；计算得到当前帧每个检测目标-运动轨迹对的IoU,排列成一个IoU矩阵,横坐标对应检测目标序号,纵坐标对应运动轨迹序号。</td>   <td>G06T7/20;G06V10/75;G01C11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温木奇;              谢明森;              黄国燕;                   万海       </td>   <td>中山大学;广州云晫信息科技有限公司</td>   <td>一种教育云平台中的大数据任务调度方法</td>   <td>广东省</td>   <td>CN109947532B</td>   <td>2023-06-09</td>   <td>本发明为教育云平台中的大数据任务调度方法,根据云平台总体资源、核心大数据处理任务优先级及其资源需求量、预期任务运行时间进行任务调度；若任务请求不是大数据任务,直接调度任务；若是核心任务则预测系统资源及运行时间；根据各项任务参数在数据库中添加相应的任务实例；根据调度方法将任务添加到任务队列中,获取运行优先级最高的任务；当云平台资源满足任务资源需求时按需分配资源,若当前使用资源未超过最大可用资源将任务分发到相应受培训者的大数据集群中；否则重新添加到任务队列中。能防止过多用户同时通过其已获得分配的虚拟机集群高并发运行大数据任务,从而支持机构利用有限物理机资源为每个受培训者提供有效的大数据实验环境。</td>   <td>1.一种教育云平台中的大数据任务调度方法,其特征在于,大数据任务调度方法运行在基于云计算技术的教育云平台,根据云平台的总体资源、核心大数据处理任务优先级及其资源需求量、预期任务运行时间进行任务调度；所述任务调度步骤包括：1)受培训者提交任务；2)系统自动拦截任务请求,并判断任务是否为大数据任务；若不是大数据任务,系统直接调度任务；否则,进入下一步骤；3)判断任务是否为教师建议的核心任务,若是核心任务,则预测核心任务需要的系统资源及运行时间；否则,将任务的运行优先级设为最低；4)根据任务代码、数据源、任务名称、任务运行参数,在数据库中添加相应的任务实例；5)根据调度方法将任务添加到任务队列中；6)根据调度方法从任务队列中获取运行优先级最高的任务；7)当云平台的资源满足任务的资源需求时,进入下一步骤；否则,将任务重新添加到任务队列中；8)按任务的资源需求分配资源后,如果用户当前使用的资源没有超过用户最大可用资源时,将任务分发到相应受培训者的大数据集群中；否则,将任务重新添加到任务队列中；所述核心任务需要的系统资源以及运行时间的预测,采用以下算法实现：S31：教师试运行实验的核心任务,系统记录每个核心任务所需的系统资源及运行时间；S32：受培训者运行实验时,如果其运行的核心任务j匹配教师建议的核心任务,则任务j在第i次运行需要的资源和运行时间分别为R-j(i-1)和T-j(i-1)；如果任务j在第i次成功运行且云平台检测到任务j所需系统资源为r-(ji)、运行时间为t-(ji),则将任务j的预测资源需求量及运行时间分别更新为：R-j(i)＝aR-j(i-1)+(1-a)r-(ji)T-j(i)＝bT-j(i-1)+(1-b)t-(ji)其中R-j(i)和T-j(i)分别表示核心任务j在第i次运行后的预测资源需求量与运行时间,R-j(0)和T-j(0)分别表示系统仅依据教师运行核心任务的历史信息预测任务j需要的系统资源以及运行时间；a和b均为取值在(0,1)区间的可预设的常量；如果任务j未能匹配教师建议的核心任务,则其运行需要的资源与运行时间未知,运行优先级为最低。</td>   <td>G06F9/455;G06F9/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              姬进财;              潘广维;                   杨清书       </td>   <td>中山大学</td>   <td>海洋锋区域的获取方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN111860146B</td>   <td>2023-06-09</td>   <td>本申请涉及一种海洋锋区域的获取方法、装置、计算机设备和存储介质。所述方法包括：根据获取的卫星遥感观测资料确定粗估计海洋锋区域、多个无人舰艇到达粗估计海洋锋区域的目标路径和沿所述目标路径到达粗估计海洋锋区域的目标时长；根据接收到的各个无人舰艇到达粗估计海洋锋区域时发送的确认到达信息,确定各个无人舰艇在粗估计海洋锋区域的各个初始位置；根据目标时长内接收到的多组卫星遥感观测资料确定的粗估计海洋锋区域的区域变化信息输出调整指令,以指示各无人舰艇基于各自对应的初始位置进行调整,得到每个无人舰艇的调整后位置；根据接收到的各个调整后位置,确定目标海洋锋区域。采用本方法能够提高海域中海洋锋区域的识别准确度。</td>   <td>1.一种海洋锋区域的获取方法,其特征在于,所述方法包括：获取卫星遥感观测资料,并根据所述卫星遥感观测资料确定粗估计海洋锋区域；其中,所述卫星遥感观测资料包括待识别海域的水色值、温度值、盐度值、叶绿素浓度值以及悬浮泥沙浓度值中的至少一个；根据所述卫星遥感观测资料,确定拟派出的多个无人舰艇到达所述粗估计海洋锋区域的目标路径以及沿所述目标路径到达所述粗估计海洋锋区域的目标时长；其中,所述目标路径用于表征所述多个无人舰艇到达所述粗估计海洋锋区域的最短路径；根据接收到的各个无人舰艇到达所述粗估计海洋锋区域时发送的确认到达信息,确定各个无人舰艇在所述粗估计海洋锋区域的各个初始位置；根据所述目标时长内接收到的多组卫星遥感观测资料,确定所述粗估计海洋锋区域的区域变化信息；根据所述区域变化信息输出调整指令,以指示各所述无人舰艇基于各自对应的初始位置进行调整,得到每个所述无人舰艇的调整后位置；根据接收到的各个所述调整后位置,确定目标海洋锋区域；所述根据所述目标时长内接收到的多组卫星遥感观测资料,确定所述粗估计海洋锋区域的区域变化信息,包括：获取所述目标时长内不同时刻的多组卫星遥感观测资料；根据所述多组卫星遥感观测资料,确定多个粗估计海洋锋区域；对所述多个粗估计海洋锋区域按照所述多个不同时刻进行插值拟合处理,得到所述区域变化信息；所述根据所述卫星遥感观测资料,确定拟派出的多个无人舰艇到达所述粗估计海洋锋区域的目标路径以及沿所述目标路径到达所述粗估计海洋锋区域的目标时长,包括：根据所述卫星遥感观测资料,确定所述粗估计海洋锋区域的面积估计值和锋面线长度；根据所述面积估计值和所述锋面线长度的第一比值结果,确定拟派出的无人舰艇数量；确定每个所述无人舰艇与所述粗估计海洋锋区域的每个预设顶点位置之间的多个直线距离,并选取每个所述无人舰艇对应的多个直线距离中最小的一个直线距离作为所述无人舰艇到达所述粗估计海洋锋区域的目标路径；获取所述多个无人舰艇的最大时速,并将所述无人舰艇到达所述粗估计海洋锋区域的目标路径与所述最大时速的第二比值结果,作为所述目标时长。</td>   <td>G06V20/13;G06V10/40;G06V10/764;G06V10/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄泽腾;              周檬;              由林麟;                   刘晟       </td>   <td>中山大学</td>   <td>一种基于联邦学习的车辆行程时间估计方法</td>   <td>广东省</td>   <td>CN116245171A</td>   <td>2023-06-09</td>   <td>本发明公开了一种基于联邦学习的车辆行程时间估计方法,方法包括：对机动车数据进行处理,获取用户行驶特征数据集；根据模型的数据输入要求,将用户行驶特征数据集输入本地模型进行单轮联邦学习训练生成本地模型权重,并计算本地模型神经网络层和全局模型神经网络层的皮尔森相关系数,将皮尔森相关系数大的本地模型神经网络层上传至联邦学习云端服务器；将本地模型权重和全局模型权重按比例加权得到新一轮的全局模型权重；将全局模型权重发送给参与本轮联邦学习的用户对应的本地模型更新本地模型权重,得到最终的本地模型；将待评估数据输入本地模型进行车辆行程时间估计,得到评估结果。本发明安全且高效,可广泛应用于智能交通系统技术领域。</td>   <td>1.一种基于联邦学习的车辆行程时间估计方法,其特征在于,包括：对机动车数据进行处理,获取用户行驶特征数据集；根据模型的数据输入要求,将所述用户行驶特征数据集输入本地模型；通过所述本地模型进行单轮联邦学习训练生成本地模型权重,并计算本地模型神经网络层和全局模型神经网络层的皮尔森相关系数,将皮尔森相关系数大的本地模型神经网络层上传至联邦学习云端服务器；将本地模型权重和全局模型权重按比例加权得到新一轮的全局模型权重；将所述全局模型权重发送给参与本轮联邦学习的用户对应的本地模型,所述本地模型根据所述全局模型权重更新本地模型权重,训练得到最终的本地模型；将待评估数据输入所述本地模型进行车辆行程时间估计,得到评估结果。</td>   <td>G06N3/098;G08G1/01;G06N3/044;G06N20/20;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         倪芃芃;              叶明鸽;              林存刚;              覃小纲;              刘凯文;                   高军       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种基于Timoshenko梁模型的管道受滑坡影响计算方法</td>   <td>广东省</td>   <td>CN116244978A</td>   <td>2023-06-09</td>   <td>本发明公开了一种基于T imoshenko梁模型的管道受滑坡影响计算方法,包括S1：对管道纵向进行受力分析并任取长度单元变形微分方程,S2：对于S1变形后的微分方程进行T imoshenko梁模型变形分析,S3：划分S2变形后得到的微分方程的求解域以此代替连续求解域,利用有限差分法附加边界条件进行变形分析；该基于T imoshenko梁模型的管道受滑坡影响计算方法,通过考虑滑坡土体的扰动,将滑坡土体对管道作用力进行一定折减,解决了在滑坡对管道影响研究中,现有Eu l er-Bernou l l i梁理论在分析过程中不能够考虑到梁在变形过程中的剪切变形影响,因此存在一定的不足的问题和目前也没有任何采用理论计算的方法计算滑坡土体对管道的影响,无法计算出管道受滑坡影响的挠度、弯矩和剪力等指标的问题。</td>   <td>1.一种基于Timoshenko梁模型的管道受滑坡影响计算方法,其特征在于,具体计算步骤包括：S1：对管道纵向进行受力分析并任取长度单元变形微分方程；S2：对于S1变形后的微分方程进行Timoshenko梁模型变形分析；S3：划分S2变形后得到的微分方程的求解域以此代替连续求解域,利用有限差分法附加边界条件进行变形分析。</td>   <td>G06F30/23;G06F119/14;G06F113/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              刘劲;                   林倞       </td>   <td>中山大学</td>   <td>基于深度学习的弱监督视频时序动作定位的方法及系统</td>   <td>广东省</td>   <td>CN111079646B</td>   <td>2023-06-06</td>   <td>本发明公开了一种基于深度学习的弱监督视频时序动作定位方法及系统,该方法包括：S1,提取视频中当前帧及前一帧,利用光流估算网络提取光流,并连同等间隔对视频采样的帧输入双流动作识别网络提取视频特征；S2,将视频特征进行语义一致性建模,获得嵌入特征；S3,训练分类模块将嵌入特征映射到类激活序列；S4,采用注意力模块更新视频特征；S5,将更新后的视频特征作为下一次循环的输入,重复S2-S4直到停止；S6,将每次循环产生的类激活序列融合,计算估计的动作类别与真实类别标签的分类损失；S7,将每次循环的嵌入特征融合计算动作特征间的相似性损失；S8,根据分类损失及相似性损失得到目标损失,更新系统模型参数。</td>   <td>1.一种基于深度学习的弱监督视频时序动作定位方法,包括如下步骤：步骤S1,提取视频的当前帧以及其前一帧,利用光流估算网络提取光流,并连同等间隔对视频采样的帧输入预训练的双流动作识别网络,提取视频特征；步骤S2,将提取的视频特征通过循环神经网络进行语义一致性建模,获得所述视频特征的嵌入表示；步骤S3,训练分类模块将步骤S2获得的嵌入特征映射到类激活序列；步骤S4,采用基于嵌入特征的注意力模块根据步骤S2获得的嵌入特征得到视频时间维度的注意力分布,并使用所述注意力分布更新视频特征；步骤S5,将更新后的视频特征作为下一次循环的输入,重复步骤S2-S4的训练过程,直到符合停止条件；步骤S6,将每次循环产生的类激活序列进行融合,进而解析生成时序动作定位结果和估计的动作类别,计算估计的动作类别与真实动作类别标签的分类损失；步骤S7,将每次循环的嵌入特征进行融合,计算视频动作特征间的相似性损失；步骤S8,将分类损失及相似性损失按权相加,得到目标损失,更新系统的模型参数。</td>   <td>G06V20/40;G06V40/20;G06V10/764;G06V10/82;G06N3/0464;G06N3/0442;G06N3/048;G06N3/0895</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   宋菁       </td>   <td>中山大学</td>   <td>基于会话的并行推荐方法及系统</td>   <td>广东省</td>   <td>CN111259243B</td>   <td>2023-06-06</td>   <td>本申请公开了一种基于会话的并行推荐方法及系统,所述方法包括：将用户在当前会话中的已点击项目序列输入可并行处理序列的切片神经网络并将输出的隐藏状态作为用户序列行为特征；利用注意力机制计算用户对已点击项目的注意力权重,由此计算用户的长期兴趣,进而结合用户的短期兴趣获取其主要意图；计算每个项目与用户的主要意图之间的相似度从而获得用户对每个项目的下一次点击概率,据此进行推荐。本申请通过并行处理序列大量减少系统的运行时间,并提升推荐准确性。</td>   <td>1.一种基于会话的并行推荐方法,其特征在于,包括：接收用户在当前会话中的已点击项目序列；将所述已点击项目序列的嵌入向量输入切片神经网络中,通过切片神经网络将所述嵌入向量分割成多个长度相等的子序列来实现并行化,并将切片神经网络最后输出的隐藏状态作为用户序列行为特征；结合用户序列行为特征、各个已点击项目的点击频率和各个已点击项目的嵌入向量,利用注意力机制来计算用户对在各个时间戳点击的项目的注意力权重,并基于注意力权重和已点击项目序列的嵌入向量计算用户的长期兴趣；将用户最后一次点击的项目的嵌入向量作为用户的短期兴趣；结合用户的长期兴趣和短期兴趣,利用多层感知机制来获取用户的主要意图；计算项目字典里每个项目的嵌入向量与用户的主要意图之间的相似度,对所有相似度进行归一化后获得用户对于项目字典里每个项目的下一次点击概率；对点击概率列表进行排序,并根据点击概率列表向用户推荐项目；所述通过切片神经网络将所述嵌入向量分割成多个长度相等的子序列来实现并行化,包括：对于已点击项目序列的嵌入向量X-T＝[x-1,x-2,…,x-T],令每次切割的切片数量为n,共切割k次,则首先X-T被切割成n个长度相等的子序列：X-T＝[N-1,N-2,…,N-n],其中第i(1≤i≤n)个子序列T表示时间戳；再如此切割k-1次,直到得到第0层的最小子序列,则最小子序列的长度/&gt;数量为n～k个；从第1层开始,每一层的子序列都由下一层每n个子序列通过带有GRU的标准循环神经网络后的最后一个输出的隐藏状态构成的序列组成；所述结合用户序列行为特征、各个已点击项目的点击频率和各个已点击项目的嵌入向量,利用注意力机制来计算用户对在各个时间戳点击的项目的注意力权重,包括：所述注意力机制为单层神经网络模型,在注意力机制中通过以下计算获得注意力权重：                  其中α-(iT)表示第i时刻的注意力权重,是sigmoid函数,h是用户序列行为特征；W-(α0)∈R～(1×d)是权重向量,W-(α1),W-(α2)∈R～(d×d)是权重矩阵,b-α,W-(α3)∈R～d是偏置向量,d是已点击项目的嵌入向量维度,T表示时间戳,f-i表示第i时刻已点击项目在当前会话中的点击频率,x-i表示第i时刻已点击项目序列的嵌入向量。</td>   <td>G06F16/9535;G06N3/0442;G06N3/0455;G06N3/048;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              康丹青;              吴凯;                   朱俊勇       </td>   <td>中山大学</td>   <td>一种基于多任务学习的表面缺陷检测方法</td>   <td>广东省</td>   <td>CN111696079B</td>   <td>2023-06-06</td>   <td>本发明公开了一种基于多任务学习的表面缺陷检测方法,包括：获取具有标注信息的输入图像并将输入图像分为训练集图像和测试集图像；对训练集图像进行剪切,得到缺陷实例并对缺陷实例进行增强,得到增强图像；构建表面缺陷检测网络并将测试集图像和增强图像输入表面缺陷检测网络,得到表面缺陷数据。通过使用本发明,可解决缺陷样本不足问题的同时提高工业缺陷检测的速度和精度。本发明作为一种基于多任务学习的表面缺陷检测方法,可广泛应用于工业视觉缺陷检测领域。</td>   <td>1.一种基于多任务学习的表面缺陷检测方法,其特征在于,包括以下步骤：获取具有标注信息的输入图像并将输入图像分为训练集图像和测试集图像；对训练集图像进行剪切,得到缺陷实例并对缺陷实例进行增强,得到增强图像；构建表面缺陷检测网络并将测试集图像和增强图像输入表面缺陷检测网络,得到表面缺陷数据；所述对训练集图像进行剪切,得到缺陷实例并对缺陷实例进行增强,得到增强图像这一步骤,其具体还包括；根据标注信息对训练集图像进行剪切得到缺陷实例,并修复剪切后的训练集图像,得到修复图像；根据标注信息得到缺陷实例的蒙版标注并对其执行膨胀操作,得到缺陷实例的多个相邻区域；计算缺陷实例被放置在修复图像不同位置时的相邻区域和原始位置相邻区域之间的相似度,得到缺陷实例在修复图像上的环境相似性热力图；将环境相似性热力图标准化得到位置选择概率图,并根据位置选择概率图选定缺陷实例粘贴的目标位置；将缺陷实例随机缩放并旋转后平移粘贴到目标位置,得到合成图像；对合成图像进行整体增强,得到增强图像；所述修复剪切后的训练集图像具体采用高斯白噪声填充来修复剪切后的训练集图像,所述环境相似性热力图具体采用以下公式计算；                  其中,D(x′,y′)为环境相似性热力图,r-i(x,y)和r′-i(x′,y′)分别为缺陷实例在原始位置(x,y)和目标位置(x′,y′)的第i个相邻区域C-i(x,y)和C′-i(x′,y′)上的像素的RGB值,g(·)为相似性的度量函数,n为距离缺陷实例不同远近程度的相邻区域的个数,ω-i为对应第i个相邻区域的加权因子；所述加权因子ω以下式设置；                  其中,ω-1对应距离缺陷实例最近的第1个相邻区域,所述ω-n对应距离缺陷实例最远的第n个相邻区域；所述位置选择概率图通过下式计算获得；                  其中,I表示用于计算环境相似性热力图的图像,(x′,y′)为图像上任意一个目标位置,γ为任一合适的正实数。</td>   <td>G06T7/00;G06T7/11;G06T5/00;G06V10/774;G06V10/74;G06V10/764;G01N21/88</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄伟浩;              郑伟诗;                   庞景龙       </td>   <td>中山大学</td>   <td>基于自动数据增强的域泛化行人重识别方法、系统及介质</td>   <td>广东省</td>   <td>CN113033410B</td>   <td>2023-06-06</td>   <td>本发明公开了一种基于自动数据增强的域泛化行人重识别方法、系统及介质,该方法包括：定义数据增强策略,并构建数据增强策略算法以得到最终输出的数据增强策略在源域训练集上应用重新训练行人重识别模型；应用训练好的行人重识别模型进行行人匹配。本发明采用了一种针对域泛化行人重识别问题的数据增强策略搜索算法搜索出一组复杂的数据增强策略,多样性强,可提升行人重识别模型在未知场景下的稳定性和鲁棒性,有利于推进行人重识别技术落地。另外,本发明在数据增强策略搜索过程中采用了TPE算法调优数据增强策略,相比普通数据增强操作进一步提升模型的泛化能力,策略搜索时不需要重复训练行人重识别模型,提升了搜索效率。</td>   <td>1.基于自动数据增强的域泛化行人重识别方法,其特征在于,包括下述步骤：定义数据增强策略,并构建数据增强策略算法以得到最终输出的数据增强策略 ,具体为：采样子数据集,所述采样子数据集具体为：从源域训练数据集/&gt;采样成/&gt;个子数据集/&gt;,每个子数据集/&gt;内部划分成训练集/&gt;和验证集/&gt;,/&gt;；其中,子数据集/&gt;内部的训练集摄像机集合/&gt;和验证集摄像机集合/&gt;的交集为空,/&gt;=1、2…/&gt;；令初始输出的数据增强策略/&gt;为空；在每个子数据集内通过数据增强策略算法搜索数据增强策略,并将搜索到的数据增强策略补充至/&gt;；所述在每个子数据集内通过数据增强策略算法搜索数据增强策略,并将搜索到的数据增强策略补充至具体为：令子数据集内搜索的数据增强策略/&gt;为空；使用子数据集的训练集/&gt;训练行人重识别模型/&gt;；重复本步骤次：通过贝叶斯优化方法搜索一组候选数据增强策略/&gt;,令/&gt;；从这一组候选数据增强策略选取验证集上损失最小的n个数据增强策略,并将这些数据增强策略的子策略添加到/&gt;,/&gt;为预设次数；将的子策略加入到最终输出的数据增强策略/&gt;中；所述通过贝叶斯优化方法搜索一组候选数据增强策略具体为：采样一组子策略构造成一个候选数据增强策略,/&gt;为子策略数量,将对应的调用概率/&gt;和对应的增强幅度/&gt;设置为行人重识别模型/&gt;的数据增强策略超参数,在验证集/&gt;上,使用TPE算法对所述数据增强策略超参数进行优化,最小化行人重识别模型/&gt;在验证集/&gt;上的损失/&gt;,以搜索一组使损失最小的数据增强策略,其中,优化时只需用行人重识别模型/&gt;计算损失,不涉及训练过程；重复上述通过贝叶斯优化方法搜索一组候选数据增强策略所包括的具体步骤B次,B为预设次数；在源域训练集上应用重新训练行人重识别模型,具体为：对源域训练集进行采样；应用/&gt;生成输入数据并输入行人重识别模型；使用损失函数优化行人重识别模型；所述行人重识别模型以残差网络ResNet50为主干网络,主干网络输出一个高维向量作为判别特征,训练网络时,判别特征输入到分类器以计算损失函数并通过反向传播更新参数,实际应用时,判别特征用于计算行人图片间的相似度；在源域训练集上应用输出的数据增强策略重新训练行人重识别模型具体为：从源域训练集随机采样若干张行人图片；应用数据增强策略生成输入数据：从数据增强策略/&gt;中随机选取一个子策略,依序在采样的样本上应用子策略中的数据增强操作,生成训练网络的输入数据,并输入至行人重识别模型/&gt;；计算损失并使用随机梯度下降法更新模型参数；重复上述在源域训练集上应用输出的数据增强策略重新训练行人重识别模型所包括的具体步骤,直到损失收敛,得到训练好的行人重识别模型；应用训练好的行人重识别模型,以行人图像判别特征间的欧氏距离作为相似度进行行人匹配。</td>   <td>G06V40/10;G06V10/84;G06V10/74;G06V10/774;G06V10/82;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         万海;              陈灏;              罗炜麟;              曾娟;                   黄佳莉       </td>   <td>中山大学</td>   <td>一种基于触发式规则的反馈式对话意图获取方法</td>   <td>广东省</td>   <td>CN113590780B</td>   <td>2023-06-06</td>   <td>本发明提供一种基于触发式规则的反馈式对话意图获取方法,该方法使用Node2Vec对游戏中的环境背景条件进行图嵌入编码,在为NPC进行对话生成时,可以应用当前环境背景条件对应的环境知识特征向量K,作为被纳入考虑的输入之一,以此来结合触发式规则,并根据分析的反馈意图标签生成输出对话。这会让游戏NPC与游戏环境之间的联系更加密切；本发明基于Seq2Seq结构,对环境知识特征向量K和玩家输入语义向量H-(in)进行整合,得到输出语义向量H-(out),并将其解码为NPC的输出语句U-(out)。这种生成对话的方式能避免NPC对玩家产生重复无效的反馈,增加玩家在与NPC接触时获得的新鲜感。</td>   <td>1.一种基于触发式规则的反馈式对话意图获取方法,其特征在于,包括以下步骤：S1：构建数据集；S2：利用步骤S1得到的数据构建模型；S3：对步骤S2构建的模型进行训练；S4：利用步骤S3训练好的模型生成系统对话；所述步骤S1的具体过程是：S11：构建游戏环境条件图：数据标注员需要为每个知识定义一个结点,对于存在联系的条件结点对,数据标注员需要手工用一条带权边将其连结起来,以揭示它们之间存在的关系；S12：构建语义文本数据集：如果采用游戏中预设的对话语料库,则游戏开发者需要预先准备好该预设对话库,无论是采用游戏预设的对话语料库,还是现有大型对话相关语料库,训练的过程都是根据输入的对话来生成输出的对话,数据标注员需要对语料库进行处理操作,揭示语句之间的上下文关系；设原语料库中的某一段文本由语句{u-1,u-2,u-3,...u-n}组成,则数据标注员先对这些语句进行预处理操作,得到预处理完毕后的语句序列{μ-1,μ-2,μ-3,...,μ-n},然后提取其中存在的对话对{μ-i,μ-j},作为一条数据,其中1≤i&lt;j≤n,重复进行此操作以构建语义文本数据集；所述步骤S2的具体过程是：S21：图嵌入编码模型构建：图嵌入编码模型拟采用Node2Vec技术,将NPC对话依赖的背景条件集合{g-1,g-2,g-3,...}编码为对应的图嵌入特征向量{k-1,k-2,k-3,...},随后将其整合为环境知识特征向量K；S22：语义编码模型构建：语义编码模型拟采用BERT+GRU Encoder结构,将输入语句U-(in)编码成输入语义特征向量H-(in)；S23：特征分析器模型构建：特征分析器对知识特征向量K和输入语义特征向量H-(in)进行分析,得到输出语义特征向量H-(out)；S24：特征解码模型构建：特征解码模型拟采用GRU Decoder架构,转化输出语义特征向量H-(out)为最终的输出语句U-(out)；所述步骤S3的具体过程是：S31：图嵌入模型训练：基于游戏环境条件图来训练图嵌入模型,得到合适的能将环境背景条件映射到固定维数向量空间的图嵌入编码模型,在该图嵌入模型训练阶段,先单独对图嵌入Node2Vec模型进行训练,设f(u)为当前游戏触发式规则节点,N-s(u)为在方法s下采样得到的邻居规则节点,则图嵌入模型的损失函数可定义为S32：语义编码/解码模型训练：固定图嵌入编码模型,基于预设对话语料库对输入语义编码模型、特征分析器、输出语义解码模型组合而成的文本生成模型进行端到端训练,在该语义编码/解码模型训练阶段,不再针对于图嵌入模型进行反向传播,而是对输入语义编码模型、特征分析器、输出语义解码模型组合而成的文本生成模型进行端到端训练,设u-(in)为输入样本,a为模型输出序列,为y真实输出序列,则语义编码/解码模型的损失函数可定义为/&gt;所述步骤S4的具体过程是：S41：玩家选择输入语句：在游戏中,玩家传递给NPC的语句通常并不是由玩家自己手动逐字生成,而是在游戏开发者为其提供的选项中作出选择,当玩家选择了某一条输入之后,该输入语句会送到系统模型中；S42：模型进行输出语句生成：训练好的模型通过分析玩家的输入语句,并结合当前游戏环境条件对应的环境知识特征,生成输出语句文本；S43：NPC表述生成语句：NPC对于生成语句的表述方式取决于游戏开发者的设定,是在电脑屏幕前直接为玩家展示NPC的反馈语句,结合字幕和语音模拟的方式来进行表述,后者消耗更多的运算资源。</td>   <td>G06F16/332;G06F16/33;G06F16/36;G06F40/30;A63F13/60;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张亚慧;              伍贵富;              宋代远;              杨迪朗;              张晓东;              陈怡锡;              麦周明;              陈子奇;                   魏文斌       </td>   <td>中山大学附属第八医院(深圳福田)</td>   <td>一种血流频谱信号分类方法及系统</td>   <td>广东省</td>   <td>CN113724208B</td>   <td>2023-06-06</td>   <td>本发明公开了一种血流频谱信号分类方法及系统,该方法包括：S1、采集动脉血管超声图像并提取动脉血流频谱变化曲线；S2、根据动脉血流频谱变化曲线建立血流速度频谱的ARX传递函数；S3、对血流速度频谱的ARX传递函数进行拟合分析,得到传递函数特征；S4、采用SVM分类器对传递函数特征进行处理,完成血流频谱信号分类。该系统包括：频谱曲线提取模块、传递函数构建模块、特征计算模块和分类模块。通过使用本发明,实现对信号的准确分类。本发明作为一种血流频谱信号分类方法及系统,可广泛应用于信号分类领域。</td>   <td>1.一种血流频谱信号分类方法,其特征在于,包括以下步骤：S1、采集动脉血管超声图像并提取动脉血流频谱变化曲线；所述采集动脉血管超声图像并提取动脉血流频谱变化曲线这一步骤,其具体包括；S11、采集颈动脉血管超声图像和肱动脉血管超声图像；S12、对颈动脉血管超声图像进行干扰因素剔除处理、二值化处理、空洞填补处理和Sobel算子边缘检测处理,得到第一Sobel梯度图像；S13、对第一Sobel梯度图像进行提取处理,得到颈动脉血流频谱变化曲线；S14、对肱动脉血管超声图像进行感兴趣区域选择、二值化处理、空洞填补处理、Sobel算子边缘检测处理,得到第二Sobel梯度图像；S15、识别第二Sobel梯度图像中的0轴位置,并锁定K值搜索上包络和下包络,得到肱动脉血流频谱变化曲线；所述识别第二Sobel梯度图像中的0轴位置,并锁定K值搜索上包络和下包络,得到肱动脉血流频谱变化曲线这一步骤,其具体包括；S151、在第二Sobel梯度图像中感兴趣区域全局搜索像素值为1的像素点,得到白色像素值的位置集；S152、根据位置集中最高的四个纵坐标数值,确定感兴趣区域中得0轴位置；S153、将K设为1并从上到下提取上包络,直至识别到0轴范围的像素点；S154、将K设为-1并从下到上提取下包络,直至识别到0轴范围的像素点；S155、返回步骤S153,直至感兴趣区域内所有像素点均识别完成,得到肱动脉血流频谱变化曲线；S2、根据动脉血流频谱变化曲线建立血流速度频谱的ARX传递函数；S3、对血流速度频谱的ARX传递函数进行拟合分析,得到传递函数特征；S4、采用SVM分类器对传递函数特征进行处理,完成血流频谱信号分类。</td>   <td>G06T7/00;G06T7/13;G06T5/30;G06V10/764;A61B8/08;A61B8/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高始军;              黄林冲;              常勇;              黄旭民;              何子良;              张箭;              任国平;              钟小春;              王浩;              尹义豪;                   梁禹       </td>   <td>中山大学·深圳;中山大学;中铁十四局集团大盾构工程有限公司;河海大学</td>   <td>一种盾构施工盾尾空隙注浆压力校验方法</td>   <td>广东省</td>   <td>CN116227000A</td>   <td>2023-06-06</td>   <td>本发明涉及隧道盾构施工技术领域,特别是涉及一种盾构施工盾尾空隙注浆压力校验方法,本发明的盾构施工盾尾空隙注浆压力校验方法,先根据拼装隧道的环间接头模型计算环间剪切力临界值；再根据设计注浆压力和拼装隧道纵向力学模型,计算拼装隧道的纵向各个位置处的剪切力理论值；之后将各剪切力理论值与环间剪切力临界值进行比较,若任一个剪切力理论值大于环间剪切力临界值,则降低设计注浆压力,从而避免了盾构施工过程中环间接头处容易因剪切力过大而出现螺栓剪切屈服。</td>   <td>1.一种盾构施工盾尾空隙注浆压力校验方法,其特征在于,包括以下步骤：根据拼装隧道的环间接头模型计算环间剪切力临界值；根据设计注浆压力和拼装隧道纵向力学模型,计算所述拼装隧道的纵向各个位置处的剪切力理论值；将各所述剪切力理论值与所述环间剪切力临界值进行比较,若任一个所述剪切力理论值大于所述环间剪切力临界值,则降低所述设计注浆压力。</td>   <td>G06F30/13;G06F30/20;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓锐;              刘海龙;              王士刚;              任航;              于祥;              莫潇越;              黄思翀;              罗富强;                   吴铁成       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种帆船速度预测方法</td>   <td>广东省</td>   <td>CN116227175A</td>   <td>2023-06-06</td>   <td>本发明公开了一种帆船速度预测方法,包括：根据帆船模型获取帆船参数,设置帆船航行时的预设风况；根据帆船参数和预设风况,利用数值计算软件分别计算帆船的风帆受力、船舶阻力、船舵受力、船体受力及稳向板受力；根据风帆受力、船舶阻力、船舵受力、船体受力及稳向板受力对帆船进行受力分析,建立帆船保持稳定姿态航行时的平衡方程组,平衡方程组包括纵向受力平衡方程、横向受力平衡方程和力矩平衡方程；利用数值计算软件求解平衡方程组,得到帆船在设风况下航行时的预测速度、预测舵角和预测航向角。本发明能在预设风况条件下,预测帆船在不同帆转角条件下的航向、航速和舵角,便于风帆操纵和自动控制。</td>   <td>1.一种帆船速度预测方法,其特征在于,包括：根据帆船模型获取帆船参数,设置所述帆船航行时的预设风况；根据所述帆船参数和所述预设风况,利用数值计算软件分别计算所述帆船的风帆受力、船舶阻力、船舵受力、船体受力及稳向板受力；根据所述风帆受力、所述船舶阻力、所述船舵受力、所述船体受力及所述稳向板受力对所述帆船进行受力分析,建立所述帆船保持稳定姿态航行时的平衡方程组,所述平衡方程组包括力矩平衡方程、纵向受力平衡方程和横向受力平衡方程；利用数值计算软件求解所述平衡方程组,得到所述帆船在所述预设风况下航行时的预测速度、预测舵角和预测航向角。</td>   <td>G06F30/20;G06F30/15;G06F17/12;B63B71/10;G06F119/14;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余世孝;              乔雪婷;                   张娟娟       </td>   <td>中山大学深圳研究院</td>   <td>一种猕猴岛屿适宜栖息地选择方法</td>   <td>广东省</td>   <td>CN116227868A</td>   <td>2023-06-06</td>   <td>本发明提供了一种猕猴岛屿适宜栖息地选择方法,该方法包括以下步骤：测定岛屿植被类型与物种多度；测定物理环境参数；构建猕猴活动强度矩阵；构建物理环境参数矩阵与物种多度矩阵、植被结构参数矩阵；对猕猴活动强度矩阵与物理环境参数矩阵,以及猕猴活动强度矩阵与物种多度矩阵、猕猴活动强度矩阵与植被结构参数矩阵分别进行典范相关分析,从而得出与猕猴活动强度相关程度大小排列的物理环境参数序列、物种序列、植被结构参数序列；依据物理环境参数序列、物种序列、植被结构参数中各值的大小,选择分别居于前列的物理环境参数、重要物种以及植被结构参数,从而确定猕猴适宜栖息地。本发明的方法能够全面、有效地为猕猴选择适宜栖息地,对生态保护和科学研究具有重要意义。</td>   <td>1.一种猕猴岛屿适宜栖息地选择方法,其包括以下步骤：(1)测定岛屿植被类型与物种多度；(2)测定物理环境参数；(3)构建猕猴活动强度矩阵；(4)构建物理环境参数矩阵与物种多度矩阵、植被结构参数矩阵；(5)对猕猴活动强度矩阵和物理环境参数矩阵,以及猕猴活动强度矩阵和物种多度矩阵、猕猴活动强度矩阵和植被结构参数矩阵分别进行典范相关分析,从而得出与猕猴活动强度相关程度大小排列的物理环境参数序列、物种序列、植被结构参数序列；(6)依据物理环境参数序列、物种序列、植被结构参数中各值的大小,选择分别居于前列的物理环境参数、重要物种以及植被结构参数,从而确定猕猴适宜栖息地。</td>   <td>G06Q10/0631;G06Q10/0639;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张云鹏;              王帆;              韦立坚;              林俊勤;              孙伟健;                   陈思航       </td>   <td>中山大学</td>   <td>一种企业负面舆情智能风险识别及指标构建方法</td>   <td>广东省</td>   <td>CN116227909A</td>   <td>2023-06-06</td>   <td>本发明提出一种企业负面舆情智能风险识别及指标构建方法,涉及企业负面舆情识别及自然语言处理的技术领域,分为舆情相关数据的采集、数据预处理、自然语言处理、机器学习预测、综合指标构建几个部分,在此基础上,通过层次分析法的专家打分对不同风险赋予不同的权重,从而更好的刻画舆情新闻的不同风险强度,最后进行指标构建,对负面舆情所蕴含的风险进行严格监控,为投资者提供更准确且可读性较高的风险信息,辅助投资者花费更短的时间理解并做出投资判断,防止负面舆情风险传播造成系统性的金融风险。</td>   <td>1.一种企业负面舆情智能风险识别及指标构建方法,其特征在于,所述方法包括以下步骤：S1.采集企业舆情新闻数据；S2.对企业舆情新闻数据进行预处理及风险分类；S3.利用自然语言处理的方式将与预处理及风险分类后的数据进行文档向量表示,并标注风险分类及情绪；S4.将得到的文本向量作为机器学习模型的输入特征,将标注的风险分类和情绪结果作为预测的指标,进行舆情风险和情绪预测；S5.对舆情风险和情绪预测结果进行评估,利用层次分析法为得到的预测结果分配权重,基于权重构建综合的负面舆情指标,并使用股价数据进行显著性检验。</td>   <td>G06Q10/0635;G06Q10/0639;G06Q40/06;G06F18/24;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋尔卫;              姚和瑞;              余运芳;              任炜;              谭钰洁;              何子凡;              姚沁玥;              汪进;              陈李粮;              单玲政;                   陈睿       </td>   <td>中山大学孙逸仙纪念医院;赛维森(广州)医疗科技服务有限公司</td>   <td>肿瘤预后评估方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN116228753A</td>   <td>2023-06-06</td>   <td>本申请涉及一种肿瘤预后评估方法、装置、计算机设备和存储介质,该方法包括：获取目标对象的术前影像数据；所述术前影像数据包括若干影像序列；对各所述影像序列进行预处理,得到四维影像数据集合；分别获取所述四维影像数据集合中的各个四维影像数据对应的肿瘤靶区掩膜；根据各所述肿瘤靶区掩膜中符合预设条件的连通区域,形成所述四维影像数据集合对应的若干肿瘤靶区影像数据集合；基于各所述肿瘤靶区影像数据集合,确定所述目标对象的肿瘤预后评估结果。本申请不仅增加了肿瘤预后评估结果的评估维度,还有效提升了肿瘤预后评估结果的准确性。</td>   <td>1.一种肿瘤预后评估方法,其特征在于,所述方法包括：获取目标对象的术前影像数据；所述术前影像数据包括若干影像序列；对各所述影像序列进行预处理,得到四维影像数据集合；分别获取所述四维影像数据集合中的各个四维影像数据对应的肿瘤靶区掩膜；根据各所述肿瘤靶区掩膜中符合预设条件的连通区域,形成所述四维影像数据集合对应的若干肿瘤靶区影像数据集合；基于各所述肿瘤靶区影像数据集合,确定所述目标对象的肿瘤预后评估结果。</td>   <td>G06T7/00;G06T7/187;G06V10/82;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苟超;              李垚坤;                   谭光       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于多任务学习的驾驶员状态估计方法</td>   <td>广东省</td>   <td>CN116229432A</td>   <td>2023-06-06</td>   <td>本发明公开了一种基于多任务学习的驾驶员状态估计方法,包括：使用共享的预训练CNN模型作为骨干网络对输入的目标图像进行特征提取,得到目标任务的共享特征；其中,所述目标任务包括关键点预测任务、遮挡概率估计任务和头部姿态估计任务；将所述共享特征输入各个任务模块中完成对应的任务预测,得到关键点预测结果、遮挡概率估计结果和头部姿态估计结果；根据所述关键点预测结果、遮挡概率估计结果和头部姿态估计结果,生成驾驶员状态估计结果。本发明联合高效地解决了驾驶员面部关键点检测、遮挡概率估计和头部姿态估计三个问题,提高了估计结果的精度,可广泛应用于深度学习技术领域。</td>   <td>1.一种基于多任务学习的驾驶员状态估计方法,其特征在于,包括：使用共享的预训练CNN模型作为骨干网络对输入的目标图像进行特征提取,得到目标任务的共享特征；其中,所述目标任务包括关键点预测任务、遮挡概率估计任务和头部姿态估计任务；将所述共享特征输入各个任务模块中完成对应的任务预测,得到关键点预测结果、遮挡概率估计结果和头部姿态估计结果；根据所述关键点预测结果、遮挡概率估计结果和头部姿态估计结果,生成驾驶员状态估计结果；其中,所述将所述共享特征输入各个任务模块中完成对应的任务预测这个步骤具体包括：在关键点预测模块中,通过Transformer的自注意力层预测得到关键点热力图；在遮挡概率评估模块中,利用关键点位置信息在共享特征中提取出每一个关键点对应的局部特征块,将所述局部特征块以及当前头部姿态的信息输入至自注意力层中,预测每一个关键点的遮挡概率；在头部姿态估计模块中,以逐层融合的方式融合拓扑、局部和全局的外貌信息。</td>   <td>G06V20/59;G06V10/44;G06V10/77;G06V10/80;G06V10/82;G06V10/25;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;              陈浩玲;                   段凯       </td>   <td>中山大学</td>   <td>一种面向栅格文本降水数据的可视化分析方法</td>   <td>广东省</td>   <td>CN109902120B</td>   <td>2023-06-02</td>   <td>本发明公开了一种面向栅格文本降水数据的可视化分析方法,通过解析栅格文本文件表头,设置并将栅格数据写入NetCDF数据库,转化为网格数据,利用NetCDF网格化数据,通过绘制等值线图,实现文本数据的可视化,将多个时间节点等值线图叠加,可进行数据时间变化特征分析。本发明可以解决ASCII数据文件管理和操作困难的问题,并提供了通过可视化快速直观地获取降雨数据时空分布特征的方法。</td>   <td>1.一种面向栅格文本降水数据的可视化分析方法,其特征在于：实现步骤如下：S1.解析栅格文本文件文件头,将文件头信息存储为Python字典；S2.依据文件头信息设置NetCDF文件数据维度及变量信息；S3.循环读取目标栅格文本文件中栅格数据,写入NetCDF文件；栅格文本数据转化为浮点型数值,无数值网格利用Python numpy.ma模块掩码；S4.读取NetCDF文件数据,转化为Python Numpy数组；S5.将数据数组输入可视化模块,定义空间范围、输出路径、降雨分布时间尺度以及图表标题,输出降雨分布的值线图；其中,可视化模块输入的经度、纬度范围需与目标数组空间维度保持一致；S6.读取各时间节点降雨分布的值线图,存储为Python List,设定延迟时间,利用Python Imageio模块输出对应的降雨分布动态变化图。</td>   <td>G06F16/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田茜;              郑慧诚;                   王腾       </td>   <td>中山大学</td>   <td>一种结合边界分布与纠正的事件提名方法</td>   <td>广东省</td>   <td>CN110059584B</td>   <td>2023-06-02</td>   <td>本发明提供的一种结合边界分布与纠正的事件提名方法,通过构建起点分布网络、终点分布网络和边界循环修正网络形成事件提名网络；通过构建事件提名网络损失函数对事件提名网络进行训练更新；利用训练更新后的事件提名网络对视频事件进行提名预测；所述起点分布网络、终点分布网络用于事件提名预测；所述边界循环修正网络用于产生预测的事件提名的偏置信息,对事件提名边界进行修正。本发明提供的一种结合边界分布与纠正的事件提名方法,结合了真实视频中的事件起止点分布规律产生拟合真实事件分布的事件提名,并利用循环修正网络对事件提名的边界进行修正,从而得到更加符合现实事件且使事件的边界更加精确的事件提名。</td>   <td>1.一种结合边界分布与纠正的事件提名方法,其特征在于：通过构建起点分布网络、终点分布网络和边界循环修正网络形成事件提名网络；通过构建事件提名网络损失函数对事件提名网络进行训练更新；利用训练更新后的事件提名网络对视频事件进行提名预测；所述起点分布网络、终点分布网络用于事件提名预测；所述边界循环修正网络用于产生预测的事件提名的偏置信息,对事件提名边界进行修正；所述起点分布网络、终点分布网络构建过程为：将现有数据集视频长度进行归一化,确定事件起止点在视频中的相对位置；统计数据集中所有事件起止点在视频中的相对位置,取视频中的所有事件起止点在视频时间线上的概率分布w-(s0),w-(e0)；w-(s0),w-(e0)分别表示事件的起点和终点概率分布,得到起点分布网络、终点分布网络；所述起点分布网络、终点分布网络进行事件提名预测的过程具体为：通过三维卷积网络获取样本视频的视频特征,基于起点分布网络和终点分布网络,将得到的视频特征利用循环神经网络进行计算,得到起点分布网络和终点分布网络中每一个时间点输出的视频特征；在起点分布网络和终点分布网络中的每一个时间点输出K个置信度,表示K个固定长度的事件提名的可能性,这K个事件提名的长度为：[t-k,t+1],k∈[0,K]；其中t与k的值满足t≥k,t的值随着视频长度的变化而变化；置信度越高,是事件提名的可能性越大；所述起点分布网络和终点分布网络中相对应的事件提名的置信度之和作为最后该事件的置信度,从而完成事件提名的预测。</td>   <td>G06V20/40;G06V10/764;G06V10/82;G06N3/0442;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁紫旭;              曹务腾;              吴磊;              王辉;              秦秀森;              李文辉;              石婧;              蔡建;              王怀明;              刘晓霞;              马腾辉;              黄榕康;              赵业标;              王馨华;              汪建平;              陈代词;              俞希虎;              钟清华;              秦启元;              初丽丽;              李杨;              曾展涛;                   黄小艳       </td>   <td>中山大学附属第六医院</td>   <td>一种肠癌腹膜转移预测模型及该模型的构建方法</td>   <td>广东省</td>   <td>CN110993110B</td>   <td>2023-06-02</td>   <td>本发明涉及生物医学领域,更具体地,本发明涉及一种肠癌腹膜转移预测模型及该模型的构建方法,所述肠癌腹膜转移预测模型为：Model＝32.892+1.51*CT-stage+1.884*tumor location+20.447*distant metastatic sites–19.898*thickened greater omentum–20.222*pelvic nodules；其中,CT-stage为T分期；tumor location为肿瘤部位；distant metastatic sites为远处转移部位；thickened greater omentum为大网膜增厚；pelvic nodules为盆腔种植结节。所述肠癌腹膜转移预测模型预测准确性高,具有高灵敏度及特异度。</td>   <td>1.一种肠癌腹膜转移预测模型的构建方法,其特征在于,所述预测模型为：Model＝32.892+1.51×CT-stage+1.884×tumor location+20.447×distantmetastatic sites-19.898×thickened greater omentum-20.222×pelvic nodules；其中,CT-stage为T分期；tumor location为肿瘤部位；distant metastatic sites为远处转移部位；thickened greater omentum为大网膜增厚；pelvic nodules为盆腔种植结节；通过如下步骤构建：S1、建模变量选择：选择结直肠癌病例150～200例,随机分成训练集和验证集,分别包含腹膜转移组和无腹膜转移组,腹膜转移癌具体CT图像参数包括13项：肿瘤位置、T分期、邻近器官侵犯、N状态、腹膜斑块阴影、肿瘤增强程度、坏死、穿孔、PC转移部位、远处转移部位、腹水、大网膜增厚、盆腔种植结节；S2、建模变量筛选：在训练组上,首先利用Boruta算法在增强CT的腹膜转移特征中,筛选出与腹膜转移因变量相关的变量集,具体为：(1)创建阴影特征：对每个真实特征R,随机打乱顺序,得到阴影特征矩阵S,拼接到真实特征后面,构成新的特征矩阵N＝[R,S]；(2)用新的特征矩阵N作为输入训练模型,能够输出特征的权重模型,得到真实特征和阴影特征的权重；(3)取阴影特征的权重的最大值W,真实特征中权重大于W的,记录一次命中；(4)用(3)中记录的真实特征累计命中,标记特征重要或不重要,在Boruta算法中增加FDR校正,用两步法参数切换两种检验方法；(5)删除不重要的特征,重复1-4,直到所有特征都被标记；S3、多变量回归模型的构建：对选出的变量集,应用前向逐步回归,根据AIC准则进一步筛选,最后得到肿瘤部位、T分期、远处转移部位、大网膜增厚以及盆腔种植结节这5个变量与腹膜转移密切相关；然后,对筛选出的5个变量,采用logistic回归模型建模即得肠癌腹膜转移预测模型；在建模变量筛选前还包括对连续变量的处理步骤：癌胚抗原水平以5ng/ml为分界点,小于5ng/ml为低水平,大于5ng/ml为高水平；年龄：以50、70为分界点,将其分为年轻(&lt;50)、中年(50-69)、老年(&gt;70)。</td>   <td>G16H50/50;G16H50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         阮思敏;              王伟;              陈立达;              胡航通;              李薇;              黄漾;              谢晓燕;              吕明德;                   匡铭       </td>   <td>中山大学附属第一医院</td>   <td>一种基于剪切波弹性成像超声组学深度分析方法及系统</td>   <td>广东省</td>   <td>CN111275706B</td>   <td>2023-06-02</td>   <td>本发明公开了一种基于剪切波弹性成像超声组学深度分析方法及系统,所述方法包括：针对不同疾病,利用超声医学声学经验获取标准化剪切波弹性图像；针对相应疾病模型,利用剪切波图像获取所在器官相应弹性超声组学数据；将所述弹性超声组学数据输入训练好的深度学习网络,并根据所述弹性超声组学数据调整神经元的连接权重、配比卷积和池化层,得到调整后的弹性超声组学数据,通过深度学习获取每个病变的分类评分；基于患者临床信息,检验指标,对结果深度学习弹性分类评分,通过机器学习分析,构建深度分析决策系统。本发明能够提高边界数据获取的可重复性及图像分析的适应性,并构建深度分析决策系统提高辅助分析结果的准确性。</td>   <td>1.一种基于剪切波弹性成像超声组学深度分析方法,其特征在于,包括：步骤S11,针对不同疾病,利用超声医学声学经验获取标准化剪切波弹性图像；步骤S12,针对相应疾病模型,利用剪切波图像获取所在器官相应弹性超声组学数据；步骤S13,将所述弹性超声组学数据输入训练好的深度学习网络,并根据所述弹性超声组学数据调整神经元的连接权重、配比卷积和池化层,得到调整后的弹性超声组学数据,通过深度学习获取每个病变的分类评分；步骤S14,基于患者临床信息,检验指标,对结果深度学习弹性分类评分,通过机器学习分析,构建深度分析决策系统；所述步骤S11中,获取标准化剪切波弹性图像包括：获取浅表占位病变标准图像,将超声探头轻置于病变表面,使切面为病变病灶最大切面,切换至剪切波弹性成像模式,使剪切波弹性成像取样框包含整个病灶,获取剪切波弹性成像彩色区域充满整个取样框；获取腹部实质器官占位病变标准图像,将超声探头轻置于病变表面,使切面为病变病灶最大切面,切换至剪切波弹性成像模式,使剪切波弹性成像取样框包含整个病灶,获取剪切波弹性成像彩色区域大于整个取样框的三分之二；所述步骤S12中,所述剪切波弹性成像取样框内全病灶的边缘为感兴趣区域；对所述剪切波图像的处理包括将彩色剪切波图像分解为RGB三通道灰阶图像,连同原彩色剪切波图像,分别获取弹性超声组学数据。</td>   <td>G06T7/00;G06N3/08;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         饶洋辉;                   张志宏       </td>   <td>中山大学</td>   <td>基于谱范数归一化的生成对抗主题模型构建方法及装置</td>   <td>广东省</td>   <td>CN113918716B</td>   <td>2023-06-02</td>   <td>本发明提出一种基于谱范数归一化的生成对抗主题模型构建方法及装置,包括：获取文本数据集,并处理得到文本的tf-idf向量集；引入谱范数归一化的方法对生成对抗主题模型进行对抗训练,得到训练好的生成器、编码器和具有分类功能的有监督鉴别器；主题模型经过对抗训练后,生成器输出文本数据集中的主题-词分布；编码器输出文本数据集中的文档-主题分布,将主题-词分布和文档-主题分布输入到有监督鉴别器中,对文本进行分类。本发明构建了一个有监督的双向生成对抗网络,并引入了谱范数归一化的方法,使得主题模型能够稳定训练；有监督鉴别器能够在保证生成对抗网络在进行对抗训练的同时,有效地提取并利用标签信息的引导来提升生成主题的质量。</td>   <td>1.一种基于谱范数归一化的生成对抗主题模型构建方法,其特征在于,包括以下步骤：S1：获取文本数据集,对文本数据集进行预处理,并对文本进行特征向量化,得到文本特征向量集,即tf-idf向量集；S2：构建生成对抗主题模型,其中所述生成对抗主题模型包括生成器、编码器和有监督鉴别器；S3：将tf-idf向量输入所述生成对抗主题模型并使用谱范数归一化的方法对所述生成对抗主题模型进行对抗训练,得到训练好的生成对抗主题模型；其中所述生成器输出文本数据集中的主题-词分布；编码器输出文本数据集中的文档-主题分布；具有分类功能的有监督鉴别器根据输入的文档-主题分布和主题-词分布,对文本进行分类；进行对抗训练的步骤包括：S3.1：初始化生成对抗主题模型参数；S3.2：使用tf-idf向量训练编码器：S3.2.1：从步骤S1得到的tf-idf向量集中的选取s篇文档的的tf-idf向量；S3.2.2：将tf-idf向量输入到编码器,得到主题向量/&gt;；S3.3：使用预设的狄利克雷分布采样数据训练生成器：S3.3.1：从狄利克雷分布先验分布中采样得到服从狄利克雷分布的向量；S3.3.2：将服从狄利克雷分布的向量输入到生成器,得到生成文档向量/&gt;；S3.4：利用编码器和生成器的输出,并同时使用谱范数归一化的方法出对有监督鉴别器进行训练,达到对抗训练的目的：S3.4.1：将主题向量与tf-idf向量/&gt;进行拼接得到/&gt;,将/&gt;作为有监督鉴别器的真实输入向量,r表示该向量来自真实样本；S3.4.2：将生成文档向量与主题向量/&gt;进行拼接得到/&gt;,将/&gt;作为有监督鉴别器的生成输入向量；f表示该向量来自生成样本；S3.4.3：将真实输入向量和生成输入向量输入到有监督鉴别器,得到分类输出概率和有监督鉴别器输出概率/&gt;；其中,C代表文本数据集中的类别数,表示有监督鉴别器输出对应样本为真实样本的概率；若识别/&gt;的概率最大,则代表有监督鉴别器认为数据是来自真实样本；S3.4.4：计算Wasserstein距离作为总的损失函数L：                                              /&gt;其中,是根据主题分布的维度确定的狄利克雷分布的先验参数,/&gt;和/&gt;是设定用于调节模型的两个分布之间训练的重要性的参数,/&gt;表示对抗损失函数 ,/&gt;表示分类损失函数；S3.4.5：对所有样本求一个算数平均,使用梯度下降法中的RMSprop方法进行反向传播以最小化损失函数L,同时使用谱范数归一化的方法限制过大梯度的传播以保证训练的稳定,直至模型收敛。</td>   <td>G06F16/35;G06N3/045;G06N3/0475;G06N3/094;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭琤琤;              吴志明;              黄河;              杨静怡;              牟永告;              陈银生;              张继;              陈建根;                   王海蓉       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>用于预测中枢神经系统生殖细胞肿瘤预后的方法及系统</td>   <td>广东省</td>   <td>CN115148365B</td>   <td>2023-06-02</td>   <td>本发明公开了一种用于预测中枢神经系统生殖细胞肿瘤预后的方法,该方法包括：将多个MR扫描图像进行特征提取生成多个影像特征；对多个影像特征进行逐步回归分析筛选出与预后关联的影像特征；通过与预后关联的影像特征和预置的评分公式构建影像组标签；将临床因素与影像组标签进行整合生成预测模型；通过预测模型对中枢神经系统生殖细胞肿瘤预后进行预测。由此,能够准确预测中枢神经系统生殖细胞肿瘤预后,有利于及时的指导临床治疗。</td>   <td>1.一种用于预测中枢神经系统生殖细胞肿瘤预后的方法,其特征在于,所述方法包括：将多个MR扫描图像进行分析生成与预后关联的影像特征；通过所述与预后关联的影像特征和预置的评分公式构建影像组标签；将临床因素与所述影像组标签进行整合生成预测模型；通过所述预测模型对中枢神经系统生殖细胞肿瘤预后进行预测,包括：所述与预后关联的影像特征包括：形状特征、最大2D直径列特征、集群突出特征、集群阴影特征、最大相关系数、依赖熵特征、小依赖低灰度强调特征、粗糙度特征；将所述与预后关联的影像特征代入到所述预置的评分公式构建影像组标签,其中,所述预置的评分公式为：-0.001922×形状特征-最大2D直径列特征+0.000000003684×集群突出特征+0.000004446×集群阴影特征+4.129×最大相关系数-0.3783×依赖熵特征-188.5×小依赖低灰度强调特征-250.4×依赖熵特征组成的邻域灰度差矩阵-粗糙度特征。</td>   <td>G16H50/50;G16H50/70;G16H50/30;G16H50/20;G16H30/00;A61B5/00;A61B5/055</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张亚琴;              陶雨溪;              韩佳悦;                   陈铭       </td>   <td>中山大学附属第五医院</td>   <td>基于FFDM的乳腺影像处理方法、系统、终端和介质</td>   <td>广东省</td>   <td>CN115619641B</td>   <td>2023-06-02</td>   <td>本发明提供了一种基于FFDM的乳腺影像处理方法、系统、终端和介质,方法包括：根据第一乳腺X线数据集和第二乳腺X线数据集构建第一数据集和第二数据集；第一乳腺X线数据集为DFM数据集,第二乳腺X线数据集为FFDM数据集；通过第一数据集训练预设的生成式对抗网络；通过训练好的生成式对抗网络,基于所述第二数据集生成目标乳腺X线数据集；其中,所述目标乳腺X线数据集为FFDM影像。相比于现有技术,采用了生成式对抗网络,在进行乳腺癌筛查过程中不需要额外进行标记；基于DFM的第二数据集生成相对更高分辨率的FFDM目标乳腺X线数据集,提高了影像的质量,使生成的影像与真实影像更为相近。</td>   <td>1.一种基于FFDM的乳腺影像处理方法,其特征在于,包括：从第一乳腺X线数据集和第二乳腺X线数据集中选取第一数据集,并根据所述第一乳腺X线数据集中未被选取的剩余数据集构建第二数据集；其中,所述第一乳腺X线数据集为DFM数据集,第二乳腺X线数据集为FFDM数据集；通过所述第一数据集训练预设的生成式对抗网络；其中,所述生成式对抗网络的生成器包括U-Net生成器；所述生成式对抗网络的鉴别器包括多尺度DNN架构；通过训练好的生成式对抗网络,基于所述第二数据集生成目标乳腺X线数据集；其中,所述目标乳腺X线数据集为FFDM影像；在所述通过所述第一数据集训练预设的生成式对抗网络之前,还包括：通过滑窗对所述第一数据集中的DFM影像和FFDM影像进行裁剪,获得若干DFM斑片和若干FFDM斑片；通过阈值法提取所述第一数据集的背景,并根据所述背景的比例,确定各斑片的类别；所述斑片的类别包括乳房区域类别、边界类别和背景类别；随机选取相同类别的DFM斑片和FFDM斑片构建若干输入对,获得经过预处理的所述第一数据集；其中,所述输入对用于训练所述生成式对抗网络。</td>   <td>G06T3/40;G06T7/00;G06N3/044;G06N3/0455;G06N3/0464;G06N3/0475;G06N3/084;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>              谭金凯       </td>   <td>中山大学</td>   <td>基于变分自编码的台风云图外推方法、系统、设备和介质</td>   <td>广东省</td>   <td>CN115661277B</td>   <td>2023-06-02</td>   <td>本发明提供了基于变分自编码的台风云图外推方法、系统、设备及介质,所述方法包括：获取卫星云图数据和历史台风最佳路径数据,并根据卫星云图数据和历史台风最佳路径数据,构建台风云图外推数据集；根据台风云图外推数据集,构建得到台风云图外推预测模型；所述台风云图外推预测模型包括依次连接的变分自编码器、解码器和三维点云重采样器；获取待预测台风的初始卫星云图数据,并将初始卫星云图数据输入台风云图外推预测模型,得到对应的云图预测结果。本发明从“数据驱动”的角度出发,挖掘出卫星云图的多种潜在特征,不仅操作过程方便简单,而且能实现更高效、更精准地台风云图外推预测。</td>   <td>1.一种基于变分自编码的台风云图外推方法,其特征在于,所述方法包括以下步骤：获取卫星云图数据和历史台风最佳路径数据,并根据所述卫星云图数据和历史台风最佳路径数据,构建台风云图外推数据集；根据所述台风云图外推数据集,构建得到台风云图外推预测模型；所述台风云图外推预测模型包括依次连接的变分自编码器、解码器和三维点云重采样器；所述变分自编码器包括依次连接的第一二维卷积层、第二二维卷积层、第三二维卷积层、第一全连接层和分布隐变量拟合层；所述解码器包括依次连接的特征重采样层、第一维度转换层、第一二维反卷积层、第二二维反卷积层和第三二维反卷积层；所述三维点云重采样器包括依次连接的坐标参数矩阵优化模块、坐标重采样模块和双线性插值模块；所述坐标参数矩阵优化模块包括线性展平层、第二全连接层、第三全连接层、第四全连接层和第二维度转换层；获取待预测台风的初始卫星云图数据,并将所述初始卫星云图数据输入所述台风云图外推预测模型进行云图外推预测,得到对应的云图预测结果；其中,所述根据所述卫星云图数据和历史台风最佳路径数据,构建台风云图外推数据集的步骤包括：将所述卫星云图数据添加对应的经纬度信息,得到预处理卫星云图数据；根据所述历史台风最佳路径数据,得到对应的台风记录；所述台风记录包括台风最大风速、台风中心经纬度、台风最低中心气压、台风登陆位置、台风转向和台风移速；将所述台风记录与所述预处理卫星云图数据按照预设规则进行匹配,得到各个台风记录的匹配卫星云图信息；所述预设规则为经纬度信息和时间信息一一对应；所述匹配卫星云图信息包括经纬度信息和时间信息；根据各个台风记录和对应的匹配卫星云图信息,构建得到所述台风云图外推数据集；所述将所述初始卫星云图数据输入所述台风云图外推预测模型进行云图外推预测,得到对应的云图预测结果的步骤包括：将所述初始卫星云图数据输入变分自编码器进行特征提取,得到隐含特征分布；将所述隐含特征分布输入所述解码器依次进行特征重采样、维度转换和解码处理,得到重构特征；将所述重构特征输入所述三维点云重采样器进行点云重采样,得到所述云图预测结果。</td>   <td>G06T9/00;G06N3/04;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              张富为;                   林谋广       </td>   <td>中山大学</td>   <td>一种文本内容结合图像分析的多模态内容检索方法与系统</td>   <td>广东省</td>   <td>CN116204706A</td>   <td>2023-06-02</td>   <td>本发明公开了一种文本内容结合图像分析的多模态内容检索方法。包括：对数据集进行预处理,得到文本图像信息对；提取图像与文本特征,对图像特征与文本特征进行多模态注意力计算,得到多模态特征；编码图像、文本和多模态特征,形成对应的哈希码；构建目标损失函数,训练得到多模态哈希码生成模型；利用多模态哈希码生成模型,从待检索的数据库中构建出该数据库的多模态哈希码数据库；根据用户输入的文本信息,生成多模态哈希码,与多模态哈希码数据库进行匹配,得到检索结果。本发明还公开了一种文本内容结合图像分析的多模态内容检索系统。本发明使用多模态哈希码,从根本上捕获模态之间的共性,弥补模态之间的异质鸿沟,显著提高有效特征的提取效率。</td>   <td>1.一种文本内容结合图像分析的多模态内容检索方法,其特征在于,所述方法包括：对数据集Imagenet中的图像集合进行标注,得到文本图像信息对；输入所述文本图像信息对,构建特征提取网络提取图像与文本特征,输出图像特征与文本特征；输入所述图像特征与所述文本特征,进行多模态注意力计算,得到加权注意力后的多模态特征；分别对所述图像特征、所述文本特征和所述多模态特征进行哈希生成,输出图像哈希码、文本哈希码以及多模态哈希码；输入所述图像哈希码、所述文本哈希码和所述多模态哈希码,构建目标损失函数,利用损失函数训练模型,最终得到多模态哈希码生成模型；利用训练得到的所述多模态哈希码生成模型,从待检索的数据库中构建出该数据库的多模态哈希码数据库；根据用户输入的文本信息,利用所述多模态哈希码生成模型生成多模态哈希码,再与所述构建的多模态哈希码数据库进行匹配,得到检索结果。</td>   <td>G06F16/9535;G06F16/9536;G06F16/901;G06F16/535;G06F16/335;G06V10/40;G06V10/82;G06V10/74;G06F18/25;G06N3/045;G06N3/0464;G06N3/048;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林宇烽;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种广告转化率预估模型及其训练方法</td>   <td>广东省</td>   <td>CN110796499B</td>   <td>2023-05-30</td>   <td>本发明涉及一种广告转化率预估模型及其训练方法,预估模型中包括编码网络、预测网络和损失函数计算模块,损失函数计算模块根据预测网络得到的部分预测结果和广告主标签数据计算出具体的损失函数值并加入差分隐私机制；预测网络根据损失函数值更新自身网络。通过训练方法对预估模型进行训练。本发明通过部分预测结果结合广告主的标签数据计算损失函数值来反馈预测网络,广告转化率预测模型可以利用广告主的标签数据,同时也保证了数据隐私,提高预估广告转化率的准确性。</td>   <td>1.一种广告转化率预估模型的建立方法,包括编码网络和预测网络,所述预测网络输入编码网络得到的整体特征向量后输出预测结果,其特征在于,还包括损失函数计算模块；所述损失函数计算模块根据预测网络得到的部分预测结果和广告主标签数据计算出具体的损失函数值；所述预测网络根据所述损失函数值更新自身网络；损失函数值的具体计算公式为：loss＝-(y*log(p)+(1-y)*log(1-p))其中,p为预测结果的概率值；y为其对应的转化标签值；所述损失函数值加上拉普拉斯机制的差分隐私,具体的公式为：loss-(dp)＝loss+Y                                    其中Y服从拉普拉斯分布,均值为0,Δf表示两个相邻数据集D,D′为最大距离；所述编码网络利用编码层来得到各个特征的特征向量,将同一特征域的特征向量取平均,不同特征域的特征向量做拼接,得到的结果输入到全连接层,得到整体特征向量；编码网络在点击率预估任务下进行训练,利用广告平台自身拥有的特征数据以及点击标签数据,得到的特征向量直接迁移到转化率预估任务中使用。</td>   <td>G06Q30/0242;G06Q10/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         成慧;              吴华栋;              杨凯;                   张东       </td>   <td>中山大学</td>   <td>一种基于图像输入的机器人主动学习方法</td>   <td>广东省</td>   <td>CN109800864B</td>   <td>2023-05-30</td>   <td>本发明涉及一种基于图像输入的机器人主动学习方法。包括以下步骤：S1.在仿真环境中,搭建一个类似于现实场景的环境；S2.根据任务的可受性制作响应图和掩膜；S3.使用步骤S1采集的彩色图像、步骤S2制作的响应图和掩膜图,训练深度神经网络,使用编码器从图片中提取有效的信息,再使用解码器生成表示可受性区域响应图；S4.将训练好的深度神经网络模型部署到真实机器人上,尝试完成指定的任务；S5.保存当前状态下摄像头捕获的彩色图像和深度图像,进行标注；S6.使用标注数据对网络进行微调,重复步骤S4；S7.机器人开始执行任务。可以通过在仿真环境中采集少量的数据,训练一个效果良好的深度神经网络,并且能够直接迁移到真实环境之中。</td>   <td>1.一种基于图像输入的机器人主动学习方法,其特征在于,包括以下步骤：S1. 在仿真环境中,搭建一个类似于现实场景的环境,捕获仿真环境中的彩色图像和对应的物体的位置,保存为数据集；S2. 根据任务的可受性制作响应图和掩膜；具体包括：S21. 根据任务的特点,计算对于指定任务下物体的可受性区域,对于抓取任务,可受性区域为物体的几何中心点；对于推动任务,可受性区域为终点物体与起点物体的连线的延长线某一区域处；S22. 根据可受性区域,制作响应图,在图上表示为一个服从高斯分布的高亮圆形,圆心的位置即为可受性区域的中心位置；S23. 根据可受性区域,制作掩膜图,在图上表示为一个服从高斯分布的高亮圆形,圆心的位置即为可受性区域的中心位置,半径比响应图的圆形要大；S3. 使用步骤S1采集的彩色图像、步骤S2制作的响应图和掩膜图,训练深度神经网络,使用编码器从图片中提取有效的信息,再使用解码器生成表示可受性区域响应图；S4. 将训练好的深度神经网络模型部署到真实机器人上,尝试完成指定的任务；具体包括：S41. 摄像头拍摄当前场景的彩色图像,将该图像进行归一化,归一化后的图像像素值的范围是(-1,1),将归一化后的图像输入到网络中；网络将会输出对应的响应图；S42. 计算输出的响应图的交叉熵,比较交叉熵和阈值大小的关系,判断能否完成任务；若交叉熵的值大于阈值,机器人能执行该任务,跳到步骤S7；若交叉熵的值小于阈值机器人无法执行任务,跳到步骤S5；S5. 保存当前状态下摄像头捕获的彩色图像和深度图像,进行标注；S6. 使用标注数据对网络进行微调,重复步骤S4；S7. 机器人开始执行任务。</td>   <td>G06N3/0464;G06N3/08;B25J9/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑培嘉;                   曾博航       </td>   <td>中山大学</td>   <td>一种面向移动云计算的密文数据存储与检索方法</td>   <td>广东省</td>   <td>CN110928980B</td>   <td>2023-05-30</td>   <td>本发明提供一种面向移动云计算的密文数据存储与检索方法。数据拥有者对文本进行预处理,提取出关键字及关键字对应的词频-逆向文件频率(TF-IDF),并生成索引；在数据使用者在文本信息隐私不被泄露的情况下本地生成陷门；云服务器上使用了优化后的搜索算法,返回最相关联的前几个加密文件。本发明是一种更适合移动设备的加密下的文本搜索方案,能够高效的搜索出所需要的文本,在保证文本搜索准确的前提下,相对于一般的方法,能够有效减少信息在网络传输过程中的时间消耗,并使用了优化的搜索算法,有效地降低了在云服务器上消耗的搜索时间。本发明还支持多关键字的搜索。</td>   <td>1.一种面向移动云计算的密文数据存储与检索方法,其特征在于,包括以下步骤：S1：提取文本中关键信息生成索引并加密；步骤S1中,提取文本中关键信息生成索引并加密具体包括以下步骤：S1.1对文本进行预处理,提取全文本关键字w,关键字的数量记为m,得出每个文本中关键字的词频TF,并计算出全部文本的逆向文件频率IDF,其中TF、IDF的维度等于关键字的数量m；S1.2随机生成可逆矩阵M,随机系数向量其中,M的维度为m×m,/&gt;的长度为m；S1.3对IDF进行加密,并生成加密IDF表,加密过程公式如下：                  其中,表示加密后的IDF值；S1.4以每个文本作为叶子结点,根据每个文本的TF值,创建二叉树结构的搜索索引I,并对结点的TF值进行加密生成I-u,u为二叉树的结点编号,公式如下：                  其中,D-u是结点u对应的TF,D′-u表示加密后的D-u；S2：将加密后的文本和加密后的索引I发送给云服务器,将加密后的IDF表发送给数据用户；S3：数据用户生成随机向量和随机数a并且a大于1,输入想要搜索的关键字,本地查找IDF表,并生成陷门；步骤S3具体包括：数据用户生成随机向量和随机数a并且a大于1,随机向量/&gt;为在μ＝0,σ＝0.5的正态分布下的随机值集合,输入需要搜索的关键字集w-q,本地查找IDF表,找到关键字集w-q对应的生成向量为Q′,并生成陷门TD；其中,当w-i∈w,1≤i≤m,有w-i∈w-q时,则Q′[i]为否则设置当前Q′[i]为0,需对Q′进一步加密,陷门TD的生成公式如下：                  TD＝M～(-1)Q″其中,Q″是对Q′加入噪声后并使用随机数a加密后的向量；S4：用户将生成的陷门发送到云服务器；S5：云服务器使用优化后的搜索算法对搜索索引I进行搜索,返回前k个最与关键字关联的文件；S6：数据用户在获得解密密钥的前提下,对返回的文件进行解密。</td>   <td>G06F16/31;G06F16/33;G06F21/60;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;                   洪发挺       </td>   <td>中山大学</td>   <td>结合深度学习与关系建模的图片/视频重要人物检测方法</td>   <td>广东省</td>   <td>CN111008558B</td>   <td>2023-05-30</td>   <td>本发明公开了一种结合深度学习与关系建模的图片/视频重要人物检测方法,包括下述步骤：S1、对图片/视频中的人像的外表信息和几何信息进行特征提取,并融合成一个表征高层次语义的个人特征；S2、通过挖掘场景中人与人之间、人与场景之间的联系,计算出单独依靠个人特征无法表达或者无法高度表达的关系特征；S3、进行重要性分类,通过对在关系计算模型中提取的每个人像的最终特征表达进行重要或不重要的二分类,将每个人像被分为重要这个类别的概率作为重要性得分,得分最高的人像就是关系计算模型认定的重要人物。通过本发明能够通过学习,自主地去构建图片/视频中人物间的关系以及人物与图片中事件的关系,并自动推断出人物的重要程度。</td>   <td>1.一种结合深度学习与关系建模的图片/视频重要人物检测方法,其特征在于,包括下述步骤：S1、对图片/视频中的人像的外表信息和几何信息进行特征提取,并将人像的外表信息和几何信息进行融合成一个表征高层次语义的个人特征,同时提取整个图片/视频的信息作为全局特征；S2、通过挖掘场景中人与人之间、人与场景之间的联系,计算出单独依靠个人特征无法表达或者无法高度表达的关系特征,再将关系特征rfeat与个人信息pfeat融合生成能高度表达个人在场景中重要性的重要性特征,所述关系特征rfeat包含人与人、人与场景之间关系的信息；步骤S2中,对人与人之间和人与场景之间的关系进行建模,具体为：S21、计算人与人之间的关系：将两两之间的特征做矩阵投影后先相加,然后再做一个矩阵投影,得到一个数值,表示两两之间的联系强度,最后做一个截断操作,小于0的强制设为0；S22、计算人与场景的关系：将人与场景之间的特征相加,然后做矩阵投影,得到一个数值,表示人与场景之间的联系强度,最后做一个截断操作,小于0的强制设为0；S23、融合步骤S21和S22得到的关系,得到两两之间重要性关系：将两者的值相乘,如果任意一个值很小,那么得到的值就会很小；S24、由步骤S23得到的是一个n*n的矩阵,第i行表示的是所有人对第i个人的关系,用来整合所有人对第i个人的重要性关系；S25、计算出每个人对应的关系特征；计算出每个人对应的关系特征rfeat,具体为公式为：a)计算人与人之间的关系：                  b)计算人与场景之间的关系：                  c)融合多种关系：                  d)计算重要性关系：                  e)计算关系特征rfeat：                  f)构建重要度评判的重要性特征ifeat：                  上式中所有的w和W都是矩阵,f为特征向量,关系ε为标量数值,f)中的上标1,…,r表示有r个关系计算模块,因为是可以迭加的,Concat表示拼接操作,整个关系计算模块建模成以下公式：                  S3、进行重要性分类,通过对在关系计算模型中提取的每个人像的最终特征表达进行重要或不重要的二分类,将每个人像被分为重要这个类别的概率作为重要性得分,得分最高的人像就是关系计算模型认定的重要人物。</td>   <td>G06V40/10;G06V40/16;G06V10/44;G06V10/764;G06V10/774;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;                   袁子逸       </td>   <td>中山大学</td>   <td>基于增广网络的无监督行人重识别方法</td>   <td>广东省</td>   <td>CN111062329B</td>   <td>2023-05-30</td>   <td>本发明提供一种基于增广网络的无监督行人重识别方法,该方法以原始数据库中的行人图像数据为基础,进行多种形式的数据增广,将增广后的图像数据视作基础数据的同一标签数据通入参数不共享的网络分别提取特征,帮助网络进行训练。本发明的方法主要考虑如何在数据集不够丰富的情况下对无法直接作为输入的无标签数据进行利用,可以直接使用这种方法得到的主网络模型直接在测试集上进行特征提取后用于测试；也可以用这种方式先使用无标签的数据进行多个增广网络与主网络的预训练,再使用有标签的数据对主网络参数进行微调,从而有效利用无标签信息并提升行人重识别的准确率。</td>   <td>1.一种基于增广网络的无监督行人重识别方法,其特征在于,包括以下步骤：S1：对无标签的原始行人图像数据集D0进行增广操作,所述增广操作包括图像缩放、随机裁剪、随机擦除、加噪和高斯模糊的一种或多种,得到M个新的增广数据集D1～DM,M为正整数；S2：将原始行人图像数据集D0中的原始图像数据通入一个卷积神经网络作为主网络N0进行前向传播提取得到特征F0；S3：将M个增广数据集D1～DN中对应的增广图像数据分别输入M个参数不共享的卷积神经网络作为增广网络N1～NM进行前向传播提取得到特征F1～FM；S4：从原始行人图像数据集D0中随机选取一张图像Inegative作为负样本,通入主网络N0前向传播提取得到特征Fnegative；S5：用输出特征F0分别与输出特征F1～FM计算欧式距离,得到M个损失值L1～LM；S6：用输出特征Fnegative分别与输出特征F0～FM计算欧氏距离,得到M+1个损失值L0nagetive～LMnegative；S7：将S5中得到的M个损失值L1～LM分别与S6中得到的M个损失值L1negative～LMnegative相减后得到的结果作为损失对增广网络N1～NM进行后向传播计算梯度更新增广网络参数；S8：将S5中得到的M个损失值L1～LM进行求和与S6中得到的损失值L0negative～LMnegative求和的结果相减,得到总损失值L0；S9：将S8中得到的总损失值L0作为损失对主网络N0进行后向传播计算梯度更新主网络参数；S10：重复S2～S9的操作,直到主网络与增广网络收敛；S11：将主网络模型作为输出。</td>   <td>G06V40/10;G06V10/40;G06V10/82;G06N3/0464;G06N3/048;G06N3/084;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡航通;              王伟;              陈立达;              阮思敏;              匡铭;              谢晓燕;                   吕明德       </td>   <td>中山大学附属第一医院</td>   <td>一种基于复合神经网络的超声造影视频数据分析方法</td>   <td>广东省</td>   <td>CN111402207B</td>   <td>2023-05-30</td>   <td>本发明公开了一种基于复合神经网络的超声造影(CEUS)视频数据分析方法,通过获取待分析肝脏病变的超声造影多期视频数据,从多期视频数据中提取出多个超声造影时序单元,并标注多个超声造影时序单元,再通过复合神经网络提取各时序单元的综合信息,并根据各时序单元的综合信息进行后续网络训练,得到针对肝脏病变判定的参数权重,根据网络参数和参数权重构建肝脏病变分析模型,最后将待分析肝脏病变的超声造影多期视频数据输入至肝脏病变分析模型,输出待分析肝脏病变的分析结果。采用本发明提供的实施例,不仅能够充分利用CEUS时序信息,还降低了对视频分析的计算机算力需求,从而能够快速地对待分析肝脏病变进行分析。</td>   <td>1.一种基于复合神经网络的超声造影视频数据分析方法,其特征在于,包括以下步骤：获取待分析肝脏病变的超声造影多期视频数据；从所述多期视频数据中提取出多个超声造影时序单元,并标注所述多个超声造影时序单元；通过复合神经网络提取各时序单元的综合信息,并根据所述各时序单元的综合信息进行后续网络训练,得到针对肝脏病变判定的参数权重,根据网络参数和所述参数权重构建肝脏病变分析模型；所述复合神经网络由特征提取网络和多期特征整合网络组成；所述特征提取网络,用于提取时序单元中各单帧图像的特征；其中,单帧特征间相互独立；所述多期特征整合网络,用于以时序单元中单帧图像的时间顺序依次读取该时序单元特征,将各帧图像进行信息整合,得到该时序单元的综合信息；将所述待分析肝脏病变的超声造影多期视频数据输入至所述肝脏病变分析模型,输出所述待分析肝脏病变的分析结果；所述获取待分析肝脏病变的超声造影多期视频数据,具体为：对待分析肝脏病变进行多期分段视频数据采集,得到多期视频数据；其中,每期包括动脉期、门脉期以及延迟期；所述从所述多期视频数据中提取出多个超声造影时序单元,并标注所述多个超声造影时序单元,具体为：按照预设的时间节点在每期视频数据的动脉期、门脉期以及延迟期中各提取单帧图像,得到多个包含三张单帧图像的组合,并根据原有动脉期-门脉期-延迟期的时间序列,对所述多个包含三张单帧图像的组合进行排序得到多个超声造影时序单元,同时标注所述多个超声造影时序单元；所述动脉期预设的时间节点为10-30秒,所述门脉期预设的时间节点为31-120秒,所述延迟期预设的时间节点为121-360秒。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              张星;                   牛群       </td>   <td>中山大学</td>   <td>一种基于室内地标文本与轮廓的室内定位方法</td>   <td>广东省</td>   <td>CN113807357B</td>   <td>2023-05-30</td>   <td>本发明公开了一种基于室内地标文本与轮廓的室内定位方法,包括步骤如下：S1：获取某一室内地标图像,图像包括地标的文本信息、轮廓信息；同时采用GPS定位获取用户当前所在的场景信息；S2：采用光学字符识别算法提取所述的图像中的文本信息,并与第三方平台的室内平面图信息进行匹配,确定用户在室内的初步定位结果,并获取该地标的尺度信息渲染模型,得到不同位置的渲染图像；S3：使用训练好的神经网络提取所述的图像的轮廓信息；S4：使用渲染图像与轮廓信息进行匹配,选择与轮廓信息最为相似的一张渲染图像,将渲染图像的渲染位置作为用户相对地标的拍摄位置,从而产生相对定位结果；S5：将初步定位结果、相对定位结果结合,得到用户的绝对位置信息。</td>   <td>1.一种基于室内地标文本与轮廓的室内定位方法,其特征在于：所述的方法包括步骤如下：S1：获取某一室内地标图像,所述的图像包括地标的文本信息、轮廓信息；同时采用GPS定位获取用户当前所在的场景信息；S2：采用光学字符识别算法提取所述的图像中的文本信息,采用字符串匹配方法将提取的文本信息与第三方平台的室内平面图信息进行匹配,从而确定用户在室内的初步定位结果,并获取该地标的尺度信息渲染模型,得到不同位置的渲染图像；S3：使用训练好的神经网络提取所述的图像的轮廓信息；S4：使用渲染图像与步骤S3提取的轮廓信息进行匹配,选择与轮廓信息最为相似的一张渲染图像,将渲染图像的渲染位置作为用户相对地标的拍摄位置,从而产生相对定位结果；S5：将步骤S2的初步定位结果、步骤S3的相对定位结果结合,得到用户的绝对位置信息；所述的隐马尔可夫模型包括初始概率分布、观测矩阵、状态转移矩阵；根据文本数据库中每个文本序列的起始字符,得到初始概率分布：π＝[p-1,p-2,…,p-t]～T              (3)其中,p-t表示第t个字符作为文本序列的初始字符的概率,向量π中所有字符相加之和为1；所述的观测矩阵的定义如下：b-i(j)＝P(o-t＝v-j|i-t＝q-i)              (4)其中,v-j表示第j个观测结果；q-i表示状态结果；式(4)表示在i状态下,生成j观测的概率；采用光学字符识别算法将某一字符识别正确的概率,其计算方式如下：                  其中,p为光学字符识别算法中识别正确时的置信度,i表示状态下标,j表示观测下标；当i与j相等时,则为观测正确时的概率,不同则为观测错误的概率；再计算状态转移矩阵,此处即计算字符之间的跳转关系即可,其中q为字符集合中的元素；a-(i,j)＝P(i-(t+1)＝q-j|i-t＝q-i)              (6)其中,q-j、q-i表示状态,a-(i,j)表示从状态q-i转移到状态q-j的概率；最后校正问题则变成了给定一个文本序列O,将其解码成为正确的文本序列I的问题,使用维特比算法进行解码,根据解码得到校正后的文本序列；所述的解码具体如下：将文本序列O中的字符称为观测,将图像中的真实字符称为状态；给定观测序列O＝(o-1,o-2,...,o-T),隐马尔可夫模型λ＝[A,B,π]；首先,计算各个状态观测到o-1的概率：δ-1(i)＝π-ib-i(o-1)                   (7)ψ-1(i)＝0                        (8)其次,计算文本序列O中下一个观测结果出现的概率：                                    求得观测o-T对应的状态：                  最后,对于前面的观测,采用最优路径回溯法,最终校正后的文本序列为I～*：</td>   <td>G06V30/148;G06V30/18;G06V30/19;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伊永菊;              王文辉;              佘广南;              李银;                   梅甜       </td>   <td>中山大学附属第六医院</td>   <td>一种模态交互的图注意融合的教育视频问答方法及系统</td>   <td>广东省</td>   <td>CN113837259B</td>   <td>2023-05-30</td>   <td>本申请提供了一种模态交互的图注意融合的教育视频问答方法及系统,本申请通过对原始教育视频素材进行预处理得到训练数据集；提取训练数据集中各个模态的特征,将视频静态帧特征、视频动态特征和字幕特征分别输入至模态内交互模块中得到模态内交互特征；将各模态内交互特征输入至模态间交互模块得到模态间交互特征；将输入视频静态交互特征、输入视频文本交互特征与模态间交互特征输入至图注意融合模块进行融合得到最终的图注意融合的特征；将最终的图注意融合的特征输入至分类器进行训练得到教育视频问答模型模型,并应用到实际场景中。本申请能够提取视频中更加精确的信息,提高用户和视频的交互效果以及用户理解视频的效率。</td>   <td>1.一种模态交互的图注意融合的教育视频问答方法,其特征在于,所述方法包括如下步骤：获取原始教育视频素材；对所述原始教育视频素材进行预处理得到训练数据集；提取所述训练数据集中各个模态的特征,包括视频静态帧特征、视频动态特征、问题特征和字幕特征；将所述视频静态帧特征、视频动态特征和字幕特征分别输入至各自对应的模态内交互模块中与所述问题特征进行第一注意力计算得到输入视频静态交互特征、输入视频动态交互特征和输入视频文本交互特征；将输入视频静态交互特征、输入视频动态交互特征和输入视频文本交互特征输入至模态间交互模块进行第二注意力计算得到模态间交互特征；将所述输入视频静态交互特征、输入视频文本交互特征与所述模态间交互特征输入至图注意融合模块进行融合得到最终的图注意融合的特征；将所述最终的图注意融合的特征输入至分类器进行训练得到教育视频问答模型,并应用到实际场景中；其中,所述将所述视频静态帧特征、视频动态特征和字幕特征分别输入至各自对应的模态内交互模块中与所述问题特征进行第一注意力计算得到输入视频静态交互特征、输入视频动态交互特征和输入视频文本交互特征包括：通过双向循环神经网络对所述问题特征进行编码得到问题嵌入；将所述视频静态特征、视频动态特征和字幕特征中的一个特征与所述问题嵌入进行第一逐点求和；将求和后的特征通过三个FC全连接层进行线性变换；将其中两个线性变换后的特征进行第一逐点求积操作,求积后进行归一化处理；将归一化的结果与剩余一个线性变换的特征进行第二逐点求积操作；将第二逐点求积操作后的特征与第一个FC全连接层变换之后的特征进行Concat连接操作；将Concat连接操作的特征通过MLP前馈感知神经网络进行线性与非线性变换得到对应模态的模态内交互特征；所述将输入视频静态交互特征、输入视频动态交互特征和输入视频文本交互特征输入至模态间交互模块进行第二注意力计算得到模态间交互特征包括：将所述输入视频静态交互特征、输入视频动态交互特征和输入视频文本交互特征进行第二逐点求和操作；对求和后的特征进行归一化处理；将归一化后的特征与输入视频文本特征进行第三逐点求积操作；将第三逐点求积操作后的特征利用两个FC全连接层进行线性变换；将经过两个线性变换的特征进行点积操作；将点积操作后的特征与输入视频文本特征进行第三逐点求和操作；利用前馈神经网络MLP对第三逐点求和后的特征进行线性与非线性变换得到模态间交互特征。</td>   <td>G06V10/764;G06V10/80;G06V10/774;G06V10/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              谢震宇;              董浩业;                   吴博文       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>基于人工智能的虚拟试穿方法、装置、服务器及存储介质</td>   <td>广东省</td>   <td>CN111784845B</td>   <td>2023-05-30</td>   <td>本申请提供了一种基于人工智能的虚拟试穿方法、装置、服务器及存储介质,属于图像处理技术领域。本申请通过获取源衣物图像的至少一个第一关键点和至少一个第二关键点,根据第一关键点在源衣物图像中确定至少两个衣物图像块,实现对衣物图像中不同衣物区域的划分,进而根据第一关键点和第二关键点,分别对至少两个衣物图像块进行变形,可以根据不同衣物区域的变形程度来对衣物进行变形,以使合并得到的变形衣物图像比较符合衣物实际变形情况,再将变形衣物图像与目标人物图像进行融合,即可以得到试穿效果图像,从而可以缩小虚拟试穿效果和实际试穿效果的差距,提高虚拟试穿的效果,进而提高用户体验。</td>   <td>1.一种基于人工智能的虚拟试穿方法,其特征在于,所述方法包括：获取源衣物图像的至少一个第一关键点和至少一个第二关键点,所述至少一个第一关键点用于标识衣物边缘的源位置,所述至少一个第二关键点为基于目标人物图像对衣物进行变形后的所述至少一个第一关键点的目标位置；根据所述至少一个第一关键点,在所述源衣物图像中确定至少两个衣物图像块；根据所述至少一个第一关键点和至少一个第二关键点,分别对所述至少两个衣物图像块进行变形,得到至少两个变形衣物图像块；确定目标衣物图像块对应的变形衣物图像块,与相邻的衣物图像块对应的变形衣物图像块之间的缝隙区域,所述目标衣物图像块为包括衣物躯干区域的图像块；基于所述目标衣物图像块对应的移动参数,获取变形后的缝隙区域,所述移动参数为将所述第一关键点转移到对应的第二关键点所需的参数；将所述目标衣物图像块对应的变形衣物图像块、变形后的缝隙区域和所述相邻的衣物图像块对应的变形衣物图像块进行拼接,得到所述变形衣物图像；基于所述目标人物图像、所述变形衣物图像,通过神经网络模型,确定中间试穿效果图像和衣物融合掩膜,所述中间试穿效果图像为不包括衣物细节的试穿效果图像,所述衣物融合掩膜用于表示所述变形衣物图像的位置；对所述衣物融合掩膜和所述中间试穿效果图像进行卷积,得到第一卷积结果图像；基于所述衣物融合掩膜,确定目标形状掩膜,将所述目标形状掩膜和所述变形衣物图像进行卷积,得到第二卷积结果图像,所述目标形状掩膜用于指示除所述变形衣物图像所覆盖部位外的人体部位的位置；对所述第一卷积结果图像和所述第二卷积结果图像进行叠加,得到所述试穿效果图像。</td>   <td>G06T19/00;G06Q30/0601</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              王敏亦;              徐锐;                   杨鹏史       </td>   <td>中山大学</td>   <td>一种多因素对空气质量影响的评价方法和装置</td>   <td>广东省</td>   <td>CN113077089B</td>   <td>2023-05-30</td>   <td>本发明提供一种多因素对空气质量影响的评价方法和装置,所述方法包括：获取路网地理信息数据、路网交通流量数据、风向数据和空气质量数据；根据路网地理信息数据,获取路网道路组成、风向数据和空气质量监测站的位置关系；根据位置关系,对数据进行预处理,构建数据集；利用关联规则算法,设定最小支持度和最小置信度,迭代计算支持度和置信度,获得强关联规则；选择合适的强关联规则,输出对应的置信度作为不同路网道路组成、不同交通流量在不同风向环境下,对空气质量影响的评价结果。本发明对影响空气质量的多因素进行定量分析,获得不同路网道路组成、不同交通流量在不同风向环境下对空气质量影响的评价结果,为改善空气质量提供理论基础。</td>   <td>1.一种多因素对空气质量影响的评价方法,其特征在于,所述方法包括以下步骤：S1：获取试验区域内路网地理信息数据、路网交通流量数据、风向数据和空气质量监测站监测的空气质量数据；S2：根据所述路网地理信息数据,获取路网道路组成、风向数据和空气质量监测站的位置关系；所述路网地理信息数据包括路网道路组成的经纬度、空气质量监测站的经纬度、道路名称、路段ID和道路长度；所述路网交通流量数据包括道路名称、流量、车型和行驶方向；所述空气质量数据包括空气质量监测站点编号、空气质量指数、空气质量等级和空气污染物浓度；获得路网道路组成和空气质量监测站的位置关系的具体方法为：将路网道路组成和空气质量监测站的经纬度进行投影转化,获得路网道路组成在投影坐标系中的折点坐标P-1(x-1,y-1),…,P-n(x-n,y-n)和空气质量监测站在投影坐标系中的位置坐标P-s(x-s,y-s)；计算相邻的两个折点间距离,记为d-1,…,d-(n-1)；依次累加两个折点间距离,每当距离和大于距离阈值d-m时,划定一个间隔点,获得路段link-(1,2,)...,以及每个路段的起始点坐标P-a(x-a,y-a)和末尾点坐标P-b(x-b,y-b)；计算每个路段的中点坐标P-c(x-c,y-c),设定基准线,计算每个路段与空气质量监测站位置的夹角α-(1,2,)...和距离D-(1,2,)...；计算每个路段自身的夹角β-(1,2,)...；计算实时风向与空气质量监测站的夹角γ-(1,2,)...；S3：根据所述位置关系,对路网交通流量数据、路网道路组成、风向数据和空气质量数据进行预处理,将预处理后的数据作为数据集的元素,构建数据集；S4：设定最小支持度和最小置信度,利用关联规则算法迭代计算数据集中元素的支持度和置信度,保留所有置信度大于最小置信度的元素,获得强关联规则；所述强关联规则包括规则前项和规则后项；S5：确定强关联规则,所述强关联规则的规则前项为不同路网道路组成、不同交通流量和不同风向,规则后项为空气质量,输出该项强关联规则对应的置信度作为不同路网道路组成、不同交通流量在不同风向环境下,对空气质量影响的评价结果。</td>   <td>G06Q10/04;G06F16/29;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         石茜;              李学章;                   刘小平       </td>   <td>中山大学</td>   <td>一种基于深度学习和多目遥感影像的地物深度预测方法</td>   <td>广东省</td>   <td>CN113139661B</td>   <td>2023-05-30</td>   <td>本发明公开了一种基于深度学习和多目遥感影像的地物深度预测方法,包括以下步骤：S1：利用无人机实际拍摄获取待预测数据,利用仿真扩充方法获取训练数据,将待预测数据和训练数据进行预处理；S2：将预处理后的训练数据和待预测数据进行单应性变换；S3：将变换后的训练数据输入至深度学习模型中对模型进行训练；S4：将变换后的待预测数据输入至训练好的深度学习模型中,输出地物深度。本发明利用深度学习模型和多目遥感影像技术结合,充分利用深度学习的特征提取与模型泛化优势,提高了地物深度预测的效率和精度。</td>   <td>1.一种基于深度学习和多目遥感影像的地物深度预测方法,其特征在于,包括以下步骤：S1：利用无人机实际拍摄获取待预测数据,利用仿真扩充方法获取训练数据,将待预测数据和训练数据进行预处理；S2：将预处理后的训练数据和待预测数据进行单应性变换；S3：将变换后的训练数据输入至深度学习模型中对模型进行训练；深度学习模型训练过程为：数据读取层读取多目遥感影像及其单应性变换后的图像并进行数据的规范处理；数据的规范化处理包括：数据的卷积运算和归一化处理；数据处理层对规范化处理的数据中每一目影像进行Resnet运算,并将Resnet的中间结果层连接至中心轴层；将Resnet的中间结果层输出的结果进行拼接,组成拼接层,然后拼接层倒叙拼接作为中心轴层的输入,中心轴层输出与下一层的输入形状大小相同的结果；拼接层倒叙拼接具体方式：利用后一级的中心轴层输出结果连接拼接层的结果作为中心轴层的输入；中心轴层的运算包括：利用上采样变换统一输入的大小、卷积运算、归一化及relu运算；S4：将变换后的待预测数据输入至训练好的深度学习模型中,输出地物深度。</td>   <td>G06T17/00;G06N20/00;G06N3/08;G01C11/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              陈敏诗;                   周凡       </td>   <td>中山大学</td>   <td>基于图表示和改进Transformer的人体解析方法</td>   <td>广东省</td>   <td>CN113313173B</td>   <td>2023-05-30</td>   <td>本发明公开了一种基于图表示和改进Transformer的人体解析方法。本发明从高维的特征表示嵌入为低维的图特征,并以改进的Transformer来进行推理计算,捕捉上下文特征关系,生成新的图特征重新解码为精解析图,从而以高效的方式迭代训练整个模型得到最终的解析结果。本发明仅根据人体层次结构的先验知识,更高效率地进行推理计算；对图表示的人体部位特征进行推理,能够在后续的迭代推理中节约更多的计算成本；改进了Transformer的结构,对人体各个部位特征的上下文信息进行全局性提取和整合,从而全面地感知不同人体部位的关联度,使得解析结果的精度更高。</td>   <td>1.一种基于图表示和改进Transformer的人体解析方法,其特征在于,所述方法包括：第一步,从服装数据集输入原始人体图像和分割真值图,并做预处理；第二步,对所述预处理后的原始人体图像,使用DeeplabV3+网络生成粗解析图,并计算得到各个部位的分割掩码；第三步,根据人体层次结构的先验知识,定义出语义类别数目和标签层次结构信息,从而定义三种邻接矩阵,作为输入图-Transformer结构的掩膜；第四步,利用所述各个部位的分割掩码,以及利用所述语义类别数目和标签层次结构信息,将高维的所述粗解析图嵌入表示为图特征；第五步,利用所述图特征和所述三种邻接矩阵,通过图-Transformer结构对全局信息推理传播,计算出新的图特征；第六步,使用所述新的图特征和所述各个部位的分割掩码,计算出中间解析图,将其与所述粗解析图进行融合得到精解析图；第七步,利用所述预处理后的原始人体图像,在神经网络的编码解码结构中重复上述第二、四、五、六步进行训练,形成最终人体解析模型；第八步,输入待处理人体图像到所述最终人体解析模型中,得到需要的精解析图；其中,所述根据人体层次结构的先验知识,定义出语义类别数目和标签层次结构信息,从而定义三种邻接矩阵,作为输入图-Transformer结构的掩膜,具体为：根据人体层次结构,定义三种层次的语义标签结构,再根据该语义标签结构,将标签序号转换成图结点的邻接矩阵A～((j))∈R～(N×N),其中j∈[1,3]分别表示三个邻接矩阵,由此表示的无向图为G＝(V,E),语义结点V表示标签类别,即结点数等于人体部位的标签类别数N＝|V|,图的边E由类别间的关系决定,对于两个结点不存在边相连的矩阵元素定义为-inf,其余存在关系的位置设为0,使后续计算的注意力权重在(0,1)的数值范围内更新；其中,所述利用所述各个部位的分割掩码,以及利用所述语义类别数目和标签层次结构信息,将高维的所述粗解析图嵌入表示为图特征,具体为：输入所述各个部位的分割掩码,即所述通过平均池化和最大池化得到的二进制掩码,记为M～((k))∈R～(N×H×W),其中k为1、2时分别代表平均池化和最大池化操作的掩码,H,W分别为掩码图层的高、宽；将两种分割掩码分别与所述粗解析图执行矩阵乘法再相加,将此过程表示为映射即通过/&gt;得到嵌入表示的图特征Y∈R～(N×D),其中D是每个图结点的特征维数,所述图结点的数目为N,即为人体部位的标签类别数目；其中,所述利用所述图特征和所述三种邻接矩阵,通过图-Transformer结构对全局信息推理传播,计算出新的图特征,具体为：将所述图特征Y∈R～(N×D)作为图-Transformer的输入序列,设向量p＝[0,1,2,…,N-1]～T为各个人体部位的位置编码,其中N为人体部位的标签类别数,将所述位置编码与所述图特征做级联操作,组成图-Transformer的新的输入序列；将所述新的输入序列通过多头注意力机制的部分计算,得到初始的兼容性得分,再将所述三种邻接矩阵作为掩膜输入,与初始的兼容性得分相加作为一种负向约束,以抑制不存在关系的结点的权重,从而得到更新的兼容性得分；将所述更新的兼容性得分做softmax归一化处理,得到0到1之间的注意力掩码；计算所述图结点之间的特征向量的余弦相似度,从而得出图结点之间的关系矩阵B～((i))∈R～(N×N),其中i∈[1,3]分别表示三个关系矩阵；将所述关系矩阵和所述注意力掩码做矩阵乘法,得到三种中间图特征；将所述三种中间图特征与所述邻接矩阵A～((j))∈R～(N×N)计算L1损失；将所述三种中间图特征做级联操作,得到融合图特征,融合后进行非线性变换,得到增强的图特征,其维度与输入图-Transformer时一致,迭代计算上述步骤一定次数,最终输出为新的图特征Y′∈R～(N×D)；其中,所述使用所述新的图特征和所述各个部位的分割掩码,计算出中间解析图,将其与所述粗解析图进行融合得到精解析图,具体为：将所述二进制分割掩码M～((k))∈R～(N×H×W)与所述新的图特征Y′∈R～(N×D)做矩阵乘法,由此将图特征中每一个人体标签类别的图表示的特征向量转换为特征图,得到中间解析图；对所述中间解析图做1*1的卷积操作,将其通道数设定为256个,以便与粗解析图进行相加融合,得到最终的精解析图Z′∈R～(C×H×W),其中C是通道数。</td>   <td>G06V10/764;G06V40/10;G06V10/20;G06V10/32;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵莹;                   杨羽菲       </td>   <td>中山大学</td>   <td>一种游客行为数据提取方法</td>   <td>广东省</td>   <td>CN115577190B</td>   <td>2023-05-30</td>   <td>本申请属于旅游数据处理技术领域,公开了一种游客行为数据提取方法。该方法包括：获取旅游景区签到数据,进行结构化处理,得到签到时空数据库；从旅游网站获取第一游记样本,对其中游记文本的时间信息和地点信息进行标记,得到标记旅游时空路径,基于标记方法,形成初步解析模块；获取第二游记样本,运行初步解析模块得到第二游记样本的解析旅游时空路径,基于解析旅游时空路径对初步解析模块进行完善,得到最终解析模块；将最终解析模块应用在预设时间窗口和预设目的地范围的游记样本中,得到游记时空数据库；基于所述签到时空数据库和所述游记时空数据库,得到可视化的游客时空行为路径图。为后续的旅游领域的专利分析提供结构化的数据。</td>   <td>1.一种游客行为数据提取方法,其特征在于,所述方法包括：获取旅游景区签到数据,并对所述旅游景区签到数据进行结构化处理,得到基于所述旅游景区签到数据的签到时空数据库；从旅游网站获取第一游记样本,对所述第一游记样本中每一篇游记文本的时间信息和地点信息进行标记,得到标记旅游时空路径,基于所述标记旅游时空路径的标记方法,形成初步解析模块；获取第二游记样本,运行所述初步解析模块得到所述第二游记样本的所有游记文本的解析旅游时空路径,基于解析旅游时空路径对所述初步解析模块进行完善,得到最终解析模块；将所述最终解析模块应用在预设时间窗口和预设目的地范围的游记样本中,得到基于游记的游记时空数据库；基于所述签到时空数据库和所述游记时空数据库构建游客流动行为数据库,基于所述游客流动行为数据库得到可视化的游客时空行为路径图；其中,所述从旅游网站获取第一游记样本,对所述第一游记样本中每一篇游记文本的时间信息和地点信息进行标记,得到标记旅游时空路径,基于所述标记旅游时空路径的标记方法,形成初步解析模块的步骤具体为：识别所述每一篇游记文本的时间关键词,并按照精确日期、精确时间、模糊时间以及相对时间来标记时间关键词,将所述时间关键词放置到时间词库中,并以精确日期和精确时间作为分割点将所述游记文本分割成文本段；识别所述每一篇游记文本的地点关键词,并按照精确地点、模糊地点以及关联地点来标记所述文本段的地点关键词,将所述地点关键词放置到地点词库中；基于所述时间关键词和地点关键词的提取方法,按照时间顺序书写和地点变化的逻辑来构建初步解析模块。</td>   <td>G06F16/9537;G06F16/9532;G06F16/957;G06F40/117;G06F40/205</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈川;              刘有明;              林昊;              郑子彬;              邬稳;                   王福海       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>三元组的实体确认方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN116186170A</td>   <td>2023-05-30</td>   <td>本申请涉及一种三元组的实体确认方法、装置、计算机设备、存储介质和计算机程序产品。方法包括：获取知识图谱中满足目标条件的多个链式规则,得到包括各链式规则的规则集；使用知识图谱表征学习和逻辑规则对规则集建模,得到可解释的推理模型；从知识图谱中获取包含已知实体和未知实体的目标三元组,使用可解释的推理模型确定与未知实体对应的候选实体；从知识图谱中获取与已知实体为同一三元组的真实实体,并基于真实实体计算候选实体的得分；根据候选实体的得分对可解释的推理模型进行优化,得到可解释的优化推理模型,并基于可解释的优化推理模型,从候选实体中确定与已知实体构成目标三元组的目标实体。采用本方法可得到三元组中缺失的实体。</td>   <td>1.一种三元组的实体确认方法,其特征在于,所述方法包括：获取知识图谱中满足目标条件的多个链式规则,得到包括各所述链式规则的规则集；使用知识图谱表征学习和逻辑规则对所述规则集进行建模,得到可解释的推理模型；从所述知识图谱中获取包含已知实体和未知实体的目标三元组,使用所述可解释的推理模型确定与所述未知实体对应的候选实体；从所述知识图谱中,获取与所述已知实体属于同一三元组的多个真实实体,并基于各所述真实实体计算每一所述候选实体各自的得分；根据每一所述候选实体的得分对所述可解释的推理模型进行优化,得到可解释的优化推理模型,并基于所述可解释的优化推理模型,从所述候选实体中确定与所述已知实体构成所述目标三元组的目标实体。</td>   <td>G06F16/28;G06N5/04;G06N5/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              黄进波;              林昊;              蔡倬;              赵山河;                   张文锋       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>类别识别模型生成方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN116186708A</td>   <td>2023-05-30</td>   <td>本申请涉及一种类别识别模型生成方法、装置、计算机设备和存储介质。所述方法包括：获取原始网络请求数据,对原始网络请求数据进行文本字段扩充,得到目标网络请求数据；从目标网络请求数据中选取目标网络字段数据,计算目标网络字段数据中各个词对应的目标词频和目标逆向文件频率；基于所述各个词对应的目标词频和目标逆向文件频率,得到目标词频特征；对目标网络请求数据中的各个网络字段进行类别编码,得到各个网络字段对应的目标类别特征；将目标词频特征和目标类别特征进行融合,得到目标文本特征；基于目标文本特征和目标网络请求数据对初始决策树模型进行训练,得到目标类别识别模型。采用本方法能够提高检测与识别网络攻击类别的效率。</td>   <td>1.一种类别识别模型生成方法,其特征在于,所述方法包括：获取原始网络请求数据,对所述原始网络请求数据进行文本字段扩充,得到目标网络请求数据；从所述目标网络请求数据中选取目标网络字段数据,计算所述目标网络字段数据中各个词对应的目标词频和目标逆向文件频率；将所述目标网络字段数据中各个词对应的目标词频和目标逆向文件频率进行融合,得到中间词频特征矩阵；对所述中间词频特征矩阵进行降维处理,得到目标词频特征；对所述目标网络请求数据中的各个网络字段进行类别编码,得到所述各个网络字段对应的目标类别特征；将所述目标词频特征和所述目标类别特征进行融合,得到目标文本特征；基于所述目标文本特征和所述目标网络请求数据对初始决策树模型进行训练,得到目标类别识别模型,所述目标类别识别模型用于基于待识别网络请求数据得到目标网络攻击类别。</td>   <td>G06F21/57;G06F18/2431;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭应林;              刘懿梅;              陈美宁;              陈利;                   邓小武       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种锥形束CT图像配准结果评价方法及系统</td>   <td>广东省</td>   <td>CN116188377A</td>   <td>2023-05-30</td>   <td>本发明公开了一种锥形束CT图像配准结果评价方法及系统,通过获取计划CT图像与CBCT图像的配准数据,配准数据包括计划靶区体积、靶区体积、计划CT体积和治疗前摆位CBCT图像中相应结构的体积,根据所述计划靶区体积和靶区体积得到计划靶区体积和靶区体积的覆盖率,根据计划CT体积和治疗前摆位CBCT图像中相应结构的体积得到相似性指数,通过相似性指数、靶区覆盖因子、危机器官安全因子、权重因子和各个器官的配准效果因子构建综合配准因子评价模型,将配准数据代入综合配准因子评价模型中得到综合配准得分,本方法通过设立和计算了不同解剖结构的配准权重因子,形成了可以量化评分的加权综合评价数学模型对配准结果进行评价,可以提高临床配准效果。</td>   <td>1.一种锥形束CT图像配准结果评价方法,其特征在于,包括：获取计划CT图像与CBCT图像的配准数据,其中,所述配准数据包括计划靶区体积、靶区体积、计划CT体积和治疗前摆位CBCT图像中相应结构的体积；根据所述计划靶区体积和靶区体积得到计划靶区体积和靶区体积的覆盖率,根据所述计划CT体积和治疗前摆位CBCT图像中相应结构的体积得到相似性指数；通过相似性指数、靶区覆盖因子、危机器官安全因子、权重因子和各个器官的配准效果因子构建综合配准因子评价模型,将所述配准数据代入所述综合配准因子评价模型中得到综合配准得分。</td>   <td>G06T7/00;G06T7/62;G06T7/32</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高智凡;              张贺晔;                   郑晓鹏       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于类激活映射特征融合的超声颈动脉内中膜分割方法</td>   <td>广东省</td>   <td>CN116188403A</td>   <td>2023-05-30</td>   <td>本发明公开了一种基于类激活映射特征融合的超声颈动脉内中膜分割方法,该方法包括：获取待测CAUS图像并将待测CAUS图像输入至预构建的分割模型；基于特征提取网络对待测CAUS图像进行特征提取,得到特征关系图像信息；基于区域激活迭代生成模块,根据特征关系图像信息生成激活地图并激活全局对象区域；基于特征生成模块,根据全局对象区域生成局部特征和全局特征；基于特征融合模块,将全局特征和局部特征进行融合,得到最终分割图。通过使用本发明,能够全自动的快速精确的分割出颈动脉内中膜边界。本发明作为一种基于类激活映射特征融合的超声颈动脉内中膜分割方法,可广泛应用于图像分割领域。</td>   <td>1.基于类激活映射特征融合的超声颈动脉内中膜分割方法,其特征在于,包括以下步骤：获取待测CAUS图像并将待测CAUS图像输入至预构建的分割模型；所述预构建的分割模型包括特征提取网络、区域激活迭代生成模块、特征生成模块和特征融合模块；基于特征提取网络对待测CAUS图像进行特征提取,得到特征关系图像信息；基于区域激活迭代生成模块,根据特征关系图像信息生成激活地图并激活全局对象区域；基于特征生成模块,根据全局对象区域生成局部特征和全局特征；基于特征融合模块,将全局特征和局部特征进行融合,得到最终分割图。</td>   <td>G06T7/00;G06V10/26;G06V10/44;G06V10/80;G06V10/82;G06N3/048</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐瑞华;              骆卉妍;              李超峰;              贺龙君;              徐国梁;              经秉中;              邓一术;                   陈浩华       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种上消化道内镜视频肿瘤诊断关键帧的提取方法及装置</td>   <td>广东省</td>   <td>CN116189050A</td>   <td>2023-05-30</td>   <td>本发明公开了一种上消化道内镜视频肿瘤诊断关键帧的提取方法及装置,包括：将待处理的内镜视频时序帧输入抖动消除模型,得到第一时序帧；将所述第一级时序帧输入至预设的肿瘤预测模型,最后输出得到包含预测结果的第二级时序帧；将所述预测结果连接成第一预测曲线,并将所述第一预测曲线输入至平滑模型,得到平滑后的第二预测曲线；根据第二预测曲线找出若干个符合预设条件的关键时间点,并从所述第二级时序帧中提取出所述若干个关键时间点对应的肿瘤关键帧图像以及对应的肿瘤预测概率和肿瘤区域。本发明能减少内镜视频中噪声对肿瘤诊断关键帧提取的干扰,提升内镜AI辅助诊断的可靠性。</td>   <td>1.一种上消化道内镜视频肿瘤诊断关键帧的提取方法,其特征在于,包括：将待处理的内镜视频时序帧输入抖动消除模型,得到消除抖动后的第一时序帧；其中,所述抖动消除模型利用仿射变换原理构建而成；将所述第一级时序帧输入至预设的肿瘤预测模型,以使所述肿瘤预测模型依次对所述第一级时序帧进行异常区域检测、噪声去除、异常区域修复以及图像编码分割预测后,得到包含预测结果的第二级时序帧；其中,所述肿瘤预测模型由异常区域检测UNet模型、图像修复MAE模型和肿瘤预测Transformer模型组合而成,所述预测结果为所述第一级时序帧中的每一帧图像内含有肿瘤区域的预测概率值；将所述预测结果连接成第一预测曲线,将所述第一预测曲线输入至平滑模型以使所述第一预测曲线的拟合残差值最小化,得到平滑后的第二预测曲线；根据第二预测曲线找出若干个符合预设条件的关键时间点,并从所述第二级时序帧中提取出所述若干个关键时间点对应的肿瘤关键帧图像以及对应的肿瘤预测概率和肿瘤区域。</td>   <td>G06V20/40;G06V10/62;G06V10/30;G06V10/34;G06V10/24;G06V10/82;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              方至钰;              吴绪芃;                   李博洋       </td>   <td>中山大学</td>   <td>一种基于车路协同的视野盲区行人检测算法</td>   <td>广东省</td>   <td>CN116189138A</td>   <td>2023-05-30</td>   <td>本发明公开了一种基于车路协同的视野盲区行人检测方法,路侧和车侧均设有相机和激光雷达,其中车侧设备包括相对固定的车载激光雷达车载相机,路侧设备包括相对固定的路侧激光雷达和路侧相机,包括坐标系统一、行人检测方法以及车路协同融合。本发明不仅结合了激光雷达以及相机进行行人检测从而使得点云数据补充了图像数据欠缺的深度信息和盲区,而图像数据补充了点云近处的盲区和远处数据稀疏的缺陷,在感知上形成互补,而且本发明还在路侧和车侧均设置激光雷达和相机并将两侧设备得到的数据进行配准转换,从而实现车路协同的超视距感知,补充了车辆的视野盲区感知数据。</td>   <td>1.一种基于车路协同的视野盲区行人检测方法,其特征在于,路侧和车侧均设有相机和激光雷达,其中车侧设备包括相对固定的车载激光雷达车载相机,路侧设备包括相对固定的路侧激光雷达和路侧相机,包括坐标系统一、行人检测方法以及车路协同融合,其中,坐标系统一包括如下步骤：S1.1：使用标定工具将位于同一侧的相机和激光雷达进行联合标定,得到相机的内部参考矩阵K和相机与激光雷达之间的外部参考矩阵S1.2：激光雷达采集点云P,其中车载激光雷达采集的点云为P1,路侧激光雷达采集的点云为P2,分别对点云P1和P2进行预处理,预处理包括点云去噪、点云下采样、点云地面分割、感兴趣区域提取,从而得到可以用于配准的点云P1-(roi)和P2-(roi)。S1.3：车辆驶入路侧设备的通信范围后,使用车辆GPS和IMU确定车辆位姿信息,通信得到路侧设备位姿信息,计算出转换矩阵的初始值T-(GPS),以T-(GPS)为初始值,将经过预处理的点云P1-(roi)和P2-(roi)进行初始配准,得到转换矩阵T-(SAC),以T-(SAC)为初始值,进行精确配准得到首次坐标系转换矩阵T-(init)；S1.4：在首次坐标系转换矩阵T-(init)的基础上,估计车辆相对首次配准位置的运动则根据坐标转换关系连续输出转换矩阵/&gt;行人检测包括如下步骤：S2.1：车载相机和路侧相机分别采集图像,对相机获取的图像进行行人检测,得到2D平面检测框,根据内部参考矩阵K和外部参考矩阵将点云P投影到图像坐标系内,并统计落在图像坐标系中2D平面检测框范围内的点云集合P-(detect)；S2.2：对点云集合P-(detect)内的点进行聚类,选取点数最多的一类作为行人点云P-(person),并生成点云包围盒序列B-1；S2.3：对点云P进行3D行人检测,并生成行人点云包围盒序列B-2；S2.4：将上述两种方法形成的行人点云包围盒序列B-1和B-2使用进行匹配,并采用加权平均的方法得到最终的行人包围盒序列B-(fusion)；S2.5：分别对点云P1和P2作为输入的点云P进行步骤S2.1至S2.4的处理,分别得到车侧设备处理形成的行人包围盒序列B1-(fusion)和路侧设备处理形成的行人包围盒序列B2-(fusion)；车路协同融合包括如下步骤：S3：根据转换矩阵将路侧设备处理形成的行人点云包围盒B2-(fusion)转换到车辆坐标系下,则行人包围盒序列B1-(fusion)和经过换矩阵/&gt;转换后的行人点云包围盒B2-(fusion)即为车辆视角下行人检测结果。</td>   <td>G06V20/58;G06V10/25;G06V10/764;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              莫一凡;              章杨清;              林昊;              蔡倬;              赵山河;                   张鹏       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>对象信用模型训练方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN116167073A</td>   <td>2023-05-26</td>   <td>本申请涉及一种对象信用模型训练方法、装置、计算机设备、存储介质和计算机程序产品。所述方法包括：获取至少两个对象对应的终端所反馈的候选梯度；基于各个对象分别对应的候选梯度分别调整初始对象信用模型,得到各个对象分别对应的中间对象信用模型；获取各个对象分别对应的测试数据,将各个测试数据分别输入对应的中间对象信用模型,得到各个对象分别对应的参考模型损失；基于各个参考模型损失,从各个候选梯度中确定目标梯度；基于目标梯度,调整初始对象信用模型的初始模型参数,得到更新对象信用模型；更新对象信用模型用于预测对象的信用分数。采用本方法能够提高模型训练隐私安全性。</td>   <td>1.一种对象信用模型训练方法,其特征在于,应用于服务器,所述方法包括：获取至少两个对象对应的终端所反馈的候选梯度；所述候选梯度是终端将对象在本地的训练数据输入初始对象信用模型得到的,所述初始对象信用模型是终端从服务器下载的；基于各个对象分别对应的候选梯度分别调整所述初始对象信用模型,得到各个对象分别对应的中间对象信用模型；获取所述各个对象分别对应的测试数据,将各个测试数据分别输入对应的中间对象信用模型,得到所述各个对象分别对应的参考模型损失；基于各个参考模型损失,从各个候选梯度中确定目标梯度；基于所述目标梯度,调整所述初始对象信用模型的初始模型参数,得到更新对象信用模型；所述更新对象信用模型用于预测对象的信用分数。</td>   <td>G06F21/62;G06F21/71;G06Q50/26;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡继华;              文梓豪;                   袁均良       </td>   <td>中山大学</td>   <td>一种地铁客流量预测方法</td>   <td>广东省</td>   <td>CN111027673B</td>   <td>2023-05-26</td>   <td>本发明涉及交通预测领域,更具体的,涉及一种地铁客流量预测方法。本发明基于门控循环单元GRU模型来对地铁人流量数据进行预测；然后通过随机搜索及贝叶斯优化方法,实现网络模型超参数自动调整,尽量逼近最佳参数,获得准确的人流量预测信息,本发明主要在软件平台实现,不需要高成本的投资建设费用,不需要耗费大量的人力。本发明适用于大规模城域网中的人流量的预测。本发明可为地铁当局提供参考,有效地将有限的资源分配给过度拥挤的区域,改善地铁的服务。</td>   <td>1.一种地铁客流量预测方法,其特征在于,包括以下步骤：步骤S1：获取地铁客流数据,对地铁客流数据进行特征分析,得到影响地铁客流数据的影响因素；步骤S2：对影响因素进行数字化处理,得到影响因素数据；步骤S3：基于影响因素数据得到最终的地铁客流数据,将最终的地铁客流数据划分为训练数据集、测试集以及验证集；步骤S4：基于门控循环单元GRU构建自动调优循环神经网络；所述的自动调优循环神经网络中包括输入层,特征提取层以及输出层；所述特征提取层中一共有n个GRU单元,在GRU单元中,首先对训练数据集进行前向传播处理,之后再进行反向传播,更新网络中每一层的参数,并输出最后的结果；对训练数据集进行前向传播的具体过程如下：首先,对训练数据集进行前向传播,具体的计算过程如下：r-t＝σ(W-r·[h-(t-1),x-t])                                               (4)z-t＝σ(W-z·[h-(t-1),x-t])                                               (5)                                    y-t＝σ(W-o·h-t)                                                   (8)其中,h-t为t时刻的输出,x-t为t时刻的输入,r代表重置门,z代表更新门,代表候选信息,σ表示sigmod函数；在重置门中,r-t为重置门的输出,W-r为重置门的权值；在更新门中,z-t为更新门的输出,W-z为更新门的权值；在候选信息中,为候选信息的权值,W-o为输出的权值；候选信息梯度：                  更新门梯度:                  重置门梯度：                  往前面步反传时间轴上的误差信号：                  其中,L为损失函数,W-(hz)和W-(xz)分别为更新门的参数矩阵,为t时刻备选的用来更新的内容,/&gt;和/&gt;为候选信息的参数矩阵,上标T代表矩阵的转置操作；/&gt;对训练数据集进行反向传播的具体过程如下：候选信息相关：                                                      更新门相关：                                                      重置门相关：                                                      其中L为损失函数,W-(hz)和W-(xz)分别为更新门的参数矩阵,和/&gt;分别为候选信息的参数矩阵,W-(hr)和W-(xr)为别为遗忘门的参数矩阵,上标T代表矩阵的转置操作；步骤S5：将训练数据集输入到自动调优循环神经网络中对自动调优循环神经网络进行训练,得到训练好的自动调优循环神经网络；步骤S6：将测试集输入到训练好的自动调优循环神经网络中,得到地铁客流数据的预测结果；步骤S7：使用随机搜索及贝叶斯优化方法,对训练好的自动调优循环神经网络进行优化,得到优化后的自动调优循环神经网络；步骤S8：通过均方根误差公式以及平均绝对百分比误差公式对优化后的自动调优循环神经网络进行评价,并使用验证集验证优化后的自动调优循环神经网络的准确性。</td>   <td>G06Q10/04;G06Q50/26;G06N3/0442;G06N3/048;G06N3/084;G06N3/0985</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   罗幸荣       </td>   <td>中山大学</td>   <td>一种纤维级织物实时渲染方法、系统及终端</td>   <td>广东省</td>   <td>CN110969692B</td>   <td>2023-05-26</td>   <td>本申请公开了一种纤维级织物实时渲染方法、系统及终端,对纤维级织物的纱线控制点进行曲线插值和预计算；对曲线插值和预计算后的所述纱线控制点进行遍历并渲染得到深度贴图；生成所述纤维级织物的核心纤维与常规纤维；对所述核心纤维与常规纤维进行遮挡剔除；对所述深度贴图中的纤维级织物进行阴影和光照计算获得渲染结果。对纤维级织物的纱线控制点进行预计算,由前往后对纱线控制点进行遍历并渲染获得初步的深度贴图,然后进行核心纤维和常规纤维生成,最后进行遮挡剔除和亮度处理,进而保证了在不丢失外观细节的前提下进一步提升了渲染效率。</td>   <td>1.一种纤维级织物实时渲染方法,其特征在于,所述方法包括：对纤维级织物的纱线控制点进行曲线插值和预计算；对曲线插值和预计算后的所述纱线控制点进行遍历并渲染得到深度贴图；生成所述纤维级织物的核心纤维与常规纤维；对所述核心纤维与常规纤维进行遮挡剔除；对所述深度贴图中的纤维级织物进行阴影和光照计算获得渲染结果；其中依据过程式纱线几何模型,利用渲染管线对核心纤维与常规纤维进行生成；过程式纱线几何模型在纱线空间中对模型进行构建；纱线空间是将纱线中心控制点与Z轴的正半轴进行对齐,对于第k个纱线中心控制点,表示为：                  对于给定的单纱中心控制点,几何模型在相应的XOY平面对单纱中心控制点进行求解；纱线的第i根单纱的中心控制点表示为：                  其中α为旋转控制因子,R～(ply)为测定的单纱半径,θ-i～(ply)则为第i根单纱的初始角度；将单纱控制中心与Z轴的正半轴进行对齐,单纱的第i根纤维中心控制点表示为：                  与测定的单纱半径不同,纤维的半径是一个关于旋转角度θ的函数：                  其中R-i与θ-i为纤维的初始半径与角度,通过根据给定的分布进行拒绝采样得到；纤维按种类细分为常规纤维、环形纤维与自由纤维,在缠绕周期中通过修改参数R-(max)统一的进行建模；顶点着色器输入的纱线控制曲线,细分着色器将其细分为64根纤维,并依据纱线中的单纱数量进行平均分配；每根单纱中的第一条纤维结合单周期单纱的法向量贴图、高度贴图、方向贴图,被几何着色器扩展为朝向视点的核心纤维面片,其余纤维以微小的宽度被几何着色器相应的扩展,使得纤维级织物具有鲜明的毛绒感。</td>   <td>G06T15/40;G06T15/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王嘉辉;              李文湧;              考塞尔·库热西;              麦麦提艾力·麦麦提;              陈泽鹏;              蔡志岗;              张佰君;                   江灏       </td>   <td>中山大学</td>   <td>一种基于深度卷积生成对抗网络的弱光散斑成像恢复方法</td>   <td>广东省</td>   <td>CN113129232B</td>   <td>2023-05-26</td>   <td>本发明提供一种基于深度卷积生成对抗网络的弱光散斑成像恢复方法,包括以下步骤：S1：获取点光源的散斑PSF；S2：获取未知物的散斑I；S3：对未知物的散斑I和点光源的散斑PSF实施图像灰阶自适应非线性归一化得到S4：根据散射体成像系统的最近似噪信比和所述归一化后的点光源散斑对所述归一化后的未知物散斑实施解卷积操作得到未知物恢复图像O-(tem)；S5：将所述未知物恢复图像O-(tem)输入至预训练好的深度卷积生成对抗网络模型,得到未知物最终重建图像O。本发明能够从信息光学、自适应优化以及深度学习出发构建完整闭环的散斑恢复成像方法,不仅增强了解卷积散斑成像的能力,还大大提高了深度学习在散斑成像恢复中的泛化性。</td>   <td>1.一种基于深度卷积生成对抗网络的弱光散斑成像恢复方法,其特征在于,包括以下步骤：S1：获取点光源的散斑PSF；S2：获取未知物的散斑I；S3：对未知物的散斑I和点光源的散斑PSF实施图像灰阶自适应非线性归一化得到S4：根据散射体成像系统的最近似噪信比和所述归一化后的点光源散斑/&gt;对所述归一化后的未知物散斑/&gt;实施解卷积操作得到未知物恢复图像O-(tem)；S5：将所述未知物恢复图像O-(tem)输入至预训练好的深度卷积生成对抗网络模型,得到未知物最终重建图像O；步骤S3中所述对未知物的散斑I和点光源的散斑PSF实施图像灰阶自适应非线性归一化得到具体为：                  式中,I[i,j]分别表示散斑/&gt;I中坐标(i,j)处像素点的灰阶值,min(I)表示散斑I中最小的灰阶值,max(I)表示散斑I中最大的灰阶值,其中1≤i≤M,1≤j≤N,M为I的宽度,N为I的高度,γ为幂；          的计算方法与/&gt;的计算方法相同；所述γ的值由以下步骤获取：S3.1：获取标定物的散斑I-0；S3.2：获取标定物的原始物象O-(true)；S3.3：设定γ初始值γ-0＝1.5；S3.4：使用γ-0对所述标定物的散斑I-0和所述点光源的散斑PSF实施图像灰阶非线性归一化得到S3.5：根据所述归一化后的点光源散斑对所述归一化后的标定物散斑/&gt;实施解卷积操作得到恢复图像O-γ；S3.6：使用图像质量评价函数以标定物的物象O-(true)作为参考图像,对所述恢复图像O-γ进行图像质量评分；S3.7：根据所述计算得到的图像质量评分对所述γ值进行调整,判断所述计算得到的图像质量评分是否达到极大值,若否,则更新γ值,并回到步骤S3.4,若是,则输出该γ值；步骤S4中所述散射体成像系统的最近似噪信比由以下步骤获取：S4.1：获取标定物的散斑I-0；S4.2：获取标定物的物象O-(true)；S4.3：设定初始的散射体成像系统噪信比k值为k-0；S4.4：根据所述散射体成像系统噪信比k值和所述点光源散斑PSF对所述标定物散斑I-0实施解卷积操作得到恢复图像O-k；S4.5：使用图像质量评价函数以标定物的物象O-(true)作为参考图像,对所述恢复图像O-k进行图像质量评分；S4.6：根据计算得到的图像质量评分对所述噪信比k值进行调整,判断所述计算得到的图像质量评分是否达到极大值,若否,则更新k值,并回到步骤S4.4,若是,则以此时的噪信比k值作为所述散射体成像系统的最近似噪信比并输出。</td>   <td>G06T5/00;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾怡瑞;              马争鸣;              李冠彬;                   林倞       </td>   <td>中山大学</td>   <td>一种对抗鲁棒的图像显著性检测方法及系统</td>   <td>广东省</td>   <td>CN111539916B</td>   <td>2023-05-26</td>   <td>本发明公开了一种对抗鲁棒的图像显著性检测方法及系统,该方法包括：步骤S1,在原始图像上,针对显著性检测的对抗攻击,基于迭代梯度的方法生成针对显著性检测的对抗攻击样本作为系统的输入图像；步骤S2,以步骤S1中得到的对抗样本作为输入,使用基于能量的生成模型重建输入图像,利用神经网络近似能量函数进行似然建模,生成去除对抗噪声的重建图像；步骤S3,将步骤S2得到的重建图像作为骨干网络的输入并产生密集标记的显著图,本发明可提高现有密集标记方法的鲁棒性并维持效率。</td>   <td>1.一种对抗鲁棒的图像显著性检测方法,包括如下步骤：步骤S1,在原始图像上,针对显著性检测的对抗攻击,基于迭代梯度的方法生成针对显著性检测的对抗攻击样本作为系统的输入图像；步骤S2,以步骤S1中得到的对抗样本作为输入,使用基于能量的生成模型重建输入图像,利用神经网络近似能量函数进行似然建模,生成去除对抗噪声的重建图像；步骤S3,将步骤S2得到的重建图像作为骨干网络的输入并产生密集标记的显著图；步骤S2进一步包括：步骤S201,使用神经网络近似能量函数,从能量函数定义的概率分布中产生样本；步骤S202,在重建图像时进一步引入噪声模型；步骤S203,沿最大化对数似然的方向训练近似能量函数的神经网络参数,能量模型完成训练后,从能量函数梯度中采样的重建图像也逐渐靠近原输入图像；于步骤S201中,采用朗之万动力学的迭代精炼过程,利用能量函数的梯度进行采样从而重建输入图像；于步骤S202中,采用朗之万动力学来增加梯度下降的扰动：                  其中,I-R为当前重建图像,I-(R+1)为下一步更新的图像,对应于学习率α,/&gt;代表神经网络F的梯度,∈是噪声强度,N(0,1)代表标准正太分布的高斯噪声。</td>   <td>G06V10/46;G06V10/82;G06V10/764;G06N3/0464;G06N3/0475;G06N3/094;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁耀华;                   方艳梅       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的重采样图像检测方法</td>   <td>广东省</td>   <td>CN111080587B</td>   <td>2023-05-26</td>   <td>本发明公开了一种基于卷积神经网络的重采样图像检测方法,包括以下步骤：将检测图像按照α进行分割,得到若干个子图像；将全部的子图像的颜色通道进行归一化处理；根据检测图像构建重采样数据库；重采样数据库通过卷积神经网络进行训练优化；归一化后子图像根据优化后的重采样数据库进行筛选；筛选后的子图像通过阈值法进行判断,若不小于阈值,则认定检测图像存在重采样操作；若小于阈值,则认定检测图像不存在重采样操作。本发明通过卷积网络进行特征提取,使用残差的思想络进行设计整体网络结构,摒弃了传统人工设置初始化参数,通过动量的技术方法优化卷积神经网络中的参数,达到全局最优的检测效果,防止卷积神经网络出现局部最优的情况。</td>   <td>1.一种基于卷积神经网络的重采样图像检测方法,其特征在于,包括以下步骤：将检测图像按照α进行分割,得到若干个子图像,所述的α是人为预设值；将全部的子图像的颜色通道进行归一化处理；所述的“将全部的子图像的颜色通道进行归一化处理”包括以下内容：将全部的子图像的颜色通道减去β进行归一化处理,所述的β是人为预设值；根据检测图像构建重采样数据库；所述的“根据检测图像构建重采样数据库”包括以下子步骤：将检测图像按照γ进行重采样,得到重采样图像,所述的γ是人为预设的重采样因子；根据子图像的大小分别对检测图像和重采样图像进行分割,得到检测图像的分割图像和重采样图像的分割图像；根据检测图像的分割图像和重采样图像的分割图像构成重采样数据库的训练集和测试集；重采样数据库通过卷积神经网络进行训练优化；所述的“重采样数据库通过卷积神经网络进行优化”中的卷积神经网络包括以下内容：卷积神经网络包括一层卷积层、三层残差层、一层平均池化层和两层全连接层；所述的三层残差层由两层卷积层串联后再与另一个卷积层并联组成,并联的卷积层作为残差映射；归一化后子图像根据优化后的重采样数据库进行筛选；筛选后的子图像通过阈值法进行判断,若不小于阈值,则认定检测图像存在重采样操作；若小于阈值,则认定检测图像不存在重采样操作；所述的“筛选后的子图像通过阈值法进行判断”包括以下内容：根据检测图像的子图像中重采样的数量和检测图像的子图像总数量计算比值,通过比值与阈值δ相比较若不小于阈值,则认定检测图像存在重采样操作；若小于阈值,则认定检测图像不存在重采样操作。</td>   <td>G06T7/00;G06T7/11;G06T7/90;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              王金鹏;              蔡佳辉;              林佳玲;                   陈嘉敏       </td>   <td>中山大学;广州智慧城市发展研究院</td>   <td>一种基于投票的时序关联模型的视频动作识别方法</td>   <td>广东省</td>   <td>CN111325149B</td>   <td>2023-05-26</td>   <td>本发明涉及计算机视觉领域,公开了一种基于投票的时序关联模型的视频动作识别方法,其包括步骤：S1、对卷积特征图进行空间池化；S2、使用大小为1的卷积核对执行了空间池化后的卷积特征图进行通道压缩；S3、使用1维的时域卷积层的三路分支对经过通道压缩后输出的卷积特征图进行不同膨胀率的一维时间卷积运算；S4、经过时序池化,将空间池化后的卷积特征图降维为特征向量；S5、将三路分支的预测结果分别相加,作为最后的分类结果。本发明的方法在对特征图进行特征提取时,可以捕获时间信息,而且在训练过程中能够快速收敛,同时能够在网络的任意深度集成,在较高的提升了模型表征能力的基础上,还很好地控制了计算开销和模型复杂度。</td>   <td>1.一种基于投票的时序关联模型的视频动作识别方法,其特征在于,包括以下步骤：S1、对卷积特征图进行空间池化；S2、使用大小为1的卷积核对执行了空间池化后的卷积特征图进行通道压缩；S3、使用1维的时域卷积层的三路分支对经过通道压缩后输出的卷积特征图进行不同膨胀率的一维时间卷积运算；S4、经过时序池化,将空间池化后的卷积特征图降维为特征向量；S5、将三路分支的预测结果分别相加,作为最后的分类结果；其中,在所述步骤S1中,卷积特征图的形状表示为：,其中,分别表示特征通道的数量、时间维度、高度、宽度,在将卷积特征图输入到空间池中进行池化操作后,获得特征维度为/&gt;的特征图,在使用大小为1的卷积核对执行了空间池化后的卷积特征图进行通道压缩后,获得特征维度为/&gt;的特征图,其中/&gt;表示类的数量,参数量为/&gt;；其中,在所述步骤S3中,所述的时域卷积层的三路分支沿着时间维度,空洞率线性增加,卷积核大小线性减小；所述的时域卷积层的三路分支沿着时间维度逐步缩小采样步长,以对应更细粒度的时间信息；所述的时域卷积层的三路分支中的一分支以最低的扩张步幅捕捉慢动作,另一分支以最高的帧率捕捉快动作。</td>   <td>G06V20/40;G06V40/20;G06V10/77;G06V10/764;G06V10/82;G06N3/0464;G06N3/049</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孔雀屏;              陈湘萍;              黄袁;              刘聪;                   周凡       </td>   <td>中山大学</td>   <td>一种高效阅读智能合约辅助方法</td>   <td>广东省</td>   <td>CN110473092B</td>   <td>2023-05-26</td>   <td>本发明公开了一种高效阅读智能合约辅助方法,用户先输入所有已读合约,提取其标识符和Token序列；之后用户输入将读合约,提取其标识符和Token序列,与数据库中所有智能合约的标识符、Token序列比较,计算出将读合约与所有已读合约的综合相似度,输出综合相似度前十的合约,并分别标记输出合约与将读合约不同的部分,辅助用户高效细读大量的智能合约。通过该方法,可快速找到与已看合约不同的部分,从而节省阅读时间,无论是编程人员还是非编程人员,都能提高细读大量智能合约的效率。另外,编程人员也可借助该工具,快速学习编写智能合约。同类型的功能在实现上会有些许的差异,利用该方法可快速获取差异,从而设计出更安全,功能更全面的智能合约。</td>   <td>1.一种高效阅读智能合约辅助方法,其特征在于,所述方法包括：用户先输入所有已读合约,预处理已读合约后,分别提取已读合约的标识符和Token序列,并把它们存储在数据库中；用户输入将读合约,预处理将读合约后,提取将读合约的标识符和Token序列,分别把将读合约的标识符、Token序列与数据库中所有智能合约的标识符、Token序列比较,计算出将读合约与所有已读合约的语义相似度和语法相似度；把语义相似度和语法相似度线性组合成综合相似度,输出综合相似度前十的合约,并分别标记输出合约与将读合约不同的部分,辅助用户高效细读大量的智能合约。</td>   <td>G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;              林会智;                   李茂楠       </td>   <td>中山大学</td>   <td>一种基于格的分布式门限加法同态加密方法</td>   <td>广东省</td>   <td>CN113591102B</td>   <td>2023-05-26</td>   <td>本发明涉及基于同态加密的安全多方计算技术领域,更具体地,涉及一种基于格的分布式门限加法同态加密方法。包括以下步骤：系统初始设置、用户密钥生成、用户私钥份额生成、系统公钥合成、数据加密、加法同态运算、部分解密和最终解密。发明提供的一种基于格的分布式门限加法同态加密方法,减少了用户端本地的份额数量,进一步减小了整个协议的通信量,同时减少了用户端算法的计算时间,允许用户端利用轻量级计算设备参与整个协议。</td>   <td>1.一种基于格的分布式门限加法同态加密方法,其特征在于,包括：S1.系统初始设置：输入安全参数λ,输出系统参数params＝{param0,paramSS},其中param0是系统初始化相关参数集合,paramSS是多秘密共享相关参数集合；S2.用户秘钥生成：输入系统参数params,输出公私钥对(pk-u,sk-u)；S3.用户私钥份额生成：输入系统参数params、用户u的私钥sk-(u0)和用户集合U中的公钥集合{pk-(v1)}-(v∈U),输出为加密消息集合{e-(uv)}-(v∈U)和用户u的公开份额的有序集合S4.系统公钥合成：输入系统参数params,所有用户的公钥集合{pk-(u0)}-(u∈U),计算pk＝[∑-(u∈U)pk-(u0)]-q,输出系统公钥pk；S5.数据加密：输入系统参数params,系统公钥pk,用户u的明文数据m-u,输出用户u的密文数据c-u＝(c-(u0),c-(u1))；S6.加法同态运算：输入系统参数params,用户的密文数据集合{c-u}-(u∈U),用户的权重系数集合{w-u}-(u∈U),然后分别计算ct-0＝[∑-(u∈U)c-(u0)·w-u]-q、ct-1＝[∑-(u∈U)c-(u1)·w-u]-q,最后输出系统密文ct＝(ct-0,ct-1)；S7.部分解密：输入系统参数params,系统密文ct,用户u的公钥pk-u和用户u收到集合U中其他用户的加密消息集合{e-(vu)}-(v∈U\{u}),输出用户u的部分解密值pm-u；S8.最终解密：输入系统参数params,系统密文ct＝(ct-0,ct-1),用户的部分解密值集合P-1＝{pm-u}-(u∈V),其中|P-1|≥th,th为门限值,系统公开份额集合OS-(sys),集合U中所有用户公开份额集合和/&gt;输出由最终解密值组成的多项式M。</td>   <td>G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈洪波;              刘立志;              黎浩江;              龚琼;              黄文捷;                   阮广英       </td>   <td>桂林电子科技大学;中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种鼻咽癌概率图谱获取及定量分析方法</td>   <td>广西壮族自治区</td>   <td>CN113822863B</td>   <td>2023-05-26</td>   <td>本发明公开了一种鼻咽癌概率图谱获取及定量分析方法,该方法通过建立头颈部标准三维坐标系,尽量消除个体间头颅大小和形状的差异,可以更好地描述肿瘤位置和浸润深度。同时在标准三维坐标系中获取鼻咽癌概率图谱,并提供一种概率图谱特征描述与定量分析方法,同时可以为大样本的头颈部肿瘤定量分析提供新的技术手段,生成鼻咽癌概率图像并研究概率图谱特征描述方法,形成标准空间下的影像学特征,完善现有鼻咽癌影像组学特征体系,并通过大数据医学影像分析,提高鼻咽癌预后模型的准确度,为制订鼻咽癌精准个性化治疗方案提供技术支持。</td>   <td>1.一种鼻咽癌概率图谱获取及定量分析方法,其特征在于,包括如下步骤：1)分别获取鼻咽癌患者和健康者的头部MRI图像,从鼻咽癌患者的头部MRI图像中获取T1W、T2W、DCE-MRI和DWI扫描图像,并从扫描图像中获取常用参数,将获取的参数采用DICOM格式存储；采用相同的参数,从健康者的头部MRI图像中获取健康者的T1W、T2W、DCE-MRI和DWI扫描图像,作为标准参考图像；2)对鼻咽癌患者头部MRI图像进行归一化显示,对MRI图像中的鼻咽癌ROI区域和四个稳定解剖结构点进行勾画,获取到头部四个稳定解剖结构点；3)根据步骤2)获得的四个稳定解剖结构点构建头部医学影像标准三维坐标系,并将鼻咽癌患者的医学图像和肿瘤ROI配准到标准三维坐标系的空间中进行图像配准,利用叠加的方法获取鼻咽癌概率图谱；4)对步骤3)获得的鼻咽癌概率图谱进行定量分析和特征描述,获得肿瘤的位置信息、肿瘤体积,以及肿瘤区域的平均概率、肿瘤边界的概率分布、概率的梯度方向；步骤3)中,图像配准是对图像进行变换,包括平移变换、尺寸变换和转换变换,得到标准空间的变换矩阵,设分别表示头部医学影像标准三维坐标系空间下四个解剖点的坐标值；/&gt;分别表示移动图像中的四个解剖点的坐标值,变换过程具体如下：平移变换的参数矩阵M-(Shift)为：                  其中(C-(Sx),C-(Sy),C-(Sz))为标准空间坐标系的原点坐标,(C-(Tx),C-(Ty),C-(Tz))为移动图像中的原点坐标,其中：                                                                                                            尺度变换的参数矩阵M-(Scale)为：                  其中S-1＝LS/LT,LS和LT分别为标准空间和移动图像中的LIA/RIA连线的长度,                                    S-2＝L1/L2,L1和L2分别为标准空间和移动图像中的LIA/RIA连线中点与LAS/RAS连线中点的线段长度,                                    旋转变换的参数矩阵M-(Rotate)为：                  其中θ为标准空间和移动图像中的LIA/RIA连线的夹角；则将参考图像配准到标准空间的变换矩阵为：M＝M-(Shift)*M-(Scale)*M-(Rotate)利用图像配准获得的参数,对每个患者的鼻咽癌ROI做同样的变换,将其变换到标准空间,得到Roi-P-i,其中i表示第i个患者,则鼻咽癌概率图谱为：</td>   <td>G06T7/00;G06T7/33;G06V10/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡庆玲;              孙玮;              何鸿奇;              林进可;                   林满盈       </td>   <td>中山大学</td>   <td>用于人工神经网络训练的医学图像数据的生成方法及装置</td>   <td>广东省</td>   <td>CN111275686B</td>   <td>2023-05-26</td>   <td>本申请提供了一种用于人工神经网络训练的医学图像数据的生成方法及装置,所述方法包括：利用人工神经网络的自学习能力,建立基础医学图像的目标特征与扩展图像的图像特征之间的对应关系；其中,所述图像特征包括纹理特征和内容特征；获取当前基础医学图像的当前目标特征；通过所述对应关系,确定与所述当前目标特征对应的当前扩展图像的图像特征；具体地,确定与所述目标特征对应的当前扩展图像的图像特征,包括：将所述对应关系中与所述当前目标特征相同的目标特征所对应的扩展图像的图像特征,确定为所述当前扩展图像的图像特征,提高了生成的扩展图像的合理性；细节还原更加出色,增加了特征的多样性。</td>   <td>1.一种用于人工神经网络训练的医学图像数据的生成方法,其特征在于,包括：利用人工神经网络的自学习能力,建立基础医学图像的目标特征与扩展图像的图像特征之间的对应关系；其中,所述图像特征包括纹理特征和内容特征；获取当前基础医学图像的当前目标特征；通过所述对应关系,确定与所述当前目标特征对应的当前扩展图像的图像特征；具体地,确定与所述目标特征对应的当前扩展图像的图像特征,包括：将所述对应关系中与所述当前目标特征相同的目标特征所对应的扩展图像的图像特征,确定为所述当前扩展图像的图像特征；其中,所述目标特征,包括：遮盖特征和/或图像特征,和/或由按设定规律自所述遮盖特征、所述图像特征中提取的特征组成的一维或两维以上的数组；其中,所述遮盖特征,包括：所述基础医学图像的被遮盖区域位置,所述基础医学图像的被遮盖区域形状,以及所述基础医学图像的被遮盖区域大小；所述图像特征,包括：图像结构,图像内容,以及图像纹理；和/或,所述对应关系,包括：函数关系；所述目标特征为所述函数关系的输入参数,所述扩展图像的图像特征为所述函数关系的输出参数；确定与所述当前目标特征对应的当前扩展图像的图像特征,还包括：当所述对应关系包括函数关系时,将所述当前目标特征输入所述函数关系中,确定所述函数关系的输出参数为当前扩展图像的图像特征；所述建立目标特征与扩展图像的图像特征之间的对应关系的步骤,包括：获取用于建立所述目标特征与所述扩展图像的图像特征之间的对应关系的样本数据；分析所述目标特征的特性及其规律,根据所述特性及其规律,确定所述人工神经网络的网络结构及其网络参数；使用所述样本数据,对所述网络结构和所述网络参数进行训练和测试,确定所述目标特征与所述扩展图像的图像特征的所述对应关系。</td>   <td>G06T7/00;G06T7/13;G06T5/00;G06T11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨智勇;              陈俊先;                   尹城川       </td>   <td>中山大学</td>   <td>基于深度顺序的三维大尺度约束随机场的模拟方法</td>   <td>广东省</td>   <td>CN116167110A</td>   <td>2023-05-26</td>   <td>本发明公开了一种基于深度顺序的三维大尺度约束随机场的模拟方法,包括以下步骤：S1、确定待模拟岩土体参数的种类以及统计特征；S2、确定待模拟场地的几何尺寸、勘探钻孔位置及钻孔数据空间分布情况；S3、将模拟区域网格单元化并确定单元尺寸；S4、确定勘探钻孔每个深度处观测数据与未观测数据的相关性矩阵,确定勘探钻孔位置的数据与模拟区域非勘探位置处数据的相关矩阵；S5、采用蒙特卡洛模拟采样方法依次模拟勘探钻孔在每个深度内未观测到的数据,使钻孔内的数据完备,得到规律分布的钻孔数据。本发明方法能够在生成三维大尺度约束随机场的过程中避免涉及超大相关矩阵的求逆运算和存储,有效提高矩阵运算过程中的效率。</td>   <td>1.基于深度顺序的三维大尺度约束随机场的模拟方法,其特征在于,包括以下步骤：S1、确定待模拟岩土体参数的种类以及统计特征；S2、确定待模拟场地的几何尺寸、勘探钻孔位置及钻孔数据空间分布情况；S3、将模拟区域网格单元化并确定单元尺寸；S4、根据实际勘探钻孔位置及模拟区域的网格坐标,确定观测数据在模拟区域的具体位置,确定勘探钻孔每个深度处观测数据与未观测数据的相关性矩阵,确定勘探钻孔位置的数据与模拟区域非勘探位置处数据的相关矩阵；S5、采用蒙特卡洛模拟采样方法依次模拟勘探钻孔在每个深度内未观测到的数据,使钻孔内的岩土体参数数据完备,得到规律分布的钻孔数据。</td>   <td>G06F30/10;G06Q10/0639;G06Q50/02;G06F111/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邵春奎;              成娜;                   陈健宁       </td>   <td>中山大学附属第三医院</td>   <td>一种基于人工智能的肝结节穿刺活检病理诊断用辅助设备</td>   <td>广东省</td>   <td>CN116168822A</td>   <td>2023-05-26</td>   <td>本发明属于病理诊断技术领域,公开了一种基于人工智能的肝结节穿刺活检病理诊断用辅助设备,所述基于人工智能的肝结节穿刺活检病理诊断用辅助设备包括：肝结节病例采集模块、诊断模型构建模块、主控模块、病变信息统计模块、分析模块、预测模块、诊断报告生成模块、显示模块。本发明通过分析模块将所述肝结节病变待分析数据的逻辑输出值在所述感受性曲线中进行比对,计算并输出准确的分析结果；同时,通过预测模块利用K近邻算法和贝叶斯算法,减少肝结节病变因专业经验不足而导致的误判,保障肝结节病变常规检查疾病预测的准确性和效率；另外,本申请提供诊断模型构建模块获得的HnAIM模型诊断准确率高。</td>   <td>1.一种基于人工智能的肝结节穿刺活检病理诊断用辅助设备,其特征在于,所述基于人工智能的肝结节穿刺活检病理诊断用辅助设备包括：肝结节病例采集模块、诊断模型构建模块、主控模块、病变信息统计模块、分析模块、预测模块、诊断报告生成模块、显示模块；肝结节病例采集模块,与诊断模型构建模块连接,用于采集5种肝结节病变(高分化肝细胞癌WDHCC、高级别异型增生结节HGDN、低级别异型增生结节LGDN、局灶性结节状增生FNH,肝细胞腺瘤HCA)以及2种背景肝组织(肝硬化NC、相对正常肝组织NNL)手术切除标本462例病例；诊断模型构建模块,与肝结节病例采集模块、主控模块连接,用于通过模型构建程序根据病例构建肝细胞结节人工智能诊断模型；主控模块,与诊断模型构建模块、病变信息统计模块、分析模块、预测模块、诊断报告生成模块、显示模块连接,用于控制各个模块正常工作；病变信息统计模块,与主控模块连接,用于通过统计程序统计肝结节病变信息；分析模块,与主控模块连接,用于通过分析程序对肝结节病变数据进行分析；预测模块,与主控模块连接,用于通过预测程序对肝结节病变进行预测；诊断报告生成模块,与主控模块连接,用于生成肝结节病变诊断报告；显示模块,与主控模块连接,用于显示肝结节病例、病变信息统计结果、分析结果、预测结果、诊断报告。</td>   <td>G16H50/20;G16H70/60;G06F18/22;G06F18/214;G06F18/2415;G06F18/2413</td>  </tr>        <tr>   <td>中国专利</td>   <td>         印鉴;                   周晨星       </td>   <td>中山大学</td>   <td>一种基于生成语义分割图的文本改写图片方法</td>   <td>广东省</td>   <td>CN110956579B</td>   <td>2023-05-23</td>   <td>本发明提供一种基于生成语义分割图的文本改写图片方法,该方法通过文字描述去修改图片中人物的衣服。不同于以往直接生成修改图片的方法,该方法首先通过双向的LSTM对文本进行编码来获取文本的语义特征,接着通过一个现有的语义分割模型获取原图片的语义分割图,然后将该语义分割图和文本编码进行拼接放入resnet网络中去学习文本编码和原语义分割图的联合表示,从而生成出修改图片的语义分割图,最后再将该生成的语义分割图和原文本编码再次拼接放入另外一个resnet网络中去学习文本编码和生成的语义分割图之间的关系表示生成出最终修改完成的图片。</td>   <td>1.一种基于生成语义分割图的文本改写图片方法,其特征在于,包括以下步骤：S1：建立生成输入图片的语义分割图模型G,语义分割图的特征抽取器T以及生成文本语义信息的双向编码器LSTM网络；所述步骤S1的具体过程是：S11：预定义20个标签,包括头发,脸部,上衣,其目标就是对输入图片的每个像素点进行分类,若输入图片用矩阵表示为[height,width,channel],则输出图片表示为[height,width]；S12：对身体部分进行缩放使其变得模糊,经过这样的特征抽取后将它们的表示拼接在一起构成一个[height,width,3]的语义分割特征矩阵；S13：输入文本首先通过word2vec工具将每个词用一个低维,稠密的实数向量进行表示,于是整个句子可以表示成X=[x-1,…,x-t, …,x-n],其中n为句子长度,向量矩阵X的维度为300维,为了让模型学习句子的每个词上下文信息,用一个双向LSTM去学习句子的上下文信息,设每一个词表示一个时间步t,每个LSTM单元的输入为当前t时刻的词向量x-t以及t-1时刻的LSTM细胞隐层输出h-(ft-1),根据此可以得到前向LSTM的表示为H-f=[h-(f1),…,h-(ft), …h-(fn)],同理,后向LSTM的表示为H-b=[h-(b1),…,h-(bt), …h-(bn)],最后将h-(fn)与h-(b1)拼接在一起作为文本的语义特征表示；S2：构建resnet1网络,将S1中生成的语义分割特征和文本语义特征输入该网络中通过GAN训练方法生成修改图片的语义分割图P；S3：构建resnet2网络,将S2中生成的语义分割图P和S1中生成的文本语义特征输入该网络中通过GAN训练方法生成修改图片。</td>   <td>G06T3/00;G06T7/11;G06T5/50;G06F40/211;G06F40/279</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青;                   黄潮立       </td>   <td>中山大学</td>   <td>一种支持树状数据结构的一致性算法系统及其实现方法</td>   <td>广东省</td>   <td>CN110597809B</td>   <td>2023-05-23</td>   <td>本发明公开了一种支持树状数据结构的一致性算法系统及其实现方法,所述系统包括若干虚拟计算节点,所述若干虚拟计算节点根据树状结构划分为具有上下级管理关系的Group,所有拥有上下级关系的Group均运行基于Multi-Paxos算法的一致性算法,各Group由一部分虚拟计算节点组成且同时管理一部分的数据子树,各Group内Leader拥有组的相关管理权限,各Group内Leader在执行相关管理权限的时候依赖于虚拟计算节点的相关参数以及数据子树的相关参数,通过组与组之间的上下级管理关系以及领导分权,将数据请求根据数据子树的请求路径进行分组处理,解决了单Leader节点的高负载问题。</td>   <td>1.一种支持树状数据结构的一致性算法系统的实现方法,包括如下步骤：步骤S1,将集群中的虚拟计算节点根据树状结构划分为具有上下级管理关系的Group；步骤S2,所有拥有上下级关系的组均运行基于 Multi-Paxos算法的一致性算法,各Group内Leader拥有组的相关管理权限,各Group内Leader在执行相关管理权限的时候依赖于虚拟计算节点的相关参数以及数据子树的相关参数；步骤S3,当接收到客户端发起的数据请求时,首先从其缓存器中获取数据子树对应的Group的Leader,然后再对Leader所在的虚拟计算节点发送请求；于步骤S2中,各Group的Leader根据目前管理的数据子树和虚拟计算节点的负载情况,决定是否产生新的SubGroup 或者利用现有的 SubGroup,将其所管理的数据子树中的其中一部分子树的管理权转交给 SubGroup,并放弃对该部分数据子树的管理权；各Group的Leader还根据负载情况进行SubGroup的回收,删除该SubGroup以及该SubGroup的所有SubGroups,同时回收该 SubGroup 管辖内的所有数据子树；所述客户端缓存之前请求过的数据子树所在的 Group,以及该 Group 的 Leader节点,若缓存不存在或者缓存错误,则发送请求至可用的虚拟计算节点来进行辅助寻找；所述辅助寻找的过程如下：首先检测当前虚拟计算节点所在的所有 Group 中是否存在拥有对该数据子树的管理权,若有则返回相应的 Group Id 和 Leader节点,否则,将请求转发至其拥有的最大管辖权的Group的父Group中进行寻找,直到寻找成功；若到 RootGroup 或者无父Group的情况下都没有找到该数据子树所在的 Group,则说明目前该数据子树不存在或者处于不可用状态；每个 Group 均保存其管理的 SubGroups 的 Group Id 以及其关联的数据子树,并缓存这些 SubGroups 的Leader节点,以便于快速找到数据子树的处理节点；其中,Group Id的产生方式通过在该组 Leader 产生 SubGroup 的时候进行分配,并使得该组内超半数节点知晓,保持 Group Id 的数据一致性,父Group有它所有的SubGroups的所有IDs,相应的组内成员集合、管辖数据子树的映射关系：&lt;GroupId,(组成员,管辖的数据子树)&gt;,所述Group Id全局唯一,用于进行Group 的寻找；在同一个Group 中,虚拟计算节点间互相进行通信,以进行该组内的领导选举、转发议题请求,同时每个Group内只有一个Leader；每个Group 至少由三个虚拟计算节点组成,每个 Group 拥有对其内部分配的 SubGroups的管理权,即 Level-i 组拥有对其内部分配的所有 Level-(i+1) 组的管理权,这部分管理权由该 Group 的Leader进行管理,具体管理权包括：添加 SubGroup、回收 SubGroup、管理数据子树；所述虚拟计算节点的相关参数来自于虚拟计算节点的节点负载收集器,其收集的数据包括CPU使用率、内存使用率、网络带宽利用率、网络延迟时间、磁盘IO速度、磁盘使用率和目前处理的 Group 数目；所述数据子树的相关参数来自于虚拟计算节点的主进程,其收集的数据包括单位时间内数据读取量、单位时间内数据处理量和所有管辖内的数据子树的数据总量。</td>   <td>G06F16/22;G06F16/23;G06F16/2455;G06F16/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         万海;              肖逸凡;                   曾娟       </td>   <td>中山大学</td>   <td>一种基于迭代精细化的图像场景图谱生成方法</td>   <td>广东省</td>   <td>CN109783666B</td>   <td>2023-05-23</td>   <td>本发明公开一种基于迭代精细化的图像场景图谱生成方法,涉及图像场景图谱领域,包括步骤：输入图像场景图谱数据集及其参数,提取图像的视觉特征；结合训练集中的图像数据以及场景图谱数据,利用视觉信息和语义信息对实体对之间的视觉关系做分类,生成图像场景图谱；产生出若干个区域包围盒和对应的每个区域的特征向量,融合区域特征向量得到图像描述文段的特征向量；将图像描述文段的特征向量输入到图像描述文段生成器中生成图像描述文段；构建精细化图,定义精细化实体对的特征向量和区域特征向量的方法,迭代执行图像场景图谱生成、图像成段图像描述文段生成、精细化特征向量,至达到最大迭代次数为止。本发明提高了图像场景图谱生成的效果。</td>   <td>1.一种基于迭代精细化的图像场景图谱生成方法,其特征在于,包括以下步骤：步骤1、输入图像场景图谱数据集及其参数,用深度神经网络提取图像场景图谱数据集中图像的视觉特征；步骤2、结合训练集中的图像数据以及场景图谱数据,利用视觉信息和语义信息对实体对之间的视觉关系做分类,生成图像场景图谱；步骤3、用区域检测器产生出若干个区域包围盒和对应的每个区域的特征向量,融合区域特征向量得到图像描述文段的特征向量；将图像描述文段的特征向量输入到图像描述文段生成器中,以生成图像描述文段；步骤4、构建精细化图,定义精细化实体对的特征向量和区域特征向量的方法,精细化特征向量后,迭代执行图像场景图谱生成、图像成段图像描述文段生成、精细化特征向量这三个步骤直到达到最大迭代次数为止；其中,步骤2包括如下步骤：(21)对图像场景图谱实体对进行视觉特征编码,得到实体对的视觉特征向量；(22)在图像数据I的实体集E中,任取两个实体,组成一个实体对p＝(h,t),取两个实体包围盒的被预测出来的实体类别,获取对应语义特征向量w-h和w-t；(23)将语义特征向量w-h、w-t和视觉特征向量v-((h,t))依次输入到一个单层双向循环神经网络中,得到一个N+1维度的概率分布向量y-(h,t)输出；取出概率分布向量y-(h,t)的组成元素中最大元素的索引作视觉分类的结果；穷取图像数据I的实体集中的所有实体对,得到所有实体对之间的视觉分类结果,实体对之间的视觉分类结果构成视觉关系矩阵Μ；(24)计算视觉关系分类的准确率和平均损失,用随机梯度下降算法进行用于生成图像场景图谱的神经网络中各层参数的反向传播得到梯度值,并更新用于生成图像场景图谱的神经网络参数；其中,步骤(21)包括如下步骤：(211)对图像数据用训练好的物体检测器生成若干个实体包围盒,每个实体包围盒标注着被预测出来的实体类别,对应于图像场景图谱的每一个实体；(212)取图像场景图谱的头部实体的包围盒和尾部实体的包围盒,根据图像场景图谱的头部实体的包围盒和尾部实体的包围盒,得到实体对的合并包围盒；(213)从图像的视觉特征中截取出每个实体对的合并包围盒的对应区域的特征；(214)将每个实体对的合并包围盒的对应区域的特征通过卷积神经网络和外加的一层实体全连接神经网络层,编码得到实体对的视觉特征向量。</td>   <td>G06F16/51;G06V10/764;G06V10/82;G06N3/0464;G06N3/0442;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈鹏飞;              麦艮廷;                   郑子彬       </td>   <td>中山大学</td>   <td>数据库配置调优方法、装置、设备及可读存储介质</td>   <td>广东省</td>   <td>CN116150128A</td>   <td>2023-05-23</td>   <td>本申请提供一种数据库配置调优方法、装置、设备及可读存储介质,当需要对数据库进行调优时,本申请可接收并根据目标客户端的调优请求,收集目标数据库对应的目标配置样本集；并将目标配置样本集输入调优模型分析,得到与其对应的配置结果；还可判断配置结果是否满足调优要求；若否,则继续将目标配置样本集输入调优模型分析,直至配置结果满足目标客户端的调优要求。若是,则可将配置结果反馈给目标客户端。本申请调优效率高并有效减少调优时间成本,且可以自适应地应用于NoSQL数据库的调优,可以有效推荐所需要调优的数据库的最优配置结果,本申请实施例提供的方法适用性较强,可以适应于不同的数据库配置调优工作。</td>   <td>1.一种数据库配置调优方法,其特征在于,包括：接收目标客户端的调优请求,所述目标客户端的调优请求包括调优要求以及需要进行调优的目标数据库；依据所述目标客户端的调优请求,收集所述目标数据库对应的目标配置样本集；将所述目标配置样本集输入预设的目标调优模型进行分析,得到所述目标数据库对应的配置结果；判断所述目标数据库对应的配置结果是否满足所述目标客户端的调优要求；若所述目标数据库对应的配置结果未满足所述目标客户端的调优要求,则返回执行所述将所述目标配置样本集输入预设的目标调优模型进行分析的操作,直至所述目标调优模型输出的所述目标数据库对应的配置结果满足所述目标客户端的调优要求；若所述目标数据库对应的配置结果满足所述目标客户端的调优要求,则将所述配置结果反馈给所述目标客户端。</td>   <td>G06F16/21;G06N20/00;G06N5/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         倪芃芃;              马伟强;              安峻彤;              孙伟;                   伍浩良       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种基于热力耦合分析的沉管隧道浇筑方法及系统</td>   <td>广东省</td>   <td>CN116151056A</td>   <td>2023-05-23</td>   <td>本发明公开了一种基于热力耦合分析的沉管隧道浇筑方法及系统,该方法包括：构建混凝土几何模型；基于混凝土几何模型,输入参数生成温度时程变化图；基于混凝土几何模型,基于混凝土几何模型,对有限元软件进行考虑徐变的二次开发并构建应力场计算模型；根据应力场计算模型进行热力耦合计算并生成温度应力时程变化图；根据温度时程变化图和温度应力时程变化图对沉管隧道浇筑进行温度控制。该系统包括：几何模型构建模块、温度计算模块、徐变模块、热力耦合计算模块和温度控制模块。通过使用本发明,能够有效提高大体积混凝土浇筑效果。本发明作为一种基于热力耦合分析的沉管隧道浇筑方法及系统,可广泛应用于混凝土浇筑领域。</td>   <td>1.一种基于热力耦合分析的沉管隧道浇筑方法,其特征在于,包括以下步骤：构建混凝土几何模型；基于混凝土几何模型,输入参数生成温度时程变化图；基于混凝土几何模型,对有限元软件进行考虑徐变的二次开发并构建应力场计算模型；根据应力场计算模型进行热力耦合计算并生成温度应力时程变化图；根据温度时程变化图和温度应力时程变化图对沉管隧道浇筑进行温度控制。</td>   <td>G06F30/23;E21D11/10;G06F119/08;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周思宇;              印鉴;                   赖韩江       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种基于对抗生成网络的与职业相关的人脸老化方法</td>   <td>广东省</td>   <td>CN109509144B</td>   <td>2023-05-23</td>   <td>本发明提供一种基于条件对抗生成网络的与职业相关的人脸老化方法。本发明首先收集一个职业面部老化数据集来研究职业对人脸老化的影响,它包括三个职业类型。其次,本发明提出了一个新的考虑职业信息的基于条件对抗生成网络的人脸老化网络,它学习了不同职业下的人脸的老化过程。本发明的老化过程中考虑了两个方向：个人特征的保留和不同职业所带来的不同的老化特征。本发明通过深度自编码网络,来保持个人的面部特征,使用了条件对抗生成网络来获得不同职业下的老化特征。</td>   <td>1.一种基于条件对抗生成网络的与职业相关的人脸老化方法,其特征在于,包括以下步骤：S1：收集与职业相关的人脸老化图片；所述步骤S1的具体过程是：通过图片搜索引擎来收集图片；收集的图片有三个年龄段,分别是20-30岁,30-50岁,50-80岁；其中20-30岁年龄段的图片不包含职业信息,30-50岁和50-80岁年龄段的图片包含职业信息；职业分成三个类别,分别是明星,室内工作者,室外工作者；20-30岁年龄段包含500张图片,男女各一半；30-50岁,50-80岁年龄段,每个职业400张图片,男女各一半,数据集总共的大小为2900张图片；S2：训练分类网络区分人脸的不同职业,并根据结果探究职业对人脸老化的影响；所述步骤S2的具体过程是：训练的分类模型以VGG16为基础,把1000维度的输出层改为3维度的输出层,先采用较大学习率训练输出层参数,再采用较小学习率训练整个网络参数；训练结束后网络输出每个标签的概率大小,通过概率大小和真实标签来确定分类是否成功；S3：训练生成网络来生成不同职业条件下老化的人脸,并通过之前的分类网络验证生成结果的好坏；所述步骤S3的具体过程是：S31：生成网络由两个部分组成,一个是深度自编码网络用于保存图片的个人特征,一个是条件对抗生成网络用于生成不同职业下老化的不同特征；S32：深度自编码网；S321：深度自编码网络结构具有一个生成器,将年轻人脸图片/&gt;生成老年图片/&gt;,这个生成器生成需要添加年龄条件a,职业条件o；S322：深度自编码网络结构具有一个生成器,将生成的老龄化的图片/&gt;输入生成20-30岁图片/&gt;,这个生成器不需要添加输入条件；S323：通过最小化loss函数训练生成器/&gt;与/&gt;来拉近y与/&gt;的距离来使得过程中生成的图片/&gt;具有y的特征；S33：条件生成对抗网络；S331：条件生成对抗网络具有一个生成器,将年轻人脸图片/&gt;生成老年图片/&gt;,这个生成器生成需要添加年龄条件a,职业条件o；S332：条件生成对抗网络具有一个判别其,区分输入的图片是真实的图片/&gt;还是生成的图片/&gt;,这个判别器判别需要添加年龄条件a,职业条件o；S333：训练过程分为两个步骤,首先固定生成器不变,训练判别器/&gt;能够最大限度区分是真实的图片/&gt;还是生成的图片/&gt;；S334：然后固定判别器不变,训练生成器/&gt;使得判别器/&gt;不能够区分是真实的图片/&gt;还是生成的图片/&gt;,同时使用/&gt;范数来训练生成器,拉近真实图片与生成图片的距离；S335：反复的执行S33与S34步骤直到不能够区分是真实的图片/&gt;还是生成的图片；/&gt;S34：使用在S2中训练好的分类网络来测试生成图片是否能够被识别为想要生成的职业类型,通过测试结果来判定生成的好坏。</td>   <td>G06T3/00;G06N3/045;G06N3/0475;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         詹杰民;              喜扬洋;              胡文清;              林凯;              罗莹莹;                   余炜光       </td>   <td>中山大学</td>   <td>一种上呼吸道凹凸榫卯装配的实验装置及该装置建模方法</td>   <td>广东省</td>   <td>CN110264560B</td>   <td>2023-05-23</td>   <td>本专利涉及临床医学、生物力学和流体力学研究领域,提供一种上呼吸道凹凸榫卯装配的实验装置及该装置建模方法,所述装置包括上呼吸道实验模型主体,所述上呼吸道实验模型主体包括多个分块模型,所述多个分块模型通过榫卯接口结构拼接；所述上呼吸道实验模型主体包括至少三个测量仪器接口。与现有技术相比防止了3D打印内部支撑的生成,并且切口处采用榫卯结构进行拼接,使得物理模型具有防漏气、易拆卸等优点；模型与器材的接口采用凹型接口,确保了测量仪器连接处的稳定性与密封性,消除了测量过程中由仪器晃动带来的异常数据。另外,实验装置使用志愿者的真实呼吸作为驱动。</td>   <td>1.一种上呼吸道凹凸榫卯装配的实验装置,其特征在于,包括上呼吸道实验模型主体,所述上呼吸道实验模型主体包括多个分块模型,所述分块模型内含多个上呼吸道腔体,且分块模型的外缘与腔体边缘上设有凹凸接口结构,相连的两个分块模型之间通过凹凸接口结构拼接；所述上呼吸道实验模型主体包括至少三个测量仪器接口；所述凹凸接口结构为榫卯接口结构；所述测量仪器接口为与测量仪器接口相对应的凹型接口；所述凹型接口包括柱形外围结构,柱形外围结构的长度为1.5cm。</td>   <td>G06T17/00;G06T19/20;G09B23/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>              李璇       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的图像隐写分析方法及系统</td>   <td>广东省</td>   <td>CN108961137B</td>   <td>2023-05-23</td>   <td>本发明公开了一种基于卷积神经网络的图像隐写分析方法及系统,包括三个模块：图像预处理部分、特征提取部分、特征分类模块。在图像预处理部分,本发明通过实验选择了一组具有多方向、多尺度参数的Gabor滤波器与输入图像卷积获得高信噪比的图像残差；特征提取部分使用了快捷连接结构将浅层的输出与后面层直接相连来减轻过拟合现象。本发明基于卷积神经网络的隐写方法不需要大量关于隐写、隐写分析的领域知识,特征提取和特征分类过程是联合的优化过程,设计简单易于实施；其次,利用Gabor滤波器的尺度性和方向性可以帮助网络提取更有效的图像残差；最后,对J-UNIWARD和UED两种内容自适应的隐写算法都能取得比较好的检测效果。</td>   <td>1.一种基于卷积神经网络的图像隐写分析方法,其特征在于,包括以下步骤：S1：设计实验所需的图像数据库,对图像数据库中的图像进行裁剪、压缩和隐秘信息嵌入,得到载密图像；将原始图像和载密图像分为互不相交的训练集、验证集和测试集；S2：设计基于卷积神经网络的网络模型,所述的网络模型包括预处理层、使用卷积层和池化层的特征提取层、全连接层和Softmax函数的特征分类层；所述预处理层对输入的图像进行解压缩到空域,然后使用多方向多尺度的Gabor滤波器与解压缩的图像进行卷积,最后对得到的图像残差数据通过截断函数进行截断操作；所述截断函数如下：                  所述f(x)表示截断函数,x表示图像残差数据,T表示截断阈值；S3：根据实验结果设计预处理层滤波器的初始化参数；S4：将训练集的图像进行数据增强后输入S2的基于卷积神经网络的网络模型进行训练；S5：选取步骤S4中训练后得到的最优的N个基于卷积神经网络的网络模型对测试集的图像进行分析,所述的N是正整数。</td>   <td>G06T1/00;G06V10/774;G06V10/84;G06V10/82;G06N3/0464;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓豪;                   权小军       </td>   <td>中山大学</td>   <td>一种基于自注意力机制的标点符号预测方法</td>   <td>广东省</td>   <td>CN109558576B</td>   <td>2023-05-23</td>   <td>本发明提供一种基于自注意力机制的标点符号预测方法,包括以下步骤：基于自动语音识别技术进行语音识别,得到无标点符号文本；对无标点符号文本进行处理,得到文本序列；构建标点符号预测模型,将文本序列导入模型中,完成文本序列的标点符号预测。本发明提供的一种基于自注意力机制的标点符号预测方法,通过构建标点符号预测模型,实现了对语音识别文本的标点符号预测,有效缓解了梯度消失的问题,加强了特征传递,有效建立文本长期依赖的关系；同时,相比之前的模型无需额外的参数,有效减少了传递的数据量,降低参数的训练难度。</td>   <td>1.一种基于自注意力机制的标点符号预测方法,其特征在于,包括以下步骤：S1：基于自动语音识别技术进行语音识别,得到无标点符号文本；S2：对无标点符号文本进行处理,得到文本序列；S3：构建标点符号预测模型,将文本序列导入模型中,完成文本序列的标点符号预测；在步骤S3中,所述标点符号预测模型包括字符嵌入层、词嵌入层、上下文信息嵌入层、自注意力层和输出层；其中：所述字符嵌入层对每个单词中的字符序列做一维卷积,对卷积的结果做最大池化,即可得到对应单词的字符级向量；所述词嵌入层通过预训练的GloVe词向量将每个词映射为一个词级的高维向量；词向量结合对应的字符级向量形成一个既有词级信息又有字符级信息的向量；所述上下文信息嵌入层通过3层稠密连接的双向长短期记忆网络获得序列的信息表达；所述自注意力层计算每一个词对序列中其他词的注意力,对序列中的每一个词分配不同的权重,从而得到一个具有权重信息的向量序列；所述输出层通过归一化指数函数对具有权重信息的向量序列进行处理,完成对每个词的标点符号预测,并输出预测结果；在上下文信息嵌入层中,所述3层稠密连接的双向长短期记忆网络分别为第一层双向长短期记忆网络、第二层双向长短期记忆网络和第三层双向长短期记忆网络；其中,第一层双向长短期记忆网络输入端接收所述词嵌入层输出的向量信息；第二层双向长短期记忆网络输入端接收所述词嵌入层输出的向量信息的同时,接收第一层双向长短期记忆网络的输出信息；第三层双向长短期记忆网络输入端接收所述词嵌入层输出的向量信息的同时,还同时接收第一层双向长短期记忆网络、第二层双向长短期记忆网络的输出信息；第三层双向长短期记忆网络输出序列的信息表达传送至所述自注意力层；所述自注意力层为多头自注意力机制,具体包括以下步骤：设头的个数为h,序列单词个数为n,序列维数为d,上下文信息嵌入层的输出序列为Q、K、V,其中Q＝K＝V,Q∈R～(n×d),K∈R～(n×d),V∈R～(n×d)；Q、K、V经过线性变换后对d维进行分割,每个头内Q、K、V注意力计算公式为：                  每个头的输入M-i为：                  其中,得到每个头的Attention后,将h个头的Attention结果进行拼接,得到拼接结果M,即：M＝Concat(M-1,...,M-h)；其中,M∈R～(n×d),对拼接结果做线性变换,有：Y＝MW；其中,W为自定义的参数矩阵,W∈R～(d×4),Y为线性变换后的结果；使用多头自注意力机制,仅需序列对自身做Attention计算即可,同时可以学习到不同表示子空间的信息,捕获长距离依赖关系；在长距离依赖上,由于自注意力机制是每个词和所有词都要进行Attention计算,故词间最大的路径长都是1。</td>   <td>G06F40/166;G06N3/0464;G06N3/08;G10L15/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈承勃;                   权小军       </td>   <td>中山大学</td>   <td>基于多模态对齐与多向量表征的人格检测方法</td>   <td>广东省</td>   <td>CN111259976B</td>   <td>2023-05-23</td>   <td>本发明公开一种基于多模态对齐与多向量表征的人格检测方法,包括将语音和视频模态数据按每个epoch进行重采样；将数个样本及其文本模态数据输入模态内表征模块进行独立编码,得到语音序列、视频序列和文本序列；将语音序列、视频序列和文本序列输入模态间对齐表征模块以两两对齐交互后拼接,得到增强后的语音表征、视频表征和文本表征；将所有语音表征、所有视频表征和所有文本表征分别拼接得到语音向量、视频向量和文本向量,输入卷积神经网络转化为至少两类人格向量；将至少两类人格向量分别线性化后通过sigmoid函数映射得到至少两类人格特点的预测概率。本发明通过3个模态数据的两两交互增强模态表征,提高模型的辨别能力,得到更为精准的预测结果。</td>   <td>1.一种基于多模态对齐与多向量表征的人格检测方法,其特征在于,包括如下步骤：S10将语音和视频模态数据按每个epoch进行重采样,生成数个彼此具有差异性的样本；S20将数个样本及其文本模态数据输入模态内表征模块进行独立编码,得到语音序列、视频序列和文本序列；包括：模态内表征模块通过傅里叶变换提取样本中音频的梅尔频率倒谱系数和响应Fbank特征,并将其输入多层双向LSTM网络进行编码以捕获语音语调变化特征,将所捕获语音语调变化特征编码为语音序列,并将其输出；模态内表征模块通过具有残差结构的卷积神经网络对样本中视频进行编码得到视频特征的高维向量,将视频特征的高维向量输入多层的双向LSTM网络中将所学习的表情和动作变化编码为视频序列,并将其输出；模态内表征模块通过基于transformer结构的Bert模型对样本中的文本进行编码得到具备深层语义信息的文本序列；S30将语音序列、视频序列和文本序列输入模态间对齐表征模块,模态间对齐表征模块分别将语音序列、视频序列和文本序列两两对齐交互后拼接,得到增强后的语音表征、视频表征和文本表征；所述模态间对齐表征模块利用文本转语音text2audio的注意力将文本序列向语音序列对齐,以增强语音表征；利用语音转视频audio2video的注意力将语音序列向视频序列对齐,以增强视频表征；S40将所有语音表征拼接成语音向量,将所有视频表征拼接成视频向量,将所有文本表征拼接成文本向量,利用卷积神经网络分别将语音向量、视频向量和文本向量转化为至少两类人格向量；S50将至少两类人格向量分别线性化后通过sigmoid函数映射得到至少两类人格特点的预测概率；所述人格向量为5类人格向量,所述5类人格向量包括：开放人格向量,用于提取个体所具有的想象、审美、情感丰富、求异、创造、智能的特质；责任人格向量,用于提取个体所显示出的胜任、公正、条理、尽职、成就、自律、谨慎、克制的特点；外倾人格向量,用于提取个体所表现出的热情、社交、果断、活跃、冒险、乐观的特质；宜人人格向量,用于提取个体所具有的信任、利他、直率、依从、谦虚、移情的特质；神经质人格向量,用于提取个体所具有的难以平衡焦虑、敌对、压抑、自我意识、冲动、脆弱的情绪特质。</td>   <td>G06V10/764;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              蔡佳辉;              王金鹏;              陈嘉敏;                   林佳玲       </td>   <td>中山大学;广州智慧城市发展研究院</td>   <td>一种基于三维交替更新网络的视频行为识别方法</td>   <td>广东省</td>   <td>CN111353394B</td>   <td>2023-05-23</td>   <td>本发明公开了一种基于三维交替更新网络的视频行为识别方法,涉及计算机视觉领域。该视频行为识别方法包括步骤：S1、将视频分为连续的帧,对数据集进行预处理；S2、对参与训练的视频片段执行数据增强操作；S3、将执行数据增强操作后的训练数据放入3D CliqueNet架构中进行训练,获得网络的预训练模型；S4、输入测试数据得到测试数据集的行为分类结果,对经过训练的网络进行测试。本发明的方法使用3D CliquNet来提取时空信息,该网络能最大化提升深度网络中的信息流的流动,可以减少训练困难以及更有效的利用参数。通过在Kinetics数据集上进行预训练,该方法具有较高的行为识别表现以及对于复杂环境具有更好的鲁棒性。</td>   <td>1.一种基于三维交替更新网络的视频行为识别方法,其特征在于,包括以下步骤：S1、将视频分为连续的帧,对数据集进行预处理；S2、对参与训练的视频片段执行数据增强操作；S3、将执行数据增强操作后的训练数据放入3D CliqueNet架构中进行训练,获得网络的预训练模型；S4、输入测试数据得到测试数据集的行为分类结果,对经过训练的网络进行测试；其中,所述3D CliqueNet架构架构由多个3D Clique Block块构成,每一层的信息来自于之前的层,且仅限于单向流向之后的层；3D Clique Block块中的每一层网络均为双向连接,任意一层网络既为其它层的输入,也是其他层的输出；3D CliqueNet架构的每一个块中的网络层参数更新分为两个阶段,第一阶段中第1层的输出为：x-l＝H-l([x-0,x-1,…,x-(l-1)]),其中,[x-0,x-1,…,x-(l-1)]表示前1层输出特征图的串联连接,H-l()为包含了三个模块的复合函数,即先执行批量归一化和ReLU激活函数,再执行1个3×3的卷积；在第二阶段,各层开始交替更新,将其它所有层串联起来更新,每一层都会从其他层中收到反馈信息流,第k(k&gt;＝2)中的第i(i&gt;＝1)层表示如下：其中,*表示卷积操作,W表示参数且W-(ij)在不同阶段保持重用,g表示一个非线性激活函数。</td>   <td>G06V20/40;G06V40/20;G06V10/774;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡佳然;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于深度学习的动作模型及其训练方法</td>   <td>广东省</td>   <td>CN110852419B</td>   <td>2023-05-23</td>   <td>本发明涉及一种基于深度学习的动作模型及其训练方法,动作模型包括数据补全模块、数据编解码模块和状态推理模块；对动作模型进行训练后,能够求解规划问题。本发明的动作模型能够补全原始数据的缺失部分,有效地解决在对动作模型训练的时候,原始数据部分缺失导致准确性差的问题。本动作模型通过数据训练,学习出状态在隐含空间的命题形式的表达,并学习在隐空间中的推理能力,使得问题可以通过搜索算法得到解序列；且训练过程均为无监督学习,高效地利用了深度学习在大量数据中总结规律的优点,无需耗费人工建模的成本。</td>   <td>1.一种基于深度学习的动作模型,其特征在于,包括数据补全模块、数据编解码模块、状态推理模块和搜索规划模块；数据补全模块用于预测原始数据P中缺失的部分,并补充到原始数据中,生成完整可观测的数据O；数据补全模块包括生成器和判别器,生成器正向运算公式如下：P-z＝M⊙P+(1-M)⊙ZH-(G1)＝ReLU(W-(G1)*[P-z；M]+b-(G1))H-(G2)＝ReLU(W-(G2)*H-(G1)+b-(G2))H-o＝σ(W-(Go)*H-(G2)+b-(Go))O＝M⊙P+(1-M)⊙H-(Go)判别器正向运算公式如下：H-(D1)＝ReLU(W-(D1)*[O,T]+b-(D1))H-(D2)＝ReLU(W-(D2)*H-(D1)+b-(D2))                  其中,Z为d维噪声向量；[；]为维度相同的两个变量的拼接操作,*为矩阵相乘,ReLU(·)为线性整流函数,σ(·)为sigmoid函数；W-(G1),b-(G1),W-(G2),b-(G2),W-(Go),b-(Go)为网络超参数；W-(D1),b-(D1),W-(D2),b-(D2),W-(Do),b-(Do)为网络超参数数据编解码模块,用于实现原始形式的数据O和隐含空间中的命题形式的数据S的双向转换；所述数据编解码模块包含两个子模块：编码模块和解码模块；编码模块用于将原始形式的数据O编码为隐含空间中的命题S；解码模块用于将隐含空间的命题S解码,得到原始形式的数据O；所述数据编解码模块的训练数据集的样本为观测向量P,将原始观测样本经过补全自后,得到原始观测数据O；所述数据编码模块包括编码器模块和解码模块,公式分别为：S＝SEn(O)                  其中,S的维度大小为m*2,表示m个2维one-hot向量,其现实含义为m个值为真或假的命题,m是一个人工设置的网络超参数；SEn为可训练的神经网络；为d维向量；SDe为可训练的神经网络；状态推理模块,用于在隐含空间中的命题上进行推理,使得在给定当前时刻状态的命题S的条件下,得到下一个时刻的所有可能状态的命题S′；原始数据中的问题进行求解,对每个问题,给定初始状态的观测图片P-0和缺失部分的位置指示变量M-0,以及目标状态的观测图片P-g和缺失部分的位置指示变量M-g,规划阶段的具体步骤如下：步骤1,将初始状态的观测图片P-0和缺失部分的位置指示变量M-0,以及目标状态的观测图片P-g和缺失部分的位置指示变量M-g,分别输入到数据补全模块的生成器G中,得到补全后的初始状态观测图片O-0,以及补全后的目标状态的观测图片O-g。步骤2：给定观测图片O-0与O-g,使用数据编解码模块的编码子模块,将O-0与O-g分别编码成隐空间下的命题形式状态向量S-0与S-g。步骤3：以S-0为起点,利用状态推理模块和搜索规划模块进行前向搜索,直到下一时刻的状态中包含S-g,并记录下搜索路径R。状态推理模块和搜索规划模块进行前向搜索的过程为：首先给定初始状态S0,目标状态Sg。然后,定义启发函数F(S)的计算规则：G(S)为当前实际成本,是指从初始状态S0到当前状态S的步数；H(S)为启发成本,是指当前状态S与目标状态Sg的曼哈顿距离。然后,进行以下搜索求解步骤：步骤i.初始化“开启”列表、“关闭”列表为空列表,计算状态S0的成本F(S0)＝G(S0)+H(S0),并把初始状态S0放入“开启”列表。步骤ii.从“开启列表”中选择F最小的状态S,将其移出“开启”列表并添加到“关闭”列表。步骤iii.判断S是否等于Sg,若是,跳转到步骤vi；否则跳转到iv。步骤iv.枚举所有的动作A,通过状态推理模块的编码器AFn得到该状态下一时刻的所有可能状态{Sn},将{Sn}中不在“关闭”列表内的状态去除,将这些状态的父节点设置为当前状态S。步骤v.计算{Sn}中各个状态的成本F(Sn)＝G(Sn)+H(Sn),跳转到步骤ii。步骤vi.通过搜索过程中记录的每个状态的父节点,回溯获取从初始状态S0到当前状态S的路径,即解序列{Si}。输出{Si},求解结束。步骤4：使用数据编解码模块的解码子模块,将搜索路径R的所有命题形式的状态向量{S-0,S-1,…,S-g}解码,得到图片形式的解序列{O-0,O-1,…,O-g},即规划问题的解。</td>   <td>G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         叶云林;              郭胜杰;              陈东;              吴志明;                   秦自科       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>预测肾脏肿瘤术后肾功能的系统及计算机可读存储介质</td>   <td>广东省</td>   <td>CN112700875B</td>   <td>2023-05-23</td>   <td>本发明公开了一种预测肾脏肿瘤术后肾功能的系统,其包括主控机,该主控机包括：分肾功能比值计算模块、双侧肾脏肾小球滤过率计算模块、部分切除术后总肾小球滤过率预测模块和根治术后总肾小球滤过率预测模块；以上模块依序分别用于利用术前肾脏影像学检查图片和3-D软件计算各自分肾功能比值；计算各自分肾的肾小球滤过率；计算切除的肾实质体积,再按比例计算这部分的肾小球滤过率,减去这部分肾功能,即术后总肾小球滤过率；最后,根治术后总肾小球滤过率预测模块用于通过公式一,预测根治术后的总肾小球滤过率。本发明只需要利用已有的术前影像学检查资料,即可无创准确评估术前分肾功能、预测术后总肾功能,有利于治疗决策参考。</td>   <td>1.一种预测肾脏肿瘤术后肾功能的系统,其特征在于：其包括主控机,该主控机包括：分肾功能比值计算模块、双侧肾脏肾小球滤过率计算模块、部分切除术后总肾小球滤过率预测模块和根治术后总肾小球滤过率预测模块；所述分肾功能比值计算模块,用于利用术前肾脏影像学检查的图片,通过3-D软件分别计算双侧肾的实质体积,以单侧肾的实质体积除以双侧肾总的实质体积,即获得各自的分肾功能比值；所述双侧肾脏肾小球滤过率计算模块,用于利用MDMRII公式计算总肾小球滤过率,所述总肾小球滤过率乘以所述分肾功能比值,即得到双侧肾脏各自的肾小球滤过率；所述部分切除术后总肾小球滤过率预测模块,用于通过3-D软件,计算肾部分切除将丢失的肾实质体积,再按将丢失的肾实质体积与双侧肾总的实质体积的比例,计算这部分将丢失的肾实质所代表的肾小球滤过率,所述总肾小球滤过率减去这部分将丢失的肾实质所代表的肾小球滤过率,即获得预测的肾部分切除的术后总肾小球滤过率；所述根治术后总肾小球滤过率预测模块,通过公式一,预测根治术后的总肾小球滤过率；公式一 eGFR-(根治)= 5.276-年龄×0.261 + eGFR-(术前总)×0.55 +eGFR-(健侧)×0.379公式一中,eGFR-(根治)即根治术后的总肾小球滤过率,年龄是指待测者的以年为计的岁数,eGFR-(术前总)是指手术前的总肾小球滤过率,eGFR-(健侧)是指健康一侧的肾小球滤过率。</td>   <td>G16H50/30;G16H30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苗建明;              张文睿;              孙兴宇;              邓侃侃;              仝懿聪;              王燕云;              刘文超;              郑若晗;              龚喜;              彭超;                   刘涛       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种水下图像复原方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN114926353B</td>   <td>2023-05-23</td>   <td>本发明公开了一种水下图像复原方法、装置、设备及存储介质,通过获取原始水下图像中图块的像素值,得到背景光值；同时构建场景深度预估模型,获取场景深度,并基于场景深度对原始水下图像的后向散射分量预估值、后向散射分量值、直接分量透射率等相关参数进行预估,并将得到的背景光值、后向散射分量值和直接分量透射率代入构建的物理成像模型中进行反演退化,得到第一水下复原图像。与现有技术相比,本发明的技术方案通过获取水下图像的场景深度,对水下图像的相关参数进行预估,并对构建物理成像模型的反演退化,实现水下图像进行复原处理,减少了对人工的依赖性,提高对水下图像复原的效率和精度。</td>   <td>1.一种水下图像复原方法,其特征在于,包括：获取原始水下图像,对所述原始水下图像进行图块划分,并基于划分出的图块的像素值,得到所述原始水下图像的背景光值；获取所述原始水下图像在RGB颜色空间中各通道的像素值,根据预设的颜色空间转换公式,计算并得到所述原始水下图像在HSI颜色空间中的亮度值和饱和度；构建第一场景深度预估模型,将所述亮度值和所述饱和度输入到所述第一场景深度预估模型中,以使所述第一场景深度预估模型输出第一场景深度,其中,所述第一场景深度预估模型,如下所示：          ；式中,为HSI颜色空间下的亮度值,/&gt;为HSI颜色空间下的饱和度值,/&gt;为绝对值；构建第二场景深度预估模型,将所述像素值输入到所述第二场景深度预估模型中,以使所述第二场景深度预估模型输出第二场景深度,其中,所述第二场景深度预估模型,如下所示：          ；式中,为RGB颜色空间中蓝绿通道中的最大像素值,/&gt;为RGB颜色空间中红色通道像素值,/&gt;、/&gt;、/&gt;分别为权重常值,其中,/&gt;、/&gt;、/&gt;参数值的确定是基于采用Song方法提出的参数值,分别为0.53214829、0.51309827和-0.91066194；/&gt;函数表示利用最小值滤波进行优化处理,/&gt;是以/&gt;为中心的/&gt;邻域,r取值为5；构建线性加权融合模型,以使所述线性加权融合模型对所述第一场景深度和所述第二场景深度进行融合,得到场景深度；对所述场景深度所对应的场景深度图进行像素点筛选,根据所筛选出的各像素点对应的通道值,计算后向散射分量预估值,并根据所述后向散射分量预估值、所述场景深度和所述背景光值,计算后向散射分量值；获取所述原始水下图像中标准化残余能量比的中值,将所述中值作为直接分量透射率的衰减参数,并将所述衰减参数和所述场景深度输入到预设的透射率公式中,得到直接分量透射率；构建物理成像模型,将所述背景光值、所述后向散射分量值和所述直接分量透射率代入所述物理成像模型中,并对所述物理成像模型进行反演退化,得到第一水下复原图像。</td>   <td>G06T5/00;G06T5/50;G06T7/194;G06T7/90;G06T7/536</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈培祥;              崔德珍;              荣丽;              金尚怡;              曹红;                   崇雨田       </td>   <td>中山大学附属第三医院</td>   <td>一种防护服穿脱行为监管系统</td>   <td>广东省</td>   <td>CN116152927A</td>   <td>2023-05-23</td>   <td>本发明公开了一种防护服穿脱行为监管系统,包括身份识别模块；在专用防护服穿脱间内设有至少一个数据采集模块,在专用防护服穿脱间内设有报警模块；还在专用防护服穿脱间内设有一用于识别人体进入该专用防护服穿脱间的人体感应模块,身份识别模块、数据采集模块、报警模块、人体感应模块均通过导电线束与一设在专用防护服穿脱间外部的监控终端电连接。本发明具有在医护人员穿脱防护服的过程中能够及时全面地监管防护服的穿脱行为、监管省时省力并且当医护人员出现穿脱行为不符合规范的突发状况时能够及时进行应急预警干预处理、还能够对医护人员出现的防护服穿脱行为问题进行集中处理以便于为后续的防护服穿脱行为策略提供指导依据的优点。</td>   <td>1.一种防护服穿脱行为监管系统,包括设在专用防护服穿脱间(100)的进入口外壁上用于供医护人员输入工卡号以进入该专用防护服穿脱间(100)的身份识别模块(1)；其特征在于：在专用防护服穿脱间(100)内设有至少一个用于进行人体行为姿态数据采集的数据采集模块(2),在专用防护服穿脱间(100)内设有一用于在出现突发状况时能够及时发出警报语音进行应急预警干预处理的报警模块(3)；还在专用防护服穿脱间(100)内设有一用于识别人体进入该专用防护服穿脱间(100)的人体感应模块(4),其中,所述身份识别模块(1)、数据采集模块(2)、报警模块(3)、人体感应模块(4)均通过导电线束与一设在专用防护服穿脱间(100)外部的监控终端(5)电连接；其还包括如下步骤：S1、医护人员通过身份识别模块(1)输入本人的工卡号进入该专用防护服穿脱间(100),此时,人体感应模块(4)识别到人体信息发出指定颜色的灯光,同时由身份识别模块(1)将该医护人员的身份信息传输至监控终端(5)建立个人信息模块；S2、由数据采集模块(2)实时采集专用防护服穿脱间(100)内的医护人员穿脱防护服的人体行为姿态数据,并将该人体行为姿态数据同步传输至监控终端(5)与预设在该监控终端(5)内部的防护服穿脱行为姿态模型进行比对,得到比对结果,同时将采集的人体行为姿态数据以及比对结果同步存储至该医护人员的个人信息模块中；S3、在比对结果中,若人体行为姿态数据与预设的防护服穿脱行为姿态模型不相符合时,则由监控终端(5)启动报警模块(3)工作及时发出警报语音进行应急预警干预处理,反之,则报警模块(3)不工作；S4、最后,通过监控终端(5)将比对结果中的人体行为姿态数据与预设的防护服穿脱行为姿态模型不相符合的部分数据进行集中分析处理,得到分析处理结果,并将该处理结果作为后续的防护服穿脱行为策略的指导依据。</td>   <td>G06V40/20;G06V20/52;G06V10/75;G06V10/94;G08B21/24;G08B7/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李荣昊;                   沈颖       </td>   <td>中山大学</td>   <td>模型训练方法、红外小目标检测方法、装置及电子设备</td>   <td>广东省</td>   <td>CN116152591A</td>   <td>2023-05-23</td>   <td>本申请公开了一种模型训练方法、红外小目标检测方法、装置及电子设备,其中的模型训练方法包括：利用特征增强网络对数据集进行图像超分辨率重构,利用改进YOLOv5模型进行模型训练时,结合Mosaic策略和Mixup策略对数据集进行数据增强,把增强数据集输入改进的YOLOv5模型进行训练；对YOLOv5模型的改进包括：在BackBone网络的特征层之间引入坐标注意力机制,在Neck网络增加浅层特征层P2,把Head网络中C3模块的BottleNeck块替换为Swin Transformer Block结构,训练得到的检测模型能够更好地把握图像的全局上下文信息,聚焦感兴趣的目标区域,解决过小目标过采样的特征丢失问题,有更好的鲁棒性。</td>   <td>1.一种模型训练方法,所述方法训练得到的模型用于红外小目标检测,包括：获取用于模型训练的数据集；利用特征增强网络对所述数据集进行超分辨率特征增强,得到第一增强数据集；对所述第一增强数据集进行二次数据增强得到第二增强数据集；把所述第二增强数据集输入改进的YOLOv5模型进行模型训练,得到用于红外小目标检测的检测模型；所述改进的YOLOv5模型在BackBone网络引入坐标注意力机制,和/或,Neck网络增加浅层特征层P2,配合Head网络构成四层检测层,和/或,把Head网络中C3模块中的BottleNeck块替换为Swin Transformer Block结构。</td>   <td>G06V10/774;G06V10/82;G06N3/08;G06T3/40;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              肖鹏;                   李嘉雄       </td>   <td>中山大学中山眼科中心</td>   <td>白内障眼底图像的修复方法、修复模型的训练方法及装置</td>   <td>广东省</td>   <td>CN115660985B</td>   <td>2023-05-19</td>   <td>本公开提供一种白内障眼底图像的修复方法、修复模型的训练方法及装置,该训练方法包括构建训练数据集,训练数据集包括清晰眼底图像以及与清晰眼底图像对应的参考白内障图像；利用生成器将参考白内障图像作为输入以通过多次下采样获取不同尺度的第一特征图,将第一特征图与相应的上采样的第二特征图进行融合,生成修复图像,利用判别器将参考白内障图像和对应的清晰眼底图像作为输入以输出第一判别结果,将参考白内障图像和对应的修复图像作为输入以输出第二判别结果；基于训练数据集、第一判别结果和第二判别结果获取目标损失,基于目标损失对修复模型进行训练以优化修复模型,进而获得用于修复白内障眼底图像的训练后的生成器。</td>   <td>1.一种白内障眼底图像的修复模型的训练方法,其特征在于,所述修复模型包括生成器和判别器,所述训练方法包括：构建训练数据集,所述训练数据集包括清晰眼底图像以及与所述清晰眼底图像对应的参考白内障图像；利用所述生成器将所述训练数据集中的所述参考白内障图像作为输入以通过多次下采样获取不同尺度的第一特征图,并将所述不同尺度的第一特征图与相应的经上采样获取的第二特征图进行融合,进而生成修复图像；利用所述判别器将所述参考白内障图像和对应的清晰眼底图像作为输入以输出针对所述清晰眼底图像的第一判别结果,并将所述参考白内障图像和对应的修复图像作为输入以输出针对所述修复图像的第二判别结果；并且基于所述训练数据集、所述第一判别结果和所述第二判别结果获取目标损失,并基于所述目标损失对所述修复模型进行训练以优化所述修复模型,进而获得用于修复白内障眼底图像的训练后的所述生成器；其中,所述目标损失包括第一损失、第二损失、第三损失和第四损失,所述第一损失由所述第一判别结果和所述第二判别结果确定,所述第二损失由所述修复图像与对应的清晰眼底图像之间像素的差异所确定,所述第三损失由基于卷积神经网络的特征提取器提取的所述修复图像与对应的清晰眼底图像之间的不同尺度的特征图的差异所确定,所述第四损失由所述修复图像与对应的清晰眼底图像之间的结构相似性所确定,所述第二损失为所述修复图像与对应的清晰眼底图像之间的像素L1损失,在确定所述第三损失时,将所述清晰眼底图像和所述修复图像输入所述特征提取器以分别提取针对所述修复图像的不同尺度的特征图以及针对所述清晰眼底图像的不同尺度的特征图,比较所述修复图像与对应的清晰眼底图像之间的不同尺度的特征图的差异,利用预设大小的滑窗以预设步长分别在所述修复图像和所述清晰眼底图像上滑动以确定各个窗口内的像素点,通过计算多个窗口中所述各个窗口内的像素值的统计值以获取所述第四损失,所述生成器包括具有多个下采样层的编码模块和具有多个上采样层的解码模块,所述编码模块用于对输入生成器的参考白内障图像进行所述多次下采样以获取所述不同尺度的第一特征图,所述解码模块中各个上采样层的输入包括经由尺度归一化的所述不同尺度的第一特征图、以及对应解码模块中前一个上采样层输出的所述第二特征图。</td>   <td>G06T5/00;G06T5/50;G06V10/82;G06V10/77;G06V10/80;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周晓聪;                   秦建华       </td>   <td>中山大学</td>   <td>一种面向方面的算法可视化方法及系统</td>   <td>广东省</td>   <td>CN112883035B</td>   <td>2023-05-19</td>   <td>本发明公开了一种面向方面的算法可视化方法及系统,涉及算法可视化领域,所述方法包括以下步骤：在算法层选择待演示的算法；对算法进行数据初始化；执行算法,将生成的上下文信息及其位置索引保存至上下文层；在演示层中划分不同算法的显示区域,将每个显示区域的当前视图索引与上下文层中保存的位置索引进行匹配,获取对应的上下文信息,根据预设的视图生成方法,在演示层中生成视图；判断算法是否执行完毕,若否,则将新生成的上下文信息继续保存至上下文层,进行上下文信息的更新,同时更新演示层中生成的视图,若是,则算法层输出算法最终的运行结果。本发明通过算法层、上下文层、演示层的配合,实现不同算法的同步对比。</td>   <td>1.一种面向方面的算法可视化方法,其特征在于,包括以下步骤：S1、在算法层选择待演示的算法；S2、对算法进行数据初始化；S3、执行算法,将生成的上下文信息及其位置索引保存至上下文层；所述生成的上下文信息采用二维数组的形式保存至上下文层；S4、在演示层中划分不同算法的显示区域,将每个显示区域的当前视图索引与上下文层中保存的位置索引进行匹配,获取对应的上下文信息,根据预设的视图生成方法,在演示层中生成视图；所述预设的视图生成方法包括数据结构、离散数学和图论中所有基础算法的视图生成方式；S5、判断算法是否执行完毕,若否,则将新生成的上下文信息继续保存至上下文层,进行上下文信息的更新,同时更新演示层中生成的视图,若是,则算法层输出算法最终的运行结果；其中,所述更新演示层中生成的视图,具体为：S5.1、预设视图刷新的时间间隔；S5.2、当到达预设的时间间隔时,检查每个显示区域的当前视图索引与上下文层中最新的位置索引是否一致,若是,则无需更新视图,若否,则将当前视图索引更新至与上下文层中最新的位置索引一致,根据更新后的当前视图索引找到新生成的上下文信息,并根据预设的视图生成方法,更新演示层中生成的视图。</td>   <td>G06F16/22;G06F16/28</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;                   高凯诗       </td>   <td>中山大学</td>   <td>一种垂直鱼眼镜头下行人属性分析方法及系统</td>   <td>广东省</td>   <td>CN110717544B</td>   <td>2023-05-16</td>   <td>本申请公开了一种垂直鱼眼镜头下行人属性分析方法及系统,将垂直鱼眼镜头获取的行人图片进行预处理,将预处理后的行人图片输入预设网络进行体态分类,获得每张行人图片的不同体态特征对应的概率；确定每张行人图片的体态分类损失和属性标签损失,对预设网络通过多次迭代的方式进行参数优化使得预设网络的损失进行收敛达到预设损失,通过优化后的所述预设网络确定行人图片的行人属性信息。通过垂直鱼眼镜头获取的行人图片对预设网络进行训练优化,使得训练后的网络的网络损失达到预设损失,利用了垂直鱼眼镜头下行人的特征对网络进行了改良,使得网络针对垂直鱼眼镜头下的行人有更好的属性分析结果,实现对垂直鱼眼镜头下的行人属性的分析。</td>   <td>1.一种垂直鱼眼镜头下行人属性分析方法,其特征在于,所述方法包括：将垂直鱼眼镜头获取的行人图片进行预处理,以使得每张行人图片都携带有行人属性标签；将预处理后的行人图片输入预设网络进行体态分类,获得每张行人图片的不同体态特征对应的概率；确定每张行人图片的体态分类损失和属性标签损失,所述体态分类损失和属性标签损失用于确定所述预设网络的损失；对所述预设网络通过多次迭代的方式进行参数优化使得所述预设网络的损失进行收敛达到预设损失,通过优化后的所述预设网络确定行人图片的行人属性信息；所述将垂直鱼眼镜头获取的行人图片进行预处理包括：对于所有训练数据中的行人图片,根据体态将行人图片分为垂直体、斜正体、斜侧体、斜背体四类,标记对应体态标签；对不同体态下的行人,标记对应的属性标签,其中不能表现的属性标识符为0；对选取的行人图片进行数据读取时,进行旋转操作；将数据进行归一化操作,以使得所述行人图片对应的数据符合预设网络的输入要求；所述将预处理后的行人图片输入预设网络进行体态分类,获得每张行人图片的不同体态特征对应的概率包括：使用ImageNet预训练好的GoogleNet网络inception前K层作为从输入垂直鱼眼行人图片I中提取的体态特征图F-k,作为经过平均池化操作后输入softmax层,得到该行人图片四种体态对应的概率矩阵Y-(pose)＝[y1pose,y2pose,y3pose,y4pose]～T；根据所述体态概率矩阵Y-(pose)从标注数据中已知其真正体态概率为使用softmax loss计算体态损失其中N为每个batch中的行人图片数量；所述确定每张行人图片的体态分类损失和属性标签损失,所述体态分类损失和属性标签损失用于确定所述预设网络的损失,包括：获取四种体态对应的全连接层得到四种体态下的特征输出                  将与对应体态概率Y-(pose)＝[y1pose,y2pose,y3pose,y4pose]～T相乘得到最后整体图像特征F-(final),最后将整体特征F-(final)输入softmax层得到属性概率矩阵Y-c＝[y～1-ty～2-c,y～3-c............y～n-c]～T,其中n代表属性标签的数量,每个值代表一个属性标签的对应概率；通过所述属性概率矩阵Y-c和已知的真正属性标签在训练过程中通过带先验知识的交叉熵计算属性损失/&gt;          其中N为每个batch中的图片数量,C为属性标签的总数量,ω-c为先验属性权值,ω-c＝exp(a-c),a-c为该属性标签数量在对应属性上的占比。</td>   <td>G06V40/10;G06V20/40;G06V20/52;G06V10/764;G06V10/774;G06V10/82;G06N3/045;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              邓铭豪;              陈荣军;              谢舜道;              何彦东;              苏宏雄;              朱雄泳;                   曾衍瀚       </td>   <td>中山大学</td>   <td>一种基于暗通道先验的图像去雾改进方法</td>   <td>广东省</td>   <td>CN110148093B</td>   <td>2023-05-16</td>   <td>本发明提供了一种基于暗通道先验的图像去雾改进方法,包括以下步骤：输入雾天图像,得到雾天图像的暗通道图像和亮通道图像；利用四叉树搜索方法得到大气光估计值,结合亮通道图像和大气光估计值得到大气光图像；计算得到透射率图像,结合大气光图像对透射率图像进行阈值处理；对透射率图像进行精细化处理,输出去雾的复原图像。本发明提供一种基于暗通道先验的图像去雾改进方法,避免出现无法存在白色或无法适应天空域的雾天图像问题,且将透射率进行阈值处理,有效改进了天空域部分的透射率过低导致的颜色失真问题提高了图像的亮度和对比度,减少图像的信息熵的丢失；且该方法计算过程简单,具有实时性。</td>   <td>1.一种基于暗通道先验的图像去雾改进方法,其特征在于,包括以下步骤：S1：输入雾天图像,得到雾天图像的暗通道图像和亮通道图像；S2：利用四叉树搜索方法得到大气光估计值,结合亮通道图像和大气光估计值得到大气光图像；S21：将暗通道图像裁剪成相同尺寸的子图像,分别计算各子图像的均值和标准差,并分别比较各子图像的均值和标准差的差值,将差值较大的子图像重复步骤S21,直至子图像的像素点个数少于阈值；S22：在暗通道图像上对应出子图像的区域,分别求出各个区域的三通道像素平均值,将最小值即为大气光估计值；S23：将亮通道图像与大气光估计值进行计算得到大气光图像A,具体计算公式为：A＝a*Lc+b*A0,(a+b&lt;1)；其中,Lc表示步骤S13求得的亮通道图像；A0为步骤S22求得的大气光估计值；S3：计算得到透射率图像,结合大气光图像对透射率图像进行阈值处理；所述步骤S3具体包括以下步骤：S31：按照暗通道先验理论的透射率估计公式得到透射率图像；S32：对大气光图像与暗通道图像做差值,得到差值图像；将差值图像每一个像素值与雾天图像标准差做比较,若比标准差小则将透射率图像对应点的像素值乘以标准差与差值的比值；S33：将透射率图像进行阈值处理,对透射率图像像素值小于0.1的像素点置0.1,大于0.9的像素点置0.9；S4：对透射率图像进行精细化处理,输出去雾的复原图像；所述步骤S4具体包括以下步骤：S41：利用步骤S12得到的暗通道图像作为引导滤波图像,对步骤S33得到的透射率图像进行快速引导滤波,得到细化透射率图像t；S42：将大气光图像A和细化透射率图像代入大气散射模型中,得到去雾的复原图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韩佳琪;                   卓汉逵       </td>   <td>中山大学</td>   <td>基于强化学习和迁移学习的图像语义分割模型及建模方法</td>   <td>广东省</td>   <td>CN110866922B</td>   <td>2023-05-16</td>   <td>本发明涉及图像的语义分割技术领域,更具体地,涉及一种基于强化学习和迁移学习的图像语义分割模型及建模方法,包括顺次通信连接的用于对原始图像进行预处理的预处理模块、用于强化学习中的环境部分的感知模块、用于强化学习中的智能体部分的像素类别决策模块。本发明将图像语义分割看成一种序列决策的过程,顺序地决定各像素的类别而不是一次性生成整张图像的分割结果,能够有效利用像素与像素之间的关系,减少训练时间,提高图像分割效果的精确性。</td>   <td>1.一种基于强化学习和迁移学习的图像语义分割的建模方法,其特征在于,包括以下步骤：S1.通过预处理模块对图像数据集进行预处理,将原始图像剪裁成固定大小,并随机旋转,得到数据集&lt;图像X,标注图像Y＞,划分训练集和测试集；S2.利用迁移学习对图像特征提取子模块的卷积神经网络参数θ进行初始化；S3.利用强化学习的深度Q网络框架,使用所述训练集,对所述图像特征提取子模块的卷积神经网络进行训练；其中,所述步骤S3的具体步骤如下：S31.从训练集采样得到原始图像x与标注图像y,对于训练集的每张图像x-i,状态生成子模块将原始图像与初始像素类别决策矩阵拼接,生成得到初始状态s-1；S32.使用分级策略,确定本轮次的分块大小m,每个分块内的像素在类别决策时选择同一个动作,且每张图像每轮次的分块大小m逐渐减小,使每张图像从粗略到精细进行分割；S33.当进入第一轮次时,直接执行步骤S34；当进入第n(n≥2)轮次时,判断每个分块是否处于边界或图像的最后一个分块；若是,则执行步骤S34,否则保留当前分块在上一轮的类别决策,直接将状态移动到下一分块,重复执行步骤S33；S34.像素类别选择子模块根据ε-greedy策略选择动作a,以ε的概率随机选择动作a-τ,以1-ε的概率根据所述图像特征提取子模块输出的Q值选择动作a-τ＝max-aQ(s-τ,a；θ)；其中,s-τ表示当前状态,θ表示所述图像特征提取子模块的卷积神经网络参数；S35.在步骤S34之后,所述状态生成子模块根据当前状态s-τ与像素类别选择动作a-τ得到新状态s-(τ+1)；S36.在步骤S35之后,奖励生成子模块根据新状态s-(τ+1)的像素类别决策部分与图像x-i对应的标注图像y-i,生成奖励r-τ；所述奖励r-τ包括分割效果奖励r-base-τ和分割比例奖励r-ratio-τ；S37.在步骤S36之后,将(s-τ,a-τ,r-τ,s-(τ+1))存储在经验回放存储器Ω中；若经验回放存储器Ω中的记录达到一定数量后,每个训练步骤从经验回放存储器Ω中采样,采样的每条记录记为(s-j,a-j,r-j,s-(j+1))；对于每条记录,计算目标值y-j和损失函数L(θ),并更新卷积神经网络参数θ,然后执行步骤S38；若所述经验回放存储器Ω中的记录没有达到一定数量,则执行步骤S38；S38.判断目前该分块是否为本图像的最后一个分块,若是,则进入步骤S39；否则,将状态移动到下一分块,然后回到步骤S33；S39.若分块大小m不等于1,则回到步骤S32,进入下一轮次；若分块大小m等于1,则使用下一张图像从步骤S31开始训练模型；S4.使用步骤S3中训练好的参数对测试集图像的分割结果进行预测；其中,所述步骤S4的具体步骤如下：S41.对于所述测试集的每张图像x-test-i,所述状态生成子模块将原始图像与初始像素类别决策矩阵拼接,得到初始状态s-test-1；S42.使用所述分级策略,确定本轮次的分块大小m；S43.当进入第一轮次时,直接执行步骤S44；当进入第n(n≥2)轮次时,判断每个分块是否处于边界或图像的最后一个分块；若是,则执行步骤S44,否则保留当前分块在上一轮次的类别决策,直接将状态移动到下一分块,重复执行步骤S43；S44.所述像素类别选择子模块根据图像特征提取子模块输出的Q值选择动作a-test-τ＝max-a Q(s-test-τ,a；θ)；S45.在步骤S44之后,所述状态生成子模块根据当前状态s-test-τ与像素类别选择动作a-test-τ得到新状态s-test-(τ+1)；S46.在步骤S45之后,判断目前该分块是否为本图像的最后一个分块,若是,则进入步骤S47；否则,将状态移动到下一分块,然后回到步骤S43；S47.若分块大小m不等于1,则回到步骤S42,进入下一轮次；若分块大小m等于1,则得到预测的图像语义分割结果并输出。</td>   <td>G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              何彦东;              邓铭豪;              陈荣军;              谢舜道;              苏宏雄;              朱雄泳;                   曾衍瀚       </td>   <td>中山大学</td>   <td>基于改进Retinex与对数图像处理的低照度图像增强方法</td>   <td>广东省</td>   <td>CN110298796B</td>   <td>2023-05-16</td>   <td>本发明提供了一种基于改进Retinex与对数图像处理的低照度图像增强方法,包括：计算样本图像的亮通道值,将该值作为样本图像的光照分量；利用现有的对数图像处理模型下的背景强度对光照分量进行自适应局部调整；结合Sobel边缘检测方法,对局部调整后的光照分量进行滤波细化；根据细化后的光照分量,基于Retinex理论得到增强图像。本发明提供一种基于改进Retinex与对数图像处理的低照度图像增强方法,在现有的对数图像处理模型下结合了Retinex理论,对样本图像进行了加强,有效地解决了Retinex算法可能存在的光晕效应以及过增强的问题,该方法能适应更多样的光照环境。</td>   <td>1.基于改进Retinex与对数图像处理的低照度图像增强方法,其特征在于,包括以下步骤：S1：计算样本图像的亮通道值,将该值作为样本图像的光照分量；S2：利用现有的对数图像处理模型下的背景强度对光照分量进行自适应局部调整；步骤S2具体包括以下步骤：S21：将样本图像的光照分量转换为对数图像处理模型下的表达,即将样本图像的灰度值表示为：f(x,y)＝M-I(x,y)；上式中,I(x,y)表示样本图像的像素值,f(x,y)为对数图像处理模型下的图像灰度值,M为图像像素值的最大值,对于8位数字图像为256；S22：根据每个像素点的邻域像素值计算样本图像的平均背景强度；S23：根据每个像素点的平均背景强度得到每个像素点对应的亮度调整系数；S24：将亮度调整系数代入对数图像处理模型中的数乘运算,完成对光照分量的局部调整；步骤S22中所述的每个像素点的邻域像素值按8邻域进行检测而得到；根据人眼视觉的方向特性,人眼对水平和垂直方向上的亮度变化比斜线方向上的亮度变化更敏感,因此所述8邻域中四个邻域像素值与对角线上四个邻域像素值根据不同的比例权重计算背景强度,从而得到更符合人眼视觉特性的背景强度；设四邻域比例系数为a,对角线上四邻域比例系数为b,平均背景强度根据以下公式计算：                  上式中,a和b表示比例权重,∑-QX(i,j)为像素点(i,j)的四个邻域像素的集合,∑-DX(i,j)为像素点(i,j)的对角线上四个邻域像素的集合；其中,与分别为对数图像处理模型中的相加与相乘操作；根据平均背景强度B(x,y)计算变换系数γ(x,y),具体为：γ(x,y)＝a(1-cos(B(x,y)×π))；将变换系数γ(x,y)代入对数图像处理模型的数乘运算,得到以下公式：                  式中,L(x,y)为增强后的光照分量,L-0(x,y)为步骤S1所得到的样本图像的光照分量,至此得到局部调整后的光照分量；S3：结合Sobel边缘检测方法,对局部调整后的光照分量进行滤波细化；步骤S3具体包括以下步骤：S31：运用Sobel边缘检测方法提取局部调整后的光照分量的边缘图像；S32：根据边缘图像求取各像素点的平滑因子；S33：根据各像素点的平滑因子对局部调整后的光照分量进行滤波、细化,得到细化后的光照分量；S4：根据细化后的光照分量,基于Retinex理论得到增强图像；步骤S4具体包括以下步骤：S41：输入低照度的样本图像并进行颜色通道分离,得到三个通道各像素点的像素值；S42：分别把三个通道各像素点的像素值除以经调整与细化后的光照分量中对应的像素点的像素值,得到三个新的颜色通道；S43：将三个新的颜色通道进行合成,得到增强图像。</td>   <td>G06T5/00;G06T7/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈武亚;                   权小军       </td>   <td>中山大学</td>   <td>一种基于门限卷积神经网络的机器阅读理解方法</td>   <td>广东省</td>   <td>CN109460553B</td>   <td>2023-05-16</td>   <td>本发明提供一种基于门限卷积神经网络的机器阅读理解方法,通过构建门限卷积神经网络模型,包括输入层、门限卷积层和答案层；输入层用于编码目标文章,将编码的文章向量序列、问题向量序列和答案向量序列传送给所述门限卷积层；门限卷积层通过交互的方式产生具有高层语义信息的文章,问题,答案表达,并将这些表达传送给答案层；最后由答案层进行推理决策,做出预测；确定目标文章,导入门限卷积神经网络模型中进行机器阅读理解,导出预测结果。本发明提供的一种基于门限卷积神经网络的机器阅读理解方法,有效简化了神经网络模型,大大减少了训练和测试时长,提高了处理效率,提升了用户体验感；保持文本的长期依赖关系,准确预测出答案信息。</td>   <td>1.一种基于门限卷积神经网络的机器阅读理解方法,其特征在于,包括以下步骤：S1：构建门限卷积神经网络模型,包括输入层、门限卷积层和答案层；其中,所述输入层用于编码目标文章,将编码的文章向量序列、问题向量序列和答案向量序列传送给所述门限卷积层；所述门限卷积层通过交互的方式产生具有高层语义信息的文章,问题,答案表达,并将这些表达传送给答案层；最后由所述答案层进行推理决策,做出预测；步骤S1中,所述输入层利用多方位信息编码目标文章,计算每个单词的多个角度的特征表达,包括：词语嵌入、关系嵌入、词性标注和命名实体嵌入、特征嵌入；其中：所述词语嵌入通过300维Glove词向量初始化词语嵌入矩阵,选择词频最高的10个单词对应的词向量进行微调,从而得到每个词对应的词语嵌入；所述关系嵌入通过提取ConceptNet库中所有的关系并为每个提取出来的关系赋值一个随机初始化的10维向量,将关系嵌入变成一个二维矩阵,矩阵行数为ConceptNet库的关系总数,列数为10；对于目标文章每个单词,若在ConceptNet库中存在一条连接该单词和问题与答案中任一单词的边,那该单词的关系嵌入就是该边所对应的向量；所述词性标注和命名实体嵌入先计算目标文章的每个单词的词性、所属的实体类型；然后将每个单词的词性训练为49个不同类型的词性标签,每个初始化为10维向量；最后将每个单词所属的实体类型训练为18个不同的标签,每个初始化为8维向量；所述特征嵌入包括：对数词频特征、词语共现特征、词语模糊匹配特征；所述对数词频特征为基于英语维基百科统计每个单词的词频,取其对数作为该单词的对数词频特征；所述词语共现特征是一个二元特征,若一个单词同时出现在文章、问题和答案中,该单词就具备词语共现特征；所述词语模糊匹配特征仅需要部分匹配即可；步骤S1中,所述门限卷积层包括门限机制模块,该模块的具体计算公式为：g-i＝relu(w-(i:i+k)*w-g+V-gv-g+b-g)；o-i＝tanh(w-(i:i+k)*w-o+b-o)；c-i＝g-i·o-i；其中,*为卷积操作；wi:ik为被卷积的文章向量、问题向量或答案向量；wg和wo为卷积核；vg为参考向量；Vg和bg分别为线性变换参数和偏置参数；oi为对文本向量经过卷积后得到的特性映射；gi为结合参考向量；c-i作为实际输出的比值,即为控制信息流动的门控；通过所述门限机制模块的一维卷积,门限卷积神经网络模型对文章、问题、答案进行交互,产生高层语义信息表达；所述门限卷积层还包括最大池化模块和自注意力机制；所述门限卷积神经网络模型对文章、问题、答案的交互具体包括以下步骤：S21：利用普通卷积核为1和3的卷积网络对问题向量序列进行卷积并通过最大池化模块进行池化处理,得到一个表征问题语意信息的向量；S22：将表征问题语意信息的向量作为参考向量,结合卷积核为3、4、5的一维卷积和门限机制模块对答案向量序列进行运算操作,并通过最大池化模块进行池化处理,得到一个表征答案语意信息的向量；S23：将表征问题和答案语意信息的向量作为参考向量,结合卷积核为3、4、5的一维卷积和门限机制模块对文章向量序列进行运算操作,然后利用自注意力机制将目标文章文本每个单词的向量经过线性变换转化为一个标量,用softmax函数将得到的标量转化为对应的概率,即每个单词的权重,最后对这些单词向量加权求和,得到一个表征文章语义信息的向量；S2：确定目标文章,导入门限卷积神经网络模型中进行机器阅读理解,导出预测结果。</td>   <td>G06F40/284;G06F40/30;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈亮;              于宙鑫;              周克涌;              郑子彬;              王福海;                   纳颖泉       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>套餐推荐方法、装置、计算机设备、存储介质和程序产品</td>   <td>广东省</td>   <td>CN116127195A</td>   <td>2023-05-16</td>   <td>本申请涉及一种套餐推荐方法、装置、计算机设备、存储介质和计算机程序产品。该方法包括：获取预设用户的特征及预设套餐集合；将预设用户的特征及预设套餐集合输入至预设套餐推荐模型中进行套餐推荐,生成预设用户的套餐推荐结果；其中,预设套餐集合及预设套餐推荐模型为基于初始超图卷积神经网络模型进行训练所生成的；预设套餐集合包括多个预设套餐,预设套餐包括多个预设产品。采用本方法相比于传统方法中只能使用多张图采用图神经网络模型才能对不同的用户进行套餐推荐的方法,能够降低套餐推荐的复杂性,且能够提高套餐推荐的准确性。</td>   <td>1.一种套餐推荐方法,其特征在于,所述方法包括：获取预设用户的特征及预设套餐集合；将所述预设用户的特征及所述预设套餐集合输入至预设套餐推荐模型中进行套餐推荐,生成所述预设用户的套餐推荐结果；其中,所述预设套餐集合及所述预设套餐推荐模型为基于初始超图卷积神经网络模型进行训练所生成的；所述预设套餐集合包括多个预设套餐,所述预设套餐包括多个预设产品。</td>   <td>G06F16/9535;G06F18/22;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;                   包笛       </td>   <td>中山大学</td>   <td>一种基于多尺度透视感知型网络的人群计数方法</td>   <td>广东省</td>   <td>CN110991317B</td>   <td>2023-05-16</td>   <td>本发明涉及图像处理和计算机视觉技术,为基于多尺度透视感知型网络的人群计数方法,包括步骤：根据原图像生成密度图和透视图,形成密度图和透视图数据集；构建神经网络模型,该神经网络模型分为主干网络和透视图分支网络；基于密度图和透视图数据集,训练神经网络模型,并利用训练好的神经网络模型输出密度图,得到人群计数结果。本发明的神经网络在每列网络使用不同扩张率的空洞卷积使得网络进行多尺度人头的特征提取,获得人群密度计数所需的密度图,对人群密度进行准确计算。</td>   <td>1.一种基于多尺度透视感知型网络的人群计数方法,其特征在于,包括以下步骤：S1、数据预处理,根据原图像生成密度图和透视图,形成密度图和透视图数据集；S2、构建神经网络模型,该神经网络模型分为主干网络和透视图分支网络；S3、基于密度图和透视图数据集,训练神经网络模型,并利用训练好的神经网络模型输出密度图,得到人群计数结果；所述主干网络包括至少三列利用空洞卷积进行计算的卷积神经网络,在每列卷积神经网络使用不同扩张率的空洞卷积使得神经网络进行多尺度人头的特征提取,获得人群密度计数所需的密度图；步骤S2所述主干网络包括前半部分和后半部分；主干网络前半部分分为4个阶段,第一阶段、第二阶段均为：连续两个卷积层,然后接一个最大池化层；第三阶段、第四阶段均为：连续三个卷积层,然后接一个最大池化层；主干网络后半部分是延伸出的三列利用空洞卷积进行计算的卷积神经网络；第一列为空洞卷积；第二列为空洞卷积,等价于普通卷积,卷积核尺寸和数量与第一列相同；第三列为混合空洞卷积,卷积核尺寸和数量与第一列相同；步骤S2所构建的神经网络模型把透视图分支网络所输出的透视图的值进行归一化,然后将归一化的值作为权重和神经网络模型的主干网络所生成的人头特征图进行合并,得到新的密度图作为神经网络模型的输出结果。</td>   <td>G06V20/52;G06N3/0464;G06N3/08;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢志;              周昊;                   何尧       </td>   <td>中山大学中山眼科中心</td>   <td>婴幼儿眼底视网膜全景影像生成采集反馈方法及系统</td>   <td>广东省</td>   <td>CN114897678B</td>   <td>2023-05-16</td>   <td>本发明公开了一种婴幼儿眼底视网膜全景影像生成采集反馈方法及系统,利用深度学习技术分别实现了配准模型和融合模型的建模设计和训练流程。通过实现影像文件监测,多图像持续配准,多图像持续融合以及全景影像图谱提示等模块功能,设计了一种婴幼儿眼底视网膜全景影像生成和反馈系统,能够在使用者采集数据过程中实时显示已采集数据的拼接图,提示已采集影像范围、未采集区域以及生成并显示视网膜全景影像。</td>   <td>1.一种婴幼儿眼底视网膜全景影像生成采集反馈方法,其特征在于,包括以下步骤：S1：采集婴幼儿眼底影像并将采集到的婴幼儿眼底影像送入至保存路径中；S2：自动监测保存路径中的是否有新的婴幼儿眼底影像,当有新的婴幼儿眼底影像时,将新的婴幼儿眼底影像送入至缓冲队列；S3：判断缓冲队列中的队列长度是否大于两个婴幼儿眼底影像,小于两个婴幼儿眼底影像时,继续等待；不小于两个婴幼儿眼底影像的话开始进行拼接和融合；S4：将缓冲队列中的两个婴幼儿眼底影像分别经过预训练的配准模型和融合模型得到拼接图；S5：监测拼接图中的视盘,以视盘为中心,将拼接图更新至预先准备的视网膜全景图谱图上；S6：根据所述视网膜全景图谱图和拼接图盘评估当前采集的影像范围和质量,决定是否继续采集数据,当确认采集完毕时,执行步骤S8；若需要继续采集数据,执行步骤S7：S7：将缓冲队列中新增的婴幼儿眼底影像与拼接图分别经过预训练的配准模型和融合模型得到新的拼接图,返回步骤S5；S8：输出当前的拼接图作为全景视网膜影像结果。</td>   <td>G06T3/40;G06T5/50;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈亮;              廖婕;              周克涌;              郑子彬;              张文锋;                   邓文强       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>物品推荐方法、装置、计算机设备、存储介质和程序产品</td>   <td>广东省</td>   <td>CN116128575A</td>   <td>2023-05-16</td>   <td>本申请涉及一种物品推荐方法、装置、计算机设备、存储介质和计算机程序产品。方法包括：根据用户节点、与用户节点对应的物品节点、用户节点之间的关系、用户节点与物品节点之间的关系,构建初始无向无权图；用户节点包括与头部用户对应的头部节点及长尾用户对应的长尾节点；将初始无向无权图输入至预设图自编码器模型中,对长尾节点与其他节点之间的关系进行更新,生成目标无向无权图；根据初始无向无权图及目标无向无权图,对长尾用户进行物品推荐,生成物品推荐结果。采用本方法能够根据构建的初始无向无权图及包含更全面反馈信息的目标无向无权图,就能够较准确地对长尾用户进行物品推荐,从而生成较准确的物品推荐结果。</td>   <td>1.一种物品推荐方法,其特征在于,所述方法包括：根据用户节点、与所述用户节点对应的物品节点、所述用户节点之间的关系、所述用户节点与所述物品节点之间的关系,构建初始无向无权图；所述用户节点包括与头部用户对应的头部节点及长尾用户对应的长尾节点；将所述初始无向无权图输入至预设图自编码器模型中,对所述长尾节点与其他节点之间的关系进行更新,生成目标无向无权图；根据所述初始无向无权图及所述目标无向无权图,对所述长尾用户进行物品推荐,生成物品推荐结果。</td>   <td>G06Q30/0251;G06Q40/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         左典;              郁鹏鹏;              梁凡;                   孙伟       </td>   <td>中山大学</td>   <td>基于双分支神经网络的大规模点云几何压缩方法</td>   <td>广东省</td>   <td>CN116128985A</td>   <td>2023-05-16</td>   <td>本发明公开了基于双分支神经网络的大规模点云几何压缩方法,包括：将点云表示为节点序列,经过稠密特征窗口与稀疏特征窗口采集,并将两个窗口的采集结果输入到包括稠密上下文分支与稀疏上下文分支的基于Transformer的双分支神经网络,有效地提取稀疏的大规模上下文和局部细节上下文,稠密特征采样结果与稀疏特征采样结果可以互补,避免压缩所有的点云,从而减少空间占用,进而将稀疏上下文特征与稠密上下文特征进行融合,并确定节点占用码及概率分布,然后通过熵模型将占用码及概率分布进行编码,最终实现对大规模点云的高效压缩。本发明可以减少大规模点云压缩的占用空间且效率较高,可广泛应用于点云压缩领域。</td>   <td>1.基于双分支神经网络的大规模点云几何压缩方法,其特征在于,包括：将输入的点云以八叉树形式表示,并通过祖先节点聚合模块将所述八叉树表示为节点序列；利用稠密特征窗口对所述节点序列进行采样,得到稠密特征采样结果；利用稀疏特征窗口对所述节点序列进行采样,得到稀疏特征采样结果；所述稠密特征窗口的窗口长度小于所述稀疏特征窗口的窗口长度；将所述稠密特征采样结果输入到基于Transformer的双分支神经网络中的稠密上下文分支,得到稠密上下文特征；将所述稀疏特征采样结果输入到基于Transformer的双分支神经网络中的稀疏上下文分支,得到稀疏上下文特征；通过特征混合模块将所述稠密上下文特征与稀疏上下文特征进行融合,得到融合特征；通过所述双分支神经网络根据所述融合特征确定所述稠密特征采样结果与所述稀疏特征采样结果中的每个节点的占用码与占用码的概率分布；将所述占用码与占用码的概率分布输入到熵模型,得到所述熵模型编码后输出的码流。</td>   <td>G06T9/40;G06T9/00;G06V10/77;G06V10/80;G06V10/82;G06N3/0455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              李辉忠;              黄明源;              张开翔;              范瑞彬;              白兴强;                   李成博       </td>   <td>深圳前海微众银行股份有限公司;中山大学</td>   <td>一种智能合约检测方法及装置</td>   <td>广东省</td>   <td>CN116127480A</td>   <td>2023-05-16</td>   <td>本申请实施例提供一种智能合约检测方法及装置,该方法包括：新智能合约为旧智能合约的更新版本；通过反编译分别获取旧智能合约对应的第一操作码记录和新智能合约对应的第二操作码记录,第一操作码记录和第二操作码记录分别用于,记录旧智能合约和新智能合约反编译时,执行的各操作码以及各操作码的执行顺序；根据第一操作码记录和第二操作码记录,分别获取旧智能合约中各第一状态变量各自的第一存储位置信息,以及新智能合约中各第二状态变量各自的第二存储位置信息；分别比较各第一存储位置信息与对应的第二存储位置信息是否存在差异,若存在,则更新失败。上述方法中,可以保证更新后获得的新智能合约,可以继承旧智能合约的服务。</td>   <td>1.一种智能合约检测方法,其特征在于,所述方法包括：获取旧智能合约和新智能合约,所述新智能合约为所述旧智能合约的更新版本；对所述旧智能合约和所述新智能合约进行反编译,分别获取所述旧智能合约对应的第一操作码记录和所述新智能合约对应的第二操作码记录,所述第一操作码记录和所述第二操作码记录分别用于,记录所述旧智能合约和所述新智能合约反编译时,执行的各操作码以及各操作码的执行顺序；根据所述第一操作码记录和所述第二操作码记录,分别获取所述旧智能合约中各第一状态变量各自的第一存储位置信息,以及所述新智能合约中各第二状态变量各自的第二存储位置信息；分别比较各第一存储位置信息与对应的第二存储位置信息是否存在差异,若存在差异,则所述新智能合约更新失败。</td>   <td>G06F21/60;G06F21/64;G06F16/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏胤宁;                   任江涛       </td>   <td>中山大学</td>   <td>一种基于排序学习的相似患者检索方法</td>   <td>广东省</td>   <td>CN112836012B</td>   <td>2023-05-12</td>   <td>本发明涉及信息检索领域,具体公开了一种基于排序学习的相似患者检索方法,包括以下步骤：构建基于排序学习的患者信息检索模型；获取患者病历文本数据库,分别组建训练文本集和测试文本集；对训练文本集进行数据预处理,再输入至所构建的基于排序学习的患者信息检索模型中进行模型训练；将待测患者病历文本与测试文本集中每个患者病历文本组成文本对,输入训练得到的基于排序学习的患者信息检索模型中进行相似度评分,得到最终检索结果。本发明建立了基于排序学习的检索模型,将相似患者的检索转化为信息检索任务,并实现有监督学习的过程,取代传统排序学习中采用的无监督学习方式,解决难以融合多种信息的问题,有效提升相似患者检索准确率。</td>   <td>1.一种基于排序学习的相似患者检索方法,其特征在于,包括以下步骤：S1：构建基于排序学习的患者信息检索模型；S2：获取患者病历文本数据库,分别组建训练文本集和测试文本集；S3：对训练文本集进行数据预处理,再输入至所构建的基于排序学习的患者信息检索模型中进行模型训练；S4：将待测患者病历文本与测试文本集中每个患者病历文本组成文本对,输入训练得到的基于排序学习的患者信息检索模型中进行相似度评分,得到最终检索结果；在所述步骤S1中,所构建的基于排序学习的患者信息检索模型包括第一编码层、第二编码层、交互层、全连接层、预测层；其中：所述第一编码层和所述第二编码层的输入作为所述基于排序学习的患者信息检索模型的输入；所述第一编码层输出端、所述第二编码层输出端与所述交互层输入端连接；所述交互层输出端与所述全连接层输入端连接；所述全连接层输出端与所述预测层输入端连接；所述预测层的输出作为所述基于排序学习的患者信息检索模型的输出；其中：将患者病历文本A输入所述第一编码层中进行向量化,得到隐含层向量a；将患者病历文本B输入所述第二编码层中进行向量化,得到隐含层向量b；将隐含层向量a、隐含层向量b输入所述交互层,分别得到患者病历文本A的最终表示向量a'、患者病历文本B最终表示向量b'、患者病历文本A和患者病历文本B的相似度向量c；其中：所述交互层包括注意力层、卷积层；其中：所述注意力层输入端与所述第一编码层输出端、所述第二编码层输出端连接；所述注意力层输出端与所述卷积层输入端、所述全连接层输入端连接；所述卷积层输出端与所述全连接层输入端连接；其中：将隐含层向量a、隐含层向量b输入至所述注意力层并进行点乘,得到相似度矩阵；将相似性矩阵作为注意力权重,在所述注意力层中分别对隐含层向量a、隐含层向量b作加权处理和最大池化处理,得到最终表示向量a'、最终表示向量b'；将相似性矩阵输入至所述卷积层并进行特征提取,得到相似度向量c；将最终表示向量a'、最终表示向量b'、相似度向量c输入所述全连接层进行拼接；将拼接完成后的向量输入所述预测层进行相似度评分。</td>   <td>G06F16/33;G06F16/338;G06F18/25;G06F18/22;G16H10/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              刘洋旗;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种CT结肠影像内容物的标注方法及系统</td>   <td>广东省</td>   <td>CN113379735B</td>   <td>2023-05-12</td>   <td>本发明公开了一种CT结肠影像内容物的标注方法及系统,该方法包括：获取CT结肠影像数据集并进行标注；对带标注的CT结肠影像数据集进行预处理；基于预处理后的CT影像数据集训练预构建的3D Inception网络和改进的U-net网络；获取待测图像并基于训练完成的DM-UNet网络进行预测,得到结肠内容物标注。该系统包括：标注模块、预处理模块、网络训练模块和应用模块。通过使用本发明,能够标注并去除CT结肠影像内容物。本发明作为一种CT结肠影像内容物的标注方法及系统,可广泛应用于医学图像处理领域。</td>   <td>1.一种CT结肠影像内容物的标注方法,其特征在于,包括以下步骤：获取CT结肠影像数据集并进行标注,得到带标注的CT影像数据集；对带标注的CT结肠影像数据集进行预处理,得到预处理后的CT影像数据集；基于预处理后的CT影像数据集训练3D Inception网络,得到训练完成的3DInception网络；所述3D Inception采用ReLU作为激活函数,对数据进行批标准化、拼接操作,并将四条子路的输出合并；所述3D Inception网络的损失函数公式如下；                  上式中,θ表示可训练的网络参数,L(θ)表示损失函数,N表示样例总数,I{·}表示指示函数,Y～((j))表示第j层横断面的目标输出值,表示第j层横断面的实际输出值,c表示目标分割区域,P表示输入,/&gt;表示实际输出Y～((j))属于目标分割区域的估计概率；基于预处理后的CT影像数据集训练改进的U-net网络并以训练好的3D Inception网络辅助训练,得到训练完成的DM-UNet网络；所述以训练好的3D Inception网络辅助训练具体为首先将预处理后的CT影像数据集及其横断面分别输入3D Inception网络和DM-UNet中学习,将DM-UNet的输出与3DInception网络的输出进行比对,再由3D Inception网络找出肠道结构的异常区域,通过对应的权重项,提升DM-UNet的分割精确度；所述训练完成的DM-UNet网络包括编解码结构和边缘检测机制；获取待测图像并基于训练完成的DM-UNet网络进行预测,得到结肠内容物标注。</td>   <td>G06T7/00;G06T7/13;G06V10/82;G06V10/774;G06V10/764;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   张权       </td>   <td>中山大学</td>   <td>一种基于深度特征正交分解的可见光-近红外行人再识别方法</td>   <td>广东省</td>   <td>CN111695470B</td>   <td>2023-05-12</td>   <td>本发明公开了一种基于深度特征正交分解的可见光-近红外行人再识别方法,包括：获取训练图像集并提取图像特征,得到全局特征和模态特征；根据全局特征和模态特征进行柱坐标系的特征分解,得到行人身份特征和视角特征；对行人身份特征、视角特征和模态特征计算特征损失函数并根据特征损失函数优化训练模型；基于训练模型对输入图像进行识别。通过使用本发明,可解决现实应用场景中常见的识别率下降的问题,提高行人再识别方法模型的抗干扰和自适应的能力。本发明作为一种基于训练模型对输入图像进行识别方法,可广泛应用于计算机视觉领域。</td>   <td>1.一种基于深度特征正交分解的可见光-近红外行人再识别方法,其特征在于,包括以下步骤：获取训练图像集并提取图像特征,得到全局特征和模态特征；根据全局特征和模态特征进行柱坐标系的特征分解,得到行人身份特征和视角特征；对行人身份特征、视角特征和模态特征计算特征损失函数并根据特征损失函数优化训练模型；基于训练模型对输入图像进行识别；所述对行人身份特征、视角特征和模态特征计算特征损失函数并根据特征损失函数优化训练模型这一步骤,其具体包括；对行人身份特征计算余弦交叉熵损失函数；所述对行人身份特征计算余弦交叉熵损失函数,其表达式如下；                  所述N表示输入图像数量,所述x表示需要计算损失的图片特征,所述y表示对应的真值标签,所述θ表示图片特征x与分类器权重归一化相乘后的角度特征,所述s和m是手动优化调节的超参数,所述i和j代表输入图像中的第i和j张图片；对视角特征计算回归损失函数；所述对视角特征计算回归损失函数这一步骤,其表达式如下；                  所述x-i表示当前需要计算损失的图片特征,所述y-i表示对应的真值标签；对模态特征计算交叉熵损失函数；所述对模态特征计算交叉熵损失函数这一步骤,其表达式如下；                  对行人身份特征、视角特征和模态特征计算正则化损失函数；所述对行人身份特征、视角特征和模态特征计算正则化损失函数,其表达式如下；Lo＝(f-f-3)～Tf-3所述f-f-3表示为差向量分量,所述f-3表示为模态特征分量；将行人身份特征的余弦交叉熵损失函数、视角特征的回归损失函数、模态特征的交叉熵损失函数和正则化损失函数之和的最小值作为目标优化训练模型。</td>   <td>G06V40/10;G06V10/40;G06V10/774;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>              丁汝鑫       </td>   <td>中山大学</td>   <td>基于宇宙成因核素恢复基岩剥露历史的方法及相关装置</td>   <td>广东省</td>   <td>CN113076651B</td>   <td>2023-05-12</td>   <td>本申请公开了基于宇宙成因核素恢复基岩剥露历史的方法及相关装置,方法包括：采用蒙特卡洛算法假设多条剥露历史曲线,并计算每一条剥露历史曲线对应的模拟最小暴露年龄；根据目标最小暴露年龄和模拟最小暴露年龄计算拟合度；通过拟合度在剥露历史曲线中选取目标最小暴露年龄对应的目标模拟剥露历史曲线；计算目标模拟剥露历史曲线的平均值,得到目标最小暴露年龄对应的平均剥露历史曲线。本申请可以为通过宇宙成因核素恢复基岩的剥露历史研究提供一种高效可行的方案。</td>   <td>1.基于宇宙成因核素恢复基岩剥露历史的方法,其特征在于,包括：采用蒙特卡洛算法假设多条剥露历史曲线,并计算每一条所述剥露历史曲线对应的模拟最小暴露年龄；根据目标最小暴露年龄和所述模拟最小暴露年龄计算拟合度；其中,所述目标最小暴露年龄的获取过程为：根据有限差分变换后的预置核素浓度公式绘制预设剥露历史曲线；根据所述预设剥露历史曲线计算所述目标最小暴露年龄；通过所述拟合度在所述剥露历史曲线中选取所述目标最小暴露年龄对应的目标模拟剥露历史曲线；计算所述目标模拟剥露历史曲线的平均值,得到所述目标最小暴露年龄对应的平均剥露历史曲线。</td>   <td>G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   程海杰       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的漫画人物身份识别方法</td>   <td>广东省</td>   <td>CN111160264B</td>   <td>2023-05-12</td>   <td>本发明公开了一种基于生成对抗网络的漫画人物身份识别方法,包括：获取真实行人和漫画行人图片,建立包含真实行人的检索库和包含漫画行人的查询库；构建人脸检测对齐模型,对检索库和查询库中的图片进行人脸检测对齐；构建漫画生成模型,将真实行人和人脸转换成对应的漫画图片；构建漫画人物身份识别模型,提取检索库和查询库中图片的融合特征,计算漫画行人和真实行人融合特征间的相似度分数；计算漫画行人融合特征间的相似度分数,利用漫画行人间的相似度分数对漫画行人与真实行人间的相似度分数进行重排序,设定阈值获取查询库中漫画行人在检索库中所对应的真实行人。本发明对漫画人物身份识别具有精度高、速度快的优点。</td>   <td>1.一种基于生成对抗网络的漫画人物身份识别方法,其特征在于,包括步骤：步骤S1：获取真实行人和漫画行人图片,建立包含真实行人的检索库和包含漫画行人的查询库；步骤S2：构建人脸检测对齐模型,对检索库和查询库中的图片进行人脸检测对齐；步骤S3：构建漫画生成模型,将真实行人和人脸转换成对应的漫画图片；步骤S3中构建漫画生成模型,将真实行人和人脸转换成对应的漫画图片,步骤是：步骤S31：将成对原始真实人脸图片x、漫画人脸图片y,及其对应关键点送入生成网络G中,G分为三个支路,分别为风格编码、内容编码和关键点检测；接着利用编码的风格E-S对编码的内容E-C进行纹理渲染记为R,为了防止风格渲染后的图片丢失语义信息,在此增加一个身份重构损失L-(idr)＝E[||R(E-C(x),E-S(x))-x||-1],x为原始真实人脸图片,E[·]表示取一个训练批次中所有训练样本计算值的期望值；而后利用定位的关键点K与偏移量ΔK对渲染后的图片进行面部变形,记为W,得到生成的漫画图片W(R(E-C(x),E-S(x)),K,ΔK)；步骤S32：将生成的漫画图片送入到判别网络D中,通过损失函数对其进行约束训练,最终得到漫画生成模型；所述步骤S31中,关键点K是利用MTCNN方法对人脸图像进行检测,并将检测的左眼K-1、右眼K-2、鼻子K-3、嘴左K-4、嘴右K-5五个关键点坐标进行保存；面部变形是通过网络学习一组偏移量ΔK＝ΔK1,ΔK2,…,ΔKn,n为关键点的数目5,然后通过薄板样条插值对网格进行采样,从而生成具有多种风格且适合人特征夸大的漫画图片；所述步骤S32中,通过三个损失函数对判别网络D进行约束,分别为对抗损失L-(adv)、身份一致性损失L-(idc)和漫画风格一致性损失L-(csc),其中,对抗损失为：L-(adv)＝E[-logD(G(x,E-S))]+E[-logD(y)]；身份一致性损失为：L-(idc)＝E[-logD(G(x,E-S(x)),l)]+E[-logD(y,l)],l为x对应的真实标签；漫画风格一致性损失为：L-(csc)＝E||MTCNN(G(x,E-S))-k||-1,k为y对应的关键点；步骤S4：构建漫画人物身份识别模型,提取检索库和查询库中图片的融合特征,计算漫画行人和真实行人融合特征间的相似度分数；步骤S4中构建漫画人物身份识别模型,提取检索库和查询库中图片的融合特征,步骤是：步骤S41：利用步骤S2中训练好的人脸检测对齐模型对用于训练和测试人物身份识别模型的数据进行预处理,得到对应的真实人脸和漫画人脸图片；步骤S42：利用步骤S3中训练好的漫画生成模型将训练和测试数据中的真实人脸和行人转换成对应的漫画图片；步骤S43：在训练阶段,将真实行人图片、真实人脸图片、漫画行人图片和漫画人脸图片分别送入到参数不共享的主干网络中去提取其各自的深度特征,而后分别将真实行人、人脸的深度特征和漫画行人、人脸的深度特征进行拼接,得到真实图片和漫画图片的融合特征；利用Softmax Loss对真实行人图片、真实人脸图片、漫画行人图片和漫画人脸图片所对应的深度特征,以及真实图片和漫画图片的融合特征进行身份约束；利用Triplet Loss对真实图片和漫画图片的融合特征进行相似度的约束；步骤S44：在测试阶段,利用训练好的漫画人物身份识别模型分别提取查询库中漫画人脸和行人对应的融合特征、检索库中真实人脸和行人所生成的漫画图片对应的融合特征,而后计算查询库中融合特征与检索库中融合特征的相似度分数；步骤S5：计算漫画行人融合特征间的相似度分数,利用漫画行人间的相似度分数对漫画行人与真实行人间的相似度分数进行重排序,设定阈值获取查询库中漫画行人在检索库中所对应的真实行人。</td>   <td>G06V40/16;G06F16/58;G06N3/08;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张英朝;              王茂桓;              任科州;              钟元芾;              周丽萍;              李鸿旭;              孙蕾;              吕娜;              孙沁;              曹志钦;              曾逸凡;              冯姗姗;              苏倩;                   黄志文       </td>   <td>中山大学</td>   <td>一种可解释的装备组合快速构建方法、系统、设备及介质</td>   <td>广东省</td>   <td>CN116108613A</td>   <td>2023-05-12</td>   <td>本发明涉及武器装备组合技术领域,尤其涉及一种可解释的装备组合快速构建方法、系统、设备及介质,包括：构建武器装备组合优化模型,武器装备组合优化模型的约束条件包括武器装备系统价值递增性约束；利用元组合算法和类间组合算法,构建武器装备组合优化模型的装备组合求解算法；通过装备组合求解算法对武器装备组合优化模型进行求解,输出最优武器装备组合方案集合。本发明通过装备分类、元组合算法和类间组合算法,在武器装备系统价值递增性约束下求解得到最终武器装备组合方案集合,解决了传统装备组合构建方法难以满足复杂多变的场景,无法有效平衡可解释性和计算复杂度的问题,有效降低了武器装备组合方案的复杂性,具有较强的可解释性。</td>   <td>1.一种可解释的装备组合快速构建方法,其特征在于,包括以下步骤：构建武器装备组合优化模型,所述武器装备组合优化模型的约束条件包括武器装备系统价值递增性约束；利用元组合算法和类间组合算法,构建武器装备组合优化模型的装备组合求解算法；通过所述装备组合求解算法对所述武器装备组合优化模型进行求解,输出最优武器装备组合方案集合。</td>   <td>G06F30/20;G06Q10/0631;G06Q10/0637;G06F18/24;G06F111/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴文斌;              王志强;              郑竞超;              姜乃斌;              李捷;              马宇;                   王亚辉       </td>   <td>中山大学</td>   <td>一种中子输运特征线方法的对称边界处理方法及系统</td>   <td>广东省</td>   <td>CN116108647A</td>   <td>2023-05-12</td>   <td>本申请属于核反应堆物理数值计算技术领域,公开了一种中子输运特征线方法的对称边界处理方法及系统。通过MOC程序构建几何堆芯模型,设置所述几何堆芯模型的边界条件,对所述几何堆芯模型进行特征线布置,得到特征线布置信息；设置所述几何堆芯模型的对称性,生成对应的额外模块,基于所述额外模块,根据对称性质生成所述额外模块的等效完整模块,计算所述等效完整模块的边界段角通量；根据所述特征线布置信息,并基于所述等效完整模块的边界段角通量和已知源项分布对所述等效完整模块进行输运计算,得到所述等效完整模块的标通量和有效增殖因子Keff。实现降低额外模块的特征线布置难度,进而提高中子输运计算效率。</td>   <td>1.一种中子输运特征线方法的对称边界处理方法,其特征在于,所述方法包括：通过MOC程序构建几何堆芯模型,设置所述几何堆芯模型的边界条件,对所述几何堆芯模型进行特征线布置,得到特征线布置信息；设置所述几何堆芯模型的对称性,生成对应的额外模块,基于所述额外模块,根据对称性质生成所述额外模块的等效完整模块,计算所述等效完整模块的边界段角通量；根据所述特征线布置信息,并基于所述等效完整模块的边界段角通量和已知源项分布对所述等效完整模块进行输运计算,得到所述等效完整模块的标通量和有效增殖因子Keff。</td>   <td>G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;              倪晓升;                   张易东       </td>   <td>中山大学</td>   <td>一种基于数字孪生的交通运输设备运行预测方法及装置</td>   <td>广东省</td>   <td>CN116108717A</td>   <td>2023-05-12</td>   <td>本发明涉及交通运输技术领域,公开了一种基于数字孪生的交通运输设备运行预测方法及装置。本发明基于目标交通运输设备的拓扑结构数据和基础环境数据构建数字孪生模型,向数字孪生模型导入目标交通运输设备在历史运行过程中产生的运行数据,对得到的目标数字孪生模型进行仿真计算,根据得到的仿真运行数据和所述运行数据对目标数字孪生模型进行训练以得到目标运行状态预测模型,将目标数字孪生模型的实时状态数据输入至目标运行状态预测模型进行预测计算,最终得到运行状态预测结果。本发明实现了对交通运输设备的运行状态的智能预测,为实现交通运输设备运行的可靠性和安全性提供客观有效的数据基础。</td>   <td>1.一种基于数字孪生的交通运输设备运行预测方法,其特征在于,包括：获取目标交通运输设备的拓扑结构数据和基础环境数据；根据所述拓扑结构数据构建相应的数字孪生设备模型,根据所述基础环境数据构建相应的数字孪生环境模型,将所述数字孪生设备模型和所述数字孪生环境模型相互关联得到数字孪生模型；获取所述目标交通运输设备在历史运行过程中产生的运行数据；向所述数字孪生模型导入所述运行数据,得到匹配所述目标交通运输设备的目标数字孪生模型；对所述目标数字孪生模型进行仿真计算,得到所述目标数字孪生模型运行过程中所产生的仿真运行数据；根据所述运行数据和所述仿真运行数据对所述目标数字孪生模型进行训练,得到目标运行状态预测模型；对所述目标数字孪生模型进行实时状态更新,获取相应的实时状态数据；将所述实时状态数据输入至所述目标运行状态预测模型进行预测计算,得到所述目标交通运输设备的运行状态预测结果。</td>   <td>G06F30/23;G06F30/28;G06Q10/04;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺丰;              叶广智;              周子扬;              王青;                   林倞       </td>   <td>中山大学</td>   <td>一种语义引导增广数据生成的少样本图像识别方法</td>   <td>广东省</td>   <td>CN116109888A</td>   <td>2023-05-12</td>   <td>本发明公开了一种语义引导增广数据生成的少样本图像识别方法,如下：构建语义引导增广数据生成模型；实例级数据生成模块,针对支持集数据中每一个训练数据,利用类别激活映射方法进行局部语义注意力特征,同时利用语义嵌入融合生成全局语义注意力特征,生成增强后的支持集数据；原型级数据生成模块,针对支持集中每一个类别,根据语义空间上的距离度量,引导少样本类结合相关的基础类进行信息迁移,估计出少样本类的类型原型及相关分布,并在相关分布上采样得到增广样本数据；将增强后的支持集数据、增广样本数据与原始支持集结合,作为新的支持集对图像识别模型进行训练。</td>   <td>1.一种语义引导增广数据生成的少样本图像识别方法,其特征在于：所述的方法具体如下：构建语义引导增广数据生成模型,包括实例级数据生成模块、原型级数据生成模块；所述的实例级数据生成模块,利用实例级数据生成少样本类数据中的支持集数据,针对支持集数据中每一个训练数据,利用类别激活映射方法进行局部语义注意力特征,同时利用语义嵌入融合生成全局语义注意力特征,生成增强后的支持集数据；所述的原型级数据生成模块,利用原型级数据生成少样本类数据中的支持集数据,针对支持集中每一个类别,根据语义空间上的距离度量,引导少样本类结合相关的基础类进行信息迁移,由此估计出少样本类的类型原型及相关分布,并在相关分布上进行采样得到增广样本数据；最后,将增强后的支持集数据、增广样本数据与原始支持集结合,作为新的支持集对图像识别模型进行训练。</td>   <td>G06V10/774;G06V10/764;G06V10/40;G06V20/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              陈家鑫;                   谢晓华       </td>   <td>中山大学</td>   <td>基于双目视觉的高低分辨率融合立体匹配方法</td>   <td>广东省</td>   <td>CN111105452B</td>   <td>2023-05-09</td>   <td>本发明公开了一种基于双目视觉的高低分辨率融合立体匹配方法,包括步骤：输入左右两张高分辨率图片和立体匹配的参数；图像进行预处理,计算左右图中视差搜索范围内的每一对像素点的视差代价,得到视差代价矩阵；视差代价矩阵下采样,得到降维后的视差代价矩阵；降维后的视差代价矩阵进行视差代价聚合,得到最佳匹配点；根据最佳匹配点进行匹配,得到视差图。本发明在预处理和视差代价计算步骤使用清晰的高分辨率图片,可得到准确的视差代价,在视差代价聚合和后处理步骤按照低分辨率图片的流程处理,可减少计算所需的时间。本发明通过立体匹配的准确率测试和耗时测试,表明本方法在准确率和耗时方面相较于现有技术,具有既准确又耗时少的优点。</td>   <td>1.基于双目视觉的高低分辨率融合立体匹配方法,其特征在于,包括步骤：输入双目相机拍摄得到的左右两张高分辨率图片以及立体匹配的参数；对图像进行预处理,计算左右图中处于视差搜素范围内的每一对像素点的视差代价,得到视差代价矩阵；视差代价矩阵下采样,得到降维后的视差代价矩阵；针对降维后的视差代价矩阵进行视差代价聚合,得到最佳匹配点；针对降维后的视差代价矩阵进行视差代价聚合,步骤是：(4-1)计算窗口视差代价：设置一个窗口,窗口长宽都为SADWindowsize,把整个窗口中的所有像素点的视差取值为d,把窗口中所有像素点的代价cost(p,d)加起来,得到整一个窗口的代价,记为C(p,d)；(4-2)动态规划做代价聚合：动态规划的处理公式如下：L-r(p,d)＝C(p,d)+min(L-r(p-r,d),L-r(p-r,d-1)+P-1,L-r(p-r,d+1)+P-1,minL-r(p-r,i)+P-2)-minL-r(p-r,k)动态规划处理是多方向的,要一个一个方向来处理,处理过程中先选定其中某一个方向为r,P-1和P-2指惩罚代价,其中P-1指当前像素点所在窗口视差为d且前一个像素点所在窗口视差为d-1或者为d+1时当前像素点所在窗口要加上的惩罚代价,P-2则指当前像素点所在窗口视差为d且前一个像素点所在窗口视差为小于d-1或者大于d+1时当前像素点窗口要加上的惩罚代价,p指当前像素点所在的窗口,L-r(p,d)表示沿着当前方向,当p的视差取值为d时的最小的匹配代价；处理了N个方向的动态规划,N个方向的L-r(p,d)加起来,即得到当前窗口的视差取值为d时的代价S(p,d),视差d的取值一共有NumofDisparities个,当前像素点有NumofDisparities个S(p,d),其中最小的一个就是当前像素点的最佳视差,得到最佳匹配点；根据上述最佳匹配点进行匹配,得到视差图；所述基于双目视觉的高低分辨率融合立体匹配方法还包括后处理步骤,该步骤包括：(5-1)唯一性检测：设唯一性检测阈值为U,那么必须满足下述公式,才认为计算的视差代价是合理的代价：                  并且,次佳视差像素点和最佳视差像素点的距离要在一个像素以上；(5-2)亚像素插值：亚像素插值选择的是抛物线插值法,找到极小值点,处理公式如下：当前点的最佳视差值是d,那么得到denom2的值,S(p,d-1)、S(p,d)和S(p,d+1)这些数值构成一条曲线,曲线在S(p,d-1)这一点的二次导数和1这两个数值中的较大值就是denom2,也就是保证了最后denom2取得大于等于1的一个数值,denom2如下：denom2＝max(S(p,d-1)+S(p,d+1)-2*S(p,d),1)接着拟合得到一个新的d值d-new,如下：                  (5-3)连通区域检测噪点并去除：调用opencv的filterSpeckles函数,输入待处理的视差图、无效值、判定为连通区域的灰度值范围SpeckleRange和连通区域的噪点面积阈值SpeckleWindowsize这四个参数值,找到视差图中的噪点连通区域,把这些区域的视差值置为无效值,最后得到去除噪点后的视差图。</td>   <td>G06T7/55;G06V10/74;G06V10/80;G06V10/44</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢晓华;              宋展仁;                   赖剑煌       </td>   <td>中山大学</td>   <td>一种基于深度表示学习跟动态匹配的行人再识别方法</td>   <td>广东省</td>   <td>CN111126198B</td>   <td>2023-05-09</td>   <td>本发明公开了一种基于深度表示学习跟动态匹配的行人再识别方法,用于判别在不同时间或者区域的行人身份。包括：构建特征提取模型,用于提取全局、局部特征,利用全局特征、局部特征进行联合学习；实现不同行人局部特征之间的动态匹配,使用三元组损失函数进行学习模型；取检索库和查询库中行人图片的全局特征,计算查询库行人和检索库行人的全局特征间的相似度分数,并利用相似度分数进行排序,获取查询库中行人在检索库中所对应的行人。本发明利用全局特征跟局部特征进行联合学习,其中实现了局部特征之间的对齐,这样使得模型学习到的全局特征同时关注了局部信息跟全局信息。缓解了行人再识别中的局部不对齐问题,提升了模型再识别的性能。</td>   <td>1.一种基于深度表示学习跟动态匹配的行人再识别方法,其特征在于,包括步骤：步骤S1：获取不同摄像头下的行人图片,构建行人检索库和查询库；步骤S2：构建局部特征、全局特征提取模型,利用全局特征、局部特征进行联合学习；步骤S3：实现不同行人局部特征之间的动态匹配,使用三元组损失函数进行模型学习；所述步骤S3中,实现不同行人局部特征之间的动态匹配,方法是：定义物体表示的是行人,一个部件表示的是行人的一个水平条纹,假设水平条纹通过弹簧连接,这允许条纹能够滑动且偏离固定分割的位置,给定两张待匹配的图像(I～0,I～1),通过可形变的条纹来动态匹配图片,试图找到两者之间的最佳对齐方式：定义配置C为图像I～1中每个条纹的位置信息,C～*为动态分割的最优配置,S表示两张图像之间的相似性,公式如下：                  此处,F(x,y)表示分别来自图像I～0,I～1的两个相对应的条纹的相似性度量；d(x,y)表示两个对用条纹的空间性变代价；表示图像的条纹,k＝0,1；λ是惩罚系数,而E则为图像I～1中连接两个相邻条纹的边,一个配置C的相似性度量S-(app)(C；I～0；I～1；θ)是F(x,y)在所有条纹对的累加,F(x,y)是一种距离；θ表示参数空间,m为分成的条纹；固定分割图像I～0,动态滑动分割图像I～1,分别计算跟/&gt;之间的相似性度量以及相关的空间形变代价,i＝1,2,...,m；根据动态规划算法,搜索整体的动态分割的最优配置C～*,在此最优配置下,得到两张图像的局部相似性度量,从而实现不同行人局部特征之间的动态匹配；步骤S4：提取检索库和查询库中行人图片的全局特征,计算查询库行人和检索库行人的全局特征间的相似度分数,并利用相似度分数进行排序,获取查询库中行人在检索库中所对应的行人。</td>   <td>G06V40/10;G06V10/26;G06V10/40;G06V10/44;G06V10/82;G06V10/74;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;                   黄嘉胜       </td>   <td>中山大学</td>   <td>基于图卷积网络和长短时记忆网络的事件预测方法</td>   <td>广东省</td>   <td>CN111488815B</td>   <td>2023-05-09</td>   <td>本发明公开了一种基于图卷积网络和长短时记忆网络的事件预测方法,包括下述步骤：S1、对篮球比赛视频单位时间视频频段的个体进行检测,依据检测到的个人位置,在空间和时间上进行视频切片,再将切片后的视频送进三维残差卷积网络进行特征提取；S2、构建基于图卷积神经网络的篮球进分时间预测模型；S3、基于图卷积神经网络和长短时记忆神经实现对一段篮球视频下一单位长度进球事件的预测。本发明定义了新型的图卷积神经网络,能有效捕捉人与人的关系,有效地考虑到了边权重的重要信息,并将场景全局特征作为模型输入,使得模型能从局部到全局刻画视频特征,从而获得一个更加完整的篮球比赛行为描述,进而有效地预测未来进球事件。</td>   <td>1.基于图卷积网络和长短时记忆网络的事件预测方法,其特征在于,包括下述步骤：S1、对篮球比赛视频单位时间视频频段的个体进行检测,依据检测到的个人位置,在空间和时间上进行视频切片,再将切片后的视频送进三维残差卷积网络进行特征提取；S2、构建基于图卷积神经网络的篮球进分时间预测模型,所述图卷积神经网络用于对具有节点和边的图模型进行特征变换和表征,从而使得每个节点不仅包含该节点所具有特征,同时包含与该节点相邻节点的信息；S3、基于图卷积神经网络和长短时记忆神经实现对一段篮球视频下一单位长度进球事件的预测,先将输入的T秒长的篮球视频,按单位时间长度1秒分为T段视频片段,对于每个视频片段,用图卷积网络进行特征提取,最后将T个视频片段的特征按顺序输入长短时记忆神经网络进行预测；所述步骤S3具体为：将每个运动员视为图的一个节点,其节点特征为x-i；将所有运动员节点两两相连,即可得到全连接的无向图,将节点i和节点j的边权重定义为：                  其中j∈N(i)将节点i连向自己的边权重定义为：                  其中0&lt;p&lt;1,p为超参数在对上面的边权重用Softmax函数进行归一化,得到：                  经过上面的定义,得到了边权重集合使得边权重具有以下性质：0＜w-(ij)＜1                  w-(ii)＝p由单位时间长视频片段构建图后,得到了图的节点特征集合X和边权重集合W,我们将其输入所述图卷积神经网络,可得到图的全局特征,将其表示为：h-(graph)＝g(X,W)其中函数g代表图卷积神经网络,h-(graph)为图卷积神经网络输出的全局特,最后我们将h-(graph)与场景特征x-(scene)拼接在一起,作为单位时间长视频片段的特征h,表示为：h＝h-(graph)||x-(scene)场景特征的加入使得提取的特征既有局部信息又有整体信息；在对T个视频片段都提取特征并按时间顺序排列,得到特征序列{h-1,h-2,...,h-T},将其作为T步长的多输入单输出的长短时记忆神经网络的输入,得到LSTM输出,并将其线性变换归一化,得到预测的篮球进球事件是否发生的后验概率为：p(y|h-1,h-2,...,h-T)＝φ(W-(out)LSTM(h-1,h-2,...,h-T))其中,φ为softmax激活函数,W-(out)是可学习参数矩阵,其行数为2,LSTM代表长短时记忆神经网络。</td>   <td>G06V20/40;G06V10/82;G06N3/0442;G06N3/045;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高燕;              武志毅;              袁泉;                   李文龙       </td>   <td>中山大学;广州地铁设计研究院股份有限公司</td>   <td>针对地质环境风险的轨道交通选线评估及成本优化方法</td>   <td>广东省</td>   <td>CN111553509B</td>   <td>2023-05-09</td>   <td>本发明涉及一种针对地质环境风险的轨道交通选线评估及成本优化方法,具体包括以下步骤：步骤S1：获取地铁修建区域的基本数据,进行线路区间的选线区段划分和选线方案编号；步骤S2：对完成区段划分和方案编号的线路区间构建风险评价目标函数、风险处理成本目标函数和风险处理工期目标函数；步骤S3：通过动态可变模糊评价模型计算线路区间的地质风险等级；步骤S4：根据地质风险等级,通过启发式算法计算出线路区间的风险评价、成本、工期多目标最优的地铁线路方案。与现有技术相比,本发明具有提高轨道交通路线的安全性和稳定性、通过对轨道交通选线方案所涵盖地质风险的等级及处理风险成本、工期的评估,进而减少轨道交通施工成本等优点。</td>   <td>1.一种针对地质环境风险的轨道交通选线评估及成本优化方法,其特征在于,具体包括以下步骤：步骤S1：获取地铁修建区域的基本数据,根据所述地铁修建区域的基本数据进行线路区间的选线区段划分和选线方案编号；步骤S2：对完成所述选线区段划分和选线方案编号的线路区间构建风险评价目标函数、风险处理成本目标函数和风险处理工期目标函数；步骤S3：通过动态可变模糊评价模型计算所述线路区间的地质风险等级；步骤S4：根据所述地质风险等级,通过启发式算法计算出所述线路区间的风险评价、成本、工期多目标最优的地铁线路方案；所述步骤S3具体分为以下步骤：步骤S301：获取所述线路区间的时间因素集f-o(t)＝(f-1(t) f-2(t)…f-i(t))和待评价样本的特征值向量x-o＝(x-1 x-2…x-i),将所述时间因素集与待评价样本的特征值向量相结合,得到所述线路区间的样本特征值的函数向量x-o(t)＝g(x-o,f-o(t))；步骤S302：获取轨道交通不良地质风险因素集,根据轨道交通不良地质风险因素集确定所述线路区间的样本特征值函数向量的评判标准矩阵I-(ab),所述评判标准矩阵I-(ab)具体表示为指标为i且级别为h的风险因素集评判标准区间[a,b]-(ih)；步骤S303：根据所述风险因素集评判标准区间对应的吸引域区间[a,b],确定所述吸引域区间对应的范围值区间[c,d],根据所述范围值区间构造i个指标h个级别的范围值矩阵I-(cd)；步骤S304：根据所述步骤S303中的指标,确定单位差异度位值,所述单位差异度位值的计算公式如下：                  其中,M为单位差异度位值,所述单位差异度位值为吸引域区间[a,b]中相对差异度D-A(u)＝1的位值,单位差异度位值M对应的隶属度μ-A(u)＝1,h为风险等级,数值为1到n之间的常数,n为风险等级上限；步骤S305：根据相对差异函数模型,由所述i个指标中确定的各指标的[a,b]、[c,d]及单位差异度位值,确定每一个所述样本指标特征值对风险等级1～n的相对隶属度,以此确定隶属度矩阵μ-A(u)；步骤S306：根据组合权重法确定所述隶属度矩阵的一级指标权向量ω-a和二级指标的权向量ω-(bi)；步骤S307：根据所述模糊可变评价模型计算所述线路区间对各级别风险等级的综合相对隶属度向量,所述模糊可变评价模型具体为：                  其中,α为模型优化准则参数,d-g和d-b为中间变量,α＝1时为最小一乘方准则,α＝2时为最小二乘法准则,p为距离参数,p＝1时为海明距离,p＝2时为欧式距离；m为识别指标数,ω-(bi)为二级指标的第i个指标权向量；当α＝1且p＝1时,对应模型为简单模糊评价模型；当α＝1且p＝2时,对应模型为理想点评价模型；当α＝2且p＝1时,对应模型为“S”型函数模型；当α＝2且p＝2时,对应模型为模糊优选模型；分别计算上述4种模型对应的模糊可变评价函数V-A(u),根据计算结果求得4种模型的综合相对隶属度向量,具体公式为：V-A(u)-h＝ω-a·V-A(u)～T其中,V-A(u)-h为综合相对隶属度向量；步骤S308：根据步骤S307中4种模型的综合相对隶属度向量,计算简单模糊评价模型、理想点评价模型、“S”型函数模型和模糊优选模型的级别特征值,具体计算公式如下：                  其中,H-j为第j段区间的风险级别特征值。</td>   <td>G06Q10/047;G06Q10/0635;G06Q10/0639;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁姗姗;                   刘自弛       </td>   <td>中山大学</td>   <td>一种用于眼底图像拼接的图像预处理方法</td>   <td>广东省</td>   <td>CN111652805B</td>   <td>2023-05-09</td>   <td>本发明为一种用于眼底视网膜图像拼接的图像预处理方法,所述方法包括以下步骤：S1获取若干的彩色眼底视网膜图像；S2对所获取的彩色眼底视网膜图像进行裁剪；S3针对S2裁剪后的图像数据进行筛选,筛选掉透光图像以及模糊图像；S4针对S3筛选后的图像进行图像相似度评价,将所在眼底视网膜区域相近的图像归为同一类别；S5针对S4分类完成后的图像,进行类间图像的清晰度评价,筛选出每一类中最清晰的图像,作为图像拼接的数据。本发明的有益效果在于,设计了一套完整的图像预处理方案,能有效的从大量彩色眼底视网膜图像中筛选出图像数据,进行图像拼接。从而能使得在单张图像中显示更加完整的眼底结构,提高医生诊断效率。</td>   <td>1.一种用于眼底图像拼接的图像预处理方法,其特征在于,所述方法包括以下步骤：S1获取若干的彩色眼底视网膜图像；S2对所获取的彩色眼底视网膜图像进行裁剪；S3针对S2裁剪后的图像进行筛选,筛选出透光图像以及模糊图像；S4针对S3筛选后的图像进行图像间相似度评价,按图像所在眼底视网膜区域,对图像进行分类；S5针对S4分类后的图像,进行类间图像清晰度评价；S6保留S5每一类中最清晰的图像数据,用于图像拼接；如进行两幅图像的相似度评价,所述步骤S4包括：S4.1在图像一中选取以图像点为中心,长宽分别占图像一长宽的60％的区域作为模板T；S4.2在图像二中进行模板匹配搜索；搜索区域大小与模板大小相同,计算搜索区域与模板T的差异值R；搜索结束后,记录最小差异值R-(min)；S4.3将最小差异值R-(min)与提前设定的阈值T-2进行比较；如果R-(min)＞T-2,则说明两幅图像差异过大,不能归为同一类图像；如果R-(min)≤T-2,则将两幅图像归为同一类别；所述步骤S4.2的公式如下：                  其中,T表示在图像一中选取的模板区域；T(x',y')表示模板中坐标为(x',y')的像素点的灰度值；I表示图像二；I(x+x',y+y')表示图像二中坐标为(x+x',y+y')的像素点的灰度值。</td>   <td>G06T3/40;G06T7/00;G06T7/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄晓;              林嘉良;              滕蔚;                   保延翔       </td>   <td>中山大学</td>   <td>一种基于关键词注意力机制的电路教材实体关系抽取方法</td>   <td>广东省</td>   <td>CN111666752B</td>   <td>2023-05-09</td>   <td>本发明提供一种基于关键词注意力机制的电路教材实体关系抽取方法,该方法该方法摒弃复杂度较高的时序序列神经网络或多层卷积神经网络,转而使用一种轻量级的卷积神经网络进行文本特征抽取,从而避免了因为数据集样本量少产生过拟合的问题；同时,根据电路教材数据集专有词汇较多,句式结构特点鲜明的特征,本发明提出关键词注意力机制,使得模型能关注句子中对实体关系预测影响最大的关键词,实现良好的实体关系预测能力。</td>   <td>1.一种基于关键词注意力机制的电路教材实体关系抽取方法,其特征在于,包括以下步骤：S1：嵌入层将输入句子中的每个单词转化为一个词向量和相对位置向量；S2：根据手工标记的关键词,使用注意力机制让模型关注对关系预测起重要作用的关键词；所述步骤S2的具体过程是：假设这句子中的每个词对关系分类预测结果的重要程度是不同的,并且句子中手工标注的关键词K对关系分类起着最重要的作用,基于以上假设,那么如果句子中的某词与关键词K的关系越密切,则该词对于关系的预测作用也更强,在嵌入层得到了句子的整个词嵌入表示矩阵S＝[f-1,f-2,…,f-k],因此,把关键词K的词嵌入表示记为d～(key),则使用以下双线性函数来描述每个词对关系预测的重要性得分I-i：                  其中,f-i表示基于第i个单词的词嵌入表示向量以及两个相对位置向量/&gt;拼接成的语义向量,i＝1,2,…,k；M是在训练过程中需要学习的权重矩阵,b是一个偏置项,然后,通过softmax函数将上述重要性得分进行处理,得到第i个单词标准化后的权重项a-i,即：                  计算所有的项后,得到一个对角注意力矩阵A,记为：A＝dig(a-1,a-2,a-3,…,a-k)    (3)将句子词嵌入表示矩阵S和对角注意力矩阵A相乘得到卷积池化层的输入矩阵Q：Q＝SA＝(q-1,q-2,…,q-k)   (4)；S3：在卷积层使用多种卷积核捕捉句子的特征信息,并对卷积层的输出作最大池化操作；所述步骤S3的具体过程是：将矩阵Q作为卷积层的输入,在卷积层引入了多个不同初始化权重的卷积核提取句子的特征,假设共有N-f个的卷积核,用W-i来表示第i个卷积核,利用卷积核W-i对输入矩阵Q进行特征提取,得到高阶语义特征o-i,o-i的计算如下：o-i＝σ(W-i·Q)       (5)其中σ是一个激活函数,依据公式(5),得到卷积核提取出来的高阶语义特征为使用最大池化方法对高阶语义特征O进行更一步筛选,得到卷积核提取的池化特征p,即：                  S4：用一个全连接层结合soft-max层来计算每一个关系的条件概率,并做出预测判决；S5：采用对数极大似然损失作为损失函数,并使用Adam优化算法解决最大化问题。</td>   <td>G06F40/279;G06N3/0464;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         范国鑫;              刘华清;              戎利民;              庞卯;              刘斌;              张良明;              黄桂芳;                   韩蓝青       </td>   <td>中山大学附属第三医院(中山大学肝脏病医院);清华珠三角研究院</td>   <td>重症脊髓损伤预后的预测模型的建立方法</td>   <td>广东省</td>   <td>CN112992346B</td>   <td>2023-05-09</td>   <td>本发明公开了重症脊髓损伤预后的预测模型的建立方法,其特征在于包括下列步骤：提取诊断为脊髓损伤患者病例的临床数据,1)纳入以下临床特征；2)预处理临床特征：根据临床特征的类型,通过不同的填补方法处理缺失的数据；3)纳入特征选择方法*机器学习分类算法的算法组合：所述特征选择方法用于筛选具有显著预测价值的临床特征,将选定的临床特征用于训练机器学习分类算法；4)从步骤3)中的算法组合在训练数据集的预测表现,选出micro平均曲线下面积AUC最大的算法组合,利用堆叠法集成所述算法组合,得到预测模型。本发明用于预测重症脊髓损伤患者预后具有准确客观性能。</td>   <td>1.一种重症脊髓损伤预后的预测模型的建立方法,其特征在于包括下列步骤：提取诊断为脊髓损伤患者病例的临床数据,1)纳入以下临床特征：人口统计信息包括种族、性别、年龄、体重指数、入院类型、ICU类型、入院来源、ICU时长、出ICU后住院时长；生命体征包括呼吸频率、心率、收缩压和舒张压、平均动脉压；实验室数据包括白细胞计数、红细胞计数RBC、血小板计数、嗜碱性粒细胞、嗜酸性粒细胞、嗜中性粒细胞、淋巴细胞、单核细胞、红细胞分布宽度RDW、血红蛋白、血细胞比容、平均红细胞血红蛋白量MCH、红细胞平均血红蛋白浓度MCHC、红细胞平均体积MCV、凝血酶原时间PT、活化部分凝血活酶时间APTT、国际标准化比值INR、氧浓度分数FiO2、氧分压PaO2、二氧化碳分压PaCO2、氢离子浓度指数PH、碳酸氢盐、乳酸盐、剩余碱BE、阴离子间隙、钾、钠、钙、镁、氯、磷酸盐、血尿素氮BUN、肌酐、白蛋白、血糖；药物的使用和治疗情况包括机械通气、硫酸吗啡、头孢唑林、氯化钾KCl、糖皮质激素、多巴胺、多巴酚丁胺、肾上腺素和去甲肾上腺素；2)预处理临床特征：根据临床特征的类型,通过不同的填补方法处理缺失的数据,连续变量特征运用预测均值匹配方法填补,二元变量特征运用逻辑回归方法填补,多分类变量特征运用多项式回归方法填补,在步骤1)中缺失病例占总病例比重大于等于50％的临床特征,直接删除该临床特征,包括红细胞分布宽度RDW、氧分压PaO2,缺失病例数占总病例数比重大于0且小于50％的特征有种族、红细胞平均体积MCV、乳酸盐、硫酸吗啡,所述年龄、体重指数、白细胞计数、红细胞计数RBC、血小板计数、嗜碱性粒细胞、嗜酸性粒细胞、嗜中性粒细胞、淋巴细胞、单核细胞、红细胞分布宽度RDW、血红蛋白、血细胞比容、平均红细胞血红蛋白量MCH、红细胞平均血红蛋白浓度MCHC、红细胞平均体积MCV、凝血酶原时间PT、活化部分凝血活酶时间APTT、国际标准化比值INR、氧分压PaO2、二氧化碳分压PaCO2、氢离子浓度指数PH、碳酸氢盐、乳酸盐、剩余碱BE、阴离子间隙、钾、钠、钙、镁、氯、磷酸盐、血尿素氮BUN、肌酐、白蛋白、血糖、呼吸频率、心率、收缩压、舒张压、平均动脉压ICU时长、出ICU后住院时长、氧浓度分数FiO2是连续变量特征,所述机械通气、硫酸吗啡、头孢唑林、氯化钾KCl、糖皮质激素、多巴胺、多巴酚丁胺、肾上腺素和去甲肾上腺素是二元变量特征,其中所述种族、性别、ICU类型、入院来源转化为虚拟变量的形式；最终获得不同的特征,并按照合理的比例,随机划分为训练数据集、验证数据集和测试数据集；3)纳入特征选择方法*机器学习分类算法的数量个算法组合：所述特征选择方法用于筛选具有显著预测价值的临床特征,将选定的临床特征用于训练机器学习分类算法,所述特征选择方法包括最大互信息系数MIC、嵌入随机森林RF、递归特征消除REF、嵌入线性支持向量分类器即嵌入LSVC、嵌入逻辑回归器即嵌入LR、嵌入树和最小冗余-最大相关度mRMR,所述机器学习分类算法包括逻辑回归、线性判别分析LDA、支持向量机SVM、K最近邻KNN、高斯朴素贝叶斯NB、决策树、额外决策树、随机森林、装袋算法Bagging、自适应增强AdaBoost、梯度提升决策树GBDT、极端梯度提升XGBoosting、轻型梯度提升机lightGBM、多层感知器MLP和深度神经网络DNN；4)从步骤3)中的算法组合在验证数据集的预测表现,对micro平均曲线下面积AUC进行排序组合,选出micro平均曲线下面积AUC最佳的算法组合,利用堆叠法集成所述算法组合,得到预测模型,所述预测表现是指AUC的高低,AUC的高低是指AUC数值由大到小的排列,具体而言指micro平均曲线下面积AUC的大小,越大说明预测表现越好,越小说明预测表现越差,其中所述验证数据集是训练数据集通过用特征选择算法选择且交叉验证后而得到；步骤3)中建立AUC矩阵,即所述训练数据集通过用特征选择算法选择且交叉验证后得到验证数据集的AUC矩阵,AUC矩阵的纵坐标是特征选择方法,横坐标是机器学习分类算法,然后构成特征选择方法*机器学习分类算法的数量个算法组合模型；根据特征选择方法*机器学习分类算法的数量个算法组合模型在验证数据集的预测表现,选出micro平均曲线下面积AUC最大的三个算法组合,利用所述堆叠法集成这三个算法组合,得到所述最终的预测模型；根据7个特征选择算法*15个机器学习分类算法组合在验证数据集的预测表现,所述选出micro平均曲线下面积(AUC)最佳三个组合分别为：最佳算法组合1：嵌入树*梯度提升决策树GBDT；最佳算法组合2：嵌入树*极端梯度提升XGBoosting；最佳算法组合3：嵌入LSVC*极端梯度提升XGBoosting；其中：嵌入树筛选出来的特征包括：格拉斯总分、住院时长、机械通气、收缩压、舒张压、ICU时长、出ICU后住院时长、白蛋白、呼吸频率、头孢唑林、乳酸、碳酸氢盐、红细胞分布宽度RDW、动脉平均压、血红蛋白、年龄、HR心率、氯化钾、血尿素氮、诊断总数、吗啡、血氯离子、血糖、RBC白细胞、钠离子、氧浓度分数FiO2；嵌入LSVC筛选出来的特征包含：肾上腺素、去甲肾上腺素、氧浓度分数FiO2、收缩压、头孢唑林、糖皮质激素、碳酸氢盐、格拉斯总分、住院时长、机械通气、血红蛋白、年龄、HR心率、白蛋白、氯化钾、血尿素氮、诊断总数、血氯离子、乳酸、凝血激活酶时间、动脉平均压、WBC白细胞、红细胞、血小板、血糖；选出患者出院终点的micro平均曲线下面积AUC的最佳三个算法组合进行构建最终预测模型,所述最佳三个算法组合是嵌入树*梯度提升决策树GBDT、嵌入树*极端梯度提升XGBoosting、嵌入LSVC*极端梯度提升XGBoosting；患者出院终点为最终预测模型的预测目标,即构建的最终预测模型为出院终点模型,用于一次性预测死亡、回家休养、继续专业康复护理治疗三个类别的概率。</td>   <td>G16H50/20;G16H50/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张宏伟;              张小虎;                   杨夏       </td>   <td>中山大学</td>   <td>一种基于扩展卡尔曼滤波器的人体姿态识别方法</td>   <td>广东省</td>   <td>CN110781803B</td>   <td>2023-05-09</td>   <td>本发明提供了一种基于扩展卡尔曼滤波器的人体姿态识别方法,其包括获取一张人体姿态背景图像并对获取的人体姿态背景图像进行数据解码,利用有限状态机方法进行人体姿态背景图像数据的提取,得到人体姿态背景图像数据；按照一定周期连续采集人体姿态图像并对人体姿态图像进行数据解码,利用有限状态机方法进行人体姿态图像数据的提取,得到人体姿态图像数据；提取人体姿态背景图像数据的亮度Y和色度C-b以及人体姿态图像数据的亮度Y-S和色度C-(bs),得到前景图像为|C-b-C-(bs)|,对前景图像进行二值化,得到二值化处理后的人体姿态图像；对二值化处理后的人体姿态图像通过扩展卡尔曼滤波器进行姿态解算,识别人体姿态。本发明能够人体运动过程中的姿态。</td>   <td>1.一种基于扩展卡尔曼滤波器的人体姿态识别方法,其特征在于,包括以下步骤：获取一张人体姿态背景图像并对获取的人体姿态背景图像进行数据解码,利用有限状态机方法进行人体姿态背景图像数据的提取,得到人体姿态背景图像数据；按照一定周期连续采集人体姿态图像并对人体姿态图像进行数据解码,利用有限状态机方法进行人体姿态图像数据的提取,得到人体姿态图像数据；提取人体姿态背景图像数据的亮度Y和色度C-b以及人体姿态图像数据的亮度Y-S和色度C-(bs),得到前景图像为|C-b-C-(bs)|,对前景图像进行二值化,得到二值化处理后的人体姿态图像；对二值化处理后的人体姿态图像通过扩展卡尔曼滤波器进行姿态解算,识别人体姿态；所述扩展卡尔曼滤波器包括以下步骤：步骤1,在k＝0时,初始化粒子,并给出初始位置x-0和协方差p-0；步骤2,在k＝1时,利用公式x-k＝f-k(x-(k-1))+v-(k-1)和z-k＝h-k(x-k)+e-k计算粒子传递值x-1和z-1；步骤3,确定修正先验概率的中心点；步骤4,序贯重要性采样,采样粒子集并预测目标轨迹利用公式/&gt;和/&gt;计算修正的权值并归一化；步骤5,重采样,根据重要性权值的大小分别增多或减少/&gt;根据修正先验概率以近似得到N个随机样本/&gt;步骤6,用粒子更新后验概率,对下一个粒子重复步骤2至5；步骤7,利用公式和/&gt;分别计算后验概率及滤波输出,并更新时间k,其中,式中Ns表示粒子数目；其中,在步骤3中,确定修正先验概率的中心点的方法包括如下步骤：3a,选择障碍函数建立目标函数,以满足约束条件p(e-k)＝0,并建立增广目标函数/&gt;并将该增广目标函数记为f-o；3b,给出阈值ε,其中0≦ε≦1；3c,利用公式计算搜索方向,其中d～i表示搜索方向；3d,利用进退法计算步长；3e,利用公式和/&gt;迭代计算中心点,其中α*是步长；3f,计算先验误差,判断先验误差是否小于等于阈值ε,如果是,则退出卡尔曼粒子滤波器。</td>   <td>G06V40/20;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄晓;              滕蔚;              林嘉良;                   保延翔       </td>   <td>中山大学</td>   <td>基于关键信息选择和变分潜在变量建模的文本摘要生成法</td>   <td>广东省</td>   <td>CN111708877B</td>   <td>2023-05-09</td>   <td>本发明提供一种基于关键信息选择和变分潜在变量建模的文本摘要生成法,该方法在编码器和解码器之间设置关键信息选择网络,控制编码器和解码器之间信息流的传递,达到选择核心的关键信息,提高编码器效率,并且过滤掉冗余信息,减轻解码器负担。同时,关键信息选择网络选择出对生成摘要核心的关键信息,以提高注意力的权重,减轻生成摘要的词语重复问题以及缓解未登录词问题,大幅提高了生成摘要的质量。利用VAE对变分潜在变量建模,获取摘要句子深层次潜在特征。通过在KL散度项之前加一个超参数系数β对VAE损失函数进行再平衡,消除VAE在训练过程中KL散度项消失,有效防止VAE网络退化,使得模型生成更精确的摘要。</td>   <td>1.一种基于关键信息选择和变分潜在变量建模的文本摘要生成法,其特征在于,包括以下步骤：S1：将输入的源文本X＝{x-1,x-2,…,x-t}首先映射成随机初始化的词向量,其中T为输入文本的长度,按顺序输入Bi-GRU经过的编码；S2：设置关键信息选择网络,选择出编码器输出中有效的关键信息内容；所述步骤S2中,设置关键信息选择网络,选择出编码器输出中有效的关键信息内容,在关键信息选择网络中,根据编码阶段输出的隐藏层状态向量和句子表征向量S设计出控制信息流的门控单元/&gt;来对原本编码器的输出隐藏层状态/&gt;进行信息选择,指定有效的信息范围,得到经过信息选择后的隐藏层变量/&gt;句子表征向量S是由编码器的前向传播的最后一个词的隐藏层状态和后向传播的第一个词的隐藏层状态拼接成一个固定长度的句子表征向量,这样拼接使得句子的关键信息压缩成一个固定的向量,S的表示如下：                  其中,为编码器的前向传播的最后一个词的隐藏层状态,/&gt;后向传播的第一个词的隐藏层状态；所述步骤S2中,将编码阶段输出的隐藏层状态向量和句子表征向量S作为选择阶段的输入,计算出门控单元向量/&gt;                  其中,为i时刻的编码阶段输出的隐藏层状态向量,S为句子表征向量,/&gt;和/&gt;为可训练的权重矩阵,b-s为偏置向量,sigmoid(·)是激活函数；接下来,将编码阶段的输出经过/&gt;进行关键信息选择,得到一个新的隐藏层状态：                  其中,⊙为点积,为i时刻的编码阶段输出的隐藏层状态向量,/&gt;为i时刻的门控单元向量；S3：在解码阶段引入变分思想对变分潜在变量建模,并且对损失函数再平衡,提取摘要句子的全局潜在信息来生成摘要；所述步骤S3中,与第一层不同的是,第二层隐藏层状态是将前一个时刻解码器的输出y-(t-1)、前一个时刻第二层隐藏层状态/&gt;和上下文语义向量C-t作为输入来计算：                  其中,y-(t-1)为前一个时刻解码器的输出,为前一个时刻第二层隐藏层状态,C-t为上下文语义向量；变分潜在变量建模实际是一个变分编码过程,利用t时刻之前解码器的输出y-(＜t)和潜在变量z-(＜t)得到一个后验分布并假设这个分布为正态分布,用/&gt;来近似真实的后验分布p-θ(z-t|y-(＜t),z-(＜t)),并从/&gt;采样出潜在变量z-t,由于采样的过程不可导,采样的结果可导,为了保证模型训练,采用重构参数技巧获得新的潜在变量z-t：                  其中,ε～N(0,I)为噪声变量,高斯参数μ-t和σ-t分别为变分均值和标准差；所述步骤S3中,在生成摘要的过程中引入句子全局潜在信息,将潜在变量z-t和第二层隐藏层状态结合作为最终的解码器的隐藏层状态/&gt;                  其中,和/&gt;为可训练的权重矩阵,/&gt;为偏置向量,tanh(·)为激活函数；将最终解码器的隐藏层状态经过线性变换后输入至so层获得目标词汇y-t的概率分布,计算方式如下：                  其中,为可训练的权重矩阵,/&gt;为偏置向量；通过最小化损失函数来训练模型和优化参数,损失函数由生成摘要目标词汇的负的对数似然和变分潜在变量建模时VAE的损失函数组成；生成摘要目标词汇的负的对数似然表示如下：                  变分潜在变量建模时VAE的损失函数由KL散度和重构误差两部分组成：                  由于VAE网络在训练时,轻视了重构误差的严重性,两个损失处于不平衡状态,这样会导致严重的KL散度项消失问题,使得VAE网络退化,因此对VAE损失函数进行再平衡,在KL散度项之前加一个超参数系数β来修复这种不平衡：                  其中,0≤β&lt;1,最终的损失函数为：loss＝loss-(word)+loss-(VAE′)。</td>   <td>G06F16/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余阳;                   陈建兵       </td>   <td>中山大学</td>   <td>一种基于区块链的可信数据通信方法及系统</td>   <td>广东省</td>   <td>CN116089978A</td>   <td>2023-05-09</td>   <td>本发明涉及业务过程协同技术领域,公开了一种基于区块链的可信数据通信方法及系统,包括以下步骤：S1.构建通信智能合约；S2.向加入区块链的业务协同的各方发送非对称密钥对；S3.发送方向业务数据接受方发起业务数据传输的请求；S4.接收方通过监听区块链,获取步骤S3中的请求内容,解析请求内容；S5.接收方生成传输密钥对和业务数据传输主题,向业务数据发送方发起回应；S6.发送方获取回应内容；S7.发送方生成公钥加密业务数据后的结果,向接收方发送公钥加密业务数据后的结果；S8.接收方通过监听区块链,传输公钥,获取结果,通过传输密钥解析结果获取业务数据。本发明解决了现有业务过程协同技术无法保证保密性、匿名通信的问题,其具有高效方便的特点。</td>   <td>1.一种基于区块链的跨域业务过程协同可信数据通信方法,其特征在于：包括以下步骤：S1.构建适用于基于区块链的业务过程协同中业务数据传输的通信智能合约；S2.向加入区块链的业务协同的各方发送唯一的一对非对称密钥对,其中公钥公开可见,作为参与方身份认证的基础,私钥由各方各自保管；S3.需要进行数据传输时,业务数据发送方调用通信智能合约内容生成业务数据传输的请求,向业务数据接受方发起业务数据传输的请求；S4.业务数据接收方通过监听区块链,获取步骤S3中的请求内容,验证业务数据发送方身份,使用接收方的自身私钥解析请求内容；S5.业务数据接收方在本地生成一对业务数据传输密钥对和一个业务数据传输主题,并调用通信智能合约生成回应,向业务数据发送方发起回应；S6.业务数据发送方通过监听区块链,获取步骤S5中的回应内容,验证业务数据接收方身份,使用发送方的自身私钥获得业务数据传输公钥和业务数据传输主题；S7.业务数据发送方通过调用智能合约生成公钥加密业务数据后的结果,向业务数据接收方发送公钥加密业务数据后的结果；S8.业务数据接收方通过监听区块链,传输公钥,获取步骤S7中的结果,通过步骤S5中生成的业务数据传输密钥解析结果获取业务数据。</td>   <td>G06F21/60;G06F21/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李雄;              谢雨琪;              张易东;                   熊宇涵       </td>   <td>中山大学</td>   <td>一种基于数字孪生的智慧城市绿化设计方法及装置</td>   <td>广东省</td>   <td>CN116090065A</td>   <td>2023-05-09</td>   <td>本发明涉及绿化规划与设计技术领域,公开了一种基于数字孪生的智慧城市绿化设计方法及装置。本发明根据目标城市绿化项目中需采集物理实体信息数据的目标数据类型建立相关的多元异构数据库；基于该数据库实时获取并存储该项目在建设过程中的物理实体信息数据,构建贯穿该项目全生命周期的虚拟数据孪生模型；基于该数据库中的时变数据调整该模型以实时反映相应物理实体的变化情况,并基于当前虚拟数据孪生模型对该项目的目标未来指标进行预测,进而输出绿化设计方案建议以提示用户；检测到方案调整指令被触发时相应调整绿化设计方案。本发明能够实现绿化设计方案的实时仿真预测与智能动态化调整,使数据信息得以从设计阶段传递至下一阶段。</td>   <td>1.一种基于数字孪生的智慧城市绿化设计方法,其特征在于,包括：确定目标城市绿化项目中需采集物理实体信息数据的目标数据类型,根据所述目标数据类型建立目标城市绿化项目相关的多元异构数据库；根据所述多元异构数据库,实时获取并存储所述目标城市绿化项目在建设过程中的各所述目标数据类型的物理实体信息数据；基于所述多元异构数据库构建贯穿所述目标城市绿化项目的全生命周期的目标虚拟数据孪生模型；基于所述多元异构数据库中的时变数据调整所述目标虚拟数据孪生模型以实时反映相应物理实体的变化情况,并基于当前的目标虚拟数据孪生模型对所述目标城市绿化项目的目标未来指标进行预测,基于得到的预测结果输出绿化设计方案建议以提示用户；所述目标未来指标包括目标植物的目标生长参数、目标植物的健康状态及目标环境参数；检测到方案调整指令被触发时相应调整所述目标城市绿化项目的绿化设计方案；所述方案调整指令在检测到物理实体约束条件发生改变或者接收到针对所述绿化设计方案建议的反馈信息时被触发。</td>   <td>G06F30/13;G06F30/20;G06T17/00;G06F16/23;G06F16/25;G06F16/51;G06Q10/0631;G06Q50/08;G06Q50/26;G06F111/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李伟忠;                   严朝煜       </td>   <td>中山大学</td>   <td>一种体外受精胚胎卵裂球图像自动分割及面积计算的方法</td>   <td>广东省</td>   <td>CN116091421A</td>   <td>2023-05-09</td>   <td>本发明涉及胚胎光镜图像处理技术领域,具体公开一种体外受精胚胎卵裂球图像自动分割及面积计算的方法,包括：采用基于深度学习的目标检测模型对胚胎光镜图片进行卵裂球检测,获取卵裂球候选框；融合卵裂球候选框,获取胚胎候选框；基于胚胎候选框提取感兴趣区域；对感兴趣区域进行图像增强处理；采用交互式图像分割算法对胚胎光镜图片进行自动分割,获取卵裂球掩码及胚胎掩码；通过卵裂球掩码及胚胎掩码在胚胎光镜图片上分别进行卵裂球描边及胚胎描边；计算卵裂球掩码及胚胎掩码的面积,获取卵裂球面积及胚胎面积。本发明的方法能够对卵裂球及胚胎图形进行精准分割,实现卵裂球及胚胎的精确描边及面积计算,识别精度高。</td>   <td>1.一种体外受精胚胎卵裂球图像自动分割及面积计算的方法,其特征在于,包括：采用基于深度学习的目标检测模型对胚胎光镜图片进行卵裂球检测,获取卵裂球候选框；融合所述卵裂球候选框,获取胚胎候选框；基于所述胚胎候选框提取感兴趣区域；对所述感兴趣区域进行图像增强处理；胚胎光镜图片的感兴趣区域经图像增强处理后,采用交互式图像分割算法对所述胚胎光镜图片进行自动分割,获取卵裂球掩码及胚胎掩码；通过所述卵裂球掩码及所述胚胎掩码在胚胎光镜图片上分别进行卵裂球描边及胚胎描边；计算所述卵裂球掩码及所述胚胎掩码的面积,获取卵裂球面积及胚胎面积。</td>   <td>G06T7/00;G06T7/11;G06T7/187;G06T7/62;G06T5/00;G06T5/30;G06T5/50;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              周凡;                   周朗       </td>   <td>中山大学</td>   <td>面向结构功能分析的非局部几何分割建模方法与系统</td>   <td>广东省</td>   <td>CN116091743A</td>   <td>2023-05-09</td>   <td>本发明公开了一种面向结构功能分析的非局部几何分割建模方法。输入待分割的同类三维模型集合,其中每个模型记为M-i,为每个三维模型M-i生成权重图G-i,为每个权重图G-i构建一个权重矩阵W-i,之后构建出每对模型之间的匹配矩阵；然后根据每个模型的权重矩阵W-i以及每对模型之间的匹配矩阵,构建模型集合的联合权重矩阵C；使用联合权重矩阵C运行多重谱图分割方法求取整个模型集合的最优分割矩阵,从而对集合中的所有模型同时进行分割,以便进行功能分析。本发明还公开了一种面向结构功能分析的非局部几何分割建模系统。本发明可以实现对模型的自动分割而不需要提供任何训练集作为先验知识,从而提升了分割方法的实用性,为后续功能分析提供基础。</td>   <td>1.一种面向结构功能分析的非局部几何分割建模方法,其特征在于,所述方法包括：输入待分割的同类三维模型集合,集合中三维模型的个数为N,集合中的每个模型记为M-i,i＝1,2,…,N；为所述每个三维模型M-i生成权重图G-i,G-i中的顶点表示M-i中的面片,G-i中的顶点与M-i中的面片的数量记作n-i；为所述每个权重图G-i构建一个权重矩阵权重矩阵中的元素w-(x,y)表示连接顶点x与y的边的权重,即度量所述每个三维模型M-i中面片f-x与f-y之间的相似性的数值；将所有三维模型M都映射到同一谱域空间中,再利用基于最大期望的点配准算法计算任意两个模型之间的非刚性变换,从而获取每对模型的面片对应关系,然后通过面片的特征向量在谱域空间中的距离计算相互匹配的面片之间的相似性,从而构建出每对模型之间的匹配矩阵；根据所述三维模型集合中每个模型的所述权重矩阵以及所述每对模型之间的匹配矩阵,构建模型集合的联合权重矩阵C；使用所述模型集合的联合权重矩阵C运行多重谱图分割方法求取整个模型集合的最优分割矩阵,从而对集合中的所有模型同时进行分割,以便进行功能分析。</td>   <td>G06T19/20;G06T7/33;G06T7/62;G06T7/64;G06V10/74;G06V10/75;G06V10/762</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘建平;              任飞;              刘尊龙;                   郑剑锋       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种胰腺癌预后预测模型建立方法</td>   <td>广东省</td>   <td>CN116092664A</td>   <td>2023-05-09</td>   <td>本发明涉及一种胰腺癌预后预测模型建立方法,包括,步骤S1,第一计算单元对数据库存储的病例信息进行胰腺癌预后相关因素统计学分析,获取与胰腺癌患者长期生存情况相关的因素；步骤S2,第二计算单元将病例划分为建模组和验证组,对建模组病例的胰腺癌患者长期生存情况相关的因素进行多因素回归分析,筛选对胰腺癌患者预后存在影响的独立风险因素；步骤S3,模型构建单元将筛选的独立风险因素按比例转换为分数,构建胰腺癌患者预后预测模型；步骤S4,中控单元对构建的胰腺癌患者预后预测模型进行重复采样校正,并根据验证组的病例数据对胰腺癌患者预后预测模型进行验证,用于更为准确的获取胰腺癌预后生存寿命。</td>   <td>1.一种胰腺癌预后预测模型建立方法,其特征在于,包括：步骤S1,第一计算单元对数据库存储的病例信息进行胰腺癌预后相关因素统计学分析,获取与胰腺癌患者长期生存情况相关的因素；步骤S2,第二计算单元将病例划分为建模组和验证组,对建模组病例的胰腺癌患者长期生存情况相关的因素进行多因素回归分析,筛选对胰腺癌患者预后存在影响的独立风险因素；步骤S3,模型构建单元将筛选的独立风险因素按比例转换为分数,构建胰腺癌患者预后预测模型；步骤S4,中控单元对构建的胰腺癌患者预后预测模型进行重复采样校正,并根据验证组的病例数据对胰腺癌患者预后预测模型进行验证。</td>   <td>G16H50/20;G16H50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马建军;              丁文洁;              李诚豪;              陈俊杰;              林越翔;              黄林冲;              杨宏伟;                   梁禹       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>二维颗粒填充模型的生成方法</td>   <td>广东省</td>   <td>CN116071447A</td>   <td>2023-05-05</td>   <td>本发明涉及二维颗粒填充模型的生成方法,该方法包括步骤：S1,基于模型边界构建出二维颗粒填充计算域；S2,确定待生成颗粒的级配,根据该级配下生成的颗粒半径的取值范围、以及所述取值对应的生成概率,构建半径数值集合；S3,根据模型边界与颗粒粒径计算网格数据,并对网格进行划分；S4,采用解析方法确定新生成颗粒的圆心坐标；S5,判断新生成颗粒与相邻网格以及所属网格内的颗粒是否发生重叠,若无重叠发生,则将该新生成颗粒填充至所述模型中,若发生重叠,则重新生成新颗粒S6,重复步骤S4至S5,直至完成模型建立。本发明的方法为离散元和非连续变形分析法前处理部分提供了一种高效可靠的二维建模方法,极大地提高了计算效率。</td>   <td>1.一种二维颗粒填充模型的生成方法,其特征在于,包括以下步骤：S1,基于模型边界构建出二维颗粒填充计算域；S2,确定待生成颗粒的级配,根据该级配下生成的颗粒半径的取值范围、以及所述取值对应的生成概率,构建半径数值集合；S3,根据模型边界与半径数值集合计算网格数据,并对网格进行划分；S4,根据所述半径数值集合确定M号种子颗粒和N号次种子颗粒的半径,根据M号种子颗粒和N号次种子颗粒的半径、圆心坐标值以及边界函数,采用解析方法确定新生成颗粒的圆心坐标；S5,根据新生成颗粒的圆心坐标、半径确定其所属网格,结合其所属网格与新生成颗粒的映射关系,判断新生成颗粒与相邻网格以及所属网格内的颗粒是否发生重叠,若无重叠发生,则将该新生成颗粒填充至所述模型中,若发生重叠,则重新生成新颗粒；S6,重复步骤S4至S5,直至完成模型建立。</td>   <td>G06T11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周瑞莹;              梁艺阐;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于问题生成和卷积神经网络的常识问答方法</td>   <td>广东省</td>   <td>CN110647619B</td>   <td>2023-05-05</td>   <td>本发明提供一种基于问题生成和卷积神经网络的常识问答方法,该方法通过BERT语言模型将内容-问题编码成向量序列,传入问题生成模块,再传入共享的BERT语言模型,然后将内容-问题-答案组成的三元组通过BERT语言模型,输出的内容-问题-答案的编码序列传入答案选择模块,通过卷积神经网络对其做分类,最后,模型得到的评分来选取最优的选项作为模型选出的候选答案。</td>   <td>1.一种基于问题生成和卷积神经网络的常识问答方法,其特征在于,包括以下步骤：S1：构建内容-问题的输入序列,传入BERT语言模型,编码好的向量序列再传入问题生成模块,问题生成模块学习到了内容与问题中的重要信息,再将序列传入共享的BERT语言模型,其中,BERT语言模型是一种预训练的深度双向Transformer语言模型；所述步骤S1的具体过程是：S11：预处理数据集文本,拼接成由内容和问题组成的新组合序列s＝{c-1,c-2,…c-n,q-1,q-2,…,q-m},其中,c代表内容的上下文序列,c-i代表的是内容的上下文序列的第i个词,q代表问题序列,q-j代表的是问题序列的第j个词,再将新组合中的每一个单词用一个低维度的,紧密的实数向量进行表示,向量从BERT语言模型的词库中进行匹配,该词库涵盖了30522个词,对于socialIQA数据集只有3％的未登录词；S12：再将该序列向量表示成[cls]&lt;内容&gt;[sep]&lt;问题&gt;[sep]传入BERT预训练语言模型中,其中,[cls]表示句首标志,[sep]表示分割符,并且BERT模型中本身已经包含了对每个单词的语义建模,所以,BERT模型输出的每个词都是带有语义信息的,从而,学习到了内容与问题的相关联的语义信息,输出表示为h～(qg)＝BERT{s},其中,BERT代表语言表示模型,s是S11过程中提及的由内容和问题组成的新序列；S13：再将该输出序列放入问题生成模块,首先将传入第一层掩码多头自注意力网络层,该网络表示成s～′-(＜t)＝Multihead(q～′-(＜t),q～′-(＜t),q～′-(＜t)),其中q～′-(＜t)是原问题序列,s′是经过掩码多头自注意力网络后的表示序列,Multihead是掩码多头自注意力网络,再传入多头注意力网络o-t＝Multihead(s～′-(＜t),h～(qg),h～(qg)),其中o-t表示的是新生成的问题序列；S14：将新生成的问题序列,传入一个前馈神经网络o～′-t＝W-2(ReLU(o-tW-1+b)),其中,ReLU(x)＝max(x,0),W-1是权重向量,W-2是权重向量,ReLU是激活函数,b是偏移常量,再将o～′-t经过一个softmax函数来计算预测的生成问题的概率序列q～′-t＝softmax(o～′-tW),其中W是权重向量；S2：构建内容-问题-答案的输入序列,传入BERT语言模型,编码成向量形式表示句子；所述步骤S2的具体过程是：S21：对于每个常识问答样例,拆分成以下的形式表示,{内容,问题,答案A},{内容,问题,答案B},{内容,问题,答案C},然后转化成BERT语言模型传入的向量形式表示为[cls]&lt;内容&gt;[sep]&lt;问题&gt;[sep]&lt;答案&gt;[sep]；S22：将候选样例传入BERT语言模型,输入为e＝{c-1,c-2,…c-n,q-1,q-2,…,q-m,a-1,a-2,…,a-k},其中,c代表内容的上下文序列,c-i代表的是内容的上下文序列的第i个词,q代表问题序列,q-j代表的是问题序列的第j个词,a代表候选答案的词序列,a-l代表候选答案序列的第l个词,随后,经过BERT语言模型,输出表示为h～*＝BERT{e}；S3：经过BERT语言模型后的内容-问题-答案编码序列,传入文本卷积神经网络中训练,得到对于每个候选项的评分,通过对评分的排序,选取最高的得分选项成为预测答案；S4：完成训练阶段,再将测试集的样例,表示成内容-问题-答案编码序列,放入模型中进行预测答案。</td>   <td>G06F16/332;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈旭琳;              林天歆;              吴少旭;              洪桂斌;              林真;              汪进;                   陈睿       </td>   <td>中山大学孙逸仙纪念医院;赛维森(广州)医疗科技服务有限公司</td>   <td>膀胱癌淋巴结转移的病理图像识别方法、装置、介质</td>   <td>广东省</td>   <td>CN115880293B</td>   <td>2023-05-05</td>   <td>本申请公开了一种膀胱癌淋巴结转移的病理图像识别方法、装置、介质,包括将目标图像块输入目标分割网络,得到分割置信度图；对分割置信度图中所有像素点的值取平均值,得到分类置信度；将分类置信度的值排序,选取前N个目标图像块进行非均匀重采样处理,得到重采样图像块；将重采样置信度图进行映射处理,得到映射置信度图；将映射置信度图与目标图像块的分割置信度图融合,得到融合置信度图；将融合置信度图与目标图像块中未进行非均匀重采样处理的目标图像块的分割置信度图拼接,得到病理图像的识别结果。本申请对病理图像进行非均匀重采样处理,能够对淋巴结组织图像中的转移癌实现准确分割,提高病理图像的识别效率和准确率。</td>   <td>1.一种膀胱癌淋巴结转移的病理图像识别方法,其特征在于,包括：获取病理图像,按照预设分辨率大小对所述病理图像进行滑窗裁剪,得到M个目标图像块,其中M为大于1的自然数；分别将M个所述目标图像块输入目标分割网络,得到M个对应于所述目标图像块的分割置信度图,其中所述分割置信度图的像素点的值表征所述像素点属于癌这一类别的概率；对所述分割置信度图中所有像素点的值取平均值,得到所述目标图像块的分类置信度；将M个所述目标图像块按照对应的所述分类置信度的值从大到小进行排序,并从中选取前N个所述目标图像块分别进行非均匀重采样处理,得到N个对应于所述目标图像块的重采样图像块,其中N为大于0且小于M的自然数；分别将N个所述重采样图像块输入目标分割网络,得到N个对应于所述重采样图像块的重采样置信度图；将所述重采样置信度图进行映射处理,得到对应于所述目标图像块的映射置信度图；将所述映射置信度图与对应于所述目标图像块的分割置信度图进行融合,得到N个融合置信度图；将所述N个融合置信度图与M个所述目标图像块中未进行非均匀重采样处理的目标图像块的分割置信度图进行拼接,得到所述病理图像的识别结果。</td>   <td>G06T7/00;G06T3/40;G06T7/11;G06V10/26;G06V10/764;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林谋广;                   周凡       </td>   <td>中山大学</td>   <td>一种智能眼镜的三维图形自适应显示方法</td>   <td>广东省</td>   <td>CN109829974B</td>   <td>2023-05-05</td>   <td>本发明公开了一种智能眼镜的三维图形自适应显示方法。本发明使用服务器对三维模型进行简化,并在简化过程中把简化掉的部分按照设计好的文件格式保存成一系列的细节文件,智能眼镜根据网络与设备性能通过读取从服务器下载的模型细节自适应地快速重构并显示三维图形。本发明可以在达到满足用户实时交互需求的显示帧率的前提下,自适应地为用户提供尽量多的三维模型细节,为用户在网上商店查看商品的三维模型、在虚拟博物馆中查看藏品的三维模型等应用中提供有效的帮助。本发明设计的便于重构的细节文件结构,把大量的图形简化与细节保存计算放到服务器上,使性能低下的智能眼镜能快速进行图形重构,提升用户交互地查看三维模型时的使用体验。</td>   <td>1.一种智能眼镜的三维图形自适应显示方法,其特征在于,所述方法包括：用户从智能眼镜的应用中选取需要查看三维模型的物品；所述智能眼镜的应用把用户所选取的物品的编号传输给服务器；所述服务器根据所述物品编号,调取对应的细节丰富的原始三维模型进行图形简化,并在简化的过程中把简化掉的细节保存成文件,最终形成一个最简模型与一系列有顺序的细节文件；所述智能眼镜的应用从所述服务器下载所述物品的最简模型进行交互显示,以满足用户最基本的交互式查看需求；当网络传输速度以及三维模型显示帧率大于设定的阈值时,所述智能眼镜的应用从所述服务器按顺序下载所述细节文件进行渐进式重构与显示,直到显示帧率刚好小于设定的阈值为止；其中,所述服务器在简化的过程中把简化掉的细节保存成文件,最终形成一个最简模型与一系列有顺序的细节文件,具体包括：所述服务器对原始三维模型M-0进行一次简化,形成一个低细节模型M-1以及把简化过程中删除掉的顶点和拓扑信息保存为细节文件detail-1；所述服务器对原始三维模型M-1进行一次简化,形成一个低细节模型M-2以及把简化过程中删除掉的顶点和拓扑信息保存为细节文件detail-2；如此类推,最终形成一个最简模型M-n与一系列有顺序的细节文件detail-1、detail-2……detail-n；具体地,所述细节文件detail-(i+1)的结构包括3个列表：列表1记录了从模型M-i简化成简化模型M-(i+1)所删除的顶点；列表1中每个被移除的顶点信息包括该顶点在原始模型M-0中的顶点索引值,以及该顶点的三维坐标值；列表1用于把简化时移除的顶点的三维坐标信息添加到M-(i+1)以重构成M-i；列表2记录了从模型M-i简化成简化模型M-(i+1)所删除的三角形；列表2记录的只是被删除的三角形,而不包括由于边折叠的缘故被改变了的三角形；列表2中每个被删除的三角形信息包括该三角形在原始模型M-0中的面索引值,以及该三角形的三个顶点在原始模型M-0中的顶点索引值；列表2用于把简化时移除的三角形的三个顶点索引信息添加到M-(i+1)以重构成M-i；列表3记录了边折叠过程中所发生的顶点合并操作；但是其记录的并不是从模型M-i简化成简化模型M-(i+1)所发生的顶点合并操作,而是从M-0简化成M-1、M-1简化成M-2、……M-(i-1)简化成M-i这一系列的简化过程中所发生的所有顶点合并操作的一个子集；所有的顶点合并操作标记为“A→B”的形式,表示点A移动到点B的位置与点B合并；简化过程中在构造detail-(i+1)细节文件的列表3的时候,服务器需要用一个递归的过程遍历所有的顶点合并操作来寻找必要的顶点合并操作以组成该子集：第1步,以顶点合并操作“A→B”作为输入,如果其中的点B在细节文件的列表1中,则“A→B”被加入到列表3中,跳到第2步；而如果点B不在列表1中,服务器检查下一条顶点合并操作,直到所有顶点合并操作都被检查完毕；第2步,由于在第1步中“A→B”被加入到列表3中,因此把点A看作是“被影响”的顶点,服务器从所有顶点合并操作中找出所有形如“x→A”的操作,然后把这些“x→A”重新作为第1步的输入；此外,列表3所包含的一系列顶点合并操作是以渐进式简化的逆序进行保存的,即先保存M-(i-1)简化成M-i的顶点合并操作,再保存M-(i-2)简化成M-(i-1)的顶点合并操作,如此类推,直到最后才保存从M-0简化成M-1的顶点合并操作；具体地,所述最简模型的文件结构与细节文件结构类似,其中列表1记录了模型简化成最简模型后的所有剩余顶点,其中每个顶点信息包括该顶点在原始模型M-0中的顶点索引值,以及该顶点的三维坐标值；列表2记录了模型简化成最简模型后的所有剩余三角形,其中每个三角形信息包括该三角形在原始模型M-0中的面索引值,以及组成该三角形的三个顶点的顶点索引值；列表3记录了各次简化所产生的所有的顶点合并操作,且同样是以渐进式简化的逆序进行保存。</td>   <td>G06T17/00;G06T15/08;G02B27/01</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              董金凤;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种基于群等变神经网络和条件概率场的病理切片识别方法</td>   <td>广东省</td>   <td>CN110930369B</td>   <td>2023-05-05</td>   <td>本发明提供一种基于群等变神经网络和条件概率场的病理切片识别方法,该方法使用群等变卷积核代替传统卷积核,提高了系统对于输入切片识别的鲁棒性,对于不同角度的输入具有更加优秀的一致性,在以上改变的基础上,本专利系统还使用了条件随机场算法,减少了预测结果中的噪声,提高了预测的准确率。</td>   <td>1.一种基于群等变神经网络和条件概率场的病理切片识别方法,其特征在于,包括以下步骤：S1：收集病理切片数据,并将获取的数据分成训练集和测试集；S2：对训练集数据进行人工标注,之后进行分割；S3：构建基于群等变换卷积和条件随机场的端到端的深度学习神经网络,并将S2得到的数据输入到该深度学习神经网络中进行训练；S4：将测试集数据输入到训练好的深度学习神经网络中进行测试步骤S3中构建基于群等变换卷积和条件随机场的端到端的深度学习神经网络的过程是：1)、替换传统卷积核为群等变换卷积核,群等变换卷积定义为：设K表示传统卷积核,将该卷积核进行旋转和镜像操作,可以得到其它卷积核K-1,K-2,K-3…,K-n,这些卷积核组成一个新的集合S,这个集合便组成了一个基于旋转和镜像操作的群,也就是S中任何一个元素进行旋转或者镜像后得到的结果还是S中的元素；2)、输入的patch中N×N个节点组成一张概率无向图,每个节点之间相互连接,这张图是一个条件随机场,每个节点都有自己的特征向量以及是癌变区域的概率,定义具有相同标签,特征向量相近的图片应当具有相似的概率输出,通过条件随机场的方式来完成这个任务；步骤S4的过程是：输入测试集切片,不同于训练阶段的随机分块分割方法,在测试阶段使用滑动窗的方式,将测试切片划分成网格形式,依次输入到训练好的模型中,得到对应切块的是否是癌区的概率,然后拼合到一起得到整张切片的概率热图。</td>   <td>G06T7/00;G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄华兵;                   王先伟       </td>   <td>中山大学</td>   <td>一种城市内涝风险快速评估方法及系统</td>   <td>广东省</td>   <td>CN111507375B</td>   <td>2023-05-05</td>   <td>本发明公开了一种城市内涝风险快速评估方法及系统,以内涝发生快慢为衡量风险的标准：对于给定内涝点,降雨之后达到危险积水深度所需的时间越短,留给应急响应的时间越有限,则相应的风险越大。以上方案只需要设计暴雨、DEM、土地利用/覆盖和排水系统设计标准即可计算,不涉及复杂的水动力模型,对排水管网数据要求低,基于GIS平台即可完成计算。本发明方法及系统解决了现有内涝风险评估对基础数据及操作人员的建模能力要求高、且其存在计算效率低、实用性差的问题。</td>   <td>1.一种城市内涝风险快速评估方法,其特征在于,包括以下步骤：S1.对于目标区域,根据DEM识别潜在的内涝发生位置,划定每一个内涝发生位置的汇水范围,并构成相应的小流域；S2.计算每个所述小流域的属性,包括其汇水面积A、平均坡度S、积水体积V；其中：S21.所述小流域的汇水面积A、平均坡度S计算：所述小流域的汇水面积A为该小流域对应洼地的自身面积与其汇水范围面积之和；平均坡度S采用洼地汇水范围内栅格的平均坡度值；S22.所述小流域的积水体积V计算：积水体积V为洼地达到危险积水深度所需的水量；先设定积水深度,得到该积水深度对应的水面高程H,统计洼地低于水面高程H的栅格共有m个,且对应的高差为h-i(i＝1,2,...,m)；设定DEM的栅格大小为d；则积水体积V为：                  S3.设定降雨情景,根据水量平衡模型,考虑包括排水系统设计标准、土壤渗透和蒸散发的影响,计算在地表形成积水的内涝雨量R-i；其中：S31.计算降雨量R：设定一个或多个降雨情景,对于每个降雨情景,执行以下计算：                  式中q为设定暴雨强度,t为设定降雨历时,P为设定重现期；其中A-1,C,b,n根据统计方法进行确定；计算得到该降雨情景暴雨强度q后,乘以降雨历时即得到其降雨量：R＝q×t；S32.计算产流雨量R-f：当目标区域具备实测的蒸散发量和土壤渗透能力数据时：利用已有的不透水面成果,或者采用监督分类方法从高分遥感影像或航空正射影像中提取不透水面的空间分布,并结合渗透模型计算通过土壤的下渗量；降雨量R扣除实测的蒸散发量和计算下渗量后即得到洼地小流域的产流雨量R-f；当目标区域不具备实测的蒸散发量和土壤渗透能力数据时：根据洼地流域的土地利用现状确定不同土地利用类型的面积比例,再使用预设的径流系数推荐值,采用面积加权平均的方式计算每个洼地小流域的综合径流系数；降雨量R乘以综合径流系数即得到洼地小流域的产流雨量R-f；S33.计算管道排水P：管道排水P根据目标区域的城市排水系统的设计资料确定或采用水力模型对目标区域的实际管道排水能力进行校核或根据目标区域的实际降雨事件对应的内涝情况进行经验性的反推；S34.计算内涝雨量R-i：R-i＝R-f-P,内涝雨量为产流雨量R-f与管道排水P之差；内涝雨量R-i值应为正值,若为非正值则说明无内涝发生；S4.以所述小流域为单元,以内涝发生快慢作为衡量标准,计算目标区域的内涝风险Risk：Risk＝ln-i×A×S～(1/)/)。</td>   <td>G06Q10/0635;G06F18/24;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         程梦成;              苏卓;                   郑贵锋       </td>   <td>中山大学</td>   <td>一种基于深度卷积生成对抗网络的视频超分辨率生成方法</td>   <td>广东省</td>   <td>CN109087243B</td>   <td>2023-05-05</td>   <td>本发明公开了一种基于深度卷积生成对抗网络的视频超分辨率生成方法。其中,该方法包括：获取目标视频,将同一场景的视频片段进行转换成连续的图像序列信息作为原图组以PNG格式保存；将所述原图组进行采样缩放,获取缩小的低分辨率图像,进行运动补偿处理,获得补偿后的低分辨率图像；构建深度卷积生成对抗网络模型,将所述补偿后的低分辨率图像输入进行计算,输出重建后的高分辨率图像后再进行放大处理,获得超分辨率图像；将所述超分辨率图像,按照所述目标视频进行重新组合,获得超分辨率目标视频。实施本发明实施例,能够有效地提高低分辨率视频的重建质量,快速生成纹理细节更加丰富、效果更加自然真实的图像。</td>   <td>1.一种基于深度卷积生成对抗网络的视频超分辨率生成方法,其特征在于,所述方法包括：获取目标视频,将同一场景的视频片段进行转换成连续的图像序列信息作为原图组以PNG格式保存；将所述原图组进行采样缩放,获取缩小的低分辨率图像,进行运动补偿处理,获得补偿后的低分辨率图像；构建深度卷积生成对抗网络模型,将所述补偿后的低分辨率图像输入进行计算,输出重建后的高分辨率图像后再进行放大处理,获得超分辨率图像；将所述超分辨率图像,按照所述目标视频进行重新组合,获得超分辨率目标视频；其中,所述构建深度卷积生成对抗网络模型,具体为：获取若干图片作为训练集,对训练集每张图像的X轴和Y轴上分别移动1个像素,再进行下采样处理,获得具有亚像素位移的低分辨率图像；利用多个残差单元组成生成网络；其中,每个残差单元包括两个卷积层Conv、两个批归一化层BN,以及一个ReLU激活函数组合而成,并使用跳跃连接使得残差单元之间相连；每个残差单元中的卷积核大小为3x3,每层卷积滤波器的数量为64；利用一个卷积层Conv、一个批归一化层BN,以及一个PReLU激活函数组合判别网络；其中,每个残差单元中的卷积核大小为3x3,每层卷积滤波器的数量分别为64,64,128,128,256,256,512,512；获取生成网络和判别网络组合成构建深度卷积生成对抗网络模型,并对其进行训练,获得训练后的深度卷积生成对抗网络模型；训练过程中,为了避免生成对抗网络陷入局部最优,采用训练好的基于最小化均方误差的残差网络块作为生成模型的初始化；其中,网络输入的图像块大小设置为36×36,初始学习率设为10～(-4),每迭代10～4次,学习率下降5％,最大迭代次数为10～6,依次更新生成网络G和判别网络D,生成器有4个相同的残差单元,判别器有6个相同的残差单元。</td>   <td>G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;                   黄荣洲       </td>   <td>中山大学</td>   <td>交通特征预测方法、系统及存储介质</td>   <td>广东省</td>   <td>CN111047078B</td>   <td>2023-05-05</td>   <td>本发明涉及一种交通特征预测方法,基于深度学习模型GA-GCN实现,包括以下内容：获取历史交通特征数据集；预处理所述历史交通特征数据集；将所述历史交通特征数据集按固定时间间隔进行划分；使用所述划分后的每份历史交通特征数据集对深度学习模型GA-GCN进行训练；结束训练,使用训练好的深度学习模型GA-GCN对测试集中的交通特征进行预测,得到预测结果。</td>   <td>1.交通特征预测方法,其特征在于：基于深度学习模型GA-GCN实现,包括以下内容：获取历史交通特征数据集；预处理所述历史交通特征数据集；将所述历史交通特征数据集按固定时间间隔进行划分；使用所述划分后的每份历史交通特征数据集对深度学习模型GA-GCN进行训练；结束训练,使用训练好的深度学习模型GA-GCN对测试集中的交通特征进行预测,得到预测结果；使用所述历史交通特征数据集对深度学习模型GA-GCN进行训练的具体过程如下：判断深度学习模型GA-GCN当前的训练次数是否达到指定的训练次数,若是则结束训练,否则执行以下内容：将所述划分后的每份历史交通特征数据集输入至深度学习模型GA-GCN的第一层GLU,得到输出A；拷贝一份输出A得到输出A’, 输出A进入深度学习模型GA-GCN的cosAtt层,输出A’进入深度学习模型GA-GCN的GCN层,GCN层输出的结果经过Sigmoid激活函数后,和cosAtt层输出的结果进行逐元素点乘,得到输出B；输出B进入深度学习模型GA-GCN的第二层GLU,得到输出C；输出C进入深度学习模型GA-GCN的卷积归一化层,卷积归一化层将数据整合成一个时间帧,输出结果表示为输出D；输出D使用激活函数Sigmoid激活后,再通过深度学习模型GA-GCN的全连接层FullyConnection得到前项传播输出结果；反向传播调整深度学习模型GA-GCN的各层参数；所述交通特征包括速度、流量。</td>   <td>G06Q10/04;G06Q50/26;G06N3/0464;G06N3/048;G06N3/084;G06N3/086;G06N3/126</td>  </tr>        <tr>   <td>中国专利</td>   <td>         窦耀勇;              唐家伟;                   吴维刚       </td>   <td>中山大学</td>   <td>一种基于注意力机制的集群资源预测方法和装置</td>   <td>广东省</td>   <td>CN110222840B</td>   <td>2023-05-05</td>   <td>本发明公开提供了一种基于注意力机制的集群资源预测方法和装置,采用改进的注意力机制,并将其集成到LSTM中,可以挖掘多个时间序列之间的相关性,并提出使用多个时间序列进行集群内资源需求预测的方案,有效提高了预测的准确率,能更加有效的辅助资源规划,从而提高集群的资源利用率,更有效地降低数据中心的运维成本。</td>   <td>1.一种基于注意力机制的集群资源预测方法,其特征在于,包括：S1：将上一时刻第一隐藏层状态、与目标实例同属于一个部署单元的所有时间序列数据、与目标实例同属于一个主机单元的所有时间序列数据以及历史时刻的目标时序作为输入注意力层的输入,得到第一输入向量；步骤S1具体包括：S11：将上一时刻第一隐藏层状态以及与目标实例同属于一个部署单元的所有时间序列数据作为部署单元注意力层的输入,得到部署单元注意力层输出向量；S12：将上一时刻第一隐藏层状态以及与目标实例同属于一个主机单元的所有时间序列数据作为主机单元注意力层的输入,得到主机单元注意力输出向量；S13：将上一时刻第一隐藏层状态以及历史时刻的目标时序作为自相关性注意力层的输入,得到自相关性注意力层输出向量；S14：将部署单元注意力层输出向量、主机单元注意力输出向量和自相关性注意力层输出向量合并作为第一输入向量；S2：将所述第一输入向量输入到LSTM编码器,得到当前第一隐藏层状态；S3：将所述当前第一隐藏层状态和上一时刻第二隐藏层状态输入到时间相关性注意力层,得到上下文向量；S4：将所述上下文向量、上一时刻第二隐藏层状态和历史时刻的目标时序输入到LSTM解码器,得到当前第二隐藏层状态；S5：将所述当前第二隐藏层状态和所述上下文向量进行线性变换,得到预测值。</td>   <td>G06N3/045;G06N3/0442;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;              廖异;                   阳建华       </td>   <td>中山大学</td>   <td>基于生成对抗网络的端到端JPEG域图像隐写方法</td>   <td>广东省</td>   <td>CN112634117B</td>   <td>2023-05-05</td>   <td>本发明提供一种基于生成对抗网络的端到端JPEG域图像隐写方法。该方法由三部分完成：编码器,解码器以及判别器。生成对抗网络的生成网络部分由编码器与解码器联合构成,对抗部分由判别器完成。编码器负责秘密信息的嵌入,解码器负责秘密信息的提取,判别器对载体图像和载密图像进行区分,将该分类误差作为损失函数来进行对抗训练,不断提升生成对抗网络的性能。另外加入干扰层用于模拟实际传输信道中会受到的常见干扰。本发明提出的针对JPEG域图像的隐写方法通过修改DCT系数的方式对JPEG图像进行秘密信息的嵌入与提取,具有较强的实用性；训练过程中添加干扰层,提高了算法在实际应用场景下的鲁棒性；通过与判别器进行对抗训练,增强了隐写算法的安全性。</td>   <td>1.一种基于生成对抗网络的端到端JPEG域图像隐写方法,其特征在于,秘密信息的嵌入与提取均由生成对抗网络来完成,所述的生成对抗网络包括编码器、解码器和判别器,另外加入干扰层用于模拟实际传输信道中会受到的常见干扰；所述生成对抗网络的训练包括以下步骤：S1：将秘密信息和载体图像在JPEG域上的DCT系数矩阵输入到编码器中,由编码器输出载密图像对应的DCT系数矩阵；S2：将载密图像的DCT系数矩阵输入到IDCT变换模块中,得到空域载密图像；S3：将空域载密图像输入干扰层,得到加入干扰后的噪声载密图像的DCT系数；S4：将步骤S3生成的噪声载密图像的DCT系数输入到解码器中,得出解密信息；S5：将S1中的载体图像的DCT系数矩阵输入到IDCT变换模块中,得到空域载体图像；S6：将S5中的空域载体图像和S2得到的空域载密图像输入到判别器中,判别器对空域载体图像和空域载密图像进行二分类,将二分类后得到的分类误差作为损失函数,并把该损失函数反向传播从而进行生成对抗网络的更新；S7：重复步骤S1-S6,直至得到训练后的生成对抗网络；S8：根据提取信息的准确率与载密图像的安全性,挑选出效果最佳的生成对抗网络,将载体图像和秘密信息放入训练好的编码器生成载密图像,将载密图像放入解码器得到解密信息。</td>   <td>G06T1/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              张达良;              陈荣军;              谢舜道;              朱雄泳;                   曾衍瀚       </td>   <td>中山大学</td>   <td>一种基于区块链和大数据技术的商品溯源系统</td>   <td>广东省</td>   <td>CN111539750B</td>   <td>2023-05-05</td>   <td>本发明公开了一种基于区块链和大数据技术的商品溯源系统,包括数据采集及查询模块,区块链溯源系统及大数据集群服务环境；数据采集及查询模块用于获取及查询商品溯源信息数据,区块链溯源系统用于对商品核心数据进行上链保存,大数据集群服务环境用于对商品详情进行存储；其中商品核心数据为所述商品溯源信息数据中的预设定的核心部分,商品详情为商品溯源信息数据的所有数据。本发明将商品核心数据提交到区块链溯源系统进行上链保存,有效防止被恶意篡改,区块链账本的去中心化分布可明显提高商品重要数据的容灾能力；同时将商品详情传输到大数据系统中进行存储,提高数据管理效率,减小区块链账本的存储压力,提高系统交易的吞吐量。</td>   <td>1.一种基于区块链和大数据技术的商品溯源系统,其特征在于,包括：数据采集及查询模块,以及分别与其连接的区块链溯源系统、大数据集群服务环境；所述数据采集及查询模块用于获取及查询商品溯源信息数据,所述区块链溯源系统用于对商品核心数据进行上链保存,所述大数据集群服务环境用于对商品详情进行存储；其中商品核心数据为所述商品溯源信息数据中的预设定的核心部分,商品详情为所述商品溯源信息数据的所有数据；所述区块链溯源系统包括介于应用程序和区块链底层之间的客户端节点,Peer节点、排序节点、证书颁发机构；其中客户端节点与Peer节点和排序节点建立连接；Peer节点包括主节点、背书节点和记账节点；在所述区块链溯源系统中,一个组织内部包括多个Peer节点,其中主节点仅有一个,所述主节点是该组织与排序节点进行通信的唯一节点；所述背书节点与智能合约绑定,用于为交易做担保,每个智能合约被安装到区块链上时,都会设置背书策略,指定该智能合约的交易经过哪些节点背书以后才有效；所有Peer节点都是记账节点,记账节点验证从排序节点接收到的区块和交易的有效性,验证完成后计入本地账本,若交易有效,则同时更新状态数据库中的数据状态,从而完成记账；全区块链溯源系统中的客户端提交的交易通过哈希算法计算出交易摘要后发送到排序节点,所述排序节点利用Raft共识算法为各个交易摘要对应的交易进行排序,排序完成后,客户端按照该排序交易直接发送给区块链各组织的主节点；证书颁发机构用于鉴定区块链上的身份是否有效及合法,只有被证书颁发机构认可的身份才能在区块链上进行交易,否则会被拒绝；所述记账节点采用并行处理方式验证从排序节点接收到的区块和交易的有效性,对于验证为无效的交易,标记并将其滤除；对于验证为有效的交易,计入区块链账本进行存储。</td>   <td>G06Q30/018;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              李威琪;                   周晓聪       </td>   <td>中山大学</td>   <td>一种基于注意力机制的推荐系统召回方法</td>   <td>广东省</td>   <td>CN111062775B</td>   <td>2023-05-05</td>   <td>本发明公开一种基于注意力机制的推荐系统召回方法,包括：提取训练样本中的用户特征和商品特征,将用户特征转化为用户嵌入向量,将商品特征转化为商品嵌入向量；将用户嵌入向量和商品嵌入向量输入注意力机制模型训练,通过模型中注意力网络学习每个特征的权重,依据权重对所有特征的嵌入向量做加权求和,得到用户表征向量和商品表征向量；计算用户表征向量和商品表征向量的内积,得到训练样本的用户购买商品意愿匹配度,建立用户购买商品意愿匹配度的交叉熵损失函数,计算最小化的交叉熵损失函数,收敛注意力机制模型；将待测样本输入收敛后的注意力机制模型,获取待测样本的用户购买商品意愿匹配度,选择用户购买商品意愿匹配度在预置区间的商品作为召回结果进行推荐。本发明增强了泛化性,大量简化了召回推荐的计算量。</td>   <td>1.一种基于注意力机制的推荐系统召回方法,其特征在于,包括如下步骤：S10提取训练样本中的用户特征和商品特征,将用户特征转化为用户嵌入向量,将商品特征转化为商品嵌入向量；S20将用户嵌入向量和商品嵌入向量输入注意力机制模型训练,通过模型中注意力网络学习每个特征的权重,依据权重对所有特征的嵌入向量做加权求和,得到用户表征向量和商品表征向量；计算用户表征向量和商品表征向量的内积,得到训练样本的用户购买商品意愿匹配度,建立用户购买商品意愿匹配度的交叉熵损失函数,计算最小化的交叉熵损失函数,收敛注意力机制模型；所述S20中多层用户注意力网络包括K层用户注意力网络,在第K层用户注意力网络中,用户表征向量u～((k))由下式给出：                                    其中,所有变量的上标K(K-1)都是表示第K(K-1)层注意力网络,U-Attation代表用户注意力网络,每一层网络都相同,网络结构的具体运算过程由下面几个式子组成,网络的输入是用户特征的嵌入向量和上一层的输出/&gt;网络的输出为该层的用户表征向量u～((k)),m～((k))是一个保存前K层网络得到的表征向量的累加和的一个存储向量,在得到输入后,注意力网络首先通过两层前馈神经网络FNN和softmax层做归一化得到注意权重/&gt;利用权重向量将T个用户特征向量做加权平均得到该层的表征向量u～((k)),在第K层,对于t＝1,2,3,…,T,先求出该层用户第t个嵌入向量的权重                                    其中,都是网络参数矩阵,/&gt;表示第k层用户注意力网络中以用户第t个特征的嵌入向量u-t为输入的神经网络的参数矩阵,/&gt;表示第k层用户注意力网络中以上一层输出的存储向量/&gt;为输入的神经网络的参数矩阵,/&gt;表示第k层用户注意力网络中以隐藏层变量/&gt;为输入的神经网络的参数矩阵,/&gt;为以用户第t个特征得到的隐藏层向量,tanh为激活函数,⊙为自定义向量乘法运算,即两个相同长度的向量,相同位置的元素相乘,得到新的向量,/&gt;通过与一个行数为1的矩阵作矩阵乘法,得到一个值/&gt;然后经过softmax变换,得到最终的用户第K层的表片向量权重/&gt;e为自然常数,然后根据计算用户嵌入向量的加权和,得到用户第K层的表征向量u～((k))：          /&gt;S30将待测样本输入收敛后的注意力机制模型,获取待测样本的用户购买商品意愿匹配度,选择用户购买商品意愿匹配度在预置区间的商品作为召回结果进行推荐。</td>   <td>G06Q30/0601;G06F16/9535</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              罗维冰;              陈荣军;              谢舜道;              邓雅文;              朱雄泳;                   曾衍瀚       </td>   <td>中山大学</td>   <td>适用于可视化二维码的全参考图像质量评价方法及系统</td>   <td>广东省</td>   <td>CN111598837B</td>   <td>2023-05-05</td>   <td>本发明公开了适用于可视化二维码的全参考图像质量评价方法及系统,针对可视化二维码的固有特点,选择颜色、对比度、梯度三个方面的失真和畸变,作为可视化二维码质量评价方案的参考指标。通过对可视化二维码颜色相似度、对比度相似度和梯度相似度分别进行计算,并通过最终的加权平均得到可视化二维码图像质量评价结果。该评价方法解决了目前的经典图像质量评价方法不适合可视化二维码的问题,将可视化二维码图像是彩色图像,编码过程中产生的图像结构、对比度失真等特点考虑进方案中,更加有针对性的评价可视化二维码编码图像质量,更好的指导可视化二维码方案的优化和改进更好的评价其特点,对编码方案的优化和改进提供更好的参考依据。</td>   <td>1.适用于可视化二维码的全参考图像质量评价方法,其特征在于,包括以下步骤：S1.获取待评价的可视化二维码图像,根据编码方案中数据区域的设置,获取其可视化二维码数据区域图像；S2.将获取的可视化二维码数据区域图像转换成RGB彩色模型；S3.基于所述RGB彩色模型,获取所述可视化二维码数据区域图像和原始可视化二维码图像的R、G、B三个通道的像素值,并计算可视化二维码图像的颜色相似度；所述步骤S3具体包括：计算R通道的颜色相似度：                  计算G通道的颜色相似度：                  计算B通道的颜色相似度：                  其中R和D分别表示大小为M×N的原始可视化二维码图像和可视化二维码数据区域图像；下标r,g,b分别R、G、B三个通道；i,j表示像素坐标；C-r、C-g、C-b分别表示R、G、B三个通道的颜色相似度；C-1为常数,C-1远小于1；通过加权评价得到可视化二维码图像的颜色相似度为：C＝α-rC-r+α-gC-g+α-bC-b其中α-r、α-g、α-b分别表示R、G、B三个通道分量的权重,α-r、α-g、α-b满足α-r+α-g+α-b＝1；S4.根据可视化二维码数据区域图像的模块数和图像大小,对可视化二维码数据区域图像和原始可视化二维码图像进行模块划分,并对两张图像的R、G、B三个通道同时以编码模块为单位进行对比度相似度计算,得到可视化二维码图像的对比度相似度；S5.对可视化二维码数据区域图像和原始可视化二维码图像的R、G、B三个通道图像分别获取梯度图像,计算可视化二维码图像的梯度相似度；S6.将所述可视化二维码图像颜色相似度、对比度相似度和梯度相似的指标合并,得到可视化二维码图像质量评价结果。</td>   <td>G06T7/00;G06T7/44;G06T7/90;G06T5/00;G06V10/74;G06K7/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         叶永杰;                   吴维刚       </td>   <td>中山大学</td>   <td>一种区块链支付通道网络的交易路径短路方法</td>   <td>广东省</td>   <td>CN110852485B</td>   <td>2023-05-05</td>   <td>本发明提供的一种区块链支付通道网络的交易路径短路方法,通过设置支付通道集线器以连接多个支付通道,从而进行不同支付通道间的资金交易,实现交易路径的短路。本发明提供的一种区块链支付通道网络的交易路径短路方法,充分利用了支付网络高灵活性的特点,通过在网络上设置支付通道集线器,实现了对不同支付通道的短路,从而大幅度缩短非直连节点之间交易的路径长度,提高了支付网络中的交易效率。</td>   <td>1.一种区块链支付通道网络的交易路径短路方法,其特征在于：通过设置支付通道集线器以连接多个支付通道,从而进行不同支付通道间的资金交易,实现交易路径的短路；所述的集线器交易的过程主要由节点A与节点B进行推动,节点A和节点B分别代表β-(AC)和β-(BD),具体过程为：节点A将消息iou发送给支付通道集线器H,其中消息iou包括消息gcc～(AC)、消息gcc～(BD)和节点A的签名信息；支付通道集线器H收到消息iou后会记录并且向节点B转发该消息；当节点B收到来自支付通道集线器H的消息iou之后,对其进行验证,判断是否与通道内协商过程的两个消息gcc消息一致,若一致则向支付通道集线器H回应消息receipt,消息receipt包括消息gcc～(AC)、消息gcc～(BD)和节点B的签名信息；当支付通道集线器H收到来自节点B的消息receipt后,会将资金从支付通道β-(AC)转移至支付通道β-(BD),并向节点A和节点B发送消息conf以完成集线器交易过程,其中消息conf包括消息iou和消息receipt；所述的通道内结算过程具体为：支付通道β-(AC)的通道内结算过程为：节点A将消息res～(AC)发送给节点C,节点C收到消息res～(AC)之后对其进行验证,随后返回消息conf～(AC)向节点A进行确认；确认完毕后,节点A和节点C双方对支付通道β-(AC)资金容量的变更达成一致,结果为通道资金容量发生了变化,节点A在支付通道内的金额发生改变,改变量为Δx,节点C在支付通道内的金额不变；其中,消息res～(AC)包括消息conf和节点A的签名信息；消息conf～(AC)包括消息res～(AC)和节点C的签名信息；同理,支付通道β-(BD)进行相应的操作,结果为通道资金容量发生了变化,节点B在支付通道内的金额发生改变,改变量为Δx,节点D在支付通道内的金额不变。</td>   <td>G06Q10/047;G06Q20/38;G06Q20/42;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张东;                   俞承言       </td>   <td>中山大学</td>   <td>一种面向多数据集的人脸表情识别方法、系统及设备</td>   <td>广东省</td>   <td>CN116071801A</td>   <td>2023-05-05</td>   <td>本发明公开了一种面向多数据集的人脸表情识别方法、系统及设备,该方法包括：收集人脸表情识别数据集；基于补充数据集挑选出标注标准一致的子集；利用标注标准一致的子集训练多任务深度学习模型；利用多任务深度学习模型对目标数据集和补充数据集赋予伪标签,并将补充数据集的标注标准统一到目标数据集上,得到标注标准统一后的人脸表情识别数据样本；利用标注标准统一后的人脸表情识别数据数据样本训练多任务深度学习模型,得到人脸表情识别模型；利用人脸表情识别模型进行人脸表情识别,输出特征结果。通过使用本发明,能够实现跨数据集的训练模型并且同时考虑离散标签和连续标签,使得识别结果更加准确。</td>   <td>1.一种面向多数据集的人脸表情识别方法,其特征在于,包括以下步骤：收集人脸表情识别数据集,所述人脸表情识别数据集包括目标数据集和补充数据集；基于补充数据集挑选出标注标准一致的子集；利用标注标准一致的子集训练多任务深度学习模型；利用多任务深度学习模型对目标数据集和补充数据集赋予伪标签,并将补充数据集的标注标准统一到目标数据集上,得到标注标准统一后的人脸表情识别数据样本；利用标注标准统一后的人脸表情识别数据样本训练多任务深度学习模型,得到人脸表情识别模型；利用人脸表情识别模型进行人脸表情识别,输出特征结果。</td>   <td>G06V40/16;G06V10/774;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡跃新;              陈俊周;              曾俊波;                   张梓睿       </td>   <td>中山大学孙逸仙纪念医院;中山大学</td>   <td>一种二阶精细化颞骨CT图像分割方法</td>   <td>广东省</td>   <td>CN116071381A</td>   <td>2023-05-05</td>   <td>本发明公开了一种二阶精细化颞骨CT图像分割方法,包括以下步骤：步骤S1：收集多组病例病人的颞骨CT图像,对原数据进行清洗,判断有无错误标注和遗漏标注；步骤S2：对原数据进行格式的转换,并划分训练集和测试集,在此基础上对颞骨的功能区分别训练目标检测模型；步骤S3：利用该目标检测模型对颞骨的功能区进行定位,并根据功能区的不同大小自适应地裁剪出图片块；步骤S4：根据裁剪出的图片块训练分割模型,得到最终的图像分割结果。本发明在第一阶段采用高精度的目标检测算法,对颞骨相关区域进行精准定位；根据颞骨不同结构的大小,自适应地裁剪出合适的图片块,用于第二阶段的分割算法,优化正负样本不均衡的问题,加快模型训练和收敛的速度。</td>   <td>1.一种二阶精细化颞骨CT图像分割方法,其特征在于：包括以下步骤：步骤S1：收集多组病例病人的颞骨CT图像,对原数据进行清洗,判断有无错误标注和遗漏标注；步骤S2：对原数据进行格式的转换,并划分训练集和测试集,在此基础上对颞骨的功能区分别训练第一阶段的目标检测模型；步骤S3：利用该目标检测模型对颞骨CT的不同结构的功能区进行定位,并根据功能区的不同大小自适应地裁剪出图片块。步骤S4：根据裁剪出的图片块训练第二阶段分割模型,得到颞骨CT不同结构最终的图像分割结果。</td>   <td>G06T7/11;G06T7/00;G06T7/73;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              卢建业;                   周凡       </td>   <td>中山大学</td>   <td>一种用于立体图像拼接的关联图构造方法</td>   <td>广东省</td>   <td>CN110443838B</td>   <td>2023-05-05</td>   <td>本发明公开了一种用于立体图像拼接的关联图构造方法。本发明根据立体图像左、右视图和视差图构成的立体信息,将立体图像视图间的2D匹配点对升维成3D匹配点对,采用基于3D匹配点对的概率模型判断立体图像间的匹配关系,从而构建多幅立体图像匹配关系的关联图,用以引导立体图像进行自动化拼接。本发明基于传统的用于平面图像拼接的关联图构造方法进行改进,开拓性地从3D视角检测立体图像间的匹配关系,给出了一种简洁有效的关联图构造方法,为多副立体图像的拼接提供可靠的匹配关系关联图,避免需要用户指定立体图像的拼接顺序,为自动化立体图像拼接提供必要前提。</td>   <td>1.一种用于立体图像拼接的关联图构造方法,其特征在于,所述方法包括：步骤一,输入一组立体图像的左视图、右视图和视差图,并给出立体相机内参；步骤二,为每一幅立体图像分配一个索引号；步骤三,以索引号为节点,构建任意两个节点均相连的关联图；步骤四,对关联图中每一条边两端节点所对应的立体图像,提取左、右视图中的SIFT特征点,获得立体图像间的2D匹配点对；步骤五,基于视差图和相机内参,将步骤四中获得的2D匹配点对升维成3D匹配点对；步骤六,选择关联图中的一条边,基于3D匹配点对,采用概率模型检测该边两端节点所对应的立体图像是否具有匹配关系,若无匹配关系,则从关联图中删除该条边；步骤七,重复执行步骤六,直至关联图中的每一条边均被检测；步骤八,检测关联图中是否存在孤立点,若存在,则删除孤立点；步骤九,输出最终关联图；其中,所述步骤五,基于视差图和相机内参,将步骤四中获得的2D匹配点对升维成3D匹配点对,具体为：对关联图中一条边的两端节点i与j,获得其对应的立体图像的视差图D-i与D-j,和2D匹配点对k＝1,2,3,...,n-(ij)},其中n-(ij)表示匹配点对的数目；进一步的,/&gt;写成/&gt;即/&gt;所对应的第i副立体图像左视图中的像素二维坐标；/&gt;在视差图D-i对应坐标的视差值为d-(ik),根据公式：                  将二维像素点升维成三维像素点/&gt;表示成/&gt;同理/&gt;对应的二维像素点/&gt;也升维成三维像素点/&gt;表示成/&gt;从而2D匹配点对升维成3D匹配点对,用Θ-(ij)表示升维后的3D匹配点对,即：                  其中→表示升维操作。</td>   <td>G06T7/33;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>              段凯       </td>   <td>中山大学</td>   <td>一种跨流域调水效率评估方法</td>   <td>广东省</td>   <td>CN111191886B</td>   <td>2023-05-02</td>   <td>本发明公开了一种基于区域水资源模拟的跨流域调水效率评估方法,该方法通过模拟调水工程对区域水资源压力的影响范围与强度,辨识复杂环境变化背景下跨流域调水对水资源受益区的正面影响与对水资源受损区的负面影响,系统地衡量复杂变化环境下的跨流域调水效率,提出了“调入比与调出比之差”、“水资源压力缓解指数”等调水效率评价指标,为不同水文地质与经济社会背景下不同跨流域调水效率的一致性量化比较提供了一种简单有效的解决方法。</td>   <td>1.一种跨流域调水效率评估方法,其特征在于,包括以下步骤：S1.根据评估目的设定跨流域调水工程的不同环境背景,分别收集各环境背景下流域径流过程的数据并计算对应的区域水资源量；S2.设定在不考虑跨流域调水工程的受水区与供水区下游影响时,跨流域调水效率的效率评价指标,根据所述效率评价指标构建跨流域调水效率的评价模型；所述的不考虑区域下游影响时跨流域调水效率的评价模型为：                                    其中TI与TO分别表示调入比与调出比,T为调水量,TF-m(r)与TF-m(s)分别为受水区与供水区在自然情景下的区域水资源量；DIO＝TI-TO其中DIO为跨流域调水工程中受水区的调入比与供水区的调出比之差,TI表示调入比,TO表示调出比；在所述评价模型中,DIO的数值越大,表示在不考虑区域下游影响时跨流域调水效率越大；S3.设定跨流域调水工程的受水区与供水区下游所受影响的影响评价指标,根据所述影响评价指标构建跨流域调水效率的总体评价模型；所述的影响评价指标包括跨流域调水工程中受水区与供水区所覆盖的面积、人口、以及跨流域调水工程导致的区域水资源压力变化；其中区域水资源压力变化的计算为：                  其中WD为区域需水量,TF-(ct)与TF-c分别为耗水及调水后情景下以及耗水后情景下的区域水资源量；所述的总体评价模型具体为：                  其中SRI为水资源压力缓解指数,P-i为第i个受到调水影响的流域内的人口,ΔWS-i为调水对第i个区域水资源压力的缓释指数λi为预赋值的区域权重系数,T为调水量；在所述总体评价模型中,SRI的数值越大,表示在综合考虑受水区与供水区下游影响的情况下该跨流域调水工程的效率越大；S4.将步骤S1收集的所述数据及区域水资源量输入步骤S2的评价模型或步骤S3的总体评价模型,从而得到相应的跨流域调水效率评估结果。</td>   <td>G06Q10/0631;G06Q10/0639;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              时福源;              陈湘萍;                   李全忠       </td>   <td>中山大学</td>   <td>一种基于代码更改关键类判定的代码提交注释预测方法</td>   <td>广东省</td>   <td>CN110908709B</td>   <td>2023-05-02</td>   <td>本发明公开一种基于代码更改关键类判定的代码提交注释预测方法,包括根据修改前的代码、修改后的代码与代码更改内容提取出结构性耦合信息作为代码结构特征,将代码更改内容作为代码修改特征；将代码结构特征与代码修改特征作为LightGBM的输入,判断此次代码更改中的关键类和非关键类；在此基础上将关键类作为transformer模型的输入,预测生成提交注释信息。本发明本发明通过识别代码修改中的关键类再对其进行提交注释信息的预测,提高了提交注释预测的有效性和准确性。</td>   <td>1.一种基于代码更改关键类判定的代码提交注释预测方法,其特征在于,包括：S10输入代码提交数据,从代码提交数据中修改前的代码、修改后的代码与代码修改内容中提取代码实体间结构耦合特征作为代码结构特征；S20从代码更改内容中获取代码修改特征；S30对代码修改内容进行分类标注,将代码核心的修改内容标注为代码更改关键类,将为了完成核心修改所进行的依赖性改动内容标注为代码更改非关键类；S40将代码结构特征、代码修改特征及分类标注输入机器学习框架LightGBM训练,获取判别代码更改关键类与代码更改非关键类的最优模型作为代码更改关键类预测模型；S50筛选出具有书写规范且具有准确表达代码更改内容的注释信息的代码输入代码更改关键类预测模型,获取代码更改内容的代码更改关键类或代码更改非关键类；S60将代码更改内容的代码更改关键类输入深度学习框架分词、编码、解码并分类处理,获得代码更改关键类的概率矩阵,并以其与代码的提交注释的均方误差作为损失函数进行训练,以均方误差最小的深度学习框架为提交注释预测模型；S70将待预测的代码数据输入训练好的提交注释预测模型获取代码注释的预测结果。</td>   <td>G06F8/73;G06F16/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;                   冯燊明       </td>   <td>中山大学</td>   <td>基于堆叠沙漏网络的关键特征区域匹配人脸识别方法</td>   <td>广东省</td>   <td>CN109657595B</td>   <td>2023-05-02</td>   <td>本发明涉及计算机视觉识别技术领域,提出一种基于堆叠沙漏网络的关键特征区域匹配人脸识别方法,包括以下步骤：采集训练集,并进行预处理；对输入人脸图片进行预处理；将图片输入堆叠沙漏网络中进行特征提取,输出人脸关键点热图和关键点位置信息；对原图片进行关键区域裁剪,并从训练集中选取三元组；将关键区域进行特征提取,得到特征图F；将特征图F输入嵌入层中得到标签E；根据特征图的L2范数计算三元损失函数,重复上述步骤至三元损失函数收敛；将待识别的人脸图片输入完成训练的堆叠沙漏网络和人脸识别模块中,输出识别的标签E。本发明引入堆叠沙漏网络进行人脸识别,排除非关键区域的影响,有效提高人脸识别效果,具有较强的鲁棒性。</td>   <td>1.基于堆叠沙漏网络的关键特征区域匹配人脸识别方法,其特征在于,包括以下步骤：S1：采集人脸图片作为训练集,并对训练集的图片进行预处理；其中,对训练集图片的预处理包括人脸检测、裁剪、人脸矫正以及人工标记；S2：将训练集的任意一张人脸图片输入堆叠沙漏网络中进行特征提取,输出人脸关键点热图和关键点位置信息；其中,所述堆叠沙漏网络包括4个密集连接的沙漏结构网络；其步骤包括：S2.1：将人脸图片输入第一个沙漏结构网络中进行四次下采样,保留每次下采样的图片,记为d-1,d-2,d-3,d-4；S2.2：将d-4输入到残差模块中,再进行四次上采样,同时每次上采样时和下采样对应尺寸的特征图进行连接,输出特征图y-1,同时保留每次上采样的图片；S2.3：将特征图y-1输入第二个沙漏结构网络中进行四次下采样,每次下采样时和上一个沙漏结构网络上采样中对应尺寸的特征图进行连接,再输入残差模块中进行四次上采样,每次上采样时和该沙漏结构网络中下采样对应尺寸的特征图进行连接,输出特征图y-2,保留每次采样时的图片；S2.4：重复S2.3步骤,至输入第4个沙漏结构网络,输出带有关键点位置信息的特征图y-4；S3：根据所述关键点位置信息对原输入人脸图片进行区域裁剪得到关键区域,并从训练集中选取三元组；S4：将关键区域输入人脸识别模块中的卷积神经网络进行特征提取,得到特征图F；S5：对特征图F求取L2范数,然后通过人脸识别模块中的嵌入层,输出完成识别的人脸图片的标签E；S6：根据L2范数计算三元损失函数,通过梯度下降法对三元损失函数进行优化；S7：重复S2～S6至三元损失函数收敛,完成堆叠沙漏网络和人脸识别模块的训练；S8：将待识别的人脸图片输入堆叠沙漏网络中进行特征提取,裁剪图片的关键区域,然后输入卷积神经网络中进行特征提取,最后通过嵌入层输出识别的人脸图片标签。</td>   <td>G06V40/16;G06V10/46;G06V10/75;G06V10/764;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗洁;              林泽帆;                   林佳吟       </td>   <td>中山大学</td>   <td>一种基于CT图像的多触点电极自动分割方法</td>   <td>广东省</td>   <td>CN110363778B</td>   <td>2023-05-02</td>   <td>本发明涉及医学影像处理技术领域,一种基于CT图像的多触点电极的自动分割方法,包括以下步骤：S1.图像预处理；S2.利用电极灰度与人体组织不同的特点初步分割采用阈值分割进行；S3.利用形态学方法,将阈值分割后图像中属于同一电极的触点连接起来,并对识别出的电极进行编号；S4.利用统计学方法,将电极主轴提取出来并根据电极规格分割触点,得到触点分割结果。本方法是一种具有高鲁棒性、易实现的基于CT图像的多触点电极的自动分割方法。该方法可以在不同CT金属伪影条件下,更有效的去除各种干扰,稳健地对多触点脑外科植入电极进行自动分割。该方法考虑了CT图像中各类可引起干扰的情况,对于不同CT伪影强度有较好的适应性。</td>   <td>1.一种基于CT图像的多触点电极的自动分割方法,其特征在于,包括以下步骤：S1.图像预处理；S2.对预处理后的图像,利用电极灰度与人体组织不同的特点采用阈值分割方式进行初步分割；S3.利用形态学方法,将阈值分割后图像中属于同一电极的触点连接起来,并对识别出的电极进行编号；S4.利用统计学方法,将电极主轴提取出来并根据电极规格分割触点,得到触点分割结果；步骤S1图像预处理的具体过程为：将电极植入后的CT配准到电极植入术前的MRI图像上,利用大脑掩模剥离颅骨外的组织及导线；步骤S2的具体过程为：对剥离颅骨外组织及导线的图像进行阈值分割以去除绝大部分大脑组织,即利用电极与人体组织的CT值区别,对电极进行第一次分割得到断开的电极,此时同属于一根电极的触点有可能不在同一连通分量里；上述阈值分割的方法采用基于图像灰度的阈值分割法、简单阈值分割、最优阈值分割或自适应阈值分割中的一种；步骤S3的具体实现过程为：S31.形态学闭操作,即在三维空间中对阈值分割结果中的连通分量进行闭运算,把同一电极且较近的触点连接起来；S32.降阈值区域生长,即以阈值分割结果中的连通分量为种子,选择低于步骤S2中所选阈值分割的阈值进行区域生长,直至达到生长终止条件；所述生长终止条件是指属于同一电极的连通分量已被生长区域包含；不属于电极的干扰都被排除；所述步骤S32中的电极的干扰都被排除,其中的干扰为颅骨、硬脑膜或距离较近但属于其他电极的触点；在进行排除时,对所有的干扰按其与颅骨的空间关系分类,并依类进行排除；具体为：基于电极的几何信息建立多种约束条件,包括体积、方向、角度、距离四类约束条件,其中体积约束：根据触点的形状和大小此类已知信息对当前连通分量是触点还是干扰加以判断；方向约束：根据电极应该朝向大脑深部而非沿皮层表面植入这一信息,对当前连通分量是电极还是干扰进行判断；角度约束：属于同一电极的两个线状连通分量的轴线所成夹角小于设定角度,据此判断这两个连通分量是否属于同一电极；距离约束：如果连通分量的中心到电极轴线的距离小于设定值,认为当前连通分量属于该电极。</td>   <td>G06T7/11;G06T7/136;G06T7/187</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   许海城       </td>   <td>中山大学</td>   <td>一种基于深度迁移网络的点击率预测方法及装置</td>   <td>广东省</td>   <td>CN110738314B</td>   <td>2023-05-02</td>   <td>本发明公开一种基于深度迁移网络的点击率预测方法及装置,本装置用于实现本方法,方法包括将连续型字段进行离散化处理；对离散特征进行预处理,转化为特征id编码,并得到映射字典；利用Glove模型将特征id编码转化为表征向量作为深度迁移网络嵌入层的初始化参数；将特征id编码输入到深度迁移网络进行训练；对测试样本进行离散化处理,并利用映射字典M将离散特征映射为特征id编码；将特征id编码输入深度迁移网络进行点击率的预测。本发明优化了点击率预测方法,提升了预测准确性的同时保持了预测的低时延。</td>   <td>1.一种基于深度迁移网络的点击率预测方法,其特征在于,包括如下步骤：S10对训练样本的连续型字段进行离散化处理,以获取训练样本离散特征；S20为每个训练样本离散特征创建唯一的特征id索引码,并根据训练样本离散特征与其特征id索引码之间映射关系建立离散特征的映射字典M；S30将特征id索引码在不同样本中共现频数进行统计以创建特征共现频数矩阵,通过Glove模型将特征id索引码转化为特征共现频数矩阵的表征向量矩阵,且将表征向量作为深度迁移网络Embedding层的初始化参数；S40将特征id索引码输入到深度迁移网络以获取预测点击率的交叉熵损失,并采用反向传播算法更新深度迁移网络的所有参数；包括：S401将特征id索引码输入到深度迁移网络的嵌入层Embedding得到相应表征向量；S402将相应表征向量输入因子分解FM网络,因子分解FM网络对相应表征向量进行内积得到FM预测点击率p-(fm)(x),其中内积公式如下：其中x为输入的特征id索引码,v为表示特征id索引码的表征向量,i,j∈n,i和j为不同的特征id索引码下标,n为特征id索引码总数,W-(fm)为FM网络线性回归项的权重参数,b-(fm)为FM网络线性回归项的偏置参数,＜v-i,v-j＞为表征向量v-i和v-j的内积运算；将相应表征向量输入共享感知机网络进行非线性变换,得到抽象表征向量：h-s＝sigmoid(W-sv+b-s),其中,v为输入到共享感知机网络的表征向量,W-s和为共享感知机网络的权重参数,b-s为共享感知机网络的偏置参数,h-s为共享感知机输出的抽象表征向量；将抽象表征向量h-s输入深层感知机网络,经如下前馈计算公式得到深层感知机网络预测点击率p-(deep)(x)：                                    其中ReLU为激活函数,为深层感知机网络的第l层权重参数,/&gt;为深层感知机网络的第l层偏置参数,/&gt;为第l层的输出向量,h-s为共享感知机网络的输出向量,且具体层数需人工设置；将抽象表征向量h-s输入轻量感知机网络,经如下前馈计算公式得到轻量感知机网络预测点击率p-(light)(x)：                                    其中ReLU为激活函数,为轻量感知机网络的第l层权重参数,/&gt;为轻量感知机网络的第l层偏置参数,/&gt;为第l层的输出向量,h-s为共享感知机网络的输出向量,且层数取经验值,并且轻量感知机网络层数比深层感知机网络少；S403整合FM网络、轻量感知机网络和深层感知机网络的预测点击率计算点击率损失L(x；W,b),计算公式如下：L(x；W,b)＝H(y,p-(fm)(x))+H(y,p-(light)(x))+H(y,p-(deep)(x))+λ||z-(light)(x)-z-(deep)(x)||～2,式中H(y,p)为二分类任务常用的交叉熵损失函数,x为输入的特征id索引码,y为训练数据的二分类标签取值,p为p-(fm)(x)时表示FM网络的点击率预测值,p为p-(light)(x)时表示轻量感知机网络的点击率预测值,p为p-(deep)(x)时表示深度网络的点击率预测值,λ为确定轻量感知机网络和深度网络预测误差的权重值,λ取经验值,z-(light)(x)为轻量感知机网络进行sigmoid变换前的模型输出值p-(light)(x)＝sigmoid(z-(light)(x)),z-(deep)(x)为深度网络进行sigmoid变换前的模型输出值p-(deep)(x)＝sigmoid(z-(deep)(x))；S404根据点击率损失L(x；W,b),采用反向传播算法更新深度迁移网络的所有参数；S50将测试样本进行离散化处理以获取测试样本离散特征,并将测试样本离散特征基于映射字典M匹配映射得到测试样本的特征id索引码；S60将测试样本的特征id索引码输入深度迁移网络进行预测,获得测试样本的点击率预测。</td>   <td>G06N3/0464;G06N3/084;G06Q10/04;G06Q30/0251;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何金钰;                   朝红阳       </td>   <td>中山大学</td>   <td>一种半监督的三维点云手势关键点检测方法</td>   <td>广东省</td>   <td>CN110751097B</td>   <td>2023-05-02</td>   <td>本发明属于计算机视觉领域下的模式识别领域,更具体地,涉及一种半监督的三维点云手势关键点检测方法,采用这种方法可以利用未标注的数据获得准确的三维关键点信息；本发明提出了基于TOF模组生成三维点云进行手势关键点识别的方法,三维点云相对二维图像对于复杂场景和光线条件较差的环境,识别精度有较大的提升；本发明优化了点云数据的处理方式,先对手部点云进行平滑再采样,比采样后再平滑精度更高。</td>   <td>1.一种半监督的三维点云手势关键点检测方法,其特征在于,包括以下步骤：S1.构建RGB-D手势数据集；S11.由TOF模组拍摄手势训练集,分别获得2D图片和1:1对应的深度图；S12.设计二维图像的手部关键点检测网络进行训练；S13.基于检测网络在2D图片上进行手部关键点的识别；S14.将2D图像上的关键点对应到深度图,获得关键点的手势关键点深度坐标；S2.数据预处理；S21.将深度图的手部区域转为三维世界坐标；S22.通过重采样对手部三维点云进行平滑,通过对周围数据点进行高阶多项式插值来重建表面缺失的部分；S23.对平滑后的手部点云进行随机采样,最后获得1024个点；S24.根据当前点云求出点云的法线；求点云的法线采用主成分分析的方法,找到最小特征值对应的方向,即为所求的法线方向,具体包括：S241.基于K-D树对点云中每个点计算K邻近邻域；S242.计算PCA的协方差矩阵S＝∑(Ni–C)×(Ni–C),其中Ni为邻域点,C为中心点；对S求解特征值和特征向量,然后取最小的特征值对应的特征向量作为该点对应的法线；S243.检查法线的朝向是否一致指向视点,如果不是则反向；S25.对点云进行归一化处理；S3.搭建点云检测网络,输入大小为Nx6的点云数据集,N为训练样本点云的大小,此处为1024,网络输出为21个关键点的三维坐标P；S4.手势关键点识别与分类；首先,基于距离阈值去除部分背景,然后,以三维点云输入网络,经过网络计算准确得到手部21个关键点的三维手势关键点坐标。</td>   <td>G06V40/10;G06V10/764;G06V10/26;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;              史正凯;                   王臣       </td>   <td>中山大学</td>   <td>一种基于霍克斯过程和矩阵分解的视频预缓存方法</td>   <td>广东省</td>   <td>CN110889063B</td>   <td>2023-05-02</td>   <td>本发明提供一种基于霍克斯过程和矩阵分解的视频预缓存方法,包括以下步骤：S1.使用击中率表示在一段时间内的所有请求中,被缓存的请求所占的比例并根据击中率模型用适合于点过程的方式,重新数学化定义了击中率；S2.自激霍克斯过程缓存模型根据设备的自身历史记录,预测所有视频的强度并进行排序,缓存一定大小的视频；S3.互激霍克斯过程缓存模型添加邻居历史点击对设备的影响,预测所有视频的强度,提高击中率；S4.矩阵分解降维模型对S3的参数进行分解降维；S5.使用过程优化算法对互激霍克斯过程缓存模型进行优化,对未来的行为强度进行预测。本发明能够有效预测每个设备在未来对于不同视频的观看强度,通过预缓存强度最大的一些视频,能够显著降低未来网络中的流量,提升用户体验。</td>   <td>1.一种基于霍克斯过程和矩阵分解的视频预缓存方法,其特征在于,包括以下步骤：S1.使用击中率表示在一段时间内的所有请求中,被缓存的请求所占的比例并根据击中率模型用适合于点击过程的方式,重新数学化定义了击中率；其中：S11.使用来表示霍克斯过程下的强度,其中u表示缓存设备,i表示视频,t则表示该强度所在的时间；S12.定义击中率为：其中,s-i是缓存视频的大小,B-u为设备u的缓存空间,/&gt;是指示函数,表示t时刻,设备u是否会缓存视频i,指示函数的定义如下：                  S13.击中率模型即目标函数表示为：                  S2.自激霍克斯过程缓存模型根据设备的自身历史记录,预测所有视频的强度并进行排序,缓存一定大小的视频；S3.互激霍克斯过程缓存模型添加邻居历史点击对设备的影响,预测所有视频的强度,提高击中率；S4.矩阵分解降维模型对S3的参数进行分解降维；S5.使用过程优化算法对互激霍克斯过程缓存模型进行优化,对未来的行为强度进行预测；在S2的具体步骤如下：S21.定义ε～T＝{t-1,t-2,…,t-K},表示所有的点击事件的点击时间,记录的时间窗口是[0,T),并且有t-1&lt;t-2&lt;…&lt;t-K,K表示事件总数；S22.定义则                  其中b-(ui)表示当前过程的基准强度或者说迁入强度,即该过程没有历史事件发生时的强度值,φ-(ui)(t-t′)表示互激霍克斯过程的激活函数,即：φ-(ui)(t-t′)＝α-(ui)g(t-t′)    (2-4)α-(ui)＞0表示当前过程会受到历史事件多大程度的影响,对g(t-t′)有：g(t-t′)＝exp(-δ(t-t′))   (2-5)δ＞0是一个超参数,表示激活函数或者说衰减函数的衰减速率,值越大,衰减越快；S23.为了使得上面定义的击中率最大,使用霍克斯过程的优化方法,对每一个过程进行优化,其似然函数定义为：                  有了似然函数之后,对其求导,然后使用梯度下降的方法预估各个参数。</td>   <td>G06F16/957;G06F16/71</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陶涛;              刘冶;              桂进军;              陈宇恒;              潘炎;                   印鉴       </td>   <td>中山大学;广州赫炎大数据科技有限公司</td>   <td>一种游戏平台用户问答业务的短文本分类方法</td>   <td>广东省</td>   <td>CN111104513B</td>   <td>2023-05-02</td>   <td>本发明涉及一种游戏平台用户问答业务的短文本分类方法,对分字与分词的词向量矩阵分别通过两个卷积神经网络模型进行语义提取,拼接两个输出结果,通过算法得到该输入文本属于各类别的概率,并选择概率最大的一个类别作为最后输出；本申请能够充分挖掘出中文短文本所包含的语义信息,有效地处理游戏平台用户问答业务中特征较少的短文本类型的数据,在短文本分类任务识别效果更好,效率也有很大的提升。</td>   <td>1.一种游戏平台用户问答业务的短文本分类方法,其特征在于,包括以下步骤：获取用户的输入文本,对所述输入文本分别进行分词和分字处理,得到分词词语和分字词语；运用基于分词的词向量模型获得所述分词词语的词向量,对所述分词词语的词向量进行拼接得到第一词向量矩阵,运用基于分词的卷积神经网络模型对所述第一词向量矩阵进行语义提取；其中,所述基于分词的词向量模型及卷积神经网络模型的训练样本源于经过分词处理的语料文本；运用基于分字的词向量模型获得所述分字词语的词向量,对所述分字词语的词向量进行拼接得到第二词向量矩阵,运用基于分字的卷积神经网络模型对所述第二词向量矩阵进行语义提取；其中,所述基于分字的词向量模型及卷积神经网络模型的训练样本源于经过分字处理的语料文本；对所述第一词向量矩阵及第二词向量矩阵的语义提取结果进行拼接,对拼接后的语义提取结果进行归一化处理以获取概率最大的分类类别；所述基于分词的卷积神经网络模型及基于分字的卷积神经网络模型中的每个卷积层都包括一组尺寸为h×n的卷积核；其中,卷积核高度h可变,1≤h≤m,m为词向量矩阵高度,n为词向量维度；根据每一个卷积核kernel,输入词向量矩阵W,卷积层一行输出y-i,按以下方式运算得到点积的值y-(ij)：y-(ij)＝f(kernel·[v-j,v-(j+h-1)]+b)；其中,b是偏置项,v是词向量,[v-j,v-(j+h-1)]表示词向量矩阵W中尺寸为h×n的子矩阵,由词向量矩阵W中j行到j+h-1行的词向量v构成,1≤j≤m；卷积核kernel从上至下与尺寸为h×n的子矩阵做点积,拼接所有点积的值y-(ij)得到一行的输出y-i；所述对拼接后的语义提取结果进行归一化处理以获取概率最大的分类类别,包括按以下方式运算得到各个分类类别的结果p-i：                  其中,i为一个分类类别,p-i为分类类别i的概率,z为全连接层的输出向量,其下标为向量对应位置的数值,k为所有分类类别的总数,各个分类类别的概率p-i相加和为1。</td>   <td>G06F16/35;G06F40/289;G06F18/2415;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              张桔;                   吴嘉婧       </td>   <td>中山大学</td>   <td>一种针对跨版本软件缺陷预测的数据噪声处理方法</td>   <td>广东省</td>   <td>CN111367808B</td>   <td>2023-05-02</td>   <td>本发明公开一种针对跨版本软件缺陷预测的数据噪声处理方法,包括通过余弦相似度计算数据集中样本件的相似性；基于样本件的相似性归类数据集中簇集合C；从簇集合C中对每簇判断其内部样本标签是否一致；若不一致,则提取簇集合C的样本容量；根据簇集合C的样本容量情况分别确定簇的本簇标签；采用本簇标签对样本的噪声重标记。本发明有效地解决软件缺陷预测中的数据降噪问题。</td>   <td>1.一种针对跨版本软件缺陷预测的数据噪声处理方法,其特征在于,包括如下步骤：S10通过余弦相似度计算数据集中样本件的相似性；S20基于样本件的相似性归类数据集中簇集合C；具体为：S201定义C＝Φ表示样本簇的集合,初始为空集；V＝Φ表示已被访问过的样本集合,初始为空集；参数相似性阈值为α；S202依次遍历数据集X中的每一个样本,对于任一样本x-i,若它已在集合V中则直接跳过；否则从该样本出发搜索其所在的簇c-i,将簇c-i加入到集合C中,并将c-i包含的所有样本都加入到V中,再接着遍历下一样本,直至所有样本都被遍历完；所述从该样本出发搜索其所在的簇c-i采用广度优先的方法,具体为：初始化c-i＝Φ,通过相似性矩阵S找出所有与x-i相似性大于阈值α的样本,称为x-i的一阶邻居N-1(x-i),即s-(i,j)＞α,将一阶邻居N-1(x-i)中所有样本都加入到c-i中；在数据集剩余样本中找出满足与N-1(x-i)中有至少一个样本的相似度大于α的样本,称为x-i的二阶邻居N-2(x-i),即/&gt;s-(j,k)＞α且N-1(x-i)∩N-2(x-i)＝Φ,将二阶邻居N-2(x-i)中所有样本都加入到c-i中；以此类推,直到不能再找到下一阶邻居,通过此过程得到的簇c-i中,对于任意一个样本,都能在簇中至少能找到另一个样本与其特征相似度大于α；S30从簇集合C中对每簇判断其内部样本标签是否一致；S40若不一致,则提取簇集合C的样本容量；S50根据簇集合C的样本容量情况分别确定簇的本簇标签；S60采用本簇标签对样本的噪声重标记；所述S10之前还包括：S01从与软件仓库中收集获得由软件模块特征及缺陷标签构成的数据集。</td>   <td>G06F11/36;G06F18/22;G06F18/214;G06F18/241;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         段凯;              陈晓宏;              刘丙军;                   赵铜铁钢       </td>   <td>中山大学</td>   <td>二元水权核算交易方法及系统</td>   <td>广东省</td>   <td>CN111709618B</td>   <td>2023-05-02</td>   <td>本发明提供的一种二元水权核算交易方法及系统,通过构建区域水资源与水环境模拟模型,建立了河道外取水总量控制与河道内排污总量控制之间的动态函数关系,创新性地将区域水量水质模拟纳入水权价值的核算中,能够通过辨识人类取水排污过程对区域水资源可利用量和水环境质量的影响,反映一定来水条件和水质管理目标下可分配取水量与排污量的转换关系,为科学衡量取水权与排污权交易价值、实现取水总量与排污总量的协同管控提供一种简单有效的解决办法。</td>   <td>1.二元水权核算交易方法,其特征在于,包括以下步骤：S1：获取调查区域内的水功能区划、行政区划及流域水系分布,建立区域水资源系统的取水排污概化模型；取水排污概化模型由若干个取水排污单元组成,在自然的水量水质平衡方程中加入取水与排污两种影响因子,依据物质守恒和污染物质迁移转化的基本原理对取水量与排污量的量化关系进行研究,具体设：上游进入取水排污单元的水量及其污染物浓度为R-i和C-i；取水排污单元内的本地自产水量及其污染物浓度为R-p和C-p；取水排污单元内的取水量及取水水质浓度为q-w,C-w,取水量包括农业、工业、生活用水及河道外生态用水；时段内取水排污单元的排污量及其平均浓度R-e,C-e,主要包括通过管网集中排放的城市生活污水与工业废水；下游流出取水排污单元的水量及其平均污染物浓度R-o、C-o,至此,完成取水排污概化模型的建立；S2：获取调查区域内水文气象条件、水资源可利用量、水资源开发利用现状与水环境现状,针对调查区域的主要流量与水质控制断面,建立水量平衡方程与污染物平衡方程；水量平衡方程包括自然水量平衡方程和人工水量平衡方程,具体表示为：自然水量平衡方程：R-i+R-p＝R-o+ΔR  (1)人工水量平衡方程：R-e＝q-w-q-c  (2)其中,ΔR为槽蓄变化量及各种自然损失,q-c为耗水量；假设取水排污概化模型水质的变化是稳定的,在确定了边界条件后即可得到相应的稳态模型；综合考虑到污染物迁移转化过程中的各个源汇项及物质守衡的基本原理,取水排污单元内的污染物平衡方程为：R-iC-i+R-pC-p+R-eC-e＝q-wC-w+R-oC-o+KR-oC-o  (3)式中K为系统内污染物综合降解系数；S3：获取并测算调查区域内耗水率、排污系数、污染物降解系数特征值,得到综合排污系数；S4：结合调查区域的污水排放标准与水环境质量标准,计算现状取水、排污条件下的可分配新增取水量与最大取水总量；当取水排污单元内取水量增大后,污染物守衡方程为：R-iC-i+R-pC-p+α(q-w+Δq)C-e＝(q-w+Δq)C-w+(1+K)[R-o-(1-α)Δq]C-o (4)式中Δq为系统取水增量,当径流量远大于取水量时R-o的变化量(1-α)Δq项可忽略；当满足C-w＜αC-e时,取水量的增大会引起C-o相应的增大；令：A＝q-wC-w+(1+K)R-oC-o-R-iC-i-R-pC-p  (5)若令输出水的水质目标为C-o≤C-t,A-t＝q-wC-w+(1+K)R-oC-t-R-iC-i-R-pC-p  (6)则得到：                  相应的现状综合排污系数之下的最大可取水量即为：q-(max)＝q-w+Δq-(max)  (8)另外,按取水排污单元输出水量的一定比例考虑河道内生态需水量,即河道内生态需水取为：R-s＝ηR-o  (9)因此,考虑生态约束与水质约束的最大取水量应为：q-(max)＝min{(1-η)R-o,q-w+Δq-(max)}  (10)至此,完成现状取水、排污条件下的可分配新增取水量与最大取水总量的计算；S5：建立在一定来水条件与水质控制目标下新增/削减取水量与削减/新增排污量的函数关系,核算用水户进行取水权与排污权交易的价值标准与调控范围。</td>   <td>G06Q10/0631;G06Q40/04;G06Q50/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   马亮亮       </td>   <td>中山大学</td>   <td>一种基于云数据中心分布式诗歌生成方法</td>   <td>广东省</td>   <td>CN112989812B</td>   <td>2023-05-02</td>   <td>本发明提供一种基于云数据中心分布式诗歌生成方法,该方法首先生成模型训练；然后引入评价模型,利用评价模型来对生成模型进行优化；最后利用步骤优化后的生成模型进行诗歌生成。本发明使用评价模型对艺术作品中词向量的发展进行学习,可以间接达到模拟内涵的效果,再应用到诗歌生成中,就可以生成创新且富有内涵的诗歌；而之前的强化学习方法,利用的大量的专家知识和人工限定,导致了诗歌生成依赖人的水平,很难以实现完全自动化；本发明的全部设计理念不包含诗歌知识,实现了自动化；而且本文对比之前的方法,两个阶段均采用了基于云数据中心的并行架构,可以加速神经网络收敛,提高模型训练效率。</td>   <td>1.一种基于云数据中心分布式诗歌生成方法,其特征在于,包括以下步骤：S1：生成模型训练；S2：引入评价模型,利用评价模型来对步骤S1中的生成模型进行优化；S3：利用步骤S2中优化后的生成模型进行诗歌生成；所述步骤S1的具体过程是：1)、预先训练好的一个词嵌入模型,将训练集中每首诗的每个字映射到一个浮点向量,对该词嵌入模型训练时,维护一个以训练数据中的一首诗的标题初始化的集合,作为模型的输入,模型先以此将标题的每个字映射为向量然后输入长短期记忆神经网络中,最后输出是一个向量,它表示生成的诗歌的第一个单词,这个向量和本轮训练用的诗中第一个字映射的词向量进行比较,用来计算训练损失；2)、训练用的诗的第一个字被添加到词嵌入模型维护的输入集合中,以生成下一个单词；训练过程一直在进行,直到一整首训练用的诗被添加到输入集中,然后继续训练下一首诗,直至达到使用者满意的收敛程度,即训练误差降低到一定范围以下；所述步骤S2中,生成模型的优化过程是：设置一个估值网络,一个经验缓冲区以及并行多个表演者网络,每轮训练学习者先同步自己的生成模型参数到每一个表演者网络、同步自己的估值网络参数到经验缓冲区；然后每个表演者网络各自开始随机初始化题目然后生成诗歌,每生成一句诗就会与评价模型进行交流,评价模型会输出一个负数的奖励,然后生成模型将此时的生成诗、字选择信息、奖励值打包送给经验缓冲区；缓冲区对经验排序,最大者优先传输给学习者进行对生成模型的优化；缓冲区对经验排序的过程是：经验缓冲区对(R-V-θ(s))-+的值从大到小排序,其中R表示奖励值加上用生成诗输入估值网络的输出,V-θ(s)表示生成此字之前的诗输入估值网络输出,+表示取与0的最大值；学习者中生成模型的损失函数使用近端策略优化损失,估值网络使用(R-V-θ(s))-+对网络进行梯度下降。</td>   <td>G06F40/279;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              徐枫;              杨雅涵;              汪瑞昕;                   吕军锋       </td>   <td>中山大学中山眼科中心;清华大学</td>   <td>一种保护眼科患者隐私的方法、装置及存储介质</td>   <td>广东省</td>   <td>CN113887311B</td>   <td>2023-05-02</td>   <td>本发明公开了一种保护眼科患者隐私的方法、装置及存储介质,其中方法包括：采集眼科患者的检查视频；提取检查视频中每一帧图像的图像特征,根据图像特征中的器官位置信息对每一帧图像进行区域划分,并根据区域划分结果得到待精密重建区域和待弱化重建区域；对待精密重建区域和待弱化重建区域进行三维重建,得到每一帧图像对应的三维重建数据；将所有三维重建数据渲染成三维重建视频。本发明根据该位置信息将每一帧图像都划分为多个图像区域,在图像区域中得到待精密重建区域和待弱化重建区域已进行三维重建,能够在保留眼科患者大部分病例特征的同时,掩盖眼科患者的大部分身份特征,从而能够在不影响医生诊断的前提下保护眼科患者的隐私。</td>   <td>1.一种保护眼科患者隐私的方法,其特征在于,包括：采集眼科患者的检查视频；提取所述检查视频中每一帧图像的图像特征,根据所述图像特征中的器官位置信息对每一帧所述图像进行区域划分,并根据区域划分结果得到待精密重建区域和待弱化重建区域；所述根据所述图像特征中的器官位置信息对每一帧所述图像进行区域划分,并根据区域划分结果得到待精密重建区域和待弱化重建区域包括：根据所述图像特征中的器官位置信息将每一帧图像划分为多个图像区域,结合眼科患者所患疾病所需的病例特征,在所述图像区域中得到待精密重建区域和待弱化重建区域；对所述待精密重建区域和所述待弱化重建区域进行三维重建,得到每一帧所述图像对应的三维重建数据；将所有所述三维重建数据渲染成三维重建视频。</td>   <td>G06V20/40;G06V10/44;G06T7/11;G06T15/00;G06T17/00;G06V10/82;G06N3/04;G06N3/08;G16H10/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;                   林军       </td>   <td>中山大学</td>   <td>医疗机器人控制软件测试数据的生成方法、注入方法</td>   <td>广东省</td>   <td>CN116048958A</td>   <td>2023-05-02</td>   <td>本发明提供了一种医疗机器人控制软件测试数据的生成方法、注入方法,生成方法包括步骤：S1、生成被测软件的CFG控制图；S2、计算CFG控制图内的有限路径数量；S3、以有限路径数量作为SUT的输入参数,进行总群的初始化；S4、若不存在未被覆盖的路径或者运行代数最大时,得到最佳染色体；S5、若存在未被覆盖的路径或者运行代数最大时,进行个体评价；S6、对染色体进行交叉操作和变异操作；S7、计算染色体的适应度值；S8、若适应度值不符合要求,则选择下一代个体,运行代数增加,并返回至步骤S4。采用本发明的方法能以更少的评估量提供更好的覆盖范围。</td>   <td>1.一种医疗机器人控制软件测试数据的生成方法,其特征在于,包括步骤：S1、生成被测软件的CFG控制图；S2、计算CFG控制图内的有限路径数量；S3、以有限路径数量作为SUT的输入参数,进行总群的初始化；S4、若不存在未被覆盖的路径或者运行代数最大时,得到最佳染色体；S5、若存在未被覆盖的路径或者运行代数最大时,进行个体评价；S6、对染色体进行交叉操作和变异操作；S7、计算染色体的适应度值；S8、若适应度值不符合要求,则选择下一代个体,运行代数增加,并返回至步骤S4。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄海东;              王黎明;              付饶;              张涛;                   赵子曰       </td>   <td>国网江苏省电力有限公司;中山大学</td>   <td>一种可信平台模块调用方法、系统、装置及存储介质</td>   <td>江苏省</td>   <td>CN116049844A</td>   <td>2023-05-02</td>   <td>本发明公开了一种可信平台模块调用方法、系统、装置及存储介质,方法包括：采用CAmkES框架实现seL4系统组件及TPM Proxy组件；根据seL4系统组件通过Linux虚拟机实现seL4微内核操作系统；基于嵌入式系统部署seL4微内核操作系统；当嵌入式系统需要升级时,通过seL4微内核操作系统执行可信升级；当嵌入式系统正常运行时,通过Linux虚拟机获取TPM调用请求,并通过TPM Proxy组件返回TPM调用结果。本发明可以为无法集成硬件TPM的嵌入式系统提供软TPM可信升级服务和TPM调用服务,提高了嵌入式系统的可信计算能力,可广泛应用于可信计算技术领域。</td>   <td>1.一种可信平台模块调用方法,其特征在于,包括以下步骤：采用CAmkES框架实现seL4系统组件及TPM Proxy组件,所述seL4系统组件包括软TPM组件、软TPM可信管理组件以及VMM组件；根据所述seL4系统组件通过Linux虚拟机实现seL4微内核操作系统；基于嵌入式系统部署所述seL4微内核操作系统；当所述嵌入式系统需要升级时,通过所述seL4微内核操作系统执行可信升级；当所述嵌入式系统正常运行时,通过所述Linux虚拟机获取TPM调用请求,并通过所述TPM Proxy组件返回TPM调用结果。</td>   <td>G06F21/60;G06F21/51;G06F8/65;G06F8/71;G06F9/445</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周雪雯;              辛秦川;              戴永久;                   吴伟       </td>   <td>中山大学</td>   <td>一种叶面积指数预测方法</td>   <td>广东省</td>   <td>CN116050047A</td>   <td>2023-05-02</td>   <td>本申请提出一种叶面积指数预测方法,该方法包括利用GSI模型计算植被的生长季节长度,基于气象变量求解年总叶面积指数,根据年总叶面积指数和植被生长季节长度预测季节性日最大叶面积指数LAI-(SM),模拟单日的稳态叶面积指数LAI-s,满足LAI-s≤LAI-(SM),基于LAI-s使用限制性生长过程模型预测叶面积指数时间序列LAI-(TS),本申请的方法通过预测的LAI-(SM)约束待模拟的LAI时间序列,其中LAI-(SM)的预测仅用到气象变量,能够预测未来气候变化下的植被物候,进而评价和分析局部到全球尺度下叶面积指数相关指标的时空分布；本发明提出的预测方法能够嵌入到现有的陆面模型中,更稳健而准确地预测全球各生物群落的叶面积指数LAI的动态变化。</td>   <td>1.一种叶面积指数预测方法,其特征在于,包括：利用GSI模型计算植被的生长季节长度；基于气象变量求解年总叶面积指数；根据年总叶面积指数和植被生长季节长度预测LAI-(SM),LAI-(SM)表示季节性最大日叶面积指数；模拟单日的稳态叶面积指数LAI-s,满足LAI-s≤LAI-(SM)；基于LAI-s,使用限制性生长过程模型预测叶面积指数时间序列LAI-(TS)。</td>   <td>G06F30/20;G06F17/18;G06F17/12;G06Q50/02;G06F111/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨戈平;                   陈翔       </td>   <td>中山大学</td>   <td>一种基于二元表示的正负图分割多视图聚类方法</td>   <td>广东省</td>   <td>CN116050119A</td>   <td>2023-05-02</td>   <td>本发明公开了一种基于二元表示的正负图分割多视图聚类方法,该方法包括：获取待聚类的多视图数据；通过核函数对待聚类的多视图数据进行生成处理,得到多视图数据的非线性表示；基于多视图数据的非线性表示构建二元表示的正负图分割多视图聚类的目标函数；对目标函数进行迭代更新处理,直至所述目标函数满足预设条件,输出聚类结果,所述聚类结果为目标函数中的指示矩阵。通过使用本发明,能够解决现存二元表示多视图聚类方法不能划分非线性二元表示和多视图图切割聚类方法中图包含的信息不充分的问题。本发明作为一种基于二元表示的正负图分割多视图聚类方法,可广泛应用于数据挖掘技术领域。</td>   <td>1.一种基于二元表示的正负图分割多视图聚类方法,其特征在于,包括以下步骤：获取待聚类的多视图数据；通过核函数对待聚类的多视图数据进行生成处理,得到多视图数据的非线性表示；基于多视图数据的非线性表示构建二元表示的正负图分割多视图聚类的目标函数,所述目标函数包括二元表示学习,投影矩阵正则化和正负图分割；对目标函数进行迭代更新处理,直至所述目标函数满足预设条件,输出聚类结果,所述聚类结果为目标函数中的指示矩阵。</td>   <td>G06F30/20;G06T7/10;G06V10/762;G06F111/04;G06F111/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨智勇;              陈俊先;                   尹城川       </td>   <td>中山大学</td>   <td>一种基于顺序钻孔的三维大尺度随机场模拟方法</td>   <td>广东省</td>   <td>CN116050128A</td>   <td>2023-05-02</td>   <td>本发明公开了一种基于顺序钻孔的三维大尺度随机场模拟方法,包括以下步骤：S1、确定待模拟岩土体参数的种类以及统计特征；S2、确定待模拟场地的维度和几何尺寸；S3、确定网格单元尺寸,将模拟区域网格单元化；S4、确定观测数据在模拟区域的具体位置,确定勘探钻孔处观测数据与未观测数据的相关性,确定勘探钻孔位置的数据与模拟区域非勘探位置处数据的相关矩阵；S5、采用吉布斯采样依次模拟每个勘探钻孔内未观测到的数据；S6、根据完备的钻孔模拟其它未勘探区域的岩土体参数的数据。本发明方法能够避免三维随机场模拟过程中的超大矩阵运算问题,有效提高矩阵运算过程中的效率,在处理多变量不完整钻孔数据的问题上具有显著优势。</td>   <td>1.一种基于顺序钻孔的三维大尺度随机场模拟方法,其特征在于,包括以下步骤：S1、确定待模拟岩土体参数的种类以及统计特征；S2、确定待模拟场地的维度和几何尺寸；S3、确定网格单元尺寸,将模拟区域网格单元化；S4、根据实际勘探钻孔位置及模拟区域的网格坐标,确定观测数据在模拟区域的具体位置,确定勘探钻孔处观测数据与未观测数据的相关性,确定勘探钻孔位置的数据与模拟区域非勘探位置处数据的相关矩阵；S5、采用吉布斯采样依次模拟每个勘探钻孔内未观测到的数据,使钻孔内的岩土体参数数据完备,得到规律分布的勘探钻孔数据；S6、根据完备的钻孔模拟其它未勘探区域的岩土体参数的数据。</td>   <td>G06F30/20;G06T17/10;G06T17/20;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱祥维;              李婉清;              宋江波;                   李杜       </td>   <td>中山大学</td>   <td>基于时域有限差分法的芯片型接收天线仿真方法及装置</td>   <td>广东省</td>   <td>CN116050224A</td>   <td>2023-05-02</td>   <td>本发明公开了基于时域有限差分法的芯片型接收天线仿真方法及装置,其中方法包括：根据接收天线的电磁场、应力场和声场建立多物理场耦合的微分方程组并转化为基于时域有限差分法的求解方程组；建立接收天线的几何结构模型,设置仿真所需的模型参数,模型参数至少包括接收天线的几何参数、材料参数、网格参数和磁感应激励源的激励频率；根据模型参数迭代计算求解方程组直至预设仿真时长,得到基于声波激励的仿真结果；根据仿真结果得到接收天线的仿真谐振频率,调整几何参数和材料参数使仿真谐振频率等于激励频率,将几何参数作为最优几何参数、材料参数作为最优材料参数。本发明能够解决多物理场问题,效率更高且占用更少存储资源。</td>   <td>1.基于时域有限差分法的芯片型接收天线仿真方法,其特征在于,包括：根据接收天线的电磁场、应力场和声场建立多物理场耦合的微分方程组,将所述微分方程组转化为基于时域有限差分法的求解方程组；建立所述接收天线的几何结构模型,在所述几何结构模型中设置仿真所需的模型参数,所述模型参数至少包括所述接收天线的几何参数、材料参数、网格参数和磁感应激励源的激励频率,所述网格参数与所述接收天线所使用材料的内部体声波相关；根据所述模型参数迭代计算所述求解方程组直至预设仿真时长,得到基于声波激励的所述接收天线的仿真结果；根据所述仿真结果计算得到所述接收天线的仿真谐振频率,在所述几何结构模型中调整所述几何参数和所述材料参数使所述仿真谐振频率等于所述激励频率,将所述几何参数作为最优几何参数、所述材料参数作为最优材料参数。</td>   <td>G06F30/23;G06F17/13;G06F119/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蒋格格;              张欣;              范庆雯;              庞爱彤;                   刘轶君       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于联邦学习的网约车聚合平台信息处理方法、装置和介质</td>   <td>广东省</td>   <td>CN116051235A</td>   <td>2023-05-02</td>   <td>本发明公开了一种基于联邦学习的网约车聚合平台信息处理方法、计算机装置及存储介质,包括将订单数据分发至各网约车公司端,各网约车公司端对各自的第一人工智能模型进行联邦学习,各网约车公司端分别使用各自的第一人工智能模型对订单数据进行处理,获得各自对应的匹配结果等步骤。本发明利用纵向联邦学习实现聚合平台、网约车公司之间的司乘匹配；网约车公司相当于联邦学习中的节点,聚合平台则相当于中心服务器,在利用联邦学习的过程中,除订单匹配外,网约车公司的乘客和司机信息存储在本地,无需上传至聚合平台,而在订单匹配过程中容易将传输的信息进行加密保护,从而实现网约车过程多方位的隐私保护。本发明广泛应用于信息安全技术领域。</td>   <td>1.一种基于联邦学习的网约车聚合平台信息处理方法,其特征在于,所述基于联邦学习的网约车聚合平台信息处理方法包括：获取乘客端发送的订单数据；将所述订单数据分发至各网约车公司端；各所述网约车公司端分别运行各自的第一人工智能模型,至少一部分所述网约车公司端存储乘客数据和司机数据；触发各所述网约车公司端对各自的所述第一人工智能模型进行联邦学习；触发各所述网约车公司端,分别使用各自的所述第一人工智能模型对所述订单数据进行处理,获得各自对应的匹配结果；所述匹配结果用于表示所述订单数据对应的乘客数据,与相应的司机数据之间的匹配关系。</td>   <td>G06Q30/0601;G06N20/20;G06F18/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾俊波;              张梓睿;              蔡跃新;                   陈俊周       </td>   <td>中山大学孙逸仙纪念医院;中山大学</td>   <td>基于颞骨高分辨CT中的病变特征构建耳科疾病分类系统</td>   <td>广东省</td>   <td>CN116051898A</td>   <td>2023-05-02</td>   <td>本发明公开了基于颞骨高分辨CT中的病变特征构建耳科疾病分类系统,其特征在于,包括以下步骤：对颞骨病变进行标注,根据病变特征库及便签构建疾病分类系统,转换数据集格式并划分训练集与测试集,记载模型预训练权重并设置超参数,加载分类数据及并进行数据增强,模型推理获得分类结果并计算训练损失,将训练损失进行反向传播并进行迭代,判断是否收敛,如未收敛则重复进行计算；如已收敛,则将模型在测试集推理并验证病变分类结果,最后由专业医生评估分类结果并应用于临床诊断。本发明基于识别颞骨高分辨CT中的多种耳科疾病特征后,再进一步构建耳科疾病的分类系统,是基于强监督学习的临床解释性强的分类系统,有效提高临床诊断效率。</td>   <td>1.基于颞骨高分辨CT中的病变特征构建耳科疾病分类系统,其特征在于：包括以下步骤：步骤S201：由临床医师团队进行使用标注软件、颞骨高分辨CT的影像学病变特征、及特征标注标准的培训,颞骨高分辨CT标注内容包括疾病名以及每种疾病在颞骨高分辨CT中所包含的病变特征,进而构建颞骨高分辨CT的影像学病变特征库；步骤S202：根据颞骨高分辨CT的影像学病变特征库及疾病名标签,基于颞骨高分辨CT的影像学病变特征构建耳科疾病的分类数据集；步骤S203：对已构建的基于颞骨高分辨CT的影像学病变分类数据集,根据病变类别进行分类数据集格式的转换,以7：3的比例划分训练集和测试集中的图像和标签文件,即70%的图像用作神经网络模型训练,30%的图像用作神经网络模型效果验证和评估；步骤S204：加载基于神经网络的分类模型预训练权重,并设置超参数,包括学习率、批数据大小、输入图片大小、权重衰减和随机种子参数；步骤S205：加载划分好的基于颞骨高分辨CT的影像学病变分类数据集,并对数据集进行一定程度的数据增强,包括随机裁剪、上下翻转与左右翻转等策略,加快模型收敛,提高模型的鲁棒性和泛化能力；步骤S206：将已加载的数据输入到已加载的基于神经网络的颞骨高分辨CT影像学病变分类模型中；颞骨高分辨CT影像学病变分类属于二分类问题,模型推理得到分类结果x=[x-1,x-2],其中x-1为CT正常的预测分数,x-2为CT异常的预测分数；该CT图像的标签为y=Y,Y∈(0,1),将标签转换为热编码形式,即y=[y-1,y-2]；将模型推理的分类结果x和y输入到交叉熵损失函数中,计算训练损失,计算公式为loss=-(y-1logx-1+y-2logx-2)；步骤S207：将步骤S206计算得到的训练损失通过反向传播,得到模型各权重的优化梯度,进而优化模型参数；步骤S208：判断模型是否收敛,若收敛到近似全局最优则保存模型,进入步骤S209,若没有收敛,则返回步骤S206,模型进行迭代与优化；步骤S209：对已训练保存的神经网络分类模型,在划分好的基于颞骨高分辨CT的影像学病变分类测试集上进行推理,输出对病变的分类结果,并进行可视化验证；步骤S2010：由专业临床医师团队对输出的病变分类结果进行评估,验证模型的准确率和泛化能力,进一步将基于神经网络的颞骨高分辨CT影像学病变分类模型应用于病变临床诊断。</td>   <td>G06V10/764;G06V10/80;G06V10/82;G06V10/778;G06V10/776;G06V10/774;G06N3/084;G16H30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘文阁;              程轶;              刘亚飞;              蔡庆玲;              梁小丹;              郑冶枫;                   王巨宏       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>疾病预测方法、装置、设备及存储介质</td>   <td>广东省</td>   <td>CN116052867A</td>   <td>2023-05-02</td>   <td>本申请提供了一种疾病预测方法、装置、设备及存储介质,该方法包括：获取患者的当前症状；确定至少一个第一历史症状,第一历史症状是与当前症状相似的历史症状；根据至少一个第一历史症状确定当前症状对应的第一疾病概率分布；根据第一疾病概率分布预测患者所得的疾病,从而可以提高疾病预测的准确度。</td>   <td>1.一种疾病预测方法,其特征在于,包括：获取患者的当前症状；确定至少一个第一历史症状,所述第一历史症状是与所述当前症状相似的历史症状；根据所述至少一个第一历史症状确定所述当前症状对应的第一疾病概率分布；根据所述第一疾病概率分布预测所述患者所得的疾病。</td>   <td>G16H50/20;G16H50/70;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭雪梅;              张千瑶;                   王国利       </td>   <td>中山大学</td>   <td>一种医学图像任意倍数放大的超分辨处理方法</td>   <td>广东省</td>   <td>CN110866870B</td>   <td>2023-04-28</td>   <td>本发明提供一种医学图像任意倍数放大的超分辨处理方法,该方法采用了梯度算子和形态学操作来检测组织区域,梯度算子可以检测出灰度值变化较大的位置,而形态学中的开操作可以去除细小的连接和孤立点,减小噪声和气泡的影响,膨胀操作会粗化物体。此方法提高了组织区域检测的速度,实现了快速定位,同时保证了检测的精度。</td>   <td>1.一种医学图像任意倍数放大的超分辨处理方法,其特征在于,包括：图像的预处理：预读取WSI图像第6层的信息,应用梯度算子、形态学操作算法检测出组织区域；将第6层检测出的组织区域映射到分辨率最高的第0层,在第0层的组织区域内使用滑动窗口进行图像块的提取,然后判断图像块是否包含组织区域来区分有信息的图像块和无信息的图像块；图像块的任意倍数放大：超分辨处理主要包括特征学习和元放大两个部分,其中特征学习主要是利用卷积神经网络和残差密集块对低分辨率图像进行特征提取,元放大部分是对提取到的特征相乘得到高分辨率图像；所述WSI图像预处理具体包括：组织区域检测：在WSI图像第6层读取图像,然后使用梯度算子、形态学操作检测出组织区域；图像块提取：将第6层的组织区域范围映射到分辨率最高的第0层,在对应区域内提取图像块,并判断图像块是否包含组织区域；其中,梯度算子为Sobel算子,形态学操作为开操作、腐蚀、膨胀,层间映射为不同层使用倍数处理的方法,图像块提取为非重叠连续提取；所述组织区域检测步骤具体包括：1)、加载所述WSI图像第6层的分辨率信息,将RGB图转换为灰度图；2)、在灰度图上使用Sobel算子计算x、y方向的梯度,用x方向的梯度减去y方向梯度,将数据转换到[0,255]范围作为最终的梯度；3)、使用9*9的均值滤波对梯度图像进行模糊,减小噪声的影响；4)、对梯度图像进行阈值处理,得到二值图,然后使用开操作去除细小的连接和孤立点、膨胀进行物体粗化；求解包含目标区域的最小矩形,作为组织区域的最终范围。</td>   <td>G06T3/40;G06N3/0464;G16H30/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   刘子璐       </td>   <td>中山大学</td>   <td>一种基于多类型特征深度学习的信息流推荐方法</td>   <td>广东省</td>   <td>CN111125530B</td>   <td>2023-04-28</td>   <td>本发明公开一种基于多类型特征深度学习的信息流推荐方法,包括：采集信息流场景数据并解析获取其中用户特征数据、文本特征数据和用户点击文本数据作为特征样本数据；根据特征样本数据数值的离散性预处理得到相应的离散特征,根据特征样本数据数值的连续性预处理得到相应的连续特征,对离散特征进行特征工程以得到交叉离散特征；将离散特征、连续特征、交叉离散特征输入深度学习模型训练学习,以挖掘用户喜好特征向量,并通对用户喜好特征向量进行非线性激活以获得用户点击文章的预测结果。本发明兼容信息流场景数据中多种类型特征,构建模型学习用户喜好,得到更为准确的用户点击行为的预测。</td>   <td>1.一种基于多类型特征深度学习的信息流推荐方法,其特征在于,包括：S10采集信息流场景数据并解析获取其中用户特征数据、文本特征数据和用户点击文本数据作为特征样本数据；S20根据特征样本数据数值的离散性预处理得到相应的离散特征,根据特征样本数据数值的连续性预处理得到相应的连续特征,对离散特征进行特征工程以得到交叉离散特征；S30将离散特征、连续特征、交叉离散特征输入深度学习模型训练学习,以挖掘用户喜好特征向量,并通对用户喜好特征向量进行非线性激活以获得用户点击文章的预测结果；S40将用户点击文章的预测结果进行排序,推荐具有最优预测结果的用户点击文章；所述深度学习模型包括：输入层,用于将离散特征、连续特征和交叉离散特征向量化得离散向量、交叉离散向量和连续向量；嵌入层Embedding,用于对离散向量和交叉离散向量进行高维向量表征得到相应的高维离散向量和高维交叉离散向量；及复制离散向量、交叉离散向量输入因子分解FM模块,复制交叉离散向量和连续向量输入神经网络Deep模块；因子分解FM模块,用于学习不同的高维离散向量之间的及高维交叉离散向量间的表示用户喜好的FM特征向量；神经网络Deep模块,用于挖掘高维交叉离散向量与连续向量间的表示用户喜好的Deep特征向量；拼接层,用于拼接FM特征向量和Deep特征向量得到用户喜好特征,并将其输入全连接输出层；全连接输出层,用于将所得到的用户喜好特征通过非线性激活得到用户点击文章的概率值；所述因子分解FM模块包括：FM线性模块,用于采用线性回归算法,先假定离散特征与最终预测结果之间是线性相关,定义每个离散特征的权重参数为w-(1i),每个离散特征对应的特征值为x-(1i),共有N个离散特征,构建重要度模型以得到每个离散特征对预测结果,其中重要度模型计算公式如下：                  FM二阶交叉计算模块,用于交叉离散向量进行两两交叉学习,以得到交叉离散特征两两之间的关联特征,定义两个输入的交叉离散向量分别为x-(2a)和x-(2b),每个两两的交叉离散向量的权重参数w-(2ab),共有n个交叉离散向量,构建FM二阶学习模型以得到交叉离散特征两两之间的关联特征,FM二阶学习模型的计算公式如下：</td>   <td>G06F16/9535;G06F16/9538;G06N3/048;G06N3/047;G06N3/082;G06F18/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>              夏俐       </td>   <td>中山大学</td>   <td>一种中文作文自动评分方法及教辅系统</td>   <td>广东省</td>   <td>CN110851599B</td>   <td>2023-04-28</td>   <td>本发明提出一种中文作文自动评分方法及教辅系统。该方法包括：待评分作文获取步骤；浅层特征提取步骤,用于提取待评分作文的浅层特征；深层语义特征提取步骤,用于提取待评分作文的深层语义特征,包括错别字特征和语法错误特征；评分步骤,用于将提取的浅层特征、深层语义特征结合并采用随机森林拟合,得到待评分作文的评分结果；还包括拼音转换步骤和主题提取步骤。本发明将作文的浅层特征、深层语义特征相结合,具有很高的评分准确率,且在小样本上训练取得理想的评估结果,有效提高了样本的利用率；同时增加了错别字识别及纠正、拼音识别及转换、语法错误识别及纠正等功能,提供多维信息作为用户写作的反馈辅导,增强用户体验。</td>   <td>1.一种中文作文自动评分系统的构建方法,其特征在于：该方法包括以下步骤：语料库构建步骤,用于构建中文作文语料库；浅层特征提取步骤,基于语料库提取作文的浅层特征；深层语义特征提取步骤,基于语料库提取作文的深层语义特征,包括错别字特征和语法错误特征；其中,提取错别字特征具体包括：采用概率分词模型对作文进行分词；根据分词结果,将作文文本与错别字识别语料库进行对比,得到可疑词集合；将可疑词集合与错别字纠正语料库进行对比,得到候选词集合；对候选词集合计算语义混淆度,取混淆度最小的词语作为错别字纠正结果；提取语法错误特征具体包括：利用语料库训练词向量,将词向量输入Bi－LSTM神经网络模型,训练得到标注序列,即为语法错误结果；回归步骤,用于将提取的浅层特征、深层语义特征结合并采用随机森林拟合,得到作文的评分结果。</td>   <td>G06F16/35;G06F40/232;G06F40/253;G06F40/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄晓;              林嘉良;              滕蔚;                   保延翔       </td>   <td>中山大学</td>   <td>基于多卷积窗尺寸注意力卷积神经网络实体关系抽取方法</td>   <td>广东省</td>   <td>CN110888944B</td>   <td>2023-04-28</td>   <td>本发明提供一种基于多卷积窗尺寸注意力卷积神经网络实体关系抽取方法,该方法提出基于卷积窗口尺寸注意力机制的卷积神经网络,在关系分类任务上相比于核方法和特征方法,能够实现自动提取特征,并且可以避免繁杂的特征工程以及相应的误差传播缺点,可以有效地关注句子中对关系分类最重要的n-gram信息,提高分类目标的准确率,与基于RNN和词嵌入注意力的神经网络相比,具有相对较低的复杂度,运行速度快的优点。</td>   <td>1.一种基于多卷积窗尺寸注意力卷积神经网络实体关系抽取方法,其特征在于,包括以下步骤：S1：对于给定的关系抽取数据集；S2：在输入层将输入句子中的每个单词转化为一个词向量和两个相对位置向量的拼接,得到整个句子的语义向量表示为S；S3：在卷积池化层使用多个尺寸的卷积核提取特征,得到卷积池化特征P；所述步骤S3中：所述卷积池化特征P特征的计算过程如下：在输入表示层之后,原来的文本内容被转化成为语义向量表示为S＝[f-1,f-2,…,f-k],接下来,为了得到句子的高阶的语义特征信息,本发明引入了N-s*N-f个卷积核来对语义向量S进行特征提取,得到高阶语义特征o-(ji),o-(ji)的计算如下：o-(ji)＝σ(W-(ji)·S) (1)其中σ是一个激活函数,N-s表示卷积核尺寸的种类数,N-f表示卷积核个数,W-(ji)表示第j种尺寸的第i个卷积核,依据(1),可以得到第j种尺寸的卷积核提取出来的高阶语义特征为使用最大池化方法对高阶语义特征O-j进行过滤,可以得到第j种尺寸卷积核提取的池化特征p-j,即：p-j＝max(O-j) (2)由于总共有N-s种不同尺寸卷积核,因此该层最终得到N-s种不同尺寸卷积核输出的池化特征,记为S4：根据卷积池化层的输出,使用注意力机制对上一层提取的特征P进行操作；所述步骤S4中使用注意力机制对上一层提取的特征P进行操作过程是：首先,使用tanh激活函数对不同尺寸的卷积核输出特征P进行映射,使其成为T；然后利用T计算权重α；最终通过加权求和的方法得到用关系推断的句子编码向量r～*：T＝tanh(P) (3)                                    r～*＝tanh(r) (6)其中,w是一个训练的参数,而参数α,r,w的向量维度大小分别为N-f,N-s和N-fN-s；S5：通过全连接层将上一层获得的句子编码向量r～*转化为各类关系的得分s,并用softmax层得到各个关系的条件概率p(y-i|S),通过取最大条件概率的关系作为预测值y～*。</td>   <td>G06F16/28;G06F16/36;G06F40/30;G06F16/35;G06N3/0464;G06N3/047;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王资;                   朝红阳       </td>   <td>中山大学</td>   <td>基于DSP芯片与量化模型的三维物体识别方法</td>   <td>广东省</td>   <td>CN110991229B</td>   <td>2023-04-28</td>   <td>本发明涉及一种基于DSP芯片与量化模型的三维物体识别方法。包括三维数据采集器、三维数据特征提取器以及特征解码器,三维数据采集器为RGB-D摄像头,拍摄后得到画面中物体的深度信息,最终合成为点云数据；将该点云数据输入到三维数据特征提取器中,特征提取器中的量化参数模型存储模块用于存量化模型的储参数,利用DSP并行计算加速模块加速特性,快速完成深度神经网络中卷积、池化、残差操作,得到输入数据的特征；特征解码器根据模型训练时对特征加密的方式反向解码,得到需要的特征格式。发明中的特征提取器可以提取三维数据的特征,并且可以通过数据结构优化和硬件加速的方法加速特征提取的速度。</td>   <td>1.一种基于DSP芯片与量化模型的三维物体识别方法,其特征在于,包括三维数据采集器、三维数据特征提取器以及特征解码器,所述的三维数据特征提取器包括量化参数模型存储模块和DSP并行计算加速模块；所述的三维数据采集器为RGB-D摄像头,拍摄后得到画面中物体的深度信息,最终合成为点云数据；将该点云数据输入到三维数据特征提取器中,特征提取器中的量化参数模型存储模块用于存量化模型的储参数,利用DSP并行计算加速模块加速特性,快速完成深度神经网络中卷积、池化、残差操作,最后得到输入数据的特征；特征解码器根据模型训练时对特征加密的方式反向解码,得到需要的特征格式；其中,在使用量化参数模型存储模块存储参数时,需要获取量化模型,量化模型的获取方法包括训练时量化和训练后量化；当为训练时量化是的步骤包括：首先,在模型训练时调用Tensorflow的tf.contrib.quantize.create-training-graph接口并实现该接口未支持的在一般操作后加入伪量化节点的功能,之后所有的运算操作后都有一个伪量化节点,伪量化节点储存上一个节点的最大值和最小值,使用这两个值,利用映射公式：Q＝R/scale+zero-pt,即可将参数由32位浮点数存储的方式转换成用8位整型数的存储方式,其中R代表32位浮点数,Q代表8位整型数,scale是映射缩放,scale＝(Vmax-Vmin)/255,zero-pt是映射零点,zero-pt＝-255*Vmin/(Vmax–Vmin)＝-Vmin/scale,其中Vmax与Vmin从伪量化节点中获取,255为8位无符号整型数可表示的最大值；然后,在模型参数固定时,调用tf.contrib.quantize.create-eval-graph接口并实现该接口未支持的在一般操作后加入伪量化节点的功能；随后进行模型参数固定,参数固定后,调用toco convert脚本,结合一般节点与其对应的伪量化节点的信息,得到量化模型；当为训练后量化时的步骤包括：首先,在模型训练阶段使用一般的训练方法；然后,在模型参数固定时,在权重、激活、矩阵乘法、加法等节点之后人工地加入伪量化节点,再向模型喂入部分训练数据以获得伪量化节点需要记录的关于上一节点的最大值和最小值；随后进行模型参数固定,参数固定后,调用toco convert脚本,结合一般节点与其对应的伪量化节点的信息,得到量化模型。</td>   <td>G06V20/64;G06V10/94;G06V10/82;G06N3/0464;G06N3/048;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              陈嘉敏;              林佳玲;              蔡佳辉;                   王金鹏       </td>   <td>中山大学;广州智慧城市发展研究院</td>   <td>一种细粒度识别方法、终端设备及计算机可读存储介质</td>   <td>广东省</td>   <td>CN111291767B</td>   <td>2023-04-28</td>   <td>本发明公开了一种细粒度识别方法、终端设备及计算机可读存储介质,涉及计算机视觉技术领域。该方法包括步骤：目标检测,对输入图片进行卷积,得到特征图,标框出目标所在位置,使用目标掩膜对检测出的目标框周围的特征进行相应的反转；局部特征提取,对特征图进行卷积和全局最大池化,得到图片显著点,提取显著点的特征；全局特征提取,将目标掩膜后得到的结果与目标检测步骤得到的特征图进行点乘,得到新的特征图,并把新特征图作为残差网络的输入,经过卷积层逐步提取图片的全局特征；特征融合,将得到的局部特征和全局特征按权重进行融合。本发明的方法基于背景分离和显著点检测,具有鲁棒性强、计算效率高的优点,可进行精确的细粒度识别。</td>   <td>1.一种细粒度识别方法,其特征在于,包括以下步骤：S1、目标检测,对输入图片进行卷积,得到特征图,标框出目标所在位置,使用目标掩膜对检测出的目标框周围的特征进行相应的反转；S2、局部特征提取,对特征图进行卷积和全局最大池化,得到图片显著点,提取显著点的特征；S3、全局特征提取,将目标掩膜后得到的结果与目标检测步骤得到的特征图进行点乘,得到新的特征图,并把新特征图作为残差网络的输入,经过卷积核大小不同的卷积层逐步提取图片的全局特征；S4、特征融合,将得到的局部特征和全局特征按权重进行融合；其中,所述步骤S1的具体步骤包括：S11、目标中心点位置确定,将输入图片进行卷积操作,得到对应的特征图,然后在特征图上进行1x1卷积,获得目标对应的分数,再通过sigmoid函数得到对应的中心点概率值,然后通过阈值筛选出高于阈值的点,标识为目标物可能存在的中心位置；S12、目标形状的预测,根据上一个部分得到预测的中心点,预测每个中心点位置对应的目标框形状,使得预测形状与距离最近的Ground truth有较高的IOU,预测出目标框对应的宽和高的数值；S13、特征调整,根据所述步骤S11以及所述步骤S12的输出结果,通过阈值筛选出最有可能的形状来生成对应的目标框；S14、目标掩膜,根据所述步骤S13得到的目标框的位置,建立目标掩膜如下：图片分为三个区域,目标框内区域的掩膜值为1,目标框外一圈区域的掩膜值为-1,其余部分为0；然后将图片特征和目标掩膜按照式1)进行运算,截取出物体区域,式1)为：；其中,mask-(object)代表根据目标框定义的目标掩膜,代表经过特征调整后得到的图片特征,通过上式的乘积操作,得到仅含有物体区域特征和周围一部分反转后的新特征f-(object)；在所述步骤S13中,还包括对特征的调整,对特征的调整按照式5)进行,式5)为：          ；其中,fi代表第i个位置对应的特征图的值,(wi, hi)为相应的目标框的形状,特征转化使用3x3的可变形卷积神经网络代表,经过转换后得到新的特征值,然后进行后续的分类及回归操作。</td>   <td>G06V10/46;G06V10/24;G06V10/80;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈武辉;              林晖;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于区块链的车联网数据交易方法</td>   <td>广东省</td>   <td>CN111402043B</td>   <td>2023-04-28</td>   <td>本发明公开一种基于区块链的车联网数据交易方法,包括：建立基于联盟区块链的数据交易网络拓扑结构,其包括：数台具有本地存储车辆数据且与授权的边缘服务器通信连接的车辆；数台边缘服务器,包括边缘层和区块链层,边缘层作为交易代理,采用双拍卖机制来执行车辆间数据交易的投标过程；作为区块链层,组成区块链网络,运行智能合约,为边缘层提供数据代理存储、投标过程的计算支持和区块链智能合同的共识；建立以买方效用最大化、卖方成本最小化、交易代理的社会福利最大化为市场均衡的第一目标函数,获取第一目标函数最优解。本发明为车联网中的数据交易提供一种安全、真实的方式。</td>   <td>1.一种基于区块链的车联网数据交易方法,其特征在于,包括：S10建立基于联盟区块链的数据交易网络拓扑结构,其包括：数台具有本地存储车辆数据且与授权的边缘服务器通信连接的车辆,在P2P数据交易中作为出售车辆数据的卖方、请求其他车辆数据的买方或既不出售又不购买数据的空闲车辆；数台边缘服务器,包括边缘层和区块链层,边缘层作为交易代理,采用双拍卖机制来执行车辆间数据交易的投标过程；作为区块链层,组成区块链网络,运行智能合约,为边缘层提供数据代理存储、投标过程的计算支持和区块链智能合同的共识；S20建立以买方效用最大化、卖方成本最小化、交易代理的社会福利最大化为市场均衡的第一目标函数,获取第一目标函数最优解；所述市场均衡的第一目标函数具体为：假设有N个车辆个体的数据交易场景,每个车辆个体可以是车辆数据卖方,也可以是车辆数据的买方,买方数量表示为N-B,卖方数量表示为N-S,且N＝N-B+N-S,每个买方的索引为i∈{1,2,…,N-B},每个卖方的索引为j∈{1,2,…,N-S}；第i个买方对第j个卖方的数据需求为d-(i,j)≥0；定义第i个买方的需求向量为d-i,效用函数为U-i(d-i),每个买方i的需求区间为即/&gt;第j个卖方对第i个买方的数据供应为s-(j,i)≥0,第j个卖方的供应向量为s-j,成本函数为C-j(s-j),每个卖方j的供给区间为/&gt;即/&gt;当买卖双方的需求和供给相匹配时,市场必然达到均衡,即对于任意i∈{1,2,…,N-B}和j∈{1,2,…,N-S},有s-(j,i)＝d-(i,j)；由于买方和卖方的目标冲突,即当买方试图使其效用最大化时,卖方则试图使其产生的成本最小化,而代理则应使其社会福利最大化并实现有效的市场均衡,第一目标函数表示为(1)：                  其中约束条件为：                                    s-(j,i)＝d-(i,j),i∈{1,2,…,N-B},j∈{1,2,…,N-S}s-(i,j)≥0,i∈{1,2,…,N-B},j∈{1,2,…,N-S},其中买方i的效用函数U-i(d-i)和卖方j的成本函数C-j(s-j)分别表示为(2)和(3)：                            /&gt;t-(i,j)为车辆i和j之间的传输损失,w-i指买方i的交易意愿,l-1和l-2为成本因子；由于t-(i,j)包含传输延迟和传输费用,所以表示为(4)：                  其中v-(i,j)为传输速度,f-(i,j)为每单位的传输费用,C为表示网络的拥塞状态的常数。</td>   <td>G06Q40/04;G06Q30/08;G06Q30/0601</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋嘉伦;              衣杨;              赵福利;              王馥君;              陈敏;              朱艺;                   李强       </td>   <td>中山大学</td>   <td>基于深度学习的随堂扫码评教数据有效性分析方法</td>   <td>广东省</td>   <td>CN111476352B</td>   <td>2023-04-28</td>   <td>本发明提供的基于深度学习的随堂扫码评教数据有效性分析方法,包括：收集随堂扫码评教数据,得到评教数据集；对评教数据集进行预处理,得到标记后的评教数据集,并将标记后的评教数据集划分成训练集、验证集和测试集；利用训练集对深度神经网络进行训练,得到多个候选的深度神经网络模型；利用测试集对候选的深度神经网络模型进行测试,最终筛选出效果最好的深度神经网络模型。本发明创新性地提出了一种将深度学习算法应用于评教数据分析的新思路,首次将深度学习应用于解决评教数据有效性的判别问题,借助深度神经网络来学习教师、课程以及学生三者的自身属性与评教数据有效性相关的深层特征。</td>   <td>1.基于深度学习的随堂扫码评教数据有效性分析方法,其特征在于：包括以下步骤：S1：随堂扫码评教数据收集,根据随堂扫码评教系统对评教数据进行收集,对每条评教数据与其相应的教师、课程及学生信息进行量化操作并组合,得到未标记的评教数据集；所述步骤S1具体包括以下步骤：S11：在课间,学生通过使用智能移动设备扫描评教二维码打开评教Web页面,并用自身的教务系统账号登录；S12：填写的教学评价问卷包含10个选择题,每个选择题的选项包括差、一般、良和优四个等级；S13：学生填写完毕并提交一份评教问卷后,服务器将从教务系统中查询到该份问卷的教师信息、课程信息以及学生信息,连同评教问卷中每道题的结果都进行量化操作再拼接后得到一条评教数据；处理完所有评教问卷后得到的所有评教数据,即为未标记的评教数据集；所述的评教数据集每条评教数据格式如下：{UID,课程ID,课程类别,课程出勤率,教师教龄,教师性别,学生年龄,学生性别,学生院系,学生专业,学生必修课平均成绩,学生选修课平均成绩,学生平均每学期所修课程数,学生当前学期所修课程数,学生出勤率,学生心理测评成绩,评教题1结果,评教题2结果,……,评教题10结果,有效性}共包含27项信息,其中：“有效性”字段的值默认为0；S2：对教数据集进行预处理,首先对未标记的评教数据集中的每条评教数据进行标记,然后将评教数据集划分成训练集、验证集和测试集；所述步骤S2具体包括以下步骤：S21：针对于每门课程,具体操作为：假设课程ID为1,在全校师生中随机选取n≥5位教师,m≥5位学生,要求每人至少旁听该门课程4个课时,且m位学生应从选修该课程的学生中抽取；由这m+n个人填写该课程的教学评价问卷,得到m+n条评教样本,记为Set-Standard,其中每条评教样本格式如下：{课程ID,评教题1结果,评教题2结果,……,评教题10结果}在评教数据集中筛选出所有课程ID为1的评教数据,记为Set-Unlabled,假设Set-Unlabled共有N条评教数据,将其中每条评教数据记为U-i(1&lt;＝i&lt;＝N),和Set-Standard中的每条评教样本S-j(1&lt;＝j&lt;＝m+n)作对比；若存在S-j,使得U-i和S-j的10个评教题的结果中至少有4个是对应相同的,则把评教数据集中U-i对应评教数据的“有效性”字段的值更新为1；S22：在对每门课程都执行过步骤S21后,即完成了对评教数据集中每条评教数据的标记,然后从评教数据集中随机抽取60％、20％和20％,分别为训练集train-set、验证集valid-set和测试集test-set；S3：训练深度神经网络模型,使用训练集中的数据对深度神经网络的参数进行训练,使用多组不同的超参数进行多次训练后得到多个候选的深度神经网络模型；在所述步骤S3中,所述深度神经网络由上下两部分构成,每部分都包含8层,其中5层为卷积层,3层为全连接层；所述步骤S3具体包括以下步骤：S31：评教数据集中的每条数据在输入深度神经网络前,被分为data和label两部分数据,其中：data是由{课程ID,课程类别,课程平均出勤率,教师教龄,教师性别,学生年龄,学生性别,学生院系,学生专业,学生必修课平均成绩,学生选修课平均成绩,学生平均每学期所修课程数,学生当前学期所修课程数,学生出勤率,学生心理测评成绩,评教题1结果,评教题2结果,……,评教题10结果}所转换成的5*5的二维矩阵；label为“有效性”字段的值；S32：在train-set数据集上进行训练,借助BP反向传播算法和梯度下降算法训练深度神经网络的参数,训练过程中,验证集valid-set用于判断模型是否过拟合,训练完成后得到1个深度神经网络模型；S33：使用10组不同的超参数,重复进行10次步骤S32,得到10个候选的深度神经网络模型；S4：筛选深度神经网络模型,利用测试数据集测试各个候选的深度神经网络模型的效果,筛选出效果最优的深度神经网络模型,对评教数据进行有效性分析。</td>   <td>G06Q10/0639;G06N3/0464;G06N3/084;G06F18/243;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马佳;              陈志广;                   卢宇彤       </td>   <td>中山大学</td>   <td>一种基于K-Truss图的存储系统缓存预取方法、系统及介质</td>   <td>广东省</td>   <td>CN111506778B</td>   <td>2023-04-28</td>   <td>本发明公开了一种基于K-Truss图的存储系统缓存预取方法、系统及介质,本发明方法步骤包括当系统中的数据请求流到达时判断数据请求流的访问模式,如果是顺序模式则预取数据请求流对应的数据块之后的n个顺序块作为预取数据；否则将数据请求流对应的数据块作为查询点查询K-Truss图得到与查询点匹配的truss结构,获取truss结构中数据块的数据作为预取数据；根据数据请求流对应的数据块更新K-Truss图；最终将预取数据块预取到主存中。本发明能够提高内存数据块的命中率,充分发挥存储系统的性能,能够提高缓存的命中率以及缩短响应时间,减少中央处理器中断等待事件,提高处理器的利用率。</td>   <td>1.一种基于K-Truss图的存储系统缓存预取方法,其特征在于实施步骤包括：1)当系统中的数据请求流到达时,判断数据请求流的访问模式是否为顺序模式,如果是顺序模式则跳转执行步骤2)；否则跳转执行步骤3)；2)预取数据请求流对应的数据块之后的n个顺序块作为预取数据,跳转执行步骤4)；3)将数据请求流对应的数据块作为查询点查询K-Truss图得到与查询点匹配的truss结构,获取truss结构中数据块的数据作为预取数据；根据数据请求流对应的数据块更新K-Truss图；4)将预取数据块预取到主存中,结束并退出；步骤3)中将数据请求流对应的数据块作为查询点查询K-Truss图得到与查询点匹配的truss结构的详细步骤包括：将数据请求流对应的数据块作为查询点,通过K-Truss查询算法将K-Truss图中包含该数据块的紧密度系数k的值最大的truss结构取出；步骤3)中根据数据请求流对应的数据块更新K-Truss图的详细步骤包括：A1)将数据请求流对应的数据块和历史窗口中的数据块产生组合并更新边组合记录表,所述边组合记录表记录有各个组合出现的次数；A2)根据边组合记录表判断新产生的组合出现的次数是否超过预设阈值T,如果未超过预设阈值T则结束更新K-Truss图并退出；否则跳转执行步骤A3)；A3)将新产生的组合插入K-Truss图中；A4)将数据请求流对应的数据块加入历史窗口中。</td>   <td>G06F16/901;G06F16/23;G06F16/2455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢子维;              魏朋旭;              詹宗沅;                   林倞       </td>   <td>中山大学</td>   <td>基于角点引导级联沙漏网络结构学习的真实图像超分辨率模型及方法</td>   <td>广东省</td>   <td>CN111696033B</td>   <td>2023-04-28</td>   <td>本发明公开了一种基于角点引导级联沙漏网络结构学习的真实图像超分辨率模型及方法,模型包括：多尺度特征提取单元,利用级联沙漏网络结构提取输入图像的多尺度信息的特征；分区域重建单元,利用不同深度的多尺度特征分别重建多个初始的超分辨率图像；分区域监督单元,利用角点检测算法将高分辨率图像解耦为平坦、边缘和角点区域,分别监督各个初始的超分辨率图像；角点引导重建单元,利用提取到的图像各区域信息；梯度加权约束单元,基于图像的梯度信息来加权损失函数,加强角点区域的拟合能力。本发明能够避免一幅图像的所有区域被同等对待,最终将重建得到的三个结果加权融合成更符合人类视觉感受的超分辨率图像,有效地提升图像质量。</td>   <td>1.基于角点引导级联沙漏网络结构学习的真实图像超分辨率模型的系统,其特征在于,包括多尺度特征提取单元、分区域重建单元、分区域监督单元、角点引导重建单元以及梯度加权约束单元,所述多尺度特征提取单元和分区域监督单元均与分区域重建单元连接,所述分区域重建单元和梯度加权约束单元均与角点引导重建单元连接；所述多尺度特征提取单元,用于通过级联沙漏网络结构提取输入图像的多尺度信息的特征；所述分区域重建单元,用于通过不同深度的多尺度特征分别重建多个初始的超分辨率图像；所述分区域监督单元,用于通过角点检测算法将高分辨率图像解耦为平坦、边缘和角点区域,分别监督各个初始的超分辨率图像；所述角点引导重建单元,用于通过提取到的角点信息来引导重建超分辨率图像；所述梯度加权约束单元,用于通过图像的梯度信息来加权损失函数,从而约束模型的拟合方向,加强角点区域的拟合能力。</td>   <td>G06T3/40;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;                   尹靓璐       </td>   <td>中山大学</td>   <td>基于端对端深度学习的目标检测与语义分割的并行方法</td>   <td>广东省</td>   <td>CN109543754B</td>   <td>2023-04-28</td>   <td>本发明提供一种基于端对端深度学习的目标检测与语义分割的并行方法,通过对海量已标注目标检测框和像素级目标分割的图像训练得到一个由目标检测神经网络Darknet-19、目标分割全卷积神经网络FCN组成的模型,成功实现了并行目标检测和目标分割的任务,该发明能够有效地提取图像特征,在保证目标检测和目标分割的基础上,实现实时性的图像处理功能,有较广的应用前景。</td>   <td>1.一种基于端对端深度学习的目标检测与语义分割的并行方法,其特征在于,过程如下：S1：构造与训练深层神经网络Darknet-19；S2：构造与训练全卷积神经网络FCN；S3：使用得到的深层神经网络Darknet-19和全卷积神经网络FCN对输入图像进行目标分类、定位及像素级别的分割；所述步骤S1的具体过程如下：S11：采集可应用场景中的含有多类需要检测目标的图片作为训练数据集,对训练数据集中的多类目标物体根据检测和分割任务进行相应的标注处理；标注后的图片作为标准输出参考图；S12：进行模型迁移,将已有的部分卷积神经网络模型参数作为初始卷积共享网络和检测任务部分的训练参数；S13：先考虑目标检测分支的训练过程,输入图像通过Darknet-19中FCN与其共享的卷积共享网络部分的一部分卷积和池化网络层后得到特征图片,将特征图片输入Darknet-19的RPN模块得到锚点和形态长宽比不同的预测框,然后将预测框中符合目标区域要求的特征图片分别送入Darknet-19的分类模块和回归模块中对目标进行分类和定位即目标检测；S14：Darknet-19的分类模块为一个全连接网络,输出单元为N+1个,得到这个目标区域中目标属于每个类和背景的概率,然后使用一个softmax,最后得到一个目标类别分数Dark-cls-prob;S15：Darknet-19的回归模块为一个全连接网络,输出单元为4*N个,得到这个目标区域目标的预测框的四个参数,包括它的横轴起点、纵轴起点以及它们与锚点的距离,最后通过修正单元对预测框参数进行修正,输出一个目标的预测框坐标Dark-bbox-pred；S16: 通过向深层神经网络Darknet-19输入带有目标物体的图片和其对应的标注好的图片,并基于深层神经网络Darknet-19输出的目标检测的结果使用随机梯度下降方法对深层神经网络Darknet-19进行参数的调整,这个过程重复进行直至深层神经网络Darknet-19符合要求；所述步骤S2的具体过程如下：S21：将FCN最后三层网络作为分割网络的后续处理模块,三层网络包括两层卷积网络和一层反卷积网络；S22：考虑目标分割分支的训练过程,输入图像通过Darknet-19中FCN与其共享的卷积共享网络部分后得到一个特征图片,这个特征图片经过FCN最后三层网络,两层不改变特征图片的大小、只改变通道数的卷积网络,最后通过一层反卷积网络将其进行两倍上采样得到Conv-FCN-out；S23：将Darknet-19中FCN与其共享的卷积共享网络部分中第四个池化层的输出特征图片Pool4-out与上一步骤的Conv-FCN-out进行融合,然后此时通过一层反卷积网络两倍上采样得到Deconv-Pool3-out；S24：将Darknet-19中FCN与其共享的卷积共享网络部分中第三个池化层的输出特征图片Pool3-out与上一步骤的融合输出再进行融合得到Deconv-Pool4-out,然后通过一层反卷积网络进行八倍上采样到原始图片大小最后得到Conv-seg-out；这里一层反卷积网络的反卷积核是由双线性插值法初始化的,在训练中进行学习；S25：对这个目标检测、分割并行网络进行训练时,目标检测分支的深层神经网络Darknet-19的部分神经网络参数使用迁移模型中的参数,对目标分割分支的全卷积神经网络FCN各层的参数随机初始化,最后采用降低损失函数的反向传导算法对整个目标检测、分割并行网络的Darknet-19目标检测网络和FCN目标分割网络进行同步训练；所述步骤S3的具体过程如下：将图片输入到卷积共享网络当中,得到的特征图片既由RPN模块继续处理,通过分类和回归得到图片中的目标的分类分数和监测框；又由FCN的全卷积层来得到像素级的分割图片。</td>   <td>G06V10/764;G06V10/70;G06V10/82;G06N3/0464;G06N3/047;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              龙衍鑫;                   林冰倩       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于对抗对比学习的导航系统训练方法、装置及导航系统</td>   <td>广东省</td>   <td>CN113627249B</td>   <td>2023-04-28</td>   <td>本发明公开了一种基于对抗对比学习的导航系统训练方法、装置及导航系统,所述方法包括：在智能体移动时采集智能体处于不同模态下的模态信息,将所述模态信息编码成特征向量；当确定智能体停止移动时,根据所述特征向量获取隐藏状态向量；对所述隐藏状态向量进行轨迹编码得到轨迹编码数据；调用预设的障碍场景轨迹数据和预设的无障碍场景轨迹数据对所述轨迹编码数据进行对抗对比学习的训练模型,得到导航训练系统。本发明可以通过对抗对比学习和训练,优化智能体长期计划能力,可以大大提高导航器在障碍条件下的鲁棒性,并提高导航的准确性。</td>   <td>1.一种基于对抗对比学习的导航系统训练方法,其特征在于,所述方法包括：在智能体移动时采集智能体处于不同模态下的模态信息,将所述模态信息编码成特征向量；当确定智能体停止移动时,根据所述特征向量获取隐藏状态向量；对所述隐藏状态向量进行轨迹编码得到轨迹编码数据；调用预设的障碍场景轨迹数据和预设的无障碍场景轨迹数据对所述轨迹编码数据进行对抗对比学习的训练模型,得到导航训练系统,其中,所述预设的障碍场景轨迹数据为智能体在障碍条件的导航轨迹数据,所述预设的无障碍场景轨迹数据为智能体在无障碍条件的导航轨迹数据；所述调用预设的障碍场景轨迹数据和预设的无障碍场景轨迹数据对所述轨迹编码数据进行对抗对比学习的训练模型,包括：对所述预设的障碍场景轨迹数据e-o和所述预设的无障碍场景轨迹数据e-f进行对抗对比训练,分别得到训练障碍场景轨迹数据和训练无障碍场景轨迹数据；其中,在有障碍场景下,预设的障碍场景轨迹数据e-o被强制接近预设的无障碍场景轨迹数据e-f,而在无障碍场景中,预设的无障碍场景轨迹数据e-f被优化为与预设的障碍场景轨迹数据e-o有区别：sim(a,b)表示a和b之间的相似性,f,o分别表示无障碍设置和有障碍条件的设置；通过对比损失函数和梯度下降算法拉近所述训练障碍场景轨迹数据和所述训练无障碍场景轨迹数据得到拉近轨迹数据；利用所述拉近轨迹数据模仿训练所述轨迹编码数据；采用学习损失函数对所述导航训练系统进行梯度计算,得到梯度参数；通过对比损失函数和梯度下降算法拉近所述训练障碍场景轨迹数据和所述训练无障碍场景轨迹数据得到拉近轨迹数据,包括：利用对比损失和梯度下降算法,通过训练以拉近e-o和e-f的表达,使得智能体将学会模仿无障碍轨迹,然后在有障碍场景下训练过程中逐渐学习收敛到导航出类似无障碍条件下走出的轨迹；其中,在障碍场景下,对比损失l-o可以如下式所示：τ是温度参数；在无障碍场景中,对比损失l-f可以如下式所示：/&gt;λ是两个损失项之间的权重；在无障碍场景中,通过收集无障碍轨迹编码e-f和沿监督路径导航获得的轨迹编码来构造特定实例的正样本对。</td>   <td>G06V20/00;G06V10/774;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              马蒙蒙;                   周晓聪       </td>   <td>中山大学</td>   <td>一种基于机器翻译模型的代码注释生成方法</td>   <td>广东省</td>   <td>CN111090461B</td>   <td>2023-04-28</td>   <td>本发明公开一种基于机器翻译模型的代码注释生成方法,将所获取含注释的代码语料库划分为源代码方法序列语料库和对应的源代码注释语料库；将源代码注释语料库中源代码注释作输入seq2seq模型；提取源代码方法序列生成抽象语法树,将节点的标识符替换为节点类别且结构化遍历得到保留结构信息的序列输入seq2seq模型；将结构信息输入编码层生成隐含状态序列和结构信息的编码输出并输入注意力机制层,根据隐含状态序列和结构信息的编码输出之间匹配程度计算上下文向量；将结构信息的编码输出和上下文向量输入解码层,并计算训练样本目标的序列概率分布；由源代码注释和序列概率分布生成基于序列机器翻译模型。</td>   <td>1.一种基于机器翻译模型的代码注释生成方法,其特征在于,包括：S10获取含注释的代码语料库,提取代码语料库中的高频词构建词典,将代码语料库划分为源代码方法序列语料库和对应的源代码注释语料库；S20提取源代码注释语料库中源代码注释作为训练样本目标Y输入seq2seq模型；S30提取源代码方法序列生成抽象语法树,将节点的标识符替换为节点的type类别且结构化遍历得到保留结构信息的序列作为模型训练样本X,将模型训练样本X将输入seq2seq模型；S40将结构信息X输入编码层生成作为模型参数的隐含状态序列S和结构信息的编码输出h；S50将隐含状态序列S和结构信息的编码输出h输入注意力机制层,注意力机制层根据隐含状态序列S和结构信息的编码输出h之间匹配程度计算得到上下文向量C；S60将结构信息的编码输出h和上下文向量C输入解码层,并计算训练样本目标Y的序列概率分布；S70由源代码注释和序列概率分布生成基于序列机器翻译模型。</td>   <td>G06F8/73;G06F40/58;G06F40/242;G06N3/0442;G06N3/0455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;                   黄立峰       </td>   <td>中山大学</td>   <td>一种作用于目标检测系统的行人图像检测方法</td>   <td>广东省</td>   <td>CN111523478B</td>   <td>2023-04-28</td>   <td>本发明公开了一种作用于目标检测系统的行人图像检测方法,包括以下步骤：在目标检测系统中构建行人图像检测模型,采集待检测的行人图像,将待检测的行人图像输入到所述行人图像检测模型,所述行人图像检测模型输出行人图像检测结果；通过将包括有伪装图案的行人图像和不含有伪装图案的行人图像作为行人图像检测模型的训练数据,使得行人图像检测模型能够具备识别伪装图案的能力,同时,通过在目标检测系统中构建所述行人图像检测模型,目标检测系统通过针对行人图像检测模型的检测结果做出相应的措施,能够提高目标检测系统的防御能力和检测能力,避免出现漏检或者错检的情况。</td>   <td>1.一种作用于目标检测系统的行人图像检测方法,其特征在于：包括以下步骤：步骤S1,在目标检测系统中构建行人图像检测模型,所述行人图像检测模型的输入端为行人图像,所述行人图像检测模型的输出端为行人图像检测结果,其中,所述行人图像包括含有伪装图案的行人图像和不含有伪装图案的行人图像；步骤S2,采集待检测的行人图像；步骤S3,将待检测的行人图像输入到所述行人图像检测模型；步骤S4,所述行人图像检测模型输出行人图像检测结果；其中,所述含有伪装图案的行人图像的生成基于目标检测系统,包括以下步骤：步骤S11,基于标准正太分布生成一张随机噪音矩阵,对随机噪音矩阵进行处理,得到原始伪装图案；步骤S12,对原始伪装图案进行物理仿真操作,得到拟真数据集；步骤S13,将拟真数据集输入到目标检测系统进行检测,得到检测结果；步骤S14,依据检测结果对拟真数据集进行调整,得到初始的含有伪装图案的行人图像；步骤S15,对初始的含有伪装图案的行人图像进行优化,生成最终的含有伪装图案的行人图像；所述步骤S12中的对原始伪装图案进行物理仿真操作包括以下步骤：步骤S121,对原始伪装图案的内在特性进行物理仿真；步骤S122,对原始伪装图案所处的外在环境进行物理仿真；所述步骤S121包括以下步骤：步骤S1211,模拟原始伪装图案处于非刚体/非平面物体情况下的拉伸状态；步骤S1212,模拟原始伪装图像处于不同遮挡程度的状态图像；步骤S1213,模拟原始伪装图像处于物体上不同位置的状态；所述步骤S15中对初始的含有伪装图案的行人图像进行优化包括以下步骤：步骤S151,基于语义约束对初始的含有伪装图案的行人图像进行处理,并将处理后的行人图像输入到目标检测系统进行检测；步骤S152,若目标检测系统没有检测到伪装图案,那就将输入该目标检测系统的初始的含有伪装图案的行人图像作为最终的含有伪装图案的行人图像,若目标检测系统检测到伪装图案,那就将输入该目标检测系统的初始的含有伪装图案的行人图像中的伪装图案作为原始伪装图案输入至步骤S12进行处理。</td>   <td>G06V40/10;G06V20/58</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   徐原       </td>   <td>中山大学</td>   <td>基于语义对齐及对称结构编码的知识图谱补全方法及装置</td>   <td>广东省</td>   <td>CN114117075B</td>   <td>2023-04-28</td>   <td>本发明提出一种基于语义对齐及对称结构编码的知识图谱补全方法及装置,涉及知识图谱补全的技术领域,基于训练集中三元组数据及三元组各部分的组合形成输入文本,然后构建知识图谱补全模型,包含有上、下路对称编码结构,利用对称编码均衡分配关系给实体做匹配,缓解了传统模型中链路预测中的不对称性问题,提升模型整体的预测性能,还将对比学习的框架引入,基于语义对齐损失函数,对比学习拉近同义三元组语义距离,增强三元组样本的语义特征,首先对比学习进行自监督训练,为增强对负样本的区分能力,还包含了负采样过程,后进行有监督训练分数拟合器,使得知识图谱补全不受限于原结构,提高了泛化能力及鲁棒性强,提升了知识图谱补全效果。</td>   <td>1.一种基于语义对齐及对称结构编码的知识图谱补全方法,其特征在于,包括以下步骤：S1.将数据集划分为训练集、验证集和测试集,从训练集中获取原始知识图谱的三元组,包括头实体、关系及尾实体三部分,并创建实体集合和关系集合；S2.将三元组的各部分组合,生成侧重头实体组合和侧重尾实体组合；S3.构建知识图谱补全模型,包括上路文本编码器、与上路文本编码器对称的下路文本编码器、上路交互单元、与上路交互单元对称的下路交互单元及分数拟合器；上路文本编码器与下路文本编码器结构对称,均选用基于transformer的预模型,定义为Transfomer-Enc,上路交互单元与下路交互单元结构对称,均定义为InterTrans-Enc；S4.侧重头实体组合及侧重尾实体组合分别输入知识图谱补全模型的下路文本编码器及上路文本编码器,分别生成下路编码向量与上路编码向量；侧重头实体组合H-h与H-t输入下路文本编码器,通过下路文本编码器生成下路编码向量,表征为：u-h＝Transformer-Enc(H-h)[0],u-t＝Transformer-Enc(H-t)[0]侧重尾实体组合T-h与T-t输入上路文本编码器,通过上路文本编码器生成下路编码向量,表征为：v-h＝Transformer-Enc(T-h)[0],v-t＝Transformer-Enc(T-t)[0]其中,下标[0]表示经过Transformer-Enc的特殊token【CLS】后对应的向量,由于【CLS】在每一路输入文本中被放置在第一个位置,所以对应[0]下标；S5.将下路编码向量通过下路交互单元进行交互拼接,将上路编码向量通过上路交互单元进行交互拼接；将上路编码向量通过上路交互单元进行交互拼接时,满足：v＝[v-h；v-h×v-t；v-h-v-t；v-t]其中,v表示上路拼接向量；将下路编码向量通过下路交互单元进行交互拼接时,满足：u＝[u-h；u-h×u-t；u-h-u-t；u-t]其中,u表示下路拼接向量,u,v彼此构成正样本；S6.经步骤S5后分别得到上路拼接向量v与下路拼接向量u,然后引入语义对齐损失函数,基于上路拼接向量v与下路拼接向量u训练上路文本编码器及下路文本编码器；经步骤S5后,输出的下路拼接向量集合表示为上路拼接向量集合表示为/&gt;b表示下路拼接向量中元素的个数；步骤S6所述语义对齐损失函数的表达式为：                  其中,表示语义对齐损失函数；/&gt;τ表示温度系数,作用是调节对困难样本的关注程度,越小的温度系数越关注于将本样本和最相似的其他样本分开；将下路拼接向量集合/&gt;与上路拼接向量集合/&gt;中的向量取出,基于对齐损失函数做对比学习对齐u,v的语义,训练上路文本编码器及下路文本编码器,以调整两路文本编码器共享的权重参数；S7.对S1中的每一个三元组进行负采样,确定最终的负采样三元组,然后对每一个负采样三元组执行S2～S5,得到负采样三元组对应的下路拼接向量u＇；对S1中的每一个三元组进行负采样时,基于关系过滤的负样本采样策略实现,设传统负采样满足：                                                      其中,集合表示负样本采样的结果,由头实体替换后的/&gt;和尾实体替换后的/&gt;组成；增强两个约束条件,采样到困难负样本和/&gt;                                    其中,和/&gt;分别被定义为：                  S8.引入得分损失函数,将下路拼接向量u和u＇输入分数拟合器,以验证集的实体/关系为指导,训练分数拟合器,得到训练好的知识图谱补全模型；S9.从测试集中选定缺失的三元组,将实体集合和关系集合作为候选集,缺失的三元组和候选集中的实体/关系输入知识图谱补全模型,将分数拟合器最终输出的分数按从高到低排序,取最高分数对应的候选集中的实体/关系,作为缺失的三元组待补全的内容。</td>   <td>G06F16/36;G06F16/28;G06F40/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;                   方静如       </td>   <td>中山大学</td>   <td>一种基于认知诊断的实践效果评估及学习路径推荐系统和方法</td>   <td>广东省</td>   <td>CN110930274B</td>   <td>2023-04-28</td>   <td>本发明提供一种基于认知诊断的实践效果评估及学习路径推荐方法,包括拓展特征预处理模型,深度知识追踪模型,知识网络构建模型和基于认知能力的路径推荐算法。拓展特征预处理模型根据学习者测验过程中的技能属性进行认知能力的初次评估,将个性化差异信息引入诊断模型。深度知识追踪模型根据测验序列与隐式编码的异构特征预测学习者的知识掌握能力,作为学习引导的基础。习题与知识网络构建模型提供了科学思维的全局导图,结合认知诊断为学习者推荐学习路径不但考虑到学习过程中的认知能力差异,而且遵循知识结构的逻辑。</td>   <td>1.一种基于认知诊断的实践效果评估及学习路径推荐方法,其特征在于,包括以下步骤：S1.拓展特征预处理模型根据学习者的历史交互记录预测学习者在异构特征条件下的习题回答情况,得到学习者的认知能力的初步预测,并将预测结果与原始的习题答案序列作为深度学习追踪模型的输入；其中：S11.给定一个学习者在第t时间步测验习题,令a-t表示拓展的异构特征,将a-t作为预处理步骤中分类模型的输入,并预测学习者是否会在引入拓展特征的条件下正确作答,利用a′-t表示分类模型预测的答题情况；S12.拓展特征预处理模型的树节点处的集合D包含了拓展的异构特征a-t∈R以及其对应的答案标签c-t∈{0,1},则将H定义为由交叉熵函数所评估的特征空间的不纯度,则对于具有N个观察值的区域R,其交叉熵由如下公式定义：H(X)＝-∑-kp-klog(p-k),          (1-1)其中其中k为标签集合,在二分类问题中用{0,1}或{-1,+1}表示,p-k代表当异构特征a-t对应的答案标签c-t＝k时,其在观察值中所占的比例；S2.深度学习追踪模型根据拓展特征预处理模型输出的信息输入至神经循环网络学习学习者的知识状态,经过sigmoid激活函数将隐藏单元h-t传递至全连接层获得输出y-t,其表现出学习者对知识概念的认知能力,得到学习者的认知能力诊断；其中：S21.生成特定的学习任务交互x-0……x-t,则交互预测学习者下一次交互的结果x-(t+1),习题集合的数量为M,则将x-t设置为交互元组O(e-t,c-t)∈{0,1}～(2M)的独热编码表示,令e-t和c-t分别表示习题的标签和学习者真实的作答表现,即c-t＝1意味着学习者正确回答该习题,否则c-t＝0；S22.当第习题被正确回答时将O(e-t,c-t)的第位设置为1,其余设置为0；而当回答错误时第i+M位将设置为1；S23.将交互元组O(e-t,c-t)与拓展向量O(a′-t,c-t)连接作为深度知识追踪模型DKT的输入x-t；S24.神经网络将输入序列x-t通过计算隐藏状态序列h-t传递到全连接层获得输出序列y-t,即为学习者的认知诊断；S3.知识网络构建模型根据学习者的历史交互记录构建知识网络,其中,自动发掘习题所对应知识概念是通过利用深度知识追踪模型探索习题间作答正确概率关系以及习题的题面经向量化后聚类两方面互相参照而形成；知识概念自身关联关系则根据总体习题得分率并适当参照学习者测验顺序和教材结构进行构建；S4.路径推荐模型根据上述模型所得的学习者的认知能力的初步预测、学习者的认知能力诊断和知识网络确定学习路径的最终元素,生成个性化学习路径。</td>   <td>G06Q50/20;G06F16/9535;G06F16/901;G06N3/042;G06N3/048;G06N3/0442;G06N3/082</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢吉松;                   倪江群       </td>   <td>中山大学</td>   <td>基于深度学习的大容量抗打印/拍摄盲水印系统及方法</td>   <td>广东省</td>   <td>CN111223034B</td>   <td>2023-04-28</td>   <td>本发明提供的基于深度学习的大容量抗打印/拍摄盲水印方法,包括编码步骤和解码步骤,待处理图像由编码器进行分块将水印嵌入图像分块后,由编码器进行还原拼接,并对还原后的图像进行图像视觉保真；采用检测步骤对含水印图像进行检测；解码器则将含有水印信息的图像恢复为未保真状态；并对未保真状态的图像进行分块；解码器使用GPU并行对图像分块进行水印信息提取,得到二进制比特序列,进而解析出水印信息；一方面充分利用了每块图像的冗余空间进行水印信息的嵌入,提高整体的嵌入容量；另一方面减小图像尺寸,并行地对所有分块图像进行神经网络的计算,充分利用GPU的并行加速能力,从而提高运行速度,并且提高了水印检测的鲁棒性和实时性。</td>   <td>1.基于深度学习的大容量抗打印/拍摄盲水印系统,包括编码器和解码器,其特征在于：所述编码器中设置有水印嵌入网络和视觉保真网络；所述解码器中设置有水印恢复网络和水印提取网络；其中：所述编码器将待处理图像进行分块后由水印嵌入网络把水印嵌入图像分块中；所述编码器将嵌有水印的图像分块进行还原拼接后,由所述视觉保真网络进行图像视觉保真；所述解码器通过所述水印恢复网络将待处理图像恢复为未保真状态并对未保真状态的图像进行分块,由所述水印提取网络进行水印提取；所述水印嵌入网络包括下采样卷积模块、上采样卷积模块和全连接层；所述下采样卷积模块用于对图像分块进行下采样卷积计算,提取图像特征,再由所述上采样卷积模块进行上采样卷积计算,得到与待处理图像原图像大小一致的一系列残差图像；最后由全连接层将一系列残差图像分别加上对应的原图像块,得到含水印信息的图像块；所述视觉保真网络为若干个Dense块组成的卷积神经网络；所述的Dense块包括四个卷积块,所述的卷积块由一个1x1卷积层和一个3x3卷积层组成；所述卷积块间通过密集连接,实现了对含水印信息的图像的图像视觉保真。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              何涛;              朱坤鑫;                   牛群       </td>   <td>中山大学</td>   <td>一种基于时空间融合特征的室内定位方法</td>   <td>广东省</td>   <td>CN110533166B</td>   <td>2023-04-28</td>   <td>本发明公开了一种基于时空间融合特征的室内定位方法,包括以下步骤：建立基于时空间融合特征的位置预测网络,所述位置预测网络以定位信号序列为输入,各定位信号序列提取的时空间融合特征对应的位置为输出；采集待确定位置的定位信号序列；将所述定位信号序列作为所述位置预测网络的输入；所述位置预测网络输出该定位信号序列对应的位置。采用本发明方法,从序列信号多个维度下的特征入手,即同时考虑到序列信号的时间和空间特征,使用多维度下的融合特征作为定位的基础,实现了对于多种不同场景的适应性,并且具有良好的泛化性,适用于多种不同的序列定位信号；同时,通过优化神经网络结构降低网络模型的计算复杂度和训练成本。</td>   <td>1.一种基于时空间融合特征的室内定位方法,其特征在于,包括如下步骤：建立基于时空间融合特征的位置预测网络,所述位置预测网络以定位信号序列为输入,各定位信号序列提取的时空间融合特征对应的位置为输出；采集待确定位置的定位信号序列；将所述定位信号序列作为所述位置预测网络的输入；所述位置预测网络输出该定位信号序列对应的位置；其中,建立基于时空间融合特征的位置预测网络包括训练阶段和测试阶段；所述训练阶段包括：步骤S1,对定位序列信号进行预处理,转换为定位序列信号对应时间维度和空间维度下的数据表示形式；步骤S2,提取定位序列信号对应时间维度和空间维度下的时间特征和空间特征,将所述时间特征和空间特征融合为时空间特征,基于时空间特征构建位置预测输出单元,得到位置预测网络模型,并基于预处理后的训练数据对模型进行训练；所述步骤S2包括以下步骤：步骤S21,构建基于双向长短期记忆网络的多层级循环神经网络来提取定位信号序列对应时间维度下的时间特征；步骤S22,构建基于ResNet的多尺度卷积神经网络来提取定位信号序列对应空间维度下的空间特征；构建基于ResNet的多尺度卷积神经网络包括构建用于提取空间特征的网络前端和用于对空间特征进行映射转换的网络后端。</td>   <td>G06N3/0442;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;              黄俊源;                   陈志炜       </td>   <td>中山大学</td>   <td>一种流水式卷积计算架构设计方法及残差网络加速系统</td>   <td>广东省</td>   <td>CN112862079B</td>   <td>2023-04-28</td>   <td>本发明提供一种流水式卷积计算架构设计方法及残差网络加速系统,该方法将该硬件加速架构分为片上缓冲区、卷积处理阵列和逐点加法模块；设置该硬件加速架构的主路由三块串行排列的卷积处理阵列组成,在它们之间插入两块流水线缓冲区,用于实现主路的三层卷积的层间流水；设置第四卷积处理阵列用于并行处理残差积木块分支的内核大小为1×1的卷积层,通过配置第四卷积处理阵列中的寄存器,改变其工作模式,使其可用于计算残差网络头部卷积层或全连接层,当残差积木块的分支无卷积时,跳过第四卷积处理阵列不执行卷积；设置逐点加法模块将残差积木块主路的输出特征与分支快捷连接的输出特征执行对应输出特征像素逐元素相加。</td>   <td>1.一种流水式卷积计算架构的设计方法,其特征在于,包括以下步骤：S1：将流水式卷积计算架构分为片上缓冲区、卷积处理阵列和逐点加法模块；S2：设置流水式卷积计算架构的主路由三块串行排列的卷积处理阵列组成,在它们之间插入两块流水线缓冲区,用于实现主路的三层卷积的层间流水,所述流水线缓冲区设置在片上缓冲区内；S3：设置第四卷积处理阵列用于并行处理残差积木块分支的内核大小为1×1的卷积层,通过配置第四卷积处理阵列中的寄存器,改变其工作模式,使其可用于计算残差网络头部卷积层或全连接层,当残差积木块的分支无卷积时,跳过第四卷积处理阵列不执行卷积；S4：设置逐点加法模块将残差积木块主路的输出特征与分支快捷连接的输出特征执行对应输出特征像素逐元素相加；所述缓冲区包括输入缓冲区、流水线缓冲区、输出缓冲区和权重缓冲区；其中,输入缓冲区用于缓存从片外存储器中读取的特征数据切片,并为残差积木块主路的第一卷积处理阵列和第四卷积处理阵列所共享以提供特征输入；在用于计算残差积木模块主路卷积的第一卷积处理阵列和第二卷积处理阵列的输出端应用流水线缓冲区。</td>   <td>G06N3/0464;G06N3/063;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁小燕;              谢志;              周昊;              孙立梅;                   何尧       </td>   <td>中山大学中山眼科中心</td>   <td>一种早产儿视网膜病变检测方法及装置</td>   <td>广东省</td>   <td>CN114862760B</td>   <td>2023-04-28</td>   <td>本发明公开一种早产儿视网膜病变检测方法和装置,方法包括以下步骤：S1：获取待筛查个体的左右两边不同方位的眼底广角影像；S2：以待筛查个体为单位将不同方位的眼底广角影像送入预先训练好的病灶检出模型,得到每张眼底广角影像的病灶检出结果；S3：将带有病灶检出结果的不同方位的眼底广角影像进行拼接合并,得到最终的拼接图像；S4：根据最终的拼接图像得到眼底视网膜分区；S5：在分区后的图像中可视化病灶检出结果和分区标识,并按照病灶类型给出分期结果。本发明实现自动检出病灶、多方位图像拼接融合、分区、分期以及各亚型识别的完整诊断流程。</td>   <td>1.一种早产儿视网膜病变检测方法,其特征在于,包括以下步骤：S1：获取待筛查个体的左右两边不同方位的眼底广角影像；S2：以待筛查个体为单位将不同方位的眼底广角影像送入预先训练好的病灶检出模型,得到每张眼底广角影像的病灶检出结果；S3：将带有病灶检出结果的不同方位的眼底广角影像进行拼接合并,得到最终的拼接图像；S4：根据最终的拼接图像得到眼底视网膜分区；S5：在分区后的图像中可视化病灶检出结果和分区标识,并按照病灶类型给出分期结果；所述步骤S3中将带有病灶检出结果的不同方位的眼底广角影像进行拼接合并,具体为：S31：对不同方位的眼底广角影像进行特征匹配,得到稳定匹配的图像对a和b；S32：根据稳定匹配的图像对的匹配点对集合进行迭代拟合得到由图像b到图像a的单映变换矩阵H和匹配得分；S33：依次对不同方位眼底图像进行两两配对,得到所有匹配得分并进行排序,对最高得分的图像对进行拼接融合,并根据匹配得分确定拼接是否成功,记录拼接失败的图像id,并保存到列表L中；S34：重复步骤S31至S33的匹配和融合步骤,直到眼底广角影像序列中所有眼底广角影像处理完毕,此时得到不同方位拼接成的眼底视网膜图像Image-1,此时检查记录列表L,将拼接失败的图像id进行重复步骤S31至S33一次,得到拼接图像Image-2,将Image-1和Image-2按照步骤S31至S33进行拼接得到最终的拼接图像；所述步骤S33中对最高得分的图像对进行拼接融合,具体为：S331：对图像b利用单映变换矩阵H进行仿射变换得到图像b’；S332：分别计算图像a和图像b’中视网膜区域的外接圆,得到圆心和半径信息；S333：拼接融合过程按照越靠近彼此边缘权重越低,靠近图像中心权重越高的原则进行融合,融合过程将融合区域分为相交非边界、相交边界和不相交三种类型：①不相交区域,分别利用图像a和图像b’对应的像素值进行对应区域填充；②相交非边界区域,计算当前位置对应图像a和图像b’中圆心的距离La和Lb’,根据两个距离的比值设置来自图像a和图像b’的像素填充权重；③相交边界区域,同样计算La和Lb’,此时引入阈值t对La和Lb’的得到的权重进行压缩或拉伸处理,根据最后的权重完成像素填充。</td>   <td>G06T7/00;G06T3/40;G06V10/25;G06V10/774;A61B3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>              黄慧玲       </td>   <td>中山大学附属第一医院</td>   <td>一种心脏风险评估系统、设备及介质</td>   <td>广东省</td>   <td>CN115458172B</td>   <td>2023-04-28</td>   <td>本申请公开了一种心脏风险评估系统、设备及介质,属于计算机领域,包括：数据采集模块,采集测试者在多个维度的评估数据；维度分析模块,根据评估数据,确定多个维度分别对应的风险指数或评估系数；风险确认模块,根据风险指数和评估系数,确定测试者对应的心脏风险级别。在多个维度中,从个人信息,病史信息,症状信息,家庭信息和日常作息信息等方面的内容能够更加全面对测试者的心脏风险进行评估,通过数据之间的相关性,来进行最终风险总分的计算,增加评估准确度。不仅仅提供风险评估的系统,还为风险的分析,提供了多个维度的统计数据,从而可以从年龄,性别,年纪,病症,日常习惯等等方面来分级统计产生心脏风险的可能性。</td>   <td>1.一种心脏风险评估系统,其特征在于,包括：数据采集模块,采集测试者在多个维度的评估数据,所述多个维度包括基础信息、心脏相关一般问题、心脏健康问题、遗传健康问题、运动作息信息中的至少多个；维度分析模块,根据所述评估数据,确定所述多个维度分别对应的风险指数或评估系数；风险确认模块,根据所述风险指数和评估系数,确定所述测试者对应的心脏风险级别；所述数据采集模块,针对所述基础信息,采集测试者的个人信息、居住环境中的至少一个子维度的评估数据；针对所述心脏相关一般问题,采集测试者的运动限制、持续健康问题中的至少一个子维度的评估数据；针对所述心脏健康问题,采集测试者的晕厥、胸痛、心悸、心血管疾病、心脏检查、呼吸困难、特定情境影响、疲劳气喘中的至少一个子维度的评估数据；针对所述遗传健康问题,采集测试者的家人的心源性猝死、遗传性心脏疾病、需要植入起搏器或除颤器的心脏疾病、不明原因的晕厥癫痫溺水中的至少一个子维度的评估数据；针对所述运动作息信息,采集测试者近期预设时间段内的运动信息、作息信息中的至少一个子维度的评估数据；所述维度分析模块,根据所述基础信息、所述心脏相关一般问题、所述运动作息信息对应的评估数据,确定对应的评估系数；根据所述心脏健康问题、所述遗传健康问题对应的评估数据,确定对应的风险指数；所述风险确认模块,针对各风险指数,通过其对应的评估系数对该风险指数进行加成；将经过评估系数加成后的风险指数相加后,与剩余的评估系数结合得到风险评估总分；其中,通过第一评估系数、第二评估系数进行加成,剩余的评估系数包括第三评估系数、第四评估系数、第五评估系数、第六评估系数、第七评估系数；根据所述风险评估总分,以及各心脏风险级别对应的阈值范围,确定所述测试者对应的心脏风险级别；所述风险确认模块,针对所述晕厥、所述胸痛、所述心悸、所述心血管疾病、所述心脏检查、所述呼吸困难、所述特定情境影响,通过第一评估系数进行加成,所述第一评估系数通过所述运动限制得到；针对所述疲劳气喘,通过第二评估系数进行加成,所述第二评估系数通过所述作息信息中的睡眠质量得到；针对所述需要植入起搏器或除颤器的心脏疾病,将其对应的风险指数设置为1。</td>   <td>G16H50/30;G16H10/60;A61B5/02;A61B5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏文康;              倪江群;              孙一言;                   卢俊雄       </td>   <td>中山大学</td>   <td>一种基于小波神经网络的图像大容量鲁棒水印方法</td>   <td>广东省</td>   <td>CN116029887A</td>   <td>2023-04-28</td>   <td>本发明针对现有技术的局限性,提出了一种基于小波神经网络的图像大容量鲁棒水印方法,在网络结构上进行了改进,采用了小波变换操作和小波逆变换操作来分别替代普通的卷积上采样和下采样操作,这种改进能使得网络在下采样时能够保留更多的高频信息,以及对噪声更加鲁棒。</td>   <td>1.一种基于小波神经网络的图像大容量鲁棒水印方法,其特征在于,通过以下步骤进行水印嵌入：S11,获取水印信息以及载体图像；S12,对所述水印信息进行维度扩充；S13,将维度扩充的结果与所述载体图像拼接后,输入经过训练的基于小波神经网络的编码器中,获得残差图像；S14,将所述残差图像与载体图像相加得到水印图像。</td>   <td>G06T1/00;G06T3/40;G06T5/10;G06T5/20;G06N3/04;G06N3/084;G06N3/094;H04N19/467</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伍伟文;              龙逸飞;              张俭嘉;                   潘嘉毅       </td>   <td>中山大学</td>   <td>一种低剂量DR图像和CT图像去噪方法</td>   <td>广东省</td>   <td>CN116029934A</td>   <td>2023-04-28</td>   <td>本发明公开了一种低剂量DR图像和CT图像去噪方法,通过构造初始去噪网络；获取训练图像；其中,训练图像是低剂量DR图像或CT图像的噪声图像；构建余数采样器,通过余数采样器对训练图像进行采样,得到训练图像组；根据训练图像组对初始去噪网络进行训练,能够完整运用噪声图像,不丢失信息地进行去噪网络的训练,得到实用、高精度的目标去噪网络,再通过使用该目标去噪网络对单张低剂量DR图像或CT图像进行去噪处理,能够实现全域无损去噪的效果,并且能够适应复杂的CT和DR带噪声图像去噪任务。本发明实施例可以广泛应用于图像去噪技术领域。</td>   <td>1.一种低剂量DR图像和CT图像去噪方法,其特征在于,包括：构造初始去噪网络；获取训练图像；其中,所述训练图像是低剂量DR图像或CT图像的噪声图像；构建余数采样器,通过所述余数采样器对所述训练图像进行采样,得到训练图像组；根据所述训练图像组对所述初始去噪网络进行训练,得到目标去噪网络；通过所述目标去噪网络对单张低剂量DR图像或CT图像进行去噪处理。</td>   <td>G06T5/00;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丘昌镇;              徐雪阳;              张志勇;                   刘紫薇       </td>   <td>中山大学</td>   <td>一种基于信息融合的目标检测方法及装置</td>   <td>广东省</td>   <td>CN116030086A</td>   <td>2023-04-28</td>   <td>本申请公开了一种基于信息融合的目标检测方法及装置,本申请提供的目标检测方法,首先进行了四通道阈值分割,随后利用D-S证据理论对四通道的分割结果进行了融合并对融合后的图像进行二值化处理,然后通过区域膨胀方法弥补了融合过程中的信息损失,结合线段连通判定条件,确定二值化图像中的各个线段间的连通关系,得到若干个连通域,最后计算连通域的平均概率分配值,以基于各个连通域的平均概率分配值确定目标图像中的目标物体,检测过程不需要依赖于大量数据的训练,也不需要长时间的等待算法训练完成,解决了现有的目标检测方法耗时长的技术问题。</td>   <td>1.一种基于信息融合的目标检测方法,其特征在于,包括：获取待处理的目标图像；遍历所述目标图像中的像素点,确定各个所述像素点的四个通道的参数值,其中所述四个通道具体为：R通道、G通道、B通道以及V通道；通过预设的图像阈值分割方法,分别计算四个通道的图像分割阈值,并根据各个所述图像分割阈值进行自适应分割,得到各个通道对应的分割图像；通过D-S证据理论,对各个所述分割图像进行融合,得到融合图像；对所述融合图像进行二值化,得到二值化图像；通过区域膨胀处理方式,对所述二值化图像进行补偿,并基于补偿后的二值化图像,结合线段连通判定条件,确定所述二值化图像中的各个线段间的连通关系,再根据所述各个线段间的连通关系,对所述线段进行相连,并对相连线段所属的连通域进行合并；计算所述连通域的平均概率分配值,以基于所述平均概率分配值识别所述目标图像中的目标物体。</td>   <td>G06T7/136;G06T7/187;G06T5/30;G06T7/90;G06T7/11;G06V10/28;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘文阁;              程轶;              刘亚飞;              蔡庆玲;              梁小丹;              郑冶枫;                   王巨宏       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>一种领域语言模型的确定方法和相关装置</td>   <td>广东省</td>   <td>CN116028632A</td>   <td>2023-04-28</td>   <td>本申请实施例公开了一种领域语言模型的确定方法和相关装置,在需要获取针对专业领域的语言模型时,获取该专业领域的知识图谱,通过在知识图谱中以规定的路径数量遍历出待定节点周边的关联节点集合,可从图结构化的知识图谱中转化出序列化的图谱知识语料,图谱知识语料可以被语言模型所理解并学习到其中携带的专业领域知识,从而可以使用已经完成了通用语言预训练的预训练语言模型直接基于序列化的图谱知识语料进行领域训练,使已经掌握通用语言知识的预训练语言模型学习到该专业领域的语言知识,不仅训练所需语料量要求更低,而且由于预训练语言模型已经完成了预训练,整体训练耗时也更低,大大提高了确定领域语言模型的效率,降低了时间成本。</td>   <td>1.一种领域语言模型的确定方法,其特征在于,所述方法包括：获取专业领域的知识图谱,所述知识图谱包括用于标识所述专业领域中专业词汇的实体节点,连接所述实体节点的路径用于标识所连接实体节点间的关联关系；基于从所述实体节点中确定出的待定节点,在所述知识图谱中遍历得到与所述待定节点对应的关联节点集合,所述关联节点集合中的关联节点为所述知识图谱中与所述待定节点间的路径数量小于或等于K的实体节点；根据所述待定节点、所述关联节点集合以及所述待定节点与所述关联节点间的关联关系,序列化得到多个图谱知识语料；通过所述多个图谱知识语料对预训练语言模型进行领域训练,得到针对所述专业领域的领域语言模型,所述预训练语言模型为完成了预训练的通用语言模型。</td>   <td>G06F16/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐彩霞;              苏培强;              李船;              田丽如;                   郭维民       </td>   <td>中山大学附属第一医院</td>   <td>一种小鼠骨质疏松症模型的构建方法和应用</td>   <td>广东省</td>   <td>CN116030985A</td>   <td>2023-04-28</td>   <td>本发明涉及生物技术领域,具体公开了一种小鼠骨质疏松症模型的构建方法和应用。本发明首次证明小鼠骨髓间充质干细胞(MSCs)中Mapk7基因的条件性敲除会诱导骨质疏松的病理学特征,并进一步阐明了Mapk7基因敲除通过抑制Wnt/β-catenin通路活性导致MSCs的成骨分化减弱,成脂分化增强及骨质疏松症的发生。本发明的技术方案即明确了诱导骨质疏松的靶向基因,又运用条件性基因敲除等手段改变目的基因模拟出近似人类骨质疏松的症状和体征,阐明Mapk7基因特异靶向作用于MSCs的成骨成脂分化调控骨质疏松发生的分子机制。</td>   <td>1.一种小鼠骨质疏松症模型的构建方法,其特征在于,包括以下步骤：1)确定消除待敲除基因的特异性靶位点,利用Cre重组酶敲除Mapk7基因,构建纯合子Mapk7～(fl/fl)小鼠；2)将纯合子Mapk7～(fl/fl)小鼠和Prx1-cre小鼠杂交,获得F1代Prx1-Cre/Mapk7～(fl/wt)小鼠,将F1代Prx1-Cre/Mapk7～(fl/wt)小鼠和纯合子Mapk7～(fl/fl)小鼠杂交,构建Prx1-Cre/Mapk7～(fl/fl)条件性基因敲除小鼠,利用特异性引物通过PCR的方法进行基因型的鉴定。</td>   <td>G16H50/50;G16B20/30;G16B25/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄敏;              钱宇翔;                   周锦荣       </td>   <td>中山大学</td>   <td>一种个体行程时间短期预测方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN111582563B</td>   <td>2023-04-25</td>   <td>本发明公开了一种个体行程时间短期预测方法、系统、装置及存储介质,方法包括：构建个体出行数据集；计算各个时间窗下各个路段的交通状态；获取每个驾驶员在所述各个交通状态下的驾驶行为,确定每个驾驶员在各个交通状态下的驾驶偏好；根据所述各个时间窗下各个路段的交通状态对下一时间窗的交通状态进行预测；基于预测得到的下一时间窗的交通状态,结合所述驾驶员在各个交通状态下的驾驶偏好,确定驾驶员的路段行程时间预测值；对所述路段行程时间预测值进行误差分析,确定驾驶员的驾驶行为概率。本发明考虑了不同交通状态的驾驶员偏好的不同,提高了驾驶员偏好的预测准确率,可广泛应用于交通数据处理技术领域。</td>   <td>1.一种个体行程时间短期预测方法,其特征在于,包括：获取每个驾驶员在每个时间窗对应路段下的行程时间,构建个体出行数据集；基于每个时间窗下的平均行程时间及对应的出行交通量,计算各个时间窗下各个路段的交通状态；获取每个驾驶员在所述各个交通状态下的驾驶行为,确定每个驾驶员在各个交通状态下的驾驶偏好；根据所述各个时间窗下各个路段的交通状态对下一时间窗的交通状态进行预测；基于预测得到的下一时间窗的交通状态,结合所述驾驶员在各个交通状态下的驾驶偏好,确定驾驶员的路段行程时间预测值；对所述路段行程时间预测值进行误差分析,确定驾驶员的驾驶行为概率；所述基于每个时间窗下的平均行程时间及对应的出行交通量,计算各个时间窗下各个路段的交通状态,包括：获取各个时间窗下各个路段的交通量；计算各个时间窗下各个路段的平均速度；根据所述交通量和所述平均速度,确定各个时间窗下各个路段的初始交通状态；根据所述初始交通状态,通过K-Means聚类方法获取各个路段下的聚类中心；根据所述平均速度对所述各个路段下的聚类中心进行排序,构建各个路段的状态序列集合；根据所述状态序列集合,计算各个时间窗下各个路段的交通状态；所述获取每个驾驶员在所述各个交通状态下的驾驶行为,确定每个驾驶员在各个交通状态下的驾驶偏好,包括：计算各个时间窗下驾驶员在各个路段的初始驾驶偏好,并记录各个时间窗下各个路段所处的状态标记；对处于不同状态标记下的初始驾驶偏好进行分组聚合,得到不同状态标记下的驾驶偏好集合；根据所述驾驶偏好集合,计算驾驶员在各个路段上对应于不同状态下的驾驶偏好；根据所述驾驶偏好,构建驾驶员偏好矩阵。</td>   <td>G06Q10/04;G06F18/23213;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              蔡佳辉;              王金鹏;              陈嘉敏;                   林佳玲       </td>   <td>中山大学;广州智慧城市发展研究院</td>   <td>一种基于通道信息共享残差模块的实时语义分割方法</td>   <td>广东省</td>   <td>CN111553921B</td>   <td>2023-04-25</td>   <td>本发明涉及计算机视觉领域,公开了一种基于通道信息共享残差模块的实时语义分割方法,其包括步骤：将特征图X通过二维通道信息共享残差模块经通道分裂进行分组操作,分成X1和X2两组；将分组X1连续经过两个不带空洞卷积的3*1和1*3的卷积核进行卷积操作,再经过带空洞卷积的3*1和1*3卷积核进行卷积操作,得到输出Y1；将输出Y1和输入X2进行拼接,再进行一系列带空洞卷积和不带空洞卷积的3*1和1*3的卷积核进行卷积操作,输出Y2；拼接Y1和Y2后,将各通道洗牌打乱；将实时语义分割网络中的编码器学习到的语义特征映射到高分辨率的特征图上,获得密集预测。该方法可对输入的特征图进行实时精确地分割,有效降低了整个网络的参数量,提高了计算效率,提高了特征图的实时分割精度。</td>   <td>1.一种基于通道信息共享残差模块的实时语义分割方法,其特征在于,包括以下步骤：S1、将特征图X通过二维通道信息共享残差模块经通道分裂进行分组操作,分成两组,分别为X1和X2；S2、将第一个分组X1连续经过两个不带空洞卷积的3*1和1*3的卷积核进行卷积操作,再经过带空洞卷积的3*1和1*3卷积核进行卷积操作,得到第一组分组的输出Y1；S3、将输出Y1和第二分组的输入X2进行拼接,再进行一系列带空洞卷积和不带空洞卷积的3*1和1*3的卷积核进行卷积操作,输出Y2；S4、拼接Y1和Y2后,将各通道洗牌打乱；S5、将实时语义分割网络中的编码器学习到的语义特征映射到高分辨率的特征图上,获得密集预测；其中,在所述步骤S1中,所述二维通道信息共享残差模块的表达式为：X1＝X[:,:C/2,:,:]；X2＝X[:,C/2:,:,:]；Y1＝f-(1-d1)(f-1(X1))；                                    其中,C为输入特征的通道数,f-1(·)为3×1和1×3卷核的卷积操作和一系列的ReLU、批量归一化BN操作,f-(1-d1)(·)为指扩张率为d1的3×1和1×3卷积核的空洞卷积操作和一系列的ReLU、批量归一化BN操作,f-2(·)为1×3和3×1卷核的卷积操作和一系列的ReLU、批量归一化BN操作,f-(2-d2)(·)为指扩张率为d2的1×3和3×1卷积核的空洞卷积操作和一系列的ReLU、批量归一化BN操作,为指特征通道的拼接操作,shuffle(·)为输入的特征通道洗牌操作,括号中为通道数。</td>   <td>G06T7/10;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         熊会元;              钱沛聪;              马健;              潘跃龙;              刘羽;              李同同;                   尹文成       </td>   <td>中山大学;中广核工程有限公司</td>   <td>特种场景的多传感器动态加权融合的点云地图构建方法</td>   <td>广东省</td>   <td>CN112950781B</td>   <td>2023-04-25</td>   <td>本发明提出了一种对最大后验概率目标函数中各传感器约束项进行动态加权以提高轨迹精度的方法,用于构建包含室外环境、室内环境和信号屏蔽区域的特种场景点云地图。在GNSS覆盖下,以载体位置与卫星定位的欧氏距离最小化为目标构造卫星定位约束,并根据激光里程计与GNSS精度因子调整其权重来减小卫星定位误差对点云地图的影响；在GNSS盲区下,以载体姿态与惯性测量数据构成的预期重力方向与实际重力方向的夹角最小化为目标构造姿态约束,并根据载体加速度大小调整其权重,解决由于缺乏全局位置观测导致点云地图高程累积误差大的问题。以激光里程计为基础,使用位姿图优化方法整合所述约束并求解载体位姿,拼接关键帧点云以准确生成所述特种场景点云地图。</td>   <td>1.一种特种场景的多传感器动态加权融合的点云地图构建方法,其特征在于,其通过设有激光雷达、卫星定位设备以及惯性测量单元的载体在预定的室内外环境中进行数据采集和激光扫描,根据激光扫描得到的点云构建所述载体移动轨迹范围内的点云地图；包括以下步骤：S1,所述载体从室外启动,将起点S-0处的载体位姿以固定顶点的方式加入位姿图中,并以起点S-0为坐标原点,以“东向-北向-天向”为基准方向,构建笛卡尔直角坐标系作为全局坐标系,后续卫星定位数据均转换到所述全局坐标系下；S2,在所述载体运动距离大于设定阈值时,将激光雷达的扫描结果记为关键帧,将该关键帧对应的载体位姿作为待求解顶点加入位姿图；根据激光雷达的帧间扫描配准结果来构造激光里程约束,并根据点云配准重合度来调整所述激光里程约束的动态权重；当载体位于室外环境时,根据卫星定位结果与所述载体位置的欧氏距离来构造卫星定位约束,并根据水平精度因子与激光里程信息来调整所述卫星定位约束的动态权重；当所述载体位于室内环境时,根据惯性测量单元的数据并结合载体姿态计算预期重力方向与实际重力方向的夹角来构造姿态约束,并根据所述载体处于静止或匀速状态的置信度来调整所述姿态约束的动态权重；当所述载体从室内返回室外环境时,利用卫星定位结果对历史关键帧进行检索得到闭环候选关键帧,利用当前的关键帧与以闭环候选关键帧为中心的局部子地图进行点云配准,根据配准结果来构造激光闭环约束,并根据点云配准重合度来调整所述激光闭环约束的动态权重；S3,根据包括所述激光里程约束、卫星定位约束、姿态约束、激光闭环约束在内的约束项以及各约束项对应的动态权重,对各项约束相关的变量顶点进行连接,构建位姿图,对位姿图中的所有约束项进行求和得到关于载体轨迹的最大后验概率目标函数,使用非线性优化方法进行求解即对所述位姿图进行求解；S4,根据所述位姿图的求解结果对所述历史关键帧的点云进行拼接,生成点云地图。</td>   <td>G06T17/05;G06T17/20;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         关学新;              沈勇婷;              徐文兵;                   姚清河       </td>   <td>中山大学</td>   <td>基于燃料电池热电联产系统的简易试验模型</td>   <td>广东省</td>   <td>CN110298127B</td>   <td>2023-04-25</td>   <td>本发明提供一种基于燃料电池热电联产系统的简易试验模型,属于氢气制备装置的模拟仿真的技术领域。本发明的简易试验模型,包括了微控制器、热力仿真器和电力仿真器,微控制器内设置有燃料电池动态模型的模拟模块,热力仿真器和电力仿真器分别为模拟燃料电池发热特性和电输出特性的仿真电路,且均受到燃料电池动态模型的模拟模块的控制。本发明可以避免真实的燃料电池测试组件,便面高成本和高安全风险的问题,还优化了电路结构,能够同时对电学和热力学特性进行研究,使得通过不同的模拟模块,就可以实现对不同的燃料电池进行测试,进一步降低生产成本。</td>   <td>1.一种基于真实数据的可对位替代燃料电池装置的,燃料电池热电联产系统的简易试验模型,包括数字控制器、电力仿真器；所述数字控制器内置有燃料电池动态模型的模拟模块；所述电力仿真器为模拟燃料电池电特性的电路；数字控制器与电力仿真器之间具有通信线路；其特征在于：还包括热力仿真器,所述热力仿真器为模拟燃料电池内部热力特性的电路；所述电力仿真器的电路包括电源和可编程电阻,所述电源与数字控制器电性连接,可编程电阻与电源电性连接,所述可编程电阻通过通信线路连接数字控制器；所述电源为直流电压源。</td>   <td>G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              蔡佳辉;              王金鹏;              陈嘉敏;                   林佳玲       </td>   <td>中山大学;广州智慧城市发展研究院</td>   <td>一种基于结合时域通道相关性块的行为识别方法</td>   <td>广东省</td>   <td>CN111325145B</td>   <td>2023-04-25</td>   <td>本发明涉及计算机视觉领域,公开了一种基于结合时域通道相关性块的行为识别方法,通过空间全局平均池化操作对输入的初始特征图进行压缩,获得时域通道描述算子；将时域通道描述算子输入注意力模块获得时域通道全局非线性依赖；将注意力模块输出的张量赋值为经过特征选择后每个通道重要性的权重,通过残差连接将输入的初始特征图与注意力模块输出的张量逐通道相乘得到通道加权之后的特征图。本发明通过网络层有效的捕获时域-通道之间的相关信息,获得一个逐通道描述算子,通过乘法逐通道加权到之前的特征上,完成在通道维度上对原始特征的重新加权,通过将网络的计算资源更多的集中到对输出结果比较重要的特征通道中去。</td>   <td>1.一种基于结合时域通道相关性块的行为识别方法,其特征在于,包括以下步骤：S1、通过空间全局平均池化操作对输入的初始三维时空信号特征图进行压缩,获得一个时域通道描述算子；S2、将时域通道描述算子输入注意力模块获得时域通道全局非线性依赖；S3、将注意力模块输出的张量赋值为经过特征选择后每个通道重要性的权重,通过残差连接将所述步骤S1中输入的初始三维时空信号特征图与所述步骤S2中注意力模块输出的张量逐通道相乘得到通道加权之后的特征图;在所述骤S3中,通过所述注意力模块融合时域-通道信息并提取逐通道信息的过程表示为：Z＝σ(MLP(F))＝σ(W-1(δ(W-0z))；其中,且/&gt;δ和σ分别表示为ReLU和Sigmoid激活函数,r为一个超参数,用于降低注意力模块的参数量；所述注意力模块输出的张量赋值所述的通过残差连接将步骤S1中输入的初始三维时空信号特征图与步骤S2中注意力模块输出的张量逐通道相乘得到通道加权之后的特征图表示为X-c,X-c＝F-(scale)(X,Z)＝X·Z；其中,X＝[x-1,x-2,…,x-C],F-(scale)(X,Z)表示特征图和/&gt;的逐通道相乘。</td>   <td>G06V20/40;G06V10/77;G06V10/80;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑俊炯;              林天歆;              孔坚秋;              卢思弘;                   蔡锦华       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>结合FISH检测的膀胱癌术后复发风险预测方法、装置及介质</td>   <td>广东省</td>   <td>CN116013528A</td>   <td>2023-04-25</td>   <td>本发明公开一种结合FISH检测的膀胱癌术后复发风险预测方法、装置及介质,所述方法包括：从候选临床因素筛选出多个预测因子；根据所述多个预测因子和FISH检测结果构建临床预测模型；根据目标患者的临床资料得到各个预测因子取值；根据所述目标患者的尿液样本确认FISH检测取值；将所述各个预测因子取值和所述FISH检测取值输入所述临床预测模型,得到所述目标患者的复发风险评分；根据所述复发风险评分对所述目标患者的术后复发风险进行预测,得到所述目标患者的危险分层。采用本发明,结合FISH检测进行膀胱癌术后复发风险预测,得到更加精确、可靠的预测结果。</td>   <td>1.一种结合FISH检测的膀胱癌术后复发风险预测方法,其特征在于,包括：从候选临床因素筛选出多个预测因子；根据所述多个预测因子和FISH检测结果构建临床预测模型；根据目标患者的临床资料得到各个预测因子取值；根据所述目标患者的尿液样本确认FISH检测取值；将所述各个预测因子取值和所述FISH检测取值输入所述临床预测模型,得到所述目标患者的复发风险评分；根据所述复发风险评分对所述目标患者的膀胱癌术后复发风险进行预测,得到所述目标患者的危险分层。</td>   <td>G16H50/30;G16H50/70;G06F16/9535</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              林淑金;                   苏卓       </td>   <td>中山大学</td>   <td>一种基于跨模态数据的警情分析方法及系统</td>   <td>广东省</td>   <td>CN116010532A</td>   <td>2023-04-25</td>   <td>本发明涉及大数据分析领域,公开了一种基于跨模态数据的警情分析方法及系统,所述方法包括获取人物图谱数据和线索文本数据。对所述人物图谱数据和线索文本数据进行特征提取,得到人物图谱特征和线索文本特征。分别对所述人物图谱特征和所述线索文本特征进行编码,得到人物图谱编码和线索文本编码。对所述人物图谱编码和所述线索文本编码进行融合,得到融合编码向量。将所述融合编码向量输入训练好的分类网络进行处理,所述分类网络输出警情类别概率。本发明充分利用了多种模态的数据,避免了需获取大量专家知识,能够提高警情分析的精度、准确率和效率。</td>   <td>1.一种基于跨模态数据的警情分析方法,其特征在于,包括：获取人物图谱数据和线索文本数据；对所述人物图谱数据和线索文本数据进行特征提取,得到人物图谱特征和线索文本特征；分别对所述人物图谱特征和所述线索文本特征进行编码,得到人物图谱编码和线索文本编码；对所述人物图谱编码和所述线索文本编码进行融合,得到融合编码向量；将所述融合编码向量输入训练好的分类网络进行处理,所述分类网络输出警情类别概率。</td>   <td>G06F16/28;G06F40/126;G06Q50/26;G06F18/2415;G06F18/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘广;              张涛;                   吕中荣       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种多体机械系统参数识别方法、系统及设备</td>   <td>广东省</td>   <td>CN116011144A</td>   <td>2023-04-25</td>   <td>本发明公开了一种多体机械系统参数识别方法、系统及设备,该方法包括：构建多体系统的动力学方程；采集多体系统的测量响应数据并结合动力学方程进行响应计算,得到计算响应数据；根据计算响应数据和测量响应数据构建最小二乘目标函数；线性化最小二乘目标函数并基于响应灵敏度算法求解满足最小二乘目标函数最小值的最优解,确定多体系统的系统参数。该系统包括：预处理模块、响应数据计算模块、目标函数构建模块和系统参数确定模块。该设备包括存储器以及用于执行上述多体机械系统参数识别方法的处理器。通过使用本发明,能够快速精准地识别出多体机械系统的真实参数。本发明可广泛应用于参数识别领域。</td>   <td>1.一种多体机械系统参数识别方法,其特征在于,包括以下步骤：构建多体系统的动力学方程；采集多体系统的测量响应数据并结合动力学方程进行响应计算,得到计算响应数据；根据计算响应数据和测量响应数据构建最小二乘目标函数；线性化最小二乘目标函数并基于响应灵敏度算法求解满足最小二乘目标函数最小值的最优解,确定多体系统的系统参数。</td>   <td>G06F30/17;G06F30/20;G06F119/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丘金宣;              权小军;                   胡弘康       </td>   <td>中山大学</td>   <td>一种基于融合编码的摘要文本生成方法</td>   <td>广东省</td>   <td>CN109522403B</td>   <td>2023-04-21</td>   <td>本发明提供一种基于融合编码的摘要文本生成方法,包括以下步骤：确定输入句子,将句子中每个词进行映射得到词向量；将句子中每个词经Spacy工具集转换为相应词性特征,通过映射得到词性标注特征；构建生成式文本摘要模型,将词向量、词性标注特征导入模型中,得到摘要序列。本发明提供的一种基于融合编码的摘要文本生成方法,通过生成式文本摘要模型,融合词向量和词性标注特征作为模型输入,有效提升了模型性能；同时将局部信息与全局信息进行融合编码,有利于模型的梯度传递,保证了句子的长期依赖。</td>   <td>1.一种基于融合编码的摘要文本生成方法,其特征在于,包括以下步骤：S1：确定输入句子,将句子中每个词进行映射得到词向量；S2：将句子中每个词经Spacy工具集转换为相应词性特征,通过映射得到词性标注特征；S3：构建生成式文本摘要模型,将词向量、词性标注特征导入模型中,得到摘要序列；在步骤S3中,所述的生成式文本摘要模型包括词嵌入层、融合模块、选择层和解码器；其中：所述词嵌入层用于融合词向量、词性标注特征,得到融合模块的350维融合输入,其中,词向量设定为300维,词性标注特征设定为50维；所述融合模块包括局部编码层、全局编码层和融合层；其中,所述局部编码层由双向门控循环单位GRU组成,通过双向GRU获取融合输入信息的上下文局部表征H,其维度为300×m,m维输入句子的总词数；所述全局编码层由多头自注意力层组成,通过6个线性变换将300维的上下文局部表征H映射维6个50维的子表征Q-i,其中i＝1,2,...,6,再使用放缩点积注意力计算每个子表征的长期依赖特征,最后通过矩阵拼接融合所有子表征的全局信息,得到上下文全局表征G,其维度为300×m；所述融合层用于将上下文局部表征H与上下文全局表征G直接相加,获得融合编码；所述选择层通过神经网络的sigmoid函数筛选融合编码中的重点信息,将重点信息保留突出；所述解码器通过门控循环单位GRU进行解码,最终得到摘要序列。</td>   <td>G06F16/34;G06N3/0464;G06N3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;                   刘稳       </td>   <td>中山大学</td>   <td>结合生成对抗网络的半监督视网膜OCT图像层分割方法</td>   <td>广东省</td>   <td>CN110443815B</td>   <td>2023-04-21</td>   <td>本发明属于计算机视觉、图像处理技术,为结合生成对抗网络的半监督视网膜OCT图像层分割方法,包括步骤：准备视网膜OCT图像数据,将部分病人的标注图片和全部病人的未标注图片作为训练集,其余病人的标注图片作为测试集；构建生成对抗网络,生成对抗网络包括分割网络和鉴别器网络,分割网络的输出端与鉴别器网络的输入端连接；设计生成对抗网络的损失函数；设置评估指标；利用所设计的损失函数,引入所准备的训练集,对生成对抗网络进行训练。本发明同时利用标注数据和未标注数据对生成对抗网络进行训练,增强了网络的鲁棒性,提高了语义分割的准确率。</td>   <td>1.结合生成对抗网络的半监督视网膜OCT图像层分割方法,其特征在于,包括以下步骤：S1、准备视网膜OCT图像数据,将部分病人的标注图片和全部病人的未标注图片作为训练集,其余病人的标注图片作为测试集；S2、构建生成对抗网络,生成对抗网络包括分割网络和鉴别器网络,分割网络的输出端与鉴别器网络的输入端连接；S3、设计生成对抗网络的损失函数；S4、设置评估指标；S5、利用所设计的损失函数,引入步骤S1所准备的训练集,对生成对抗网络进行训练；步骤S3中所设计的损失函数包括分割网络的损失函数和鉴别器网络的损失函数；分割网络的损失函数为：L-(seg)＝λ-(ce)L-(ce)+λ-(dice)L-(dice)+λ-(adv)L-(adv)+λ-(semi)L-(semi)其中,λ-(ce)、λ-(dice)、λ-(adv)及λ-(semi)分别为权重系数；L-(ce)和L-(dice)都是计算分割网络的输出和标签Y-(Oh)之间的损失,L-(ce)代表加权交叉熵损失函数；L-(semi)表示半监督训练损失函数；标签Y-(Oh)为对原始标签采用one-hot编码后得到的标签；L-(adv)是对抗损失函数；                  分割网络预测x-n～((h,w))像素属于c类的概率为S(X-n)～((h,w,c)),当前像素的权重为W-n～((h,w))；为每个像素引入一个权重W-n：                  其中I(logic)表示当logic为真时,I(logic)＝1,否则I(logic)＝0；考虑到不同层识别难度不一样,当L＝1、2、5、6或7时,λ-2＝5；当L＝3、4或9时,λ-2＝15；否则λ-2＝0；L-(dice)代表Dice系数损失函数,定义如下：                  步骤S4采用Dice系数评估每张OCT图片中每个类的重叠情况,Dice系数的计算方式如下：                  其中,Dice-c表示第c类的Dice系数。</td>   <td>G06T7/11;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         叶梅;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于强化学习的中文命名实体识别模型及其训练方法</td>   <td>广东省</td>   <td>CN110826334B</td>   <td>2023-04-21</td>   <td>本发明涉及一种基于强化学习的中文命名实体识别模型及其训练方法,模型包括策略网络模块、分词重组网络和命名实体识别网络模块；先是策略网络指定动作序列,然后分词重组网络会逐个执行该动作序列中的动作,通过“终止”动作得到一个短语,将该短语作为辅助的输入信息,进行lattice-LSTM建模得到隐状态序列,并将该隐状态输入到命名实体识别网络,得到句子的标签序列,并将识别结果作为延迟奖励指导策略网络模块的更新。本发明利用强化学习对句子进行有效划分,避免对句子中匹配出的多余干扰词语进行建模,以及有效避免对外部词典的依赖和长文本的影响,能够更好地利用这些正确的词语信息,更好地帮助中文命名实体识别模型提高识别效果。</td>   <td>1.一种基于强化学习的中文命名实体识别模型的训练方法,其特征在于,包括以下步骤：步骤一：将用于训练的句子数据输入策略网络模块,策略网络模块在各个状态空间下对句子中的每个字采样一个动作,输出整个句子的动作序列；步骤二：分词重组网络根据所述策略网络模块输出的动作序列,对句子进行划分,将句子断开成一个个短语,将短语进行编码和该短语的最后一个字的编码向量结合,从而得到字的lattice-LSTM表征；字是通过LSTM来进行字符层面的表征,并根据终止得到一个个短语,更新公式如下所示：                  其中,表示LSTM的转换函数；x-t表示句子t时刻输入的字的编码向量；/&gt;和/&gt;分别表示时刻t时的细胞状态和隐藏状态；在完成句子的划分后,将短语信息整合进基于字粒度的LSTM模型中,基于字粒度的LSTM模型是基本的循环LSTM函数,如下：                                                      其中,表示句子中第j个字的编码向量；/&gt;表示句子第j-1个字时刻的隐藏状态；W～(cT)和b～c是模型参数；/&gt;分别代表输入、忘记和输出门；/&gt;表示新的候选状态；/&gt;表示句子第j-1个字时刻的细胞状态；/&gt;表示更新后的细胞状态；/&gt;表示句子第j个字时刻的隐藏状态；由输出门/&gt;和当前时刻的细胞状态/&gt;决定；σ()表示sigmoid函数,tanh()表示双曲正切激活函数；短语信息通过没有输出门的LSTM模型进行表征,具体的公式如下：                                    其中,表示句子中从第b个字开始到第w个字结束的短语的编码向量；/&gt;表示句子第b个字时刻的隐藏状态,即短语第一个字的隐藏状态；W～(wT)和b～w是模型参数；/&gt;分别代表输入和忘记门；/&gt;表示新的候选状态；/&gt;表示短语第一个字的细胞状态；/&gt;表示更新后的细胞状态；σ()表示sigmoid函数；tanh()表示双曲正切激活函数；另外增加一个附加门对字粒度和词粒度信息进行选取,输入为字的编码向量和以该字结尾的短语的细胞状态,公式定义如下：                  其中,表示句子中第e个字的编码向量；/&gt;表示从第b个字开始到第e个字结束的短语的细胞状态,即句子中以第e个字为词尾的短语的细胞状态；W～(lT)和b～l是模型参数；/&gt;表示附加门；σ()表示sigmoid函数；          的更新方式就变了,隐藏状态的更新没有变化,基于lattice-LSTM模型的表征最终公式如下：                  其中,为第j个字的输入门向量；/&gt;为从b开始以j结尾的短语的输入门向量；/&gt;为短语细胞状态；/&gt;为字的新候选细胞状态；/&gt;为短语信息向量；为字信息向量；步骤三：命名实体识别网络从所述分词重组网络得到的隐藏状态输入到条件随机场层中,最后得到命名实体识别结果,并根据识别结果计算得到一个损失值用来训练命名实体识别模型,同时将该损失值作为延迟奖励指导所述策略网络模块的更新；句子通过lattice-LSTM模型进行表征,就会得到句子中每个字的隐藏状态向量h-i,然后将该状态向量序列H＝{h-1,h-2,…,h-n}输入条件随机场层；令y＝l-1,l-2,…,l-n表示条件随机场层的输出标签,输出标签序列概率通过下式计算：                  其中,s表示句子；是针对于l-i的模型参数；/&gt;是针对于l-(i-1)和l-i的偏置参数；y′表示所有可能的输出标签集合；损失值函数的计算公式为：                  其中,λ为L-2正则项系数；θ表示参数集；s和y分别表示句子和该句子对应的正确的标注序列；P表示为句子s标注为序列y的概率,即标注正确的概率。</td>   <td>G06F40/295;G06N3/0464;G06N3/08;G06N3/0442</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;                   陈雅迪       </td>   <td>中山大学</td>   <td>一种结合时间因子的社交网络高影响力用户识别方法</td>   <td>广东省</td>   <td>CN110992195B</td>   <td>2023-04-21</td>   <td>本发明提供一种结合时间因子的社交网络高影响力用户识别方法,包括以下步骤：S1.通过用户的社交关系和互动行为抽象出社交网络图模型；S2.根据抽象出的社交网络图模型,对社交网络图进行分解识别,识别出社交网络图的关键节点(k,h)-核,其中(k,h)-核中的每个节点都有大于等于k个邻居,同时与每个邻居之间都有大于等于h条边；S3.动态识别出S2所得的关键节点并做最小调整。本发明充分考虑了用户之间社交关系的强弱对用户影响力的作用,同时结合时间信息,可以挖掘出指定时间范围内的高影响力用户,也可用于用户影响力变化的研究。</td>   <td>1.一种结合时间因子的社交网络高影响力用户识别方法,其特征在于,包括以下步骤：S1.通过用户的社交关系和互动行为抽象出社交网络图模型；S2.根据抽象出的社交网络图模型,对社交网络图进行分解识别,识别出社交网络图的关键节点(k,h)-核,其中(k,h)-核中的每个节点都有大于等于k个邻居,同时与每个邻居之间都有大于等于h条边；所述的社交网络图模型中,一个节点的邻居数并不等于其度数,则使用表示一个节点u的邻居集合,使用表示任意两个节点u和v之间的边；S3.动态识别出S2所得的关键节点并做最小调整；其具体步骤如下：S31.输入上一时刻t-1时的(k,h)-核集合T-(t-1)、多重边时态图G-t；S32.若当前时刻t时的社交网络所抽象出图G-t为出现新的边或节点,则新的边及其节点所组成的图即为插入子图,在上一计算时刻所得的(k,h)-核的基础上根据插入子图进行最小调整,计算出当前时刻的(k,h)-核集合T-t；否则进入步骤S33；S33.若当前时刻t时的社交网络所抽象出的图G-t中会有很多边消失,由消失的边及其对应节点所组成的图即为删除子图；在上一计算时刻已得到的(k,h)-核的基础上根据删除子图做最小调整,计算出当前时刻的(k,h)-核集合T-t；其中,所述的S32包括以下步骤：S321.计算当前时刻t时插入子图S-i在多重边时态图G-t上的邻居子图对于插入子图S-i中的所有节点在图G-t中的对应节点,记录图G-t中其任意两节点之间的边以及任意节点的邻居及之间的边,得到邻居子图/&gt;S322.令q为一个空的队列,将上一时刻的(1,1)-核与中的类似(1,1)-核合并,插入队列q中；S323.输出队列q中第一个元素图Q-+,得到当前计算的k,h值；S324.若将/&gt;中的节点加入空队列q-2,取出队列中的第一个节点u,其中/&gt;S325.当同时/&gt;上一时刻t-1时的(k+1,h)-核,则将/&gt;加入到/&gt;否则进入S327；S326.若则将v加入到/&gt;将v加入到队列q-2,/&gt;即为F(k+1,h)；S327.若P(k+1,h)不是空图,将上一时刻t-1时的(k+1,h)-核与P(k+1,h)合并,结果放入集合T-t和队列q中；否则使用上节提到的分解算法在F(k+1,h)中识别出当前时刻t的(k+1,h)-核；S328.若当前时刻t的(k+1,h)-核不为空,将当前时刻t的(k+1,h)-核放入集合T-t和队列q中；S329.若则执行步骤S324至S328,但此时将步骤S324至S328中所有的k+1替换为k,所有的h替换为h+1。S3210.输出集合T-t。</td>   <td>G06Q50/00;G06F16/906</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   刘颀       </td>   <td>中山大学</td>   <td>一种基于显著性检测的颜色迁移方法及系统</td>   <td>广东省</td>   <td>CN111080722B</td>   <td>2023-04-21</td>   <td>本发明公开了一种基于显著性检测的颜色迁移方法及系统,包括以下步骤：区分出输入图像的前景和背景；计算出前景和背景的主题颜色；将前景主题颜色和背景主题颜色进行合并；将输入图像每个像素重新划分进最终主题色谱；根据用户需求对输入图像进行重新着色。通过先将输入图像的前景和背景区分开,再分别提取前景和背景的主题颜色,这使得主题颜色提取能更加准确,更加适用于布料图片；同时,通过根据用户需求,灵活地调整主题颜色,减少生产布料所需的成本,帮助用户高效地找到最满意的配色方案；此外,本方法不仅能够将目标颜色准确应用到特定的图像区域,还能够高度保留布料纹理特征,且算法的计算效率较高,适用于工业场景。</td>   <td>1.一种基于显著性检测的颜色迁移方法,其特征在于,具体包括以下步骤：步骤S1,输入图像,并通过显著性检测区分出输入图像的前景和背景；步骤S2,基于颜色空间计算出前景和背景的主题颜色；步骤S3,将前景主题颜色和背景主题颜色进行合并,得到最终主题色谱；步骤S4,依据色差将输入图像每个像素重新划分进最终主题色谱；步骤S5,根据用户需求修改最终主题色谱,得到修改后的主题色谱,并依据修改后的主题色谱对输入图像进行重新着色；其中,所述步骤S1包括以下步骤：步骤S11,采用基于聚类的协同显著度检测方法获得输入图像的显著度图；步骤S12,确定用于划分前景区域和背景区域的像素阈值；步骤S13,通过确定的像素阈值对输入图像的显著度图进行划分,获得输入图像的前景区域和背景区域；所述步骤S12包括以下步骤：步骤S121,获取显著度图的全图灰度最小值和全图灰度跨度；步骤S122,利用公式：像素阈值＝全图灰度最小值+全图灰度跨度×1/5,得到像素阈值；所述步骤S2基于HSV颜色区间计算出前景和背景的主题颜色,具体包括以下步骤：步骤S21,将整个HSV空间划分成42个颜色区间；步骤S22,计算输入图像每个像素的H,S和V的值；步骤S23,根据划分的42个颜色区间,判定每个像素的H,S和V所处的区间；步骤S24,计算出输入图像前景和输入图像背景所属各个颜色空间的像素数量,前景和背景分别取覆盖像素多的颜色区间并分别计算这些颜色区间覆盖像素的HSV均值作为初始的前景和背景主题颜色。</td>   <td>G06T7/90;G06V10/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              谢震宇;              梁小丹;                   董浩业       </td>   <td>中山大学</td>   <td>一种基于混合光流的视频虚拟试穿方法及装置</td>   <td>广东省</td>   <td>CN111275518B</td>   <td>2023-04-21</td>   <td>本发明公开了一种基于混合光流的视频虚拟试穿方法及装置,该方法包括：步骤S1,根据人体图像获得姿态热图,并对人体图像处理得到只保留头部和下半身区域的人体分割图像,将姿态热图、人体分割图像及对应的衣服图像生成目标姿态下的目标人体语义分割图；步骤S2,对人体图像和表示人体姿态的骨架图分别提取人体SMPL模型,并计算两个SMPL模型间的3D光流图；步骤S3,根据示例衣服图像和目标衣服图像的二进制掩模,利用渐进式修正网络预测两者之间的衣服光流图；步骤S4,根据人体分割图像,衣服图像,目标姿态热图,目标人体语义分割图和上一张合成视频帧,在3D光流图和衣服光流图指导下,利用特征融合网络合成当前试穿视频帧。</td>   <td>1.一种基于混合光流的视频虚拟试穿方法,包括如下步骤：步骤S1,根据人体图像获得表示目标姿态的姿态热图,并对所述人体图像处理得到只保留头部和下半身区域的人体分割图像,将所述姿态热图、人体分割图像以及对应的衣服图像利用生成器网络生成目标姿态下的目标人体语义分割图；步骤S2,对人体图像和表示人体姿态的人体姿态骨架图,分别提取其各自的人体SMPL模型,并通过3D顶点匹配的方法,计算两个SMPL模型间的3D光流图；步骤S3,根据示例衣服图像的二进制掩模和目标衣服图像的二进制掩模,利用渐进式修正网络预测示例衣服图像与目标衣服图像之间的衣服光流图；步骤S4,根据所述人体分割图像,衣服图像,目标姿态热图,目标人体语义分割图和上一张合成视频帧,在3D光流图和衣服光流图的指导下,利用特征融合网络合成当前试穿视频帧；步骤S1进一步包括：步骤S100,对所示人体图像,通过人体姿态估计器获得包含若干特征点的姿态图,所述姿态图上每个特征点都被转化为1通道的热图,然后将每个特征点对应的热图按通道拼接起来,得到编码人体姿态信息的姿态热图；步骤S101,对于同一张人体图像,使用人体解析器得到该人体图像的人体语义分割图,根据该人体语义分割图,去除人体图像中上衣,手臂,脖子及背景区域,得到只保留头部和下半身的人体分割图像；步骤S102,将步骤S100获得的姿态热图、步骤S101获得的人体分割图像以及对应的衣服图像拼接起来,一起输进生成器网络,由所述生成器网络生成目标姿态下的目标人体语义分割图；步骤S100进一步包括：步骤S100a,对于所述人体图像,使用人体姿态估计器预测包含18个特征点的姿态图,姿态图上每个特征点都会被转换为1通道的热图,所述热图上以特征点为中心的8*8的区域值为1,其余区域值为0；步骤S100b,将18个1通道的热图按通道拼接在一起, 得到一张18通道编码了人体的姿态信息的姿态热图；于步骤S101中,在得到所述人体语义分割图之后,遍历所述人体语义分割图上每个像素,如果像素值为语义分割图中头部或下半身区域的值,则置为1,否则置为0,将得到的二进制掩模与人体图像进行逐像素相乘,得到只保留头部和下半身区域的人体分割图像；步骤S2进一步包括：步骤S200,利用人体姿态估计器估计出若干关键特征点,并将人体姿态估计器预测到的关键特征点,按照一定的连线规则,将位置相邻的特征点连接起来,得到人体姿态骨架图；步骤S201,使用预训练的HMR模型提取人体图像的3D模型,即人体图像的SMPL模型；步骤S202,使用重新训练的姿态HMR模型提取人体姿态骨架图的3D模型,即姿态图的SMPL模型；步骤S203,将两个SMPL模型分别映射到2D平面,根据两个SMPL模型间3D顶点对应关系,得到2D平面中两张投影图像上像素间的映射关系,从而计算出不同姿态下人体图像的3D光流图。</td>   <td>G06Q30/0601;G06V40/10;G06V10/774;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苟超;              郝坤坤;              卓莹;                   熊宸       </td>   <td>中山大学</td>   <td>基于深度对抗网络的带边界标注信息乳腺肿块图生成方法</td>   <td>广东省</td>   <td>CN111667491B</td>   <td>2023-04-21</td>   <td>本发明提供一种基于深度对抗网络的带边界标注信息乳腺肿块图生成方法,该方法首先从含有肿块病变的乳腺钼靶图片以及对应的肿块标注图片上提取肿块图片和肿块分割图片,并将提取的图片缩放到统一尺寸；然后利用这些提取的图片,根据肿块的形状、大小、边缘、密度来设计肿块图片生成器；最后根据设计的肿块图片生成器,在健康的乳腺钼靶图片上生成形状、大小、边缘、位置都具有多样性的肿块和其对应的肿块标注图片。本发明克服了现有肿块生成方法的不足,充分利用了肿块的病理信息来生成肿块,解决了基于人工智能实现自动诊断过程中医疗图像数据有限且难以标注的问题,大力推动现有人工智能乳腺辅助诊断的研究,具有重大临床意义与实际应用价值。</td>   <td>1.一种基于深度对抗网络的带边界标注信息乳腺肿块图生成方法,其特征在于,包括以下步骤：S1：利用乳腺钼靶数据集中所有含有肿块病变的乳腺钼靶图片以及对应的肿块标注图片,分别提取肿块图片和肿块分割图片,并将提取的图片缩放到统一尺寸；S2：利用步骤S1提取的图片,根据肿块的形状、大小、边缘、密度来设计肿块图片生成器G2,使该生成器能够生成高质量的多样性丰富的肿块图片；S3：利用肿块分割图片,设计肿块分割图片生成器G1来模拟肿块分割区域的形状和大小,并生成无限多的肿块分割图片；S4：利用步骤S3生成的肿块分割图片,模拟其对应于健康乳腺钼靶图片上的位置,并生成肿块标注图片,重复步骤S1中的操作得到提取的健康乳腺组织图片和肿块分割图片；S5：利用步骤S2设计的肿块图片生成器G2在步骤S4中提取到的健康乳腺组织图片上生成肿块,并把生成的肿块还原到健康乳腺钼靶图片的原始位置；对抗损失中,利用基于图像块的判别损失使生成器对图像的局部高频信息进行建模,对抗损失函数表示如下：                  式中,x为三通道输入图像,R为真实肿块图像,G(x)代表生成器生成的肿块图像；特征匹配损失能够使生成器对肿块图像的全局低频特征进行建模,假设用{Φ-l}表示VGG-19卷积神经网络Φ的不同卷积层的集合,特征匹配损失函数被定义如下：                  式中,θ表示生成器的网络参数,Φ-0表示恒等映射,R代表真实的目标图像,x表示三通道输入图像,G(x,θ)代表生成的图像,超参数λ-l平衡每一层对特征损失的贡献；对于Φ-l,l≥1,使用了VGG-19网络中的“conv1-2”、“conv2-2”、“conv3-2”、“conv4-2”和“conv5-2”五个卷积激活层,超参数{λ-l}是被自动设置的,并被初始化为每个层中元素数量的倒数；所述步骤S4中,所述肿块标注图片的生成具体包括以下步骤：S41：模拟真实肿块分割区域的大小：首先计算从数据集中提取的全部未经缩放的肿块分割图片高度的均值和方差；然后利用高斯分布函数生成大量的新的图片高度值；最后利用这些模拟的宽度或高度值对生成的肿块分割图片进行缩放；S42：模拟肿块在健康乳腺钼靶图片上的位置：首先对所有的乳腺钼靶图片做翻转处理,使乳房都在图片的同一侧；假设w是乳腺钼靶图片的宽度,h是乳腺钼靶图片的高度,生成一张分辨率为w×h、像素值全为0的灰度图像,记为image-(anno)；然后使用均匀分布函数来选取生成的肿块分割图片对应于正常乳腺钼靶图片上的横坐标和纵坐标,其中横坐标x～U(w/10,w/2),纵坐标y～U(h/4,×3h)/,最后根据坐标(x,y),把肿块分割标签复原到图片image-(anno)上。</td>   <td>G06T7/11;G06T7/12;G06N3/0464;G06N3/0475;G06N3/048;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   黄观杰       </td>   <td>中山大学</td>   <td>一种基于云数据中心分布式文本摘要方法</td>   <td>广东省</td>   <td>CN112883722B</td>   <td>2023-04-21</td>   <td>本发明提供一种基于云数据中心分布式文本摘要方法,该方法使用无监督学习的方法进行摘要生成,节省了在大规模数据集中收集标签数据所需的巨大人力成本；其次,获得句子向量表示的方法使用层级的BERT模型,即通过单词级别的BERT模型和句子级别的BERT模型来训练得到具有单词和句子两重上下文语义的句子向量,相较于绝大多数通过平均词向量得到句子向量的方法而言,具有更丰富的语义信息,能更好地进行文本摘要生成；使用基于云数据中心的分布式训练方法,流水线的模型并行方法,大大提高了BERT模型训练的速度。</td>   <td>1.一种基于云数据中心分布式文本摘要方法,其特征在于,包括以下步骤：S1：获得单词向量表示；S2：获得句子向量表示；S3：无监督文本摘要生成；S4：ROUGE指标评价摘要的质量；所述步骤S1的具体过程是：利用HuggingFace的单词分割器对文章中的单词进行分割,分割的过程把多余的标点符号去除,同时把单词映射到HuggingFace的BERT模型中的词汇表中,获得每个单词在词汇表中的序号,根据序号,匹配到HuggingFace已经预训练好的单词向量表示,进而获得文档中所有单词的单词向量表示；所述步骤S2的具体过程是：1)、在步骤S1得到单词表示后,得到初级的句子向量：将句子中所有的单词向量取平均得到：其中S-i表示文档中第i个句子,|S-i|表示第i个句子所含的单词数量,/&gt;表示第i个句子的初级向量表示；2)、获取句子位置信息以及句子级别的遮掩令牌,将得到的句子的初级向量表示、句子位置信息以及句子级别的遮掩令牌输入到经过重新设计的句子级别BERT模型中进行训练,将得到富含上下文语义信息的高级句子向量表示在句子级别的BERT模型的实现上将采用分布式的训练方法；采用基于云数据中心模型并行的方法把该BERT模型进行分解,将每一个Transformer层部署到不同的机器上进行训练；将采用流水线的方式,以产生并行训练的效果；在训练时将数据集划分成多个小批次,每个批次依次进入模型来训练,所以将原来的逐批次训练改成多批次同时训练,在整个分布式训练达到稳定状态时,在某个时刻每个机器都有前传或反传的计算任务。</td>   <td>G06F40/279;G06F40/30;G06F18/23213</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周毅;              毛钤镶;                   承垠林       </td>   <td>中山大学</td>   <td>一种CT图像结石数量和体积的计算方法、系统及装置</td>   <td>广东省</td>   <td>CN113096093B</td>   <td>2023-04-21</td>   <td>本发明公开了一种CT图像结石数量和体积的计算方法、系统及装置,该方法包括：对CT图像进行标注处理,得到标注后图像；对标注后图像进行结石分割处理,得到结石切片信息和轮廓信息；根据结石切片信息和预设规则判断不同帧CT图像的结石切片是否属于同一结石,得到切片归属信息；基于轮廓信息和切片归属信息计算结石数量和结石体积。该系统为应用于上述CT图像结石数量和体积的计算方法的模块。通过使用本发明,实现了CT图像中结石的分割及结石数目和体积的测算。本发明作为一种CT图像结石数量和体积的计算方法、系统及装置,可广泛应用于医学图像处理领域。</td>   <td>1.一种CT图像结石数量和体积的计算方法,其特征在于,包括以下步骤：获取多帧CT图像,并对CT图像进行标注处理,得到标注后图像；对标注后图像进行结石分割处理,得到结石切片信息和轮廓信息；所述对标注后图像进行结石分割处理,得到结石切片信息和轮廓信息这一步骤具体包括；根据标注后图像对标注数据进行定位,得到标注框位置；基于阈值分割算法对结石进行分割,得到分割结果和结石切片信息；基于分割结果构建结石轮廓,得到轮廓信息；基于标注框位置和轮廓信息,将结石轮廓映射回原CT图像；根据结石切片信息和预设规则判断不同帧CT图像的结石切片是否属于同一结石,得到切片归属信息；所述预设规则具体为；同一结石在连续帧中存在,非连续帧间的结石切片属于不同结石；同一帧不同结石切片轮廓间不进行判定；连续两帧间非同一帧的结石切片轮廓存在包含、被包含或相交任一关系时即判定为两结石切片属于同一结石；设计查询函数,将得到的全部结石切片的轮廓信息与判定结果进行关联；基于轮廓信息和切片归属信息计算结石数量和结石体积；所述基于轮廓信息和切片归属信息计算结石数量和结石体积这一步骤具体包括；根据轮廓信息计算结石面积和结石数量；根据切片归属信息对属于同一结石的结石面积进行累加,得到像素数目；基于像素点计算方法对每个结石进行体积计算,得到结石体积；CT图像分辨率为512*512,所述基于像素点计算方法对每个结石进行体积计算,得到结石体积这一步骤具体还包括；根据轮廓信息得到结石轮廓；基于fillPoly函数,以结石轮廓点填充轮廓并作为掩膜；计算掩膜像素和,得到层面积；基于像素间距获得真实层面积并乘以层间距进行像素累加,得到结石体积。</td>   <td>G06T7/00;G06T7/136;G06T7/62;G16H30/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘立林;                   胡泽天       </td>   <td>中山大学</td>   <td>一种多ToF相机系统实时配准方法</td>   <td>广东省</td>   <td>CN113112532B</td>   <td>2023-04-21</td>   <td>本发明属于计算机视觉技术领域,更具体地,涉及一种多ToF相机系统实时配准方法,包括多个相机分别实时获取相位与振幅信息,多个相机之间具有重合视野；将相位与振幅信息分别转换为深度图像与红外图像；根据红外图像与深度图像计算得到多个相机的实时位姿关系；根据深度图像得到在相机坐标系下的三维点云信息；根据实时相对位姿与三维点云信息,完成多个相机的三维信息实时配准。本发明中通过特征点匹配求解相机间位姿关系,不需要对多个相机进行标定,适用于多个相机间具有相对运动的情况,且不需要保证多个相机的时序严格同步,降低系统成本,具有较高的实用性。</td>   <td>1.一种多ToF相机系统实时配准方法,其特征在于,包括：S1：多个相机分别实时获取相位与振幅信息,所述多个相机之间具有重合视野；S2：将所述相位与振幅信息分别转换为深度图像与红外图像；S3：根据所述红外图像与深度图像计算得到多个相机的实时位姿关系；所述步骤S3具体包括：S31：对所有红外图像提取特征点；S32：提取所述特征点的描述子；S33：根据所述描述子对所述多个相机中的第一相机对应的红外图像与其余相机对应的红外图像分别进行特征点匹配,并在相应的深度图像上得到匹配点；步骤S33中所述特征点匹配具体包括：S331：计算一张红外图像中每个描述子与另一张红外图像中每个描述子的汉明距离；S332：将步骤S331中得到的所有汉明距离按大小进行排序,将汉明距离最小对应的特征点记为最优点,将汉明距离次小对应的特征点记为次优点；S333：设定第二判断阈值,将所述最优点的描述子的汉明距离除以次优点的描述子的汉明距离得到比较值r；S334：判断r与所述第二判断阈值的大小关系,若r大于第二判断阈值,则剔除当前特征点,若r小于第二判断阈值,则将当前最优点记为正确点并保留；S335：根据坐标关系由所述正确点在对应的深度图像上找到相应的点坐标,并将深度图像上相应的点记为匹配点；S34：选取特征点匹配对数最多的红外图像对应的相机作为对准相机,根据所述深度图像上的匹配点计算所述对准相机与所述第一相机的位姿关系；S35：对所述多个相机的红外图像与深度图像均执行步骤S33至步骤S34,得到所有相机间的实时位姿关系；S4：根据所述深度图像得到在相机坐标系下的三维点云信息；S5：根据实时相对位姿与三维点云信息,完成多个相机的三维信息实时配准。</td>   <td>G06T7/33;G06T19/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;                   童天瑶       </td>   <td>中山大学</td>   <td>一种基于骨架特征学习的人脸欺诈检测方法及系统</td>   <td>广东省</td>   <td>CN115995120A</td>   <td>2023-04-21</td>   <td>本发明提出一种基于骨架特征学习的人脸欺诈检测方法及系统,涉及计算机视觉与深度学习、网络安全的技术领域；从原始视频和人脸欺诈视频中提取到人脸样本,并划分为训练集、验证集和测试集；构建人脸重构模型,基于可分离的非对称卷积结构和全局权重阈值对人脸重构模型进行改进,提取骨架特征,进行分类学习,利用训练集和验证集训练人脸重构模型,包括人脸重构和分类学习,将待测试的人脸输入进训练好的模型进行分类,判断待测试视频是否经过人脸欺诈。非对称卷积结构易于迁移,能提升标准卷积核的表达能力及模型性能,全局权重阈值增加有价值信息的影响,并降低保留无价值信息的概率,提升了高压缩率低质量视频的人脸欺诈检测准确率。</td>   <td>1.一种基于骨架特征学习的人脸欺诈检测方法,其特征在于,所述方法包括：S1.从数据库中选取原始视频和利用不同篡改方式篡改的人脸欺诈视频；S2.对原始视频和人脸欺诈视频进行处理,得到人脸样本,将人脸样本划分为训练集、验证集和测试集；S3.以多尺度的方式使用编码器和解码器以构建人脸重构模型；S4.基于可分离的非对称卷积结构和全局权重阈值对人脸重构模型进行改进,以提取骨架特征以及分类学习,得到改进后的人脸重构模型；S5.将训练集输入至S4中得到的人脸重构模型中,训练人脸重构模型,利用验证集验证人脸重构模型的性能,保存验证集下人脸欺诈检测准确度最佳时对应的人脸重构模型的参数,以作为训练好的人脸重构模型的参数；S6.从测试集中提取出待检测人脸,并输入至训练好的人脸重构模型中,判断测试集中的待检测人脸是否经过欺诈。</td>   <td>G06V40/40;G06V40/16;G06V20/40;G06V10/52;G06V10/774;G06V10/776;G06V10/82;G06N3/0464;G06N3/0455;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         闫志强;              苏蕾;              夏北成;              吴迪;              李志今;              萧海敬;              黄秀玲;              张晓健;              周刚;                   王广义       </td>   <td>广州资源环保科技股份有限公司;中山大学</td>   <td>一种预测和模拟浅水湖泊生态系统总磷循环的方法</td>   <td>广东省</td>   <td>CN109255168B</td>   <td>2023-04-18</td>   <td>本发明公开了一种预测和模拟浅水湖泊生态系统总磷循环的方法,包括,A、构建水体中的磷循环模型；B、构建底泥中的磷循环模型；C、构建浅水湖泊生态系统总磷循环模型。本发明的方法可以对湖泊所存在的磷污染问题做出科学的评价,并预测不同管理方法的使用所达到的环境效益、风险以及不确定性,并利用环境条件对不同管理方法的使用做出情景模拟,从而做出预测,为环境管理者提供科学的理论参考和指导。</td>   <td>1.一种预测和模拟浅水湖泊生态系统总磷循环的方法,其特征在于包括,A、构建水体中的磷循环模型：根据水体中的磷循环的过程构建湖泊水体中的磷循环模型,过程如下：a、外界输入；b、底泥的扩散；c、碎屑的分解和来源；d、沉水植物的生长吸收；e、浮游植物的生长吸收；f、附生藻的生长吸收；g、水体中磷的沉降；h、输出；B、构建底泥中的磷循环模型：根据底泥中的磷循环的过程构建底泥中的磷循环模型,过程如下：i、所述水体中磷的沉降；j、底栖生物的死亡分解；k、所述底泥的扩散；l、所述沉水植物的生长吸收；C、构建浅水湖泊生态系统总磷循环模型：利用系统动力学模拟软件,将水体中的磷循环模型和底泥中的磷循环模型输入系统动力模拟软件,得到浅水湖泊生态系统总磷循环模型。</td>   <td>G06F30/20;G16C20/20;G06Q10/0637;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李奥;              顾佳良;              衣杨;              朱艺;              周小峰;                   沈金龙       </td>   <td>中山大学</td>   <td>一种基于行为关联度融合特征的视频人体行为识别算法</td>   <td>广东省</td>   <td>CN109543590B</td>   <td>2023-04-18</td>   <td>本发明涉及一种基于行为关联度融合特征的视频人体行为识别算法,本发明在考虑视频帧之间时序关系的基础上,通过分别定义轨迹和视频帧与目标行为之间的关联度,突出了更具表达力的特征在形成视频表示过程中的重要性,并且与基于时间分割网络得到的视频表示进行融合,得到更具判别力的视频表示,有利于更有效地识别自然场景下视频中的人体行为。</td>   <td>1.一种基于行为关联度融合特征的视频人体行为识别算法,其特征在于,包括以下步骤：步骤S1：输入视频,计算视频中轨迹的行为关联度；步骤S2：根据轨迹的行为关联度生成基于轨迹关联度的视频帧表示；步骤S3：根据基于轨迹关联度的视频帧表示计算视频帧的行为关联度；步骤S4：生成基于视频帧行为关联度的视频表示；步骤S5：从视频中提取光流以及将时间分割网络作为特征提取器；步骤S6：生成基于时间分割网络的视频表示；步骤S7：结合基于视频帧行为关联度的视频表示以及基于时间分割网络的视频表示,利用支持向量机进行学习和分类,产生视频相应的动作类别标签；所述的步骤S1具体包括一下步骤：步骤S101：对视频帧进行时空金字塔的构建；步骤S102：在改进密集轨迹的基础上,提取时空多尺度的轨迹特征；步骤S103：计算静态显著性图谱和动态显著性图谱,静态显著性图谱S利用快速最小障碍距离变换算法得到,动态显著性图谱的计算方法是由静态显著性图谱的计算方法改进得到；步骤S104：以光流作为输入,截取视频帧上下左右四个边缘区域步骤S105：计算像素相对于每一个边缘区域的距离图谱z：                  其中,p-x表示像素点；χ～2表示卡方距离；b-i表示边缘区域,i＝1,2,3,4；h-j(p-x)是p-x处的平滑光流向量直方图的第j个bin值；h-j(b-i)为边缘区域对应bin的平均,j表示bin值的个数；步骤S106：定义M为视频帧的动态显著性图谱,将基于四个区域的距离图谱进行融合：                  其中i和j分别为视频帧边缘区域以及bin值的索引,z-k分别为上下左右四个边缘区域的距离图谱,k＝1,2,3,4,表示对应于第i个边缘区域和第j个bin值,视频帧四个边缘区域的距离图谱中的最大值；步骤S107：设轨迹所在序列位于空间金字塔的第z层,时间尺度为s,起始帧为w,轨迹的长度为L,且轨迹的起始帧位于该序列的第a帧；定义轨迹整体的静态行为关联度为多帧的静态显著性图谱对应像素显著值的平均值：                  其中T表示轨迹,P-t表示轨迹中的第t个点,表示轨迹点对应序列帧的静态显著性图谱,类似地,轨迹的动态行为关联属性可以表示为：/&gt;                  其中表示轨迹点对应序列帧的动态显著性图谱；步骤S108：得到轨迹的行为关联度定义如下：</td>   <td>G06V40/20;G06V20/40;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张年崧;              杨嵩毅;              符顺;                   陈翔       </td>   <td>中山大学</td>   <td>基于计算机视觉成像的工业型材几何尺寸自动检测方法</td>   <td>广东省</td>   <td>CN109658402B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于计算机视觉成像的工业型材几何尺寸自动检测方法,包括步骤：从输入源获取图像,自动检测型材位置并提取感兴趣区；对提取图像进行检测前预处理,改善图片动态范围并得到二值图；分别提取内外轮廓,并做多边形拟合；对于外轮廓,判断多边形顶点处于直线或曲线上,对于内轮廓,判断其为孔或槽；对于外轮廓,根据判断结果计算直线与曲线参数,对于内轮廓,计算孔的位置与半径,槽的位置、长宽与倾斜度；最后,输出检测参数,并将检测结果标注于原图,展现给用户。本发明自动识别图片中工业型材位置,运用计算机视觉和图像处理技术,精确检测输出工业型材的直线、曲线、内部钻孔、锯槽与铣槽各项参数,并将结果标注于原图上。</td>   <td>1.一种基于计算机视觉成像的工业型材几何尺寸自动检测方法,其特征在于,所述的工业型材几何尺寸自动检测方法包括以下步骤：S1、从输入源获取图像,自动检测型材位置并提取感兴趣区域；S2、对提取的图像感兴趣区域进行检测前预处理,改善图像动态范围并得到二值图；S3、分别提取内外轮廓,并做多边形拟合；所述的步骤S3的过程如下：S31、使用Suzuki-Abe算法提取轮廓,跟踪二值图边界并对边界编号,构建各个轮廓的拓扑关系树,分析内外轮廓的相互包含关系,实现从二值图中提取轮廓；S32、根据轮廓拓扑结构区分外部轮廓与内部轮廓并分别存储；S33、使用Ramer–Douglas–Peucker算法进行多边形拟合,使用上一步提取出的轮廓点迭代选取适应点,将曲线近似表示为一系列适应点并减少点的数目,即对轮廓做多边形拟合,得到逆时针排序的多边形顶点；S4、对于外轮廓,判断多边形顶点处于直线或曲线上,对于内轮廓,判断其为孔或槽；S5、对于外轮廓,根据判断结果计算直线与曲线参数,对于内轮廓,计算孔的位置与半径,槽的位置、长宽与倾斜度；S6、输出检测参数,并将检测结果标注于原图,展现给用户。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              叶灵昶;                   王青       </td>   <td>中山大学</td>   <td>一种人体骨骼关键点的快速检测方法及系统</td>   <td>广东省</td>   <td>CN110084161B</td>   <td>2023-04-18</td>   <td>本发明公开了一种人体骨骼关键点的快速检测方法及系统,所述方法包括如下步骤：步骤S1,构建并训练一卷积神经网络,以通过所述卷积神经网络利用多尺寸图像特征信息来检测图像中人体的各个部位；步骤S2,获取一二维彩色图；步骤S3,将所述二维彩色图输入至步骤S1中经训练好的卷积神经网络中,利用多尺寸图像特征信息来检测图像中人体的各个部位,并将该些检测到的部位聚合起来以形成单人的骨骼点集合,完成关键点的检测,本发明通过设计轻量化的卷积神经网络结构,可减少运算时间,实现在智能相机上实现人体骨骼关键点的检测。</td>   <td>1.一种人体骨骼关键点的快速检测方法,包括如下步骤：步骤S1,构建并训练一卷积神经网络,以通过所述卷积神经网络利用多尺寸图像特征信息来检测图像中人体的各个部位；步骤S2,获取二维彩色图；步骤S3,将所述二维彩色图输入至步骤S1中经训练好的卷积神经网络中,利用多尺寸图像特征信息来检测图像中人体的各个部位,并将检测到的部位聚合起来以形成单人的骨骼点集合,完成关键点的检测；步骤S1进一步包括：步骤S100,收集二维彩色图,对所述二维彩色图中人体骨骼关键点进行标注得到相应的二维坐标；步骤S101,构建卷积神经网络,并随机初始化该卷积神经网络的参数；步骤S102,以所述二维彩色图为卷积神经网络的输入,以所述二维彩色图的特征图和每个骨骼关键点所属人体的标签信息为卷积神经网络的目标输出,使用随机梯度下降算法对所述卷积神经网络进行端到端的模型训练,更新网络中的参数,使网络输出逐渐趋于目标输出；所述卷积神经网络包括初级特征提取模块和人体特征提取模块,所述初级特征提取模块用以提取低级特征,人体特征提取模块用以组合低级特征来形成高级特征进而表达人体各部位特征,通过组合二维深度可分离3×3卷积层和二维1×1卷积层来替换现有网络中的二维3×3卷积层,以在原有能对图像进行特征提取的基础上,减少网络的参数；所述卷积神经网络采用如下目标损失函数来衡量卷积神经网络的输出和所希望的输出之间的差距：                  其中K为骨骼关键点的数量,z为输出特征图在二维空间上的坐标,Z为输出特征图在二维空间上的范围,N为图中人的数量,b～k(z)是骨骼点k的输出特征图,是骨骼点k的目标特征图,σ为高斯激活函数中的常数,h-k(x-(nk))为第n个人的骨骼点k的输出人体标签特征图,/&gt;为经过网络的输出人体标签特征图中除第n个人以外的所有人n～′所属的标签值,/&gt;为经过网络的输出人体标签特征图中第n个人所属的标签值：                  其中,n为图中第n个人,n～′为图中除第n个人以外所有人,h-k为骨骼点k的输出人体标签特征图,x-(nk)为图像中第n个人骨骼点k的坐标位置。</td>   <td>G06V40/10;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭英;              杨荣骞;              谢杨洁;                   龚瑾       </td>   <td>中山大学附属第三医院</td>   <td>颅骨缺损结构的重建方法、装置及电子设备</td>   <td>广东省</td>   <td>CN110176066B</td>   <td>2023-04-18</td>   <td>本发明提供了一种颅骨缺损结构的重建方法、装置及电子设备,涉及颅骨修复技术领域,该方法包括：获取术前完整颅骨的三维图像信息、术中缺损颅骨的缺损边缘轮廓信息和主视角方向；根据主视角方向、预设的旋转方向和预设的投影平面,对三维图像信息中的第一点集和缺损边缘轮廓信息中的第二点集均做旋转和投影操作,得到第一平面点集和第二平面点集；根据第一平面点集和第二平面点集,获取缺损颅骨对应的目标点集；对目标点集进行模型结构的三维重建,得到目标颅骨缺损结构。本发明中不需要医生手动分割颅骨缺损结构,减少了手动操作带来的误差,提高了重建颅骨缺损结构的准确度。</td>   <td>1.一种颅骨缺损结构的重建方法,其特征在于,所述方法包括：获取术前完整颅骨的三维图像信息、术中缺损颅骨的缺损边缘轮廓信息和主视角方向；其中,所述三维图像信息包括由形成所述完整颅骨的各个点的坐标构成的第一点集,所述术中缺损颅骨的缺损边缘轮廓信息和主视角方向是利用术中导航设备获取的,所述缺损边缘轮廓信息包括由形成所述缺损颅骨的缺损边缘轮廓的各个点的坐标构成的第二点集,所述主视角方向与所述缺损边缘轮廓的拟合平面的法向量平行；根据所述主视角方向、预设的旋转方向和预设的投影平面,对所述第一点集和所述第二点集均做旋转和投影操作,得到所述三维图像信息对应的第一平面点集和所述缺损边缘轮廓信息对应的第二平面点集；其中,所述旋转方向与所述投影平面垂直；根据所述第一平面点集和所述第二平面点集,获取所述缺损颅骨对应的目标点集；对所述目标点集进行模型结构的三维重建,得到目标颅骨缺损结构。</td>   <td>G06T17/00;G06T19/20;G06T7/00;G06T7/13;G06T7/181</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              刘稳;                   黄捷       </td>   <td>中山大学</td>   <td>基于深度学习子网络特征提取的视网膜OCT图像分类方法</td>   <td>广东省</td>   <td>CN110188820B</td>   <td>2023-04-18</td>   <td>本发明涉及计算机视觉技术,为基于深度学习子网络特征提取的视网膜OCT图像分类方法,对计算机辅助诊断提供算法支持,计算资源消耗小,训练速度快,准确率高；包括步骤：准备视网膜OCT图像数据；构建多个不同的深度学习模型子网络；对视网膜OCT图像数据用所构建的不同的深度学习模型子网络进行特征提取,将所提取的特征输入随机森林分类器进行训练和分类,并对训练和分类的结果进行评估筛选,获得准确率较高的几个模型；利用所评估筛选出来的模型,采用特征连接或多数投票的分类方法对视网膜OCT图像进行分类。</td>   <td>1.基于深度学习子网络特征提取的视网膜OCT图像分类方法,其特征在于,包括以下步骤：S1、准备视网膜OCT图像数据；S2、构建多个不同的深度学习模型子网络；S3、对视网膜OCT图像数据用步骤S2所构建的不同的深度学习模型子网络进行特征提取,将所提取的特征输入随机森林分类器进行训练和分类,并对训练和分类的结果进行评估筛选,获得准确率较高的几个模型；S4、利用步骤S3所评估筛选出来的模型,采用特征连接或多数投票的分类方法对视网膜OCT图像进行分类；步骤S2中,深度学习模型包括Inception-v3模型,利用Inception-v3模型所构建的深度学习模型子网络包括：mixed10模型,为不去除Inception-v3模型的任何模块,仅替换掉最后一层分类层所形成的子网络；mixed8模型,为除去Inception-v3模型中InceptionE1、Inception E2所形成的子网络；mixed4模型,为除去Inception-v3模型中Inception E1、Inception E2、Inception D、Inception C2、Inception C3、Inception C4所形成的子网络；深度学习模型包括ResNet50模型,利用ResNet50模型所构建的深度学习模型子网络包括：ac46模型,为除去ResNet50模型中最后一个identity模块所形成的子网络；ac43模型,为除去ResNet50模型中最后两个identity模块所形成的子网络；ac37模型,为除去ResNet50模型中最后两个identity模块、最后一个卷积模块以及最后一个卷积模块之前的一个identity模块所形成的子网络；步骤S2中,深度学习模型包括DenseNet121模型,利用DenseNet121模型所构建的深度学习模型子网络包括：C5-b16模型,为不去除DenseNet121模型的任何模块,只替换最后一层分类层所形成的子网络；C5-b14模型,为去除DenseNet121模型中最后2个卷积模块所形成的子网络；C5-b12模型,为去除DenseNet121模型中最后4个卷积模块所形成的子网络；C5-b10模型,为去除DenseNet121模型中最后6个卷积模块所形成的子网络；C5-b4模型,为去除DenseNet121模型中最后12个卷积模块所形成的子网络；C4-b2模型,为去除DenseNet121模型中倒数第二个dense模块中最后22个卷积模块以及之后的层所形成的子网络；步骤S4中特征连接的分类方法为：利用多个不同的深度学习模型子网络,对训练集图片提取多个不同的特征向量,然后用numpy库的concatenate函数进行串联得到新的特征向量,再运用训练好的随机森林分类器进行训练,得到特征连接的分类器；同理,利用多个不同的深度学习模型子网络对测试集图片进行特征提取和特征连接得到新的向量,运用训练好的随机森林分类器分类得到结果；步骤S4中多数投票的分类方法为：基于多个不同的深度学习模型子网络进行特征提取,分别用随机森林方法进行训练得到多个分类器；对测试图片进行测试,每个分类器得到一维列向量；对于一维列向量中的每个元素,都有多个不同分类器得到的值,采取其中的众数作为最终的结果,得到1个的一维列向量作为分类结果。</td>   <td>G06V40/18;G06V10/764;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              王绍菊;              林冰倩;                   林倞       </td>   <td>中山大学</td>   <td>一种可自动定制的医学病灶检测架构及方法</td>   <td>广东省</td>   <td>CN110473195B</td>   <td>2023-04-18</td>   <td>本发明公开了一种可自动定制的医学病灶检测架构及方法,该检测架构包括：候选特征提取模块,对医学图像进行特征提取；病灶检测网络头部自动定制模块,定义搜索空间将候选区域间的感知关系合并在一起,并利用可微NAS算法得到最佳病灶检测网络头部；病灶检测网络头部最优模块,利用一卷积层,并经过一个标准细胞和两个收缩细胞得到新的候选特征,通过两连接层对候选特征进行二元分类和预测框回归,将二元分类中候选特征分类的权重M作为高层次语义信息输出至知识迁移模块；知识迁移模块,结合语义关系并在不同的区域内传递相关的上下文信息,得到增强的候选特征,并将增强的候选特征和原候选特征合并,最后通过全连接层进行多元分类和回归。</td>   <td>1.一种可自动定制的医学病灶检测架构,包括：候选特征提取模块,用于对输入的医学图像进行特征提取,提取出图像的候选特征；病灶检测网络头部自动定制模块,用于根据医学图像特性、病灶特征和目标检测的相关知识,定义新的搜索空间,所述搜索空间包括具有灵活感受野、跳层连接子网络架构的先进操作,并增加一个非局部操作,将候选区域间的感知关系合并在一起,根据候选特征并利用可微NAS算法在设计的搜索空间中搜索合适的操作和连接方式使其组成一个适合医学图像的最佳病灶检测网络头部；病灶检测网络头部最优模块,为所述病灶检测网络头部自动定制模块定制的最佳病灶检测网络头部,将所述候选特征提取模块输出的候选特征,首先经过一个卷积核为3×3的卷积层,然后经过一个标准细胞和两个收缩细胞得到新的候选特征,并通过两个连接层对新的候选特征进行二元分类和预测框回归,将二元分类中候选特征分类的权重M作为高层次语义信息输出至知识迁移模块；知识迁移模块,在最佳病灶检测网络头部学习到的区域关系图的基础上,结合语义关系,并在不同的区域内传递相关的上下文信息,以得到一个增强的候选特征,并将增强后的候选特征和原来的候选特征合并在一起去共享多种病灶类型的相关信息,最后通过全连接层进行多元分类和回归；所述搜索空间包括以下9种操作：1)无连接；2)跳层连接；3)3×3的平均池化；4)非局部；5)1×3和3×1的卷积；6)3×3的深度可分离卷积；7)5×5的深度可分离卷积；8)膨胀率为3的3×3空洞卷积；9)膨胀率为5的3×3空洞卷积；在所述可微NAS算法中,首先需要根据任务设计合适的搜索空间,然后定义搜索的模块,包括标准细胞模块和收缩细胞模块,其中标准细胞模块步长为1,以保持输出与输入同等的分辨率,同时通道数不变,收缩细胞模块步长为2,将分辨率降低一半,同时将通道数翻倍,每个模块即细胞看做一个有向无环图,定义其分支数,每个分支表示一个特征图,分支间的连接方式表示操作；每一条分支有两个来自之前分支的输入和一个输出,在完成定义之后,进行初始化设置,同时通过softmax函数使其离散结构连续化,之后利用梯度下降算法进行梯度回传更新其权值,最后在经过一定时间的搜索之后,首先在9种操作连接中保留权值最大的一个操作,即由一个密集连接变成稀疏连接,然后选择权值最大的两个连接作为该分支的输入,并将它们的结果合并作为输出。</td>   <td>G06T7/00;G06V10/44;G06V10/764</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              钟沈君;              谢舜道;                   陈荣军       </td>   <td>中山大学</td>   <td>一种基于增强相关系数的双阶二维码防伪认证方法</td>   <td>广东省</td>   <td>CN110570210B</td>   <td>2023-04-18</td>   <td>本发明提供的一种基于增强相关系数的双阶二维码防伪认证方法,包括以下步骤：选取双阶二维码扫描版本进行输入；对输入的双阶二维码进行纹理分类；根据分类结果,将纹理相同的图案匹配成纹理图案对；利用纹理图案对计算增强相关系数；将增强相关系数与认证阈值对比,完成双阶二维码的防伪认证。本发明提供的双阶二维码防伪认证方法,对输入的二阶二维码中的纹理图案进行分类并形成两种不同的纹理图案对,再根据增强相关系数计算双阶二维码的增强相关系数的均值,最后由均值判断双阶二维码的真伪,该方法对比传统的相关系数具有更大的防伪认证差值,认证鲁棒性强,同时增强相关系数的提高有效地增强了真伪分类的可靠性。</td>   <td>1.一种基于增强相关系数的双阶二维码防伪认证方法,其特征在于：包括以下步骤：S101：选取双阶二维码扫描版本进行输入；S102：对输入的双阶二维码进行纹理分类；S103：根据分类结果,将纹理相同的图案匹配成纹理图案对；S104：利用纹理图案对计算增强相关系数；具体为：根据纹理图案对的传统相关系数,根据传统相关系数计算增强相关系数的均值,即双阶二维码的认证增强相关系数；所述计算增强相关系数均值的过程具体为：设两个随机向量X＝(x-1,x-2,...,x-n)和Y＝(y-1,y-2,...,y-n),其中随机向量X为S1纹理图案,随机向量Y为S2纹理图案；X与Y中对应的分量组成一个元素对集合XY,其包含的元素为(x-i,y-i)(i＝1,2,...,n),元素对集合XY分为三类,分别为：第一类：两个元素对一致,即是集合XY中任意两个元素(x-i,y-i)与(x-j,y-j)的排行相同；第二类：两个元素对不一致,集合XY中任意两个元素(x-i,y-i)与(x-j,y-j)的排行不相同；第三类：两个元素对不确定,集合XY中任意两个元素(x-i,y-i)与(x-j,y-j)的排行不确定；计算单个纹理图案的相关系数,具体公式为：                  其中C表示在集合XY中的第一类元素对,D表示XY中的第二类元素对；因此所有纹理图案对得出的增强相关系数的均值具体公式为：                  其中,Corr(,)表示纹理图案对的肯德尔相关系数,k＝1,2表示是真实二维码的扫描版本和伪造二维码的扫描版本,系数α和β都是为0.1,R-(adv2S)是所有纹理图案对的增强相关系数的均值；S105：将增强相关系数与认证阈值对比,完成双阶二维码的防伪认证。</td>   <td>G06Q30/018;G06K7/14;G06T7/41</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              郭叙森;              许子潇;                   郭思璐       </td>   <td>中山大学</td>   <td>一种基于关键帧的三维物体检测与跟踪方法</td>   <td>广东省</td>   <td>CN110688905B</td>   <td>2023-04-18</td>   <td>本发明涉及一种基于关键帧的三维物体检测与跟踪方法,通过输入包含点云数据和图像数据的相邻两关键帧,首先使用特征提取网络对数据进行特征提取分别得到特征图,然后将特征图输入候选框提取网络得到两关键帧共享的候选框；之后通过共享候选框截取特征图相应特征进行特征融合,回归得到三维预测框；然后使用共享候选框截取特征图进行特征互相关得到相关特征,回归得到物体三维框在两关键帧的偏移量；通过插值算法得到所有帧的检测结果之后,对所有帧物体框进行关联,得到跟踪结果。本发明利用了流数据的冗余性,通过只对关键帧预测,大大减少了计算量,并且能够利用时序信息改善检测结果,提升了检测速度和更好的追踪目标。</td>   <td>1.一种基于关键帧的三维物体检测与跟踪方法,其特征在于,包括如下步骤：步骤一：输入前后两帧由点云数据和图像数据组成的关键帧数据,对数据进行预处理,其中的点云数据在俯视图方向上投影结构转化成BEV图；步骤二：将步骤一中的两关键帧数据进行特征提取,分别得到两关键帧的特征图,分别为点云特征图和图像特征图；步骤三：将步骤一中的两关键帧数据输入共享区域提取网络模块,生成能被两个关键帧共享的共享候选框集合；步骤四：步骤三中的共享候选框在所述特征图提取候选框特征,然后送入分类网络与框回归网络,得到物体的类别以及三维框位置；步骤五：步骤三中的共享候选框分别提取两关键帧的BEV图特征块,送入追踪模块提取对应候选框的相关特征,然后输入偏移回归网络得到两关键帧对应物体的三维框的偏移量；步骤六：根据物体的三维框和三维框对应的偏移量,运用插值法得到两个关键帧数据之间的其他帧数据的物体的三维框,从而得到所有帧中的物体的三维检测结果；步骤七：根据检测结果,对所有帧数据对应的物体相互关联,得到跟踪结果。</td>   <td>G06V20/40;G06V20/64;G06V10/80;G06V10/44;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         印鉴;                   陈智聪       </td>   <td>中山大学</td>   <td>一种基于深度学习的视频检索方法</td>   <td>广东省</td>   <td>CN110717068B</td>   <td>2023-04-18</td>   <td>本发明提供一种基于深度学习的视频检索方法,该方法能通过G网络中的视频输入层以及RseNet的深度学习模型学习到视频的上下文特征,能够提取出可以表达视频类型的特征数,并且经过Hash层转换优化存储空间,使得视频特征存储所占空间极大降低。通过在相应数据集上的实验表明,本发明对比之前的视频检索方法,有较大提升,并且同样数据集占用的存储空间也有较大降低。</td>   <td>1.一种基于深度学习的视频检索方法,其特征在于,包括以下步骤：S1：建立用于视频特征提取的深度学习网络模型G；所述步骤S1的具体过程是：S11：建立G网络的第一层视频向量层,将预处理后的每个视频中的每一帧照片表示成一个低纬、稠密的实数向量,在大规模标注照片上预训练好的图片模型Resnet,将整个视频表示成视频向量矩阵X＝[x1,…,xt,…,xn],其中n是视频帧数,向量矩阵X的维度是照片预处理大小112*112；S12：建立G网络的第二层ResNet层,在这一层中让模型学习到整个视频的上下文信息,对于向量X,每一帧图片是向量中的一个元素,第t个帧元素表示为xt,通过ResNet模型后提取到一组设定好的nbit长度的特征向量；步骤S12中,特征提取过程如下：先将ResNet模型经过Kinetics视频数据集进行预训练,然后再进行微调,每个视频经过预训练好的ResNet模型后,会生成一组k大小的特征数向量,这个k是指视频有k种分类；然后再经过一个Linear层转换成自定义的n长度的特征数；S13：建立G网络的第三层特征向量Hash层,将ResNet输出的特征向量进行Hash转化成0、1值的向量,以此减少存储空间；S2：对步骤S1中得到的模型进行训练与测试；所述步骤S2的具体过程是：S21：将数据集分为训练数据以及测试数据；S22：整体的模型要进行训练,G网络的训练步骤如下：由G网络提取出视频特征,由损失函数L1的最小化来训练G网络模型,训练G网络的参数；S23：模型的测试步骤为：先过第一遍测试数据集,将测试数据输入到G网络,然后由G网络生成特征,将特征存储到数据库DB1,然后进行第二遍特征mAP计算,将每一个视频的特征与DB1中数据进行距离计算,之后进行mAP计算；S3：利用S3中得到的弄醒建立用于提供后台接口的进程,提供检索入口以及返回检索结果。</td>   <td>G06F16/73;G06F16/75</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙颖;              辛秦川;                   黄健锋       </td>   <td>中山大学</td>   <td>基于深度学习的单木级树种识别方法</td>   <td>广东省</td>   <td>CN110728197B</td>   <td>2023-04-18</td>   <td>本发明实施例公开了一种基于深度学习的单木级树种识别方法,所述方法包括：通过LiDAR点云数据获取冠层高度模型；通过局部最大值算法与冠层高度模型进行航空影像单木分割,并裁剪得到单株树木的块状影像；基于单株树木的块状影像利用深度卷积神经网络对单木树种进行识别。在本发明实施例中以LiDAR点云数据与高分辨率航空影像为基础,利用深度卷积神经网络图像分类技术进行单木尺度树种识别,实现了同时获取林区树木棵数及单株树木类型。</td>   <td>1.一种基于深度学习的单木级树种识别方法,其特征在于,所述方法包括：通过LiDAR点云数据获取冠层高度模型；通过局部最大值算法与冠层高度模型进行航空影像单木分割,并裁剪得到单株树木的块状影像；基于单株树木的块状影像利用深度卷积神经网络对单木树种进行识别；所述通过LiDAR点云数据获取冠层高度模型包括：通过反向距离权重IDW插值法提取数字高程模型DEM和数字表面模型DSM；根据DSM和DEM的差值建立了冠层高度模型CHM；所述通过局部最大值算法与冠层高度模型进行航空影像单木分割,并裁剪得到单株树木的块状影像包括：使用可变的移动窗口扫描新生成的树冠高度模型表面,标识局部最大值；运用树冠与树高的经验关系构建可变的移动窗口,以局部最大值作为单木顶点；以树冠最高点为中心截取64*64个像元的单木影像；所述运用树冠与树高的经验关系构建窗口判断局部最大值是否为单木顶点包括：在局部最大值对应的树冠范围内没有更高的像元点,那么该像元所在位置即为单木顶点,树冠与树高的经验关系见式如下：width(m)＝2.51503+0.00901ht～2其中：ht表示插值后的CHM模型中的树高,width表示预测的冠幅直径；所述基于单株树木的块状影像利用深度卷积神经网络对单木树种进行识别包括：基于单株树木的块状影像作为深度残差卷积神经网络ResNet-50中输入层的参数；通过卷积模块组逐层提取特征,残差模块配合卷积模块增强了特征的提取,最终通过分类模块实现对单木树种的分类；所述ResNet-50中设置有四个Dropout层,所述Dropout层设置于投影快捷模块之后；所述ResNet-50中输入层尺寸为64×64像素,对应第一个卷积模块的特征输入为64；最后一个池化层的内核大小为2,以确保最后一个要素映射的大小为1*1；所述ResNet-50中输出层中的每个神经元对应一个树种类型。</td>   <td>G06V20/10;G06V20/17;G06V10/26;G06V10/774;G06V10/764;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张宏伟;              张小虎;                   杨夏       </td>   <td>中山大学</td>   <td>一种基于信息论流形的人脸图像识别方法</td>   <td>广东省</td>   <td>CN110781802B</td>   <td>2023-04-18</td>   <td>本发明提供了一种基于信息论流形的人脸图像识别方法,包括如下步骤：步骤1,通过Gabor滤波器对人脸二维图像进行处理,使用多个中心尺度和多个方向组合,提取人脸二维图像的纹理结构特征；步骤2,使用不确定度计算人脸二维图像经过多尺度变换后各个尺度特征结果的权值；步骤3,对高维张量空间数据进行降维,得到低维数据并提取人脸二维图像数据的特征；步骤4,根据已提取到的人脸二维图像数据,利用线性判别分析和最近邻算法识别人脸二维图像；本发明相对于一些基础的人脸二维图像特征提取算法而言,具有较好的识别率。</td>   <td>1.一种基于信息论流形的人脸图像识别方法,包括如下步骤：步骤1,通过Gabor滤波器对人脸二维图像进行处理,使用多个中心尺度和多个方向组合,提取人脸二维图像的纹理结构特征；步骤2,使用不确定度计算人脸二维图像经过多尺度变换后各个尺度特征结果的权值；步骤3,对高维张量空间数据进行降维,得到低维数据并提取人脸二维图像数据的特征；步骤4,根据已提取到的人脸二维图像数据,利用线性判别分析和最近邻算法识别人脸二维图像；在步骤1中,通过Gabor滤波器对人脸二维图像进行处理的具体方法为：获取人脸二维图像上给定点I(z)附近区域的灰度特征；利用公式G-(u,v)(z)＝I(z)＊ψ-(u,v)(z),对获取的灰度特征与Gabor函数进行卷积运算；其中＊表示卷积运算,z＝(x,y)为具体某个点的坐标,I(z)为给定点的灰度值,ψ-(u,v)(z)中参数u和v分别表示Gabor内核的方向和中心尺度；在步骤2中,不确定度权值的具体计算方法为：对M张同类人脸图像样本{Y-i,i＝1,…,M},使用5个不同的中心尺度和8个不同的方向组合成40个Gabor滤波器,得到40张人脸图像特征使为G-i的算术平均值,则第j个Gabor滤波器的不确定度/&gt;其中/&gt;表示矩阵间的欧式距离；设40个多尺度Gabor滤波器的权值分别为A-1,A-2,A-3,…A-(40),且通过融合得到人脸图像样本的最终特征/&gt;且人脸图像样本Y-i经过Gabor滤波响应后的方差结合不确定度U-j和方差σ～2,得到使用拉格朗日乘法完成计算,其中γ为拉格朗日常数,有求解得到不确定度权值/&gt;在步骤3中,对高维张量空间数据进行降维以得到低维数据的具体方法为：使用M个张量样本{X-m,m＝1,…,M}为练本,且A-m∈R～(I1×I2×…×IN),即构建的张量空间属于张量空间其中In作为张量第n模的维数；/&gt;通过多线性主成分分析方法计算多线性变换空间{U～((n))∈R～(In×Pn),n＝1,2,…,N},其中U～((n))由Φ～((n))中最大的P-n个特征值对应P-n个特征向量构成,其中,                                                                为最大化张量总的散布值；利用公式其中Ω&lt;1,使用基于Q值的方法计算较优的P-n值。</td>   <td>G06V40/16;G06V10/26;G06V10/44;G06V10/77;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   李腾龙       </td>   <td>中山大学</td>   <td>一种基于细粒度插入式解码的摘要生成方法</td>   <td>广东省</td>   <td>CN110795556B</td>   <td>2023-04-18</td>   <td>本发明提供一种基于细粒度插入式解码的摘要生成方法,该方法将训练目标分解成信息提取压缩和自然语言抽象生成两部分,由内容框架提取器负责信息提取压缩部分,使得神经网络语言模型生成器专注于学习摘要文风技巧；预先提取的内容框架构成上下文信息能指导生成过程,相比于从零产生的自左向右解码方式,内容框架能提供给下一个待生成的词丰富的上下文信息；减少了解码步骤,相对加快了自回归解码过程,缓解了基于自注意力网络解码速度比循环神经网络慢的缺陷,同时一定程度缓解了序列到序列模型的暴露偏差(Expose Bias)问题。</td>   <td>1.一种基于细粒度插入式解码的摘要生成方法,其特征在于,包括以下步骤：S1：对输入文件进行预处理；S2：通过编码器对S1中处理的文本进行编码；编码器对S1得到的词嵌入序列输入进行编码,编码器包含6个基于自注意力网络的转换器单元层叠得到,转换器单元包含自注意力层和前馈全连接层,具体编码过程是：S21：每个转换器单元的输入是上一个单元的编码输出,第一个转换器单元的输入则是步骤1得到的词向量；S22：在转换器单元内部,输入首先传入自注意力层,使得每一个词对应的向量能感知上下文信息,捕捉当前词与其他词的依赖与联系,自注意力层包含8个参数不同的注意力头,拓展了模型关注不同位置的能力,每一个注意力头包括三个权重矩阵,分别是查询Query、键Key、值Value,中间向量Z通过获得；S23：将中间向量Z按位置分别传入前馈全连接层,得到该转换器单元的输出,为提高模型表示能力和稳定性,引入残差连接Residual Connections、层归一化机制LayerNormalization、随机丢弃机制Dropout,自注意力层计算得到的中间向量与自注意力层计算的输入向量进行残差连接,然后再进行随机丢弃以及层归一化,同样的操作也应用于前馈全连接层的输出与中间向量的残差连接；S3：内容框架提取器分析编码后的文本；S4：解码器对内容框架提取器处理后的文本进行处理得到文本摘要；所述步骤S4中,解码器结合编码器输出和当前已产生的解码序列作为输入,产生下一个词加入已解码序列,具体解码过程是：S41：以句子的起始标志“BOS”,再加上步骤S3提取的内容框架,作为解码器初始输入；S42：根据解码器当前输入,执行词嵌入操作,与步骤S12-S15过程相同,获得解码器的输入词向量；S43：对于解码器的每个转换器单元,计算过程与步骤S21-S23相似,但在每一个转换器单元的内部引入编码-解码注意力层,以编码器输出作为额外记忆,该部分的自注意层与普通的自注意力层计算原理相同,唯一的区别在于将额外记忆作为键向量和值向量,即用于捕捉解码序列中每一个词与原文每一个词的联系,在得到解码器自注意力层与编码-解码注意力层的输出后,也进行残差连接及层归一化计算,并传入前馈全连接层,得到转换器单元的输出向量；S44：通过层叠的转换器单元得到当前时刻高层级的隐藏状态向量Z-(dec),在内容框架基础上,首先需要决定下一个词在已解码序列中的插入位置,使用指针(Pointer)向量q与隐藏状态向量Z-(dec)进行点积寻址操作,得到插入位置的概率分布P-(insert)(1)＝softmax(Z-(dec)·q),选择概率最大的位置l-i作为待插入位置；S45：取第i个位置的隐藏状态向量传入全连接的线性变换层,将该隐藏状态向量投射到维度为输出词表大小的向量中,又称对数几率向量,对应每个词被选取的概率分布可以用/&gt;表示；S46：选择概率最大的词作为该解码步骤的输出单词,若该输出单词不为终止字符“EOS”,则将该词按其插入位置i插入当前解码序列,更新后的解码序列作为解码器下一时刻输入,重复步骤S42-S46,直到输出“EOS”,作为模型生成摘要结束,得到该长文本的短文本摘要。</td>   <td>G06F16/34;G06F40/126;G06F40/151;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张兴宇;              潘炎;                   印鉴       </td>   <td>中山大学</td>   <td>基于Embedding技术的无监督关键词提取方法</td>   <td>广东省</td>   <td>CN110851570B</td>   <td>2023-04-18</td>   <td>本发明提供一种基于Embedding技术的无监督关键词提取方法,该方法利用图卷积词嵌入技术得到文章单词的语义兼句法词向量；利用Node2Vec技术训练单词的共现关系拓扑图,从而得到共现特征词向量；利用主题词嵌入技术,得到文章单词的主题词向量；将单词的三种特征向量拼接得到混合词向量,利用混合词向量计算单词间的余弦相似度去构造单词拓扑图,使用PageRank图迭代算法得到单词的重要性分数。该方法运用多种词嵌入技术,综合了单词间的语义、句法、共现以及主题多种关联特征,使得提取效果得到大大的提升。</td>   <td>1.一种基于Embedding技术的无监督关键词提取方法,其特征在于,包括以下步骤：S1：对文档进行切词和词性标注,得到一个单词集合W；S2：利用词性标注和“形容词+名词”模式得到一系列候选短语；S3：利用无监督图卷积词嵌入技术得到集合W中每个单词的句法兼语义词向量Gi；所述步骤S3的具体过程是：S31：以句子为单位,构造每个句子的句法依存树；S32：利用图卷积神经网络和句法依存树中单词的邻居关系去得到每个单词的隐层状态,即向量表示Gi；S33:利用每个单词的邻居集合去极大化该单词的条件概率,以此作为图卷积神经网络的损失函数,去训练得到单词的词向量。该向量具备单词的语义和句法依存特征；S4：以W集合中单词的共现关系构造单词的共现拓扑图,使用Node2Vec技术训练得到单词的共现特征向量Ni；所述步骤S4的具体过程是：S41：设置共现窗口,在文章中进行滑动,将两个单词出现在同一窗口的次数作为单词间的共现次数,以单词为节点,单词间的共现次数构造单词的共现拓扑图；S42：利用Node2Vec技术,去训练单词的共现拓扑图,将单词节点向量化,每个单词的向量Ni融入了该单词的共现关联特征和共现图的结构相似特征；S5：利用主题词嵌入技术得到集合W中每个单词的主题词向量Ti；所述步骤S5的具体过程是：S51：利用LDA主题模型得到文章中的K个潜在主题,每个单词分配一个主题；S52：替每个单词和主题都保留不同的嵌入向量Ui与Ki,将单词和主题的向量进行拼接Ti＝[Ui,Ki],利用word2vec的原理去训练拼接后的向量Ti；S53：将训练好的单词向量和其对应的主题向量进行拼接,得到该单词的主题词向量Ti,该向量融入了语义特征和主题特征；S6：将W集合中单词的三种向量进行拼接得到混合词向量Vi＝[Gi,Ni,Ti],具体地,将步骤S3、S4和S5步骤中的三种词向量进行拼接,得到混合词向量Vi＝[Gi,Ni,Ti],该向量兼具单词的语义特征、句法依存特征、共现关联特征以及主题特征；利用混合词向量得到单词之间的余弦相似度,以单词为节点,相似度作为边权构造单词的拓扑图；利用PageRank算法迭代单词的分数；S7:根据单词的分数间接对候选短语排序,从而得到关键词。</td>   <td>G06F16/33;G06F40/284;G06F40/211</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张榕瑜;                   倪江群       </td>   <td>中山大学</td>   <td>一种采用密集结构卷积网络的图像篡改检测和定位方法</td>   <td>广东省</td>   <td>CN110852316B</td>   <td>2023-04-18</td>   <td>本发明提供的一种采用密集结构卷积网络的图像篡改检测和定位方法,包括输入待测图像,对待测进行空间富集SRM卷积进行预处理,得到预处理后的图像；构建密集连接卷积网络对预处理后的图像进行篡改图像特征提取,得到待测图像的二分类信息,完成对图像篡改的检测；构建与连接卷积网络结构对称的反卷积网络,将二分类信息作为输入；根据得到的图像篡改区域,由反卷积网络完成定位后的图像。本发明所提供的方法,将深度学习技术应用到图像篡改检测与定位中,适用于多种篡改手段,具有好的鲁棒性和实用性；提供了检测和定位的统一框架,不仅能够多图像是否经过篡改做出预测,还能对篡改区域进行预测,给出逐像素的精确标注,得到细致的物体轮廓边界。</td>   <td>1.一种采用密集结构卷积网络的图像篡改检测和定位方法,其特征在于,包括以下步骤：S1：输入待测图像,对待测进行空间富集SRM卷积进行预处理,得到预处理后的图像；S2：构建密集连接卷积网络对预处理后的图像进行篡改图像特征提取,得到待测图像的二分类信息,完成对图像篡改的检测；S3：构建与连接卷积网络结构对称的反卷积网络,将待测图像的二分类信息作为输入,定位图像篡改区域；S4：根据得到的图像篡改区域,由反卷积网络完成定位后的图像,完成对图像篡改的定位；在所述步骤S2中,所述的密集连接卷积网络包括池化层、密集层、过渡层、全局平均池化层和全连接层；其中：所述池化层对预处理后的图像进行一次卷积和最大池化操作,并将结果输入密集层中；所述密集层、过渡层均设置有多层,每个密集层的输出结果均输入对应的过渡层中,最终由最后一层过渡层将得到的篡改图像特征图输入所述全局平均池化层中；所述全局平均池化层将篡改图像特征图进行平均池化,并由所述全连接层计算输出两个概率值,分别代表篡改和非篡改的概率,得到待测图像的二分类信息；所述密集层包括多个基本结构层,每个基本结构层由两个连续的卷积层组成,其中每个基本结构层的输入都有前一层的输出进行合并操作而成,是残差结构的局部稠密版本；所述密集连接卷积网络设置有四个密集层,分别包含了5、10、20、12个基本结构层；所述过渡层包括一层卷积层,其对密集层输入的特征图先卷积一次,再进行平均池化,对图像尺寸进行缩小。</td>   <td>G06V10/764;G06V10/25;G06V10/774;G06V10/82;G06N3/0464;G06N3/084;G06N3/045</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              方媛;              郭雪梅;                   戴宪华       </td>   <td>中山大学</td>   <td>一种低剂量CT图像修复去噪方法</td>   <td>广东省</td>   <td>CN110930318B</td>   <td>2023-04-18</td>   <td>本发明公开了一种低剂量CT图像修复去噪的方法,包括：模拟生成训练所需的低剂量CT图像：将高剂量CT图像做扇形射束投影变换得到投影域的投影数据,将得到的投影矩阵进行指数运算后加入泊松噪声之后取对数,通过MATLAB自带的反投影函数将模拟的投影数据转回图像域得到模拟的低剂量CT图像。本发明所公开的低剂量CT图像修复去噪的方法高效地实现了低剂量CT图像到高剂量CT图像的转化,有效地恢复了CT图像上的细节部分,同时可以降低网络的复杂度,加快网络训练并提高重构效率,可在不影响医生诊断的情况下有效的降低CT技术对于病人带来的伤害。</td>   <td>1.一种车辆所在车道快速划分方法,适用于直线车道区域,其特征在于,包括以下步骤：根据图像中的直线车道区域,得到各个车道线与各个车辆关键点的交点差值；若存在车道线的斜率k＝0的情况,通过下式计算交点差值：                  上式中,所述的O-(0,0),O-(0,1),…,O-(m-1,n-1)为各个车道线在各个车辆关键点下的交点差值；所述的k-0,k-1,…,k-(m-1)为各个车道线的斜率；所述的b-0,b-1,…,b-(m-1)为各个车道线的截距值；所述的y-0,y-1,…,y-(n-1)为各个车辆的关键点纵坐标值；所述的x-0,x-1,…,x-(n-1)为各个车辆的关键点的横坐标值；                  若不存在车道线的斜率k＝0的情况,通过下式计算交点差值：其中,          if k-j＝∞ and X-j＝a上式中,所述的k-j表示第j条车道线的斜率；所述的b-j表示第j条车道线的截距值；所述的X-j＝a为第j条车道线的表达式；计算相邻车道线之间的交点差值的乘积；根据交点差值的乘积判断各个车辆的所属车道。</td>   <td>G06T5/00;G06V10/25;G06N3/084;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              王弘焌;              王广润;                   李冠彬       </td>   <td>中山大学</td>   <td>一种基于类激活映射图引导的正则化方法及系统</td>   <td>广东省</td>   <td>CN111027634B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于类激活映射图引导的正则化方法及系统,该方法包括：S1,利用深度神经网络的全局池化层及全连接层参数产生基于标签类别的通道权重因子及类激活映射图；S2,将生成的通道权重因子及类激活映射图分别根据其对神经网络中各层特征图的所有通道及空间区域的贡献度排序；S3,根据步骤S2得到特征通道集以及特征点集,进而得到基于通道权重因子和类激活映射图的二元掩模图M～((1))和M～((2))；S4,生成基于伯努利分布的随机种子二元图M～((3)),与M～((1))和M～((2))进行逻辑运算得到最终的二元掩模图M,并由此获得正则化掩模图M～l；S5,多次迭代式地进行S1-S4的训练过程,完成正则化的优化过程。</td>   <td>1.一种基于类激活映射图引导的正则化方法,包括如下步骤：步骤S1,利用深度神经网络的全局池化层及全连接层参数产生基于标签类别k′的通道权重因子α～(k′)及类激活映射图J～(k′)；步骤S2,将步骤S1产生的基于标签类别k′的通道权重因子α～(k′)及类激活映射图J～(k′),通过生成的通道权重因子及类激活映射图分别对所述深度神经网络中各层不同分辨率的特征图的所有通道及空间区域的贡献度从大到小进行排序；步骤S3,从所有通道中抽取前n个重要的特征通道,得到特征通道集并对类激活映射图的所有空间区域也选定前n′个重要的特征点,得到特征点集/&gt;并根据上述集合分别得到两张基于通道权重因子和基于类激活映射图的二元掩模图M～((1))和M～((2))；步骤S4,根据预指定的保留率参数γ,生成基于伯努利分布的随机种子二元图M～((3)),对其自身进行逻辑运算后,与步骤S3中生成的M～((1))和M～((2))一同进行逻辑运算,得到最终的二元掩模图M,最后对二元掩模图M做归一化计算,得到当前迭代时刻及对应网络层l的正则化掩模图M～l；步骤S5,多次迭代式地进行步骤S1-S4的训练过程,最终完成正则化的优化过程；于步骤S3中,置一存在于上述两个集合的所有点,同时置零不存在于上述两个集合的所有点,分别得到两张基于通道权重因子和基于类激活映射图的二元掩模图M～((1))和M～((2))；步骤S3进一步包括：步骤S300,基于标签类别k′的通道权重因子向量α～(k′),按贡献度从大到小进行排序,继而从所有通道中抽取前n个重要的特征通道,得到特征通道集置一存在于上述集合的所有通道,同时置零不存在于上述集合的所有通道,并将其重塑为大小为W*H的二元掩模图M～((1))；步骤S301,对类激活映射图的所有空间区域也选定前n′个重要的特征点,得到特征点集置一存在于上述集合的所有点,同时置零不存在于上述集合的所有点,得到基于类激活映射图的二元掩模图M～((2))；步骤S4进一步包括：步骤S400,根据预指定的保留率参数γ,生成基于伯努利分布的随机种子二元图ψ,并对其自身做逻辑非运算后得到二元掩模图M～((3))；步骤S401,将得到的二元掩模图M～((3))与步骤S3中生成的二元掩模图M～((1))和M～((2))一同做逻辑与运算,得到最终的掩模图M；步骤S402,遍历整张二元掩模图M,将落在集合中的所有点置零,其中u为M中所有值为1的点,r为用于控制正则化区域的超参数,m为所有存在于M中的点,||·||-1为街区距离；步骤S403,对所述二元掩模图M做归一化计算,得到的即为当前迭代时刻及对应网络层l的正则化掩模图M～l；于步骤S5中,根据每一轮经迭代训练后的参数,更新所述类激活映射图J～(k′),将其作为下一轮正则化迭代的输入,多次迭代式地进行步骤S1-S4的训练过程。</td>   <td>G06V10/82;G06V10/80;G06N3/04;G06N3/09</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡庆玲;              何鸿奇;              孙玮;              林进可;                   林满盈       </td>   <td>中山大学</td>   <td>肺结节多尺度检测方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN111028940B</td>   <td>2023-04-18</td>   <td>本申请提供了一种肺结节多尺度检测方法、装置、设备及介质,所述方法包括：利用设有特征增强层的人工神经网络的自学习能力,建立肺部的CT图像特征与肺结节位置之间的对应关系；获取患者的当前肺部的当前CT图像特征；通过所述对应关系,确定与所述当前CT图像特征对应的当前肺结节位置；具体地,确定与所述CT图像特征对应的当前肺结节位置,包括：将所述对应关系中与所述当前CT图像特征相同的CT图像特征所对应的肺结节位置。确定为所述当前肺结节位置,提升了模型提取有效特征的能力,加强对有用特征的关注,减少对无用特征的关注程度,以提升检测模型的检测精度。</td>   <td>1.一种肺结节多尺度检测方法,其特征在于,包括：利用设有空间信息和通道信息卷积的人工神经网络的自学习能力,建立肺部的CT图像特征与肺结节位置之间的对应关系；具体地,所述建立肺部的CT图像特征与肺结节位置之间的对应关系的步骤,包括：获取用于建立所述CT图像特征与所述肺结节位置之间的对应关系的样本数据；分析所述CT图像特征的特性及其规律,根据所述特性及其规律,确定所述人工神经网络的网络结构及其网络参数；使用所述样本数据,对所述网络结构和所述网络参数进行训练和测试,确定所述CT图像特征与所述肺结节位置的所述对应关系；其中,所述获取用于建立所述CT图像特征与所述肺结节位置之间的对应关系的样本数据的步骤,包括：收集不同肺结节状况的患者的所述CT图像特征和所述肺结节位置；对所述CT图像特征进行分析、并结合预存的专家经验信息,选取与所述肺结节位置相关的数据作为所述CT图像特征；将所述肺结节位置、以及选取的所述CT图像特征构成的数据对,作为样本数据；其中,对所述网络结构和所述网络参数进行训练,包括：选取所述样本数据中的一部分数据作为训练样本,将所述训练样本中的所述CT图像特征输入到所述网络结构,通过所述网络结构的激活函数和所述网络参数进行训练,得到实际训练结果；确定所述实际训练结果与所述训练样本中的相应肺结节位置之间的实际训练误差是否满足预设训练误差；当所述实际训练误差满足所述预设训练误差时,确定对所述网络结构和所述网络参数的所述训练完成；和/或,对所述网络结构和所述网络参数进行测试,包括：选取所述样本数据中的另一部分数据作为测试样本,将所述测试样本中的所述CT图像特征输入到所述训练完成的所述网络结构中,以所述激活函数和所述训练完成的所述网络参数进行测试,得到实际测试结果；确定所述实际测试结果与所述测试样本中的相应肺结节位置之间的实际测试误差是否满足设定测试误差；当所述实际测试误差满足所述设定测试误差时,确定对所述网络结构和所述网络参数的所述测试完成；其中,对所述网络结构和所述网络参数进行训练,还包括：当所述实际训练误差不满足所述设定训练误差时,通过所述网络结构的误差能量函数更新所述网络参数；通过所述网络结构的所述激活函数和更新后的所述网络参数进行重新训练,直至所述重新训练后的实际训练误差满足所述设定训练误差；和/或,对所述网络结构和所述网络参数进行测试,还包括：当所述实际测试误差不满足所述设定测试误差时,对所述网络结构和所述网络参数进行重新训练,直至所述重新训练后的实际测试误差慢速所述设定测试误差；获取患者的当前肺部的当前CT图像特征；通过所述对应关系,确定与所述当前CT图像特征对应的当前肺结节位置；具体地,确定与所述CT图像特征对应的当前肺结节位置,包括：将所述对应关系中与所述当前CT图像特征相同的CT图像特征所对应的肺结节位置,确定为所述当前肺结节位置；其中,所述CT图像特征,包括：空间特征和/或通道特征,和/或由按设定规律自所述空间特征、所述通道特征中提取的特征组成的一维或两维以上的数组；其中,所述空间特征,包括：肺部CT图像中每一个二维切片对应的像素值,肺部CT图像中的HU值；所述通道特征,包括：肺部CT图像中每一个二维切片；和/或,所述对应关系,包括：函数关系；所述CT图像特征为所述函数关系的输入参数,所述肺结节位置为所述函数关系的输出参数；确定与所述当前CT图像特征对应的当前肺结节位置,还包括：当所述对应关系包括函数关系时,将所述当前CT图像特征输入所述函数关系中,确定所述函数关系的输出参数为当前肺结节位置。</td>   <td>G16H50/20;G06T7/00;G06N3/0464;G06F3/048;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;                   滕伟       </td>   <td>中山大学</td>   <td>一种基于门控图卷积网络的商品推荐方法及系统、存储介质</td>   <td>广东省</td>   <td>CN111080400B</td>   <td>2023-04-18</td>   <td>本发明涉及一种基于门控图卷积网络的商品推荐方法,包括：将会话序列建模为无向图；无向图中,一个顶点代表一个商品,每条边代表用户在会话的连续两次点击中点击了边两端的商品,根据每条边在会话中出现的次数赋予每条边相应次数的权重；将会话序列中所有会话中的商品初始化到一个统一的嵌入空间中,得到每个会话中的商品的嵌入表示,通过图卷积网络和门控循环单元学习会话中商品的嵌入表示；根据学习到的会话中商品的嵌入表示,对会话的嵌入表示进行学习；根据得到的所有商品的嵌入表示,以及每个会话的嵌入表示,将之进行相乘,然后通过softmax函数进行归一化处理,得到针对每个会话所有商品的推荐分数,根据所述推荐分数进行商品推荐。</td>   <td>1.一种基于门控图卷积网络的商品推荐方法,其特征在于：包括：将会话序列建模为无向图；无向图中,一个顶点代表一个商品,每条边代表用户在会话的连续两次点击中点击了边两端的商品,根据每条边在会话中出现的次数赋予每条边相应次数的权重；将会话序列中所有会话中的商品初始化到一个统一的嵌入空间中,得到每个会话中的商品的嵌入表示,通过图卷积网络和门控循环单元学习会话中商品的嵌入表示；根据学习到的会话中商品的嵌入表示,对会话的嵌入表示进行学习；根据得到的所有商品的嵌入表示,以及每个会话的嵌入表示,将之进行相乘,然后通过softmax函数进行归一化处理,得到针对每个会话所有商品的推荐分数,根据所述推荐分数进行商品推荐；所述通过图卷积网络和门控循环单元学习会话中商品的嵌入表示的具体过程如下：对于单个会话s,具体操作由如下公式表示：                  r-s＝σ(G-sW-(ir)+b-(ir)+X-sW-(hr)+b-(hr))z-s＝σ(G-sW-(iz)+b-(iz)+X-sW-(hz)+b-(hz))n-s＝tanh(G-sW-(in)+b-(in)+(X-s*r-s)W-(hn)+b-(hn))V-s＝(1-z-s)*X-s+z-s*n-s其中其中A-s∈R～(n×n)为根据会话序列s构建的无向图得到的带权邻接矩阵,包含了会话图中商品顶点之间的连接信息,其中n为会话s中不同商品的个数,/&gt;为/&gt;的度矩阵,其对角线上每个元素表示将会话图中每个商品顶点的与所有商品顶点的连接信息求和,/&gt;为将/&gt;归一化后的结果；X-s∈R～(n×h)为会话s中不同商品的初始化嵌入表示,h为统一的嵌入维度,即每个商品初始为一个h维向量表示；W-0∈R～(h×h)、W-1∈R～(h×h)为可学习的参数矩阵；ReLU(·)为线性整流函数,σ(·)为sigmoid函数,tanh(·)为双曲正切函数,*为Hadamard积；G-s为X-s经过两层图卷积后的结果,其中每一行表示每个商品经过图卷积信息传播后的商品嵌入表示,W-(ir),W-(hr),W-(iz),W-(hz),W-(in),W-(hn)∈R～(h×h),b-(ir),b-(hr),b-(iz),b-(hz),b-(in),b-(hn)∈R～(n×1)为可学习的参数矩阵,将G-s和X-s代入门控循环单元公式可以得到会话s中不同商品嵌入表示V-s∈R～(n×h),其中r-s和z-s为重置门和更新门,分别控制商品嵌入表示信息的遗忘和更新,n-s为商品的嵌入表示的候选状态信息；所述会话的嵌入表示的学习过程具体如下：求取会话的邻近嵌入表示、局部嵌入表示、全局嵌入表示,将全局嵌入表示、局部嵌入表示、邻近嵌入表示进行拼接并经过一个线性转换得到混合嵌入表示作为会话的嵌入表示。</td>   <td>G06Q30/0601;G06N3/084;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         冯展祥;              赖剑煌;                   谢晓华       </td>   <td>中山大学</td>   <td>一种基于跨分辨率知识蒸馏的神经网络加速方法</td>   <td>广东省</td>   <td>CN111160533B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于跨分辨率知识蒸馏的神经网络加速方法,包括：获取高、低分辨率训练样本；构建高、低分辨率学生网络；通过高分辨率样本数据预训练教师网络；固定教师网络参数,并从高分辨率图像提取教师网络输出；利用学生网络提取低分辨率图像特征,并通过跨分辨率蒸馏损失约束高分辨率教师网络和低分辨率学生网络输出特征保持一致；测试阶段,利用学生网络从低分辨率输入图像提取鲁棒特征。本发明利用跨分辨率蒸馏损失实现高低分辨率领域之间的知识传播,通过从低分辨率图像提取特征加速网络,减少计算复杂度,利用高分辨率图像先验知识提高深度特则的判别能力和泛化能力,在大幅度减少深度网络计算复杂度的同时保持优秀的识别性能。</td>   <td>1.一种基于跨分辨率知识蒸馏的神经网络加速方法,其特征在于,包括步骤：(1)获取同一图像的高分辨率图像和低分辨率图像,将上述高分辨率图像和低分辨率图像分别作为高分辨率训练样本、低分辨率训练样本；(2)构建跨分辨率知识蒸馏基本框架,该框架包括高分辨率教师网络和低分辨率学生网络；(3)通过高分辨率样本数据预训练高分辨率教师网络,得到教师网络参数；(4)固定教师网络参数,并从高分辨率图像提取教师网络输出；利用学生网络提取低分辨率图像特征,并通过跨分辨率蒸馏损失约束高分辨率教师网络和低分辨率学生网络输出特征保持一致；所述步骤(4)中,跨分辨率知识蒸馏损失包括两部分,其中一部分是分辨率无关蒸馏损失L-(RD),另外一部分是成对欧式空间特征约束L-(PEC)；跨分辨率知识蒸馏损失的目标函数表示为：L＝(1-α)L-(CE)(y,z-s)+αL-(RD)+βL-(PEC)其中,α是分辨率无关蒸馏损失相关的权值,β是成对欧式空间特征约束相关的权值,L-(CE)是交叉熵损失函数,y是训练样本对应的类标,z-s是学生网络的输出；分辨率无关蒸馏损失迫使学生网络模仿教师网络的输出,使得来自不同分辨率输入图像的网络产生分布接近的输出特征,方法是：采用KL散度约束学生网络和教师网络的响应输出以获取相近的特征概率分布,用公式表示为：                  其中z-t和z-s对应教师网络和学生网络的输出,σ(.)对应Softmax函数的响应,T是平滑蒸馏损失的参数,N表示样本个数,L-(KL)(.)是KL散度,其公式为：                  其中所述成对欧式空间特征约束直接在特征空间对教师网络和学生网络的特征进行约束,使得教师网络的输出和学生网络的输出在欧式空间接近,用公式表示为：                  其中,(x～h,x～l)表示高分辨率训练样本、低分辨率训练样本,N表示样本个数,W-t代表教师网络的参数,W-s代表学生网络的参数；(5)测试阶段,利用学生网络从低分辨率输入图像提取鲁棒特征。</td>   <td>G06N3/045;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   邓卓爽       </td>   <td>中山大学</td>   <td>一种基于深度学习的自然图像抠图方法</td>   <td>广东省</td>   <td>CN111161277B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于深度学习的自然图像抠图方法,其包括以下步骤：获取抠图数据集,并进行数据增强；搭建具有编码器-解码器结构的自然图像抠图模型,为保留细节信息,设计编码器使其下采样倍数为4,为弥补下采样倍数下降带来的感受野变小,引入空洞卷积扩大感受野,保存最大池化操作中最大像素位置,以便为上采样阶段提供位置信息；为解决多尺度问题,在编码器顶部连接一个空洞空间金字塔模块；在解码器中设计全局语境模块,用于融合所述编码器与解码器对应的高层特征；最后训练并测试。本发明在提取特征过程中保留更多细节信息,同时关联多尺度特征,使模型能捕抓到全局信息,有利于模型处理细节以及大面积透明物体,提升抠图质量。</td>   <td>1.一种基于深度学习的自然图像抠图方法,其特征在于,包括步骤：S1：获取抠图数据集,把所述抠图数据集中样本划分为训练集与测试集；S2：搭建具有编码器-解码器结构的自然图像抠图模型,该模型中所述编码器的下采样倍数为4,结合普通卷积和空洞卷积操作；编码器顶部连接一个空洞空间金字塔池化模块；所述解码器包含全局语境模块,用于融合所述编码器与解码器对应的高层特征；步骤S2中,所述编码器由5个stage组成,在stage1和stage2中使用普通卷积和步长为2的最大池化操作,把stage3和stage4中最大池化操作的步长设为1,去除stage5的池化操作,以上结构使得所述编码器的下采样倍数为4；在stage4和stage5引入空洞卷积操作；把所有全连接层替换成一层卷积核大小为1的卷积层；步骤S2中所述解码器包括4个阶段：阶段D4：对输出自所述空洞空间金字塔池化模块的特征图进行卷积操作,利用所述全局语境模块对所得特征图和所述编码器stage5的输出进行融合,利用所述编码器stage4最大池化操作保留的最大值坐标信息,对全局语境模块输出的特征图进行反池化操作,步长设置为1,使特征图尺度保持不变；阶段D3：对输出自阶段D4的特征图进行卷积操作,利用所述全局语境模块对所得特征图和所述编码器stage4的输出进行融合,利用所述编码器stage3最大池化操作保留的最大值坐标信息,对全局语境模块输出的特征图进行反池化操作,步长设置为1,使特征图尺度保持不变；阶段D2：对输出自阶段D3的特征图进行卷积操作,利用所述编码器stage2最大池化操作保留的最大值坐标信息,对所得特征图进行反池化操作,步长设置为2,使特征图上采样2倍；阶段D1：对输出自阶段D2的特征图进行卷积操作,利用所述编码器stage1最大池化操作保留的最大值坐标信息,对所得特征图进行反池化操作,步长设置为2,使特征图上采样2倍,尺度恢复原图大小,对所得特征度进行两次卷积操作,通道数降为1,最后通过sigmoid函数输出预测的alpha蒙版；S3：初始化并训练模型,利用所述训练集中的alpha蒙版生成三元图,把原图与三元图作为模型输入,对模型进行训练,模型输出为预测的alpha蒙版,计算预测的alpha蒙版与真实alpha蒙版之间的误差,保存在所述测试集上表现最好的模型；S4：将需要测试的图片及对应的三元图输入到已训练好的自然图像抠图模型中,得到预测的alpha蒙版。</td>   <td>G06T7/11;G06T7/194;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;              苏吟雪;                   林会智       </td>   <td>中山大学</td>   <td>一种基于两方签名的区块链钱包客户端私钥保护方法</td>   <td>广东省</td>   <td>CN111191262B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于两方签名的区块链钱包客户端私钥保护方法,涉及用户区块链钱包和私钥服务器,包括用户区块链钱包和私钥服务器初始化的过程,通过该过程用户区块链钱包获得私钥服务器的部分公钥,私钥服务器获得用户区块链钱包的初始部分公钥和初始链码；之后用户区块链钱包根据私钥服务器的部分公钥和本地部分私钥生成用户的第i个区块链地址,其中0≤i＜2～(31)；最后用户区块链钱包和私钥服务器根据两方签名协议,生成关于第i个区块链地址的数字签名；本发明融合了两方签名协议和区块链钱包的业界规范,降低了区块链钱包私钥泄露的风险,提升了区块链钱包客户端的安全性。</td>   <td>1.一种基于两方签名的区块链钱包客户端私钥保护方法,涉及用户区块链钱包和私钥服务器两个实体,其特征在于包括以下步骤：A)用户区块链钱包和私钥服务器初始化,用户区块链钱包获得私钥服务器的部分公钥pk-(BA),私钥服务器获得用户区块链钱包的初始部分公钥和初始链码/&gt;B)用户区块链钱包根据私钥服务器的部分公钥pk-(BA)和本地部分私钥生成用户的第i个区块链地址,其中0≤i＜2～(31)；C)用户区块链钱包和私钥服务器根据两方签名协议,生成关于第i个区块链地址的数字签名；所述步骤A)包括以下子步骤：A1)用户区块链钱包与私钥服务器通过TLS协议建立一个认证的安全通道；A2)用户区块链钱包遵循BIP0044规范,生成一个初始部分私钥和初始链码/&gt;并使用初始部分私钥计算初始部分公钥/&gt;A3)用户区块链钱包通过认证的安全通道发送和/&gt;给私钥服务器；A4)私钥服务器根据两方签名协议计算私钥服务器的部分公钥pk-(BA)；A5)私钥服务器通过认证的安全通道发送pk-(BA)给用户区块链钱包；A6)用户区块链钱包存储pk-(BA),私钥服务器存储和/&gt;所述步骤B)包括以下子步骤：B1)用户区块链钱包根据BIP0044规范计算第i个本地部分私钥其中0≤i＜2～(31)；B2)用户区块链钱包输入本地部分私钥和私钥服务器公钥pk-(BA),根据两方签名协议,计算第i个区块链地址对应的公钥,并使用该公钥计算区块链地址；所述步骤C)包括以下子步骤：C1)用户区块链钱包生成交易数据M做为待签名数据；C2)用户区块链钱包确定需要解锁的区块链地址的序号i；C3)用户区块链钱包与私钥服务器根据两方签名协议的需要建立认证的安全通道；C4)用户区块链钱包根据两方签名协议的需要向私钥服务器发送序号i,之后私钥服务器根据BIP0044标准,基于和/&gt;计算第i个部分公钥/&gt;C5)用户区块链钱包与私钥服务器交换两方签名协议的消息,生成针对第i个区块链地址的数字签名。</td>   <td>G06F21/60;G06F21/62;G06F21/64;G06Q20/36;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;                   张朗淇       </td>   <td>中山大学</td>   <td>一种基于云簇的虚拟机借调方法</td>   <td>广东省</td>   <td>CN111338754B</td>   <td>2023-04-18</td>   <td>本发明涉及计算机技术领域,是基于云簇的虚拟机借调方法,包括步骤：微云接收终端计算机的任务请求,将任务请求转化为一定数量和规格的虚拟机申请；微云在本地资源充足时,直接服务任务请求；在本地资源不足时,计算每个邻居微云可提供的虚拟机数量以及任务成本；微云根据跨微云虚拟机借调算法生成虚拟机借调方案；依据虚拟机借调方案,微云向租借方案列表中的邻居微云进行虚拟机借调。本发明支持在本地微云本地资源不足时,按照跨微云的虚拟机调度算法,从空闲微云处进行虚拟机借调,满足本地的用户任务需求,达到了在微云之间共享闲置资源的目的。</td>   <td>1.一种基于云簇的虚拟机借调方法,其特征在于,包括以下步骤：S1、微云接收终端计算机的任务请求,将任务请求转化为一定数量和规格的虚拟机申请；S2、微云在本地资源充足时,直接服务任务请求；在本地资源不足时,计算每个邻居微云可提供的虚拟机数量以及任务成本；S3、微云根据跨微云虚拟机借调算法生成虚拟机借调方案；S4、依据虚拟机借调方案,微云向租借方案列表中的邻居微云进行虚拟机借调；在步骤S3中,跨微云虚拟机借调算法为：按照每个邻居微云的任务成本进行排序,选择任务成本最小的邻居微云添加入借调方案中,然后在剩余的邻居微云继续重复这一步骤,直至满足任务要求的虚拟机数量或者是没有可供选择的剩余邻居微云,最终获得本次的借调方案；S31、获取邻居微云列表和本次借调所需的虚拟机数量,邻居微云列表包含步骤S2中计算得出的每个邻居微云的可借用虚拟机数量和任务成本,将每个邻居微云可借调的虚拟机数量以及任务成本作为结果添加入候选列表中；S32、计算借调方案列表,将候选列表中的微云按任务成本大小进行升序排序；S33、选择任务成本最小的邻居微云添加入借调方案列表中,同时记录对应的借调数量；S34、在剩余的邻居微云中重复步骤S33,直至满足任务要求的虚拟机数量或者邻居微云列表中无可供选择的邻居微云；若邻居微云列表中无可供选择的邻居微云且任务要求的虚拟机数量没有满足,则将借调方案列表清空；S35、返回借调方案列表,若借调方案列表为空,则表示无可用的虚拟机借调方案；若不为空,则表示有可用的虚拟机借调方案；步骤S2包括：S21、微云的资源调度模块收到虚拟机申请后,使用本地微云的虚拟机资源池来创建虚拟机；当本地资源无法满足全部虚拟机申请时,用本地的剩余资源提供部分虚拟机,欠缺部分的虚拟机向邻居微云借调；S22、邻居微云的可借用资源信息保存在邻居微云资源列表中,由微云的资源调度模块负责更新和维护；本地微云的资源调度模块通过云簇管理接口模块定时与邻居微云通信,获取邻居微云的可借用资源信息；S23、计算邻居微云可提供的虚拟机数量,计算方式为：(1)分别计算邻居微云的各项剩余资源指标除以虚拟机规格中对应指标的结果；(2)然后取这些结果中的最小值作为该邻居微云可提供的虚拟机数量：                  其中total-cpu指邻居微云可供借调的cpu资源,total-ram指邻居微云可供借调的内存资源,total-disk指邻居微云可供借调的硬盘资源,total-bandwidth指邻居微云可供借调的带宽资源,vm-cpu指虚拟机规格要求的cpu资源,vm-ram指虚拟机规格要求的内存资源,vm-disk指虚拟机规格要求的硬盘资源,vm-bandwidth指虚拟机规格要求的带宽资源；S24、计算邻居微云的任务成本,邻居微云的任务成本等于传输成本、运行成本和服务质量成本的加权和：cost-task＝w-1*cost-trans+w-2*cost-use+w-3*cost-qos其中,w-1、w-2及w-3是权重,w-1+w-2+w-3＝1,cost-task是任务成本,cost-trans是传输成本,cost-use是使用成本,cost-qos是服务质量成本；传输成本指将任务镜像从本地微云转载到邻居微云,提供虚拟机服务所需要的传输开销；运行成本指任务虚拟机在邻居微云上运行时的开销,与任务时长和该邻居微云的虚拟机单位时长运行成本有关；服务质量成本指邻居微云提供的虚拟机在用户服务质量方面的评估指标,与虚拟机的时延以及虚拟机的启动时间有关；步骤S4包括：S41、申请方微云向邻居微云发送与任务相关的预申请信息,包括：虚拟机数量、虚拟机规格、使用时长、镜像校验信息；S42、邻居微云收到预申请信息后,查看自身资源是否足够,确认本地是否有对应的任务镜像；若自身资源足够,则进行借调,为申请方进行资源的预留；若自身资源不足,则不进行借调,将在返回信息中附上最新的可借调资源情况；若本地无对应镜像且资源足够,则进行镜像传输,将在返回信息中要求申请方微云进行任务镜像传输；S43、当存在一个邻居微云拒绝了预申请时,申请方微云需要重新规划借调方案,采用增量方式重新提交新的预申请；申请方微云将根据返回信息,更新自身的邻居微云资源列表,并统计欠缺的虚拟机数量,使用步骤S3中的算法计算增量式的借调方案列表；S44、当申请方微云的所有预申请都成功后,将向参与借调的所有邻居微云进行申请的确认；若存在被拒绝的预申请同时又无可用的增量式借调方案时,代表着邻居微云无足够的资源可供借调,在该情况下申请方微云需要通知参与借调的邻居微云,取消预申请,并拒绝为终端计算机的任务请求提供服务；S45、收到申请确认后,邻居微云按照任务要求,使用任务镜像为申请方微云生成对应数量和规格的虚拟机,并向申请方微云返回虚拟机的连接许可,并赋予申请方对这些虚拟机的管理权限；S46、任务虚拟机建立在邻居微云上,由邻居微云直接提供服务,申请方微云将终端计算机的虚拟机连接请求通过连接凭证重定向到邻居微云的虚拟机中。</td>   <td>G06F9/455;H04L67/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;                   王铎沣       </td>   <td>中山大学</td>   <td>一种图像描述生成方法、系统、装置和存储介质</td>   <td>广东省</td>   <td>CN111368118B</td>   <td>2023-04-18</td>   <td>本发明公开了一种图像描述生成方法、系统、装置和存储介质,其中方法包括以下步骤：获取图片信息；采用基于融合多种特征的图像描述模型对图片信息进行处理后,获得描述信息；所述多种特征包括区块特征、目标特征和文本特征。本发明的图像描述模型在训练过程中,融合了区块特征、目标特征和文,基于多种特征进行融合,根据不同特征表示的语义层级不同,高语义层级的特征向量可以为底层的特征向量起到信息指导的作用,低语义层级的特征向量可以为高层级的特征向量起到信息,使得生成的句子描述更加准确,提高图像描述的效果,可广泛应用于数据处理技术领域。</td>   <td>1.一种图像描述生成方法,其特征在于,包括以下步骤：获取图片信息；采用基于融合多种特征的图像描述模型对图片信息进行处理后,获得描述信息；所述多种特征包括区块特征、目标特征和文本特征；还包括建立图像描述模型的步骤,具体包括以下步骤：采用预设网络提取图像数据集的区块特征、目标特征及文本特征；采用刺激性关注机制对区块特征进行处理后,将目标特征、文本特征及处理后的区块特征输入transformer模块；采用多模融合映射模块对输入transformer模块的特征进行特征融合,获得融合特征；结合融合特征和预设的损失函数对网络进行训练,并在训练完成后,获得图像描述模型；所述采用预设网络提取图像数据集的区块特征、目标特征及文本特征这一步骤,具体包括以下步骤：采用第一预设神经网络提取图像数据集的区块特征,所述第一预设神经网络为深度残差网络；采用第二预设神经网络提取图像数据集的目标特征,所述第二预设神经网络为用于目标检测的卷积神经网络；采用第三预设神经网络提取图像数据集的文本特征,所述第三预设神经网络为用于文本分类的卷积神经网络；所述采用刺激性关注机制对区块特征进行处理这一步骤,具体为：基于SALICON数据集训练获得显著目标预测网络,根据显著目标预测网络获得刺激性关注机制网络；将区块特征输入刺激性关注机制网络进行处理后,获得处理后的区块特征；所述刺激性关注机制网络的公式表达式为：                  其中,所述I′代表经过处理后的区块特征,所述W-v代表卷积核数量为2048,卷积核大小为1的卷积层,所述代表矩阵对应元素的乘法计算,所述W-(sal)代表利用显著目标预测网络的得到的卷积层,所述I代表输入的区块特征,所述∈代表一个超参。</td>   <td>G06F16/58;G06F16/583;G06N3/0455;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              叶雪辀;              甘叔玮;                   林彬       </td>   <td>中山大学</td>   <td>基于张角序列的像机标定异面控制点自动匹配方法</td>   <td>广东省</td>   <td>CN111524191B</td>   <td>2023-04-18</td>   <td>本发明公开一种基于张角序列的像机标定异面控制点自动匹配方法,包括：获取控制点和相机光心三维空间坐标以及控制点在像素坐标系下的二维图像坐标；获取三维控制点两两相对于相机光心的夹角,形成第一角度序列矩阵,获取该矩阵中的最大值；筛选出距离最远的两个二维控制点,得到像机的等效焦距；基于等效焦距得到二维控制点两两相对于相机坐标系原点的夹角,形成第二角度序列矩阵；基于第一角度序列矩阵与第二角度序列矩阵得到每一个三维控制点与所有二维控制点的距离矩阵；基于距离矩阵完成像机标定异面控制点的匹配。利用张角序列对于序列的不一致具有鲁棒性,同时除了像点误差、物点误差及光心初值误差以外,张角序列不会额外引入其他误差。</td>   <td>1.一种基于张角序列的像机标定异面控制点自动匹配方法,其特征在于,包括如下步骤：步骤1,获取所有控制点和相机光心在世界坐标系下的三维空间坐标以及所有控制点在像素坐标系下的二维图像坐标；步骤2,计算世界坐标系下所有三维控制点两两之间P-i、P-j相对于光心O-w的夹角∠P-iO-wP-j,形成N×N的第一角度序列矩阵[X-(ij)]-(N×N),并获取矩阵[X-(ij)]-(N×N)中的最大值α-(max),其中,N为控制点的总数,i＝1,2,3···,j＝1,2,3···,i≠j；步骤3,筛选出像素坐标系下距离最远的两个二维控制点p-a、p-b,根据α-(max)与点p-a、p-b的二维图像坐标得到像机的等效焦距f；步骤4,基于等效焦距f得到所有二维控制点两两之间p-i、p-j相对于相机坐标系原点O-c的夹角∠p-iO-cp-j,形成N×N的第二角度序列矩阵[x-(ij)]-(N×N)；步骤5,基于矩阵[X-(ij)]-(N×N)与矩阵[x-(ij)]-(N×N)得到每一个三维控制点与所有二维控制点的距离,形成N×N的距离矩阵；步骤6,基于距离矩阵完成像机标定异面控制点的匹配。</td>   <td>G06T7/80;G06V10/75</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴博文;              谢震宇;              梁小丹;              董浩业;                   林倞       </td>   <td>中山大学</td>   <td>一种基于单张图片的运动转移方法及系统</td>   <td>广东省</td>   <td>CN111539262B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于单张图片的运动转移方法及系统,所述方法包括：步骤S1,对源视频利用人体姿态估计器获得对应的姿势序列S-(pose),对目标人物图片I使用人体解析器获取对应的人体解析分割图I-(parsing),根据源视频对应的姿势序列S-(pose)以及人体解析分割图I-(parsing),生成目标视频的人体语义解析图步骤S2,根据生成人体语义解析图以及目标人物外观图片前景I-a,生成目标视频的前景步骤S3,通过修护后的背景图bg、步骤S2中生成的前景以及步骤S2中生成的前一帧前景预测出前景掩膜,并通过该前景掩膜融合前后景得到最终目标视频中的帧x～t。</td>   <td>1.一种基于单张图片的运动转移方法,包括如下步骤：步骤S1,对源视频利用人体姿态估计器获得对应的姿势序列S-(pose),对目标人物图片I使用人体解析器获取目标人物图片I所对应的人体解析分割图I-(parsing),根据源视频对应的姿势序列S-(pose)以及目标人物图片I所对应的人体解析分割图I-(parsing),并生成目标视频的人体语义解析图步骤S2,根据步骤S1中生成的目标视频的人体语义解析图以及目标人物外观图片前景I-a,生成目标视频的前景/&gt;步骤S3,通过修护后的背景图bg、步骤S2中生成的前景以及步骤S2中生成的前一帧前景/&gt;预测出前景掩膜fg-maskt,并通过该前景掩膜融合前后景得到最终目标视频中的帧x～t；步骤S1进一步包括：步骤S100,对源视频的每一帧通过人体姿态估计器获得包含若干特征点的姿态图,所述姿态图上每个特征点都被转化为1通道的热图,将每个特征点对应的热图按通道拼接起来,得到编码人体姿态信息的18通道的热图,从而获得所述源视频所对应的姿势序列S-(pose)；步骤S101,对步骤S100所获得的姿势序列S-(pose)进行时序光滑；步骤S102,使用人体解析器获取目标人物图片I所对应的人体解析分割图I-(parsing),该分割图上不同区域对应人体的不同部位,并利用该人体解析分割图I-(parsing)分割目标人物图片I得到外观图片前景I-a；步骤S103,将姿势序列S-(pose)中的姿势热图逐帧与目标人物图片I所对应的人体解析分割图I-(parsing)一起输入到残差网络结构的生成器中,所述生成器输出第i帧对应的人体语义解析图从而得到目标视频的人体语义解析序列。</td>   <td>G06V20/40;G06V40/20;G06V20/70;G06V10/26;G06V10/82;G06N3/0475;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         印鉴;              陈智聪;                   陈殷齐       </td>   <td>中山大学</td>   <td>一种基于深度学习的视频哈希检索表征转换方法</td>   <td>广东省</td>   <td>CN111563184B</td>   <td>2023-04-18</td>   <td>本发明提供一种基于深度学习的视频哈希检索表征转换方法,该方法通过G网络中的视频输入层以及RseNet的深度学习模型学习到视频的上下文特征,能够提取出可以表达视频类型的特征,并且经过精心设计的Hash层模拟哈希编解码过程转换成n位编码从而优化存储空间,使得视频特征存储所占空间极大降低。并为训练过程设计了直接度量汉明距离的损失函数,使得训练过程与检索过程使用的距离度量指标完全一致,从而增强检索准确率。</td>   <td>1.一种基于深度学习的视频哈希检索表征转换方法,其特征在于,包括以下步骤：S1：建立用于视频特征提取的深度学习网络模型G；S2：在网络模型G后加上哈希检索表征转换层即Hash层；S3：用新的度量汉明距离的损失函数对模型进行训练与测试；所述步骤S3的具体过程是：S31：将数据集分为训练数据以及测试数据；S32：整体的模型要进行训练,G网络的训练步骤如下：由G网络提取出视频特征,经过哈Hash层由新设计的汉明距离损失函数的最小化来训练G网络模型,训练G网络的参数；步骤S32中,G网络的训练过程中,采用交叉熵损失与三元组损失作为损失函数,并且损失值的大小是根据交叉熵损失与三元组损失的总和,其中三元组损失中的距离度量函数为新的汉明距离度量,传统的欧式距离跟在实际中使用的汉明距离检索有本质的不同,这导致了转换为哈希后距离计算与训练中的距离不一致,汉明距离损失计算如下：在前面的网络经过哈希表征转换层之后到每一个视频的编码output,根据三元组损失：Loss＝||output-a-output-p||-H-||output-a-output-n||-H+Margin,其中output-a为锚点,output-p为正样本,output-n为正样本,目的是使得锚点尽量接近正样本,远离负样本,||·||为在某个度量空间中的距离计算,设计的||·||-H为在汉明空间上的距离度量,解决了传统方法中无法直接度量汉明距离而用欧氏距离代替的问题,计算如下：汉明距离的计算是计算俩个二进制数串中相同的个数,在经过哈希表征转换层之后,把二进制的0,1表示成正负数,正因为这种表征形式,二进制相同的与否的判断运算可以转换为相同位置正负号是否相同的运算,俩个向量的相同位置做一个乘法,如果他们是相同符号的则为正,反之则为负,那么计算负号的个数即为俩个编码的汉明距离,一个正负数转换为计数可以使用sigmoid函数σ(·),如果为负数那么sigmiod的值为0,反之为1,所以对编码结果的俩个向量点乘之后按位做sigmiod操作再求和即为俩个output向量符号相同的位的个数,那么不同的即为其与n的差,这样就用可导的方式为俩个编码向量的汉明距离做了度量,使得训练过程用的距离度量和检索过程用的距离度量一致,训练过程中采用SGD进行优化,采用Margin设置距离间距,防止过拟合；S33：模型的测试步骤为：先过第一遍测试数据集,将测试数据输入到G网络,然后由G网络生成特征,将特征编码结果存储到数据库DB1；然后进行第二遍特征mAP计算,将每一个视频的输出编码与DB1中数据进行距离计算,之后进行mAP计算,具体计算方式是：计算所有视频间的距离,然后按距离从小到大排序,接着判断是否属于同类视频,若第t个视频特征,如果是则正确数加1,正确数表示为r,然后计算AP即r除以t,把所有视频的AP计算出来后进行求AP总和,并处以视频总数量n,即得到最终结果mAP；S4：建立用于提供后台接口的进程,提供检索入口以及返回检索结果。</td>   <td>G06F16/78;G06F16/732</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王熊辉;              胡建芳;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种网页端人物换背景的方法</td>   <td>广东省</td>   <td>CN111581568B</td>   <td>2023-04-18</td>   <td>本发明公开了一种网页端人物换背景的方法,包括下述步骤：上传待转换背景的图片或视频；构建网页端人物换背景架构；在服务器端对其进行预处理,采用Mask-RCNN作为图像分割模型,使用训练好的分割模型并行运算得到二值化的掩膜；得到的掩膜经过高斯低通滤波器进行羽化,然后和指定的背景进行融合,得到换背景后的图片或视频；将输入图片、掩膜和换背景后的图片存入数据库中,并将换背景后的图片返回至网页端。本发明提出的一种网页端人物换背景的方法,通过网页和服务器之间的通信,将复杂的计算过程放到服务器计算,它可以同时满足对图片和视频分割的快速性和准确性要求。</td>   <td>1.一种网页端人物换背景的方法,其特征在于,包括下述步骤：上传待转换背景的图片或视频；构建网页端人物换背景架构,包括前端和后端,前端采用React进行网页端设计,用以上传和下载图片和视频,后端使用Django接受图片利用卷积神经网络进行图片分割,将分割出的人体与新的背景做融合；使用SQLite实现数据库,用以储存原始图片以及背景图片；前端和后端之间使用nginx反向代理进行前后端交互；所述网页端提供的功能有待分割图片选择,背景选择,分割模型主干网络选择,分割后mask下载和换背景后的图片下载；Django用于网页后台逻辑的实现和数据的读取,负责给用户提供预设好的背景图片,将用户上传的待换背景图片或视频传输至服务器,解帧后送入预训练好的Mask-RCNN计算得到前景的掩膜,再将前景和预设的背景融合,保存到数据库中并返回至网页端；用公式来更具体的描述换背景的过程,记I为输入图片,J为预设的背景图片,Θ为若干个1*1的卷积层,则离散化前的掩膜可以表示为：M＝sigmoid(Θ(f-I))其中f-I是输入图片的CNN特征图上的ROI区域,M代表ROI每一个像素点是前景的概率,通过sigmoid函数计算得到,其二元交叉熵即为损失函数L-(mask),利用双线性插值将M恢复至原图大小,再以0.5为阈值将其进行二值化,得到离散化后的掩膜则输出图片可以表示为：                  其中⊙表示对位乘法；在服务器端对其进行预处理,采用Mask-RCNN作为图像分割模型,使用训练好的分割模型并行运算得到二值化的掩膜；得到的二值化掩膜经过高斯低通滤波器进行羽化,然后和指定的背景进行融合,得到换背景后的图片或视频；将输入图片、掩膜和换背景后的图片存入数据库中,并将换背景后的图片返回至网页端。</td>   <td>G06F16/958;G06T1/20;G06T5/00;G06T7/194;G06F16/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁姗姗;              岳孟挺;              李新宇;                   张军       </td>   <td>中山大学</td>   <td>基于深度学习的视网膜层和积液区域的层分割方法及系统</td>   <td>广东省</td>   <td>CN111583291B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于深度学习的视网膜层和积液区域的层分割方法及系统,所述方法包括：获取医疗系统中各节点区域的视网膜OCT数据集,将该数据集划分为预训练数据集及测试数据集,对预训练数据集中的数据进行随机平移,得到训练数据集；根据构建的分割网络及对应的损失函数对分批次送入该分割网络的训练数据集中的数据进行前向传播,得到分割预测图；根据联合损失函数公式计算分割预测图与专家像素级标记图像进行one-hot编码后的标准概率图之间的联合损失值,将联合损失值反向传播,通过预设周期长度的迭代训练得到分割网络模型；通过测试数据集对分割网络模型进行测试,以验证分割网络模型的可靠性。本发明能够提高分割网络泛化能力与类别分割准确率。</td>   <td>1.一种基于深度学习的视网膜层和积液区域的层分割方法,其特征在于,所述方法包括如下步骤：获取医疗系统中各节点区域的视网膜OCT数据集,将所述视网膜OCT数据集划分为预训练数据集及测试数据集,并对所述预训练数据集中的数据进行随机平移,以得到训练数据集；根据构建的改进型Unet分割网络及该分割网络对应的损失函数,对分批次送入该分割网络的训练数据集中的数据进行前向传播,以得到分割预测图；根据联合损失函数公式计算分割预测图与专家像素级标记图像进行one-hot编码后的标准概率图之间的联合损失值,将所述联合损失值进行反向传播,并通过预设周期长度的迭代训练得到分割网络模型；通过所述测试数据集对分割网络模型进行测试,以验证所述分割网络模型的可靠性；根据构建的改进型Unet分割网络及该分割网络对应的损失函数,对分批次送入该分割网络的训练数据集中的数据进行前向传播,以得到分割预测图的方法包括：在Unet网络中的每个编码模块和解码模块的3*3卷积块之前增加一个1*1卷积层,在该1*1卷积层之后分别建立一个SE模块和空分支,SE模块的分支和3*3卷积块并联,空分支和3*3卷积块的输出端连接,以得到改进型Unet分割网络,其中所述3*3卷积块为两个3*3卷积层的串联,SE模块用于获取每个特征通道的重要程度；将所述训练数据集中的数据输入改进型Unet分割网络后,先通过第一个改进后的编码块,以得到经1*1卷积层输出的第一特征图、经3*3卷积块输出的第二特征图及经SE模块输出的第三特征图；将所述第一特征图、第二特征图及第三特征图以残差的方式进行相加融合得到的特征图作为第一个下采样层即2*2最大池化层的输入,再通过分割网络剩余池化层和卷积层等的前向传播以得到分割预测图。</td>   <td>G06T7/143;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;                   黄嘉胜       </td>   <td>中山大学</td>   <td>一种基于图神经网络的群体行为识别方法</td>   <td>广东省</td>   <td>CN111598032B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于图神经网络的群体行为识别方法,方法包括以下步骤：特征提取,对单位时间内视频段的个体视觉特征进行提取,获取每个人的特征表达与整个场景特征表达；生成虚图,根据得到的每个人的特征表达与场景特征表达生成全连接的无向图,在无向图中引入虚节点,生成虚图；图神经网络更新,对虚图进行图神经网络更新；构建图神经网络,根据图神经网络层构建图神经网络模型；群体行为识别,将完整的虚图导入到图神经网络,对预测类标和真实类标进行误差计算。本发明定义了一种新型的基于虚节点的图神经网络,可以学习到视频中丰富的时间空间特征,从而帮助对视频中的群体行为进行准确的识别。</td>   <td>1.一种基于图神经网络的群体行为识别方法,其特征在于,包括以下步骤：特征提取,对单位时间视频端的个体进行检测,并依据检测到个体的位置,在空间和时间上进行视频切片,然后将视频切片输入到三维残差卷积网络进行特征提取,获取每个个体的特征表达与整个场景特征表达；生成虚图,根据得到的每个个体的特征表达与场景特征表达,将每个个体视为图的一个节点,计为实节点,将所有实节点两两相连,得到全连接的无向图,在无向图中引入虚节点,将虚节点与原图中的节点连接,形成虚图；对多个图进行虚拟节点引入形成的虚图进行图神经网络的更新,更新后的图神经网络层具有充分的特征表达能力；所述图神经网络的更新具体为：对所有节点特征进行一个线性变换,每个节点特征线性变换后得到的特征y-i表示为：y-i＝Θx-i其中Θ为一个所有节点共享的线性变换矩阵,x-i为节点特征,Θ∈R～(F′xF),x-i∈R～F,y-i∈R～(F′),R代表实数空间,其右上角上标为实数空间的维度,R～F代表其为F维的实数空间,R～(F′)代表其为F′维的实数空间,R～(F′xF)代表其为F′xF维的实数空间；Θ是一个可学习的参数,由所有节点特征共享；构建图神经网络,表达图神经网络层,根据图神经网络层的表达式构建图神经网络模型；所述构建图神经网络具体为：构建图神经网络层,用如下公式表示：                                                      其中Θ∈R～(F′xF),a∈R～(3F′)为学习参数；β-(ij)为α-(ij)未进行归一化时的数值；图神经网络层将虚图的节点特征集合X作为输入,将新的节点特征集合X′作为输出,将其抽象为：X′＝f(X)将n个图神经网络层叠加,将当前层的输出作为下一层的输入,则图神经网络第L层表示为：X～L＝f～L(X～(L-1))其中1L≤n,X～(L-1)为第L层输入的节点特征集合；为表征整个图的特征,将最后一层图神经网络层输出的所有节点特征进行平均,作为该图的全局特征h-(graph),表示如下：          /&gt;其中N为图节点的个数,X～n为图神经网络第n层的节点特征集合；群体行为识别,将完整的虚图导入到图神经网络模型,进行非线性变换归一化处理,对预测类标和真实类标进行误差计算。</td>   <td>G06V40/20;G06V20/40;G06V10/44;G06V10/764;G06V10/82;G06N3/0464;G06N3/048;G06N3/047;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张贺晔;                   郭宜锋       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的磁共振成像方法及装置</td>   <td>广东省</td>   <td>CN111598966B</td>   <td>2023-04-18</td>   <td>本申请提供了一种基于生成对抗网络的磁共振成像方法及装置,包括：利用人工神经网络的自学习能力,建立欠采样MRI数据与MRI图像的图像特征之间的对应关系；具体地,确定相邻时序对应的数据段之间的相关性；确定欠采样MRI数据中的目标空间特征；依据相关性和目标空间特征,确定欠采样MRI数据与MRI图像的图像特征之间的对应关系；获取当前受检测者的当前欠采样MRI数据；通过对应关系,确定与当前欠采样MRI数据对应的当前MRI图像的图像特征；具体地,确定与当前欠采样MRI数据对应的当前MRI图像的图像特征,包括：将对应关系中与当前欠采样MRI数据相同的欠采样MRI数据所对应的MRI图像的图像特征,确定为当前MRI图像的图像特征。避免了在重建过程中产生大量残余噪声。</td>   <td>1.一种基于生成对抗网络的磁共振成像方法,应用于将压缩感知磁共振成像装置获取的欠采样MRI数据进行成像,所述欠采样MRI数据包含多段依据时序获取及排列的数据段,其特征在于,包括：利用人工神经网络的自学习能力,建立欠采样MRI数据与MRI图像的图像特征之间的对应关系；确定相邻时序对应的所述数据段之间的相关性；确定所述欠采样MRI数据中的目标空间特征；依据所述相关性和所述目标空间特征,确定所述欠采样MRI数据与MRI图像的图像特征之间的对应关系,包括：获取用于建立所述欠采样MRI数据与所述MRI图像的图像特征之间的对应关系的样本数据；分析所述欠采样MRI数据的特性及其规律,根据所述特性及其规律,确定所述人工神经网络的网络结构及其网络参数；使用所述样本数据,对所述网络结构和所述网络参数进行训练和测试,确定所述欠采样MRI数据与所述MRI图像的图像特征的所述对应关系；获取当前受检测者的当前欠采样MRI数据；通过所述对应关系,确定与所述当前欠采样MRI数据对应的当前MRI图像的图像特征；确定与所述当前欠采样MRI数据对应的当前MRI图像的图像特征,包括：将所述对应关系中与所述当前欠采样MRI数据相同的欠采样MRI数据所对应的MRI图像的图像特征,确定为所述当前MRI图像的图像特征。</td>   <td>G06T11/00;G06N3/0464;G06N3/048;G06N3/045;G06N3/0442;G06N3/084;G01R33/48;G01R33/54;G01R33/56</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张贺晔;                   郭宜锋       </td>   <td>中山大学</td>   <td>一种基于条件生成对抗网络的MRI成像方法及装置</td>   <td>广东省</td>   <td>CN111612865B</td>   <td>2023-04-18</td>   <td>本申请提供了一种基于条件生成对抗网络的MRI成像方法及装置,包括：利用人工神经网络的自学习能力,建立欠采样MRI数据与MRI图像的图像特征之间的对应关系；具体地,人工神经网络通过依据欠采样MRI数据生成的模拟MRI数据和欠采样MRI数据生成模拟MRI图像的图像特征；依据MRI图像的图像特征和模拟MRI图像的图像特征建立对应关系；获取当前受检测者的当前欠采样MRI数据；通过对应关系,确定与当前欠采样MRI数据对应的当前MRI图像的图像特征；具体地,确定与当前欠采样MRI数据对应的当前MRI图像的图像特征,包括：将对应关系中与当前欠采样MRI数据相同的欠采样MRI数据所对应的MRI图像的图像特征,确定为当前MRI图像的图像特征。实现更好的重建细节。</td>   <td>1.一种基于条件生成对抗网络的MRI成像方法,应用于将压缩感知磁共振成像装置获取的欠采样MRI数据进行成像,其特征在于,包括：利用人工神经网络的自学习能力,建立欠采样MRI数据与MRI图像的图像特征之间的对应关系；人工神经网络通过依据所述欠采样MRI数据生成的模拟MRI数据和所述欠采样MRI数据生成模拟MRI图像的图像特征；依据所述MRI图像的图像特征和所述模拟MRI图像的图像特征建立所述对应关系,包括：获取用于建立所述欠采样MRI数据与所述MRI图像的图像特征之间的对应关系的样本数据；分析所述欠采样MRI数据的特性及其规律,根据所述特性及其规律,确定所述人工神经网络的网络结构及其网络参数；使用所述样本数据,对所述网络结构和所述网络参数进行训练和测试,确定所述欠采样MRI数据与所述MRI图像的图像特征的所述对应关系；获取当前受检测者的当前欠采样MRI数据；通过所述对应关系,确定与所述当前欠采样MRI数据对应的当前MRI图像的图像特征；确定与所述当前欠采样MRI数据对应的当前MRI图像的图像特征,包括：将所述对应关系中与所述当前欠采样MRI数据相同的欠采样MRI数据所对应的MRI图像的图像特征,确定为所述当前MRI图像的图像特征。</td>   <td>G06T11/00;G06N3/0475;G06N3/048;G06N3/094</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈武辉;              高振量;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于区块链及动态网络服务质量的数据商品交易方法</td>   <td>广东省</td>   <td>CN111626717B</td>   <td>2023-04-18</td>   <td>本发明提出一种基于区块链及动态网络服务质量的数据商品交易方法,包括：S1.计算服务供应商从发送数据商品至任意买家节点接收到数据商品所花费的时间,作为最初的网络服务质量；S2.进行商品交易,收集买家报价集,确定数据商品的最终买家分配方案和成交价格；S3.服务供应商通过奖励激励中继节点,中继节点提交传输凭证至区块链,获取收益；S4.根据步骤S3中数据商品从发送至买家节点接收所花费的时间记录,更新网络服务质量；S5.判断数据商品交易是否完成,若是,结束；否则,返回S2进入下一轮的数据商品交易。本发明提出的基于区块链及动态网络服务质量的数据商品交易方法,提高网络服务质量,有效保障数据交易的安全隐私。</td>   <td>1.一种基于区块链及动态网络服务质量的数据商品交易方法,其特征在于,至少包括：S1.计算服务供应商从发送数据商品至任意买家节点接收到数据商品所花费的时间,作为最初的网络服务质量；步骤S1所述最初的网络服务质量的计算过程为：S11、服务供应商向任意n个买家节点发送两批相同的数据商品A和数据商品B,数据商品A通过奖励激励中继节点的方式传输,数据商品B不通过奖励激励中继节点的方式传输；S12.记录数据商品A到达第m个买家节点所花费的时间T-(Am),记录数据商品B到达第m个买家节点所花费的时间T-(Bm),m为n个买家节点中的任意一个；S13.计算服务供应商发送数据商品至第m个买家节点的网络服务质量Q-m；服务供应商发送数据商品至第m个买家节点的网络服务质量Q-m的计算公式为:Q-m＝T-(Bm)-T-(Am)+C其中,Q-m表示服务供应商发送数据商品至第m个买家节点的网络服务质量；T-(Bm)表示数据商品B到达第m个买家节点所花费的时间；T-(Am)数据商品A到达第m个买家节点所花费的时间；C为常数,表示非网络因素的服务质量；最初的网络服务质量计算公式为：                  其中,Q表示最初的网络服务质量；n表示买家节点的总个数；Q-m表示服务供应商发送数据商品至第m个买家节点的网络服务质量；S14.确定最初的网络服务质量；S2.进行商品交易,服务供应商收集购买同一数据商品的买家报价集,确定数据商品的最终买家分配方案和成交价格；S3.服务供应商通过奖励激励中继节点,向买家传输数据商品,中继节点提交传输凭证至区块链,获取收益；S4.根据步骤S3中数据商品从发送至买家节点接收所花费的时间记录,更新网络服务质量；S5.判断数据商品交易是否完成,若是,结束；否则,返回步骤S2进入下一轮的数据商品交易。</td>   <td>G06Q20/06;G06Q20/38;G06Q30/0273;G06Q30/08;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              郭彤彤;                   李中华       </td>   <td>中山大学</td>   <td>一种自动驾驶图像语义分割优化方法</td>   <td>广东省</td>   <td>CN111639524B</td>   <td>2023-04-18</td>   <td>本发明公开了一种自动驾驶图像语义分割优化方法,该方法设计了一种使用标签来辅助激活的AAM模块,通过分割标签对网络提取的特征进行修正,使得同类物体提取出来的特征具有近似相同的值。将AAM模块集成到分割模型的编码器与解码器中间,通过训练得到一个性能比基准模型更好的模型,称为教师网络；通过知识迁移将教师网络基于AAM模块的所学知识迁移到分割模型中,从而提升其分割性能。本发明能够很好地挖掘分割标签的信息来提高分割模型的性能,并且无需修改网络结构,具有很强的应用价值。</td>   <td>1.一种自动驾驶图像语义分割优化方法,其特征在于,构建一教师-学生学习网络,其中教师网络是指编码器、AAM模块、解码器训练得到的分割模型,学生网络为仅包括编码器、解码器的基准模型,通过知识迁移将学习好的教师网络的知识迁移到学生网络,进而训练学生网络；在训练教师网络过程中将AAM模块集成到基准模型的编码器和解码器中间,得到教师网络分割模型；其中,AAM模块中没有可学习参数,其执行下述4个步骤：将编码器输出的多通道高层语义特征图按通道的维度求平均,获得每个像素位置的平均特征值,进而得到单通道平均特征图；将单通道平均特征图逐像素的和训练集分割标签相乘,得到单通道前辅助性特征激活图；所述训练集分割标签中属于不同的目标的像素有不同的激活等级；将单通道前辅助性特征激活图与激活因子相乘,得到最终辅助性特征激活图；所述激活因子在训练过程中会随着训练次数的增加逐渐减小直至为零；将最终辅助性特征激活图与多通道高层语义特征图相加,作为解码器的输入；教师网络的分割损失采用多类交叉熵损失,每一个类别损失权重根据数据集提前计算,被忽视的类别的权重设为零,多类交叉熵损失计算公式如下：                  其中,W×H表示图像的分辨率大小,q-(i,j)表示由网络预测的第i个像素属于第j类的概率,y-(i,j)代表对应的真值,ω-j表示第j类的权重,R表示从1到W×H的像素集合,K表示所有类别的集合；学生网络的训练采用KL损失去迁移教师网络的知识,其表达式如下：                  其中,W×H表示图像的分辨率大小,表示由学生网络预测的第i个像素的类概率,/&gt;表示由教师网络预测的第i个像素的类概率,R表示从1到W×H的像素集合；学生网络训练过程中总的损失函数表达为以下式子：                  其中是多类交叉熵损失,λ是一个超参数。</td>   <td>G06V10/26;G06V20/56;G06V20/70;G06V10/764;G06V10/82;G06N3/0464;G06N3/0455;G06N3/096</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐瑞华;              李超峰;              陈海畴;              邓一术;                   经秉中       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种轮廓提取方法及装置、电子设备、存储介质</td>   <td>广东省</td>   <td>CN112183541B</td>   <td>2023-04-18</td>   <td>本申请实施例涉及计算机视觉处理技术领域,公开了一种轮廓提取方法及装置、电子设备、存储介质,能够提高轮廓提取的效率。该方法包括：获取待识别图像。通过训练得到的目标分割模型对待识别图像中的目标对象进行轮廓分析,得到轮廓参数,并基于轮廓参数获得N条分段曲线的分段参数,N为正整数。之后,通过目标分割模型,并结合曲线方程对每条分段曲线的分段参数进行曲线解码,获得N条分段曲线各自对应的轮廓点坐标。最后,对N条分段曲线各自对应的轮廓点坐标进行拼接,生成目标对象的目标轮廓。</td>   <td>1.一种轮廓提取方法,其特征在于,所述方法包括：获取待识别图像；通过训练得到的目标分割模型对所述待识别图像中的目标对象进行轮廓分析,得到轮廓参数,所述轮廓参数包括M个控制点和O个端点,M、O为正整数,所述目标分割模型包括分类神经网络和解码器；通过所述解码器,根据所述O个端点对所述M个控制点进行分类,确定N条分段曲线各自对应的控制点,N为正整数；按照预设采样策略获取每条所述分段曲线上多个轮廓点对应的求解系数矩阵；通过所述解码器,并结合曲线方程将每条所述分段曲线对应的求解系数矩阵和控制点进行曲线解码,获得每条所述分段曲线对应的多个轮廓点坐标；将所述N条分段曲线各自对应的轮廓点坐标进行拼接,生成所述目标对象的目标轮廓；所述获取待识别图像之前,所述方法还包括：获取样本图像中目标对象的目标样本轮廓,以及获取从所述目标样本轮廓中确定的目标轮廓参数；将所述样本图像输入到所述分类神经网络进行轮廓分析,获得预测轮廓参数；将所述目标轮廓参数和所述预测轮廓参数分别输入到所述解码器进行曲线解码,获得所述目标轮廓参数所对应轮廓曲线上的多个目标轮廓点坐标和所述预测轮廓参数所对应轮廓曲线上的多个预测轮廓点坐标；根据所述多个目标轮廓点坐标和所述多个预测轮廓点坐标计算所述目标分割模型的损失,并根据所述损失调整所述目标分割模型的参数。</td>   <td>G06V10/26;G06V10/44;G06V10/82;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘迅;              刘翔;                   张卓       </td>   <td>中山大学附属第三医院;广州知汇云科技有限公司</td>   <td>一种肾小球滤过率估计模型的构建方法</td>   <td>广东省</td>   <td>CN112768073B</td>   <td>2023-04-18</td>   <td>本发明公开了一种肾小球滤过率估计模型的构建方法,包括：获取数位肾小球滤过率真实值对应的患者信息,并随机拆分成训练集和测试集；对训练集的患者信息进行中心化处理,以肾小球滤过率真实值为因变量,且以中心化处理的患者信息为自变量；构建Ensemble的树模型；在Ensemble的树模型的目标函数中添加惩罚项控制模型的复杂度；对添加惩罚项的Ensemble的树模型进行逐步训练；利用二阶展开近似逼近原目标函数；优化并去掉常数项；根据贪婪算法求得任一次分叉后的损失函数；以完成肾小球滤过率估计模型的构建；对Ensemble的树模型的预测输出进行加总求平均,得到肾小球滤过率。</td>   <td>1.一种肾小球滤过率估计模型的构建方法,其特征在于,包括以下步骤：获取数位肾小球滤过率真实值对应的患者信息,并随机拆分成训练集和测试集；对训练集的患者信息进行中心化处理,以肾小球滤过率真实值为因变量,且以中心化处理的患者信息为自变量,并获得数据空间；所述/&gt;表示训练集的患者的样本数量；所述/&gt;表示患者信息的特征数量；所述/&gt;表示实数集,/&gt;表示第/&gt;个样本,/&gt;表示第/&gt;个样本的标签；构建Ensemble的树模型,其表达式为：          其中,/&gt;表示第/&gt;个树模型,表示所有树模型构成的空间,/&gt;表示所有参与模型集成的树模型的集合；在Ensemble的树模型的目标函数中添加惩罚项,其表达式为：          其中,/&gt;表示损失函数,/&gt;表示惩罚项,惩罚项表达式为：          其中,/&gt;表示树模型数量的惩罚系数,/&gt;表示树模型/&gt;的节点个数,/&gt;表示树模型的预测结果,/&gt;表示树模型的预测结果/&gt;对应的惩罚系数；对添加惩罚项的Ensemble的树模型进行逐步训练,其表达为：          其中,/&gt;表示当前的步数,/&gt;表示第/&gt;步的树模型预测结果,/&gt;表示当前的树模型,/&gt;表示当前树模型对应的惩罚项；利用二阶展开近似逼近原目标函数,其表达式为：          其中,/&gt;和/&gt;分别表示损失函数的一阶导数和二阶导数；优化并去掉常数项,其表达式为：          预设/&gt;为数据空间的第/&gt;个叶子的事件集,/&gt;表示输入样本/&gt;经过树模型的分叉进入到第/&gt;个叶子的映射；对公式(6)进行优化：          其中,/&gt;表达第/&gt;个叶子的权重值；求得任一叶子的最优权重值,其表达式为：          根据贪婪算法求得任一次分叉后的损失函数,其表达式为：          其中,表示树模型中分叉的左边的事件集,/&gt;表示表示树模型中分叉的右边的事件集,/&gt;表示一个树模型在展开新的节点之前的总事件集合；以完成肾小球滤过率估计模型的构建；对Ensemble的树模型的预测输出进行加总求平均,得到肾小球滤过率。</td>   <td>G16H50/30;G16H50/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘梦曦;                   石茜       </td>   <td>中山大学</td>   <td>一种基于超分辨率的多分辨率遥感影像的变化检测方法</td>   <td>广东省</td>   <td>CN112949549B</td>   <td>2023-04-18</td>   <td>本发明提出一种基于超分辨率的多分辨率遥感影像的变化检测方法,解决了如何更准确的对遥感影像进行变化检测的问题,构建基于高分辨率遥感影像的双时相变化检测数据集,进行多分辨率预处理,得到低分辨率影像,利用超分辨率模块学习恢复低分辨率影像中的语义信息特征,恢复得到更真实的具有语义信息的样本,可以减少不确定性映射带来的误差累积,有助于提高后续高分辨率变化检测的精度,设计基于多层次注意力机制模块的深度学习变化检测网络模型并训练,多层次注意力模块增强多层次特征的有效信息,获取更具有可区分性的特征对,帮助深度学习变化检测网络模型学习到更准确的变化检测图,实现对多分辨率遥感影像土地覆盖的变化检测。</td>   <td>1.一种基于超分辨率的多分辨率遥感影像的变化检测方法,用于土地覆盖变化的检测识别,其特征在于,至少包括：S1.构建基于高分辨率遥感影像的双时相变化检测数据集；S2.将单一分辨率的双时相变化检测数据集进行多分辨率预处理,得到低分辨率影像；S3.利用超分辨率模块学习恢复低分辨率影像中的语义信息特征,将低分辨率影像的尺寸扩大,输出超分辨率影像,与原双时相变化检测数据集共同组成输入数据集；S4.设计基于多层次注意力机制模块的深度学习变化检测网络模型；S5.将输入数据集输入深度学习变化检测网络模型,对深度学习变化检测网络模型进行训练；S6.将待检测变化区域的多分辨率的双时相遥感影像输入至训练好的深度学习变化检测网络模型,得到变化检测结果。</td>   <td>G06V20/13;G06V10/25;G06V10/44;G06V10/774;G06V10/82;G06N3/0464;G06N3/048;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周锦;              张青;              孙伟;              郑伟诗;                   席杨       </td>   <td>中山大学</td>   <td>基于无监督学习的单张图片本征图像分解方法、系统及介质</td>   <td>广东省</td>   <td>CN113077451B</td>   <td>2023-04-18</td>   <td>本发明公开了一种基于无监督学习的单张图片本征图像分解方法、系统及介质,方法包括下述步骤：构建本征图像分解模型,所述本征图像分解模型包括两个分支,一支为反射率生成网络,另一支为光照生成网络；设置随机噪声参数并经过训练后得到两个与原图尺度相同的随机噪声；将生成的两个随机噪声分别作为反射率网络和光照网络的输入,在损失函数的约束下,不断利用反向传播算法更新反射率网络和光照网络的参数；当更新反射率网络和光照网络的参数多次后,在历史输出中选取重构图与原图峰值信噪比PSNR值最小的那组结果作为本征图像分解的最终结果。通过两个结构相同的反射率生成网络和光照网络,分别输出反射率和光照,实现无监督的本征图像分解。</td>   <td>1.基于无监督学习的单张图片本征图像分解方法,其特征在于,包括下述步骤：构建本征图像分解模型,所述本征图像分解模型包括两个分支,一支为反射率生成网络,另一支为光照生成网络；设置随机噪声参数并经过训练后得到两个与原图尺度相同的随机噪声；将生成的两个随机噪声分别作为反射率网络和光照网络的输入,在损失函数的约束下,不断利用反向传播算法更新反射率网络和光照网络的参数；所述在损失函数的约束下,不断利用反向传播算法更新反射率网络和光照网络的参数,具体为：重构误差,所述反射率生成网络和光照生成网络分别输出反射率和光照,根据Retinex理论,图像模型表示为：I＝r·s,(1)其中,r表示反射率,s表示光照,I表示原图,要满足Retinex理论,即网络的两个输出需要满足(1)等式的约束,因此重构误差表示为：                  其中,R表示网络输出的反射率,S表示本方法网络输出的光照,为了将网络的两个分支解耦,使其学习过程相对独立,把原Retinex理论转化到了log域,表达式从乘积式子变成和式；互斥误差,在梯度域设置一个损失项以区分开反射率和光照,在多种尺度上计算互斥损失项,具体为：                                    其中,θ表示网络的参数；n表示下采样的系数；f-S,f-R分别表示输出光照的网络分支和输出反射率的网络分支,f-S,f-R使用双线性插值法下采样2～(n-1)；||·||-F表示Frobenius范数；⊙表示点乘；本征图像分解模型训练,以生成的两个随机噪声为输入,在训练M-1次循环之后在两个初始随机噪声的基础上分别添加扰动,然后分别作为反射率生成网络和光照生成网络最终的网络输入；训练本征图像分解模型使用的目标函数为重构误差和互斥误差；使用Adam优化器更新反射率生成网络和光照生成网络的参数；各分支网络的初始化均采用泽维尔初始化；当更新反射率网络和光照网络的参数多次后,在历史输出中选取重构图与原图峰值信噪比PSNR值最小的那组结果作为本征图像分解的最终结果。</td>   <td>G06T7/00;G06N3/0464;G06N3/084</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   黄泽青       </td>   <td>中山大学</td>   <td>一种耦合伯努利-伽马-高斯分布的日尺度降水预报校正方法</td>   <td>广东省</td>   <td>CN113095579B</td>   <td>2023-04-18</td>   <td>本发明为克服日尺度降水数据呈现的偏态与离散-连续混合分布导致难以对日尺度降水预报进行分析及校正的缺陷,提出一种耦合伯努利-伽马-高斯分布的日尺度降水预报校正方法,包括以下步骤：采集日尺度的原始预报数据和观测数据；采用伯努利分布进行降水发生分析；采用伽马分布对发生降水的数据进行降水量分析；根据伯努利分布和伽马分布的分析结果,采用高斯分布将原始预报数据和观测数据进行正态转化,得到相应的正态化变量；构建双变量联合正态分布；构建预报变量的条件概率分布；判断待校正预报是否为发生降水事件,根据预报变量的条件概率分布,确定预报变量的条件概率分布参数后对其进行随机采样,再根据正态分位逆变换得到校正预报。</td>   <td>1.一种耦合伯努利-伽马-高斯分布的日尺度降水预报校正方法,其特征在于,包括以下步骤：S1：采集日尺度的流域面平均降水的原始预报数据和相应流域面的平均降水的观测数据；S2：采用伯努利分布对所述原始预报数据和观测数据进行降水发生分析；其中：S2.1：设置原始预报数据阈值T-f和观测数据阈值T-o并对降水事件是否发生进行判断：当原始预报数据的降水量、观测数据的降水量小于相应的阈值T-f、T-o时,则分析为未发生降水事件；当原始预报数据的降水量、观测数据的降水量大于或等于相应的阈值T-f、T-o时,则分析为发生降水事件；S2.2：根据降水事件发生判断结果计算原始预报数据中未发生降水事件的概率q-f和观测数据中未发生降水事件的概率q-o,其计算公式如下：q＝K-0/K式中,K-0表示未发生降水事件的数据样本个数,K表示数据样本总数；根据所述未发生降水事件的概率进行伯努利分布拟合,其表达公式如下：                  式中,F＝[f-1,f-2,...,f-K]表示原始预报数据,O＝[o-1,o-2,...,o-K]表示观测数据；B()表示伯努利分布；S3：采用伽马分布对发生降水的原始预报数据和观测数据进行降水量分析；其中：将分析为发生降水事件的原始预报数据样本记为F-c,将分析为发生降水事件的观测数据样本记为O-c,采用伽马分布分别拟合原始预报数据样本F-c和观测数据样本O-c,得到其边缘分布,其表达公式如下：                  式中,G()表示伽马分布,α-f、β-f、α-o、β-o分别表示通过拟合得到的原始预报数据、观测数据的伽马分布参数；S4：根据伯努利分布和伽马分布的分析结果,将所述原始预报数据和观测数据进行正态转化,得到所述原始预报数据和观测数据相应的正态化变量和/&gt;其中,将所述原始预报数据和观测数据进行正态转化的步骤包括：S4.1：根据伯努利分布和伽马分布的分析结果,将所述原始预报数据和观测数据转化为相应的累积分布函数值,其计算公式如下：                  式中,表示于第i年的原始预报数据f-i、观测数据o-i的累积分布函数值,且i＝1,2,...,K；/&gt;分别表示原始预报数据、观测数据的伽马分布的累积分布函数；m-f、m-o分别表示未发生降水事件的原始预报数据、观测数据的累积分布函数值；/&gt;S4.2：通过标准正态分布累积分布函数的反函数,将累积分布函数值转化为服从标准正态分布的变量,其表达公式如下：                  式中,表示标准正态分布累积分布函数的反函数,/&gt;分别表示正态分位变换后的原始预报变量和观测变量,则原始预报数据的正态化变量/&gt;和观测数据的正态化变量/&gt;服从正态分布；所述正态化变量/&gt;和/&gt;的双变量联合正态分布表达式为：                  式中,ρ表示正态化变量和/&gt;的相关系数；所述正态化变量和/&gt;的相关系数ρ通过极大似然估计法计算得到,其中,总似然函数L的计算公式如下：                  式中,l-i表示第i年的原始预报数据f-i及观测数据o-i的似然函数,其中,似然函数l-i的表达公式如下：                  式中,PDF-(BN)表示标准双变量联合正态分布的概率密度函数；和/&gt;分别表示在双变量联合正态分布中的观测与原始预报对应的条件概率分布的累积分布函数；CDF-(BN)()表示标准双变量联合正态分布的累积分布函数；/&gt;和/&gt;表示阈值T-f、T-o对应的正态分布变量；S5：根据所述正态化变量和/&gt;构建双变量联合正态分布；S6：将所述原始预报数据的正态化变量作为预报因子,将所述观测数据的正态化变量作为预报变量,构建所述预报变量/&gt;的条件概率分布；S7：判断待校正的预报数据是否发生降水事件,确定预报变量的条件概率分布,进一步对预报变量/&gt;的条件概率分布进行随机采样,再根据正态分位逆变换得到校正预报。/&gt;</td>   <td>G06Q10/04;G06F16/2458;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   李佳铭       </td>   <td>中山大学</td>   <td>半监督领域自适应方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113326848B</td>   <td>2023-04-18</td>   <td>本发明公开了一种半监督领域自适应方法,包括获取有标签源域图像、有标签目标域图像及无标签目标域图像；将有标签目标域图像、无标签目标域图像分别转换为具有源域图像风格的第一图像、第二图像；将第二图像输入至源域分割模型,得到第一概率置信图；将无标签目标域图像输入至目标域分割模型,得到第二概率置信图；根据第一概率置信图推断出的类别结果图合成第一伪标签,根据第二概率置信图推断出的类别结果图合成第二伪标签；利用第一伪标签及第一概率置信图监督目标域分割模型,得到其损失函数；利用第二伪标签及第二概率置信图监督源域分割模型,得到其损失函数。本发明能更好地缩减域间差及更好地利用目标域图片,进而提高语义分割效果。</td>   <td>1.一种半监督领域自适应方法,其特征在于,包括：获取有标签源域图像、有标签目标域图像及无标签目标域图像；将所述有标签目标域图像、所述无标签目标域图像分别转换为具有源域图像风格的第一图像、第二图像；将所述有标签源域图像转换为具有目标域图像风格的第三图像；将所述第二图像输入至源域分割模型,得到第一概率置信图；及将所述无标签目标域图像输入至目标域分割模型,得到第二概率置信图；根据所述第一概率置信图推断出的类别结果图合成第一伪标签,及根据所述第二概率置信图推断出的类别结果图合成第二伪标签；利用所述第一伪标签及所述第一概率置信图监督目标域分割模型,得到目标域分割模型的损失函数；及利用所述第二伪标签及所述第二概率置信图监督源域分割模型,得到源域分割模型的损失函数；利用所述有标签源域图像和所述第一图像对所述源域分割模型进行有监督学习,及利用所述第三图像和所述有标签目标域图像对所述目标域分割模型进行有监督学习。</td>   <td>G06V10/26;G06V10/764;G06V10/82;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘文阁;              程轶;              刘亚飞;              蔡庆玲;              梁小丹;                   王巨宏       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>信息处理方法、装置、计算机设备和存储介质</td>   <td>广东省</td>   <td>CN115982313A</td>   <td>2023-04-18</td>   <td>本申请涉及一种信息处理方法、装置、计算机设备和存储介质。所述方法包括：获取目标对象在当前对话轮次中指定的异常描述信息；基于异常类别与症状类别之间的贝叶斯网络,确定与异常描述信息对应的异常类别概率分布,并根据异常症状转移矩阵以及异常类别概率分布,确定第一症状类别概率分布；根据第一症状类别概率分布确定候选症状类别,进入下个对话轮次,获取目标对象从候选症状类别中选定的补充症状类别；基于补充症状类别更新异常描述信息,返回基于异常类别与症状类别之间的联合概率分布的步骤继续执行,直至达到预设停止条件时停止；基于最终更新得到的异常描述信息,向目标对象输出相应的推荐信息。采用本方法能够提升推荐信息生成效率。</td>   <td>1.一种信息处理方法,其特征在于,所述方法包括：获取目标对象在当前对话轮次中指定的异常描述信息；基于异常类别与症状类别之间的贝叶斯网络,确定与所述异常描述信息对应的异常类别概率分布,并根据异常症状转移矩阵以及所述异常类别概率分布,确定第一症状类别概率分布；根据所述第一症状类别概率分布确定候选症状类别,并进入下个对话轮次,获取所述目标对象从所述候选症状类别中选定的补充症状类别；基于所述补充症状类别更新异常描述信息,返回所述基于异常类别与症状类别之间的联合概率分布,确定与所述异常描述信息对应的异常类别概率分布的步骤继续执行,直至达到预设停止条件时停止；基于最终更新得到的异常描述信息,向所述目标对象输出相应的推荐信息。</td>   <td>G06F16/33;G06F16/332;G06F16/335;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张东;                   郑晓雨       </td>   <td>中山大学</td>   <td>一种基于偏振参数的颜色恒常性方法、系统及存储介质</td>   <td>广东省</td>   <td>CN115984391A</td>   <td>2023-04-18</td>   <td>本发明提出一种基于偏振参数的颜色恒常性方法、系统及存储介质,涉及计算机视觉、图像处理和颜色增强的技术领域,首先采集偏色图像和偏色图像对应的偏振图像,然后计算出偏振图像的斯托克斯参数,基于斯托克斯参数获取各个像素点对应的偏振程度值,再通过偏振程度值提取出偏色图像的有效像素点,再区分有效像素点中的伪灰色像素和灰色像素并获得灰色像素权重,再对偏色图像中的灰色像素的值进行加权平均,得到用于消除偏色图像的光照颜色的全局光照颜色估计,最终得到无色偏图像,可以有效排除图像中伪灰色像素对光照颜色估计的造成的不良影响,提高了颜色恒常性算法的准确性和鲁棒性。</td>   <td>1.一种基于偏振参数的颜色恒常性方法,其特征在于,包括：S1.采集偏色图像以及偏色图像对应的偏振图像；S2.计算偏振图像的斯托克斯参数；S3.基于偏振图像的斯托克斯参数,计算偏振图像中每一个像素点对应的包含偏振信息的偏振程度值；S4.基于每个像素点的偏振程度值,提取偏色图像中的有效像素点；S5.区分有效像素点中的伪灰色像素和灰色像素,得到用于光照颜色估计的灰色像素权重；S6.基于灰色像素权重,对偏色图像中的灰色像素的值进行加权平均,得到全局光照颜色估计；S7.基于全局光照颜色估计,消除偏色图像的光照颜色,得到无色偏图像,实现颜色恒常性。</td>   <td>G06T7/90;G06T7/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄楷;              吕琳;              沈润楠;              尤国昌;              徐嘉堂;                   陈雄       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种基于XGBoost预测DVT后PTS发生风险的系统</td>   <td>广东省</td>   <td>CN115985493A</td>   <td>2023-04-18</td>   <td>本发明提供了一种基于XGBoost(Extreme Gradient Boosting)预测DVT后PTS发生风险的系统,包括：数据输入模块,模型计算模块,结果输出模块。本发明通过端到端机器学习模型,对所有DVT患者个体进行PTS发生风险预测,通过对不同风险等级的患者使用优化的预防与治疗策略,更有效地预防和延缓患者院内或出院后PTS的形成。此系统能较好地发挥优势以弥补前人研究的不足,操作简便、快捷,预测性能更好,同时可根据患者PTS发生概率选择更适合患者个体的预防与治疗策略。</td>   <td>1.一种基于XGBoost预测DVT后PTS发生风险的系统,其特征在于,包括：数据输入模块,用于将DVT患者临床特征检测结果输入模型计算模块,所述模块采集的信息包括以下临床特征：是否联合应用PCDT与抗凝治疗；DVT类型；年龄；性别；是否患高血压；是否患糖尿病；是否存在高胆固醇；是否患哮喘；是否患慢性阻塞性肺疾病；是否患心肌梗死；是否患心力衰竭；身高；体重；BMI；发生DVT下肢；先前是否发生VTE；是否进行大手术；是否接受住院治疗；是否使用石膏模；是否生育；是否住院时发生DVT；是否服用阿司匹林；基线Villalta评分；模型计算模块,包括XGBoost模型,用于根据DVT患者临床特征检测结果以及XGBoost模型计算DVT患者评分结果；所述XGBoost模型公式如下：                  其中y-i为预测值,K表示树的数量,x-i表示第i个样本,将K棵树的输出加权求和即为XGBoost模型的最终预测值；其模型训练函数如下：                  其中,第1项为损失函数,表示第i个样本的预测误差；第2项为正则化项,规范模型复杂度以防止过拟合；结果输出模块,用于根据模块输出预测概率判定DVT患者发生PTS的风险；当DVT患者预测概率大于40％,判定该DVT患者为PTS发生高风险组；当DVT患者预测概率小于30％,判定该DVT患者为PTS发生低风险组；当DVT患者预测概率为30％到40％,判定该DVT患者为PTS发生中风险组。</td>   <td>G16H50/30;G16H50/70;G16H10/60;G16H20/00;G06F18/2431;G06F18/214</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;                   吴杰锋       </td>   <td>中山大学</td>   <td>一种基于最小顶点覆盖的新闻文本去重方法</td>   <td>广东省</td>   <td>CN109299443B</td>   <td>2023-04-14</td>   <td>本发明涉及一种基于最小顶点覆盖的新闻文本去重方法,通过去除尽量少的文本,使得剩余的文本数据集中不存在重复的文本,本发明使用了树状的动态规划和基于优先队列的贪心算法,在保证在有效去除重复文本的同时,使得需要去除的文本数量尽量地少。这种方法降低了去除的文本数量,增大了去重后可用的数据量,使后续的数据分析过程更为准确和有效。</td>   <td>1.一种基于最小顶点覆盖的新闻文本去重方法,其特征在于,包括以下步骤：步骤S1：计算两篇新闻文本两两之间的相似度sim(t-i,t-j),t-i,t-j分别表示两篇新闻文本；判断相似度sim(t-i,t-j)是否达到阈值α,若达到阈值α,则进行步骤S2,若相似度没有达到阈值α,则认为两篇文章不重复；步骤S2：为新闻文本之间的相似关系建立一个相似图G＝&lt;V,E&gt;,并用邻接表进行存储,将文本看做图论中的顶点,在这两个顶点之间连着一条无向边；其中,V表示顶点集,E表示边集；步骤S3：创建一个相似图G中需要去除的顶点列表list,接着判断G的每一个连通分量G’＝&lt;V’,E’&gt;是不是一棵树,即判断有没有环,若G’无环,则转到步骤S4进行处理；若G’有环,则转到步骤S5处理；其中,V’表示顶点集V在连通分量上的子集,E’表示边集在连通分量上的子集；步骤S4：对相似图G中的每一棵树执行树状的动态规划算法以筛选出需要去除的节点,将需要去除的节点加入list中；步骤S5：对相似图G中的每一个有环的连通分量执行基于优先队列的贪心算法筛选出需要去除的节点,将需要去除的节点加入list中；步骤S6：在新闻文本数据集中删除list中所有需要去除的顶点所对应的文本,则剩余的新闻文本均为不重复,将这些不重复的文本作为输出。</td>   <td>G06F40/194;G06F16/9535</td>  </tr>        <tr>   <td>中国专利</td>   <td>         程乐华;                   曾韵       </td>   <td>中山大学</td>   <td>情绪识别能力测评方法、装置、电子设备及存储介质</td>   <td>广东省</td>   <td>CN111241980B</td>   <td>2023-04-14</td>   <td>本发明提供了一种情绪识别能力测评方法、装置、电子设备及存储介质。其中的方法包括：收到用于触发测评系统的测评题集进行展示的指令时,展示单选题集中的一选择题；收到由被测者对当前展示的选择题进行作答时触发的选项所产生的指令时,确定当前展示的选择题的答题信息,并将当前展示的选择题更新为单选题集中的另一选择题；其中,更新后的选择题与更新前已展示的任一选择题不同；当已展示的选择题总数达到第一预设数量时,根据答题信息和预存的正确答案,确定用于表征被测者的情绪识别能力的测评结果。</td>   <td>1.一种情绪识别能力测评方法,其特征在于,应用于情绪识别能力的测评系统,所述测评系统配置有测评题集,所述测评题集包括单选题集,单选题集中的每一选择题均包括用于表征图中人物从平静到指定情绪的变化过程的面部表情动图、和用于供被测者择一选择的若干选项；所述指定情绪为以下之一：恐惧、愤怒、厌恶、快乐、悲伤和惊讶；所述若干选项中,不同选项对面部表情动图所表达的情绪的描述不同；所述单选题集中的面部表情动图包括女性面部表情动图和男性面部表情动图；所述方法包括：收到用于触发测评系统的测评题集进行展示的指令时,展示单选题集中的一选择题；收到由被测者对当前展示的选择题进行作答时触发的选项所产生的指令时,确定当前展示的选择题的答题信息,并将当前展示的选择题更新为单选题集中的另一选择题；其中,更新后的选择题与更新前已展示的任一选择题不同；当已展示的选择题总数达到第一预设数量时,根据答题信息和预存的正确答案,确定用于表征被测者的情绪识别能力的测评结果；所述测评结果的确定过程包括：根据答题信息和预存的正确答案确定答题正确率和错误的答题信息；基于预存的答题正确率与情绪识别能力等级之间的对应关系,根据当前确定得到的答题正确率确定被测者的情绪识别能力等级；统计全部答题信息中用于描述同一情绪的信息的第一总数,并记录各第一总数对应的情绪；所述第一总数表示被测者对对应情绪的情绪觉察数；基于错误的答题信息及其对应的正确答案,统计对应于用于描述同一情绪的正确答案的错误的答题信息的第二总数,并记录各第二总数对应的正确答案所描述的情绪；所述第二总数表示被测者对对应情绪的情绪识别不能数；统计错误的答题信息中用于描述同一情绪的信息的第三总数,并记录各第三总数对应的情绪；所述第三总数表示被测者对对应情绪的情绪空间数；基于确定得到的情绪识别能力等级、各情绪的情绪觉察数、情绪识别不能数和情绪空间数,生成整体测评结果；根据答题信息和预存的正确答案,分别确定包含有女性面部表情动图的所有第一选择题的第一答题正确率和包含有男性面部表情动图的所有第二选择题的第二答题正确率；对于每个第一总数,确定所述第一总数对应的选择题中所包含的第一选择题的数量和第二选择题的数量；基于第一总数与其对应的情绪、以及第一总数所包含的第一选择题的数量和第二选择题的数量,确定被测者对女性和男性的各情绪的情绪觉察数；对于每个第二总数,确定所述第二总数对应的选择题中所包含的第一选择题的数量和第二选择题的数量；基于第二总数与其对应的情绪、以及第二总数所包含的第一选择题的数量和第二选择题的数量,确定被测者对女性和男性的各情绪的情绪识别不能数；对于每个第三总数,确定所述第三总数对应的选择题中所包含的第一选择题的数量和第二选择题的数量；基于第三总数与其对应的情绪,确定被测者对女性和男性的各情绪的情绪空间数；基于第一答题正确率、女性各情绪的情绪觉察数、情绪识别不能数和情绪空间数,生成用于表征被测者对女性的情绪的识别能力的第一测评结果；基于第二答题正确率、男性各情绪的情绪觉察数、情绪识别不能数和情绪空间数,生成用于表征被测者对男性的情绪的识别能力的第二测评结果；所述测评结果还包括第一测评结果和第二测评结果。</td>   <td>G06V40/16;G16H10/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   黄泽青       </td>   <td>中山大学</td>   <td>一种面向矢量图形文件的流域地图制作方法</td>   <td>广东省</td>   <td>CN111475592B</td>   <td>2023-04-14</td>   <td>本发明公开了一种面向矢量图形文件的流域地图制作方法,其以流域地图绘制所需的矢量图形文件作为输入数据,读取其中的区域边界数据；根据获得的区域边界数据,对其进行空间分析从而进行河网裁切和流域地图要素分布的计算；随后对流域地图要素进行可视化,将绘制的流域地图保存到指定路径；将绘制过程封装成类函数,调用该类函数进行流域地图绘制。本发明通过设计面向矢量图形文件可视化类函数,实现对所需要的矢量图形文件进行自动化处理,且在流域地图的绘制过程中,自动计算并进行要素分布位置的分配,无需手动调整,从而实现了流域地图绘制的全流程自动化。</td>   <td>1.一种面向矢量图形文件的流域地图制作方法,其特征在于,包括以下步骤：S1.文件输入：以流域地图绘制所需的矢量图形文件作为输入数据,读取其中的区域边界数据；S2.数据处理：根据获得的区域边界数据,对其进行空间分析从而进行河网裁切和流域地图要素分布的计算；其中,进行河网裁剪的计算包括：S211.基于构建的A国河网和目标流域边界的矢量图形,采用Python第三方库Shapely中的intersection函数,依次将A国河网中各个矢量图形对象与目标流域边界矢量图形进行重叠分析,辨识出A国河网与目标流域边界的重叠区域：                  式中,D-(basin)为目标流域边界的矢量图形,为A国河网矢量图形的第i个对象,N为A国河网矢量图形中的对象总数,d-i为辨识出来的D-(basin)与/&gt;的重叠区域,若无重叠区域,则d-i为空；S212.在辨识出A国河网与目标流域边界的所有重叠区域后,采用Python第三方库Shapely中的union函数,依次将辨识得到的所有重叠区域d-i合并,则得到目标流域边界内的河网完成对河网裁切的计算；S213.通过Python第三方库Shapefile中的Writter函数对裁切后的河网进行保存；进行流域地图要素分布的计算包括：S221.获取目标流域地图的经纬度范围,并存储于列表bbox中；其中流域地图的最小经度、最小纬度、最大经度和最大纬度分别记为lon-(min)、lat-(min)、lon-(max)和lat-(max)；S222.根据得到的列表bbox,构建四个矢量图形,所述四个矢量图形分别表示流域地图左上角、右上角、左下角和右下角四个区域,构建的矢量图形的经纬度长度均为流域地图经纬度范围的四分之一：                  式中,L-x和L-y分别表示矢量图形的经度和纬度的长度；S223.根据列表bbox与计算得到的矢量图形经度和纬度的长度L-x和L-y,分别计算出所述四个矢量图形的四个顶点坐标,即每个矢量图形的左上角、右上角、左下角和右下角共四个顶点；S224.采用Python第三方库Shapely中的geometry.Polygon函数,根据计算得到的顶点坐标依次构建矢量图形,则能够得到左上角、右上角、左下角和右下角四个矢量图形D-1、D-2、D-3和D-4；S225.采用Python第三方库Shapely中的intersection函数,分别将矢量图形D-1、D-2、D-3和D-4与目标流域边界的矢量图形D-(basin)进行重叠分析,并计算出重叠区域的面积为A-1、A-2、A-3和A-4；S226.采用Python第三方库Numpy中的argsort函数,计算得到四个矢量图形与目标流域边界的矢量图形的重叠区域面积A-1、A-2、A-3和A-4从小到大的排序；S3.流域地图要素可视化：基于步骤S2的计算结果,对流域地图要素进行可视化,将绘制的流域地图保存到指定路径；S4.将步骤S1～S3的绘制过程封装成类函数,调用所述类函数进行流域地图绘制。</td>   <td>G06F16/29;G06T11/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              欧广盛;              蔡倬;              周克涌;              王福海;                   朱煜       </td>   <td>招联消费金融有限公司;中山大学</td>   <td>基于联盟链的资源借调评估方法、装置和计算机设备</td>   <td>广东省</td>   <td>CN115965459A</td>   <td>2023-04-14</td>   <td>本申请涉及一种基于联盟链的资源借调评估方法、装置和计算机设备。方法包括：响应于联盟链中的资源需求方的资源借调请求,获取资源需求方提供的资源转移类型以及资源需求方提供的原始资源转移信息；根据资源转移类型从联盟链中获取目标资源转移信息；目标资源转移信息为第三方存储在联盟链中的,用于表征资源需求方与第三方之间的资源转移信息；基于目标资源转移信息对原始资源转移信息进行验证,得到验证结果；若验证结果表征原始资源转移信息真实有效,根据原始资源转移信息对第三方进行资源借调评估,得到第三方的评估结果；若评估结果表征评估通过,则将第三方的评估结果作为资源需求方的评估结果。采用本方法能够提高资源借调的审核效率。</td>   <td>1.一种基于联盟链的资源借调评估方法,其特征在于,所述方法包括：响应于联盟链中的资源需求方的资源借调请求,获取所述资源需求方提供的资源转移类型以及所述资源需求方提供的原始资源转移信息；所述资源转移类型用于表征所述资源需求方和所述联盟链中的第三方之间的资源转移方式；根据所述资源转移类型从所述联盟链中获取目标资源转移信息；所述目标资源转移信息为所述第三方存储在所述联盟链中的,用于表征所述资源需求方与所述第三方之间的资源转移信息；基于所述目标资源转移信息对所述原始资源转移信息进行验证,得到验证结果；若所述验证结果表征所述原始资源转移信息真实有效,根据所述原始资源转移信息对所述第三方进行资源借调评估,得到所述第三方的评估结果；若所述评估结果表征评估通过,则将所述第三方的评估结果作为所述资源需求方的评估结果。</td>   <td>G06Q40/03;G06Q10/10;G06F16/23;G06F16/27;G06F21/60;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭裕兰;                   危义民       </td>   <td>中山大学·深圳;中山大学</td>   <td>点云序列识别模型的训练、识别方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN115965833A</td>   <td>2023-04-14</td>   <td>本发明公开了点云序列识别模型的训练、识别方法、装置、设备及介质,包括：获取点云序列,从点云序列中选取不相邻的任意两帧点云数据,得到源点云和目标点云；将源点云和目标点云输入辅助任务模型进行点云重建得到重建点云,根据重建点云与目标点云的特征相似误差对辅助任务模型的编码器进行预训练处理,得到训练好的编码器；获取识别任务解码器,将识别任务解码器与训练好的编码器进行组合处理,得到初始化的点云序列识别模型；将点云序列输入初始化的点云序列识别模型进行训练,得到训练好的点云序列识别模型。本发明实施例能够减少点云序列识别模型对人工标记数据的依赖,能够适用于多种点云识别任务,可广泛应用于人工智能技术领域。</td>   <td>1.一种点云序列识别模型的训练方法,其特征在于,所述方法包括：获取点云序列,从所述点云序列中选取不相邻的任意两帧点云数据,得到源点云和目标点云；将所述源点云和所述目标点云输入辅助任务模型进行点云重建得到重建点云,根据所述重建点云与所述目标点云的特征相似误差对所述辅助任务模型的编码器进行预训练处理,得到训练好的编码器；获取识别任务解码器,将所述识别任务解码器与所述训练好的编码器进行组合处理,得到初始化的点云序列识别模型；将所述点云序列输入初始化的点云序列识别模型进行训练,得到训练好的点云序列识别模型。</td>   <td>G06V10/774;G06V10/82;G06T7/73;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林键;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于强化学习的多轮对话答复选择模型及其方法</td>   <td>广东省</td>   <td>CN109597876B</td>   <td>2023-04-11</td>   <td>本发明公开了一种基于强化学习的多轮对话答复选择模型及其方法,该模型包括：策略网络模块,采用随机策略,在各个状态空间下对上下文文本的各句子中的各个单词采样一个动作,从而对整个上下文文本得到一个动作序列,并根据分类网络的分类结果获得延时奖励；上下文文本重构网络,根据所述策略网络模块输出的动作序列,重构出一个新的上下文文本；分类网络模块,将上下文文本重构网络重构后的上下文文本与候选回答句子进行匹配,最后得到分类结果,并根据分类结果计算得到一个损失值,将该损失值作为延迟奖励更新所述策略网络模块,本发明不仅能够自动地过滤掉与任务无关的词语,同时在句子匹配的过程中充分考虑了不同句子与回答之间的语义相关性。</td>   <td>1.一种基于强化学习的多轮对话答复选择方法,包括如下步骤：步骤S1,利用策略网络模块采用随机策略,在各个状态空间下对上下文文本的各句子中的各个单词采样一个动作,从而对整个上下文文本得到一个动作序列；步骤S2,利用上下文文本重构网络根据策略网络模块输出的动作序列,重构出一个新的上下文文本；步骤S3,利用分类网络模块将上下文文本重构网络重构后的上下文文本与候选回答句子进行匹配,最后得到分类结果,并根据分类结果计算得到一个损失值,将该损失值作为延迟奖励更新策略网络模块；所述随机策略为：π(a-ts-t；θ)＝sigmod(W*[h-(u,t-1)；e-(u,t)；e'-(u,t)]+b)其中π(a-ts-t；θ)表示选择动作a-t的概率,θ、W、b表示策略网络的参数,且θ＝{W,b},e-(u,t)为上下文句子u在t状态下输入的词向量,h-(u,t-1)表示上一状态下门循环网络GRU的隐藏状态向量,令候选回答/&gt;其中e-(r,i)表示句子r中的第i个单词,对/&gt;有/&gt;e-(t,i)建模了当前状态输入的单词和候选答复句子中各个单词的相关性；步骤S3进一步包括：步骤S300,将门循环单元的内部隐藏状态作为文本单词的表示,将重构后的上下文文本和候选回答句子,计算重构后上下文文本单词向量矩阵与候选回答句子单词向量句子乘积,得到一个单词-单词的相似性矩阵；步骤S301,利用卷积神经网络提取该相似性矩阵中的关键特征；步骤S302,将该关键特征一个全连接层得到最后的分类结果,并根据分类结果计算得到一个损失值,将该损失值作为延迟奖励更新策略网络模块。</td>   <td>G06F16/332;G06F16/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   殷家康       </td>   <td>中山大学</td>   <td>一种基于word2vec的房源词向量训练方法及装置</td>   <td>广东省</td>   <td>CN109858024B</td>   <td>2023-04-11</td>   <td>本发明公开一种基于word2vec的房源词向量训练方法及装置,本装置用于实现本方法,本方法包括制定房源点击行为的训练数据结构；输入训练数据集,构建语料库,且由房源ID及其对应的城市ID生成二元组,统计二元组生成房源词典；在word2vec的skipgram模型中输入有下单标签的房源ID,以滑窗方式获取其正样本；在房源词典的二元组中,从与房源ID对应的同城ID和非同城ID中分别采样其负样本；将其正样本和其负样本一起作为训练样本,使用skipgram模型进行训练,输出房源ID对应的词向量。本发明通过城市ID以及房源ID的对应关系,在训练样本采样中保证了数据的差异性和类别的均衡性,得到了更加优质的词向量。</td>   <td>1.一种基于word2vec的房源词向量训练方法,其特征在于,包括以下步骤：S10将用户的房源点击行为数据集按房源ID分割成若干房源ID的点击序列,一房源ID的点击序列,由若干房源ID的点击序列生成训练数据集,每个训练数据的结构：第一列为当前点击行为的下单或未下单标签,其后列为同一房源ID按时间顺序排列的点击行为数据集,其中后列末尾为同一房源ID的当前点击行为数据；S20输入训练数据集,统计训练数据集生成语料库,在训练数据集中抽取房源ID及其对应城市的同城ID的点击序列生成若干房源ID二元组,统计若干房源ID二元组,生成房源词典；S30在word2vec的skipgram模型中输入有下单标签的房源ID,以滑窗方式获取其正样本；在房源词典的若干房源ID二元组中采样其同城ID的第一负样本；在房源词典中采样其非同城ID的第二负样本；S40将其正样本、第一负样本和第二负样本一起作为训练样本,使用skipgram模型进行训练,输出房源ID对应的词向量。</td>   <td>G06F40/205;G06F18/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              李百林;              王青;                   李冠彬       </td>   <td>中山大学</td>   <td>一种多跳视觉问题推理模型及其推理方法</td>   <td>广东省</td>   <td>CN110110043B</td>   <td>2023-04-11</td>   <td>本发明公开了一种多跳视觉问题推理模型及其推理方法,所述模型包括：多跳视觉问题推理数据集建立单元,用于通过将场景图和知识库相融合成知识图,利用知识图构造包含多跳知识推理问答对的数据集；卷积神经网络,用于提取输入图像的图像特征；长短期记忆网络,用于提取问题特征；知识路由模块化网络,用于将问题解析为查询树,其中查询树是问题的推理过程的符号化表达,并结合查询树和知识库,在知识图中提取出正确的关系或实体,进行多跳推理以给出最终的回答。</td>   <td>1.一种多跳视觉问题推理系统,包括：多跳视觉问题推理数据集建立单元,用于通过将场景图和知识库相融合成知识图,利用知识图构造包含多跳知识推理问答对的数据集；卷积神经网络,用于提取输入图像的图像特征；长短期记忆网络,用于提取问题特征；知识路由模块化网络,用于将问题解析为查询树,其中查询树是问题的推理过程的符号化表达,并结合查询树和知识库,在知识图中提取出正确的关系或实体,进行多跳推理以给出最终的回答；所述数据集基于自然图像场景图和外部知识库提取到的一或两个事实三元组,构造复杂问题的问题-答案对；所述多跳视觉问题推理数据集建立单元根据场景图标注和知识库,选取若干事实三元组,对问答模板填空,生成问题,并生成相应的答案及推理中间过程标注；所述多跳视觉问题推理数据集建立单元通过问题对应的三元组来诊断模型的可解释性,并要求模型在给出问题的答案时,同时给出对应的依据,通过衡量三元组的准确率或召回率量化模型的可解释性；所述知识路由模块化网络进一步包括：查询树生成网络,用于将问题解析为查询树,用以指导树形神经模块化网络的拓扑结构；树形模块化神经网络,由查询树指导生成,其根结点所对应的模块最后接入一个多层感知机,从图片和知识库中提取出视觉依据或知识,最后将这些提取到的信息整合下通过多跳推理得到最终答案；多层感知机,用于获取所述树形模块化神经网络的输出,多层感知处理后得到整个问题的答案；所述查询树生成网络为一个序列到序列的循环神经网络,由一个编码器循环神经网络和一个解码器循环神经网络构成,所述编码器每次读入问题的一个单词,取最后一步的循环神经网络输出作为问题向量编码,然后用一个解码器神经网络生成查询语句,每一步的输入都是问题向量编码,输出是查询语句的一个字符,最后再用一个移入-规约语法解析器将查询语句转化为查询树。</td>   <td>G06F16/33;G06F16/332;G06F16/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              余伟江;              梁小丹;              龚科;                   王青       </td>   <td>中山大学</td>   <td>一种服装关键点定位系统及其训练、定位方法</td>   <td>广东省</td>   <td>CN109559345B</td>   <td>2023-04-11</td>   <td>本发明公开了一种服装关键点定位系统及其训练、定位方法,该系统包括：基础卷积网络,对输入的服装训练图像或服装测试图像提取卷积特征图；堆叠式层级布局知识推理单元,包括多个层级布局知识推理模块,用于于训练时,结合预定义的服装关键点空间布局关系信息来对提取的卷积特征图进行图-点转换、节点知识推理和点-图转换,利用目标函数对基础卷积网络和层级布局知识推理单元进行协同训练；于测试时,调用层级布局知识推理单元对提取的卷积特征图进行图-点转换、节点知识推理和点-图转换,实现知识推理和特征增强；后处理模块,用于将层级布局知识推理单元输出的卷积特征图转换为特征定位图,基于特征定位图预测和计算出服装关键点的位置。</td>   <td>1.一种服装关键点定位系统,包括：基础卷积网络,用于对输入的服装训练图像或服装测试图像提取卷积特征图；堆叠式层级布局知识推理单元,包括多个层级布局知识推理模块,用于在训练时,结合预定义的服装关键点空间布局关系信息来对提取的卷积特征图进行图-点转换、节点知识推理和点-图转换,利用目标函数对所述基础卷积网络和堆叠式层级布局知识推理单元进行协同训练；于测试时,调用多个层级布局知识推理模块对提取的卷积特征图进行图-点转换、节点知识推理和点-图转换,实现知识推理和特征增强；后处理模块,用于将所述堆叠式层级布局知识推理单元输出的卷积特征图转换为特征定位图,基于生成的特征定位图来预测和计算出服装关键点的位置；所述堆叠式层级布局知识推理单元包括：图-点子模块,用于将所述基础卷积网络输出的卷积特征图转换为图节点特征；层级推理子模块,用于利用服装关键点空间布局关系的信息结合所述图节点特征进行层级布局知识推理,丰富所述图节点特征的层级语义信息,得到进化增强后的图节点特征；点-图子模块,用于将所述层级推理子模块输出的图节点特征转换为卷积特征图；所述层级推理子模块包括至底向上的图聚类式推理和至顶向下的图反卷积式推理,所述图聚类式推理过程分多个层级,包括从叶子节点间的推理聚类到中间节点间的推理、中间节点内部的聚类和推理、中间节点间的推理聚类到根节点的推理,所述图反卷积式推理包括从根节点的推理反卷积到中间节点间的推理,最后到叶子节点间的推理,最后通过结合两类推理的层级输出来建模全局结构语义。</td>   <td>G06T7/73</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈定安;              刘智泉;                   招倩莹       </td>   <td>中山大学</td>   <td>基于单一图像的国旗检测方法</td>   <td>广东省</td>   <td>CN110992308B</td>   <td>2023-04-11</td>   <td>本发明提供的基于单一图像的国旗检测方法,包括：构建五角星几何模型；从拍摄的图像中提取每个五角星的边缘点；从大五角星的边缘点中提取出五角星的五个顶点；计算大星五个顶点的物体空间坐标,校正相机姿态及畸变；将每个五角星的顶点进行坐标转换,计算每个五角星的中心和角度；根据计算出的五角星的中心和角度与国家国旗规格对比,判断国旗是否符合规格。本发明提供的基于单一图像的国旗检测方法,通过基于五边形几何模型构建出五角星几何模型,将从普通数码照相机拍摄到的单一图像进行五角星提取并还原实物比例,利用构建的五角星形状的二维几何模型准去地判别国旗是否含有不符合规格的五角星。</td>   <td>1.基于单一图像的国旗检测方法,其特征在于：包括以下步骤：S1：基于五边形几何模型构建五角星几何模型；具体为：设五角星的中心坐标为(X-C,Y-C),Z轴方向旋转角Ψ和半径R-0,则参数满足以下转换方程：                  其中,X'、Y'表示转换成原始位置的横轴坐标、纵轴坐标,R-(2D)(Ψ)表示Ψ的旋转矩阵；在第一个五区划分中的位置受以下约束方程约束：(X'-R-0)tan(54°)＝|Y'|将五角星进行十区划分,则位于不同分区内的点在经过角度(p-1)·36°+Ψ旋转后,会满足约束方程的约束条件,其中,参数p为十区划分编码,具体定义为：                  其中,Θ(0°≤Θ≤360°)为点在X-Y平面上的极角；由于每两个十区划分内的点均满足约束方程的约束条件,因此将十区划分合并为五区划分,使位于不同分区内的点在经过角度q·72°+Ψ-72°旋转后,同样满足约束方程的约束条件；其中,q是五区划分编码,具体定义为：                  至此,五角星的几何模型已经构建完成,该模型将用于S5的五星中心、角度计算；S2：运用边缘检测算法从拍摄的图像中提取每个五角星的边缘点；S3：利用直线提取的方式,从大五角星边缘点中计算出大五角星的五个顶点；S4：在仿真平台上确定一坐标点,根据正五角星二维集合模型得到大星五个顶点的物体空间坐标,校正照相机拍摄国旗时的姿态；S5：将每个五角星的顶点从照相机的影像坐标转换到物体空间坐标,计算每个五角星的中心和角度；S6：根据计算出的五角星的中心和角度与国家国旗规格对比,判断国旗是否符合规格。</td>   <td>G06T7/00;G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青;              谢柏基;                   江波       </td>   <td>中山大学</td>   <td>一种拦截利用摄像头漏洞窃取用户隐私行为的方法及系统</td>   <td>广东省</td>   <td>CN111090880B</td>   <td>2023-04-11</td>   <td>本发明公开了一种拦截利用摄像头漏洞窃取用户隐私行为的方法及系统,该方法包括：步骤S1,将监控捕获模块嵌入于系统执行摄像头调用的实现流程中,以实时监视记录摄像头调用的时间及调用者,并获取当前调用摄像头应用的设置处理方式,于处理方式为识别时,将记录信息封装为识别请求,发送到分析识别模块；步骤S2,所述分析识别模块于接收到来自所述监控捕获模块的识别请求时进入分析识别工作,判定应用当前调用摄像头是否处于无预览模式,若识别结果为应用以无预览方式调用摄像头,则通知用户交互模块发送告警通知给用户；步骤S3,利用所述用户交互模块,根据分析识别模块的分析结果发送告警通知给用户。</td>   <td>1.一种拦截利用摄像头漏洞窃取用户隐私行为的方法,包括如下步骤：步骤S1,将监控捕获模块嵌入于系统执行摄像头调用的实现流程中,以实时监视记录摄像头调用的时间及调用者,并获取当前调用摄像头应用的设置处理方式,于处理方式为识别时,将记录信息封装为识别请求,发送到分析识别模块；步骤S2,所述分析识别模块于接收到来自所述监控捕获模块的识别请求时进入分析识别工作,判定应用当前调用摄像头是否处于无预览模式,若识别结果为应用以无预览方式调用摄像头,则通知用户交互模块发送告警通知给用户；步骤S3,利用所述用户交互模块,根据分析识别模块的分析结果发送告警通知给用户；于步骤S2中,所述分析识别模块通过执行系统截屏并与摄像头当前捕获帧的图像相似比对以识别判定应用当前调用摄像头是否处于无预览模式；步骤S2进一步包括：步骤S200,获取摄像头拍摄原图以及系统截屏图片,对摄像头拍摄原图与系统截屏图片进行裁剪,取其中心区域作为下一步计算数据；步骤S201,根据颜色直方图算法原理,分别计算图像裁剪单元所得的两张图的向量；步骤S202,计算两张图向量的相似度；步骤S203,若步骤S202返回的结果大于系统设定的阈值,则认为该应用以正常预览方式调用摄像头,否则认为该应用以无预览方式调用摄像头；于步骤S1中,所述监控捕获模块的权限检查是通过调用安卓系统下的PackageManagerService服务的checkUidPermission(int uid,String permission)来实现的。</td>   <td>G06F21/62;G06F21/71</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢宇彤;              杜云飞;                   陈志广       </td>   <td>中山大学</td>   <td>面向用户自定义元数据的索引与查询方法和系统</td>   <td>广东省</td>   <td>CN111427847B</td>   <td>2023-04-11</td>   <td>本发明公开了一种面向用户自定义元数据的索引与查询方法和系统,本发明索引方法包括提取用户自定义元数据,初始化包含值存储哈希表、路径存储哈希表的层次式哈希索引结构并填充用户自定义元数据,值存储哈希表的键存储“属性名”、值存储该“属性名”对应的“属性值”集合；路径存储哈希表的键存储“属性名”和某一“属性值”组成的字符串,值存储该“属性名”及“属性值”对应“数据对象路径”集合。本发明只需提取文件的用户自定义元数据信息,无需任何数据移动开销；相比于遍历方式,本发明设计的层次式索引与查询机制能够快速定位目标文件,高效满足查询需求,能够满足科研人员对科学数据的定位需求。</td>   <td>1.一种面向用户自定义元数据的索引方法,其特征在于实施步骤包括：1)获取自描述文件的用户自定义元数据,包括“属性名”、“属性值”和“数据对象路径”；2)初始化包含值存储哈希表ValueStore、路径存储哈希表PathStore的层次式哈希索引结构并填充用户自定义元数据,所述值存储哈希表ValueStore的键存储“属性名”、值存储该“属性名”对应的“属性值”集合；所述路径存储哈希表PathStore的键存储“属性名”和某一“属性值”组成的字符串,值存储该“属性名”及“属性值”对应“数据对象路径”集合；3)将层次式哈希索引结构持久化存储；还包括处理类型为范围查询的用户查询请求：A1)获取用户查询请求中指定的目标“属性名”；A2)根据目标“属性名”查询值存储哈希表ValueStore得到目标“属性名”对应的所有“属性值”集合,其中值存储哈希表ValueStore中存储的被查询数据的键为“属性名”、值为该“属性名”对应的所有“属性值”集合；其次,根据查询请求中指定的“属性值”范围筛选满足查询条件的“属性值”；A3)针对目标“属性名”对应的所有筛选后的“属性值”：将目标“属性名”、该“属性值”组合为新的字符串,根据新的字符串作为键查询路径存储哈希表PathStore得到该“属性值”对应的“数据对象路径”集合,其中路径存储哈希表PathStore中存储的被查询数据的键为“属性名”和某一“属性值”组成的字符串,值为该“属性名”及“属性值”对应的“数据对象路径”集合；A4)将每一个“属性值”查询得到的“数据对象路径”集合组合后作为查询结果返回。</td>   <td>G06F16/13;G06F16/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张岐良;              张卉;                   陈洪波       </td>   <td>中山大学</td>   <td>一种SA-BESO联合拓扑优化方法</td>   <td>广东省</td>   <td>CN113094945B</td>   <td>2023-04-11</td>   <td>本发明公开了一种SA-BESO联合拓扑优化方法,本发明通过将结构模型划分为多个结构单元并求解出初始解,之后根据灵敏度对结构单元进行更新,得到新的结构模型,在对新的结构模型进行求解得到新的计算结果,根据新的计算结果、初始解和SA算法求解出最优解。本发明实施例在对结构模型进行结构拓扑优化的过程中,将SA和BESO算法相结合,通过BESO算法的不断对结构模型的结构进行更新,并在求解出最优解的过程中引入了SA算法,提高求解的全局最优性。</td>   <td>1.一种SA-BESO联合拓扑优化方法,其特征在于,包括以下步骤：S1：获取第i结构模型,对SA-BESO参数进行初始化；其中,i∈N*；所述SA-BESO参数包括初始温度、删除率、体积约束、惩罚因子、Markov链长度L和降温指标；S2：将第i结构模型划分为多个第i结构单元,对所述第i结构单元进行分析,得到第i结构数据；S3：基于所述SA-BESO参数以及所述第i结构数据计算所述第i结构模型的目标函数,得到第i计算结果；S4：计算每个所述第i结构单元的第i灵敏度,根据所述第i灵敏度对所述第i结构单元进行更新,得到第i+1结构模型以及更新次数；所述第i灵敏度为第i结构单元对第i结构模型的贡献度；S5：令i=i+1,重新执行步骤S2-S4,基于第i-1计算结果、所述第i计算结果、所述更新次数以及SA算法,求解出最优解；其中,所述第i结构模型以结构柔顺度最小值为所述目标函数,以体积约束为约束条件,并且在结构拓扑优化过程中,所述第i结构模型具有受力等载荷条件；基于所述约束条件以及所述受力等载荷条件,使用Abaqus建立结构模型对第i结构单元进行有限元分析,得到第i结构数据；在步骤S4中,计算每个所述第i结构单元的第i灵敏度的具体过程为：计算每个所述第i结构单元的第i初始灵敏度,对每个所述第i结构单元的第i初始灵敏度进行过滤,得到每个所述第i结构单元的第i灵敏度；在步骤S4中,根据所述第i灵敏度对所述第i结构单元进行更新的具体过程为：根据所述第i灵敏度制定随机更新原则以及增删原则,基于所述随机更新原则以及所述增删原则对所述第i结构单元进行更新；所述随机更新为按照实体单元全为数字“1”,空洞单元为一定比例的“1”和“0”组合的原则给每个第i结构单元赋予6-10位二进制编码,并基于二进制编码的交叉变异随机更新；其中,利用交叉变异随机产生新解的方法为：将每个第i结构单元对应的灵敏度进行降序排序,并将单元灵敏度分成两个部分,第一部分为前N×(1-ER)个灵敏度组,称为预保留数组,第二部分为剩下的N×ER个灵敏度组,称为预去除数组；在两个数组间进行交叉操作和变异操作,从而建立新旧解间的关系；在交叉阶段,每个个体只能进行一次配对与交叉；根据预设配对概率选定两个数组进行交叉后,随机产生一个断点,并对断点后的数字进行交叉操作；变异操作直接改变二进制编码中的数位值,按照预设变异概率实现“0”与“1”间相互转换；利用增删准则进行第i结构单元增删产生新结构的方法为：将经过交叉、变异之后得到新的二进制编码中含有纯“0”字符串的实体单元从设计区域中移除,而在上一次迭代中的空洞单元,若空洞单元的编码中含有50%或以上的“1”数位,则将空洞单元添加到设计区域中,以及根据增删后剩下的结构单元形成新的结构。</td>   <td>G06F30/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王嘉辉;              杨上玄;              郭祥;              劳子健;              蔡志岗;              江灏;                   张佰君       </td>   <td>中山大学</td>   <td>一种基于特殊复合平面镜虚像成像的三维重建装置和方法</td>   <td>广东省</td>   <td>CN113223135B</td>   <td>2023-04-11</td>   <td>本发明提供一种基于特殊复合平面镜虚像成像的三维重建装置和方法,装置包括相机设备和标定-成像联合器件,其中：所述相机设备获取视场深度图；所述标定-成像联合器件其表面设置有镀银的镜面区域、漫反射区域和定位标识图像,所述镜面区域与漫反射区域位于同一平面上；所述相机设备通过标定-成像联合器件的反射,获取不在所述相机设备视场范围内的目标物的深度图。方法包括点云重建,镜面区域框定,镜面点云分离,平面拟合以及镜面对称。相比于光路几何解算,本方法无需得知相机设备,镜面,目标物之间的相对位置关系,也不要额外的标准尺寸参考物,可实现快速动态得到非直接视场的目标在相机坐标系中的空间位置,从而得到方位和距离等信息。</td>   <td>1.一种基于特殊复合平面镜虚像成像的三维重建装置,其特征在于,包括相机设备和标定-成像联合器件,其中：所述相机设备获取视场深度图；所述标定-成像联合器件其表面设置有镀银的镜面区域、漫反射区域和定位标识图像,所述镜面区域与漫反射区域位于同一平面上；所述相机设备通过标定-成像联合器件的反射,获取不在所述相机设备视场范围内的目标物的深度图。</td>   <td>G06T15/04;G06T15/00;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              肖鹏;              王耿媛;              黄远聪;                   李赛群       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于深度学习的角膜内皮细胞活性因子的分析方法</td>   <td>广东省</td>   <td>CN114693646B</td>   <td>2023-04-11</td>   <td>本公开提供了一种基于深度学习的角膜内皮细胞活性因子的分析方法,包括对细胞图像进行分割以得到分割图像,在分割图像中获取细胞区域图像,细胞区域图像具有位于图像中心的中心细胞,统计细胞区域图像内的细胞个数和分布密度,基于细胞个数和分布密度计算细胞区域图像的总体径向分布函数,基于总体径向分布函数获得细胞的生长势能曲线,基于生长势能曲线的变化率获得角膜内皮细胞活性因子,基于角膜内皮细胞活性因子获得细胞图像中的细胞的生理状态。本公开的分析方法,通过获得细胞图像的势能转换常数进而获得角膜内皮细胞的生理状态,在这种情况下,能够提高角膜内皮细胞的生理状态的检测效率。</td>   <td>1.一种基于深度学习的角膜内皮细胞活性因子的分析方法,其特征在于,对细胞图像进行分割以得到分割图像,在所述分割图像中获取细胞区域图像,所述细胞区域图像具有位于图像中心的中心细胞,统计所述细胞区域图像内的细胞个数和分布密度,基于所述细胞个数和所述分布密度计算所述细胞区域图像的总体径向分布函数,基于所述总体径向分布函数获得细胞的生长势能分布图,采用四次多项式对所述生长势能分布图进行曲线拟合以获得细胞的生长势能曲线,基于所述生长势能曲线的变化率获取所述生长势能曲线的最小值,并基于所述生长势能曲线在所述最小值的二阶导数获得角膜内皮细胞活性因子,基于所述角膜内皮细胞活性因子获得所述细胞图像中的细胞的生理状态；其中,基于所述细胞个数和所述分布密度计算所述细胞区域图像的总体径向分布函数的步骤包括：选定一个参考细胞,通过回归分析,计算得到所述细胞区域图像的总体径向分布函数的函数式,所述总体径向分布函数的函数式满足公式：                  其中,g(r)表示所述总体径向分布函数,r表示给定所述参考细胞之后所选区域的边缘与所述参考细胞中心之间的距离,n-i(r)表示在不同的r之内包含的细胞数量,ρ表示所述细胞区域图像上的平均细胞密度,dr表示给定所述参考细胞之后所述参考细胞中心与所述所选区域的边缘之间的距离的变化。</td>   <td>G06T7/00;G06T7/11;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁国晟;              江凯萱;              吴左晗;              李冬玲;              刘光亚;              余建兴;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于搭配修辞语法纠错的作文批改方法及系统</td>   <td>广东省</td>   <td>CN115952789A</td>   <td>2023-04-11</td>   <td>本发明提供一种基于搭配修辞语法纠错的作文批改方法及系统,本发明构造了条件随机场层；条件随机场层以马尔科夫决策链为基础,可以重新串联语句词与词之间的关系,将BERT编码单元的输出输入到条件随机场层之后运行改进过后的维特比算法解码出最后的语法修改标签；输出构建单元则基于语法修改标签构造出输出的正确句子。</td>   <td>1.一种基于搭配修辞语法纠错的作文批改方法,其特征在于,包括以下步骤：S1：对中文句子进行任务形式化定义；S2：构建搭配不当错误样例构造单元来对经步骤S1处理的中文句子构造出搭配不当错误样例；S3：构建BERT编码单元将步骤S2得到的中文句子编码成一个词向量；S4：构建条件随机场层单元将步骤S3得到的中文句子进行解码；S5：构建输出构建单元将步骤S4进行处理得到最终结果。</td>   <td>G06F40/279;G06F40/216;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              齐浩然;                   邱钰苇       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于transformer和卷积神经网络联合的人脸超分辨率重建方法和系统</td>   <td>广东省</td>   <td>CN115953296A</td>   <td>2023-04-11</td>   <td>本发明公开了一种基于transformer和卷积神经网络联合的人脸超分辨率重建方法和系统,包括使用基本特征提取模块和隐编码器对待处理人脸图像进行处理,获得基本特征信息和隐空间风格向量,进一步处理得到空间分布特征信息,对空间分布特征信息和空间分布特征信息分别进行自变换、高频特征增强处理和提取,获得人脸空间分布特征信息和人脸成分纹理特征信息,根据人脸空间分布特征信息和人脸成分纹理特征信息处理得到重建人脸图像等步骤。本发明提升了重建的人脸在轮廓与内容恢复中的表现,综合了基于卷积神经网络以及基于transformer的人脸超分辨率重建技术的优点,获得精准自然的重建结果,广泛应用于图像处理技术领域。</td>   <td>1.一种基于transformer和卷积神经网络联合的人脸超分辨率重建方法,其特征在于,所述基于transformer和卷积神经网络联合的人脸超分辨率重建方法包括：获取待处理人脸图像；使用基本特征提取模块对所述待处理人脸图像进行处理,获得基本特征信息；使用隐编码器对所述待处理人脸图像进行处理,获得隐空间风格向量；根据所述基本特征信息和所述隐空间风格向量,处理得到空间分布特征信息；对所述空间分布特征信息进行自变换和高频特征增强处理,获得人脸空间分布特征信息；对所述空间分布特征信息进行提取,获得人脸成分纹理特征信息；根据所述人脸空间分布特征信息和所述人脸成分纹理特征信息,处理得到重建人脸图像。</td>   <td>G06T3/40;G06V40/16;G06N3/0464;G06N3/0455;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭裕兰;              敖晟;                   胡庆拥       </td>   <td>中山大学·深圳;中山大学</td>   <td>一种基于旋转等变网络的点云配准方法及系统</td>   <td>广东省</td>   <td>CN115953442A</td>   <td>2023-04-11</td>   <td>本发明公开了一种基于旋转等变网络的点云配准方法及系统,方法包括：获取待配准点云；利用基于点的旋转等变且平移不变的第一网络对每个待配准点云进行处理,获取逐个点云的参考方向和关键点得分；根据关键点得分进行关键点提取,并根据参考方向和基于补丁的第二网络为每个关键点提取旋转不变和SO(2)等变的特征；基于预设的匹配策略,根据特征生成具有高内点率的点对应；根据点对应,通过对应分组算法求解相对位姿,完成点云配准。本发明实施例构建了高效通用的特征学习框架,能够利用旋转不变和SO(2)等变的特征产生具有高内点率的点对应,可广泛应用于计算机技术领域。</td>   <td>1.一种基于旋转等变网络的点云配准方法,其特征在于,包括：获取待配准点云；利用基于点的旋转等变且平移不变的第一网络对每个所述待配准点云进行处理,获取逐个点云的参考方向和关键点得分；根据所述关键点得分进行关键点提取,并根据所述参考方向和基于补丁的第二网络为每个关键点提取旋转不变和SO(2)等变的特征；基于预设的匹配策略,根据所述特征生成具有高内点率的点对应；根据所述点对应,通过对应分组算法求解相对位姿,完成点云配准。</td>   <td>G06T7/33;G06N3/0464;G06N3/08;G06N3/047</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭裕兰;              王逸舟;                   刘砚       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于深度学习和不确定性估计的三维点云全景分割方法、计算机装置和存储介质</td>   <td>广东省</td>   <td>CN115953581A</td>   <td>2023-04-11</td>   <td>本发明公开了一种基于深度学习和不确定性估计的三维点云全景分割方法、计算机装置及存储介质,包括对点云数据进行处理,获得原型点和结构化特征,根据结构化特征获得点云语义标签、嵌入特征和原型预测点；根据原型预测点和嵌入特征进行不确定性估计获得原型修正点和协方差矩阵,根据原型修正点和协方差矩阵进行概率建模所得的平均概率矩阵,向点云数据的点分配实例标签,向点云数据中的点分配点云语义标签等步骤。本发明通过不确定性估计过程对网络学习中产生的认知不确定性和数据固有的偶然不确定性进行捕捉；直接将表达每个嵌入特征的相关点云分配给与其匹配概率最高的原型,实现高效、精确的聚类方式。本发明广泛应用于点云数据处理技术领域。</td>   <td>1.一种基于深度学习和不确定性估计的三维点云全景分割方法,其特征在于,所述基于深度学习和不确定性估计的三维点云全景分割方法包括：获取点云数据；对所述点云数据进行数据规范化处理,获得原型点；从所述点云数据提取出结构化特征；根据所述结构化特征进行语义分割,获得点云语义标签；根据所述结构化特征进行嵌入预测,获得嵌入特征；根据所述原型点进行原型预测,获得原型预测点；根据所述原型预测点和所述嵌入特征进行不确定性估计,获得原型修正点和协方差矩阵；所述协方差矩阵表示以所述原型修正点作为所述点云数据的高斯分布中心时,对应的高斯分布协方差矩阵；根据所述原型修正点和所述协方差矩阵进行概率建模,获得平均概率矩阵；根据所述平均概率矩阵,向所述点云数据的点分配相应的一种实例标签；根据所述点云数据中的点所属的高斯分布,向所述点云数据中的点分配相应的点云语义标签。</td>   <td>G06V10/26;G06V10/774;G06V10/40;G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              林格;                   林淑金       </td>   <td>中山大学</td>   <td>一种基于跨媒介数据的人物图谱关系识别方法及系统</td>   <td>广东省</td>   <td>CN115953716A</td>   <td>2023-04-11</td>   <td>本发明公开了一种基于跨媒介数据的人物图谱关系识别方法及系统,涉及计算机视觉的技术领域；包括获取视频数据和文本数据；对视频数据进行镜头分割处理和关键帧提取,获得视频镜头分割集和每个视频镜头的关键帧；对关键帧提取视觉特征和人脸特征,获得场景分割集和视频人物实体集；融合关键帧视觉特征和场景分割集,获得故事分割集,构建基于视频的人物图谱；利用视频镜头分割集对文本数据进行分割和人物提取,获得文本人物集；基于场景分割集与文本人物集,构建基于文本的人物图谱；聚合基于视频的人物图谱和基于文本的人物图谱,获得最终人物图谱,分析识别出人物关系。本发明构建出的最终人物图谱更加符合实际,能够识别出更准确的人物关系。</td>   <td>1.一种基于跨媒介数据的人物图谱关系识别方法,其特征在于,包括：S1：获取对应的视频数据和文本数据；S2：对视频数据依次进行镜头分割处理和关键帧提取,获得视频镜头分割集和每个视频镜头的关键帧；S3：对每个视频镜头的关键帧分别进行视觉特征提取和人脸特征提取,获得关键帧视觉特征和关键帧人脸特征；并基于关键帧视觉特征获得场景分割集,基于关键帧人脸特征获得视频人物实体集；S4：融合关键帧视觉特征和场景分割集,获得故事分割集；S5：根据视频数据、视频镜头分割集、场景分割集、故事分割集和视频人物实体集,构建基于视频的人物图谱；S6：根据视频镜头分割集对文本数据进行分割,获得文本镜头分割集；并对每个文本镜头进行人物提取,获得文本人物集；S7：基于场景分割集与文本人物集,构建基于文本的人物图谱；S8：聚合基于视频的人物图谱和基于文本的人物图谱,获得最终人物图谱；S9：对最终人物图谱进行分析,识别并输出人物关系。</td>   <td>G06V20/40;G06V40/16;G06V30/14;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪瑞昕;              林浩添;              徐枫;              余新平;                   吕军锋       </td>   <td>中山大学中山眼科中心;清华大学</td>   <td>一种基于三维重建的眼位偏斜角度的测量方法及装置</td>   <td>广东省</td>   <td>CN115953717A</td>   <td>2023-04-11</td>   <td>本申请属于眼位测量技术领域,公开了一种基于三维重建的眼位偏斜角度的测量方法及装置。采集被测试者人脸图像序列；通过第一神经网络中,获取人脸图像序列的遮盖情况,确定关键帧图像；将关键帧图像输入到第二神经网络中,获取特征点热图,并转化为人脸特征点坐标；构建人脸特征点和人脸三维模型的投影点之间的目标函数,得到关键帧图像对应的头部姿态；对眼球位置进行初始化,基于头部姿态,固定基准眼位的眼球旋转角度为预设角度,求解基准眼位图像中眼球在头部坐标系下的三维坐标；固定待测量图像中眼球在头部坐标系下的三维坐标,求解待测量图像中的眼球旋转角度,得到该眼球的偏斜角度。提高了测量眼位偏斜角度的便利性和测量精度。</td>   <td>1.一种基于三维重建的眼位偏斜角度的测量方法,其特征在于,所述方法包括：采集被测试者人脸的视频流信息,基于所述视频流信息得到所述被测试者的人脸图像序列；将所述人脸图像序列输入到第一神经网络中,得到所述人脸图像序列的遮盖情况,基于所述遮盖情况确定所述人脸图像序列的关键帧图像；将所述关键帧图像输入到第二神经网络中,得到所述关键帧图像的特征点热图,将所述特征点热图转化为人脸特征点坐标；构建人脸三维模型,基于所述人脸特征点坐标和所述人脸三维模型,得到所述人脸特征点坐标和所述人脸三维模型的投影坐标之间的目标函数,基于所述目标函数得到所述关键帧图像的人脸特征点坐标对应的头部姿态；从所述关键帧图像中选取左眼和右眼的各一帧基准眼位图像对眼球位置进行初始化,基于所述头部姿态,固定基准眼位的眼球旋转角度为预设角度,求解基准眼位图像中眼球在头部坐标系下的基准三维坐标；基于所述基准三维坐标,固定待测量图像中眼球在头部坐标系下的三维坐标,求解所述待测量图像中的眼球旋转角度,基于所述眼球旋转角度和基准眼位的眼球旋转度数,得到所述待测量图像中眼球的偏斜角度。</td>   <td>G06V20/40;G06V40/16;G06V10/82;G06V10/774;G06V10/46;G06T17/00;G06T7/60;G06N3/0464;G06N3/08;A61B3/14;A61B3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         盛璞义;              孙伟;              谷琛;              陈蔚深;              胡玄韬;              张紫机;              古明晖;              郑霖力;              潘柏祺;              张炜哲;              吴小宇;              王超;              李诚新;              阿尔曼·阿力木;              黄东伟;                   涂玉成       </td>   <td>中山大学附属第一医院;中山大学</td>   <td>一种人工关节假体周围感染诊断模型及诊断系统</td>   <td>广东省</td>   <td>CN115954102A</td>   <td>2023-04-11</td>   <td>本发明公开了一种人工关节假体周围感染诊断模型,所述人工关节假体周围感染诊断模型包括1个元学习器和6个底层学习器；所述元学习器集成6个底层学习器；该人工关节假体周围感染诊断模型运用集成型机器学习算法,综合多个子模型优势以提升模型性能,进而提高PJI诊断的精准度。本发明所述人工关节假体周围感染诊断模型可以显著提高PJI早期诊断的效能,改善临床诊疗现状,为PJI的精确诊断和预后预测提供了新的方案；可以在各级医院中大规模开展及使用,模型中的诊断指标均为易获取的常规指标,对各级医院尤其是基层医院PJI误诊率的降低具有极为重要的作用。</td>   <td>1.一种人工关节假体周围感染诊断模型,其特征在于,所述人工关节假体周围感染诊断模型包括1个元学习器和6个底层学习器；所述元学习器集成6个底层学习器；所述人工关节假体感染诊断模型以患者的21项指标作为输入参数分别输入每个底层学习器,将每个底层学习器输出的结果输入顶层的元学习器中,并从元学习器中获取输出结果,即预测结果；所述元学习器为加权投票的集成学习模型ELWV；所述6个底层学习器包括弹性网络、线性支持向量机、核支持向量机、额外树、轻型梯度提升机和多层感知机；所述21项指标具体为：关节类型、伤口渗液情况、关节局部皮温升高、窦道或假体暴露情况、前次置换距入院时间、初次置换后激素或免疫抑制剂使用情况、吸烟史、感染前3个月内菌血症病史、低白蛋白血症、球蛋白值、纤维蛋白原值、C-反应蛋白值、空腹血糖指数、白球比、血沉值、白介素-6值、中性粒细胞百分比、CT积液情况、X线透亮带/骨质破坏情况、假体周围化脓、快速病理诊断感染。</td>   <td>G16H50/20;G16H50/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈广亮;              谢贻新;              梁圣;              刘禹麒;                   罗伟玲       </td>   <td>广州蓝图地理信息技术有限公司;广东国地规划科技股份有限公司;中山大学</td>   <td>基于斑块元胞自动机和港口城市规划的港城发展模拟方法</td>   <td>广东省</td>   <td>CN109190161B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于斑块元胞自动机和港口城市规划的港城发展模拟方法,该方法采用了斑块增长模拟策略,科学的将城市用地的增长通过自发增长和组织增长两种增长模式,以种子核生长和边缘生长的方式,结合港口规划和港口城市规划来对不同发展阶段的港口城市的城市扩张过程进行动态模拟。本发明方法可以避免容易产生的过度拟合现象,能够更加合理的模拟出真实的城市增长格局,从而得出城市规划空间布局方案下的城市空间扩张模拟结果。本发明方法有效的解决了港口城市在没有建设基础的情境下根据规划方案指导的模拟城市建设过程的问题,并且得到了真实港口城市发展形态相似的空间格局,是一种切实可行的模拟港口城市空间扩展的方法。</td>   <td>1.基于斑块元胞自动机和港口城市规划的港城发展模拟方法,其特征在于,其包括如下步骤：S1,获取港口规划和港口城市规划信息数据,进行空间配准解译处理,选取若干影响港口城市土地利用或土地覆盖变化的空间引导性要素和限制性要素,组成影响因子；确定未来城市建设用地的需求面积；S2,使用港口城市规划信息数据规定好模拟区域的范围与标准栅格影像大小,然后计算模拟区域内空间栅格到各个影响因子的距离,并进行归一化处理；生成与标准栅格影像图幅大小一致的栅格距离数据；S3,利用层次分析法(AHP)来获取各个影响因子的权重,根据变量的权重大小对所有影响因子进行加权求和计算发展适宜性数据；根据中心元胞周围已转化为城市建设用地的元胞数量来判断城市发展密度,通过5*5的网格窗口来计算中心元胞的邻域的城市发展密度数据；处理限制性数据,输出限制发展数据,所述限制性数据包括水域数据和生态红线数据；将输出的适宜性数据、邻域城市发展密度数据和限制发展数据相乘,计算元胞的发展概率；S4,确定元胞的发展模式,根据邻域城市发展密度数据判断元胞是否属于种子元胞,若是,转到S5,否则转到S6；确定好增长模式之后,利用移动窗口方式来模拟城市建设用地的增长过程；S5,自发增长模式下,通过比较生成的随机数和动态阈值的大小来确定该种子元胞是否转化为城市建设用地,若否,种子元胞不进行转化,进行下一次迭代；若是,则计算新增斑块面积大小,比较种子元胞5*5邻域内每个元胞适宜性的大小,适宜性高的优先转化为城市建设用地,当达到新增斑块面积大小时停止转化；S6,组织增长模式下,通过比较生成的随机数和动态阈值的大小来确定该元胞是否转化为城市建设用地；S7,在满足既定的终止条件时,停止模拟过程,输出模拟结果。</td>   <td>G06F30/20;G06N3/00;G06T17/05;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;                   黄杨健       </td>   <td>中山大学</td>   <td>一种基于条件生成对抗网络的人脸老化方法</td>   <td>广东省</td>   <td>CN109523463B</td>   <td>2023-04-07</td>   <td>本发明提供了一种基于条件生成对抗网络的人脸自动老化机制,通过对于海量已标注年龄的不同年龄段的图像训练得到一个由四个部分组成的条件生成对抗网络,包括图像生成器G,图像判别器D,年龄估计网络AEN和身份识别网络FRN。其中,G被训练用于生成老化图像,通过输入年轻图像和预设的年龄条件,自动有效地生成年老图像。D用于鉴别生成的年老图像是否为真实图片,能够确保生成的年老图片具备欺骗性。AEN是用于减小生成图像的年龄与预设值的差异,而FRN则是保证生成过程中人像身份的一致性。发明通过对网络结构的设计,使整个网络达到端对端的训练,并且在人脸老化方面有很好的表现,能够生成身份一致,欺骗性强和分辨率高等优点的优质人脸老化图像。</td>   <td>1.一种基于条件生成对抗网络的人脸老化方法,其特征在于,包括以下步骤：S1：搜集人脸数据,并对人脸数据进行预处理；S2：输入预处理后的人脸数据分别训练年龄估计网络AEN和身份识别网络FRN；S3：编码年龄信息,构造图像生成器G和图像判别器D,并将图像生成器G的生成图像分别输入到构造的图像判别器D、训练好的年龄估计网络AEN以及身份识别网络FRN中,计算图像判别器、年龄估计网络、身份识别网络的损失函数并将损失函数进行融合作为生成器G最终的损失函数,从而构造生成对抗网络Age-GAN,训练生成对抗网络Age-GAN；S4：将待测数据输入到生成对抗网络Age-GAN中用于人脸老化；步骤S3的具体过程如下：S31：利用步骤S2中训练好的年龄估计网络AEN对标准人脸图像的年龄信息进行编码,并获得代表若干年龄组的特征向量y-i,i表示年龄组的个数；S32：构造图像生成器G和图像判别器D；S33：去除身份识别网络FRN和年龄估计网络AEN的Softmax层和最后一个全连接层,并将两个模型的参数进行固定,即在生成对抗网络Age-GAN的训练过程中两个模型的参数不发生变化；S34：将原始图像和年龄相关向量作为输入到图像生成器G,将图像生成器G的生成图像分别输入到图像判别器D、年龄估计网络AEN以及身份识别网络FRN中,其中年龄估计网络的输入还包括年龄信息,身份识别网络的输入还包括原始图像；S35：分别计算图像判别器、年龄估计网络、身份识别网络的损失函数；S36：通过将误差反向传播的方式来更新模型参数,即将图像判别器D、年龄估计网络AEN以及身份识别网络FRN中输出的损失函数进行融合并将其作为生成器G最终的损失函数。</td>   <td>G06T3/00;G06N3/084;G06N3/0464</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              张俊轩;              刘铮;              何琛;                   王伟轩       </td>   <td>中山大学</td>   <td>一种基于运动前景关注及非监督的关键帧提取的动作识别方法</td>   <td>广东省</td>   <td>CN109558811B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于运动前景关注及非监督的关键帧提取的动作识别方法,步骤包括：方法包括如下步骤：选用预训练好的卷积神经网络作为神经网络模型,构造基于方差统计的视觉关注模型并生成视觉关注权重；利用视觉关注模型提取的视觉关注权重对卷积神经网络的特征进行关注。构造非监督的关键帧提取模型并生成对于每个视频帧的置信度；利用得到的视频帧置信度对视频帧进行筛选,并采用一种随机选取的训练策略训练卷积神经网络；利用光流图像对视频的时间动态信息进行捕获,从而获得更优异的性能。本发明在现有的双流卷积神经网络的基础上,结合基于方差统计的视觉关注机制以及非监督的关键帧提取策略对输入的动作视频进行分类识别。</td>   <td>1.一种基于运动前景关注及非监督的关键帧提取的动作识别方法,其特征在于,所述方法包括如下步骤：S1：选用在图像数据集ImageNet上预训练好的卷积神经网络作为卷积神经网络模型A,将对视频进行密集采样得到一系列视频帧,所述视频帧作为所述神经网络模型A的输入,构建基于方差统计的视觉关注模型并生成视觉关注权重矩阵；所述步骤S1的具体过程如下：S11：首先对视频中进行密集采样得到一系列的视频帧,并保证帧之间的时间间隔小于或等于30fps；S12：将步骤S11中得到的视频帧输入到在ImageNet数据集预训练好的卷积神经网络模型A中；S13：在卷积神经网络模型A正向传播过程中,将获得卷积神经网络模型A最后一层卷积层的特征；S14：构建基于方差统计的视觉关注模型,其生成视觉关注权重矩阵的具体过程如下：S141：对步骤S11中所有连续相邻帧之间作差,得到差分图像；S142：将所有差分图像堆叠成一个3维的时空块；S143：对3维时空块中的相同空间位置的像素沿时间轴求方差,从而得到每个空间位置的方差值,由方差值组成图成为方差图,方差图用于反映视频帧中运动剧烈的空间位置；S144：利用均值池化策略对S14步骤中得到的方差图进行空间下采样得到关注权重矩阵,使得下采样后的关注权重矩阵与S13中获得的卷积特征有相同的空间分辨率；S2：利用视觉关注模型提取的视觉关注权重对卷积神经网络模型A的特征进行关注；S3：构造非监督的关键帧提取模型并生成对于每个视频关键帧的置信度,将得到的关键帧的置信度作为所在视频块的置信度；S4：利用得到的不同视频块置信度采取不同的选取概率对步骤S1中采集的视频帧进行筛选,并采用一种随机选取的训练策略训练卷积神经网络模型A,然后将筛选后的视频帧输入到上述随机策略训练好的卷积神经网络模型A得到测试结果A；S5：对步骤S4筛选的所有相邻的视频帧提取其光流运动信息,生成光流图像；将生成的光流图像输入到在ImageNet预训练好的卷积神经网络B中；通过反向传播对网络参数进行更新；将更新后的卷积神经网络B用于测试,得到测试结果B；将测试的结果B与S1-S4步骤中的测试结果A进行结合,得到最终的识别结果。</td>   <td>G06V40/20;G06V20/40;G06V10/764;G06V10/774;G06V10/82;G06N3/0464;G06N3/084;G06N3/088</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周小峰;              李奥;              衣杨;              沈金龙;              朱艺;                   顾佳良       </td>   <td>中山大学</td>   <td>一种基于时空信息融合的视频人体行为识别方法</td>   <td>广东省</td>   <td>CN109583335B</td>   <td>2023-04-07</td>   <td>本发明涉及人工智能领域,更具体的,涉及一种基于时空信息融合的视频人体行为识别方法。本发明基于密集光流场结合轨迹的时间显著值提取显著轨迹,并基于底层显著轨迹构造了一种新的中层特征——轨迹组,其在一定程度上刻画了时间维度上的运动信息,弥补了底层轨迹的缺陷,同时构造了轨迹组在时间维度上的前后、远近关系,丰富了轨迹组的时间关系。本发明基于稀疏采样提出了自适应分段采样策略,对视频采样的数目随视频时长而自适应变化,对任意时长的视频都能够提取到富有判别力的空间信息。</td>   <td>1.一种基于时空信息融合的视频人体行为识别方法,其特征在于,包括以下步骤：步骤S1：对视频时间信息进行提取分类,将原始视频进行灰度空间尺度变换,提取显著轨迹；步骤S2：根据显著轨迹的持续时间进行聚类而构建视频中层特征TG；步骤S3：构造TG之间的时间关系；步骤S4：计算TG的特征描述符；步骤S5：采用Fisher编码方法对TG特征进行编码,结合TG以及时间关系作为时间信息视频表示；步骤S6：采用隐结构的支持向量机对视频进行分类；步骤S7：对视频空间信息进行提取分类,采用自适应分段采样策略从视频中进行稀疏采样；步骤S8：对采样所得到的视频帧利用卷积神经网络提取空间特征；步骤S9：根据提取到的特征进行行为视频分类；步骤S10：把根据视频时间信息得到的分类结果和根据视频空间信息得到的分类结果进行平均加权融合,得到最后的视频分类结果；步骤S1具体包括以下步骤：步骤S101：输入原始视频序列X；步骤S102：计算初始化视频轨迹长度L,采样步长STEP：步骤S103：对原始视频做灰度转换；步骤S104：对进行灰度转换后的视频起始帧进行密集采样得到轨迹集初始点；步骤S105：跟踪初始点在后续视频帧的位置,同时计算各个视频帧的时间显著值以及过滤阈值；步骤S106：将视频序列的轨迹记作表示以第j帧为起始帧,第i个点/&gt;形成的长度为L的轨迹,将第j帧上每个特征点p～j(x～j,y～j),通过中值滤波后的密集光流场f＝(u-t,v-t)跟踪至第j+1帧：得到第j+1帧的位置p～(j+1),具体公式如下：                  其中,M为中值滤波核,是(x～j,y～j)四舍五入取整后的位置坐标；步骤S107：计算第j帧的所有采样点的时间显著值,设在第j帧中,点周围3×3像素块作为该点的中心块为/&gt;其周围9×9像素块为第一周围块为/&gt;16×16像素块为第二周围块为/&gt;为中心块/&gt;建立一个光流字典/&gt;和/&gt;分别为/&gt;对应的同一光流图像上的两个周围块,点/&gt;的中心块与周围块的运动差值/&gt;作为/&gt;的时间显著值,记作/&gt;由以下公式计算获得：/&gt;                  其中O-v(·)和O-h(·)分别是中心块和周围块的水平和垂直方向上的光流平均值,轨迹的时间显著值S(t-i～j)定义为该轨迹上每个点的平均时间显著值：                  步骤S108：在第j帧的时间显著值的基础上计算平均时间显著值,第j帧的平均时间显著值S-f定义为：                  其中,H和W分别是帧的高度值和宽度值；为第j帧所有采样点的时间显著值总和；count是帧采样点的总个数；步骤S109：计算每一帧的过滤阈值T-f；步骤S110：初始化T-f为2S-f,若点的时间显著值小于T-f,则T-f设置为/&gt;否则T-f保持不变；步骤S111：计算每条轨迹的时间显著值；步骤S112：计算轨迹的自适应过滤阈值长度为L的轨迹共跨越L+1帧；步骤S113：提取显著轨迹集,步骤S2具体包括以下步骤：步骤S201：构建视频表示M-c：                  其中,φ(X)表示提取到的整个视频的显著轨迹,X为视频序列,表示从一个视频的N个TG中学习出K个最具有判别力的TG,τ表示隐变量,μ＝(μ-0,μ-i)表示显著轨迹特征和TG的权重；步骤S202：将视频轨迹作为视频表示M-c中的隐变量进行学习,学习到的隐变量为具有较强判别力的TG集合。</td>   <td>G06V40/20;G06V20/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈子良;              王可泽;              林倞;              彭湃;              郭晓威;                   余伟江       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>神经网络训练方法、装置、计算机设备及可读介质</td>   <td>广东省</td>   <td>CN109583583B</td>   <td>2023-04-07</td>   <td>本发明公开了一种神经网络训练方法及装置,涉及机器学习领域,该方法包括：将第n图像数据库中的无标签图像数据输入第n神经网络,提取得到无标签图像数据的第n特征；将无标签图像数据输入第n+1神经网络提取得到无标签图像数据的第n+1特征；根据第n特征以及第n+1特征确定出符合预设要求的无标签图像数据,对符合预设要求的无标签图像数据标注伪标签；更新得到第n+1图像数据库；根据第n+1图像数据库对第n+1神经网络进行训练,得到第n+2神经网络。通过两个神经网络对无标签图像数据进行选择,并对选择得到的无标签图像数据标注伪标签,从而增加了对神经网络进行训练的有标签图像数据的数量,提高了神经网络的精确度。</td>   <td>1.一种神经网络的训练方法,其特征在于,所述方法包括：将第n图像数据库中的无标签图像数据输入第n神经网络,提取得到所述无标签图像数据的第n特征,其中n≥1,n用于指示所述神经网络的迭代次数；将所述无标签图像数据输入第n+1神经网络提取得到所述无标签图像数据的第n+1特征；根据所述第n特征以及所述第n+1特征确定出符合预设要求的所述无标签图像数据；根据所述第n图像数据库中的有标签图像数据的标签,对符合预设要求的所述无标签图像数据标注伪标签,所述有标签图像数据的标签用于指示图像数据中的物体类别；将所述第n图像数据库中被标注有所述伪标签的所述无标签图像数据更新为所述有标签图像数据,得到第n+1图像数据库；根据所述第n+1图像数据库对所述第n+1神经网络进行训练,得到第n+2神经网络。</td>   <td>G06V10/82;G06N3/0464;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林创伟;              赖韩江;              印鉴;                   高静       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种基于双层BiLSTM-CRF的工作履历信息抽取方法</td>   <td>广东省</td>   <td>CN109657039B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于双层BiLSTM-CRF的工作履历信息抽取方法,包括以下步骤：S1：工作履历信息预处理；S2：根据时间拆分工作履历信息为工作经历,对工作经历预处理；S3：利用双层BiLSTM-CRF模型对工作经历的信息实体进行抽取；S4：对S3中抽取的信息实体进一步处理；S5：整理信息。本发明使用双层BiLSTM-CRF模型,可以更好的抽取工作经历中的信息实体。更好解决因信息实体交叉,中文信息实体不规则等因素造成信息抽取困难问题。此外,将传统信息抽取任务分成多个子任务,增加了消歧模块和联想模块,高聚合,低耦合,可以并发进行,提高抽取性能,还可以充分利用上下文关系,丰富实体信息。可以更加好的完成信息抽取任务,得到更好的呈现效果。</td>   <td>1.一种基于双层BiLSTM-CRF的工作履历信息抽取方法,其特征在于,包括以下步骤：S1：工作履历信息预处理；S2：根据时间拆分工作履历信息为工作经历,对工作经历预处理；S3：利用双层BiLSTM-CRF模型对工作经历的信息实体进行抽取；S4：对S3中抽取的信息实体进一步处理；S5：整理信息；所述步骤S3中双层BiLSTM-CRF模型,具体为：包括第一BiLSTM-CRF模型与第二BiLSTM-CRF模型,所述第一BiLSTM-CRF模型用于获取组织部门信息,包括第一embedding层、第一BiLSTM神经网络和第一CRF层,其中所述embedding层使用预训练好的Word2Vec模型,所述Word2Vec模型能将句子中的每个字映射成为一300维的向量,将工作经历使用空格补全成为20个字符长度后使用Word2Vec模型将工作经历转化为一20*300的向量,作为第一BiLSTM神经网络的输入；所述第一BiLSTM神经网络包括第一正向LSTM层、第一反向LSTM层和第一线性变换层,所述第一正向LSTM层和第一反向LSTM层的输入为经所述第一embedding层得到的20*300的向量,分别输出另一20*300的向量,将两个输出经线性变换层组合得到一20*600的向量lstm-ouput,利用下述公式得到第一CRF层的状态特征函数：crf-inpute＝lstm-ouput*w+b式中,crf-inpute为第一CRF层的状态特征函数,w为一600*9的权重向量,b为一20*9的偏移向量b；所述第一CRF层利用所述状态特征函数给各种可能的序列打分,用于获取状态转移函数以及最优的序列,同时产生最大似然估计作为误差进行用于梯度下降优化模型,具体如下：给各种可能的序列打分的公式如下：                  式中,score(x,y)为打分函数,为状态特征函数,/&gt;为状态转移函数,由所述第一CRF层自动生成；利用Softmax得到归一化后的概率,可以得到各种情况的概率：                  其最大似然如下：                  第二BiLSTM-CRF模型包括第二embedding层、第三embedding层、第二BiLSTM神经网络、第二线性变换层和第二CRF层,其中：第二embedding层与第一embedding层一样,第三embedding层使用onehot编码对第一BiLSTM-CRF模型产生的序列进行处理,得到一20*9的向量；第二BiLSTM神经网络针对每一句子得到另一20*9的向量,将该向量和第三embedding层得到的20*9的向量合并得到一个20*18的向量,使用一18*9的权重向量w1和20*9的偏移权重向量b1进行线性变换,得到一20*9的状态特征向量作为第二CRF层的输入；第二CRF层利用所述状态特征向量给各种可能的序列打分,用于获取状态转移函数以及最优的序列,同时产生最大似然估计作为误差进行用于梯度下降优化模型。</td>   <td>G06F16/332;G06F40/295;G06Q10/105;G06N3/0442;G06N3/045;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王青;              赵惠;              陈添水;              陈日全;                   林倞       </td>   <td>中山大学</td>   <td>一种知识驱动参数传播模型及其少样本学习方法</td>   <td>广东省</td>   <td>CN109934261B</td>   <td>2023-04-07</td>   <td>本发明公开了一种知识驱动参数传播模型及其少样本学习方法,该模型包括：特征提取模块,用于在基础类别样本组成的数据集上对特征提取器进行训练,并利用训练好的特征提取器提取基础类别和只有少量样本的新类别的样本的特征；图神经网络模块,用于引入类别之间的关系作为先验知识,利用知识图表示类别之间的先验关系,并集成该知识图利用图神经网络通过图形式传播迭代更新分类器参数；分类预测模块,用于利用提取出的特征和更新后的分类器参数得到分类结果,本发明可提供提高少样本分类的精度及泛化能力。</td>   <td>1.一种知识驱动参数传播模型,包括：特征提取模块,用于在基础类别样本组成的数据集上对特征提取器进行训练,并利用训练好的特征提取器提取基础类别和只有少量样本的新类别的样本的特征；图神经网络模块,用于引入类别之间的关系作为先验知识,利用知识图表示类别之间的先验关系,并集成该知识图利用图神经网络通过图形式传播迭代更新分类器参数。分类预测模块,用于利用提取出的特征和更新后的分类器参数得到分类结果；所述图神经网络根据如下公式在类别先验关系的指导下迭代更新分类器参数W:                  其中,表示类别之间的先验关系的知识图,φ(·)为在基础类别样本组成的数据集上训练好的特征提取器,用于提取基础类别和新类别样本的特征,f(·)为参数传播和更新函数,在时间t,用上个时间t-1的参数W～(t-1)和图/&gt;作为输入来计算得到精修的参数W～t。</td>   <td>G06V10/774;G06V10/74;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              麦思杰;              邢宋隆;                   陈志鸿       </td>   <td>中山大学</td>   <td>基于度量学习和元学习的小样本和零样本图像分类方法</td>   <td>广东省</td>   <td>CN109961089B</td>   <td>2023-04-07</td>   <td>本发明涉及计算机视觉识别和迁移学习领域,提出一种基于度量学习和元学习的小样本和零样本图像分类方法,包括以下步骤：构建训练数据集和目标任务数据集；从训练数据集选取支撑集和测试集；将测试集和支撑集的样本分别输入特征提取网络得到特征向量；将测试集和支撑集的特征向量依次输入特征关注模块和距离度量模块中,计算测试集样本与支撑集样本的类别相似度,并利用损失函数对各个模块的参数进行更新；重复上述步骤至各个模块网络的参数收敛,完成各模块的训练；将从目标任务数据集中的待测图片和训练图片依次通过特征提取网络、特征关注模块和距离度量模块,输出与测试集类别相似度最高的类别标签,即为待测图片的分类结果。</td>   <td>1.基于度量学习和元学习的小样本和零样本图像分类方法,其特征在于,包括以下步骤：S1.收集生活场景图像,经过人工分类构建训练数据集和目标任务数据集；S2.从训练数据集中随机抽取不同类别的若干张训练图片或语义属性作为样本组成支撑集,从所选取的类别中抽取若干张不重复的训练图片作为样本组成测试集；其中,对于小样本图像分类,从训练数据集中随机选取N个类别,并从N个类别中对应的每一类别随机选取K张训练图片组成支撑集,从所选取的N个类别中随机抽取与支撑集不重合的T张训练图片组成测试集；对于零样本图像分类,从训练数据集中随机选取N个类别对应的语义属性作为训练样本组成支撑集,从所选取的N个类别中随机抽取T张训练图片组成测试集,其中N的数值应为目标任务数据集中所包含类别的数量,K的数值应为目标任务数据集的每一类的训练图片的数量,N、K、T为正整数；S3.将测试集样本输入特征提取网络f-θ,将支撑集样本输入特征提取网络g-θ中输出得到对应的特征向量f(x)和g(x)；S4.将测试集样本和支撑集样本对应的特征向量f(x)和g(x)分别输入特征关注模块中,输出对应的关注后的特征向量f′(x)和g′(x)；S5.将测试集样本和支撑集样本对应的关注后的特征向量f′(x)和g′(x)分别输入距离度量模块中,计算测试集样本与支撑集样本的类别相似度,并利用损失函数通过梯度反向传播算法更新各个模块的参数；S6.重复步骤S2～S5,直到各个模块或网络的参数收敛；S7.将目标任务数据集中的待测图片输入训练后的特征提取网络f-θ,将目标任务中的所有训练图片或语义属性输入训练后的特征提取网络g-θ,然后将输出的特征向量依次通过训练后的特征关注模块和距离度量模块,最终输出与待测图片类别相似度最高的类别标签,即为待测图片的识别分类结果。</td>   <td>G06V10/764;G06V20/70;G06V20/60;G06V10/774;G06V10/74;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   肖一土       </td>   <td>中山大学</td>   <td>一种基于深度学习的区块链智能合约漏洞检测方法及装置</td>   <td>广东省</td>   <td>CN109977682B</td>   <td>2023-04-07</td>   <td>本发明公开一种基于深度学习的区块链智能合约漏洞检测方法及装置,本装置用于实现本方法,本方法包括抽取智能合约样本规则对齐并标注漏洞,将行列代码输入循环神经网络模型得到包含漏洞发生判断集的语言词向量；将行列代码编译成等长的二进制代码后输入Wide网络模型训练输出包含漏洞预测集的字节码模型,将语言词向量和字节码模型输入深度神经网络迭代训练修正漏洞发生判断集和漏洞预测集中共享预设权重。本发明检测结果准确度更高,检测方法更灵活,时间成本与经济成本更低。</td>   <td>1.一种基于深度学习的区块链智能合约漏洞检测方法,其特征在于,包括如下步骤：S10抽取H个智能合约的源代码,将源代码规则对齐并对其用户自定义函数/变量依顺序标注漏洞t,共有n个漏洞,t为当前漏洞,1≤t≤n；S20将行列代码输入循环神经网络模型,输出深度神经网络可识别的语言词向量X,其中包括由n个漏洞的发生判断形成的漏洞发生判断集M＝{m-1,m-2,…,m-t,…,m-n},所述循环神经网络模型为BiLTSM网络模型,将行列代码输入Bilstm网络模型,输出深度神经网络可识别的语言词向量X,其中：Bilstm网络的ForWard层按漏洞顺序正向计算得到每个漏洞向前隐含层的输出h-t＝f(W-1X-t+W-2h-(t-1)),Bilstm网络的BackWard层按漏洞顺序反向计算得到每个漏洞向后隐含层的输出h-t′＝f(W-3X-t+W-5h-(t-1)),结合h-t和h-t′通过第t个漏洞的发生判断m-t＝g(W-4h-t+W-6h-t′)得到漏洞发生判断集M＝{m-1,m-2,…,m-t,…,m-n}；其中,h-t表示第t个漏洞正向计算结果,h-t′表示第t个漏洞反向计算结果；f为sigmod激活函数,g为relu激活函数；将行列代码编译成等长的二进制代码后,将其输入Wide网络模型训练,输出字节码模型,其中包括通过Wide网络的隐含层函数y-t＝g(W-i X-(Wide)+B-(Wide))得到wide网络的漏洞预测集Y＝{y-1,y-2,...,y-n},其中g为relu激活函数,X-(Wide)为输入字节码,W-1、W-2、W-3、W-4、W-5、W-6均为预设权重,W-i表示第i个预设权重,i＝1,2,3,4,5,6；B-(Wide)为预设偏置值；S30将语言词向量X和字节码模型输入深度神经网络的激活层训练以获取深度神经网络概率预测p-t,计算公式为：p-t＝f(W-(deep)[m-t]+W -(Wide)[y-t]+B-(Wide)),其中,W -(Wide)取与m相乘的权重参数,W-(deep)取与y相乘的权重参数；S40求预测值与其对应的漏洞标注的偏差以获取当前模型误差Loss,当前模型误差的公式为其中s为漏洞标注,无漏洞取0,有漏洞取1,/&gt;为单个合约的误差值,H为当前取样训练的全体合约数量,采用梯度下降公式：W＝W-α*loss*u迭代训练,以将预设权重修正为误差小于预定数值的W,其中α为用于控制训练速度和效果的训练因子,u为X、m-t或y-t,loss*u为梯度,梯度的方向指明了误差扩大的方向。</td>   <td>G06F21/57;G06N3/0442;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘泉;              谢怡;              林浩添;                   赵兰琴       </td>   <td>中山大学中山眼科中心</td>   <td>一种基于深度学习的角膜地形图判别方法及系统</td>   <td>广东省</td>   <td>CN110517219B</td>   <td>2023-04-07</td>   <td>本发明公开了一种基于深度学习的角膜地形图判别方法及系统,将现有技术中获取的角膜地形图进行预处理,得到角膜地形图判别模型可以处理的角膜地形特征数据,将角膜地形特征数据输入角膜地形图判别模型,通过角膜地形图判别模型得到角膜形态结果。通过角膜地形图判别模型对角膜地形图进行分析确定其形态结果,医生可以根据该角膜地形图判别模型输出的结果直接的确定角膜形态,并且预测准确率高。本发明提供的一种基于深度学习的角膜地形图判别方法及系统,利用训练好的卷积神经网络模型对角膜地形图进行形态判别,解决了现有技术中缺少对角膜地形图进行深度学习处理分析的角膜形态判别技术的问题。</td>   <td>1.一种基于深度学习的角膜地形图判别方法,其特征在于,包括：获取待判别角膜地形图数据；所述待判别角膜地形图数据包括Pentacam屈光四联图；所述Pentacam屈光四联图包括角膜前表面轴向曲率图、角膜前表面高度图、角膜后表面高度图以及角膜厚度图；删除角膜地形图数据中的无效数据,得到有效角膜地形图数据,合并有效角膜地形图数据,得到角膜地形特征数据；根据所述角膜地形图判别模型、所述角膜地形特征数据、热度、BAD-D扩张分析结果,结合预设的大数据特征及预设的专家经验知识,分析得到角膜地形图判别模型输出的角膜形态结果；所述角膜地形图判别模型的获得步骤包括：获取角膜判别样本数据集,所述角膜判别样本数据集包括训练集、验证集、测试集；将训练集和验证集输入卷积神经网络模型,计算模型输出值与角膜判别样本数据集中对应的目标值之间的误差和模型预测准确率；所述卷积神经网络模型为Resnet模型；根据残差更新模型权重,将训练集和验证集输入更新后的卷积神经网络模型,计算模型输出值与角膜判别样本数据集中对应的目标值之间的误差和模型预测准确率；将更新次数达到预定值的卷积神经网络模型作为角膜地形图判别模型。</td>   <td>G06T7/00;A61B3/107</td>  </tr> </table></body></html>