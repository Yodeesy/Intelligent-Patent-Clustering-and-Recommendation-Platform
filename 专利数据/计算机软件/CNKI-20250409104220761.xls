<html xmlns:o='urn:schemas-microsoft-com:office:office' xmlns:x='urn:schemas-microsoft-com:office:excel' xmlns='http://www.w3.org/TR/REC-html40'><head><style>table td,th{vnd.ms-excel.numberformat:@;text-align: center;} table th{color:red}</style><title></title><meta http-equiv='Content-Type' content="text/html; charset=utf-8"></head><body><table cellspacing='0' border='1'>     <tr>   <td style='vnd.ms-excel.numberformat:@'>SrcDatabase-来源库</td>   <td style='vnd.ms-excel.numberformat:@'>Author-作者</td>   <td style='vnd.ms-excel.numberformat:@'>Applicant-申请人</td>   <td style='vnd.ms-excel.numberformat:@'>Title-题名</td>   <td style='vnd.ms-excel.numberformat:@'>CountryName-国省名称</td>   <td style='vnd.ms-excel.numberformat:@'>PubNo-公开号</td>   <td style='vnd.ms-excel.numberformat:@'>PubTime-公开日期</td>   <td style='vnd.ms-excel.numberformat:@'>Summary-摘要</td>   <td style='vnd.ms-excel.numberformat:@'>Claims-主权项</td>   <td style='vnd.ms-excel.numberformat:@'>CLC-中图分类号</td>  </tr>  <tr>   <td>中国专利</td>   <td>         刘咏梅;                   杨宇灏       </td>   <td>中山大学</td>   <td>一种基于语义解析和SMT求解的阅读理解题求解方法</td>   <td>广东</td>   <td>CN108829666A</td>   <td>2018-11-16</td>   <td>本发明提出一种基于语义解析和SMT求解的阅读理解题求解方法。该方法首先对阅读理解题进行语义解析,继而生成与阅读理解题对应的一阶逻辑公式,再引入四个假设——唯一名称假设、封闭世界假设、封闭原因假设和唯一答案假设来生成额外的一阶逻辑公式。这两部分一阶逻辑公式构成了表达阅读理解题所包含信息的知识库。再根据阅读理解题中的问句来生成候选答案对应的一阶逻辑公式。最后,该方法使用SMT求解器来验证知识库是否蕴涵候选答案对应的一阶逻辑公式,继而求出答案。相比已有的使用神经网络模型和词向量来表达文本的方式,本发明能更好地建立起阅读理解题中所描述的事件之间的关系,从而赋予了阅读理解系统更强的表达能力和推理能力。</td>   <td>1.一种基于语义解析和SMT求解的阅读理解题求解方法,其特征在于,所述方法先使用语义解析工具对阅读理解题进行语义解析,然后根据语义解析结果生成表示阅读理解题文本信息的一阶逻辑公式φ；再生成候选答案所对应的一阶逻辑公式<img file="FDA0001672050820000011.TIF" wi="67" he="48"/>最后,该方法对<img file="FDA0001672050820000012.TIF" wi="35" he="48"/>取非并与φ进行合取而得到公式<img file="FDA0001672050820000013.TIF" wi="179" he="56"/>并调用SMT求解器去求解<img file="FDA0001672050820000014.TIF" wi="155" he="55"/>的可满足性；若<img file="FDA0001672050820000015.TIF" wi="157" he="64"/>是不可满足的,那么<img file="FDA0001672050820000016.TIF" wi="47" he="47"/>所对应的候选答案就是该方法所求解出来的阅读理解题的答案。该方法包括以下步骤：S1.输入阅读理解题文本,使用SEMPRE语义解析工具对阅读理解题文本进行解析,获取阅读理解题文本中单词的词元、词性以及词与词之间的依赖关系；S2.对单词的词元和词性执行判断来获得谓词符号以及常元；S3.根据谓词符号及其相关参数来构造原子公式；S4.根据文本中的句子之间的连接关系来构造复杂公式；S5.在复杂公式中添加量词以获得完整的一阶逻辑公式<img file="FDA0001672050820000017.TIF" wi="63" he="49"/>S6.引入四个假设来生成额外的一阶逻辑公式<img file="FDA0001672050820000018.TIF" wi="425" he="63"/>S7.对<img file="FDA0001672050820000019.TIF" wi="493" he="56"/>进行合取来得到新的公式φ；S8.对阅读理解题中的问句进行语义解析并求解出答案。</td>   <td>G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         成慧;              申静怡;                   周佺       </td>   <td>中山大学</td>   <td>一种基于深度学习的智能物流仓库引导线视觉检测方法</td>   <td>广东</td>   <td>CN108830171A</td>   <td>2018-11-16</td>   <td>本发明涉及检测方法的技术领域,更具体地,涉及一种基于深度学习的智能物流仓库引导线视觉检测方法。一种基于深度学习的智能物流仓库引导线视觉检测方法,包括训练阶段和测试阶段,所述的训练阶段包括：训练数据获取与标记、构建模型、模型训练、模型验证与对比、模型选取、模型转换；所述的测试阶段包括：输入数据、引导线检测、检测结果拟合。本发明提出的方法灵活性较高,而且可以根据不同的性能要求,修改用于检测的神经网络的卷积核大小以及深度,满足不同的精度要求和运行时间要求。</td>   <td>1.一种基于深度学习的智能物流仓库引导线视觉检测方法,其特征在于,包括训练阶段和测试阶段,所述的训练阶段包括：训练数据获取与标记、构建模型、模型训练、模型验证与对比、模型选取、模型转换；所述的测试阶段包括：输入数据、引导线检测、检测结果拟合。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08;G06Q10/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王为;                   王俊       </td>   <td>中山大学</td>   <td>PMT信息综合管理系统</td>   <td>广东</td>   <td>CN108830544A</td>   <td>2018-11-16</td>   <td>本发明公开了一种PMT信息综合管理系统,包括管理员模块、厂家模块、仓储人员模块、批量测试记录员模块、抽样测试记录员模块、封装记录员模块和普通访客模块。本发明使得管理PMT信息更加高效、准确,不仅可以减少人力投入,降低管理经济成本,还可以提高管理效率,方便信息的检索、整合、传递和分享。数据存放数据库,具有高度的保密性、安全性和保真性,运行成本低。</td>   <td>1.一种PMT信息综合管理系统,其特征在于：该系统包括有：管理员模块、厂家模块、仓储人员模块、批量测试记录员模块、抽样测试记录员模块、封装记录员模块和普通访客模块。</td>   <td>G06Q10/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐晓颖;              李晓舒;                   杨慧琳       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于LDDMM的高维空间多条非交叉曲线的匹配方法及装置</td>   <td>广东</td>   <td>CN108830887A</td>   <td>2018-11-16</td>   <td>本发明公开了基于LDDMM对高维空间多条非交叉曲线进行匹配的方法,方法包括以下步骤：获取各条曲线并进行离散化表示,形成由几何位置和切向量信息所表示的各条非交叉曲线；采用LDDMM算法对由非交叉曲线组成的整体流形进行自动循环匹配,直至所有非交叉曲线匹配完成。本发明可对高维空间内多条非交叉曲线同时进行精准匹配,可以更大程度了解或还原物体特征,可应用到人脸识别、目标跟踪等领域。</td>   <td>1.基于LDDMM的高维空间多条非交叉曲线的匹配方法,其特征在于,包括以下步骤：S1、获取各条曲线并进行离散化表示,形成由几何位置和切向量信息所表示的各条非交叉曲线；S2、采用LDDMM算法对由非交叉曲线组成的整体流形进行自动循环匹配,直至所有非交叉曲线匹配完成。</td>   <td>G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         路永和;              周月鹏;              罗嘉仪;              翟媛媛;                   郑雅文       </td>   <td>中山大学</td>   <td>一种科技论文文本建模方法</td>   <td>广东</td>   <td>CN108804422A</td>   <td>2018-11-13</td>   <td>传统的TF#IDF权重计算方法对特征词的词性、所处文章位置、词在类间分布等特点考虑不足。本发明认为在考虑特征词的不同特点如词性、位置等时候,应当使用不同加权方法对TF#IDF进行改进。因此首先对科技论文的不同结构进行分类,区分出随着文本长度增加而同比例增加的结构,如摘要、前言、正文、结语等结构和随着文本长度增加而长度不变的结构,如标题、关键字、段落标题等结构。然后对前者使用乘法进行加权,对后者使用加法进行加权,最终得到基于科技论文结构的改进TF#IDF权重计算公式。在传统TF#IDF权重计算过程中合理使用位置影响参数来进行两类结构不同方式的加权,解决了传统方法中未考虑特征词的位置信息这一缺点。</td>   <td>1.一种科技论文文本建模方法,其特征在于：包括以下步骤：阶段一、预处理：Step1.导入科技论文集,经过格式转换、结构识别和数据清洗构成未分词数据库；Step2.抽取关键词集,结合结巴分词系统进行文本分词,然后去停用词,利用词性过滤以后,完成科技论文数据库的构建；Step3.通过word2vec计算特征词的词向量,利用k#means聚类算法进行词聚类,然后基于word2vec的特征构造方法构造主题特征；阶段二、优化位置参数Step4.初始化6个位置影响参数的最优数值,其中标题、关键字、段落标题、摘要、前言、结语的参数取值范围为[0,1],设置和声搜索算法的记忆思考概率HMCR,音调调整概率PAR、步长bw、迭代次数；Step5.从解空间中随机产生HMS个和声和对应的优化目标函数值放入HM；Step6.HS通过记忆思考、音调调整、随机选取的机理在每次迭代中产生一个新解；Step7.判断新解是否优于HM内的最差解,若是,则将新的解替换最差解,得到新的HM；Step8.重复Step6到Step8,直到达到最大的迭代次数或满足停止准则后结束循环,输出最优解；Step9.利用k#means算法对产生的最优解进行聚类,利用CH指标和轮廓系数对聚类效果进行评判；Step10.完成一次聚类分析,等待下一个科技论文集的到达,转步骤Step1。</td>   <td>G06F17/27;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         路永和;                   张炜婷       </td>   <td>中山大学</td>   <td>一种基于word2vec的短文本表示方法</td>   <td>广东</td>   <td>CN108804595A</td>   <td>2018-11-13</td>   <td>本发明涉及一种基于word2vec的短文本表示方法,包括以下步骤：S1：输入经过文本预处理的训练文本集,设置word2vec方法参数,训练得到训练文本集对应的词向量集合；S2：对于每篇文档中的每个词通过词向量之间的余弦距离计算得到该词在整个训练文本集中的一系列相近词；S3：计算每篇文档中的相近词与文档的余弦距离；S4：按照余弦距离从大到小排序,最终选取前n个相近词以及对应的余弦距离形成文档的n个相近词和余弦度量；S5：计算文档中的词和选取的n个相近词在该文档中的权重,形成新的文本表示,输出每一个文档基于word2vec改进后的向量空间表示。</td>   <td>1.一种基于word2vec的短文本表示方法,其特征在于：包括以下步骤：S1：输入经过文本预处理的训练文本集,设置word2vec方法参数,训练得到训练文本集对应的词向量集合；S2：对于每篇文档中的每个词通过词向量之间的余弦距离计算得到该词在整个训练文本集中的一系列相近词；S3：计算每篇文档中的相近词与文档的余弦距离；S4：按照余弦距离从大到小排序,最终选取前n个相近词以及对应的余弦距离形成文档的n个相近词和余弦度量；S5：计算文档中的词和选取的n个相近词在该文档中的权重,形成新的文本表示,输出每一个文档基于word2vec改进后的向量空间表示。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;                   梁惠欣       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的伪装语音识别方法</td>   <td>广东</td>   <td>CN108806698A</td>   <td>2018-11-13</td>   <td>本发明公开了一种基于卷积神经网络的伪装语音识别方法,包括以下步骤：对伪装语音和原始语音进行预处理操作；用训练数据对原始卷积神经网络进行训练,训练出一个模型；用测试数据对模型进行检测,同时确定分类的准确率。本发明的识别方法的准确率较传统方法有1个多百分点的提升,并且设计简单。</td>   <td>1.一种基于卷积神经网络的伪装语音识别方法,其特征在于,包括以下步骤：S1：选定语音库并对语音库进行平均律变调,包括原始语音和伪装语音,并将语音库中的数据划分为训练数据和测试数据；S2：对训练数据和测试数据进行切割,同时对切割后的音频片段进行预加重；S3：利用短时傅里叶变换(STFT)对预加重后的音频进行预处理,把一维数据变换为二维矩阵的形式；S4：将训练数据输入到卷积神经网络中进行训练,得到训练好的卷积神经网络模型；S5：将经过预处理后的测试数据输入到训练好的卷积神经网络中进行二分类,得到分类的准确率。</td>   <td>G10L17/18;G10L17/02;G10L17/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         劳斌;              解静仪;              徐文涛;                   农革       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>常数工作空间并行构造后缀数组的方法及系统</td>   <td>广东</td>   <td>CN108763170A</td>   <td>2018-11-06</td>   <td>本发明公开了常数工作空间并行构造后缀数组的方法及系统,通过获取字符串X中所有LMS子串的首字符指针并记录在数组P1中,以进一步利用P1和SA来对字符串X中所有的LMS子串进行常数工作空间内的并行归纳排序,得到字符串X1,并依据X1中字符的唯一性来区别SA的不同构造输入参数,最终通过X1与其后缀数组SA1的对应关系得以在常数工作空间内并行归纳计算字符串X的后缀数组到SA中。本发明降低了计算机内存要求且运行速度更快,使时空复杂度达到最优,适用于大规模字符串的后缀数组构建。</td>   <td>1.常数工作空间并行构造后缀数组的方法,其特征在于,包括以下步骤：S1、从右向左扫描一遍输入的字符串X,按照后缀类型的定义比较当前扫描的两个相邻字符X[i]和X[i+1],从而得到每一个字符和后缀的类型；在扫描过程中,按照LMS子串的S+L+S类型模式定义找出所有LMS字符出现的位置,从而获取字符串X中所有LMS子串的首字符指针,并记录在数组P1中；S2、通过数组P1和SA来对字符串X中所有的LMS子串进行常数工作空间内的并行归纳排序,并将排序结果保存在SA1中；其中,SA为用于记录字符串X的后缀数组；SA1为用于记录排序结果的后缀数组；S3、根据排序结果在常数工作空间内并行重命名字符串X中所有的LMS子串,从而形成字符串X1；S4、检查字符串X1中的每个字符是否唯一,若是则直接排序字符串X1的各后缀来计算字符串X1的后缀数组,保存至SA1中,否则以字符串X1和SA1作为新输入参数替代字符串X和SA,分别递归调用至步骤S1和S2；S5、根据获得的保存在SA1中的字符串X1的后缀数组,在常数工作空间内并行归纳计算字符串X的后缀数组,保存至SA中。</td>   <td>G06F17/22;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王珩;              毛明志;                   潘嵘       </td>   <td>中山大学</td>   <td>基于规则和远程监督的百度百科关系三元组抽取方法</td>   <td>广东</td>   <td>CN108763353A</td>   <td>2018-11-06</td>   <td>本发明提供一种基于规则和远程监督的百度百科关系三元组抽取方法,该方法对信息框这种信息集中的结构化文本,本发明主要采用基于规则、正则表达式的方法抽取关系三元组,这些三元组后续又可以作为远程监督算法的输入。对正文这种信息零散的非结构化文本,本发明一方面通过撰写简单的、准确的、显而易见的规则,抽取小部分关系三元组,另一方面,将前面所有基于规则得到的三元组作为远程监督算法的输入,将所有正文文本中包含头实体和尾实体的句子标记出来,按关系分类,训练分类器,再将分类器应用到正文文本的其他句子上,藉此发现更多的三元组。</td>   <td>1.一种基于规则和远程监督的百度百科关系三元组抽取方法,其特征在于,包括以下步骤：S1：从信息框中抽取关系三元组：将HTML源码中属于信息框的部分取出；信息框的每一行,第一个属性作为关系,第二个属性作为尾实体,词条名则是头实体；将出现次数累计不少于阈值N的关系,作为有意义的关系继续考察,并以此为基础,筛选出连接的头尾实体主要是名词、命名实体的关系；随后,将尾实体完全被书名号括起来的三元组全数保留；将带有并列关系的尾实体拆开,简化为多个具有相同头实体和关系的三元组；凡是材料、配料、用料相关的关系三元组,只要实体,不要数字；尾实体不是都由名词或者命名实体组成的,也不予保留；S2：应用简单的规则从正文中抽取关系三元组：使用正则表达式,将语法简单且蕴含关系三元组的句子标记出来,直接抽取关系；S3：以S1、S2两步得到的关系三元组为基础,运用远程监督算法,训练关系分类器,学习不同关系在开放域文本表达的不同特征,随后将该分类器运用到百度百科正文的所有句子上,抽取所要的关系。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李洽;                   唐建雄       </td>   <td>中山大学</td>   <td>一种基于l&lt;sub&gt;0&lt;/sub&gt;-合页损失函数的鲁棒分类方法</td>   <td>广东</td>   <td>CN108764274A</td>   <td>2018-11-06</td>   <td>本发明提出了一种基于l<sub>0</sub>#合页损失函数的鲁棒分类方法,所述方法利用罚函数与分块坐标下降法解出分类超平面,对测试样本进行预测判决,所述方法包括鲁棒分类器l<sub>0</sub>#SVM模型,所用的l<sub>0</sub>#合页损失函数具有分段常数性质,误分类样本的离散性不会被平滑,并且误分类样本离边界的远近不影响l<sub>0</sub>#合页损失函数的大小变化,基于l<sub>0</sub>#合页损失函数设计的分类器l<sub>0</sub>#SVM对被标签噪声具有鲁棒性。在训练样本包含标签噪声的情况下,仍能够训练出分类性能较好的分类超平面。</td>   <td>1.一种基于l0#合页损失函数的鲁棒分类方法,其特征在于,所述方法利用罚函数与分块坐标下降法解出分类超平面,对测试样本进行预测判决,具体包括以下步骤：S1.获取训练集数据<img file="FDA0001621041550000011.TIF" wi="243" he="74"/>S2.计算关于训练样本的核矩阵K,令n维对角方阵Y的主对角元为训练标签；S3.初始化参数向量u、v,罚函数惩罚因子β；S4.在鲁棒分类器l0#SVM模型中,通过分块坐标下降法交替迭代求解u和v,使目标函数的误差最小化；S5.当鲁棒分类器l<sub>0</sub>#SVM模型的目标函数的相对误差小于设定阈值,令分类超平面参数w的组合系数<img file="FDA0001621041550000012.TIF" wi="233" he="55"/>偏置b＝u<sub>n+1</sub>,跳转至S6；否则,增大惩罚因子β,跳到S4；S6.输出α,b；S7.对测试样本进行准确度预测。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李浚时;              李文军;                   陈龙       </td>   <td>中山大学</td>   <td>一种基于颜色特征和词袋特征的票据图像分类方法</td>   <td>广东</td>   <td>CN108764302A</td>   <td>2018-11-06</td>   <td>本发明涉及图像的技术领域,更具体地,涉及一种基于颜色特征和词袋特征的票据图像分类方法。本发明利用了计算机视觉中经典的Bag#of#Words的思路,即先对训练样本中提取每张票据的SIFT特征点并生成128维特征描述符,然后进行K均值聚类获得K个视觉单词,并对每一类票据统计其视觉单词出现次数形成该类的视觉单词直方图作为特征,最后融入颜色特征形成总的特征向量,送入SVM分类器进行训练,得到票据分类器模型。因为词袋模型并没有用到票据图像的颜色特征,故本方法加入了图像的全局主颜色特征,进一步提升票据分类器的性能。本发明仅需极少量训练样本且无需人工设计额外特征就能训练出票据分类器模型,而且分类器分类速度快,准确率高。</td>   <td>1.一种基于颜色特征和词袋特征的票据图像分类方法,其特征在于,包括线下票据分类器训练和线上票据快速分类两大部分,线下票据分类器训练部分分为颜色特征提取和词袋模型训练两大部分：颜色特征模块首先对训练集中的图片转化为HSV色彩空间,并对H分量进行量化生成颜色直方图,记录每类票据的主颜色并保存下来存入硬盘保存；词袋模型训练根据对训练集的票据进行SIFT特征提取并进行K均值聚类得到K个聚类中心,并进行特征量化生成词袋,并对每一类的票据训练样本进行视觉单词频数进行统计,生成该类的视觉单词直方图,并以此直方图生成相应的特征向量,以此为特征SVM分类器的输入进行训练,最后将训练好的模型参数文件存入硬盘保存；线上票据快速分类部分首先需要载入已经训练好的票据分类器模型和颜色分类参数文件,首先对图像转换到HSV颜色空间,生成其颜色直方图并提取主颜色特征,用该特征判定该票据的主颜色在已有票据类别存在且唯一,若是则直接输出分类结果,若不是则进入词袋模型分类过程；词袋模型分类过程首先需要提取图像的SIFT特征并生成视觉单词,并将此特征向量送入SVM进行分类,得到分类结果,然后需要对此分类结果根据颜色特征做二次判断,即根据该分类结果查询该结果对应的主颜色特征是否与先前得到的主颜色特征相同,若是则输出分类结果,若不同则表示分类结果错误,分类失败。</td>   <td>G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王为;              王俊;                   赵荣       </td>   <td>中山大学</td>   <td>线上和线下相结合的PMT设备数据库系统</td>   <td>广东</td>   <td>CN108764647A</td>   <td>2018-11-06</td>   <td>本发明公开了一种线上和线下相结合的PMT设备数据库系统,其是由线下数据录入平台和线上数据查阅平台组成。所述的线下数据录入平台连接有仓管模块、供应商模块、表观检测模块、批次测试模块、扫描测试模块、PMT封装模块、安装模块、线下平台管理模块；所述的线上数据查阅平台连接有线上平台管理模块、访客模块。通过本发明,PMT设备数据的检索、分析和管理更加高效、便捷。数据存在数据库中,具有极好的保密性、安全性和无损性。数据通过线下数据录入平台录入、线上数据查阅平台查阅,可以有效防止数据被远程非法修改。</td>   <td>1.一种线上和线下相结合的PMT设备数据库系统,其特征在于：线上和线下相结合的PMT设备数据库系统是由线下数据录入平台和线上数据查阅平台组成。所述的线下数据录入平台连接有仓管模块、供应商模块、表观检测模块、批次测试模块、扫描测试模块、PMT封装模块、安装模块、线下平台管理模块；所述的线上数据查阅平台连接有线上平台管理模块、访客模块。</td>   <td>G06Q10/06;G06Q10/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗丽萍;              衣杨;              周晓聪;              张念旭;              周翼丰;                   郑镇贤       </td>   <td>中山大学</td>   <td>教学质量评价方法及装置</td>   <td>广东</td>   <td>CN108764710A</td>   <td>2018-11-06</td>   <td>本发明涉及教育信息化技术领域,提供一种教学质量评价方法及装置,所述方法包括：获取待评价教师的初始得分数据、以及与待评价教师对应的学生评分数据及多个评教变量数据；对多个评教变量数据进行教学特征提取,得到多个评教变量数据的综合评教指标；依据学生评分数据、待评价教师的初始得分数据和综合评教指标,求解出综合评教指标对待评价教师的最终得分的影响权重；依据影响权重和所述学生评分数据,计算出待评价教师的最终得分数据。本发明通过对教学过程中诸多影响教学质量的因素进行数据挖掘分析,得到不同因素对教学质量的影响权重,从而指导教师在教学过程中进行及时、有效地调整教学行为,提高教学质量。</td>   <td>1.一种教学质量评价方法,其特征在于,所述方法包括：获取待评价教师的初始得分数据、以及与所述待评价教师对应的学生评分数据及多个评教变量数据；对所述多个评教变量数据进行教学特征提取,得到所述多个评教变量数据的综合评教指标；依据所述学生评分数据、待评价教师的初始得分数据和综合评教指标,求解出所述综合评教指标对所述待评价教师的最终得分的影响权重；依据所述影响权重和所述学生评分数据,计算出所述待评价教师的最终得分数据。</td>   <td>G06Q10/06;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾青青;              赵泽慧;              张俊;              李昀;              刘金秀;              邓楚玲;                   钟铭邦       </td>   <td>中山大学新华学院;广州菁泽信息技术有限公司</td>   <td>一种基于移动互联网的随堂教学评价服务系统</td>   <td>广东</td>   <td>CN108764759A</td>   <td>2018-11-06</td>   <td>本发明公开了一种基于移动互联网的随堂教学评价服务系统,包括：基本信息设置模块,管理存储教师基本信息、学生基本信息和所有教授课程数据；数据关联管理模块,建立教师基本信息与其课程数据、学生基本信息与其课程数据的关联,并设定课程的评价量表指标；教学评价管理模块,设置需要生成二维码的课程的范围,根据基本信息设置模块和数据关联管理模块的数据,批量生成设置范围内课程的二维码,并发学生；教学评价分析模块,接收所有学生通过扫描二维码完成的教学评价,并按课程分类整理,分别对每门课程的教学评价进行综合分析得到教学问题和教学改进建议。本发明实现对二维码的批量生成和集中管理,简化支持移动端的教学评价过程,减少工作量。</td>   <td>1.一种基于移动互联网的随堂教学评价服务系统,其特征在于,包括：基本信息设置模块,管理存储教师基本信息、学生基本信息和所有教授课程数据；数据关联管理模块,建立所述基本信息设置模块中每个教师基本信息与其所教授课程数据的数据关联、学生基本信息与其所上课程数据的数据关联,并设定每门课程的评价量表指标,供评价；教学评价管理模块,设置需要生成二维码课程的范围,根据所述基本信息设置模块和数据关联管理模块中的数据,批量生成设置范围内所有课程的二维码,并发送给对应学生；教学评价分析模块,接收所有学生通过扫描二维码完成的教学评价,并按课程分类整理,分别对每门课程的教学评价进行综合分析,得到存在的教学问题和教学改进建议。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张念旭;              周晓聪;              衣杨;              罗丽萍;              周翼丰;                   谢韬       </td>   <td>中山大学</td>   <td>课程类别与出勤率分析及装置</td>   <td>广东</td>   <td>CN108765224A</td>   <td>2018-11-06</td>   <td>本发明实施例涉及教学管理技术领域,提供一种课程类别与出勤率分析方法及装置,所述方法包括：获得每个课程类别对应的学生出勤统计数据；依据学生出勤统计数据,计算出组内离差平方和及组间离差平方和；依据组内离差平方和组间离差平方和,计算出第一出勤率偏差和第二出勤率偏差；若第一出勤率偏差小于或等于第二出勤率偏差,则依据第二出勤率偏差与第一出勤率偏差的比值得到出勤影响率；若出勤影响率大于预设显著水平下F分布表对应的值,则确定课程类别对学生出勤率有影响。本发明实施例可以准确分析出课程类别是否对出勤率产生影响,从而指导学校教学管理系统根据分析结果合理修改不同课程类别的课程要求来提高教学质量。</td>   <td>1.一种课程类别与出勤率分析方法,其特征在于,所述方法包括：获得每个课程类别对应的学生出勤统计数据；依据所述学生出勤统计数据,计算出表征同一课程类别中个体误差的组内离差平方和、以及不同课程类别之间差异程度的组间离差平方和；依据所述组内离差平方和所述组间离差平方和,计算出第一出勤率偏差和第二出勤率偏差；若所述第一出勤率偏差小于或等于所述第二出勤率偏差,则依据第二出勤率偏差与所述第一出勤率偏差的比值得到出勤影响率；若所述出勤影响率大于预设显著水平下F分布表对应的值,则确定课程类别对学生出勤率有影响。</td>   <td>G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              谢志勇;              陈荣军;              谢舜道;              林远鑫;              朱雄泳;                   曾衍瀚       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种离焦QR码图像盲复原方法</td>   <td>广东</td>   <td>CN108765305A</td>   <td>2018-11-06</td>   <td>本发明公开了一种离焦QR码图像盲复原方法,先对QR码图像进行灰度化处理以及边缘检测处理后得到边缘图像,然后对边缘图像进行处理得到边缘直线以及导数值变化率最大的点,根据边缘直线和导数值变化率最大的点可以计算得到离焦半径,进而可以得到点扩散函数,最后根据点扩散函数对模糊的QR码图像进行复原,在尽可能恢复图像质量的同时,减少计算量,并且减少复原的时间。</td>   <td>1.一种离焦QR码图像盲复原方法,其特征在于：包括以下步骤：A、对输入的QR码图像进行灰度化处理；B、对灰度化处理后的QR码图像进行截取,得到边缘图像；C、对边缘图像进行边缘检测,得到边缘矩阵；D、对边缘矩阵进行逐列扫描,获取边缘直线的位置；E、对边缘图像进行求导,并通过计算得到导数值变化率最大的点；F、计算边缘直线和导数值变化率最大的点之间的距离,得到估计的离焦半径；G、根据离焦半径计算得到点扩散函数,根据点扩散函数对散焦模糊的QR码图像进行复原。</td>   <td>G06T5/00;G06T7/13;G06K19/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   曹渝       </td>   <td>中山大学</td>   <td>一种基于高斯分布的词向量生成方法</td>   <td>广东</td>   <td>CN108733647A</td>   <td>2018-11-02</td>   <td>本发明公开了一种基于高斯分布的词向量生成方法,首先对语料库进行预处理；其次使用标点符号对语料库划分上下文；然后结合局部和全局信息推断词义,确定词与词义的映射关系；最后通过优化目标函数获得词向量。本发明技术方案的创新点和有益效果在于：1、基于高斯分布来表示词,避免传统词向量的点估计特性,能为词向量带来概率质量,词义蕴含、包含关系等更为丰富的信息。2、使用多个高斯分布来表示词,能够应对自然语言中一词多义的语言特性。3、基于Hellinger距离定义高斯分布之间的相似性,将参数更新和词义判别结合起来,能够自适应地推断词义的数量,解决了现有技术模型的假定词义数量固定的问题。</td>   <td>1.一种基于高斯分布的词向量生成方法,其特征在于：首先对语料库进行预处理；其次利用标点符号将语料库划分为上下文；然后结合局部和全局信息推断词义,确定词与词义的映射关系；最后通过优化目标函数获得词向量。</td>   <td>G06F17/27;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐晓颖;              钟志权;                   袁进       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学;中山大学中山眼科中心</td>   <td>一种基于深度学习的左右眼识别算法</td>   <td>广东</td>   <td>CN108734102A</td>   <td>2018-11-02</td>   <td>本发明公开了一种基于深度学习的左右眼识别算法,图像预处理和数据扩充,Alexnet与Resnet对左右眼识别效果的比较分析,基于Alexnet网络的优化,分类器Softmax回归与支持向量机SVM的比较。通过卷积神经网络对图像特征的自动提取功能,实现对左右眼的判断,识别速率快、准确率高,克服了人工判断费时费力的弊端,以及不用使用光学仪器,成本低,容易普及。</td>   <td>1.一种基于深度学习的左右眼识别算法,其特征在于,包括以下步骤：S1：图像预处理和数据扩充,S11：图像的裁剪：获取的眼科图像往往四周带有许多黑色的无效区域,为了消除黑色无效区域对图像识别的干扰并减少数据量,需要对图像中的有效区域进行提取,由于有效区域与黑色无效区域具有明显的边界,且黑色所对应的像素值为0,所以不需要人工标记有效区域的四个边缘点A、B、C、D,可以直接通过算法来自动提取,获取的眼科彩图的各个通道的像素值大小范围通常均为[0,255],设置像素值阈值为20,通过逐行或逐列遍历图像通道的像素,获取的第一个与最后一个像素值大于阈值的点即为对应的边缘点,具体的算法流程如下：A1：逐行遍历图中像素,获取的第一个像素值大于20的像素的纵坐标,即为A的纵坐标y1；A2：逐行遍历图中像素,获取的最后一个像素值大于20的像素的纵坐标,即为C的纵坐标y2；A3：逐列遍历图中像素,获取的第一个像素值大于20的像素的横坐标,即为B的横坐标x1；A4：逐列遍历图中像素,获取的最后一个像素值大于20的像素的横坐标,即为D的横坐标x2；有了A、B、C、D四个点的坐标x1,x2,y1,y2,我们可以直接得到裁剪后的有效图像；S12：对图片进行亮度和对比度的随机调整来扩充数据,调整图像的亮度和对比度来扩充训练数据集的数据量,使用下面这个公式来改变图像的亮度和对比度来扩充训练数据集,g(x)＝a*f(x)+b其中：f(x)表示原图像像素,g(x)表示输出图像像素,参数a被称为增益,常常被用来控制图像的对比度,我们设置a的取值范围为[0.5,1.5],每次对图像操作时从中随机取值,参数b被称为偏置,常常被用来控制图像的亮度,我们设置b的取值范围为[#50,50],每次对图像操作时从中随机取值,S13：对图片进行标准化,使用反向传播算法学习参数,同时,对图像进行标准化处理,其公式如下：<img file="FDA0001632775730000021.TIF" wi="352" he="183"/>其中：x为图片的RGB三通道像素值,mean为三通道像素各自的均值,σ为三通道像素各自的标准差,N为三通道各自的像素个数；S2：以Alexnet与Resnet经典网络模型为基础进行网络的设计并训练神经网络,经典的Alexnet网络包含五个卷积处理操作以及某些卷积处理操作后连接的最大池化层和三个全连接层,而所选取的Resnet网络有50层,num_blocks参数设置为[3,4,6,3]。在这两种网络结构的基础上进行修改,设计合适的左右眼识别模型,具体步骤如下：B1、训练数据集为8243张眼底彩照,包括左眼眼底照4166张、右眼眼底照4077张；B2、对输入的每一张图片都进行缩放,resize成512*512的大小；B3、设置学习率为0.001,每个batch的大小为32,正则化系数为0.001；B4、训练过程采用GPU的训练方式；B5、使用优化函数进行权值参数的优化；B6、激活函数；B7、使用5重交叉验证来判断何时终止训练；S3：分类器Softmax回归与支持向量机SVM的比较,确定分类器。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张燕;              柯戈扬;              潘炎;                   印鉴       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种基于张量奇异值分解的多视图谱聚类算法</td>   <td>广东</td>   <td>CN108734187A</td>   <td>2018-11-02</td>   <td>本发明提供一种基于张量奇异值分解的多视图谱聚类算法,该算法用三阶张量<img file="DDA0001275079370000011.TIF" wi="51" he="50"/>表示所有视图数据的概率转移矩阵。由于张量具有横向、纵向、竖向三个方向的低秩性,本发明采用基于张量奇异值分解(Tensor#SVD)的多重秩(multi#rank)来表征该张量在各个维度上的低秩性。因为Tensor#SVD分解基于tube卷积产生的,不仅能比其他张量分解方式和基于二维结构关系建模的方法更能充分表达在空间结构上的相关性,而且可通过傅里叶变换进行快速计算,提高计算效率。因此,基于Tensor#SVD张量分解进行建模,会更加科学、快速、高效,并且实验结果表明可有效地提高多视图聚类的效果。</td>   <td>1.一种基于张量奇异值分解的多视图谱聚类算法,其特征在于,包括以下步骤：S1：将每个视图通过高斯核表示得到各自的概率转移矩阵；S2：用一个张量<img file="FDA0001275079340000012.TIF" wi="48" he="43"/>表示所有视图的概率转移矩阵,每个张量的前片表示一个视图的概率转移矩阵,利用数据分布规律建模求解,得到一个概率转移矩阵L,其中<img file="FDA0001275079340000013.TIF" wi="243" he="48"/>其中n表示样本总数,m表示视图总数；S3：将概率转移矩阵L作为基于马尔可夫链的谱聚类算法的关键输入,计算得到谱聚类输出结果。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              程高升;              陈荣军;              谢舜道;              朱雄泳;              王灿昆;                   曾衍瀚       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>一种基于大数据关联度分析的溯源防伪方法</td>   <td>广东</td>   <td>CN108734475A</td>   <td>2018-11-02</td>   <td>本发明公开一种基于大数据关联度分析的溯源防伪方法,通过消费者使用溯源终端扫描一次商品上的溯源标签,同时获得溯源序列号和关联度数据项；查询溯源序列号和关联度数据项是否存在以及满足商品实际预设条件,从而确保查询数据是否有效；根据查询结果,将溯源序列号和关联度数据项集合进行大数据关联度分析；根据分析结果,对比本次查询的溯源序列号和关联度数据项是否满足关联度分析结果,从而确保商品信息的真伪,即达到商品信息溯源防伪的效果。</td>   <td>1.一种基于大数据关联度分析的溯源防伪方法,其特征在于,包括以下步骤：S1：获取溯源码,根据溯源码得到溯源序列号；S2：溯源终端应用获取商品流通或售卖时具有关联度的数据项；S3：溯源终端发送获取的溯源序列号以及相关联度的数据项到溯源系统平台；S4：溯源系统平台中溯源防伪功能接口接受溯源终端发送的溯源序列号和相关联度数据,进行匹配查询；S5：对溯源序列号和商品关联度数据项进行关联度分析;S6：溯源终端显示结果。</td>   <td>G06Q30/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              梁宁;                   刘镇       </td>   <td>中山大学</td>   <td>一种基于随机分形的多孔介质细观结构模型生成方法</td>   <td>广东</td>   <td>CN108734751A</td>   <td>2018-11-02</td>   <td>本发明提供一种基于随机分形的多孔介质细观结构模型生成方法,可模拟多孔介质内部细观结构的分布情况。通过编写程序语言模拟孔隙生成,实现孔隙模型的规范化处理,针对多孔介质中孔隙边界的复杂、不确定等形状,通过林顿伊尔系统仿真模式进行模拟,实行字符串序列的等价变换,将字符串序列转化为边界演变规则作为边界生成的依据。同时,基于分形几何的迭代方式,并结合随机分布概率模拟孔隙结构的生成,得出多样化复杂的多孔介质细观结构模型。本发明的仿真效果良好,可有效揭示多孔介质内部细观结构特性,在软件模型建立与三维重构方面可实现广泛应用。</td>   <td>1.一种基于随机分形的多孔介质细观结构模型生成方法,其特征在于,包括：(1)基于林顿伊尔系统仿真模式,生成字符串发展序列并自动存储,以字符串序列模式实现孔隙边界模型的随机控制,通过字符串的拓展与演变,系统识别字符串排列特征,并执行字符串的等价变换,建立起孔隙边界模型的构造规则,实现孔隙边界的复杂连续性处理,体现形态各异孔隙边界的组合方式,更好的模拟实际孔隙边界；(2)定义异形孔隙初始元模型,运用分形几何迭代方式对孔隙初始元进行有限次迭代,模拟孔隙演变过程,结合林顿伊尔系统仿真模式并加入随机因子决定初始元迭代方向,实现孔隙生成过程的多样化、吻合度高与随机性强的无规则模拟以及孔隙模型复杂变化的动态生长方式；(3)对绘图区进行全局域遍历,建立非生长相内部坐标矩阵,同时给出区域内部随机概率分布元素,形成坐标矩阵、随机概率相统一的组装矩阵,控制孔隙初始元的大小与迭代步数,实现孔隙大小的随机分布,孔隙结构模型进一步优化处理；(4)以指定色块进行孔隙结构对非生长相的实时嵌入,并跟踪该色块对全区域所占的比例,通过该比例反演孔隙率的实时大小,通过与目标孔隙率的比较,判定孔隙生成条件,自动控制循环迭代过程。以达到循环迭代条件而终止整个模型生成,得出多孔介质细观结构模型二值图像,有效表征实际多孔介质内部结构特征。</td>   <td>G06T11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何兆成;                   杨昀霖       </td>   <td>中山大学</td>   <td>基于冲突区侵占度的交叉口内部冲突消解仿真模拟方法</td>   <td>广东</td>   <td>CN108710719A</td>   <td>2018-10-26</td>   <td>本发明涉及一种基于冲突区侵占度的交叉口内部冲突消解仿真模拟方法,包括以下步骤：S1.识别冲突区；S2.对车辆的运动参数进行估计；S3.计算冲突双方车辆分别到达冲突区的时间；S4.判断最先到达冲突区的车辆到达冲突区的时间是否少于决策时间,若是则进入决策时刻,执行步骤S5；否则车辆继续行驶,然后执行步骤S3；S5.计算最先到达冲突区的车辆到达冲突区的时间和离开冲突区的时间以及另一车辆到达冲突区的时间,从而判断是否存在冲突,若是则执行步骤S6,否则车辆继续行驶；S6.分别计算最先到达冲突区的车辆的侵占度；S7.基于冲突区侵占度的车辆占先决策行为的概率模型分别计算最先到达冲突区的车辆的占先概率；S8.判断最先到达冲突区的车辆的占先概率是否大于所设定的阈值,若是则车辆占先行驶,否则则车辆避让。</td>   <td>1.基于冲突区侵占度的交叉口内部冲突消解仿真模拟方法,其特征在于：包括以下步骤：S1.识别冲突区；S2.对车辆的运动参数进行估计；S3.计算冲突双方车辆分别到达冲突区的时间；S4.判断最先到达冲突区的车辆到达冲突区的时间是否少于决策时间,若是则进入决策时刻,执行步骤S5；否则车辆继续行驶,然后执行步骤S3；S5.计算最先到达冲突区的车辆到达冲突区的时间和离开冲突区的时间以及另一车辆到达冲突区的时间,从而判断是否存在冲突,若是则执行步骤S6,否则车辆继续行驶；S6.计算最先到达冲突区的车辆的侵占度；S7.基于冲突区侵占度的车辆占先决策行为的概率模型计算最先到达冲突区的车辆的占先概率；S8.判断最先到达冲突区的车辆的占先概率是否大于所设定的阈值,若是则车辆占先行驶,否则则车辆避让。</td>   <td>G06F17/50;G06Q10/06;G06Q50/26;G08G1/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         桑远超;                   陈龙       </td>   <td>中山大学</td>   <td>一种基于深度学习计算机视觉的哨兵瞌睡智能监控系统</td>   <td>广东</td>   <td>CN108710839A</td>   <td>2018-10-26</td>   <td>本发明涉及哨兵执勤状态监控系统的技术领域,更具体地,涉及一种基于深度学习计算机视觉的哨兵瞌睡智能监控系统。一种基于深度学习计算机视觉的哨兵瞌睡智能监控系统,其中,包括数据采集单元、数据处理单元、数据分析单元和报警单元,四个单元依次相连。本发明使用卷积神经网络进行人脸检测和人脸对齐,通过使用丰富的训练数据进行模型训练,能达到实际可用的泛化性能,能鲁棒的识别出眼镜和嘴巴两个特征部位的状态,并且输出头部位置的姿势估计,准确率高。</td>   <td>1.一种基于深度学习计算机视觉的哨兵瞌睡智能监控系统,其特征在于,包括数据采集单元、数据处理单元、数据分析单元和报警单元,四个单元依次相连。</td>   <td>G06K9/00;G08B21/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡燕嫦;                   倪江群       </td>   <td>中山大学</td>   <td>一种基于特征融合的数字图像相机源模型分类方法</td>   <td>广东</td>   <td>CN108710893A</td>   <td>2018-10-26</td>   <td>本发明提供一种基于特征融合的数字图像相机源模型分类方法,该方法基于深度卷积神经网络CNN,设计了一种针对相机源模型的定制化神经网络结构,主要包括：采用图像隐写分析人工特征集中的30个基本滤波器初始化CNN网络第一层,以生成具有显著表征能力的残差特征图；在训练样本图像较少的情况下,通过将样本图像随机分块来扩充数据量,并训练CNN作为分块图像的特征表达；对待分类图像对应分块图像的CNN特征按位置、亮度、纹理复杂度进行特征融合,并以支持向量机进行分类判决。本发明基于深度卷积网络和多位置特征融合,通过对样本图像全局、位置、亮度和纹理信息的综合利用,有效提升了相机模型分类准确度。</td>   <td>1.一种基于特征融合的数字图像相机源模型分类方法,其特征在于：包括以下步骤：S1：对训练集和验证集中的大图进行随机分块,生成的小块标签与大图标签一致；S2：用训练集小块训练CNN作为分块图像的特征表达,选取在验证集上平均分类准确率最高的模型作为CNN特征提取器；S3：再次对训练集和验证集的大图进行切块,每个小块按照其亮度、纹理复杂度计算其可信度,形成可信度矩阵并且记住每个小块在大图中的位置；S4：将训练集和验证集中每张大图的小块输入到CNN特征提取器中得到分类图像对应分块图像的CNN特征,按照小块在大图中的位置以及小块的可信度进行特征融合,得到训练集和验证集融合后的特征；S5：用训练集和验证集融合后的特征训练SVM,即支持向量机作为分类器,判断分类器在验证集的平均分类准确度是否不再上升,如果分类器的准确率持续提高,则继续训练；如果分类器的准确度不再提高,则结束训练,得到分类器；S6：将目标图片通过CNN特征提取器提取特征,特征融合后导入分类器中,进行分类。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李宇;              李竺珊;              谭洪舟;                   农革       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种单麦克风的感知增益函数的语音增强方法</td>   <td>广东</td>   <td>CN108711432A</td>   <td>2018-10-26</td>   <td>本发明提供一种单麦克风的感知增益函数的语音增强方法,本发明在DFT域用判决引导方法估计先验信噪比；其次,利用基于广义Gamma模型与感知的加权欧式失真测度的增益函数来增强语音；最后,对语音的频谱分量进行DFT的逆变换,则获得增强语音的时域形式,通过该方法,可有效实现从带噪语音中恢复纯净语音信号。</td>   <td>1.一种单麦克风的感知增益函数的语音增强方法,其特征在于,包括以下步骤：S1：利用基于MMSE的无偏噪声功率谱估计得到<img file="FDA0001265758870000011.TIF" wi="85" he="63"/>S2：利用判决引导方法<img file="FDA0001265758870000012.TIF" wi="700" he="151"/>估计先验信噪比；S3：根据广义Gamma先验的感知MMSE准则来计算增益函数<img file="FDA0001265758870000013.TIF" wi="134" he="127"/><img file="FDA0001265758870000014.TIF" wi="700" he="148"/>S4：利用增益函数来增强语音<img file="FDA0001265758870000015.TIF" wi="606" he="79"/></td>   <td>G10L21/0208;G10L21/0216;G10L21/04;G10L25/18;G10L25/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;                   徐光       </td>   <td>中山大学</td>   <td>一种基于自然特征的跟踪注册方法及装置</td>   <td>广东</td>   <td>CN108694348A</td>   <td>2018-10-23</td>   <td>本发明公开了一种基于自然特征的跟踪注册方法及装置,所述跟踪注册方法包括以下步骤：图像序列划分,获取图像序列后,对图像序列进行人脸检测,并将所述图像序列划分为人脸区域和背景区域；相机位姿估计,对所述背景区域提取特征,并通过帧间匹配估算相机位姿,计算投影矩阵；人脸视觉检测,将所述人脸区域进行人脸特征点定位和人脸姿态估计；跟踪注册,根据所述上述步骤所得参数计算注册矩阵,完成跟踪注册；所述装置包括图像序列划分模块、相机位姿估计模块、人脸视觉检测模块和跟踪注册模块。本技术方案能够有效实现运动相机和运动目标区域之间的估计,完成增强现实的跟踪注册。</td>   <td>1.一种基于自然特征的跟踪注册方法,其特征在于,包括以下步骤：图像序列划分：获取图像序列后,对图像序列进行人脸检测,并将所述图像序列划分为人脸区域和背景区域；相机位姿估计：对所述背景区域提取特征,并通过帧间匹配估算相机位姿,计算投影矩阵,并得到三维空间不变点；人脸视觉检测：将所述人脸区域进行人脸特征点定位,得到人脸特征点位置信息,再进行人脸姿态估计；跟踪注册：根据所述投影矩阵、人脸特征点位置信息和三维空间不变点计算注册矩阵,完成跟踪注册。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         范新娟;              汪建平;              王磊;              万香波;              丁轶;              王云龙;                   郑坚       </td>   <td>中山大学附属第六医院</td>   <td>直肠癌术前同期新辅助放化疗疗效评估系统和方法</td>   <td>广东</td>   <td>CN108694718A</td>   <td>2018-10-23</td>   <td>本发明涉及直肠癌术前同期新辅助放化疗疗效评估系统和方法。本发明的评估系统包括图像获取单元,用于获取初诊局部晚期直肠癌患者的病理活检切片扫描图像和新辅助放化疗治疗前MRI影像,并将直肠癌患者分为训练集、校验集和测试集,作为已输入图像数据；图像标注单元,用于将训练集、校验集和测试集的病理活检切片扫描图像和MRI影像分别进行数据标注；卷积神经网络构造单元,用于构造第一卷积神经网络模型；以及卷积神经网络模型训练单元,获得用于评估直肠癌术前同期新辅助放化疗疗效的第二卷积神经网络模型。本发明的直肠癌术前同期新辅助放化疗疗效评估系统具有准确率高、耗时短且工作持续时间长、客观、立体等诸多优点。</td>   <td>1.一种直肠癌术前同期新辅助放化疗疗效评估系统,其特征在于,包括图像获取单元,用于获取初诊局部晚期直肠癌患者的病理活检切片扫描图像和新辅助放化疗治疗前MRI影像,并将初诊局部晚期直肠癌患者分为训练集、校验集和测试集,作为已输入图像数据；图像标注单元,用于将训练集、校验集和测试集的病理活检切片扫描图像和MRI影像分别进行数据标注；卷积神经网络构造单元,用于构造第一卷积神经网络模型；以及卷积神经网络模型训练单元,根据已输入图像数据和所进行的数据标注对第一卷积神经网络模型的参数进行调节,在校验集上观察分类的准确率,并训练第一卷积神经网络模型,获得用于评估直肠癌术前同期新辅助放化疗疗效的第二卷积神经网络模型。</td>   <td>G06T7/00;G06N3/04;G16H30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;              李效良;                   李亚龙       </td>   <td>中山大学</td>   <td>基于微外观模型的织物真实感外观渲染系统及方法</td>   <td>广东</td>   <td>CN108694739A</td>   <td>2018-10-23</td>   <td>本发明提供了一种基于微外观模型的织物真实感外观渲染系统及方法,其中系统包括织物模型构建模块、织物模型合成模块、体纹理映射模块以及渲染模块,通过结合纤维级别的织物样本体素模型和织物照片,系统自动构建出可渲染的织物体外观模型。同时,本系统采用基于物理的渲染方法,对织物进行渲染,可生成出高真实感的织物图片。在织物三维数据合成阶段,本专利书提出了一种基于图像缝合的织物三维模型的合成方法。该方法通过缝合样本织物表面图片中多个不规则像素块对应的立体数据,来合成出织物的三维数据,进而增加渲染结果的真实性。</td>   <td>1.一种基于微外观模型的织物真实感外观渲染系统,其特征在于包括：织物模型构建模块,负责根据织物样本,重建出织物样本的三维模型；织物模型合成模块,负责把织物样本的三维模型合成为大的织物的三维模型；体纹理映射模块,通过体纹理映射方法,负责把合成的大的三维模型附着到现有的服装或编织品模型上；渲染模块,负责把整个大织物三维模型渲染出来。</td>   <td>G06T15/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈金坤;              蔡丹蔚;              蔡炜城;                   李明       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于重排序超向量和残差网络的说话人识别方法及其装置</td>   <td>广东</td>   <td>CN108694949A</td>   <td>2018-10-23</td>   <td>本发明公开了基于重排序超向量和残差网络的说话人识别方法及其装置,方法包括：对语音样本进行信号检测,提取及优化MFCC特征；基于TDNN声学模型处理MFCC特征,得到均值中心化超向量；根据senone状态的相似性对均值中心化超向量进行重排序；以重排序后的均值中心化超向量作为外部神经网络的输入,对外部神经网络进行训练,其中输入端为残差网络,从其输出端获取说话人的深度编码特征；对说话人的深度编码特征进行PLDA建模,得到PLDA模型；计算语音样本的深度编码特征在PLDA模型上的似然得分,判断说话人是否为同一个人。本发明能够更好地学习超向量内部的连续性信息和局部相关性信息,有利于提升说话人识别性能。</td>   <td>1.基于重排序超向量和残差网络的说话人识别方法,其特征在于,包括以下步骤：S1、对语音样本进行语音信号检测,提取及优化MFCC特征；S2、基于TDNN声学模型处理MFCC特征,从而得到均值中心化超向量；S3、根据senone状态的相似性对均值中心化超向量进行重排序；S4、以重排序后的均值中心化超向量作为外部神经网络的输入,对外部神经网络进行训练,其中外部神经网络的输入端为残差网络；从外部神经网络的输出端获取说话人信息的深度编码特征；S5、对说话人信息的深度编码特征进行PLDA建模,从而得到PLDA模型；S6、计算多个语音样本的深度编码特征在PLDA模型上的似然得分,并比较对应的似然得分是否相同,若相同,则判定对应的说话人为同一个人,否则不为同一个人。</td>   <td>G10L17/04;G10L17/02;G10L17/18;G10L17/06;G10L25/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卓汉逵;                   荣二虎       </td>   <td>中山大学</td>   <td>一种基于图谱拓扑结构和实体文本描述的深度学习方法</td>   <td>广东</td>   <td>CN108681544A</td>   <td>2018-10-19</td>   <td>本发明提供一种基于图谱拓扑结构和实体文本描述的深度学习方法,该方法在解决知识图谱补全问题中,要补全的实体可能已经存在于知识图谱中(需发现),也可能不在知识图谱中(需生成)。对于需要发现的任务,可视作是封闭环境下的知识图补全问题,模型M1能够很好地“发现”这个实体；对于需要发现的任务,模型M2在注意力机制和循环卷积网络的帮助下,能够充分地发掘文本信息,为“生成”这个实体提供有力保障。这两个子模型的联合,能够解决开放世界知识图谱补全问题。</td>   <td>1.一种基于图谱拓扑结构和实体文本描述的深度学习方法,其特征在于,包括以下步骤：S1：构建基于图拓扑结构的预测模型M1；S2：构建基于注意力机制的文本处理模型M2；S3：通过大量的训练数据训练该模型,得出两个模型内部的参数,将现有的知识图谱结构作为子模型M1输入,相关的文本信息作为子模型M2的输入,分别得到M1的输出和M2的输出；S4：根据词向量字典查询,即可得出预测实体的名称。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         詹宜巨;              李海良;              蔡庆玲;              毛宜军;                   王永华       </td>   <td>中山大学</td>   <td>一种甲状腺癌症超声图片自动标注方法及系统</td>   <td>广东</td>   <td>CN108681731A</td>   <td>2018-10-19</td>   <td>本发明公开了一种甲状腺癌症超声图片自动标注方法和系统,通过对待处理的癌症图片数据集进行预处理,提取每张癌症图片的ROI子图数据集,然后采用VGG16深度学习网络模型对ROI子图数据集进行特征提取后,采用K#means++算法对提取获得的特征进行聚类,进而将聚类获得的结果与预设的无癌症图片的基准聚类结果进行比较后,提取获得癌症图片的癌症特征簇,最后在癌症图片的原图上对应标记提取获得的癌症特征簇。本发明工作效率高,准确度较高,节省了大量的财力物力,应用成本低,可广泛应用于医学图像数据的处理领域中。</td>   <td>1.一种甲状腺癌症超声图片自动标注方法,其特征在于,包括以下步骤：S1、对待处理的癌症图片数据集进行预处理,提取每张癌症图片的ROI子图数据集；S2、采用VGG16深度学习网络模型对ROI子图数据集进行特征提取；S3、采用K#means++算法对提取获得的特征进行聚类；S4、将聚类获得的结果与预设的无癌症图片的基准聚类结果进行比较后,提取获得癌症图片的癌症特征簇；S5、在癌症图片的原图上对应标记提取获得的癌症特征簇。</td>   <td>G06K9/32;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郇宜东;              徐文涛;              解静仪;                   农革       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种后缀数组自适应的合并方法及其装置</td>   <td>广东</td>   <td>CN108664459A</td>   <td>2018-10-16</td>   <td>本发明公开了一种后缀数组自适应的合并方法及其装置,通过训练决策树构建后缀数组自适应合并模型,在指定配置的计算机上根据待合并的后缀数组的源数据大小和类型、当前可用内存以及后缀数组大小和类型,决策树自动选取时间消耗最低的合并方法,加快以后缀数组所谓底层索引结构的索引系统的合并效率,避免了传统单一低效的合并方法对全文索引的维护造成的效率影响。</td>   <td>1.一种后缀数组自适应的合并方法,其特征在于,包括以下步骤：获取当前系统的可用内存大小；获取两个待合并的后缀数组的源数据大小和类型；获取两个待合并的后缀数组的大小和类型；将当前系统的可用内存大小、两个待合并的后缀数组的源数据大小和类型以及两个待合并的后缀数组的大小和类型作为参数输入到训练后的自适应合并模型,所述自适应合并模型以消耗最短合并时间的合并方法对两个待合并的后缀数组进行合并。</td>   <td>G06F17/22;G06F17/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨智;                   陈锭敏       </td>   <td>中山大学</td>   <td>一种网站网页源代码自动爬取方法</td>   <td>广东</td>   <td>CN108664559A</td>   <td>2018-10-16</td>   <td>本发明涉及一种网站网页源代码自动爬取方法,在确定好的网站中爬取网页,使得爬取的网页比较集中,有着比较明显的共同特性,方便在编写爬虫程序爬取网页。而且在特定的网站爬取网页,使得要爬取的目标信息比较集中,能够完整得快速得爬取到所需要的信息。在爬取网站网页源代码上,能够有效得伪装成浏览器发出的网页请求,防止被网站识别为机器代码在爬取网站数据。通过设置一定的等待时间,使得当网站或者网络出现异常情况而未对爬虫程序做出反应时代码报错停止运行,能够长时间自动得运行代码爬取网页源代码。通过添加代理IP地址数据库,能够有效地防止当爬虫代码被封锁IP拒绝访问网站时,程序还能自动更换IP继续爬取网页源代码。</td>   <td>1.一种网站网页源代码自动爬取方法,其特征在于,包括以下步骤：S1、确定含有目标信息的网站,分析该网站确定目标信息所在的网页,以及该些含有目标信息网页特有的共同特点；S2、加载爬取的初始网页以及该网页的URL；S3、加载要爬取网页的共同特点；S4、爬取初始网页的源代码,并检查是否存在含有目标信息的网页的URL,若不存在即结束爬取程序,若存在即逐一爬取含有目标信息的网页源代码,直到所有包含目标信息的网页爬取完毕；S5、将爬取到的目标源代码保存在指定位置的指定文件夹中,方便后期提取目标信息。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              吴明华;              李元新;              马媛;                   杨焕       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于辅变字典及最大边际线性映射的人脸识别方法和系统</td>   <td>广东</td>   <td>CN108664917A</td>   <td>2018-10-16</td>   <td>本发明公开了基于辅变字典及最大边际线性映射的人脸识别方法和系统,方法包括：根据训练集中同类别的不受外界因素影响的自然样本和受外界因素影响的非自然样本之间的差异来构建辅助变量字典；输入待测样本,根据主成分分析法对待测样本、训练集和辅助变量字典进行降维；对降维后的待测样本、训练集和辅助变量字典进行最大边际线性映射；对经降维和最大边际线性映射后的待测样本进行稀疏表示,并计算与每一类训练样本之间的线性结合的差别,判定待测样本所属类别为对应的使计算所得的差别最小的一类训练样本。本发明可提高待测样本在欠采样情况下的识别率,同时针对不同的外界环境因素具有良好的鲁棒性。</td>   <td>1.基于辅变字典及最大边际线性映射的人脸识别方法,其特征在于,包括以下步骤：S1、根据训练集中同类别的不受外界因素影响的自然样本和受外界因素影响的非自然样本之间的差异来构建辅助变量字典；S2、输入待测样本,根据主成分分析法对待测样本、训练集和辅助变量字典进行降维；S3、对降维后的待测样本、训练集和辅助变量字典进行最大边际线性映射；S4、对经降维和最大边际线性映射后的待测样本进行稀疏表示,并计算与每一类训练样本之间的线性结合的差别,判定待测样本所属类别为对应的使计算所得的差别最小的一类训练样本。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         许志明;              瞿文政;              潘志宏;              倪伟传;              刘少江;                   万智萍       </td>   <td>中山大学新华学院</td>   <td>基于CUDA的深度时空信息融合的目标跟踪方法及系统</td>   <td>广东</td>   <td>CN108664935A</td>   <td>2018-10-16</td>   <td>本发明公开了基于CUDA的深度时空信息融合的目标跟踪方法,包括以下步骤：通过图像采集装置获取图像帧,以相邻的两个图像帧中前一图像帧为匹配模板并传送至控制平台；通过基于CUDA的控制平台对匹配模板和后一帧图像进行检测,获取移动目标；控制平台对移动目标采用深度时空信息融合进行识别跟踪。本发明还公开了基于CUDA的深度时空信息融合的目标跟踪系统。本发明利用距离均值和匹配模板来重新定义移动事件,过滤噪声和其他干扰元素；利用图像帧间信息相关性特征,以及目标与周围环境存在的时空联系,得到精确的跟踪效果；本发明采用了GPU资源对系统进行加速处理,提高跟踪系统的运算速度。</td>   <td>1.基于CUDA的深度时空信息融合的目标跟踪方法,其特征在于,包括以下步骤：通过图像采集装置获取图像帧,以相邻的两个图像帧中前一图像帧为匹配模板并传送至控制平台；通过基于CUDA的控制平台对匹配模板和后一帧图像进行检测,获取移动目标；控制平台对移动目标采用深度时空信息融合进行识别跟踪。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈海波;                   虞志益       </td>   <td>中山大学</td>   <td>一种快速生成sift描述子的方法及其系统</td>   <td>广东</td>   <td>CN108664982A</td>   <td>2018-10-16</td>   <td>本发明涉及一种快速生成sift描述子的方法,包括以下步骤：S1.接收从外部传来的高斯图数据信息；S2.经过幅值幅角计算模块后,得到该关键点的主方向；S3.得到的主方向会送入旋转区间计算模块,来计算旋转后的幅角信息；S4.旋转区间计算模块会接收初始幅角信息及主方向,然后根据主方向进行区间旋转,最终确定其所在的行列信息；同时接收幅值和权值2对幅值进行加权；S5.128bin计算模块则接收旋转后的角度信息,旋转后的坐标信息及加权后的幅值,从而计算得到128维的描述子进行输出。</td>   <td>1.一种快速生成sift描述子的方法,其特征在于：包括以下步骤：S1.接收从外部传来的高斯图数据信息,该信息将作为计算dx、dy的数据被幅值幅角模块接收；S2.经过幅值幅角计算模块后,将产生初始幅值幅角信息,产生的数据存入幅值幅角buffer；当从关键点buffer中取出关键点位置信息后,会通过地址发生器模块来从幅值幅角buffer中获取对于位置的幅值幅角信息,同时,该坐标信息也会作用于gaussian权值buffer1,从中取出加权值,同幅值幅角信息一起送入主方向计算模块,从而得到该关键点的主方向；S3.得到的主方向会送入旋转区间计算模块,来计算旋转后的幅角信息；此时会再次获取关键点周围像素的坐标信息,该位置信息除了送入幅值幅角buffer获取幅值幅角外,还会送入gaussian权值buffer2获取第二次所使用的加权值,同时该位置信息还会送入旋转坐标幅值加权模块进行旋转坐标判断；S4.旋转区间计算模块会接收初始幅角信息及主方向,然后根据主方向进行区间旋转,最终确定其所在的行列信息；同时接收幅值和权值2对幅值进行加权；S5.128bin计算模块则接收旋转后的角度信息,旋转后的坐标信息及加权后的幅值,从而计算得到128维的描述子进行输出。</td>   <td>G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   刘润坤       </td>   <td>中山大学</td>   <td>一种二分类任务标签噪声容忍分类器学习方法</td>   <td>广东</td>   <td>CN108665002A</td>   <td>2018-10-16</td>   <td>本发明涉及一种二分类任务标签噪声容忍分类器学习方法,包括以下步骤：S1.输入模型调整参数,包括样本探测范围、样本权重因子、样本标签反转比例参数x%、循环次数；S2.输入带标签噪声训练集；S3.用带标签噪声训练集训练基础算法模型；S4.利用影响函数计算样本影响值,根据样本影响值排序将排序前x%的样本标签反转；S5.将部分标签反转的样本集作为之后的训练集训练基础算法模型；S6.判断是否达到最大循环次数,若是则根据模型的效果选取最佳模型作为输出模型；否则利用影响函数计算样本影响值,并更新探测范围和样本权重；更新样本权重时,适当降低探测范围内的训练样本的权重,同时相应提高探测范围外的训练样本的权重；S7.重复执行步骤S5<sup>S</sup>6。</td>   <td>1.一种二分类任务标签噪声容忍分类器学习方法,其特征在于：包括以下步骤：S1.输入模型调整参数,包括样本探测范围、样本权重因子、样本标签反转比例参数x％、循环次数；S2.输入带标签噪声训练集；S3.用带标签噪声训练集训练基础算法模型；S4.利用影响函数计算样本影响值,根据样本影响值排序将排序前x％的样本标签反转；S5.将部分标签反转的样本集作为之后的训练集训练基础算法模型；S6.判断是否达到最大循环次数,若是则根据模型的效果选取最佳模型作为输出模型；否则利用影响函数计算样本影响值,并更新探测范围和样本权重；更新样本权重时,适当降低探测范围内的训练样本的权重,同时相应提高探测范围外的训练样本的权重；S7.重复执行步骤S5～S6。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余阳;                   赖威       </td>   <td>中山大学</td>   <td>一种实现云工作流系统流程实例均衡调度的方法</td>   <td>广东</td>   <td>CN108665157A</td>   <td>2018-10-16</td>   <td>本发明提供一种实现云工作流系统流程实例负载均衡的方法,包括：(1)使用日志分析的方法估计当前到达的流程实例在运行时期内每个监控周期内的计算资源需求；(2)使用带有缓冲队列的首次适应降序策略为当前启动的流程实例选取调度域内合适的工作流引擎。本发明所述方法能够解决传统流程实例负载均衡算法需要迁移流程实例,影响用户体验的问题。</td>   <td>1.一种实现云工作流系统流程实例负载均衡的方法,其特征在于包括工作流引擎空闲资源监控和流程实例调度两个部分；其中所述工作流引擎资源监控部分为调度域内每一个工作流引擎维护一个空闲资源向量,并通过向量更新机制保证向量能实时体现工作流引擎在给定时间范围内的空闲资源；流程实例调度部分用于分析当前启动流程实例的资源需求、选取空闲资源大于流程实例需求的工作流引擎和调度流程实例至选定的工作流引擎。</td>   <td>G06Q10/06;G06Q10/10;H04L29/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨骏;              印鉴;                   高静       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种结合情感词典的卷积神经网络文本情感分析方法</td>   <td>广东</td>   <td>CN108647219A</td>   <td>2018-10-12</td>   <td>本发明提供一种结合情感词典的卷积神经网络文本情感分析方法。通过获取英文评论,进行情感极性的标注的方法。得到所需要的语料,并对其做去停用词的操作,然后采用word2vec算法对处理得到的语料进行训练,得到相应的词向量。把每句话中的词向量与词典中对应的各情感分值相乘并拼接,得到句子的矩阵表示,将其输入到的卷积神经网络(CNN)结构中,从而在模型训练过程中,将词语的情感极性程度嵌入其中,让模型的关注点更接近于人类的理解,提高了文本情感分析的准确度。</td>   <td>1.一种结合情感词典的卷积神经网络文本情感分析方法,其特征在于,包括以下步骤：S1：首先获取英文文本语料,接着对语料进行情感分类标注,最后将语料分为训练和测试集两个集合；S2：对步骤S1)中的所有语料集进行停用词处理；S3：使用word2vec算法对步骤S2)中获取的语料进行训练得到相应的词向量；S4：根据sentiwordnet(情感词典)获取预知的各词语的情感极性分布,并利用词语在不同极性上的权重与该词语的词向量相乘,得到词语在不同情感取向下的特征表示；S5：将处理后的训练集语料按照句子顺序拼接起来形成矩阵放进卷积神经网络中进行训练,其中句子里的词语在多个情感取向下的表示可以拼接得到多个矩阵,而这多个矩阵对应卷积神经网络中的多个频道；S6：将步骤S2)、S3和步骤S4处理获取的测试集语料放入步骤S5中训练好的情感分析模型,最终获取测试集的情感分类结果。</td>   <td>G06F17/30;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              潘文优;                   陈湘萍       </td>   <td>中山大学</td>   <td>一种基于CNN的保持表情信息的人脸转移方法</td>   <td>广东</td>   <td>CN108647560A</td>   <td>2018-10-12</td>   <td>本发明公开了一种基于CNN的保持表情信息的人脸转移方法。该方法通过结合人脸识别网络和表情识别网络达到保存特征信息的脸部转换效果,可以把图片A的人脸转移到另外一张图片B人脸上,在转换的过程中,仍然保持图片B的表情信息和其余的非人脸信息。它解决了两个核心技术问题,一是人脸合成的过程中合成部分与原图部分不和谐的问题；第二个是合成部分和原图部分合成之后人脸信息丢失的问题,包括识别信息和表情信息丢失。实施本发明实施例,可以增加人们生活中对图像处理的需求,使得在人脸处理上又多一样应用；同时,能够使“拍照不适人群”通过图像合成的方式生成更多自己的图片。</td>   <td>1.一种基于CNN的保持表情信息的人脸转移方法,其特征在于,所述方法包括：从网络以及人脸数据库中获取人脸图片,以及对人脸图片的表情分类的标记信息,组成照片库；从照片库中选取两张照片作为一组样本,图片A作为身份信息图,图片B作为表情信息图；将较高像素图片下采样到较低像素图片的大小,使二者等大小；使用AdaBoost算法对图A和图B进行人脸区域检测与分割；将图A和图B的人脸区域组合成组合通道,作为输入数据输入到生成式CNN网络中,通过前向传播生成一张合成人脸；将合成人脸与图B非人脸区域进行泊松融合；将合成人脸与图A人脸区域输入到FaceNet神经网络中,得到识别信息的损失L1；将合成人脸与图B人脸区域输入到深度ConvNets中求出表情特征信息损失L2；结合L1和L2的损失值,对生成式CNN网络进行反向传播,更新网络权重；最后重复训练生成式CNN网络。</td>   <td>G06K9/00;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱俊祺;              印鉴;                   高静       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种结合新闻语料和股市交易数据的股票预测方法</td>   <td>广东</td>   <td>CN108647828A</td>   <td>2018-10-12</td>   <td>本发明提供一种结合新闻语料和股市交易数据的股票预测方法,该方法充分利用网络大量的语料信息,打破传统单一分析数据来源的界限。通过深度学习模型,能够批量化分析股市新闻语料,自动判断语料对于预测的重要性,实现了网络资讯分析的自动化和精准化；利用深度学习对新闻语料和交易数据进行建模,多方面利用了不同信息,综合分析各种数据的相互关系。把握股市信息对股价的影响性、持久性、投资者的心理因素,进一步提高股市预估的准确性；使用了词向量、GRU神经网络、注意力机制等深度学习前沿技术,把科学落实到产业当中,实现科技创新。</td>   <td>1.一种结合新闻语料和股市交易数据的股票预测方法,其特征在于,包括以下步骤：S1：获取股票新闻文档集合并进行预处理,获得文档集合词向量；S2：获取股票交易数据进行预处理,获得归一化后的交易数据和每天的分类标签；S3：使用GRU神经网络和注意力机制对文档编码,得到文档集合向量；S4：文档向量和交易数据进行拼接,然后按照时间顺序输入到GRU神经网络中进行预测,得到股票第二天的趋势预测结果。</td>   <td>G06Q10/04;G06Q40/04;G06F17/30;G06F17/27;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              晏斌;              李凯祥;                   全小虎       </td>   <td>中山大学</td>   <td>一种基于Spark的个性化推荐方法及系统</td>   <td>广东</td>   <td>CN108647996A</td>   <td>2018-10-12</td>   <td>本发明公开了一种基于Spark的个性化推荐方法及系统,其中,所述个性化推荐方法包括：获取用户对商品的行为信息并进行用预处理,获取用户对商品的隐式反馈；根据用户对商品的隐式反馈进行用户对商品的交互矩阵构建处理,获取用户对商品的交互矩阵；根据用户对商品的交互矩阵进行商品相似度矩阵计算处理,获取商品相似度矩阵；根据商品相似度矩阵进行商品邻近集构建处理,获取商品邻近集；根据商品邻近集进行用户对商品的偏好值预测处理,获取用户对商品的偏好值；根据用户对商品的偏好值向用户进行商品推荐,并将推荐结果进行展示。在本发明实施例中,融合多源信息,充分利用用户对商品的行为信息,缓解数据稀疏和冷启动问题。</td>   <td>1.一种基于Spark的个性化推荐方法,其特征在于,所述个性化推荐方法,包括：获取用户对商品的行为信息并进行用预处理,获取用户对商品的隐式反馈；根据用户对商品的隐式反馈进行用户对商品的交互矩阵构建处理,获取用户对商品的交互矩阵；根据用户对商品的交互矩阵进行商品相似度矩阵计算处理,获取商品相似度矩阵；根据商品相似度矩阵进行商品邻近集构建处理,获取商品邻近集；根据商品邻近集进行用户对商品的偏好值预测处理,获取用户对商品的偏好值；根据用户对商品的偏好值向用户进行商品推荐,并将推荐结果进行展示。</td>   <td>G06Q30/02;G06Q30/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>              毛锦庚       </td>   <td>中山大学南方学院</td>   <td>一种便于灰尘清理的计算机用键盘</td>   <td>广东</td>   <td>CN207965819U</td>   <td>2018-10-12</td>   <td>本实用新型公开了一种便于灰尘清理的计算机用键盘,包括键盘主体、拉手和第一集灰钩刺面,所述键盘主体的前下方安装有转轴,所述键盘主体的上表面安装有固定杆,且固定杆的上方设置有键帽,所述拉手位于键盘主体的左右两侧,且键盘主体的右后方安装有指示灯,所述第一集灰钩刺面的左侧安装有第二集灰钩刺面,所述键盘主体的后下方安装有折叠垫板,且键盘主体的上方开设有滑槽,所述滑槽的内部安装有滑块板,所述托盘的上方安装有胶垫,且托盘的表面开设有销孔。便于灰尘清理的计算机用键盘设置有托盘,且托盘通过转轴与键盘主体构成转动结构,使得托盘在闲置时可以折叠放置,增加装置的实用性。</td>   <td>1.一种便于灰尘清理的计算机用键盘,包括键盘主体(1)、拉手(7)和第一集灰钩刺面(9),其特征在于：所述键盘主体(1)的前下方安装有转轴(2),且转轴(2)的下方安装有托盘(3),并且转轴(2)的左右两侧均安装有固定销(4),所述键盘主体(1)的上表面安装有固定杆(5),且固定杆(5)的上方设置有键帽(6),所述拉手(7)位于键盘主体(1)的左右两侧,且键盘主体(1)的右后方安装有指示灯(8),所述第一集灰钩刺面(9)的左侧安装有第二集灰钩刺面(10),且第二集灰钩刺面(10)和第一集灰钩刺面(9)的上表面均安装有毛刷(11),所述键盘主体(1)的后下方安装有折叠垫板(12),且键盘主体(1)的上方开设有滑槽(13),所述滑槽(13)的内部安装有滑块板(14),所述托盘(3)的上方安装有橡胶垫(15),且托盘(3)的表面开设有销孔(16)。</td>   <td>G06F3/02;B08B1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卓汉逵;                   付豪       </td>   <td>中山大学</td>   <td>结合注意力机制和多任务协同训练的命名实体识别方法</td>   <td>广东</td>   <td>CN108628823A</td>   <td>2018-10-09</td>   <td>本发明提供一种结合注意力机制和多任务协同训练的命名实体识别方法,该方法包括如下步骤：(1)对训练数据进行预处理操作,通过字符层级的映射获得句子的字符向量表征；(2)将步骤(1)中获得的字符向量表征输入一个双向LSTM网络,获得每个词语的字符向量表征；(3)通过词语层级的映射,获得每一个句子的词向量表征；(4)通过注意力机制对步骤(3)中获得的词向量表征和步骤(1)中获得的字符向量表征进行拼接,传入双向LSTM神经网络,获得句子的语义特征向量；(5)针对步骤(4)中得到的语义特征向量,利用条件随机场对每个单词进行实体标注,解码出实体标签。</td>   <td>1.一种结合注意力机制和多任务协同训练的命名实体识别方法,其特征在于,包括以下步骤：(1)、对训练数据进行预处理操作,通过字符层级的映射获得句子的字符向量表征；(2)、将步骤(1)中获得的字符向量表征输入一个双向LSTM网络,获得每个词语的字符向量表征；(3)、通过词语层级的映射,获得每一个句子的词向量表征；(4)、通过注意力机制对步骤(3)中获得的词向量表征和步骤1中获得的字符向量表征进行拼接,传入双向LSTM神经网络,获得句子的语义特征向量；(5)、针对步骤(4)中得到的语义特征向量,利用条件随机场对每个单词进行实体标注,解码出实体标签。</td>   <td>G06F17/27;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;                   殷海元       </td>   <td>中山大学</td>   <td>一种基于FPGA的并行字符串匹配算法</td>   <td>广东</td>   <td>CN108628953A</td>   <td>2018-10-09</td>   <td>本发明涉及一种基于FPGA的并行字符串匹配算法,通过FPGA并行处理来实现在一个时钟周期找到模式字符串前j个字符的子串,以及它的前缀和后缀的最大公共元素值,通过前缀和后缀的最大公共元素值可直接得到并输出NEXT数组,利用NEXT数组可实现多个模式字符串的并行匹配。</td>   <td>1.一种基于FPGA的并行字符串匹配算法,其特征在于：通过FPGA并行处理在一个时钟周期找到模式字符串前j个字符的子串,以及它的前缀和后缀的最大公共元素值,通过前缀和后缀的最大公共元素值可直接得到并输出NEXT数组,利用NEXT数组可实现多个模式的字符串并行匹配。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑培嘉;              郭剑艇;                   黄继武       </td>   <td>中山大学</td>   <td>基于H.264/AVC加密视频的运动异常检测方法</td>   <td>广东</td>   <td>CN108629237A</td>   <td>2018-10-09</td>   <td>本发明提供一种基于H.264/AVC加密视频的运动异常检测方法,本发明通过对加密视频进行信息提取,对提取的信息进行特征计算,再利用训练集提取的特征,训练模型,最后,利用训练好的模型,进行异常检测。该方法采用直接在压缩码流上处理的方法使得算法效率更高,更适应于实际应用场景,同时根据加密码流结构的特性进行信息提取,为应对加密视频下异常运动的特点,重新设计了特征提取方法,使得异常检测能够在加密视频上实现,利用物理世界物体运动的特性,减少加密视频检测结果的离散问题,进一步提高了检测的准确率,从而可以为云监控系统、云存储系统等应用提供帮助。</td>   <td>1.一种基于H.264/AVC加密视频的运动异常检测方法,其特征在于,包括以下步骤：S1：对加密视频进行信息提取；S2：对提取的信息进行特征计算；S3：利用训练集提取的特征,训练模型；S4：利用训练好的模型,进行异常检测。</td>   <td>G06K9/00;G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              李宏伟;              黄灏;                   李瑞溪       </td>   <td>中山大学</td>   <td>一种人类上皮细胞样本图像自动分类方法</td>   <td>广东</td>   <td>CN108629359A</td>   <td>2018-10-09</td>   <td>本发明公开了一种人类上皮细胞样本图像自动分类方法,包括步骤：将人类上皮细胞样本图像分割成多张细胞群图片；从细胞群图片中筛选出有效的训练样本；使用有效的训练样本对深度卷积神经网络进行训练；用训练完成的深度卷积神经网络对未筛选的细胞群图片进行模式分类；统计模式分类结果,得到每个人类上皮细胞样本图片的模式分布直方图；使用模式分布直方图作为特征向量,输入到统计分类器进行模型训练；使用训练好的统计分类器对测试样品进行分类预测。本发明使用深度卷积神经网络,对单个细胞进行模式识别,具有鲁棒性；使用模式分布直方图作为样本图像的特征表达,对噪声数据有一定的容忍度,识别率高。</td>   <td>1.一种人类上皮细胞样本图像自动分类方法,其特征在于,包括步骤S1：将人类上皮细胞样本图像分割成多张细胞群图片；S2：从所述细胞群图片中筛选出有效的训练样本；S3：使用有效的训练样本对深度卷积神经网络进行训练；S4：用训练完成的深度卷积神经网络对未筛选的细胞群图片进行模式分类；S5：统计模式分类结果,得到每个人类上皮细胞样本图片的模式分布直方图；S6：使用所述模式分布直方图作为特征向量,输入到统计分类器进行模型训练；S7：使用训练好的统计分类器对测试样品进行分类预测。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡晨;              王若梅;              罗笑南;                   林淑金       </td>   <td>中山大学</td>   <td>一种基于深度网络增强服装属性识别精度的方法</td>   <td>广东</td>   <td>CN108629367A</td>   <td>2018-10-09</td>   <td>本发明公开了一种基于深度网络增强服装属性识别精度的方法。本发明通过Mask#out策略对服装图像数据集进行处理,通过计算图像的局部特征从而改善全局特征,最终获取最优解。该过程经历了三个神经网络,多标签属性识别增强网络将输入的一维属性特征向量处理为一个一维的预测向量,多示例全卷积网络将输入的二维特征图处理为一个二维预测矩阵,弱监督属性识别网络将输入的二维预测矩阵转化为一维预测向量完成整个服装属性识别任务。在多标签属性增强网络阶段,网络通过弱标签学习接收训练数据,避免了大量人工标注工作,这使得本方法更加经济、高效；基于弱监督学习强化的属性识别网络利用局部最优解改善整张图像的属性识别精度,从而进一步提高服装属性的识别精度。</td>   <td>1.一种基于深度网络增强服装属性识别精度的方法,其特征在于,所述方法包括：获取服装图像数据以及标签数据作为初始数据集,数据集分为训练集与测试集。将初始训练集服装数据和标签数据输入多标签属性识别增强网络模型,模型学习后输出测试数据的预测信息。利用步骤二输出的预测信息,并结合Mask#out策略和多示例学习策略制作多示例全卷积网络模型的训练集与测试集。将步骤三生成的训练集和测试集对多示例全卷积网络模型进行训练,之后把初始的训练集服装数据输入训练好的多示例全卷积网络,输出学习到的特征分布。联合初始训练集服装数据和标签数据,以及步骤四输出的特征分布,作为弱监督属性识别网络的输入；弱监督属性识别网络对服装图像中的属性信息进行识别,输出最终的识别结果。</td>   <td>G06K9/62;G06K9/66;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   卜凡       </td>   <td>中山大学</td>   <td>一种基于Lyapunov优化的数据中心电能开销优化控制方法及系统</td>   <td>广东</td>   <td>CN108629448A</td>   <td>2018-10-09</td>   <td>一种基于Lyapunov优化的数据中心电能开销优化控制方法,包括以下步骤：获得当前时刻的电网批发电价Pr,电网向数据中心输出的最大功率PBmax以及电网当前的碳排放率Cb,当前时刻的最大可用风电输出功率PWavail和风电的碳排放量Cw；基于电网能源和风电能源建立数据中心电能能耗模型；建立数据中心电能开销模型：基于Lyapunov优化得到数据中心电能开销的优化函数F(t)；取数据中心电能开销的优化函数F(t)的最小值,并结合能耗模型和开销模型,求得此时数据中心的电网能源负载PB、风电能源负载PW、延时敏感服务器数量mu及延时容忍服务器数量md。本发明将电网电力与风电绿色能源两种电力输入,统筹考虑绿色清洁能源的使用,合理分配电力负载,最终有效降低数据中心能耗开销。</td>   <td>1.一种基于Lyapunov优化的数据中心电能开销优化控制方法,其特征在于包括以下步骤：获得当前时刻的电网批发电价Pr,电网向数据中心输出的最大功率PBmax以及电网当前的碳排放率Cb,当前时刻的最大可用风电输出功率PWavail和风电的碳排放量Cw；基于电网能源和风电能源建立数据中心电能能耗模型,能耗模型为：PB+PW＝[mu·POu+md·POd]·PUE其中,0≤PB≤PBmax,0≤PW≤PWavail,0＜md≤Md,PB为数据中心的电网能源负载,PW为数据中心的风电能源负载,POu为数据中心单个延迟敏感服务器物理机的能耗,POd为数据中心单个延迟容忍服务器物理机的能耗,mu为延时敏感服务器数量,md为延时容忍服务器数量,PUE为系数常数,Md为延时容忍服务器数量的最大值；建立数据中心电能开销模型,开销模型为：COST＝CT[PB·Cb+PW·Cw]+PB·Pr其中CT为碳税价格；基于Lyapunov优化得到数据中心电能开销的优化函数F(t),F(t)＝V·COST#Qd(t)·md·srd其中V为Lyapunov惩罚系数,Qd(t)为t时刻延迟容忍任务的虚拟队列值,srd为延时容忍作业处理速率；取数据中心电能开销的优化函数F(t)的最小值,并结合能耗模型和开销模型,求得此时数据中心的电网能源负载PB、风电能源负载PW、延时敏感服务器数量mu及延时容忍服务器数量md。</td>   <td>G06Q10/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         衣杨;              吴昱焜;              张念旭;              谢韬;              李仲泓;                   周翼丰       </td>   <td>中山大学</td>   <td>一种乳腺癌图像识别方法、装置和用户终端</td>   <td>广东</td>   <td>CN108629761A</td>   <td>2018-10-09</td>   <td>本发明提供了一种乳腺癌图像识别方法、装置和用户终端,其中所述方法包括：将预处理病理图像通过阈值分割算法进行分割,得到分割后二值图像；以淋巴细胞为区域生长算法的种子,以所述分割后二值图像的并集作为目标图片,通过所述区域生长算法分割出区域二值图像；根据所述区域二值图像获得与所述区域二值图像对应的区域面积,并通过所述区域面积计算得到浸润癌间质淋巴细胞比例。本发明所提供的方法实现了通过计算机对乳腺癌的病理图像中的癌细胞的识别,提高了对于乳腺癌病理图像诊断的准确性,避免了人工肉眼判断的误差,减少了对于乳腺癌病理图像诊断的时间,提高了诊断效率,从而为医生的诊断工作带来方便。</td>   <td>1.一种乳腺癌图像识别方法,其特征在于,包括：将预处理病理图像通过阈值分割算法进行分割,得到分割后二值图像；以淋巴细胞为区域生长算法的种子,以所述分割后二值图像的并集作为目标图片,通过所述区域生长算法分割出区域二值图像；根据所述区域二值图像获得与所述区域二值图像对应的区域面积,并通过所述区域面积计算得到浸润癌间质淋巴细胞比例。</td>   <td>G06T7/00;G06T7/11;G06T7/155;G06T7/187;G06T7/62;G06T5/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卓汉逵;                   刘恩乐       </td>   <td>中山大学</td>   <td>一种基于端到端神经网络的指代消解方法</td>   <td>广东</td>   <td>CN108595408A</td>   <td>2018-09-28</td>   <td>本发明提供一种基于端到端神经网络的指代消解方法,该方法通过对知识库的抽取,解决了在代词消解问题中训练数据不足的问题,同时考虑了代词在句子中的结构信息,抽取出一系列特征用于训练深度神经网络,使得模型个具有代词消歧的能力。</td>   <td>1.一种基于端到端神经网络的指代消解方法,其特征在于,包括以下步骤：S1：基于知识库的词向量通过WikiPedia和CBTest这两个数据集训练得到,提取知识库不等式；S2：建立skip#gram权重矩阵；该权重表达了基于知识库的分布式词向量网络的全部内容；S3：训练深度神经网络,网络的输入为句子提取的特征映射的低维空间的向量。</td>   <td>G06F17/27;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              许伟原;                   陈家炜       </td>   <td>中山大学</td>   <td>一种互联网信息过滤以及互联网用户信息和网帖结构分析方法</td>   <td>广东</td>   <td>CN108595466A</td>   <td>2018-09-28</td>   <td>本发明公开了一种互联网信息过滤以及互联网用户信息和网帖结构分析方法,通过爬虫获取数据,并利用spark#sql进行数据检索,接着利用关注度模型对用户信息和贴吧进行了分析,最后对帖子的文本进行相关性计算和相关词挖掘,有效的提高了对水贴和广告贴的过滤效果。</td>   <td>1.一种互联网信息过滤以及互联网用户信息和网帖结构分析方法,其特征在于包括以下步骤：数据采集,利用python的爬虫框架,分析所需信息所在页面的url结构,根据分析结果构造请求url,模拟浏览器提交网络请求,使用正则表达式或者第三方库提取信息；数据存储与检索,将采集回来的数据,按照贴吧数据的分类建表,然后将数据导入hbase,存储方式采用列存储,检索的方式是利用基于mapreduce计算框架的spark#sql进行检索；用户关系分析,利用spark#sql筛选后的数据,通过关注度模型,把每个用户当做一个点,关系用边来表示,很多用户就构成一个无向有环图,把用户与用户之间的关系,转化为点与点之间的可达性问题；贴吧分析,统计每个主题贴吧所拥有的用户数来确定贴吧的关注度,挖掘每个贴吧之间的关系,通过扫描每个用户关注的贴吧列表,来建立贴吧与贴吧之间的关系,贴吧作为点,贴吧之间的关系作为边,构造无向有环图；文本相关性挖掘,利用TFI#DF模型、LSI模型和余弦距离计算两个文本之间的相似性,在相似文本之间挖掘相关词；相关词挖掘,把文本中出现的词转化为词向量,使用word2vec中的cbow模型来学习从当前词的周围的词预测当前词生成的概率的过程,利用skim#gram模型来学习从当前词预测其他词生成的概率的过程,最后使用神经网络对上述学习过程进行训练。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卓汉逵;                   李运聪       </td>   <td>中山大学</td>   <td>一种基于智能规划的知识获取方法</td>   <td>广东</td>   <td>CN108595471A</td>   <td>2018-09-28</td>   <td>本发明提供一种基于智能规划的知识获取方法,本发明通过对领域建模过程中输入的predicate或者action结合参数列表进行重命名,将不同规划问题领域的领域知识进行一致性检查并兼容地融合在领域知识库中,借助领域知识库中的知识模板,可以减少规划研究人员进行领域建模的工作量以及减轻负担。</td>   <td>1.一种基于智能规划的知识获取方法,其特征在于,包括以下步骤：S1：对不同领域知识进行融合,添加到领域知识库；S2：根据领域知识库自动提示,协助研究人员进行领域建模。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨尚明;                   潘炎       </td>   <td>中山大学</td>   <td>一种带有物体位置感知的多标签图片哈希方法</td>   <td>广东</td>   <td>CN108595474A</td>   <td>2018-09-28</td>   <td>本发明提供一种带有物体位置感知的多标签图片哈希方法,该方法提出的自学习背景过滤结构,对模型抽取的特征进行优化,能够有效的剔除背景的干扰,且使用了一个可一体化训练的网络结构,提高了图片搜索的准确度。</td>   <td>1.一种带有物体位置感知的多标签图片哈希方法,其特征在于,包括以下步骤：S1：采集训练样本数据；S2：将448×448大小的图片输入到卷积子网络中,这里的卷积子网络结构使用的是改造后的GoogLeNet,我们把原始结构中最后一个pooling层去除,新增一个卷积核大小为3×3的卷积层,最终的输出为14×14×480的feature#map；S3：步骤S2得到的feature#map之上新增一个1×1的卷积层,得到一个大小为14×14的feature#map,再通过softmax操作和截断操作,其中大于预设置参数θ则取为1否则为0,后最终得到一个14×14的二值feature#map,称为binary#mask,值1表示的区域是有物体的区域,值0则对应于背景,Softmax函数的定义如下：<img file="FDA0001592976510000011.TIF" wi="542" he="150"/>Fi,j为featrue#map上横轴为i,竖轴为j的位置的值；S4：根据步骤S3得到的binary#mask对步骤B中的feature#map进行pooling,只保留对应binary#mask中值为1的区域,这样我们就得到一个480维的特征；S5：将步骤S4最终的480维特征输入到一个480×k的激活函数为TanH的全连接网络,得到k维的#1到1之间的实数表示,再将该k维实数表示输入到cross#entropy#loss层和triplet#loss层进行训练；triplet#loss的定义如下：<img file="FDA0001592976510000012.TIF" wi="700" he="46"/>s.t.B(I),B(I+),B(I_)∈[#1,1]qcross#entropy#loss的定义如下：<img file="FDA0001592976510000013.TIF" wi="534" he="127"/>最终的loss由这两个loss合并得到：<img file="FDA0001592976510000014.TIF" wi="700" he="77"/>S6：用训练好的模型重复步骤B到步骤E,并将步骤E的k维实数进行截断,其中大于0的截断为1否则截断为0,得到k维的二值哈希码。</td>   <td>G06F17/30;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡学东;              解静仪;              徐文涛;                   农革       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于后缀数组的自适应索引构建方法及系统</td>   <td>广东</td>   <td>CN108595508A</td>   <td>2018-09-28</td>   <td>本发明公开了一种基于后缀数组的自适应索引构建方法及系统,通过读取索引文档并计算构建此文档的最小所需内存,并将最小所需内存与计算机内存作比较,以选出满足计算机内存要求的索引文档集和与之对应的候选构建工具集,并对索引文档集进行训练以及记录训练构建数据和各构建工具所用时间,最后通过读取所述的记录信息来实现构建速度最快的构建工具的调用,从而达到构建后缀数组的目的；本发明有效地划定了可构建范围,使得后缀数组的构建适配于计算机,并且可寻找、调用构建速度最快的构建工具,有利于提高构建效率。</td>   <td>1.一种基于后缀数组的自适应索引构建方法,其特征在于,包括以下步骤：S1、读取索引文档并获取该文档的字节数n,计算存储该文档每个字节地址所需的最小位数p并转换为存储索引地址的最小字节数t；S2、计算存储索引地址的最小字节数t、待索引文档的字节数n和构建工具的构建系数k三者的相乘值,从而得到构建该文档的最小所需内存a；S3、筛选出所有a小于或等于m的索引文档集,选取对应符合所述内存要求的候选构建工具集,其中m为计算机可用内存；S4、依次调用候选构建工具集中的构建工具进行所述索引文档集的后缀数组的训练构建,并记录所有的训练构建数据以及每个构建工具所用的构建时间；S5、读取所述的记录信息,从而选择并调用构建时间最少的构建工具构建后缀数组。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              晏斌;                   李凯详       </td>   <td>中山大学;广州搏创信息科技有限公司</td>   <td>一种融合多源异构信息的个性化推荐方法及系统</td>   <td>广东</td>   <td>CN108595527A</td>   <td>2018-09-28</td>   <td>本发明公开了一种融合多源异构信息的个性化推荐方法及系统,其中,所述个性化推荐方法包括：采集用户行为记录信息,所述用户行为记录信息包括不限于系统中记录用户对项目的各种行为和所述各种行为发生时间、发生地点和存储至数据库；对用户对项目的各种行为按照不同权重进行线性加权转换处理,获取用户对项目的隐式反馈；根据用户对项目的隐式反馈进行交互矩阵构建处理,获取用户项目交互矩阵；根据用户项目交互矩阵构建个性化推荐模型,并获取向用户推荐的对应项目。在本发明实施例中,可以有效的缓解数据协同过滤中存在的数据稀释问题和冷启动问题,能根据用户的具体情况向用户推荐合适的项目,有效的提高用户的使用友好体验。</td>   <td>1.一种融合多源异构信息的个性化推荐方法,其特征在于,所述个性化推荐方法包括：采集用户行为记录信息,所述用户行为记录信息包括不限于系统中记录用户对项目的各种行为和所述各种行为发生时间、发生地点和存储至数据库；对用户对项目的各种行为按照不同权重进行线性加权转换处理,获取用户对项目的隐式反馈；根据用户对项目的隐式反馈进行交互矩阵构建处理,获取用户项目交互矩阵；根据用户项目交互矩阵构建个性化推荐模型,并获取向用户推荐的对应项目。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              陆瑞智;                   谢晓华       </td>   <td>中山大学</td>   <td>一种基于双目视觉的串联通道融合行人检测方法</td>   <td>广东</td>   <td>CN108596040A</td>   <td>2018-09-28</td>   <td>本发明公开了一种基于双目视觉的串联通道融合行人检测方法,该方法根据双目RGB图像生成视差图,构建一个卷积神经网络,把RGB图像通道和视差图通道串联作为卷积神经网络的输入,学习RGB图和视差图之间的互补关系,从卷积神经网络输出的检测结果中挑选出预测值大于设定值的部分,对该部分进行非极大值抑制,得到最终行人位置。由于RGB彩色图有丰富的颜色信息,视差图对光照有不变性,本发明把两者联合起来能使行人检测更加鲁棒、准确。</td>   <td>1.一种基于双目视觉的串联通道融合行人检测方法,其特征在于,包括步骤：根据双目RGB图像生成视差图,构建一个卷积神经网络,把RGB图像通道和视差图通道串联作为卷积神经网络的输入,学习RGB图和视差图之间的互补关系,从卷积神经网络输出的检测结果中挑选出预测值大于设定值的部分,对该部分进行非极大值抑制,得到最终行人位置。</td>   <td>G06K9/00;G06K9/46;G06K9/62;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              卓嘉璇;                   陈泽宇       </td>   <td>中山大学</td>   <td>一种基于集中学习与深度网络学习的遮挡行人再识别方法</td>   <td>广东</td>   <td>CN108596211A</td>   <td>2018-09-28</td>   <td>本发明公开了一种基于集中学习与深度网络学习的遮挡行人再识别方法,该方法通过遮挡模拟器从原始未遮挡训练样本生成多种类型遮挡训练样本,生成的遮挡训练样本与原始训练样本组成联合训练集用于模型的训练,同时添加遮挡与非遮挡分类损失到行人分类损失中去,用多任务损失函数代替以往的单任务损失函数,有效地应对遮挡下行人再识别的问题,使得深度网络学习特征的时候考虑遮挡与非遮挡的先验信息进行特征的提取。实验表明,本发明能较大幅度地提高现有的深度网络在遮挡行人再识别上的性能,具有广泛的应用价值。</td>   <td>1.一种基于集中学习与深度网络学习的遮挡行人再识别方法,其特征在于,包括步骤：S1.建立一个遮挡模拟器,从原始的未遮挡行人图像中生成各种不同类型遮挡的行人图像,生成的遮挡行人图像组成遮挡行人集合；S2.将生成的遮挡行人图像与原始完整的行人图像合并,联合训练一个带有多任务损失函数的深度网络,即集中学习框架,在这个框架下,深度网络通过不断前向传播和后向调整,实现对图像中行人部位提取特征并再进行分类的功能；训练直至深度网络的参数收敛得到网络模型；S3.在步骤S2得到的网络模型的基础上进一步训练真实的遮挡行人图像和非遮挡行人图像,得到最后的网络模型；S4.使用步骤S3中得到的网络模型对目标行人图像及行人图像库中的行人图像分别进行特征的提取,然后将从目标行人图像中提取的特征依次与从图像库中的行人图像中提取的特征进行匹配,基于匹配的结果确定目标行人图像的身份。</td>   <td>G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   练紫莹       </td>   <td>中山大学</td>   <td>基于文本描述信息和生成对抗网络的视频生成模型</td>   <td>广东</td>   <td>CN108596265A</td>   <td>2018-09-28</td>   <td>本发明涉及一种基于文本描述信息和生成对抗网络的视频生成模型,以带有文本描述信息的视频作为训练数据,应用自助抽样法抽取出训练数据中部分的视频和其相应的文本描述信息一同输入到动作识别模型中进行训练,剩下的训练数据去除文本描述信息后再输入动作识别模型中进行训练,从而训练出训练数据中文本描述信息的有效词向量,将<词向量,视频>输入到所提出的生成对抗网络模型中,以词向量作为限制条件,使得模型中生成器能够生成视频。</td>   <td>1.基于文本描述信息和生成对抗网络的视频生成模型,其特征在于：以带有文本描述信息的视频作为训练数据,应用自助抽样法抽取出训练数据中部分的视频和其相应的文本描述信息一同输入到动作识别模型中进行训练,剩下的训练数据去除文本描述信息后再输入动作识别模型中进行训练,从而训练出训练数据中文本描述信息的有效词向量,将<词向量,视频>输入到所提出的生成对抗网络模型中,以词向量作为限制条件,使得模型中生成器能够生成视频。</td>   <td>G06K9/62;G06K9/00;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姜楠;              王军;                   杨青       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于Verilog的判题装置、方法及系统</td>   <td>广东</td>   <td>CN108596799A</td>   <td>2018-09-28</td>   <td>本发明公开了一种基于Verilog的判题装置,包括录入模块、处理模块、判定模块以及输出模块,可以对用户输入的Verilog答案信息进行仿真处理并进行判定,最后通过输出模块将判定结果输出到用户,可以实现对Verilog硬件语言作业的自动判题；本发明采用的一种基于Verilog的判题方法,可以对Verilog答案信息进行自动判题,同时还能对仿真结果中的波形信息进行转换,从而将对波形信息的对比转换成其他形式的信息的对比,方便判题,可以减少教师的工作量；本发明的一种基于Verilog的判题系统,包括浏览器、处理器和寄存器,可以实现对Verilog答案信息的自动判题,并且可以通过浏览器在任意地方上传Verilog答案信息。</td>   <td>1.一种基于Verilog的判题装置,其特征在于：包括用于接收用户的Verilog答案信息的录入模块(1)、用于对用户的Verilog答案信息进行仿真处理的处理模块(2)、预设参数的判定模块(3)以及将判定结果传输到用户的输出模块(4),所述录入模块(1)将接收的Verilog答案信息传输到处理模块(2),处理模块(2)对Verilog答案信息进行处理后传输到判定模块(3),判定模块(3)根据预设参数对处理后的Verilog答案信息进行判定后通过输出模块(4)输出。</td>   <td>G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              朱普良;                   郑贵锋       </td>   <td>中山大学</td>   <td>一种基于深度学习的人脸漫画生成方法及其装置</td>   <td>广东</td>   <td>CN108596839A</td>   <td>2018-09-28</td>   <td>本发明公开开了一种基于深度学习的人脸漫画生成方法及其装置,其中,该方法包括：获取个人图像,标定出77个人脸特征点；进行重新估计及旋转操作,获得含有正面标准姿态人脸的图像；根据其图像构建人脸矩形框；并等比放大三倍、进行裁剪,构建人头图像块；同时,裁剪出人脸矩形框对应图像,进行归一化处理,并依次送入预先训练好的人脸及五官属性多标签分类深度卷积神经预测网络,获得人脸的性别及五官属性标签；根据人脸的性别及五官属性标签、人头图像块及人脸矩形框对应图像,在漫画素材库中选择相应的素材,进行相应形变处理,获得五官、头发及人脸肤底的漫画素材；然后进行拼接处理,最终获得漫画图像。在本发明实施例中,能够实现智能化人脸漫画的绘制,不惜要任何的人工辅助。</td>   <td>1.一种基于深度学习的人脸漫画生成方法,其特征在于,所述方法包括：获取个人图像,在照片中标定出77个人脸特征点；根据标定的36号左眼眼球特征点和39号右眼眼球特征点对图像中的人脸倾斜角度进行估计处理,通过计算出的倾斜角度对原图像进行旋转操作,使得36号左眼眼球特征点和39号右眼眼球特征点达到水平位置,即获得含有正面标准姿态人脸的图像；获取含有正面标准姿态人脸图像,标定出其图像中77个特征点,从中获取2号、12号、15号和17号四个特征点,构建人脸矩形框；将人脸矩形框按中心不变的方式等比放大三倍,并将其放大后的矩形框圈定的图像区域进行裁剪,构建人头图像块；获取含有正面标准姿态人脸照片中的77个特征点,裁剪出人脸中五官的所在矩形区域,进行归一化处理,并依次送入预先训练好的人脸及五官属性多标签分类深度卷积神经预测网络,获得人脸的性别及五官属性标签；根据人脸的性别及五官属性标签,在漫画素材库中选择相应的五官素材,以输入的对应真实图片为参考,对选定素材进行相应形变处理,获得对应生成的五官漫画素材；对所述人头图像块进行计算、分割处理,获得头发精分割区域,结合所述人脸性别属性,在漫画素材库中选出相应的头发素材,以输入的对应真实图片为参考,对选定的头发漫画素材进行相应形变处理,获得对应生成的头发漫画素材；获取所述人脸矩形框,结合所述人脸性别属性,在相应的漫画素材库中选出人脸肤底素材,进行形变处理,获得对应生成的人脸肤底漫画素材；结合所述的五官漫画素材、头发漫画素材、人脸肤底漫画素材,按照原真实照片中对应所在位置进行拼接处理,最终获得漫画图像。</td>   <td>G06T3/60;G06T7/11;G06T3/40;G06N3/08;G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              任创杰;              成慧;              王青;                   王可泽       </td>   <td>中山大学</td>   <td>一种用于卷积神经网络的特征图增强系统及方法</td>   <td>广东</td>   <td>CN108596865A</td>   <td>2018-09-28</td>   <td>本发明公开了一种用于卷积神经网络的特征图增强系统及方法,该系统包括：内置特征图单元,用于存储训练样本之间的本质共性特征；输入控制器,基于原输入特征图及以往的内置特征图,整合两者的特征信息,进行一系列卷积操作,得到一个与内置特征图大小一致的输入控制器的中间特征图；特征图控制器,以原输入特征图以及以往内置特征图作为输入,进行一系列卷积操作,得到一个与内置特征图大小一致的特征图控制器的中间特征图,结合所述输入控制器的中间特征图,并以β参数来控制两者的表达能力,得到最新的内置特征图表达；输出控制器,以最新内置特征图以及原输入特征图作为输入,通过卷积操作以及对最新内置特征图的特征提取,得到辅助特征图输出。</td>   <td>1.一种用于卷积神经网络的特征图增强系统,包括：内置特征图单元,用于存储训练样本之间的本质共性特征；输入控制器,基于原输入特征图x以及以往的内置特征图Mt#1,整合两者的特征信息,进行一系列卷积操作,得到一个与内置特征图大小一致的输入控制器的中间特征图；特征图控制器,以原输入特征图x以及以往内置特征图Mt#1作为输入,进行一系列卷积操作,得到一个与内置特征图大小一致的特征图控制器的中间特征图,结合所述输入控制器的中间特征图,并以β参数来控制两者的表达能力,得到最新的内置特征图Mt表达；输出控制器,在得到最新内置特征图表达Mt的情况下,以最新内置特征图Mt以及原输入特征图x作为输入,通过卷积操作以及对最新内置特征图的特征提取,得到辅助特征图输出。</td>   <td>G06T5/50;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         云径平;                   王智       </td>   <td>中山大学肿瘤防治中心</td>   <td>病理图片的识别方法及装置</td>   <td>广东</td>   <td>CN108596882A</td>   <td>2018-09-28</td>   <td>本发明公开了一种病理图片的识别方法及装置,其中该方法包括：获得样本数据,所述样本数据包括正样本和负样本,所述正样本为恶性病变病理图片,所述负样本为正常或良性病变病理图片,所述恶性病变病理图片上标记出病变区域；将所述样本数据划分为训练集和测试集；利用所述训练集对深度神经网络模型进行训练；利用所述测试集对训练好的深度神经网络模型进行测试；根据测试结果对训练好的深度神经网络模型进行参数调整；利用训练好的深度神经网络模型对病理图片进行识别。本发明可以提高病理图片识别的效率和准确率。</td>   <td>1.一种病理图片的识别方法,其特征在于,包括：获得样本数据,所述样本数据包括正样本和负样本,所述正样本为恶性病变病理图片,所述负样本为正常或良性病变病理图片,所述恶性病变病理图片上标记出病变区域；将所述样本数据划分为训练集和测试集；利用所述训练集对深度神经网络模型进行训练；利用所述测试集对训练好的深度神经网络模型进行测试；根据测试结果对训练好的深度神经网络模型进行参数调整；利用训练好的深度神经网络模型对病理图片进行识别。</td>   <td>G06T7/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈树超;              陈洪波;              刘立志;              黎浩江;              徐绍凯;              傅嘉文;                   朱志华       </td>   <td>桂林电子科技大学;中山大学</td>   <td>一种胸部CT图像中的食管癌分割方法</td>   <td>广西</td>   <td>CN108596884A</td>   <td>2018-09-28</td>   <td>本发明公开了一种胸部CT图像中的食管癌分割方法,首先选取多组含有食管癌的CT图像,将含有食管癌的CT图像作为训练样本；对选取的CT图像进行预处理,获取食管癌特征,并进行特征描述后,得到的图像作为训练数据；建立基于全卷积神经网络的食管癌语义分割模型,将描述后的食管癌特征作为全卷积神经网络的特征输入作为学习样本进行训练,得到食管癌分割网络模型；食管癌的三维重建,对得到的食管癌分割网络模型所得到的食管癌分割结果进行三维重建和分析,得到三维空间下的食管癌影像组学参数；将得到的食管癌影像组学参数进行可视化显示。该方法模型规模小,速度快,准确度高。</td>   <td>1.一种胸部CT图像中的食管癌分割方法,其特征在于,具体包括如下步骤：1)选取多组含有食管癌的CT图像,将含有食管癌的CT图像作为训练样本,并作为步骤3)的数据范围；2)对步骤1)选取的CT图像进行预处理,获取食管癌特征,并进行特征描述后,得到的图像作为步骤3)的训练数据；3)建立基于全卷积神经网络的食管癌语义分割模型,将步骤2)描述后的食管癌特征作为全卷积神经网络的特征输入,作为学习样本进行训练,得到食管癌分割网络模型；4)食管癌的三维重建,对步骤3)得到的食管癌分割网络模型所得到的食管癌分割结果进行三维重建和分析,得到三维空间下的食管癌影像组学参数,参数为步骤5)做准备；5)将步骤4)得到的食管癌影像组学参数进行可视化显示。</td>   <td>G06T7/00;G06T7/11;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              陈泽宇;                   卓嘉璇       </td>   <td>中山大学</td>   <td>基于循环对抗生成网络的行人图像遮挡检测方法</td>   <td>广东</td>   <td>CN108573222A</td>   <td>2018-09-25</td>   <td>本发明公开了一种基于循环对抗生成网络的行人图像遮挡检测方法,步骤：(1)在无遮挡的行人图像中随机加入遮挡图像块,生成带遮挡的行人图像及对应的带遮挡标注的行人图像；(2)将上述带遮挡的行人图像及对应的带遮挡标注的行人图像作为两个数据域,训练循环对抗生成网络模型,构建遮挡图像与遮挡标注之间的映射；(3)对于当前输入的待标注图像,利用训练后的循环对抗生成网络模型去产生该图像对应的遮挡标注,同时对待标注图像进行分割,得到若干个超像素块,根据每个超像素块内遮挡标注的信息,采用区域生长方法得到最终的遮挡区域。本发明方法可以在缺少遮挡标注的情况下,针对不同类型的遮挡进行建模,得到像素级别的遮挡区域检测结果。</td>   <td>1.基于循环对抗生成网络的行人图像遮挡检测方法,其特征在于,包括步骤：(1)在无遮挡的行人图像中随机加入遮挡图像块,生成带遮挡的行人图像及对应的带遮挡标注的行人图像；所述的遮挡标注是指人为设定的遮挡图像块或者原图自带的遮挡物体在行人图像中的区域；(2)将上述带遮挡的行人图像及对应的带遮挡标注的行人图像作为两个数据域,训练循环对抗生成网络模型,构建遮挡图像与遮挡标注之间的映射；(3)对于当前输入的待标注图像,利用训练后的循环对抗生成网络模型去产生该图像对应的遮挡标注,同时对待标注图像进行分割,得到若干个超像素块,根据每个超像素块内遮挡标注的信息,采用区域生长方法得到最终的遮挡区域。</td>   <td>G06K9/00;G06K9/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林俊浩;                   周育人       </td>   <td>中山大学</td>   <td>一种基于MPI的分布式差分进化算法及装置</td>   <td>广东</td>   <td>CN108573338A</td>   <td>2018-09-25</td>   <td>本发明公开一种基于MPI的分布式差分进化算法,其包括如下步骤：采用Master#Slave模型,将N+1个计算核心分为一个Master节点和N个Slave节点；每个Slave节点负责计算用户定义的函数Fitness；及Master节点用于运行差分进化算法进行分配计算任务的工作。本发明还公开了一种用于求解最优化的基于MPI的分布式差分进化系统,用于实现上述方法。本发明此算法可以使任务在有限的资源下以最短的时间完成,且具有高鲁棒性和容错能力,本发明的运算结果,和单机的运行结果一致,保证了原算法的能力不退化,并且差分进化算法基本不用改动,易于替换成新的进化算法,方便用户选择不同的进化算法。</td>   <td>1.一种基于MPI的分布式差分进化算法,其特征在于,包括如下步骤：S10采用Master#Slave模型,将N+1个计算核心分为一个Master节点和N个Slave节点；S20每个Slave节点负责计算Fitness的值；及Master节点用于运行差分进化算法进行分配计算任务的工作。</td>   <td>G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              刘力;              李亮;              徐琰;              郭斌;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种超高分辨率病理图像癌变区域可视化方法</td>   <td>广东</td>   <td>CN108564567A</td>   <td>2018-09-21</td>   <td>本发明提供一种超高分辨率病理图像癌变区域可视化方法,首先,使用阈值最优算法识别待测超高分辨率病理图像的组织区域,并从组织区域有重叠地提取切片,达到剔除无关背景降低计算量及避免引入噪声的目的。其次,把提取的切片输入已持久化的深度神经网络模型进行预测,将预测得到的每张切片的概率构成概率矩阵Mp。而后,基于概率矩阵生成概率探针图像H,从H提取特征训练一个分类模型进行全图预测。最后,基于全图预测结果,将概率探针图像H可视化为癌变区域概率表达及癌变区域轮廓表达。本发明提供的癌变区域可视化方法用于辅助病理医生对病理切片进行分析和诊断,将极大地减轻病理医生的工作负担,提高诊断准确率。</td>   <td>1.一种超高分辨率病理图像癌变区域可视化方法,其特征在于,包括以下步骤：S1：兴趣区域切片提取：采用基于像素RGB值的阈值最优算法将所述图像划分为组织区域和无关背景区域,对组织区域进行分割并提取切片；S2：模型预测及概率矩阵构建：将所述小切片输入卷积神经网络模型进行前向传播获得每张小切片的癌变概率,将所得概率按预设更新方法构建概率矩阵；S3：全图预测：基于概率探针图像对超高分辨率病理图像进行全图预测,划分为阳性和阴性两类；S4：预测结果可视化：基于全图预测结果,将概率探针图像映射得到癌变区域概率表达及癌变区域轮廓表达。</td>   <td>G06T7/00;G06T7/11;G06T7/136;G06T7/194</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卓汉逵;                   纪登林       </td>   <td>中山大学</td>   <td>基于HRED和内外记忆网络单元的情感对话生成方法</td>   <td>广东</td>   <td>CN108563628A</td>   <td>2018-09-21</td>   <td>本发明提供一种基于HRED和内外记忆网络单元的情感对话生成方法,该方法通过构建特殊的情感聊天对话语料和提出一种基于层次循环神经网络和内外记忆单元的情感对话生成模型来解决情感因素在大规模多轮对话中的嵌入和应用。内部记忆网络的提出提高了情感表达和语法表达之间的自动均衡,外部记忆网络的提出增加了情感的显式表达,使得模型生成的回答更具情感信息。</td>   <td>1.一种基于HRED和内外记忆网络单元的情感对话生成方法,其特征在于,包括以下步骤：S1：准备情感对话系统数据；S2：对于S1得到的数据集若是单轮对话,利用该单轮对话数据集对编码#解码模型进行训练,其中在解码模块中添加预先训练的情感类别的词向量以及内外记忆单元,模型训练完毕后进行测试；S3：对于S1中得到的数据集若是多轮对话,利用该多轮对话数据集采用层次循环神经网络模型进行训练,将每轮对话的中间上下文向量与该轮对话的情感向量拼接作为输入另构建一层循环神经网络,模型训练完毕后进行测试,给定一句话和接下来两句话的情感标签,可以生成接下来两轮对话的语句。</td>   <td>G06F17/27;G06F17/30;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         易敬之;              孙伟;                   卢伟       </td>   <td>中山大学</td>   <td>一种基于面向对象聚类的协同过滤推荐方法</td>   <td>广东</td>   <td>CN108563690A</td>   <td>2018-09-21</td>   <td>本发明提供一种基于面向对象聚类的协同过滤推荐方法,包括以下步骤：读取用户对物品的历史评分数据、物品类型数据信息；通过优化的PMF模型生成用户评分预测矩阵；计算用户偏置因子、物品偏置因子、类型偏置因子,生成偏置因子预测矩阵；构建面向对象的特征样本,对面向对象的特征样本进行聚类编号,生成面向对象聚类结果；构建用户偏好矩阵；更新用户偏好矩阵中的偏好指标值,产生推荐列表。本发明提供的一种基于面向对象聚类的协同过滤推荐方法,使用偏好指标表示用户对物品兴趣度的推荐策略,同时,通过引入面向对象之间的相似性关系,缓解传统矩阵分解模型预测准确度不佳而造成推荐效果不理想的问题,提升推荐系统的推荐效果,并且该推荐方法可适用于多种场景。</td>   <td>1.一种基于面向对象聚类的协同过滤推荐方法,其特征在于,包括以下步骤：S1：读取用户对物品的历史评分数据、物品类型数据信息；S2：根据用户对物品的历史评分数据,通过优化的PMF模型生成用户评分预测矩阵；S3：根据用户对物品的历史评分数据、物品类型信息数据,计算用户偏置因子、物品偏置因子、类型偏置因子,生成偏置因子预测矩阵；S4：利用物品类型信息构建面向对象的特征样本,并利用K#means聚类方法对面向对象的特征样本进行聚类编号,生成面向对象聚类结果；S5：利用用户评分预测矩阵以及偏置因子预测矩阵,构建用户偏好矩阵；S6：根据面向对象聚类结果,更新用户偏好矩阵中的偏好指标值,根据更新后的用户偏好指标值产生推荐列表。</td>   <td>G06F17/30;G06Q30/06;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;                   姚伟斌       </td>   <td>中山大学</td>   <td>基于知识网络的以用户为中心的教学资源组织与服务系统</td>   <td>广东</td>   <td>CN108564499A</td>   <td>2018-09-21</td>   <td>本发明为基于知识网络的以用户为中心的教学资源组织与服务系统,包括从下往上架设的持久化层、服务层和接口层；服务层包括知识网络地图模块、用户模块和教学资源支撑模块；用户模块用于管理和维护不同用户的个人信息及不同用户间的交互与业务需求关系；知识网络地图模块用于构建基于知识点的三维网状图形结构,形成知识网络；教学资源支撑模块负责教学资源的存储和管理,支撑教学资源在不同用户之间的组织与表达。本系统针对用户特性需求,实现教学资源对不同用户角色进行表达,并实现资源在不同用户之间的传递与表达。</td>   <td>1.基于知识网络的以用户为中心的教学资源组织与服务系统,其特征在于,包括从下往上架设的持久化层、服务层和接口层；其中持久化层包括缓存和数据库连接层,通过数据库连接层与数据库连接,通过缓存与服务层连接；服务层包括知识网络地图模块、用户模块和教学资源支撑模块,用户模块分别与知识网络地图模块、教学资源支撑模块连接；接口层包括权限监控过滤器和请求派发器,权限监控模块与服务层连接,请求派发器用于接收用户的请求,并对请求进行派发；用户模块用于管理和维护不同用户的个人信息及不同用户间的交互与业务需求关系；知识网络地图模块用于构建基于知识点的三维网状图形结构,形成知识网络；教学资源支撑模块负责教学资源的存储和管理,支撑教学资源在不同用户之间的组织与表达。</td>   <td>G06Q50/20;G06N5/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   张泽昕       </td>   <td>中山大学</td>   <td>基于深度神经网络的特征点提取方法</td>   <td>广东</td>   <td>CN108564120A</td>   <td>2018-09-21</td>   <td>本发明公开了一种基于深度神经网络的特征点提取方法,包括：数据生成,利用OpenCV随机生成不同基础图形,同时对于有角点的图形记录角点的位置作为后续训练的标签；训练深度神经网络,利用数据生成的训练集训练网络模型,来检测角点的产生；测试,利用深度神经网络训练好的模型,对OpenCV生成的数据集和互联网上下载到的真实数据集进行测试,评估该算法的性能表现。本发明减少了深度学习标注特征点数据集的难度,同时用良好的深度神经网络结构提高了提取的稳定性。</td>   <td>1.一种基于深度神经网络的特征点提取方法,其特征在于包括以下步骤：数据生成,利用OpenCV随机生成不同基础图形,同时对于有角点的图形记录角点的位置作为后续训练的标签；训练深度神经网络,利用数据生成的训练集训练网络模型,来检测角点的产生；测试,利用深度神经网络训练好的模型,对OpenCV生成的数据集和互联网上下载到的真实数据集进行测试,评估该算法的性能表现。</td>   <td>G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;              叶国桥;                   黄宇韬       </td>   <td>中山大学</td>   <td>一种基于FPGA的低能耗社区挖掘方法</td>   <td>广东</td>   <td>CN108563748A</td>   <td>2018-09-21</td>   <td>本发明涉及一种基于FPGA的低能耗社区挖掘方法,包括以下步骤：S1.将大型网络抽象成一个图,初始化系统参数,设置遍历节点的半径阈值；S2.遍历还没有被访问过的节点,根据节点半径的阈值,选择输入到FPGA的数据,从而建立起基于FPGA的数据结构；将该节点设置为社区圈子的种子,从该节点出发进行扩展圈子；S3.不断扩展该节点,采用基于FPGA的节点遍历函数、基于FPGA的导率计算函数,使用FPGA的查找表结构标记节点的访问状态,当社区圈子的导率无法再减小时,社区扩展完毕,将社区圈子加入到社区圈子集合；S4.判断节点访问状态,如果仍有节点没有被访问,跳到步骤S2,否则进入步骤S5；S5.输出挖掘出来的社区圈子。</td>   <td>1.一种基于FPGA的低能耗社区挖掘方法,其特征在于：包括以下步骤：S1.将大型网络抽象成一个图,初始化系统参数,设置遍历节点的半径阈值；S2.遍历还没有被访问过的节点,根据节点半径的阈值,选择输入到FPGA的数据,从而建立起基于FPGA的数据结构；将该节点设置为社区圈子的种子,从该节点出发进行扩展圈子；S3.不断扩展该节点,采用基于FPGA的节点遍历函数、基于FPGA的导率计算函数,使用FPGA的查找表结构标记节点的访问状态,当社区圈子的导率无法再减小时,社区扩展完毕,将社区圈子加入到社区圈子集合；S4.判断节点访问状态,如果仍有节点没有被访问,跳到步骤S2,否则进入步骤S5；S5.输出挖掘出来的社区圈子。</td>   <td>G06F17/30;G06Q50/00;G06F15/78;G06F9/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;                   王成成       </td>   <td>中山大学</td>   <td>基于多维度信息和知识网络的在线教育系统资源推荐方法</td>   <td>广东</td>   <td>CN108563749A</td>   <td>2018-09-21</td>   <td>本发明提供基于多维度信息和知识网络的在线教育系统资源推荐方法,包括以下步骤：构建精准在线教育系统；设计知识网络管理引擎；基于知识网络管理引擎搭建知识网络；依托于知识网络,以知识元为单位,多渠道构建资源库；资源库支持以知识元为单位存储的资源单元；根据资源单元特征和用户使用统计特征对资源单元的质量进行量化,获取资源单元的质量量化特征；获取资源单元的可用性量化特征；根据资源单元的质量量化特征和资源单元的可用性量化特征,计算资源单元的推荐指数；根据学习者聚焦点不同,进行资源单元排序的动态调整。本发明依据资源单元排序,区分热点资源和非热点资源,提升用户体验,减少在线学习系统的建设及运维成本。</td>   <td>1.基于多维度信息和知识网络的在线教育系统资源推荐方法,其特征在于,包括以下步骤：S1、构建精准在线教育系统,所构建的在线教育系统包括知识网络管理引擎、知识网络、基于角色的用户管理子系统、由不同资源者提供的围绕知识网络中的知识元而构建的资源单元；所有资源单元形成系统教学资源；其中,知识元包括知识点、知识子网及知识点簇,知识子网包含以知识点集为起点或终点所涉及的所有学习路径下其它知识点及这些知识点之间的关系,知识点簇由一系列未能形成直接连通的知识子网的知识点构成；知识点按照系统设定的关系与其关联的知识点连接,形成三维的知识网络；S2、设计知识网络管理引擎,用于实现知识点的加入、删除、修改；知识元的标注；知识点与知识元的存储；资源单元与知识元的关联；S3、基于知识网络管理引擎搭建知识网络；S4、依托于知识网络,以知识元为单位,多渠道构建资源库；资源库支持以知识元为单位存储的资源单元；S5、根据资源单元特征和用户使用统计特征对资源单元的质量进行量化,获取资源单元的质量量化特征；S6、获取资源单元的可用性量化特征；S7、根据资源单元的质量量化特征和资源单元的可用性量化特征,计算资源单元的推荐指数；S8、根据学习者聚焦点不同,进行资源单元排序的动态调整。</td>   <td>G06F17/30;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         钱哲;              万嘉;              刘伟;              张东;                   安东·埃迪斯·博登       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于柔性传感器的人体坐姿识别方法及其系统</td>   <td>广东</td>   <td>CN108549834A</td>   <td>2018-09-18</td>   <td>本发明公开了一种基于柔性传感器的人体坐姿识别方法,先采集用户背部的弯曲数据,并对弯曲数据进行预处理以及特征提取,接着利用已训练好的误差反向传播的人工神经网络对特征向量进行识别即可得到识别结果,然后可以将识别结果传输到用户的智能终端；本发明的一种基于柔性传感器的人体坐姿识别系统,采用柔性传感器对用户背部的弯曲数据进行检测,利用设置了误差反向传播的人工神经网络的分类识别单元对处理后的弯曲数据进行识别即可得到最终的识别结果,并通过无线通信单元将识别结果传输到用户的智能终端,由于采用柔性传感器进行检测,结构简单,检测方便。</td>   <td>1.一种基于柔性传感器的人体坐姿识别方法,其特征在于：包括以下步骤：A、柔性传感器(11)采集用户背部的弯曲数据；B、对用户背部的弯曲数据进行预处理；C、对处理后的弯曲数据进行特征提取并组成特征向量；D、将特征向量分为训练集和测试集,构建误差反向传播的人工神经网络模型,利用训练集以及测试集对误差反向传播的人工神经网络进行训练；E、利用已训练好的误差反向传播的人工神经网络对待识别用户背部的弯曲数据的特征向量进行识别,并得到识别结果；F、将识别结果传输到智能终端。</td>   <td>G06K9/00;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李坚波;              路韬;              虞志益;                   欧阳明       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于深度学习的快速迭代目标检测方法</td>   <td>广东</td>   <td>CN108549901A</td>   <td>2018-09-18</td>   <td>本发明公开了一种基于深度学习的快速迭代目标检测方法,利用卷积神经网络、RPN网络和Fast#R#CNN网络的设计,并采用预设好的RPN网络实现忽略区域的去除,在加快数据标记的同时,保证了模型训练的有效性,可提高目标检测精确率；通过去除训练数据集中的忽略区域,从而免去对数据集中的无效数据进行训练；并且对于深度学习目标检测模型进行结果判断及多次扩充训练,可进一步提高深度学习的目标检测精确率。相对于传统目标检测方法,本发明的成本低且目标检测精确率高,可节约大量人力和时间,实现快速的目标检测,同时有效增强了目标检测的鲁棒性。</td>   <td>1.一种基于深度学习的快速迭代目标检测方法,其特征在于,包括以下步骤：S1、获取图像并进行标记处理,得到训练数据集；S2、对所述训练数据集中的标记区域进行聚类,得到聚类信息；S3、构建卷积神经网络、RPN网络和Fast#R#CNN网络；S4、根据所述聚类信息预设RPN网络并利用RPN网络去除训练数据集中的忽略区域,所述的忽略区域为相对于标记区域中图像清晰的区域的图像模糊区域或图像密集区域；S5、训练所述的训练数据集,得到深度学习目标检测模型；S6、判断所述的深度学习目标检测模型是否符合标准,若符合,则得到最终的深度学习目标检测模型,否则执行步骤S7；S7、扩充训练数据集的容量并进行忽略区域二次剔除处理,执行步骤S5。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              何炜雄;                   谢晓华       </td>   <td>中山大学</td>   <td>基于深度网络增强的特定场景下行人检测器自动学习方法</td>   <td>广东</td>   <td>CN108549852A</td>   <td>2018-09-18</td>   <td>本发明公开了一种基于深度网络增强的特定场景下行人检测器自动学习方法,步骤是：在服务器端使用通用的数据集训练出第一神经网络和第二神经网络,第二神经网络部署到嵌入式设备中；通过嵌入式设备对当前场景的图像进行捕捉,获得新增图像样本,传送到服务器端；在服务器端利用之前训练好的第一神经网络对新增图像样本进行测试,根据测试得分对样本进行标注；估计当前高度行人检测框的大小,剔除正样本中检测框和估计的大小有明显差异的样本,保留剩余样本；服务器端对第二神经网络进行调优；将调优后的第二神经网络模型从服务器端重新部署到嵌入式设备中。本发明可以在特定场景下快速得到精准的行人检测模型。</td>   <td>1.基于深度网络增强的特定场景下行人检测器自动学习方法,其特征在于,包括步骤：(1)在服务器端使用通用的数据集训练出第一神经网络和第二神经网络,第二神经网络用于部署到嵌入式设备中；(2)通过嵌入式设备在进行行人检测的工作过程中,对当前场景的图像进行捕捉,获得新增图像样本,传送到服务器端；(3)在服务器端利用之前训练好的第一神经网络对新增图像样本进行测试,利用第一神经网络的测试得分对样本进行标注；(4)对嵌入式设备当前高度下行人检测框的大小进行估计,计算正样本中检测框和估计的行人检测框的差异值,若差异值超过阈值,则进行剔除,保留剩余样本；(5)服务器端利用上述剩余样本对第二神经网络进行调优；(6)将调优后的第二神经网络模型从服务器端重新部署到嵌入式设备中。</td>   <td>G06K9/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;              叶国桥;              吴展鹏;                   陈润源       </td>   <td>中山大学</td>   <td>一种面向大规模复杂网络的密集可重叠社区划分方法</td>   <td>广东</td>   <td>CN108537452A</td>   <td>2018-09-14</td>   <td>本发明涉及一种面向大规模复杂网络的密集可重叠社区划分方法,包括以下步骤：S1.将大型网络抽象成一个无向图,初始化系统参数,包括设置初始社区圈子集合为空集,设置迭代停止条件；S2.遍历还没有被访问过的节点,并将该节点设置为社区圈子的种子,从该节点出发进行扩展圈子；并使用优先队列来维护该节点的可扩展的节点集合,该优先队列维护邻居节点,并且不断更新；S3.不断扩展该节点,当社区圈子的导率无法再减小或者已达到迭代停止条件时,社区扩展完毕,将社区圈子加入到社区圈子集合；S4.判断所有节点是否都已经访问完毕,如果没有,跳到步骤S2,否则进入S5；S5.输出社区圈子集合,算法结束。</td>   <td>1.一种面向大规模复杂网络的密集可重叠社区划分方法,其特征在于：包括以下步骤：S1.将大型网络抽象成一个无向图,初始化系统参数,包括设置初始社区圈子集合为空集,设置迭代停止条件；S2.遍历还没有被访问过的节点,并将该节点设置为社区圈子的种子,从该节点出发进行扩展圈子；并使用优先队列来维护该节点的可扩展的节点集合,该优先队列维护邻居节点,并且不断更新；S3.不断扩展该节点,当社区圈子的导率无法再减小或者已达到迭代停止条件时,社区扩展完毕,将社区圈子加入到社区圈子集合；S4.判断所有节点是否都已经访问完毕,如果没有,跳到步骤S2,否则进入S5；S5.输出社区圈子集合,算法结束。</td>   <td>G06Q10/06;G06Q50/00;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              陈浩钧;              王青;                   江波       </td>   <td>中山大学</td>   <td>一种弱交互式的物体检测深度学习方法及其系统</td>   <td>广东</td>   <td>CN108537269A</td>   <td>2018-09-14</td>   <td>本发明公开了一种弱交互式的物体检测深度学习方法及系统,该方法包括：步骤S1,选取一些无标签数据进行物体识别的人工标注,并与公开的数据集组合成初始数据集；步骤S2,选定一深度学习模型,利用步骤S1中的有标签数据对模型进行训练；步骤S3,利用训练得到的模型对初始数据集的无标签数据及有标签数据进行特征提取；步骤S4,将特征进行组合,建立特征矩阵,利用有标签的数据对无标签数据进行标签映射,将标签映射到无标签数据中,完成对无标签数据的标注；步骤S5,根据步骤S4的结果与步骤S1中的有标签数据组合成一个新的有标签数据训练集；步骤S6,利用新的有标签数据训练集重复对模型训练,直至模型表现达到预期效果为止。</td>   <td>1.一种弱交互式的物体检测深度学习方法,包括：步骤S1,选取一些无标签数据进行物体识别的人工标注,并与一些公开的数据集组合成初始数据集；步骤S2,选定一深度学习模型,利用步骤S1中的有标签数据对所述深度学习模型进行模型训练；步骤S3,利用步骤S2训练得到的模型对步骤S1获得的初始数据集中的无标签数据及有标签数据分别进行特征提取；步骤S4,于得到无标签数据以及有标签数据的特征后,将特征进行组合,建立特征矩阵,并利用有标签的数据对无标签数据进行标签映射,将标签映射到无标签数据中,完成对无标签数据的标注；步骤S5,根据步骤S4的结果与步骤S1中的有标签数据组合成一个新的有标签数据训练集。步骤S6,利用新的有标签数据训练集重复步骤S2#S5对所述深度学习模型再次训练,直至模型表现达到预期效果为止。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈俊豪;                   潘炎       </td>   <td>中山大学</td>   <td>一种基于人脸特征点和光流场的人脸识别活体检测方法</td>   <td>广东</td>   <td>CN108537131A</td>   <td>2018-09-14</td>   <td>本发明提供一种基于人脸特征点和光流场的人脸识别活体检测方法,采用卡方检验作为活体检测的依据,真实人脸在人脸特征点的运动方向与脸部整体运动方向有明显的不一致性；而照片无论怎样运动,人脸特征点的运动方向与脸部整体运动方向基本一致。本发明使用卡方检验计算人脸特征点的光流场方向的直方图分布和眼球区域的光流场方向的直方图分布的相似程度。若卡方检验值超过阈值,则判定为活体,否则判定为非活体。</td>   <td>1.一种基于人脸特征点和光流场的人脸识别活体检测方法,其特征在于,包括以下步骤：S1：人脸检测；S2：得到人脸特征点以及眼球区域；S3：计算相邻两帧的人脸特征点和眼球区域的光流场；S4：计算人脸特征点和眼球区域关于光流场方向的直方图分布；S5：活体检测。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周晓聪;                   尹林枫       </td>   <td>中山大学</td>   <td>一种数据库模式的数据表重构方法、装置及系统</td>   <td>广东</td>   <td>CN108536758A</td>   <td>2018-09-14</td>   <td>本发明公开一种数据库模式的数据表重构方法、装置及系统,其中,该方法包括租户将数据输入在Universal#Table#Layout数据库模式中的数据表mt<sub>d</sub>ata中,每行数据记录匹配一个租户ID和表ID,所述租户ID用以标识租户身份,所述表ID用以标识当前租户的数据表名称；将数据表mt<sub>d</sub>ata划分为与租户ID值一一对应的每个租户的数据表；将每个租户的数据表按照表ID划分,且所划分的数据表中部分表之间存在外键约束；根据存在的外键约束生成数据表间的有向图；从有向图中的所有路径中剔除被包含路径,由此获得有纯净路径的有向图；将有向图中的每条纯净路径上的数据划分为一个数据表,重构数据库。本发明最大程度地避免数据跨库连接操作。</td>   <td>1.一种数据库模式的数据表重构方法,其特征在于,包括如下步骤：S10；租户将数据输入在Universal#Table#Layout数据库模式中的数据表mt_data中,每行数据记录匹配一个租户ID和表ID,所述租户ID用以标识租户身份,所述表ID用以标识当前租户的数据表名称；S20将数据表mt_data划分为与租户ID值一一对应的每个租户的数据表；S30将每个租户的数据表按照表ID划分,且所划分的数据表中部分表之间存在外键约束；S40根据存在的外键约束生成数据表间的有向图；S50从有向图中的所有路径中剔除被包含路径,由此获得有纯净路径的有向图；S60将有向图中的每条纯净路径上的数据划分为一个数据表,重构数据库。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         许志明;              鲁鹏程;              刘少江;              倪伟传;                   万智萍       </td>   <td>中山大学新华学院</td>   <td>基于改进差分阈值和位移匹配模型的移动车辆跟踪方法</td>   <td>广东</td>   <td>CN108520528A</td>   <td>2018-09-11</td>   <td>本发明公开了基于改进差分阈值和位移匹配模型的移动车辆跟踪方法,包括以下步骤：获取至少两个图像帧,以相邻的两个图像帧中前一图像帧为匹配模板,后一图像帧为检测模板；对匹配模板上的运动区域进行检测,获取参考目标并进行标识；对检测模板上的运动区域进行检测,并与匹配模板上的参考目标进行比对得到检测目标在检测模板的位置；采用位移匹配模型确定参考目标和检测目标是否为同一目标；当检测目标与参考目标为同一目标时进行标识,否则不标识；重复上述步骤,对目标进行标识跟踪。本发明只检测并跟踪移动车辆；可以准确实时地跟踪多个移动车辆目标,在智能交通监控领域具有较好的应用前景。</td>   <td>1.基于改进差分阈值和位移匹配模型的移动车辆跟踪方法,其特征在于,包括以下步骤：获取至少两个图像帧,以相邻的两个图像帧中前一图像帧为匹配模板,后一图像帧为检测模板；对匹配模板上的运动区域进行检测,获取参考目标并进行标识；对检测模板上的运动区域进行检测,并与匹配模板上的参考目标进行比对得到检测目标在检测模板的位置；采用位移匹配模型确定参考目标和检测目标是否为同一目标；当检测目标与参考目标为同一目标时进行标识,否则不标识；重复上述步骤,对目标进行标识跟踪。</td>   <td>G06T7/246</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐晓颖;              邓丽洁;              袁进;                   黄海香       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学;中山大学中山眼科中心</td>   <td>超像素提取过渡期片状角膜溃烂区域的方法</td>   <td>广东</td>   <td>CN108510470A</td>   <td>2018-09-07</td>   <td>本发明公开了一种超像素提取过渡期片状角膜溃烂区域的方法,包括步骤：S1.图像预处理；S2.超像素分割；S3.超像素特征提取；S4.SVM分类；S5.分割结果自动修正。在超像素分割的基础上,结合基于支持向量机(SVM)的自动分类以及基于线性回归的自动形态运算,有效地解决了过渡期片状角膜溃烂难以精准分割的问题。该方法可以在数据不断更新与增多的过程中,实现对算法模型的自我更新和完善,来达到适应更多角膜溃烂类型的目的,也为其他相关检测的算法设计提供借鉴,为多类型角膜溃烂实现溃烂区域的自动提取以及基于人工智能的辅助诊断提供有力基础。</td>   <td>1.超像素提取过渡期片状角膜溃烂区域的方法,其特征在于,包括以下步骤：S1.图像预处理：对输入图像构建角膜椭圆模型进行分割,提取角膜区域图像,对角膜区域图像进行滤波去噪；S2.超像素分割：基于超像素分割算法,对角膜区域图像进行超像素分块；S3.超像素特征提取：对每一个超像素块所包含的像素点求R、G、B各通道以及坐标位置(X,Y)的均值,得到<img file="FDA0001578358340000011.TIF" wi="302" he="85"/>构建5维特征矩阵；S4.SVM分类：利用所提取的超像素特征,对每个超像素进行基于SVM线性分类器的自动分类,得到初步分割结果；S5.分割结果自动修正：基于SVM分类的初步分割结果,进行腐蚀或膨胀操作的形态运算,获得准确分割结果。</td>   <td>G06T7/00;G06T7/11;G06T7/155;G06T7/90;G06T5/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱伟伟;                   康显桂       </td>   <td>中山大学</td>   <td>一种基于PCA和分段RHT的PCB图像圆检测方法</td>   <td>广东</td>   <td>CN108510513A</td>   <td>2018-09-07</td>   <td>本发明公开了一种基于PCA和分段RHT的PCB图像圆检测方法,包括以下步骤：S1.载入原始彩色PCB板图像；S2.对图像进行灰度二值化,采用边缘检测算法提取图像边缘,除去交叉次数较多的点；S3.对灰度二值化图像中的线段进行标记,找出长度大于所设阈值t的线段；S4.对每条线段进行主成分分析,得到特征值,保留类圆曲线段；S5.对类圆曲线段进行圆拟合,得到粗略圆参数,在类圆曲线段中筛选出有效曲线段；S6.对有效曲线段进行分段圆检测,得到精确圆参数。本发明的优点在于,对圆的检测更加精确,对非圆曲线的去除更加有效,圆的参数误差更小,处理速度上也有优势。</td>   <td>1.一种基于PCA和分段RHT的PCB图像圆检测方法,其特征在于,包括以下步骤：S1.载入原始彩色PCB板图像；S2.对图像进行灰度二值化,采用边缘检测算法提取图像边缘,除去交叉次数较多的点；S3.对灰度二值化图像中的线段进行标记,找出长度大于所设阈值t的线段；S4.对每条线段进行PCA方向分析,得到特征值,保留类圆曲线段；S5.对类圆曲线段进行圆拟合,得到粗略圆参数,在类圆曲线段中筛选出有效曲线段；S6.对有效曲线段进行分段圆检测,得到精确圆参数。</td>   <td>G06T7/13;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>         于跃;              龙冬阳;              熊绘;                   甘加升       </td>   <td>中山大学</td>   <td>基于词性和多重CNN的多通道文本分类模型的构建方法</td>   <td>广东</td>   <td>CN108509520A</td>   <td>2018-09-07</td>   <td>本发明提供一种基于词性和多重CNN的多通道文本分类模型的构建方法,该方法对卷积神经网络进行训练时,所采用的方法依然是传统的梯度下降法。其中,若采用批量梯度下降法,虽然能够获得最好的收敛效果,但由于每次迭代过程都需要所有训练样本参与运算,严重制约训练过程的收敛速度；若采用随机梯度下降法,则每次迭代只需要一个样本,因此在训练速度方面具有明显的优势。</td>   <td>1.一种基于词性和多重CNN的多通道文本分类模型的构建方法,其特征在于,包括以下步骤：S1：对输入文本进行预处理；S2：对模型的输入进行处理；S3：构建模型；S4：对模型进行训练。</td>   <td>G06F17/30;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王颖杰;                   常会友       </td>   <td>中山大学</td>   <td>一种基于大数据分析的食品风味评定方法</td>   <td>广东</td>   <td>CN108509601A</td>   <td>2018-09-07</td>   <td>本发明涉及一种基于大数据分析的食品风味评定方法,包括以下步骤：S1.从数据库中加载气味信息数据和滋味信息数据并分别对两种数据进行结构化处理,处理成结构化的数据,分别记为气味信息向量和滋味信息向量；S2.训练线性模型；S3.训练深度神经网络模型；S4.评定食品风味等级,对需要进行风味评定的食品的气味信息数据和滋味信息数据进行结构化的处理,将气味信息向量输入到线性模型中,将滋味信息向量输入到深度神经网络模型中,分别得出气味评定等级k1和滋味评定等级k2,综合两个模型中的评定等级,得到最终的食品风味评定等级k。</td>   <td>1.一种基于大数据分析的食品风味评定方法,其特征在于：包括以下步骤：S1.从数据库中加载气味信息数据和滋味信息数据并分别对两种数据进行结构化处理,处理成结构化的数据,分别记为气味信息向量和滋味信息向量；S2.训练线性模型,将已经结构化的气味信息向量及其对应的人工感官评定等级分别作为线性模型的输入和输出,对线性模型进行多次的迭代训练,得到一个训练好的线性模型；S3.训练深度神经网络模型,将已经结构化的滋味信息向量及其对应的人工感官评定等级分别作为模型的输入和输出,对深度神经网络模型进行多次的迭代训练,得到一个训练好的深度神经网络模型；S4.评定食品风味等级,对需要进行风味评定的食品的气味信息数据和滋味信息数据进行结构化的处理,将气味信息向量输入到线性模型中,将滋味信息向量输入到深度神经网络模型中,分别得出气味评定等级k<sub>1</sub>和滋味评定等级k<sub>2</sub>,综合两个模型中的评定等级,得到最终的食品风味评定等级k,其表达式为<img file="FDA0001615480390000011.TIF" wi="350" he="71"/>θ<sub>1</sub>和θ<sub>2</sub>分别表示加权平均的参数,<img file="FDA0001615480390000012.TIF" wi="68" he="71"/>表示向下取整的符号。</td>   <td>G06F17/30;G06N3/04;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐志康;                   任江涛       </td>   <td>中山大学</td>   <td>一种基于图数据库的任务履历管理及分析方法</td>   <td>广东</td>   <td>CN108509614A</td>   <td>2018-09-07</td>   <td>本发明提供了一种基于图数据库的任务履历管理及分析方法,所述方法包括基础图构建、履历结构化、发现人物间复杂关系三个部分,其中本发明利用了图数据库便于存储关系的特性,避免了使用关系型数据库频繁的联动匹配操作,大大提高了关系查找效率,同时各个节点与现实中的实体一一对应,使得每个实体节点都便于访问和管理,实体节点的层级结构也可以方便地保存在图中,而且在特定的使用场景中,每个人物的信息确认及维护工作都可以交给其本人去完成,这将全面提升整个图数据的信息完整性、信息可靠性。</td>   <td>1.一种基于图数据库的任务履历管理及分析方法,其特征在于,所述方法包括以下步骤：S1.先构建基础图数据库；S2.再结构化履历信息并导入图数据库；S3.发现人物间复杂关系。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              郭佳明;                   周凡       </td>   <td>中山大学</td>   <td>一种在联合条件下进行群体着装解析的方法</td>   <td>广东</td>   <td>CN108509838A</td>   <td>2018-09-07</td>   <td>本发明实施例公开了一种在联合条件下进行群体着装解析的方法。其中,该方法包括：获取原始图片,采用粗分割网络对原始图片进行初步的着装解析处理,获得粗略的分割结果图片；将原始图片使用群体姿势估计网络,获取图片中前景人物的姿势骨架,生成姿势估计热度图；将粗略的分割结果图片及姿势估计热度图同时进行深度卷积处理,获得精细化的服装分割结果及姿势估计结果。实施本发明实施例,不仅能够处理单人简单场景,更能够解决群体的、复杂场景下的着装解析问题,扩展了着装解析的应用场景。</td>   <td>1.一种在联合条件下进行群体着装解析的方法,所述方法包括：获取原始图片,采用粗分割网络对原始图片进行初步的着装解析处理,获得粗略的分割结果图片；将原始图片使用群体姿势估计网络,获取图片中前景人物的姿势骨架,生成姿势估计热度图；将粗略的分割结果图片及姿势估计热度图同时进行深度卷积处理,获得精细化的服装分割结果及姿势估计结果。</td>   <td>G06K9/00;G06K9/62;G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              吴伟基;                   吴岸聪       </td>   <td>中山大学</td>   <td>基于轻量级网络的行人再识别系统及实现方法</td>   <td>广东</td>   <td>CN108491884A</td>   <td>2018-09-04</td>   <td>本发明公开了一种基于轻量级网络的行人再识别系统及实现方法,系统包括：图像处理模块、行人再识别神经网络训练模块以及行人再识别系统测试模块；所述图像处理模块通过数据增广技术增加图片数据量以及图片的变化性；所述行人再识别神经网络训练模块包括神经网络构架模块和网络训练模块；所述神经网络构架模块根据神经网络的特点,构建轻量级双通道神经网络,所述网络训练模块,对扩充后的图像数据进行训练；所述测试模块用于验证行人测试系统的性能,所述测试性能通过累计匹配特性曲线和Rank#k正确率来表征。本发明通过轻量级双通道网络来实现,通过加入两个子网络,使本发明的轻量级网络能更好的去学习有用的信息,提取的特征可以更好地识别行人。</td>   <td>1.基于轻量级网络的行人再识别系统,其特征在于,包括：图像处理模块、行人再识别神经网络训练模块以及行人再识别系统测试模块；所述图像处理模块,用于通过数据增广技术增加图片数据量以及图片的变化性,以达到神经网络模型训练结果的提升；所述行人再识别神经网络训练模块包括神经网络构架模块和网络训练模块；所述神经网络构架模块,用于根据神经网络的特点,构建轻量级双通道神经网络,所述神经网络构架模块,采用如下的策略构建神经网络；A、利用全局池化层来代替全连接层,用全局池化层可大大减少参数量；B、采用bottle#neck的网络结构,用1*1的卷积层与3*3的卷积层的组合去代替传统的只用3*3的卷积层；C、通过增加使用双通道轻量级网络提升网络性能；所述网络训练模块,将训练数据集合划分为两个数据子集合,一个作为训练集合,一个作为验证集合,对扩充后的图像数据进行训练；所述行人再识别系统测试模块用于验证行人测试系统的性能,所述测试性能通过累计匹配特性曲线和Rank#k正确率来表征。</td>   <td>G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘威;              杨伟伟;              王志杰;              印鉴;                   高静       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种对长尾兴趣点进行扩展的模型构建方法</td>   <td>广东</td>   <td>CN108491425A</td>   <td>2018-09-04</td>   <td>本发明提供一种对长尾兴趣点进行扩展的模型构建方法,该方法计算兴趣点v的访问者集合UV＝{u′1,u′2,···,u′t}的相关兴趣点集JV；再计算每个用户u的模型下的似然概率p(u|RV)；本算法通过相关模型Rv,计算基于兴趣点v简况的似然概率就能够通过相关兴趣点集Jv来计算得到,该方法对长尾兴趣点进行扩展,从而缓解数据稀疏问题,解决了当前模型的局限性。</td>   <td>1.一种对长尾兴趣点进行扩展的模型构建方法,其特征在于,包括以下步骤：S1：计算兴趣点v的访问者集合UV＝{u1',u'2,···,ut'}的相关兴趣点集JV；S2；计算每个用户u的模型下的似然概率p(u|RV)。</td>   <td>G06F17/30;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              马天俊;                   朱婷       </td>   <td>中山大学</td>   <td>一种端到端的基于深度决策森林的人群计数方法</td>   <td>广东</td>   <td>CN108491766A</td>   <td>2018-09-04</td>   <td>本发明提供一种端到端的基于深度决策森林的人群计数方法,将视频帧图像与人数标签分布联系起来,标签分布反映了不同标签对该视频帧的贡献程度。采用深度回归森林来学习人数标签分布模型,输入测试数据便可得到对应的分布预测,其中描述程度最大的标记便是该图像数据对应的人数。本发明定义了一个基于分布的森林损失函数,使所有的树能够共同学习,并且通过变分边界可以导出叶节点预测的更新函数,从而保证了损失函数的严格下降。</td>   <td>1.一种端到端的基于深度决策森林的人群计数方法,其特征在于,包括以下步骤：S1：利用深度学习框架caffe建立卷积神经网络,对视频帧图像进行深度特征提取；S2：利用卷积神经网络全连接层输出,将决策森林替代卷积神经网络的softmax层训练深度回归森林；S3：对视频帧图像按角度旋转、图像的多尺度缩放、图像的镜像以及图像金字塔缩放的操作实现图像数据增强；S4：将视频人群图片输入给卷积神经网络训练,通过反向传播不断地优化最终得到训练好的卷积神经网络模型；S5：输入测试图像得到的分布预测,其中描述程度最大的标记便是该图像对应的人数,最终预测结果是森林中所有决策树的均值。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              崔明月;              周晓梅;              李博洋;              杨俊杰;              朱笛;              张文权;                   康德开       </td>   <td>中山大学</td>   <td>一种基于FPGA的超低功耗实时车道线检测的方法</td>   <td>广东</td>   <td>CN108491811A</td>   <td>2018-09-04</td>   <td>本发明涉及车道线检测的技术领域,更具体地,涉及一种基于FPGA的超低功耗实时车道线检测的方法。一种基于FPGA的超低功耗实时车道线检测的方法,包括图像预处理、车道线检测和车道线跟踪三个部分；本发明利用OpenCL作为编程语言和COTS组件搭建了ADAS开发的基础平台,提出了一种可以在检测精度和速度成本进行协调的可伸缩的车道线检测算法,实现了在异构平台上车道线检测算法的并行化,大大提高了在可接受的精度下车道线检测的速度。实现了低成本的超低功耗车道线实时检测,对自动驾驶辅助系统(ADAS)的投入实际应用提供了可能。</td>   <td>1.一种基于FPGA的超低功耗实时车道线检测的方法,其特征在于,包括图像预处理、车道线检测和车道线跟踪三个部分；所述的图像预处理,从传入的图像中选择一个感兴趣区域,该区域包含车道线的信息；首先将该部分转为灰度图像,然后用Sobel滤波器检测图像的边缘,最后通过一个阈值进行再次滤波,去除噪声和增强图像；所述的车道线检测,在预处理之后,ROI中会有高强度的像素带表示车道线；提取车道线的准确位置是车道检测和车道跟踪算法的任务；如果没有对车道线的估计,就执行车道线检测；在检测到车道线后,只在车道跟踪算法不能跟踪车道线时再进行车道线检测；在ROI中,我们假设车道线都是直线,因此一条车道线可以定义为两点,一个点在ROI顶部,一个在底部,直线可表示为<img file="FDA0001611722080000011.TIF" wi="278" he="111"/>因此可以通过以下关系来获取任意给定直线X的强度值：<img file="FDA0001611722080000012.TIF" wi="700" he="97"/>为了检测多个车道标记,ROI被垂直分割为多个区域,每个区域有一个车道标记每一条直线的强度是通过计算ROI内所有像素的强度之和来确定的；另外,在一个可调的邻域附近的像素也被添加到这个强度权重中：<img file="FDA0001611722080000013.TIF" wi="700" he="170"/>2Nn是可调邻域的宽度；选择具有最高强度权重的候选线作为车道标记候选线是通过正态分布后采样其x#top和x#bottom来创建的,使用更多的候选线可以获得更好的检测效果,单也会消耗更多的计算资源,因此可以权衡车道线检测的时间性能和质量。所述的车道线跟踪,使用了先前帧的信息来检测后续帧的车道标记,实际上它没有检测到车道标记,只是跟踪他们；车道跟踪算法有两个信息来源,即预处理的ROI和前一帧的候选线,然后使用粒子滤波来跟踪标记；粒子滤波是一种基于贝叶斯信号处理马尔可夫链蒙特卡洛仿真模型的随机计算方法；<img file="FDA0001611722080000014.TIF" wi="700" he="78"/>假设从前一帧采样到i＝0,1,2,…,N个加权粒子,粒子状态为Xi,此外,每个例子被赋予一个权重wi,表示似然值；本算法中的例子滤波器以迭代的方式用以下三步实现：每个粒子的状态预测更新；每个例子的重要性权重更新；根据例子的重要性权重进行重采样；由于粒子已经以良好的线条形式给出,所以在检测阶段,从正常分布中取样候选线是没有必要的；因此引入了预测更新步骤；粒子代表每一帧中的车道标记,在下一帧中被用作先验分布；在新的一帧中,车道的标记可能稍微移动了；粒子需要移动相同的距离,以便在新坐标系中有效的先验分布；粒子权重更新公式如下：<img file="FDA0001611722080000021.TIF" wi="622" he="151"/>其中,μf＝Y是观测直线,σf是测量噪声,Xt#μf＝Xt#Y是两直线之间的距离；则观测直线是车道线的概率值为：<img file="FDA0001611722080000022.TIF" wi="700" he="167"/>其中,<img file="FDA0001611722080000023.TIF" wi="438" he="78"/>预测和重要性权重的更新产生了一组新的粒子,其中每个粒子都有一个标准化的重要性权重。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              黄捷;                   林格       </td>   <td>中山大学</td>   <td>一种基于CNN的图像风格化方法及系统</td>   <td>广东</td>   <td>CN108470320A</td>   <td>2018-08-31</td>   <td>本发明实施例公开了一种基于CNN的图像风格化方法及系统,其中,该方法包括：获取艺术图画作品的风格图像及现实图片；对图像进行预处理；分别对风格图像和内容图像进行图像分割,获取它们各自的多通道语义图像；构建多尺度风格化卷积神经网络,利用网络输入包含多个尺寸的内容图,得到输出图；利用深度卷积神经网络计算出风格损失值及内容损失值；结合两者,利用误差反向传播算法进行反向传播处理,更新多尺度风格化卷积神经网络权重；获取现实图片,裁剪成512*512大小,输入到多尺度风格化卷积神经网络中,得到风格化后的目标图像。在本发明实施例中,能够将任意艺术作品图片上的风格信息迁移到另一张实际图片当中,使得普通人制作出大师级别的绘画作品成为可能。</td>   <td>1.一种基于CNN的图像风格化方法,其特征在于,所述方法包括：获取艺术图画作品的风格图像及现实图片；对图像进行预处理,获得各尺度大小的风格图像和内容图像；分别对风格图像和内容图像进行图像分割,获取它们各自的多通道语义图像；构建多尺度风格化卷积神经网络,利用网络输入包含多个尺寸的内容图,得到输出图；获取风格图像和内容图像、多通道语义图像及输出图,利用深度卷积神经网络计算出输出图与风格图像之间的风格损失值及输出图与内容图像之间的内容损失值；结合风格损失值和内容损失值,利用误差反向传播算法对多尺度风格化卷积神经网络进行反向传播处理,对其进行更新网络权重；获取现实图片,裁剪成512*512大小,输入到多尺度风格化卷积神经网络中,得到风格化后的目标图像。</td>   <td>G06T3/00;G06T7/10;G06T3/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              刘畅;                   吴贺丰       </td>   <td>中山大学</td>   <td>融合卷积网络特征和判别式相关滤波器的目标跟踪方法</td>   <td>广东</td>   <td>CN108470355A</td>   <td>2018-08-31</td>   <td>本发明公开了一种融合卷积网络特征和判别式相关滤波器的目标跟踪方法。建立了一个端到端的轻量级网络体系结构,通过学习连续帧中丰富的流信息来训练卷积特征,改善特征表示和跟踪精度。将相关滤波跟踪组件构造为网络中的特殊层次跟踪单个图像块,在跟踪过程中,同时跟踪目标块和多个背景块,通过感知目标与周围背景块的结构关系,对目标及其周围环境辨识度高的部分建立模型,通过峰值旁瓣比和置信图峰值关系度量目标跟踪效果,在发生大面积遮挡、目标外形极度形变、光照剧烈变化等跟踪难度大的情况下,自动利用判别的背景部分进行定位。</td>   <td>1.一种融合卷积网络特征和判别式相关滤波器的目标跟踪方法,其特征在于包括以下步骤：步骤A,在离线阶段,使用视频中连续帧中的图像对训练跟踪特征神经网络；步骤B,初始化跟踪目标块和背景块集合的中心坐标、矩形框宽度和高度等属性；步骤C,对图像进行surf特征点检测,找出其中最具辨别性的背景块；步骤D,按顺序将特征点集中与目标块没有交集的surf特征点块加入背景区域块集合中；步骤E,重复步骤C和步骤D,直到满足背景块数量达到需求；步骤F,对于目标块训练和背景块集合中的每个背景块训练一个分辨式相关滤波器；步骤G,构建相对目标中心的运动模型；步骤H,读取下一帧图像；步骤I,同时跟踪目标块和背景块,计算他们的跟踪结果置信图；步骤J,通过分析置信图的特征判断目标图像块和背景图像块是否跟丢；步骤K,如果目标跟踪失败,则使用背景块集合推测目标位置；步骤L,如果目标没跟丢,使用跟踪置信图确定目标位置；步骤M,如果有背景块跟踪失败,则使用辨别性更强的新的背景块替换跟踪失败的块；步骤N,根据定位到的目标点更新网络；步骤O,重复执行步骤C至步骤H,直至处理完所有图像序列。</td>   <td>G06T7/246;G06T7/277;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陆逸扉;              杨伟伟;              方梓丞;              印鉴;                   潘文杰       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司</td>   <td>嵌入情感词典的注意力机制循环神经网络文本情感分析法</td>   <td>广东</td>   <td>CN108460009A</td>   <td>2018-08-28</td>   <td>本发明提供一种嵌入情感词典的注意力机制循环神经网络文本情感分析法。该发明主要根据获取的英文评论,对其情感极性进行标注。通过爬虫或其他软件获取需要的语料集,首先进行去除停用词的操作,接着采用word2vec算法对处理后的语料进行训练来得到相应的词向量。将训练集输入到基于注意力机制的循环神经网络(RNN/LSTM)结构中,在实现注意力权重训练的过程中,将词语的情感极性程度嵌入进去,使模型的关注点更接近于人类的理解,最终提高了文本情感分析的准确度。</td>   <td>1.一种嵌入情感词典的注意力机制循环神经网络文本情感分析法,其特征在于,包括以下步骤：S1：获取英文文本语料,对语料进行情感分类标注,将语料分为训练和测试集两个集合；S2：对步骤S1中的所有语料集合进行停用词处理；S3：使用word2vec算法对步骤S2中处理的语料进行训练得到相应的词向量；S4：根据sentiwordnet获取预知的各词语的情感极性分布,并对句子中极性较大的词语分配较大的权重；S5：将训练集语料放进具有注意力机制的循环神经网络中进行训练,在训练过程中使模型的注意力拟合步骤S4所获取的词语的权重；S6：将步骤S2和步骤S3处理获取的测试集语料放入步骤S5中,获取测试集的情感分类结果。</td>   <td>G06F17/27;G06F17/30;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;              陈家亮;                   方艳梅       </td>   <td>中山大学</td>   <td>一种基于局部纹理模式的二值图像隐写分析方法</td>   <td>广东</td>   <td>CN108460715A</td>   <td>2018-08-28</td>   <td>本发明涉及多媒体信息安全以及图像信息隐写技术领域,更具体地,涉及一种基于局部纹理模式的二值图像隐写分析方法。包括以下步骤：S1.构建十三宫格像素点块模板；S2.利用块模板扫描图像得到二值图像局部纹理模式；S3.统计每个二值图像局部纹理模式出现的频率；S4.将局部纹理模式出现的频率级联形成特征向量,利用集成分类器进行学习分类。本发明利用集成分类器进行学习分类,所提取的二值图像分析特征具有较高的特征维度,并且能够很好地描述图像的纹理,集成分类器能够很好地利用所提取的高维特征进行学习分类,能够很好地检测出待检测图像是否包含隐秘信息,具有较强可靠性。</td>   <td>1.一种基于局部纹理模式的二值图像隐写分析方法,其特征在于,包括以下步骤：S1.构建十三宫格像素点块模板；S2.利用块模板扫描图像得到二值图像局部纹理模式；S3.统计每个二值图像局部纹理模式出现的频率；S4.将局部纹理模式出现的频率级联形成特征向量,利用集成分类器进行学习分类。</td>   <td>G06T1/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         熊绘;              龙冬阳;              余跃;                   甘加升       </td>   <td>中山大学</td>   <td>基于汉字部件特征的卷积神经网络的文本情感分析方法</td>   <td>广东</td>   <td>CN108446271A</td>   <td>2018-08-24</td>   <td>本发明提供一种基于汉字部件特征的卷积神经网络的文本情感分析方法,该方法首先考虑情感词的情感强烈程度,结合Attention优化情感词典中词的权重；同时在特征提取方面采用了更细粒度的特征,由于中文的基本语素是汉字部件,其携带语音和语义等丰富信息,不同于英文的26个字母,最终提出了一种基于汉字组成部件与情感词典的双通道词嵌入的卷积神经网络的中文文本情感分类方法,在多个公开数据集上实验证明,该模型可以显著提高文本的情感分类效果。</td>   <td>1.一种基于汉字部件特征的卷积神经网络的文本情感分析方法,其特征在于,包括以下步骤：S1：获取汉字和汉字组成部件的信息：从HTTPCN网站爬取所有汉字的组成部件和部首的数据,以列表形式保存所有基本部件,以字典形式保存所有汉字和其对应的部件序列,最后生成部件级别的词嵌入；S2：得到第一个输入通道表达：对情感分类语料的所有中文文本以汉字为单位,基于汉字组成部件的字典和部件级的词嵌入生成汉字级别的部件嵌入表达,即第一个通道的输入；S3：得到第二个输入通道表达：对情感分类语料的所有中文文本进行分词和词性标注,结合词性匹配情感词典,对情感词的情感强度结合Attention机制优化权重,获得第二个通道的输入；S4：第一个CNN：第一个输入通道作为char#cnn的输入,连接卷积核大小为[2,3,4,5]、卷积核数目为256的卷积层,通过1#max池化层选取最显著的特征,再接入全连接层和softmax层,得到情感类别；S5：第二个CNN：第二个输入通道作为cnn的输入,连接卷积核大小为[2,3,4]、卷积核数目为256的卷积层,通过1#max池化层选取最显著的特征,再接入全连接层和softmax层,得到情感类别；S6：融合两个CNN：两个输入通道分别得到一个情感类别输出,作为一个新的DNN的输入,接入全连接层,通过分类器最终得到目标情感倾向。</td>   <td>G06F17/27;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              唐永毅;                   李伟宏       </td>   <td>中山大学</td>   <td>基于图模型的图片重要行人检测方法</td>   <td>广东</td>   <td>CN108446625A</td>   <td>2018-08-24</td>   <td>本发明公开了一种基于图模型的图片重要行人检测方法,包括下述步骤：S1、给定一张包含多行人的图片,对图片中行人进行检测与行人重要特征提取；S2、对于图片检测到行人,通过关系函数基于不同的特征构建混合关系图；S3、提出基于图模型的重要行人检测算法PersonRank,通过提出的PersonRank算法对混合关系图中的行人的重要程度进行排序；S4、对重要行人特征进行分析,并使用空间特征、动作特征、外观特征以及注意力特征来对行人进行表征。本发明利用不同的特征,对图片中检测出来的行人构建混合关系图来模型图片中行人之间的关系。通过改进著名排序算法PageRank使之能够用于对多层混合关系图中的行人的重要程度进行排序,最终检测到图片中最重要的行人。</td>   <td>1.基于图模型的图片重要行人检测方法,其特征在于,包括下述步骤：S1、给定一张包含多行人的图片,对图片中行人进行检测与行人重要特征提取；S2、对于图片检测到行人,通过关系函数基于不同的特征构建混合关系图,在混合关系图中,检测到的行人为图的结点,关系函数则用以构造图中结点间的相互联系的有向边；S3、提出基于图模型的重要行人检测算法PersonRank,通过提出的PersonRank算法对混合关系图中的行人的重要程度进行排序；S4、对重要行人特征进行分析,并使用空间特征、动作特征、外观特征以及注意力特征来对行人进行表征。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈广亮;              黄应淮;              罗伟玲;              刘禹麒;              严韵诗;              陈景标;              周裕丰;                   梁伟峰       </td>   <td>广东国地规划科技股份有限公司;广州蓝图地理信息技术有限公司;中山大学</td>   <td>基于车辆轨迹数据和人口分布的医疗设施可达性分析方法</td>   <td>广东</td>   <td>CN108446470A</td>   <td>2018-08-24</td>   <td>本发明公开了一种基于车辆轨迹数据和人口分布的医疗设施可达性分析方法,根据初始土地利用数据和驱动力数据,通过FLUS模型中对所述研究区域进行未来土地利用模拟,生成模拟结果,并根据所述模拟结果、所述距离值和所述数量关系,通过所述第一线性回归模型,求解得到研究区域的未来人口分布数据；结合车辆轨迹数据、医疗设施数据、初始人口分布数据和交通距离,挖掘出它们的内部潜在关系,进而准确求解出改进引力模型中不确定的弹性系数,并通过修正后的引力模型求解得医疗设施可达性值。本发明能够提高医疗设施可达性分析的准确性和可操作性,有效解决现状单时段的医疗设施可达性研究的不足,为未来医疗资源均等化、城市人口合理引导提供科学指导。</td>   <td>1.一种基于车辆轨迹数据和人口分布的医疗设施可达性分析方法,其特征在于,包括如下步骤：获取研究区域的遥感影像,并根据所述遥感影像提取所述研究区域的初始土地利用数据；根据所述初始土地利用数据,选定所述研究区域的空间驱动力因子组成驱动力数据；基于所述遥感影像设定的模拟区域范围和像元大小,根据所述初始土地利用数据和所述驱动力数据,计算所述模拟区域内各像元与所述驱动力因子的距离值；基于所述研究区域的初始人口分布数据,利用预先构建的第一线性回归模型建立所述初始土地利用数据与初始人口分布数据的数量关系；将所述初始土地利用数据和所述驱动力数据输入FLUS模型中对所述研究区域进行未来土地利用模拟,生成模拟结果,并根据所述模拟结果、所述距离值和所述数量关系,通过所述第一线性回归模型,求解得到所述研究区域的未来人口分布数据；根据所述初始人口分布数据和所述研究区域的医疗设施数据,基于交通网路的数学模型,采用网络分析法计算居民点与医疗设施点之间的交通距离；获取所述居民点与医疗设施点之间的所有有效车辆轨迹数据,并根据所述车辆轨迹数据、所述初始人口分布数据、所述医疗设施数据和所述交通距离,通过预先构建的第二线性回归模型,求解得到改进引力模型中的各项弹性系数；将各项弹性系数代入所述改进引力模型,得到修正后的引力模型,并将所述未来人口分布数据、所述医疗设施数据和所述交通距离输入修正后的引力模型中,求解得到医疗设施可达性值。</td>   <td>G06F17/50;G16H40/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄志康;                   黄方军       </td>   <td>中山大学</td>   <td>一种基于分段的自适应直方图平移可逆信息隐藏方法</td>   <td>广东</td>   <td>CN108447492A</td>   <td>2018-08-24</td>   <td>本发明公开了一种基于分段的自适应直方图平移可逆信息隐藏方法,首先将音频分为辅助段和嵌入段,对嵌入段进行分段；然后,构造辅助信息和包括秘密信息的待嵌信息,辅助信息先嵌入音频中；对嵌入段中的每个子段进行基值计算,构造子段直方图,将子段的每个元素与基值进行比对,进行平方图平移,进而将待嵌信息嵌入音频中,得到带有秘密信息的音频。本发明方案的优点在于,在保证信息被完全嵌入的情况下,每子段选取一对用于比较的基值提高了在音频上信息被嵌入的容量；音频的数值变化最多为一个单位,实现较好的听觉效果；嵌入秘密信息后的音频依然具有高信噪比。</td>   <td>1.一种基于分段的自适应直方图平移可逆信息隐藏方法,其特征在于,包括以下步骤：S1.获取原始音频、密钥、秘密信息S和嵌入量EC；其中,所述密钥的内容为十进制数或者任意字符串,用于指定一段音频中为辅助段的音频元素；所述秘密信息S的内容为被转换为二进制流的文本或者图片；S2.通过所述密钥从原始音频中随机选取一定长度的辅助段,剩余的均为嵌入段；S3.设定分段阈值L的初始值,将所述嵌入段均分为N个长度为L的子段；S4.将所述分段阈值L和嵌入量EC的信息组合为与辅助段的长度一致的辅助信息,并转换为二进制格式的辅助信息流X,将辅助段的最低有效位LSB的值与秘密信息S组合为待嵌信息M,将辅助信息流X的值依次替换辅助段的最低有效位LSB处的值；S5.对所述嵌入段的每个子段均进行基值计算,从子段中选择第一元素数值p1和第二元素数值p2,从两者中比较出较大值和较小值,作为两个用于后续比较的基值,其中,较大值为max_p,较小值为min_p,比较的计算过程如下列公式所示：max_p＝max(p1,p2)；min_p＝min(p1,p2)；S6.对所述嵌入段的每个子段均构造以max_p和min_p为嵌入点的子段直方图,顺序扫描子段中其他元素的数值p,判断p与max_p和min_p之间的关系并做出相应的变动,完成将待嵌信息M嵌入音频,得到携带秘密信息的音频。</td>   <td>G10L19/018</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梅晗;                   张东       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种双层圆环麦克风阵列语音增强方法</td>   <td>广东</td>   <td>CN108447499A</td>   <td>2018-08-24</td>   <td>本发明公开了一种双层圆环麦克风阵列语音增强方法,根据声场环境的不同采用不同的波束形成方法,提高了麦克风阵列的对噪声的鲁棒性,其中当声场环境为散射噪声场时,在不同频段分别采用一阶和二阶差分波束形成器项组合的方法进行语音增强,可以在不牺牲白噪声增益的情况下获得较高的方向性因数。</td>   <td>1.一种双层圆环麦克风阵列语音增强方法,其特征在于：包括以下步骤：A、采集通道的时域信号；B、对采集到的通道的时域信号进行分帧、加窗后得到通道的接收信号的频域表示；C、对通道的接收信号的频域表示进行短时傅里叶变换,得到整个麦克风阵列接收的信号的频率子带；D、根据静音段不同通道间的相干函数对声场环境进行判定；E、当声场环境为非相关噪声场时,在子带上采用一阶差分波束形成器进行波束形成得到权向量；当声场环境为散射噪声场时,在低频段的子带上采用一阶差分波束形成器进行波束形成得到权向量,在高频段的子带上采用二阶差分波束形成器进行波束形成得到权向量；F、根据权向量计算得到输出信号；G、将输出信号进行变换后得到增强后的语音信号。</td>   <td>G10L21/0216;G10L21/0232;G10L21/0264</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王甲海;              岑彬忠;              印鉴;                   潘文杰       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司</td>   <td>一种基于并行协同演化的高维多目标优化算法</td>   <td>广东</td>   <td>CN108428005A</td>   <td>2018-08-21</td>   <td>本发明提供一种基于并行协同演化的高维多目标优化算法,该算法维持两个种群：一个种群负责寻找极值点,另一个种群负责在整个决策空间中搜索一组兼顾收敛性与多样性的解。这两个种群协同演化。在整个进化过程中,两个种群分别有自己的演化方式,同时它们之间又存在信息交流和信息共享。在算法框架中,任何基于帕累托占优的多目标进化算法都可以应用在负责在整个决策空间中搜索一组兼顾收敛性与多样性的解的种群上。该框架改善了基于帕累托占优的多目标进化算法在高维多目标优化问题上的性能,克服了传统基于帕累托占优的进化算法在求解高维多目标问题时性能急剧恶化的缺点,平衡了高维多目标优化问题求解的收敛性和多样性。</td>   <td>1.一种基于并行协同演化的高维多目标优化算法,其特征在于,包括以下步骤：S1：设定目标个数M,最大评估次数MFE,初始化搜索一组解的初始种群P1且种群大小为N1,初始化寻找极值点的初始种群P2且种群大小为N2；S2：生成一组方向向量W＝{w1,w2,…,w2M}来引导种群来寻找极值点；S3：从P<sub>1</sub>中随机选出个体x<sub>1</sub>,然后从P<sub>1</sub>,P<sub>2</sub>两个种群随机选择一个种群,再从该种群中随机选出个体x<sub>2</sub>,对个体x<sub>1</sub>和x<sub>2</sub>进行交叉产生两个子代个体o<sub>1</sub>和o<sub>2</sub>,重复<img file="FDA0001550637760000011.TIF" wi="71" he="111"/>次产生子种群Q<sub>1</sub>；S4：从P<sub>2</sub>中随机选出个体y<sub>1</sub>,然后从P<sub>1</sub>,P<sub>2</sub>两个种群随机选择一个种群,再从该种群中随机选出个体y<sub>2</sub>,对个体y<sub>1</sub>和y<sub>2</sub>进行交叉产生两个子代个体q<sub>1</sub>和q<sub>2</sub>,重复<img file="FDA0001550637760000012.TIF" wi="75" he="119"/>次产生子种群Q<sub>2</sub>；S5：将种群P1,Q1和Q2进行合并,得到新种群R1,然后使用基于帕累托占优的环境选择策略从合并种群R1中选出个N1个体,得到种群A1,令P1＝A1；S6：将种群P2,Q1和Q2进行合并,得到新种群R2,然后,基于切比雪夫方程,计算种群R2中的每个个体的适应值,再根据适应值从小到大地对种群R2中的个体进行排序,最后,选择从R2中选出前N2个个体,得到种群A2,令P2＝A2；S7：复步骤S3#S8直到评估次数达到MFE,输出种群P1。</td>   <td>G06Q10/04;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              原尉峰;                   周凡       </td>   <td>中山大学</td>   <td>一种基于深度学习的快速图像检索方法</td>   <td>广东</td>   <td>CN108427738A</td>   <td>2018-08-21</td>   <td>本发明实施例公开了一种基于深度学习的快速图像检索方法,其中,该方法包括：从图像数据库中随机生成两张图像作为网络的输入,一张作为查询图像,一张作为样本图像,其中每张图片都包括对应的类别标签；构建卷积神经网络,该网络包括三组卷积池化层和两组全连接层；利用训练样本集随机组合成数据对根据卷积网络进行训练,得到相应的哈希编码并计算两者之间的欧几里得距离；计算卷积网络输出值的误差函数,对卷积神经网络进行训练,利用反向传播算法和随机梯度下降法更新网络参数；获得训练数据集的二值编码后,对其按欧几里得距离从小到大排序,按顺序输出检索结果。在本发明实施例中,能够解决现有技术检索速度慢、占用内存空间大、检索结果不精确的问题,大大提高了图像检索的时空效率。</td>   <td>1.一种基于深度学习的快速图像检索方法,其特征在于,所述方法包括：从图像数据库中随机生成两张图像作为网络的输入(I1,I2),一张作为查询图像I1,一张作为样本图像I2,其中每张图片都包括对应的类别标签；构建卷积神经网络,该网络包括三组卷积池化层和两组全连接层；利用训练样本集随机组合成数据对(I1,I2),根据卷积网络进行训练,得到相应的哈希编码H1、H2,并计算两者之间的欧几里得距离；计算卷积网络输出值的误差函数,对卷积神经网络进行训练,利用反向传播算法和随机梯度下降法更新网络参数；获取需要检索的图像,通过训练后的卷积神经网络,获得训练数据集的二值编码后,对其按欧几里得距离从小到大排序,按顺序输出检索结果。</td>   <td>G06F17/30;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              李浪宇;              石晓红;                   周凡       </td>   <td>中山大学</td>   <td>一种基于双拉普拉斯金字塔卷积神经网络的图像放大方法</td>   <td>广东</td>   <td>CN108428212A</td>   <td>2018-08-21</td>   <td>本发明公开了一种基于双拉普拉斯金字塔卷积神经网络的图像放大方法,其中,所述方法包括：获取低分辨率的图像,进行双三次放大处理,获得对应放大倍数的模糊高分辨率图像；将模糊高分辨率图像进行提取特征处理,获得由大到小不同尺度的图像特征；将低分辨率的图像进行提取特征处理,获得由小到大的逐层不同尺度的图像特征；获取所述的由大到小不同尺度的图像特征以及所述的由小到大的逐层不同尺度的图像特征通过重建超分辨率网络进行融合,获得高分辨率的图像。通过实施本发明实施例,能够较为快速的重建出高质量的高分辨率图像,使得通过将低分辨率的图像进行重建图像质量得到提高能够更好的被应用于更多场景。</td>   <td>1.一种基于双拉普拉斯金字塔卷积神经网络的图像放大方法,其特征在于,所述方法包括：获取低分辨率的图像,进行双三次放大处理,获得对应放大倍数的模糊高分辨率图像；将模糊高分辨率图像进行提取特征处理,获得由大到小不同尺度的模糊高分辨率图像特征；将低分辨率的图像进行提取特征处理,获得由小到大的逐层不同尺度的低分辨率图像特征；获取模糊高分辨率图像特征以及低分辨率图像特征通过重建超分辨率网络将不同层次的图像特征进行融合,获得图像残差；获取图像残差结合模糊高分辨率图像通过卷积方法进行叠加处理,获得高分辨率的图像。</td>   <td>G06T3/40;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王凯;                   许忆彤       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于光电传感器的屏下光学指纹识别的方法</td>   <td>广东</td>   <td>CN108416252A</td>   <td>2018-08-17</td>   <td>本发明公开了一种基于光电传感器的屏下光学指纹识别的方法,以在顶部栅极集成光电传感器的多晶硅双栅薄膜晶体管代替传统TFT屏幕内的薄膜晶体管,在图像显示的基础功能上通过触控启动开关切换到指纹采集模式,利用光电传感器采集从手指反射回来的光,并通过电荷放大器被系统读取,从而实现光学指纹识别,即采用单一器件实现液晶显示屏下的指纹图像采集功能,减小手机终端内部空间的占用,为手机终端的高集成化提供了基础。</td>   <td>1.一种基于光电传感器的屏下光学指纹识别的方法,其特征在于包括以下步骤：S1：当手指触碰到屏幕时,触控启动开关闭合；S2：模式开关切换到成像端,进入指纹图像采集模式,对偏置端施加负电压使光电传感器反向偏置以处于工作状态,从手指反射回来的光被光电传感器吸收并产生电子空穴对；S3：电子向顶部栅极聚集,使多晶硅双栅薄膜晶体管的阈值电压产生变化,并通过多晶硅双栅薄膜晶体管顶部电容和光电传感器的结电容存储变化电容；S4：对选择端施加负电压,多晶硅双栅薄膜晶体管打开并使电荷流进电荷放大器,使系统获取所采集指纹的电荷信息。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韩广云;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于深度学习的本征图像分解方法及装置</td>   <td>广东</td>   <td>CN108416805A</td>   <td>2018-08-17</td>   <td>本发明公开一种基于深度学习的本征图像分解方法及装置,其中该方法包括在若干3D模型中选取3D模型加载入基于物理的渲染器,随机设置光照,任取视角渲染图片,并通过渲染器获取对应的反射成分和光照成分,以此重复操作,生成大批量的有标注本征图分解的数据集；利用所生成的数据集将全卷积神经网络训练成本征图分解网络；对本征图分解网络进行应用,由预测输出的分解结果,得到期望输出的分解目标。本发明提出的本征图分解方法允许通过图形渲染的方式获取大批量有标注数据集,通过训练深度神经网络,获取鲁棒性良好的分解模型；通过应用损失网络,进一步提高泛化性能并且避免了损失函数的设计困难。</td>   <td>1.一种基于深度学习的本征图像分解方法,其特征在于,包括如下步骤：S10在若干3D模型中选取3D模型加载入基于物理的渲染器,随机设置光照,任取视角渲染图片,并通过渲染器获取对应的反射成分和光照成分,以此重复操作,生成大批量的有标注本征图分解的数据集；S20利用所生成的数据集将全卷积神经网络训练成本征图分解网络；S30对本征图分解网络进行应用,由预测输出的分解结果,得到期望输出的分解目标。</td>   <td>G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              陈志坚;                   李伟宏       </td>   <td>中山大学</td>   <td>图片重要人脸检测方法</td>   <td>广东</td>   <td>CN108416314A</td>   <td>2018-08-17</td>   <td>本发明公开了一种图片重要人脸检测方法,本发明能够利用图片人脸检测与重要人脸检测的固有的关系,对输入的图片同时进行人脸检测与重要人脸检测。为了达到这样的目标,本发明提出一个二分支的框架,该框架首先对输入的图片进行人脸预检测,提取人脸预选框(即,图像中所有可能包含人脸的区域)。紧接着,将预选框分别输入到两个分支中,其中一个分支进行人脸分类、人脸框回归以及人脸特征点定位,另外的分支则是对人脸重要程度特征提取并进行重要人脸分类,最终该框架能从原始图片中准确的检测到最重要的人脸。本发明方法将特征学习与重要人脸检测连结起来,通过卷积神经网络来学习能够反映图片中人脸的重要程度的深度特征。</td>   <td>1.一种图片重要人脸检测方法,其特征在于,利用图片人脸检测与重要人脸检测的固有的关系,对输入的图片同时进行人脸检测与重要人脸检测,具体包括下述步骤：S1、构建一个二分支的框架,利用该二分支的框架对输入的图片进行人脸预检测,提取人脸预选框,所述人脸预选框是指图片中所有可能包含人脸的区域；S2、将人脸预选框分别输入到两个分支中,其中一个分支进行人脸分类、人脸框回归以及人脸特征点定位,使用预训练好的人脸检测模型实现；另外的一个分支则是对人脸重要程度特征提取并进行重要人脸分类；S3、在重要人脸检测分支中,对人脸预选框进行扩大,得到上下文候选框,利用重要人脸检测分支提取人脸周围的上下文信息以及纹理特征,同时引入在人脸检测分支中提取的包含人脸信息的局部特征,使得用于重要人脸检测的特征包含丰富有效的信息；S4、在重要人脸检测分支中,采用端到端的训练方式,即重要人脸分类的梯度能够回传到特征提取的卷积神经网络,并更新网络的参数从而达到将重要人脸特征表达与重要人脸分类连结起来；S5、最终利用该二分支的框架,从原始图片中准确的检测到最重要的人脸。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵一霖;              吕中荣;                   刘济科       </td>   <td>中山大学</td>   <td>一种基于残余力向量法和树种算法的结构损伤识别二步法</td>   <td>广东</td>   <td>CN108416074A</td>   <td>2018-08-17</td>   <td>本发明提供一种基于残余力向量法和树种算法的结构损伤识别二步法,该发明利用改进的树种算法来实现损伤程度的反演和识别,首先利用改进的残余力向量定位法来对无损单元进行大规模的排查,进而锁定若干个受损单元。第二步在原有树种算法的基础上,引入了两种更好的搜索模式,并且采用了自适应判断参数,进而使得迭代的初期使得算法侧重于全局搜索,在迭代后期使得算法更加专注于局部搜索,这样就实现了算法两种搜索能力(局部搜索和全局搜索)的平衡。同时本文假定损伤模型为单元质量和刚度的线性折损,基于频率残差和模态确保准则建立损伤识别问题的目标函数,利用改进后的算法对该目标函数进行求解以获得损伤参数的识别。</td>   <td>1.一种基于残余力向量法和树种算法的结构损伤识别二步法,其特征在于,包括以下步骤：S1：将结构划分为nel个单元,再利用有限单元法得到系统刚度和质量矩阵,再提取前N阶固有频率和模态；S2：构建损伤结构的目标函数；S3：利用改进的树种算法优化目标函数。</td>   <td>G06F17/50;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         阮文俊;                   翁安林       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种超市路径推荐系统及其方法</td>   <td>广东</td>   <td>CN108416611A</td>   <td>2018-08-17</td>   <td>本发明公开了一种超市路径推荐方法,先获取用户行走路径以及与用户行走路径对应的购买清单,采用谱聚类算法对用户行走路径进行聚类后得到簇划分集,根据簇划分集计算得到所有簇类的商品概率分布及平均簇类的商品概率分布,当用户购物时,判断用户所属的簇类,根据对应簇类的商品概率分布计算出所有的路径以及路径上的商品概率分布,最后通过A*算法计算得到一条最符合用户需求的最短路径,该路径上的商品会引起用户的兴趣,路径距离也相对较短；本发明的一种超市路径推荐系统,包括智能终端和推荐系统模块,推荐系统模块将推荐的路径信息显示在智能终端为用户导航,本发明可以为用户提供最佳的路径,提高用户体验,刺激消费。</td>   <td>1.一种超市路径推荐方法,其特征在于：包括以下步骤：A、获取数据,其中数据包括用户行走路径以及与用户行走路径一一对应的购买清单；B、使用谱聚类算法对用户行走路径进行聚类,并得到簇划分集<img file="FDA0001564202380000011.TIF" wi="699" he="79"/>C、根据簇划分集<img file="FDA0001564202380000012.TIF" wi="635" he="79"/>计算其所有簇类的所有的商品概率分布以及平均簇类的商品概率分布；D、根据用户的当前状态判断其所属的簇类,并计算得到不同路径下所有已抵达的商品概率总和；E、采用A*算法为用户推荐一条路径上商品概率总和最大,并且路径长度相对较小的路径。</td>   <td>G06Q30/02;G06Q30/06;G06Q10/04;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗燕;              王学钦;                   吕林       </td>   <td>中山大学中山眼科中心;中山大学</td>   <td>眼底彩照视盘与黄斑定位识别方法</td>   <td>广东</td>   <td>CN108416344A</td>   <td>2018-08-17</td>   <td>本发明公开了一种眼底彩照视盘与黄斑定位识别方法,通过对眼底彩照中各部位的自动定位以及测量,达到疾病预筛选的效果,将有病变嫌疑的图片自动筛选出,以供医生复查准确判断是否患病,减少医生工作量；并且其结果不依赖于医生经验,更加客观,能够快速有效地对眼底彩照中的视盘、视杯与黄斑进行定位识别,从而可以辅助诊断正常眼底、青光眼及异常发育的眼底等疾病,实现远程会诊的目的。</td>   <td>1.一种眼底彩照视盘与黄斑定位识别方法,其特征在于包括以下步骤：图片质量检测,输入原始图像,进行图像特征的提取,并进行训练,对图片质量进行预测,检测出图片质量过关的眼底图像进行后续处理；图像预处理,在所有的图像中选择一张识别效果最好的,并提取其RGB三个轨道的灰度分布,将其作为标准图；视盘识别,包括以下步骤：初定位,首先将将整张图片更亮的区域用阈值分割的方法提取出来,其余较暗区域利用均值填补,修改后的图片再次进行阈值切分,通过多次迭代,将较亮区域面积一步步减小,当感兴趣区域面积事先确定的阈值后,停止迭代,再对提取出的高亮区域进行筛选,提取出该感兴趣区域的中心并截取以供下一步分析；精确定位与平滑拟合：利用形态学处理方法先去掉噪音影响,然后对于图像进行阈值分割以得到相对不光滑的边界位置,然后对于边界位置进行椭圆拟合,最后将边界方程绘制在原图上。</td>   <td>G06K9/20;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何俊奇;                   黄方军       </td>   <td>中山大学</td>   <td>一种基于消除块效应的非对称JPEG隐写方法</td>   <td>广东</td>   <td>CN108416725A</td>   <td>2018-08-17</td>   <td>本发明公开了一种基于消除块效应的非对称JPEG隐写方法,将图像由DCT域解压至空域,在保证图像尺寸不变的情况下,对解压后的图像进行一定的改动,得到经过改动的图像,然后将原图像的量化表转换至经过改动的图像的DCT域中；通过计算原始图像的代价值并对原图像和经过改动的图像均进行切割,调整标记系数对应的代价值,得到经过改动的图像的代价值；以经过原始图像作为载体,通过经过改动的图像的代价值和编码算法将秘密信息嵌入至经过改动的图像中,作为最终完成隐写的图像。本发明提供的隐写方法可在不影响现有隐写方法嵌入量和算法效率的基础上提高隐写方法的安全性,规避了常规DCT变换可能引起的块效应。</td>   <td>1.一种基于消除块效应的非对称JPEG隐写方法,其特征在于,包括以下步骤：S1.提取载体图像的DCT系数C和量化表q_tab,获取秘密信息；S2.根据所述DCT系数将DCT域解压到空域中,得到各子块对应的空域像素值；S3.将解压到空域的图像裁剪i行、j列,其中0≤i≤2,0≤j≤2且i+j＞0；在保证行数为i、列数为j的条件下,将经过裁剪的图像进行一定修改,得到经过修改的空域图像组C'i,j；S4.将所述空域图像组C'i,j的像素值相加求均值,并利用步骤S1中的量化表q_tab将其转换到DCT域内,得到与原载体图像对应的、经过块效应消除的图像Cs,具体公式如下：<img file="FDA0001595656330000011.TIF" wi="502" he="135"/>0≤i≤2,0≤j≤2且i+j＞0,1≤x≤M,1≤y≤N其中,x表示图像的行,y表示图像的列；S5.计算原始的代价值ρ；S6.将所述C和Cs分成8×8的不重叠块,并将各块的边界进行标记,调整标记的系数所对应的代价值,得到新的代价值ρ'；S7.通过最终的代价值ρ'和编码算法将秘密信息嵌入到载体图像中,得到最终的隐写图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈跃东;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于生成式对抗网络进行图像去运动模糊的方法</td>   <td>广东</td>   <td>CN108416752A</td>   <td>2018-08-17</td>   <td>本发明公开一种基于生成式对抗网络进行图像去运动模糊的方法及用于该方法的去运动模糊的生成式对抗网络模型,该方法包括设计生成式对抗网络模型；模型训练；应用阶段,该生成式对抗网络模型包括生成器和判别器,生成器用于不断优化参数以使其生成的图像趋近清晰图像的分布,判别器用于不断优化参数以使其能更好地判别图像来自于去模糊图像分布或清晰图像分布,其中生成器包括降采样器和上采样器,降采样器用于对图像进行卷积操作,提取图像的语义信息,上采样器用于根据获取到的语义信息,结合图像的结构信息,对图像进行解卷积操作。本发明有效地去除图像的运动模糊,获得符合人类感知的清晰图像。</td>   <td>1.一种基于生成式对抗网络进行图像去运动模糊的方法,其特征在于,包括如下步骤：S10设计运动去模糊的生成对抗式网络模型结构,其中该网络模型由生成器和判别器组成,其中生成器包括降采样器和上采样器,降采样器用于对图像进行卷积操作,提取图像的语义信息,上采样器用于根据获取到的语义信息,结合图像的结构信息,对图像进行解卷积操作；S20将一个包含模糊图像和清晰图像的图像对数据集中模糊图像作为队列元素存储至模糊图像队列,清晰图像作为队列元素存储至清晰图像队列,且以清晰图像队列中的元素顺序调整模糊图像队列的元素顺序,以使清晰图像与模糊图像一一对应；S30输入一组包含有m个从S20步骤中的两个队列获取的清晰#模糊图像对至网络模型,分别将该图像对中的清晰图像和模糊图像缩放成Sh×Sw的尺寸,再剪成出尺寸为Ch×Cw的图像块；S40将由S30得到的图像块输入该网络模型,通过迭代应用后向传播算法,逐步更新该网络模型的训练参数,每代队列中的所有元素训练结束之后,重新打乱队列元素的排序,开始新一代的训练,循环多代训练,直至该网络模型收敛,保存并导入该网络模型收敛时的训练参数,以使得该网络模型拟合成一个从模糊图像分布到清晰图像分布的映射；S50输入模糊图像,通过一次前向传播计算,生成去模糊图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              康德开;              郭叙森;                   郑杰鑫       </td>   <td>中山大学</td>   <td>一种基于细粒度神经网络的织物种类识别方法</td>   <td>广东</td>   <td>CN108416774A</td>   <td>2018-08-17</td>   <td>本发明涉及图像处理及深度学习的技术领域,更具体地,涉及一种基于细粒度神经网络的织物种类识别方法。一种基于细粒度神经网络的织物种类识别方法,其中,包括以下步骤：步骤1：构建细粒度卷积神经网络；步骤2：采集织物图像,并对其进行预处理,建立织物图像数据库；步骤3：使用预处理后的织物图像,训练细粒度识别卷积神经网络模型；步骤4：使用测试图像对细粒度卷积神经网络模型进行测试,得到测试图像的织物类别识别结果。本发明能够更好地提取织物纹理等细粒度特征,实现织物种类的准快速识别。</td>   <td>1.一种基于细粒度神经网络的织物种类识别方法,其特征在于,包括以下步骤：步骤1：构建细粒度卷积神经网络；步骤2：采集织物图像,并对其进行预处理,建立织物图像数据库；步骤3：使用预处理后的织物图像,训练细粒度识别卷积神经网络模型；步骤4：使用测试图像对细粒度卷积神经网络模型进行测试,得到测试图像的织物类别识别结果。</td>   <td>G06T7/00;G06N3/04;G06F17/30;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              林倞;              谢圆;                   成慧       </td>   <td>中山大学</td>   <td>基于深度学习的弱监督显著性物体检测的方法及系统</td>   <td>广东</td>   <td>CN108399406A</td>   <td>2018-08-14</td>   <td>本发明公开了一种基于深度学习的弱监督显著性物体检测的方法及系统,该方法包括：利用非监督的显著性检测方法产生所有训练图像的显著图；将显著图与对应的图像级别的类别标签作为初次迭代的有噪声的监督信息,以训练多任务的全卷积神经网络,训练过程收敛后,生成新的类别激活图和显著性物体预测图；利用条件随机场模型调整类别激活图和显著性物体预测图；利用标签更新策略为下一次迭代更新显著性标注信息；多次迭代进行训练过程直到符合停止的条件；在含有未知类别图像的数据集上进行泛化式训练,得到最终模型,本发明在优化过程中自动清除噪声信息,只使用图像级别的标注信息就能达到良好的预测效果,避免了冗繁耗时的像素级别的人工标注过程。</td>   <td>1.一种基于深度学习的弱监督显著性物体检测方法,包括如下步骤：步骤S1,利用非监督的显著性检测方法通过多任务的全卷积神经网络产生所有训练图像的显著图Sanno；步骤S2,将所述显著图与对应的图像级别的类别标签同时作为初次迭代的有噪声的监督信息,以训练多任务的全卷积神经网络,于训练过程收敛后,生成新的类别激活图Scam和显著性物体预测图Spredict；步骤S3,利用条件随机场模型调整所述类别激活图和显著性物体预测图；步骤S4,利用标签更新策略为下一次迭代更新显著性标注信息；步骤S5,多次迭代式地进行步骤S2#S4的训练过程,直到符合停止的条件；步骤S6,在含有未知类别图像的数据集上进行泛化式训练,得到最终模型。</td>   <td>G06K9/32;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              冯玉琢;              李凝;                   李启运       </td>   <td>中山大学</td>   <td>一种视频序列下实时火灾检测预警方法</td>   <td>广东</td>   <td>CN108399359A</td>   <td>2018-08-14</td>   <td>本发明提供一种视频序列下实时火灾检测预警方法,S1：读取一帧视频序列,采用帧差法提取视频中的运动区域；若未检测到运动区域,则返回步骤S1；S2：同时检测火焰区域和烟雾区域,将运动区域的运动像素点与火焰颜色特征模型和烟雾颜色特征模型进行匹配,从而识别出火焰区域和烟雾区域；如果未提取到火焰区域和烟雾区域,则返回步骤S1；S3：如果检测到火焰区域或烟雾区域,则表示有火焰或烟雾发生,此时进行火灾预警,然后读取下一帧。本发明采用了静态和动态特征结合的方法,根据不同场景下火灾燃烧情况,对火焰和烟雾进行双重检测。可以提高检测火灾的敏感性,降低误报率。</td>   <td>1.一种视频序列下实时火灾检测预警方法,其特征在于,包括以下步骤：S1：读取一帧视频序列,采用帧差法提取视频中的运动区域；若未检测到运动区域,则返回步骤S1；S2：同时检测火焰区域和烟雾区域,将运动区域的运动像素点与火焰颜色特征模型和烟雾颜色特征模型进行匹配,从而识别出火焰区域和烟雾区域；如果未提取到火焰区域和烟雾区域,则返回步骤S1；S3：如果检测到火焰区域或烟雾区域,则表示有火焰或烟雾发生,此时进行火灾预警,然后读取下一帧。</td>   <td>G06K9/00;G06K9/44;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              尹森堂;              张冬雨;                   王青       </td>   <td>中山大学</td>   <td>一种快速行人检测方法及装置</td>   <td>广东</td>   <td>CN108399362A</td>   <td>2018-08-14</td>   <td>本发明公开了一种快速行人检测方法及装置,所述方法包括如下步骤：步骤S1,构建可配置的基于卷积神经网络的深度模型,利用训练样本学习出构建的网络参数,获得用于测试过程的模型；步骤S2,输入测试样本,通过训练好的模型利用神经网络感知域的变化规律使用不同的中间层对不同尺度范围内的目标物体进行检测,预测出图像中目标物体的框图,本发明通过利用神经网络感知域的变化规律,使用不同的中间层对特定尺度范围内的目标物体进行检测,更好的适应了感知域与物体大小的关系,有效提高了检测结果。</td>   <td>1.一种快速行人检测方法,包括如下步骤：步骤S1,构建可配置的基于卷积神经网络的深度模型,利用训练样本学习出构建的网络参数,获得用于测试过程的模型；步骤S2,输入测试样本,通过训练好的模型利用神经网络感知域的变化规律使用不同的中间层对不同尺度范围内的目标物体进行检测,预测出图像中目标物体的框图。</td>   <td>G06K9/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              李伟宏;                   李本超       </td>   <td>中山大学</td>   <td>基于全局-局部RGB-D多模态的手势识别方法</td>   <td>广东</td>   <td>CN108388882A</td>   <td>2018-08-10</td>   <td>本发明公开了一种基于全局#局部RGB#D多模态的手势识别方法,本发明主要通过包括骨骼位置、RGB图像、深度图像和光流图像等数据模态对输入的手势视频进行表示,得到多模态的手势数据表示后,利用卷积神经网络和递归神经网络的方法把不同模态的手势数据分别进行特征表达,并且利用不同模态下得到的特征进行手势的分类。最终将不同模态下得到的不同类别的手势得分进行融合,得到最终基于多模态的手势分类结果。本发明可以应用于客户端或云端对用户输入的手势视频进行识别,通过手势的输入使计算机或手机软硬件做出对应的响应。</td>   <td>1.基于全局#局部RGB#D多模态的手势识别方法,其特征在于,包括下述步骤：S1、骨骼序列生成及基于骨骼数据的全局#局部手势识别：给定输入的RGB#D视频图片,利用多人姿态估计方法估计出每帧图片中人体骨骼的坐标位置,并根据整个视频获得的上半身的骨骼点,利用长短时记忆网络对上半身的骨骼点进行特征进行时序建模和分类,得到基于全局骨骼的手势分类得分Ss#g；S2、基于全局#局部的RGB#D模态手势识别：对于RGB数据和深度数据的全局手势表示,首先分别将T帧的RGB和T帧深度图在通道沿时间进行堆叠,分别得到堆叠后的RGB图IRGB和T帧深度图IDepth,并且对VGG16卷积神经网络的输入通道进行改进,使其能够接受对应通道数目的数据输入；通过卷积神经网络的特征提取处理,分别在堆叠的RGB数据和堆叠的深度图获得对应的全局RGB特征xRGB#g和全局深度特征和xDepth#g；最后,利用神经网络的非线性分类方法分别获得基于全局的RGB手势分类得分SRGB#g和全局的深度手势分类得分SDepth#g；S3、基于全局#局部的RGB光流和深度光流模态手势识别；分别在RGB视频数据和深度视频数据中提取光流信号,从而分别获得RGB光流和深度光流图片数据,光流是一种记录像素运动的方式,其主要记录了每个像素沿时间帧之间的运动方向和强度；S4、多模态的手势分类得分融合；在获得骨骼、RGB图、深度图、RGB光流图和深度光流图5种不同的数据模态的全局和局部手势分类得分Ss#g,Ss#l,SRGB#g,SRGB#l,SDepth#g,SDepth#l,SRGB#f#g,SRGB#f#l,SDepth#f#g和Sdepth#f#l后；基于以上的手势分类得分进行平均,并且利用归一化函数进行类别得分的归一化,最终获得不同手势类别的概率。</td>   <td>G06K9/00;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈宇恒;              马朔;              刘冶;              李浩跃;              李锦芬;              彭楠;              徐振涛;                   印鉴       </td>   <td>火烈鸟网络(广州)股份有限公司;中山大学</td>   <td>一种游戏智能评级方法与系统</td>   <td>广东</td>   <td>CN108389082A</td>   <td>2018-08-10</td>   <td>本发明涉及一种游戏智能评级方法及系统,所述方法包括以下步骤：采集已上线游戏在上线前的数值数据和文本数据；提取已上线游戏在上线前的数值特征和文本特征并进行特征处理；根据特征处理后已上线游戏在上线前的数值特征、文本特征和已上线游戏的级别标签,建立并训练最优随机森林算法模型；采集未上线游戏的数值数据和文本数据；提取未上线游戏的数值特征和文本特征并进行特征处理；根据最优随机森林算法模型,输入特征处理后未上线游戏的数值特征和文本特征,预测未上线游戏的游戏级别。本发明的游戏智能评级方法及系统具有评级准确,且不受人为主观因素影响的优点。</td>   <td>1.一种游戏智能评级方法,其特征在于,包括以下步骤：采集已上线游戏在上线前的数值数据和文本数据,其中,所述数值数据为游戏自身参数,所述文本数据包括短文本数据和长文本数据；提取已上线游戏在上线前的数值特征和文本特征并进行特征处理,其中,所述文本特征包括短文本特征和长文本特征；根据特征处理后已上线游戏在上线前的数值特征、文本特征和已上线游戏的级别标签,建立并训练最优随机森林算法模型,其中,所述游戏级别标签为：根据已上线游戏上线后一段时间内的受欢迎程度和盈利能力设立的游戏级别；采集未上线游戏的数值数据和文本数据；提取未上线游戏的数值特征和文本特征并进行特征处理；根据所述的最优随机森林算法模型,输入特征处理后未上线游戏的数值特征和文本特征,预测未上线游戏的游戏级别。</td>   <td>G06Q30/02;G06F17/30;G06F17/27;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   李纪先       </td>   <td>中山大学</td>   <td>一种基于频域差分统计特征的JPEG图像重压缩检测方法</td>   <td>广东</td>   <td>CN108376413A</td>   <td>2018-08-07</td>   <td>本发明涉及数字图像取证技术领域,更具体地,涉及一种基于频域差分统计特征的JPEG图像重压缩检测方法,针对JPEG压缩原理,利用了DCT变换后,DCT块内的DCT系数的相关性在频域方向增强的现象,对图像的DCT系数矩阵进行了重排列,使得相邻频域的DCT系数在重排矩阵中水平相邻,然后提取重排矩阵水平差分的Markov特征,并结合图像的DCT系数矩阵的斜对角差分矩阵的水平和垂直的Markov特征作为分类特征,该特征很好地利用了块内频率域的差分信息,能够得到有效的分类器,本发明能够有效地检测图像是否经过JPEG重压缩操作,结合JPEG压缩原理,利用图像频率域的块内差分统计特征作为分类特征,具有较好的检测效果,有效提高了检测的准确率。</td>   <td>1.一种基于频域差分统计特征的JPEG图像重压缩检测方法,其特征在于,包括以下步骤：S1.选取图像训练集：训练集由各种质量因子QF1压缩的单次JPEG压缩图像和由质量因子QF1、QF2压缩得到的JPEG重压缩图像构成,其中,QF1∈{50,55,60,65,70,75,80,85,90,95},QF2∈{50,55,60,65,70,75,80,85,90,95},且QF1≠QF2；S2.对训练图像Y通道的DCT系数矩阵进行重排列；S3.提取Markov特征：先对S2中得到的重排矩阵计算水平的二阶差分矩阵,得到原图像频域方向的块内二阶差分矩阵,然后对该差分矩阵使用阈值T进行截断处理,大于T的数值全部用T来替换,小于#T的数值全部用#T来替换,最后对处理后的差分矩阵提取水平的三阶Markov转移概率矩阵,并结合原图像的DCT系数矩阵的斜对角方向的二阶差分矩阵的水平、垂直的三阶Markov转移概率矩阵,得到该图像块内的Markov特征向量；S4.训练特征准备：对所有训练集中的图像进行S3操作后,可以得到训练集中所有图像的特征向量,再将单次JPEG压缩图像的特征向量标识为1,将重压缩图像的特征向量标识为#1,并将标识好的特征集作为SVM的特征训练集,输入SVM分类模型中进行学习；S5：SVM#RFE降维：使用基于支持向量机的回归特征消除方法SVM#RFE对特征训练集进行排序,使有效的特征排在特征训练集前面,得到重排后的特征列表后,选择特征列表的前n个特征值构成新的特征向量,所有图像的n个特征组成一个新的特征向量集；S6.寻找最优的c,g参数：对S5得到的特征向量集和对应的标识集使用径向基内核的SVM进行训练,使用网格搜索的方法搜索最优的惩罚参数c和核参数g,得到分类器模型；S7.测试图像提取特征：先对测试图像进行S2中的重排列,然后提取重排矩阵的水平差分矩阵的水平方向的Markov特征向量,并提取DCT系数矩阵的斜对角差分矩阵的水平、垂直的Markov特征,即进行S3的操作,然后按照S5操作,取重排后的特征排序列表的前n个特征值,组成测试图像的特征向量；S8.分类预测：将S7得到的测试图像的特征向量输入到S6得到的SVM分类模型中,得到测试图像的预测结果；其中,1代表测试图像为单次JPEG压缩图像,#1代表测试图像为JPEG重压缩图像。</td>   <td>G06T9/00;G06K9/62;H04N19/625</td>  </tr>        <tr>   <td>中国专利</td>   <td>              李弘艺       </td>   <td>中山大学</td>   <td>基于seq2seq深度神经网络模型的关键词抽取方法</td>   <td>广东</td>   <td>CN108376131A</td>   <td>2018-08-07</td>   <td>本发明涉及计算机领域,具体涉及一种基于seq2seq(sequence#to#sequence序列到序列)深度神经网络模型的关键词抽取方法,所述方法将目标信息先通过预处理模块作提取,再分别词向量转换模块和词性标注模块进行转换和标注,接着经过候选词权重计算模块得出候选词序列,再经过候选词筛选模块得出关键词,本发明通过将文档向量视为词向量的平均,将词向量和文档向量结合起来作为单词的向量表示,能够更好地分析各个词语对于文档的重要性,选择出更能够代表文档主旨的关键词,同时扩充了关键词提取的考察范围,克服了现有抽取技术不能预测词汇表以外的关键词以及不在源文档内容中的关键词的缺点。</td>   <td>1.一种基于seq2seq深度神经网络模型的关键词抽取方法,其特征在于,所述方法包括以下步骤：S1.将待提取文档和语料库导入预处理模块作提取；S2.经过预处理模块作提取的信息分别进入词向量转换模块和词性标注模块,在词向量转换模块进行词向量转化,在词性标注模块进行词性标注；S3.经过词向量转化和词性标注的信息进入候选词权重计算模块,得出候选词序列。S4.得出的候选词序列进入候选词筛选模块,得出合适关键词。</td>   <td>G06F17/27;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              梁彦豪;              刘镇;                   陆仪启       </td>   <td>中山大学</td>   <td>一种岩土材料连续跨尺度量测表征方法</td>   <td>广东</td>   <td>CN108376422A</td>   <td>2018-08-07</td>   <td>本发明涉及一种岩土材料连续跨尺度量测表征方法,为减少岩土试验的离散性,对同一岩样进行连续跨尺度全断面扫描、多效应试验。本发明包括以下步骤：一、对同一岩样进行连续跨尺度全断面扫描,数据传输至数据快速处置系统,用图像投影重建法处理生成可编辑的岩样跨尺度三维结构图像；二、对同一岩样进行多效应连续跨尺度基本性质和性能参数的试验,数据传输至数据快速处置系统,利用数据属性整理法转化为可识别的标准化数据格式,建立岩样试验数据的标准化数据库；三、利用预设调用路径法从标准化数据库中调用可识别的标准化数据格式的试验数据,采用坐标导航法不断补充赋予至可编辑的岩样跨尺度三维结构图像,构建岩样连续跨尺度四维数字模型。</td>   <td>1.一种岩土材料连续跨尺度量测表征方法,其特征在于扫描得到同一岩样的跨尺度三维结构图像,利用多效应试验获取同一岩样的试验数据并建立标准化数据库,通过调用标准化数据库中的试验数据补充赋予到可编辑的岩样跨尺度三维结构图像,建立表征岩样变化的时空关联,构建岩样连续跨尺度四维数字模型；本发明主要包括以下步骤：(1)对同一岩样进行连续跨尺度全断面扫描,扫描数据传输至数据快速处置系统,处理生成可编辑的岩样跨尺度三维结构图像；(2)对同一岩样进行物理、化学、力学多效应在微观、细观、宏观连续跨尺度上的基本性质和性能参数的试验,试验数据传输至数据快速处置系统,转化为可识别的标准化数据格式,建立岩样试验数据的标准化数据库；(3)从标准化数据库中调用可识别的标准化数据格式的试验数据,不断补充赋予至可编辑的岩样跨尺度三维结构图像；结合岩样变化的物理、化学、力学多效应发生的时差,建立表征岩样变化多效应、多参数的时间关联,在此基础上,结合岩样在宏观、细观、微观上的组成和结构数据,建立表征岩样变化的时空关联,在数据快速处置系统上构建岩样连续跨尺度四维数字模型。</td>   <td>G06T17/05;G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁耀淦;              谢舜道;              陈荣军;                   朱雄泳       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于先验知识的大规模BGA封装最优引脚分布生成方法</td>   <td>广东</td>   <td>CN108363839A</td>   <td>2018-08-03</td>   <td>本发明公开了一种基于先验知识的大规模BGA封装最优引脚分布生成方法,以矩阵代替封装电路进行引脚分布的设计,其中矩阵内部的元素包括信号引脚、电源引脚、地引脚,将这三类引脚以0、1、2代替并填充到矩阵的第一列向量中,以第一列向量的元素为开始,依次进行移位得到下一列元素,最终得到完整的矩阵,然后改变移位的距离可以得到多个不同的矩阵,根据每个矩阵的总电感以及返回路径质量可以得到最优矩阵,该矩阵对应的引脚分布即为最优的引脚分布,本发明的方法不需要进行耗时的迭代搜索,极大地缩短了求解时间,且在相同的参数下所构造的最优解是比较稳定的,封装电路的信号完整性也较强。</td>   <td>1.一种基于先验知识的大规模BGA封装最优引脚分布生成方法,其特征在于：包括以下步骤：A、确定集成电路电源引脚与地引脚之和与封装上总引脚数量的比例,比例参数设置为1：R,同时设置垂直间隔参数vi与水平间隔参数hi,并且vi*hi＝R；B、根据集成电路的封装尺寸M*N设置一个尺寸数值相同的矩阵；C、生成一个长度为M的向量col,根据M与vi,计算出向量col的补偿长度comp后,将向量col延长comp个单位；D、将信号引脚、电源引脚、地引脚分别用0、1、2元素表示,往延长后的向量col中填入0、1、2元素,其中非0元素不连续出现,且非0元素之间由vi#1个0隔开；E、将填充在向量col内的元素作为矩阵的第一列,下一列由上一列的元素在垂直方向上移位得到,将所有列最底端的comp个单位的元素去除后得到完整的矩阵,其中下一列与上一列水平间隔hi个单位,移位的距离为d；F、改变移位距离d,得到多个不同的矩阵,分别计算每个矩阵总电感与返回路径质量,根据所有矩阵的总电感以及返回路径质量的数据得到最优的矩阵,该矩阵内对应的元素为最优的引脚分布。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              梁耀淦;              谢舜道;              陈荣军;              朱雄泳;                   曾衍瀚       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于模拟退火的三维集成电路分层方法及装置</td>   <td>广东</td>   <td>CN108363897A</td>   <td>2018-08-03</td>   <td>本发明公开了一种基于模拟退火的三维集成电路分层方法,通过执行内循环并同时对不同层进行扰动操作,使得不同层之间的功能模块能够进行重组,然后再通过比较旧解与新解选出更优解,以及基于所有的更优解来选出其中的最优解,该最优解即是考虑了硅通孔数量及层间面积差异的因素的解,因此可以根据最优解对应的功能模块在各层中的分布状态来对集成电路进行分层。因此,本发明通过对三维集成电路进行合理分层,有效地考虑了硅通孔数量及层间面积差异的因素影响,相比于传统技术,能够减少设置硅通孔的数量以及使不同层的面积设置得相对平衡,有利于提高信号传输能力。</td>   <td>1.一种基于模拟退火的三维集成电路分层方法,其特征在于,包括以下步骤：S1、随机初始化集成电路中的功能模块及模拟退火参数,记录功能模块所处层的编号并获得旧解；其中,所述模拟退火参数包括初始温度、冷却参数、终止温度和每个温度下的内循环次数；S2、在初始温度下执行内循环,同时对不同编号的层进行扰动操作,从而获得新解；S3、将旧解与新解进行硅通孔数量及层间面积差异的计算比较,选出其中的更优解,并判断是否完成所有次数的内循环,若是则记录该更优解并执行步骤S4,否则返回步骤S2,执行剩余次数的内循环；S4、按照冷却参数进行模拟降温,每降低一次后判断是否达到终止温度,若是则停止模拟降温,执行步骤S5,否则返回步骤S2；S5、从记录的所有更优解中择出最优解,根据最优解对应的功能模块在各层中的分布状态来对集成电路进行分层。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐承佩;              王善庆;              张明;              潘麒元;              李略韬;                   谭杜康       </td>   <td>中山大学;广州物维信息科技有限公司;广州汇数信息科技有限公司</td>   <td>一种家庭监护的行为识别系统及其方法</td>   <td>广东</td>   <td>CN108363989A</td>   <td>2018-08-03</td>   <td>本发明公开一种家庭监护的行为识别系统及其方法,包括设置有摄像模块、无线传输模块、语音报警模块的四旋翼飞行器和上位计算机,所述四旋翼飞行器进行自动巡航和实时定位,采集实时视觉图像数据传送给所述上位计算机,所述上位计算机通过搭建和训练深度神经网络,对图像数据进行实时分析,识别出图像中儿童的行为类别及判断其危险性,发送反馈信号给所述语音报警模块进行警示,并通过互联网向监护人手机发送警报信息。本发明可以及时发现和制止儿童的危险行为,对儿童攀爬、坠落这一常见的意外危险事件进行有效的防范,弥补因监护人监管不到位导致意外事件发生的不足。</td>   <td>1.一种家庭监护的行为识别系统,包括四旋翼飞行器和上位计算机,其特征在于,所述四旋翼飞行器,进行自动巡航和实时定位,设置有摄像模块、无线传输模块和语音报警模块；所述摄像模块,实时捕捉人体行为视觉图像,并把图像数据传送给所述无线传输模块；所述无线传输模块,把接收到图像数据通过无线方式传输给所述上位计算机,并接收所述上位计算机的反馈信号；所述语音报警模块与所述无线传输模块连接,通过所述无线传输模块接收并响应来自所述上位计算机的反馈信号并发出相应的语音警示；所述上位计算机,接收来自所述无线传输模块的图像数据,通过搭建和训练深度神经网络,对图像数据进行实时分析,识别出图像中儿童的行为类别及判断其危险性,并把结果反馈给所述无线传输模块；所述上位计算机还通过互联网与监护人手机连接,向监护人手机发送报警信息。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   王汝鑫       </td>   <td>中山大学</td>   <td>一种基于四元数小波变换的图像拼接检测方法</td>   <td>广东</td>   <td>CN108364256A</td>   <td>2018-08-03</td>   <td>本发明涉及数字图像取证技术领域,更具体地,涉及一种基于四元数小波变换的图像拼接检测方法。本发明首先对图像进行四元数小波变换,四元数小波变换在保留离散小波变换的优势基础上,还具有近似平移不变性,丰富的相位信息,有限的数据冗余等特点,能够很好的描述细节纹理信息和图像轮廓,在四元数小波变换分解得到的各个子带上提取子带四元数系数的实部和3个虚部系数组成新的实数系数矩阵,在实数系数矩阵上提取Markov特征能够用来捕获多方向和多尺度的差异信息,再结合机器学习,得到有效的分类器,因此可以同时保证检测的准确率和检测效率。</td>   <td>1.一种基于四元数小波变换的图像拼接检测方法,其特征在于,包括以下步骤：S1.选取图像训练集：训练集包含没有经过任何篡改操作的原始图像和经过拼接篡改操作的拼接图像；S2.对训练图像进行色彩通道选择：对于图像训练集中的每一张图像,首先进行色彩通道选择,如果训练图像是灰度图像则直接进行S3步骤,如果训练图像是彩色图像,则首先选择亮度Y通道再进行S3步骤；S3.对S2步骤得到的图像进行四元数小波变换：对于每一张图像,使用K层的四元数小波分解,得到3K+1个子带,分别提取每个子带四元系数的实数部分和3个虚部,每个子带可以得到4个实数系数矩阵,经过K层分解后共得到M＝12K+4个实数系数矩阵；S4.提取Markov特征：针对每张图像经过S3步骤得到的M个实数系数矩阵提取Markov特征,得到该图像最终的Markov特征向量；S5.训练特征标识：得到训练图像集所有图像的Markov特征向量后,将原始图像的特征向量标识为+1,将拼接图像的特征向量标识为#1,将两类特征集作为SVM的特征训练集,特征集每行对应一张图像的特征向量；S6.特征降维：使用基于支持向量机的回归特征消除方法SVM#RFE对特征训练集的每一列特征进行排序,得到特征排序列表,按照特征排序列表对每张图像的特征向量选择前n个特征值构成新的特征向量,组成一个新的特征向量集；S7.SVM分类器参数寻优：寻找最优的惩罚参数c和核参数g并训练得到分类器。对S6得到的特征向量集和相应的标识集使用径向基内核的SVM训练,使用网格搜索的方法搜索最优的惩罚参数c和核参数g,得到分类器模型；S8.测试图像提取特征：对测试图像进行与训练图像相同的四元数小波变换,对得到的每个系数子带提取系数成分分离的Markov特征得到特征向量,即进行S2、S3和S4的操作,然后按照S6操作步骤得到测试图像的降维后特征向量；S9.分类预测：利用S7得到的SVM分类模型,对S8得到的测试图像的Markov特征向量进行分类预测,得到预测结果,+1代表分类器检测测试图像为原始图像,#1代表分类器检测测试图像为拼接图像。</td>   <td>G06T3/40;G06K9/62;G06F17/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李禹源;              张东;                   吴增程       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于卷积神经网络的织带边缘毛疵缺陷检测方法</td>   <td>广东</td>   <td>CN108364281A</td>   <td>2018-08-03</td>   <td>本发明公开了一种基于卷积神经网络的织带边缘毛疵缺陷检测方法,利用摄像机采集织带图片,对织带的边缘进行提取,分别得到有毛疵缺陷的样本图片和无毛疵缺陷的样本图片；将采集到的样本图片利用具有多尺度并行训练结构的卷积神经网络进行分类检测,该卷积神经网络能够在增加神经网络深度与宽度的同时,去除普通卷积神经网络中的全连接层,并将一般的卷积转化为稀疏连接,再利用密集成分来近似最优的局部稀疏结构来保持神经网络的高计算性能。因此,本发明的毛疵缺陷检测方法,不仅能够对织带边缘毛疵缺陷进行有效的检测,并且能够有效保持或减小卷积神经网络的计算量,从而提高计算性能。</td>   <td>1.一种基于卷积神经网络的织带边缘毛疵缺陷检测方法,其特征在于：包括以下步骤：A、图像采集及预处理,得到样本图片；B、对样本图片进行图像增强处理,得到训练图片；C、构建具有多尺度并行训练结构的卷积神经网络；D、利用训练图片对卷积神经网络进行训练处理；E、利用经过训练处理的卷积神经网络进行毛疵缺陷检测。</td>   <td>G06T7/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;              刘凯;                   阳建华       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的空域图像隐写方法及系统</td>   <td>广东</td>   <td>CN108346125A</td>   <td>2018-07-31</td>   <td>本发明公开了一种基于生成对抗网络的空域图像隐写方法,通过利用U型结构的生成网络将载体图像转换为概率图,然后利用双曲正切编码模块对概率图进行编码,生成篡改点图,并将载体图像与篡改点图相加,生成载密图像；再利用隐写分析网络对载体图像和载密图像进行区分,并将分类结果以误差的形式反馈回生成网络；最后将训练好的生成网络和编码模块组合在一起,作为最终的空域图像隐写模型,对整个模型输入载体图像,输出载密图像。本发明还公开了一种基于生成对抗网络的空域图像隐写系统,包括生成网络模块、编码模块和图像隐写模块。本发明所提出的基于生成对抗网络的空域图像隐写方法在安全性方面有明显提升,并且设计简单。</td>   <td>1.一种基于生成对抗网络的空域图像隐写方法,其特征在于,包括以下步骤：S1：将载体图像输入到生成网络中,经过生成网络处理后得到与载体图像尺寸相同的概率图；S2：将步骤S1中得到的概率图和相同尺寸的随机噪声图像输入到编码模块中,输出一张与载体图像尺寸相同的篡改点图,将篡改点图与载体图像相加,得到载密图像；S3：用载体图像和步骤S3中生成的载密图像对隐写分析网络进行训练,训练的误差以损失的形式反馈回生成网络,也对生成网络进行训练,此步骤即生成对抗训练；S4：将训练好的生成网络和编码模块组合在一起,作为最终的空域图像隐写模型,对整个模型输入载体图像,输出载密图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              王育基;              陈荣军;              谢舜道;              莫韵;              王灿坤;                   朱雄泳       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于移动互联网技术的小区门禁报警预测方法</td>   <td>广东</td>   <td>CN108345959A</td>   <td>2018-07-31</td>   <td>本发明公开了一种基于移动互联网技术的小区门禁报警预测方法,包括以下步骤：采集门禁报警数据；对门禁报警数据进行初始化处理；对初始化处理后的门禁报警数据进行关联性分析；对关联性分析结果整合实现警情预测。本发明通过对小区以往的警情数据进行分析,对小区警情的事先预测,可以预先测出下一个发生警情的报警点,克服了以往小区发生警情后事后分析研判处理,被动出警的模式,实现了对小区未来警情的预测和区域治安形式的分析,可以主动加强巡逻防控,减少警情的发生,维护社会的长治久安。</td>   <td>1.一种基于移动互联网技术的小区门禁报警预测方法,其特征在于,包括以下步骤：采集门禁报警数据；对门禁报警数据进行初始化处理；对初始化处理后的门禁报警数据进行关联性分析；对关联性分析结果整合实现警情预测。</td>   <td>G06Q10/04;G06F17/30;G07C9/00;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘冶;              林志远;              彭楠;              张允聪;                   印鉴       </td>   <td>广州赫炎大数据科技有限公司;中山大学;刘冶</td>   <td>一种基于搜索引擎技术的数据分析方法及系统</td>   <td>广东</td>   <td>CN108345686A</td>   <td>2018-07-31</td>   <td>本发明涉及一种基于搜索引擎技术的数据分析方法及系统,包括如下步骤：获取用户输入的搜索语句；根据搜索语句获取关键词集合；根据该关键词集合获取匹配的数据分析资源集合；根据匹配的数据分析资源集合,生成并显示数据分析结果集合。相比于现有技术,本发明用户只需要输入搜索语句,即可获取相匹配的数据分析资源,无需用户多次点击操作各个功能模块,也无需用户熟悉阅读复杂的使用说明,操作门槛低,操作方便快捷。</td>   <td>1.一种基于搜索引擎技术的数据分析方法,其特征在于,包括如下步骤：获取用户输入的搜索语句；根据搜索语句获取关键词集合；根据该关键词集合获取匹配的数据分析资源集合；根据匹配的数据分析资源集合,生成并显示数据分析结果集合。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;              武泰屹;              刘洁;              李佳铭;                   苏薛       </td>   <td>中山大学</td>   <td>一种基于黎曼流形的行人重识别方法</td>   <td>广东</td>   <td>CN108334849A</td>   <td>2018-07-27</td>   <td>本发明涉及模式识别技术领域,具体涉及基于属性学习与黎曼流形相结合的一种行人重识别方法。该方法通过研究行人的表征以及语义属性,提出一种泛化能力更强的模型,通过引入行人属性标签,使用卷积神经网络模型,采用多目标损失函数,模型不仅要准确地预测出行人ID,还要预测出各项正确的行人属性。将行人图片通过训练完毕的卷积神经网络得到卷积层的输出张量,分别计算每一张行人图片的协方差描述子。利用协方差描述子进行特征融合以消除特征冗余,进而研究描述子所在黎曼流形的度量,实现更准确的相似度计算。</td>   <td>1.一种基于属性学习与黎曼流形相结合的行人重识别方法,其特征在于：A.从行人重识别领域专家设定的属性中选择最具代表性并适合本行人重识别任务的27个属性,包括了与服装相关的属性及与人体生物特征相关的属性。B.构建一个深度学习模型并对该模型进行训练,深度学习模型使用Resnet残差卷积神经网络模型,使用50层的Resnet结构,采用MSRA初始化方法对网络权值进行初始化。C.该卷积神经网络模型中损失函数的设计,在网络最后连接m+1个全连接层,其中m个给出的是对行人属性特征的预测,1个给出对行人ID的预测。采用多目标损失函数,在给定行人图片后,网络可以同时预测行人标签和属性标签。D.在深度学习模型中损失函数的设计采用多目标损失函数,其中,对于行人ID的分类任务采用交叉熵损失函数,对于属性学习的分类任务同样采用交叉熵损失函数,而深度学习模型总的损失函数定义为<img file="FSA0000158961040000011.TIF" wi="446" he="133"/>其中L<sub>ID</sub>,L<sub>att</sub>分别表示行人ID分类的损失函数和属性标签分类的损失函数,参数λ的作用是平衡两类损失函数在预测任务中的贡献。E.对训练好的卷积神经网络输入测试样本图像,经过多次卷积和下采样的过程得到最后一个卷积层的输出张量F∈RL×L×N。F.在卷积层的输出张量F∈R<sup>L×L×N</sup>中,设<img file="FSA0000158961040000012.TIF" wi="216" he="82"/>是F内的N维特征向量,定义输出特征张量的协方差描述子为<img file="FSA0000158961040000013.TIF" wi="662" he="132"/>其中μ是特征张量块中所有特征向量的均值。G.将测试集中的每张行人图片输入训练完毕的卷积神经网络,均如前所述得到输出张量,并分别计算每一张行人图片的协方差描述子。H.这些协方差描述子均是N×N的对称、半正定矩阵,它们构成<img file="FSA0000158961040000014.TIF" wi="233" he="121"/>维线性空间中的一个凸锥,由于N维特征向量的每一维的方差皆非零,所以对称正定的协方差描述子对应于上述凸锥的内部,凸锥内部是一个微分流形,通过对其赋予一个可计算的有效度量,使其满足黎曼流形的要求,即可运用微分几何的方法,给出流形上点之间距离的计算。I.本发明使用一种仿射不变度量用于协方差矩阵构成的凸锥上,该度量的主要思想是：对于黎曼流形M上任一点X,均可作一个切空间SX,并构造切空间SX和流形M的微分同胚,对切空间SX中的向量V,可通过指数映射将V映射成为流形M上从点X出发的等长同向测地线。J.查找所述特征相似度高于预设相似度阈值的参考行人图像；将特征相似度高于预设相似度阈值的参考行人图像所对应的参考行人确认为所述目标行人图像中的目标行人。所述确定所述目标行人图像中的目标行人和所述参考行人图像中的参考行人为同一个行人,按照所述特征相似度由高至低的排序顺序对所述参考行人图像进行排名,以生成相似度排名；在所述相似度排名中查找排名超过预定名次的参考行人图像；将排名超过预定名次的参考行人图像所对应的参考行人确认为所述目标行人图像中的目标行人。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈海波;                   虞志益       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种用于并行生成SIFT描述子的系统及其方法</td>   <td>广东</td>   <td>CN108334882A</td>   <td>2018-07-27</td>   <td>本发明公开了一种用于并行生成SIFT描述子的系统,包括地址发生器模块、初始描述子生成模块、主方向计算模块、初始描述子重排模块以及子区域重排模块；本发明的一种用于并行生成SIFT描述子的方法,地址发生器模块根据关键点位置信息产生不同的存储文件的地址信息,主方向计算模块以及初始描述子生成模块接收存储文件的地址信息分别计算得到主方向以及生成初始描述子,最后初始描述子重排模块以及子区域重排模块根据主方向对初始描述子进行描述子重排以及子区域重排后得到最终的描述子,主方向的计算以及初始描述子的生成是同时进行的,相较于传统的先计算主方向后计算初始描述子的方式而言,加快了处理速度,减少了计算的时间。</td>   <td>1.一种用于并行生成S#I#FT描述子的系统,其特征在于：包括对关键点进行处理以产生不同的存储文件的地址信息的地址发生器模块(1)、用于生成初始描述子的初始描述子生成模块(2)、用于计算得到主方向的主方向计算模块(3)、用于对初始描述子进行重排的初始描述子重排模块(4)以及对像素点所处的子区域进行重排的子区域重排模块(5),所述地址发生器模块(1)与主方向计算模块(3)、初始描述子生成模块(2)连接,所述初始描述子重排模块(4)与主方向计算模块(3)、初始描述子生成模块(2)、子区域重排模块(5)连接,所述地址发生器模块(1)将产生的幅值幅角存储文件地址、权值存储文件地址送到主方向计算模块(3),所述地址发生器模块(1)将产生的幅值幅角存储文件地址、权值存储文件地址以及子区域划分地址送到初始描述子生成模块(2)。</td>   <td>G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;              张芳;                   刘红梅       </td>   <td>中山大学</td>   <td>一种基于图像放大策略的二值图像可逆信息隐藏方法</td>   <td>广东</td>   <td>CN108335257A</td>   <td>2018-07-27</td>   <td>本发明涉及数字取证、信息安全的领域,更具体地,涉及一种基于图像放大策略的二值图像可逆信息隐藏方法,该方法够实现在信息提取后无损地恢复原始图像。利用十字形模式块来放大原图以达到可逆信息隐藏的目的,通过对32种十字形模式块进行分析并分类,并选择合适的模式块作为参考模式块,以得到视觉质量较好的参考图；在确定参考模式块后,分析原图中以每个像素点为中心的十字形模式块类型,采用设计的放大策略,将每个像素点放大成为一个2×2的块,得到参考图；最后采用一种块内可翻转像素的选择策略,翻转像素点,进行信息的嵌入。发明可用于信息安全特别是二值图像秘密信息传输方面。</td>   <td>1.一种基于图像放大策略的二值图像可逆信息隐藏方法,其特征在于,包括以下步骤：S1.放大图像,输入原始图像X,其大小为W×H,使用图像放大策略将图像放大,得到大小为2W×2H的参考图RX；S2.分块,将参考图RX分为非重叠的2×2的块；S3.选择并置乱,选择所有的非全黑或非全白块组成一个块序列S,使用一个随机序列用做密钥K去置乱块序列S,得到一个新的序列S1；S4.嵌入秘密信息,对S1中的每一块使用一种块内可翻转像素的选择策略,选择嵌入的位置,通过翻转可嵌入位置的像素点将秘密信息M的比特嵌入到块中,嵌入完成后得到嵌入秘密信息的块序列S2；S5.反置乱,使用步骤S3中的密钥K对快序列S2进行反置乱,得到新的序列S3；S6.生成隐写图Y,扫描参考图RX和块序列S3,用S3中的块去替换RX中的非全黑和非全白块,得到最终的隐写图Y,大小为2W×2H。</td>   <td>G06T1/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   黄信朝       </td>   <td>中山大学</td>   <td>一种基于LIOP特征与块匹配的图像区域复制篡改检测方法</td>   <td>广东</td>   <td>CN108335290A</td>   <td>2018-07-27</td>   <td>本发明主要针对数字图像的取证领域,更具体地,涉及一种基于LIOP特征与块匹配的图像区域复制篡改检测方法。本发明将基于特征点及基于分块两类方法相结合,融合两类方法的优势；首先选取LIOP特征作为图像特征提取算法,相比其他特征,能够更好地应对旋转、缩放、JPEG压缩、添加噪声等情况；特征匹配之后,使用新的匹配对表达模型对匹配对进行表达并筛选,去除冗余的匹配对,使得精确度提高,计算复杂度降低。根据匹配对进行图像切割并分块提取特征后,使用了块匹配算法对篡改进行匹配,最后进行精确定位；本算法检测精度高,同时对各种类型图像复制粘贴篡改如旋转、缩放、加噪声、压缩等,都有着很好的效果。</td>   <td>1.一种基于LIOP特征与块匹配的图像区域复制篡改检测方法,其特征在于,包括以下步骤：S1.检测DoG关键点：对于待检测的图像,构造DoG尺度空间,在DoG尺度空间中找寻极值点作为关键点,并把关键点定位于图像上；S2.提取LIOP特征向量：把步骤S1获取的每个关键点区域规范化成圆形区域,根据像素值将区域分割为B个子区间,每个子区间的所有像素的像素值都在相应区间段之内,区域内每个像素的描述子通过该像素周围采样点的灰度信息来计算得到,通过将局部顺序区间内所有像素点的描述子串联起来构成LIOP特征向量；S3.匹配特征：对于步骤S2中提取出来的每个特征向量,计算其与其它所有特征向量之间的欧式距离,并按照从小到大排序；计算最近邻d1和次近邻d2之间的比值,如果比值小于ε(0.5<ε<0.7),则认为距离为d1的两个特征匹配,构成匹配对；S4.转换匹配对模型并过滤：在匹配对的两个特征点中,确定其中的一个特征点为起始点(x1,y1),对应特征点为终点(x2,y2),将匹配对表达为四维空间M∈{x1,y1,x2#x1,y2#y1|x1,x2,y1,y2∈R}中的点,并确保相邻的匹配对使用相同一侧的特征点作为起始点,将四维空间M的每一维都划分为相同大小的区间,大小取为μ,则各维度上不同区间的组合将四维空间M划分为相同大小的矩形四维子空间集,对于落在同一子空间的点的数量σ,若σ>1,则随机选择其中的一个点进行保留,去除掉其他的点；S5.切割图像并分块提取Zernike特征：若存在有效的匹配对,则对于每一个匹配对,以匹配对的两个特征点坐标为中心点,切割出两个α×α大小的矩形图像,以b×b(b<α)为窗口,以1为步进,遍历图像并将分割出的图像有重叠的进行分块,对每个分块,计算其5阶Zernike矩系数,生成一个12维特征向量作为该位置的特征；S6.进行块匹配：以Zernike矩系数为准,对切割出的两个对应的图像块A和B进行匹配,首先随机初始化匹配,A中的点随机匹配到B中的点,然后通过迭代的传播以及随机搜索对匹配进行不断优化,每一次迭代方向为从左上到右下以及从右下到左上交替进行,最后获得A到B的匹配结果,通过相同的方式获得B到A的匹配,最终获得两个不同方向的块匹配结果；S7.定位复制区域：以每个像素为中心,m×m为大小,计算矩阵方差De,对于矩阵方差De小于Δ的像素,则认为是属于待选篡改区域；对两个块匹配结果,可分别获得A中的待选篡改区域ΓA以及B中的区域ΓB,然后根据块匹配算法的结果,将待选篡改区域的点一一映射到对应区域,得到B中的Γ'A以及A中的Γ'B,最后定位区域为ΓA∩Γ'B以及ΓB∩Γ'A,将所有匹配对的结果进行整合,并应用形态学操作以滤除杂乱点,生成最终的检测结果图。</td>   <td>G06T7/00;G06T7/11;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄佳博;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于生成式对抗网络的多图像人脸对齐的方法及装置</td>   <td>广东</td>   <td>CN108319932A</td>   <td>2018-07-24</td>   <td>本发明公开一种基于生成式对抗网络的多图像人脸对齐方法,包括输入多张真实人脸图像至生成器,生成器处理该图像,以生成拟合真实图像分布的合成图像；将真实人脸图像与合成图像输入判别器,以获得真实人脸图像的真实概率及合成图像的真实概率,迭代更新生成器和判别器的参数直至其收敛以确定由生成器和判别器构建的模型；将待对齐多人脸图像输入到所确定的模型中,通过一次前向传递运算得到对齐后人脸图像。本发明能够根据多张人脸图像生成一张清晰且对齐后的人脸图像,多人脸图像矩阵与对齐图像相减得到的噪声矩阵的稀疏程度反应了生成人脸图像与输入人脸图像对齐的程度,而生成式对抗网络记录了人脸的整体与细节特征。</td>   <td>1.一种基于生成式对抗网络的多图像人脸对齐方法,其特征在于,包括如下步骤：S10输入多张经过预处理的真实人脸图像至生成器,生成器对所输入的真实人脸图像进行编码、转码及解码处理,生成拟合真实图像分布的合成图像,将多张预处理后真实人脸图像与合成图像输入判别器,以获得真实人脸图像的真实概率及合成图像的真实概率,迭代更新生成器和判别器的参数直至其收敛以确定由生成器和判别器构建的模型；S20将待对齐多人脸图像输入到所确定的模型中,通过一次前向传递得到对齐后人脸图像。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;              戴利孟;              刘洁;              车航健;                   张扬       </td>   <td>中山大学</td>   <td>一种局部非线性对齐的非线性数据降维方法</td>   <td>广东</td>   <td>CN108319983A</td>   <td>2018-07-24</td>   <td>本发明公开了一种基于局部非线性对齐的非线性数据降维方法。首先对高维空间中的每一个样本点都采用KNN算法取它的近邻点并组成相应的块。将这些高维空间的数据点块分别都用PCA算法降到低维的空间平面。在低维空间上把通过PCA降下来的每一个块通过各自的平移旋转使得块能够被完美的拼接起来。拼接的准则是每一个点可能被不同的几个块包含,那么所有块中被包含的这个点属于同一个点,它们在低维的表示理论上应该是可以重合的；于是这几个块中的这个点可以求出其平均点的位置,所有在不同块中应该被表示为同一点的点到它的平均点的距离的二范数之和应要最小,如此才能保证不同块中的同一点尽可能重合。所有块通过各自的平移旋转之后使得每一个点所产生的误差总和最小,如此我们可以把不同的块在低维平面进行了完美的拼接。从而解得样本点在低维嵌入的全局坐标,得以实现局部非线性对齐的非线性数据降维。</td>   <td>1.一种局部非线性对齐的非线性数据降维方法,其特征在于该方法的步骤如下：A.对高维空间中的每一个样本点都采用KNN算法取其k个最近邻点作为这个点的领域块,有N个点就可以形成N个块；B.将这些高维空间的数据块分别都用PCA算法降到低维的空间平面,坐标表示为Θp,p＝1,…,N。高维空间中点xi,i＝1,…,N,经PCA降维后在Θp中的坐标表示为θi,p；C.对每一个块Θp构建未知的旋转矩阵和平移矩阵。Θp经过平移旋转后的低维嵌入局部坐标表示为Yp,而Θp中某一点θi,p经过平移旋转后的低维坐标表示为yi,p；D.计算出所有低维嵌入点与其均值点总体误差的目标函数为<img file="FSA0000158788950000011.TIF" wi="272" he="84"/>通过对目标函数的求解,取最小特征值所对应的特征向量来求出所有块的旋转矩阵V,进而求出所有块平移矩阵ξ；E、求出了ξ和V后,进一步求出所有样本点的最终低维嵌入的坐标为：Y＝Smeanξ+LmeanV。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              孙雪冬       </td>   <td>中山大学</td>   <td>一种基于教学资源的个性化教学过程自动生成方法及系统</td>   <td>广东</td>   <td>CN108319705A</td>   <td>2018-07-24</td>   <td>本发明公开了一种基于教学资源的个性化教学过程自动生成方法。该方法主要是通过分析教学资源的知识构成及知识聚集程度进行知识单元及知识元划分,并应用超图理论对知识元间的关系进行图形化描述；并根据教学资源对知识表达的方式、方法,应用活动对知识表达进行描述；利用教学资源中包含的知识元及知识元间的关系抽象出不同领域的、基于有向超图描述知识图谱；基于相关知识图谱,根据学习者的目标知识和背景知识进行逆向回溯生成个性化的、优化的知识路径；利用资源中包含的知识元与个性化知识路径中包含的知识元之间的包含关系生成相关教学过程所有可能的支持资源；利用资源中活动属性与教学过程属性之间的关系进行资源的组合优选,从而生成优化的教学过程。</td>   <td>1.一种基于教学资源的个性化教学过程自动生成方法,其特征在于：该方法包括以下步骤：步骤1,对教学资源进行分解,分解为知识单元和知识元,并用知识表达活动对知识元进行描述,建立资源知识模型；应用有向超图对资源知识表达进行描述,建立资源活动模型；步骤2,根据教学资源的知识构成及学习者的知识目标和知识背景生成个性化的、优化的知识路径；步骤3,利用教学资源中包含的知识元及个性化知识路径中的知识元之间的包含关系生成过程可能的支持资源；根据活动属性与过程属性之间的关系及学习者的性能目标,利用遗传算法进行活动与资源的优选,生成相对于学习者的、个性化的、优化的教学过程；步骤4,监测学习目标、知识背景和资源环境,若三者任一出现变化时,则进行相关性判断以及相应处理。</td>   <td>G06F17/30;G06N5/02;G06Q10/04;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              丁卉;                   余志       </td>   <td>中山大学</td>   <td>一种大气高污染过程动态追踪方法</td>   <td>广东</td>   <td>CN108304610A</td>   <td>2018-07-20</td>   <td>本发明提供一种大气高污染过程动态追踪方法。该方法首先利用连续多日大气污染状态估计,结合高污染发生可能性诊断,实现当前日期下对未来连续多日的高污染发生的追踪诊断；并跟随当前日期的更新,实现追踪时期的动态更新,动态循环未来连续多日高污染发生追踪诊断,最终实现对大气高污染过程的动态追踪。</td>   <td>1.一种大气高污染过程动态追踪方法,其特征在于,具体步骤如下：1S.确定追踪开始日期的大气污染状态以及未来连续多日的气象条件；2S.基于气象对大气污染状态的影响关系,建立连续多日大气污染状态估计方法,滚动估计未来连续多日的大气污染状态；3S.通过估计结果进行未来高污染发生可能性的诊断；4S.当日期有更新时,更新开始日期,重复1S#3S。</td>   <td>G06F17/50;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;              丁卉;                   刘永红       </td>   <td>中山大学</td>   <td>一种气象影响下的大气污染转变关系定量估计方法</td>   <td>广东</td>   <td>CN108280131A</td>   <td>2018-07-13</td>   <td>本发明提供一种气象影响下的大气污染转变关系定量估计方法,该方法基于大气污染和气象条件的历史数据,通过层次化挖掘多种关键气象因素对大气污染的影响,实现不同水平大气污染转变发生可能性估计。首先建立大气污染和气象数据的基础样本库,在此基础上,确定影响大气污染的关键气象因素,进而依据关键气象因子相似判别,多层次挖掘相似样本集,最后,基于相似样本集实现对估计日不同污染变化程度的估计。通过此方法能够获得不同污染变化发生可能性概率的精细化定量结果。</td>   <td>1.气象影响下的大气污染转变关系定量估计方法,其特征在于,具体步骤如下：1S.获取历史污染频发期的大气污染数据和气象数据,建立基础样本库；2S.确定影响大气污染变化的关键气象因素；所述的关键气象因素为分析所有气象因子对大气污染变化的影响作用,并分别计算气象因子与大气污染变化的相关性,选择影响作用强或相关性显著的因子作为关键气象因子；3S.基于关键气象因素,层次化挖掘相似样本集；4S.基于相似样本集,计算污染转变发生可能性概率矩阵。</td>   <td>G06F17/30;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         滕家宁;                   张东       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于稀疏表示的超市商品图像识别方法</td>   <td>广东</td>   <td>CN108280469A</td>   <td>2018-07-13</td>   <td>本发明公开了一种基于稀疏表示的超市商品图像识别方法,先采集商品的图像数据,并分成训练集和测试集,首先分别对训练集以及测试集的图像数据进行处理后得到训练集的关键点的局部描述符以及测试集的关键点的局部描述符,根据训练集的关键点的局部描述符可以训练得到稀疏字典,训练好的稀疏字典可以对局部描述符进行稀疏并计算得到全局特征描述符,利用SVM分类方法对图像数据的类标和训练集的全局特征描述符进行训练得到SVM分类器,然后将测试集的全局特征描述符输入到SVM分类器即可完成对商品的识别,本发明的识别方法对超市商品的识别精度较高。</td>   <td>1.一种基于稀疏表示的超市商品图像识别方法,其特征在于：包括以下步骤：A、采集商品的图像数据,并分成训练集和测试集,分别对训练集和测试集的各个图像数据进行分割、合并以及提取处理,得到训练集和测试集中各个商品完整的食物区域；B、选取训练集和测试集中对应的食物区域的关键点；C、对每一个关键点进行特征提取后得到每一个关键点的局部描述符；D、根据训练集的关键点的局部描述符,采用稀疏字典训练方法对图像数据进行学习得到一个过完备的稀疏字典；E、利用学习到的稀疏字典对训练集以及测试集的每一个图像数据的关键点的局部描述符进行稀疏表示,并计算得到训练集的全局特征描述符以及测试集的全局特征描述符；F、利用SVM分类方法对图像数据的类标和训练集的全局特征描述符进行训练得到SVM分类器；G、SVM分类器根据测试集的全局特征描述符对商品进行识别。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林凯荣;              李文静;                   梁汝豪       </td>   <td>中山大学</td>   <td>基于GIS-神经网络集成的山洪灾害风险区划及预测方法</td>   <td>广东</td>   <td>CN108280553A</td>   <td>2018-07-13</td>   <td>本发明涉及一种基于GIS#神经网络集成的山洪灾害风险区划及预测方法,包括：S1.利用关联规则挖掘山洪灾害中风险因子与风险等级之间的关联关系,辨识风险因子,构建定量化的山洪灾害风险评价指标体系；S2.采用层次分析法确定危险性和易损性指标体系及其权重,生成各要素图层；S3.利用ArcGIS将山洪灾害危险性和易损性分布图层叠加得到山洪灾害风险分布图；S4.采用ISO最大似然法聚类及自下而上区域合并与自上而下定性分析结合的方法,形成山洪灾害风险区划；S5.利用Elman神经网络分析评价指标与风险等级、灾情数据之间的非线性关系,构建山洪灾害风险评价及损失预估模型。本发明解决了变化环境下山洪灾害评估中的空间尺度不确定性问题,可广泛用于山洪灾害风险评估。</td>   <td>1.一种基于GIS#神经网络集成的山洪灾害风险区划及预测方法,其特征在于,包括以下步骤：S1.利用关联规则挖掘山洪灾害中风险因子与风险等级之间的关联关系,辨识风险因子,构建定量化的山洪灾害风险评价指标体系；S2.采用层次分析法确定危险性和易损性指标体系及其权重,生成各要素图层；S3.利用ArcGIS将山洪灾害危险性和易损性分布图层叠加得到山洪灾害风险分布图；S4.采用ISO最大似然法聚类以及自下而上区域合并与自上而下定性分析结合的方法,形成山洪灾害风险区划；S5.利用Elman神经网络分析评价指标与风险等级、灾情数据之间的非线性关系,构建山洪灾害风险评价及损失预估模型。</td>   <td>G06Q10/04;G06Q10/06;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王语聪;                   张东       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种轧钢板热喷字符串识别与验证系统及方法</td>   <td>广东</td>   <td>CN108268841A</td>   <td>2018-07-10</td>   <td>本发明公开了一种轧钢板热喷字符串识别与验证系统及方法,提出了针对轧钢板热喷字符串识别和喷印质量验证系统,而且进一步对存在喷印问题和识别问题的字符串的识别提出了基于图像对比的解决方法。该方法可以适用于无法剔除喷印有误产品的情况,有效提高生产自动化程度和生产效率。</td>   <td>1.一种轧钢板热喷字符串识别与验证系统,其特征在于：包括喷印工位和后续工位,所述喷印工位设有图像采集部分、预处理部分、字符提取部分、字符识别部分、字符验证与喷印质量检测部分,所述后续工位设有图像采集部分、预处理部分、字符提取部分、字符识别部分和字符判断部分；所述图像采集部分,用于使用图像采集设备采集并储存产品图像；所述预处理部分,用于对有图像采集设备采集到的视频信息进行预处理,获取所需识别的字符的清晰图像；所述字符提取部分,用于从预处理后的清晰图像中提取字符；所述字符识别部分,用于对提取出的字符进行OCR识别；所述字符验证与喷印质量检测部分,使用喷印时已知的所需喷印字符信息与字符识别结果对比,并将字符识别结果和字符图像保存到数据库中,使用标准的字符图像与采集到的字符图像对比,检测喷印质量,在出现喷印质量问题时予以提示；所述字符判断部分,用于将字符识别结果在数据库中检索,取得字符识别结果的图像信息,依据字符图像相似程度做二次验证,选取字符图像相似程度最高的作为识别结果,并在存在字符图像差异过大时予以警示,并请求人工判断。</td>   <td>G06K9/00;G06K9/32;G06K9/34;G06K9/46;G06K9/54;G06K9/62;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         钟鸣;              林凯荣;              陈晓宏;              江涛;                   王娇       </td>   <td>中山大学</td>   <td>一种基于信息扩散的小流域山洪灾害风险分析方法</td>   <td>广东</td>   <td>CN108269016A</td>   <td>2018-07-10</td>   <td>本发明涉及一种基于信息扩散的小流域山洪灾害风险分析方法,其引入信息扩散理论,以有限的历史山洪资料为依据,将不完备信息条件下具有单值观测值的样本进行集值化,转变为具有模糊不确定性的模糊集值样本,建立山洪灾害信息矩阵,并引入皮尔逊三型曲线、超越概率及置信度的计算,从而实现通过有限的知识快速地进行山洪灾害风险定量化评价,使结果更加接近实际情况。本发明能够提高山洪灾害风险分析结果的客观性和科学性。</td>   <td>1.一种基于信息扩散的小流域山洪灾害风险分析方法,其特征在于：包括以下步骤：(1)资料搜集的步骤：收集小流域在历史上经受山洪灾害时的环境数据；(2)风险因子分析与选取的步骤：通过对收集的数据的分析,选取若干个可能诱发山洪灾害的环境影响因素作为风险因子；(3)利用信息扩散构建山洪灾害信息矩阵的步骤：根据信息扩散理论,利用正态信息扩散函数,构造研究区域山洪灾害信息矩阵,具体步骤如下：1)确定样本集的步骤：将所选取风险因子的在收集的环境数据中的实测数据作为观测样本点,用x表示,假设x数量为n,则样本集X如式①所示,X＝{x1,x2,x3,...,xn#1,xn}##①2)确定论域的步骤：根据X的最大值b和最小值a,选取适当的监控点数m,取得监测点集合U如式②所示,U＝{u1,u2,u3,···,um}(u1≤a≤b≤um)##②<img file="FDA0001552298190000011.TIF" wi="534" he="87"/>其中xi为观测样本集X中第i个样本点,1≤i≤n3)构建山洪灾害信息矩阵的步骤：由于山洪灾害中水文过程的随机性比较符合正态分布,所以选取正态分布模型作为扩散模型,通过正态信息扩散函数③,样本集X中的每一个观测样本点xi都将其所携带的信息扩散给监测点集合U中的所有点,<img file="FDA0001552298190000012.TIF" wi="700" he="141"/>其中,uj为监测点集合U中的第j个元素,1≤j≤m；μij表示xi扩散至uj的信息；h是扩散系数,根据样本X中的最大值b和最小值a及样本X中x的数量n来确定,如公式④所示：<img file="FDA0001552298190000021.TIF" wi="700" he="420"/>则,X在二维空间X×U上的山洪灾害信息矩阵Q,如式⑤所示：<img file="FDA0001552298190000022.TIF" wi="541" he="302"/>其中,Qij为山洪灾害信息矩阵Q中第i行第j列的元素(4)对矩阵归一化处理的步骤：对山洪灾害信息矩阵Q的各行进行归一化处理：<img file="FDA0001552298190000023.TIF" wi="406" he="87"/>将各行分别除以所对应的Ci的值,使得各行累加之和分别等于1,生成新的矩阵P,其中,pij为矩阵P中第i行第j列的元素,如式⑦所示：<img file="FDA0001552298190000024.TIF" wi="285" he="127"/>(5)计算风险概率的步骤：将各个监控点由不同实测数据分配得到的信息叠加,得到各个监测点所分配到的信息总和qj,如式⑧所示<img file="FDA0001552298190000025.TIF" wi="310" he="79"/>再将监测点累加得到的信息除以qj叠加得到的样本总和数,得到各监控点的风险概率值wj,如式⑨所示：<img file="FDA0001552298190000026.TIF" wi="326" he="143"/>(6)计算风险超越概率的步骤：完成风险评估要计算超过uj值的概率总和,即形成超越概率Rk,超越概率值表明不同区域面临不同程度山洪风险的差别,如式⑩所示。<img file="FDA0001552298190000031.TIF" wi="333" he="85"/>(7)计算超越概率分布区间的步骤：计算超越概率后,对不同置信水平下的概率风险做一个范围的估计,假设置信水平为1#α,将Rk重新从小到大排序,得到新的Rk后,计算1#α置信度下的置信区间[Rk1,Rk2],其中,<img file="FDA0001552298190000032.TIF" wi="310" he="79"/><img file="FDA0001552298190000033.TIF" wi="318" he="87"/>式中,z＝round(M(α/2)),round为四舍五入函数,M为监控点数；(8)计算风险因子阈值的步骤：通过皮尔逊三型曲线拟合水文关系曲线,根据历史数据得到灾害发生频率,结合具体情况确定洪水频率,通过拟合曲线获取风险因子阈值；(9)确定山洪灾害风险值的步骤：将计算得到的风险因子阈值代入超越概率与其分布区间,得到该值下风险值以及风险区间；将给定洪水频率对应的风险因子的实测数据代入超越概率分布中,计算超越概率值以及分布区间下的取值范围,即流域发生大于或等于某量级山洪灾害的风险。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;              薛飞;                   刘红梅       </td>   <td>中山大学</td>   <td>一种JPEG重压缩图像篡改定位方法</td>   <td>广东</td>   <td>CN108269221A</td>   <td>2018-07-10</td>   <td>本发明涉及数字图像取证技术领域,更具体地,涉及一种JPEG重压缩图像篡改定位方法。包括以下步骤：S1.估计DCT系数值,计算出篡改区域的DCT系数C1和未篡改区域的DCT系数C2的值；S2.用归一化灰度梯度共生矩阵对DCT系数分布的混合模型进行建模；S3.计算出带未知参数的DCT系数条件概率；S4.对未知参数进行估计,将估计得到的参数代入至S3步骤中,得到不含未知参数的DCT系数条件概率；S5.计算某一频率f上的篡改概率图S6.得到DCT系数块的篡改概率图；S7.利用连通性和高斯权值滤波对篡改概率图后处理；S8.对篡改区域进行定位。本发明首次使用二阶的灰度梯度共生矩阵对DCT的混合分布进行了建模,得到了更为准确的混合分布模型,使得对JPEG重压缩篡改定位更加的准确。</td>   <td>1.一种JPEG重压缩图像篡改定位方法,其特征在于,包括以下步骤：S1.估计DCT系数值,计算出篡改区域的DCT系数C1和未篡改区域的DCT系数C2的值；S2.用归一化灰度梯度共生矩阵对DCT系数分布的混合模型进行建模；S3.计算出带未知参数的DCT系数条件概率；S4.对未知参数进行估计,将估计得到的参数代入至S3步骤中,得到不含未知参数的DCT系数条件概率；S5.计算某一频率f上的篡改概率图：提取测试图片某一频率f上的DCT系数值组成一个矩阵,计算矩阵中所有点的篡改概率,这些概率值按矩阵中点的顺序就可以得到某一频率f上的篡改概率图,篡改概率图中的每一个点代表的是每个8*8块的篡改概率；S6.按zig#zag的排列顺序求出前21个AC系数的篡改概率图,21个频率上的篡改概率求平均后,得到DCT系数块的篡改概率图；S7.利用连通性和高斯权值滤波对篡改概率图后处理；S8.对篡改区域进行定位。</td>   <td>G06T1/00;G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周达敏;              陈荣军;              嵇志辉;              谢舜道;              李小敏;                   朱雄泳       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种圆形寻像图形二维码及其生成和解译方法</td>   <td>广东</td>   <td>CN108256609A</td>   <td>2018-07-06</td>   <td>本发明公开了一种圆形寻像图形二维码及其生成和解译方法,该二维码包括由三个黑色大圆组成的寻像图形和由黑色小圆组成的矩阵,所述三个黑色大圆圆心组成一个等腰直角三角形。其生成方法步骤为：将数据流转化为字节流,进行编码,确定二维码大小,布置寻像图形,转化为矩阵,布置矩阵,生成二维码图像。其解译方法步骤为：扫描二维码图片,进行处理,寻找寻像图形,对二维码进行校正,转化为0/1矩阵,将矩阵解码,译为数据信息,完成解译。寻像图形和矩阵都采用圆形,结构简单,抗模糊性好,易识别,可以使用霍夫变换算法进行检测,提高其解码速度。采用中短码长的LDPC码编码,其纠错性能比RS算法更高。</td>   <td>1.一种圆形寻像图形二维码,其特征在于：所述二维码包括由三个黑色大圆组成的寻像图形和由黑色小圆组成的矩阵,所述三个黑色大圆圆心组成一个等腰直角三角形。</td>   <td>G06K19/06;G06K7/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              陈子良;              王可泽;                   许瑞佳       </td>   <td>中山大学</td>   <td>一种基于对抗学习的多源域适应迁移方法及系统</td>   <td>广东</td>   <td>CN108256561A</td>   <td>2018-07-06</td>   <td>本发明公开了一种基于对抗学习的多源域适应迁移方法及系统,所述方法包括如下步骤：步骤一,使用各源域数据进行预训练并初始化目标模型的表示网络和分类器；步骤二,使用多源域数据与目标域数据进行多路对抗,更新目标模型的表示网络和多路判别器；步骤三,计算每个源域与目标域之间的对抗分数；步骤四,基于各源域的分类器和对抗分数对目标域进行分类；步骤五,选取高置信度的目标域伪样本微调目标模型的表示网络和分类器；步骤六,返回步骤二,进行步骤二#五,直至模型收敛或达到最大迭代次数时停止训练,本发明可不再依赖单一源域标签集合与目标域一致的假设,并且可有效地避免多源域适应过程中存在的负迁移现象。</td>   <td>1.一种基于对抗学习的多源域适应迁移方法,包括如下步骤：步骤一,使用各源域数据进行预训练并初始化目标模型的表示网络和分类器；步骤二,使用多源域数据与目标域数据进行多路对抗,更新目标模型的表示网络和多路判别器；步骤三,计算每个源域与目标域之间的对抗分数；步骤四,基于各源域的分类器和对抗分数对目标域进行分类；步骤五,选取高置信度的目标域伪样本微调目标模型的表示网络和分类器；步骤六,返回步骤二,进行步骤二#五,直至模型收敛或达到最大迭代次数时停止训练。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吕子仙;              陈艺芳;                   康显桂       </td>   <td>中山大学</td>   <td>基于方向一致性卷积神经网络的图像增强检测方法及系统</td>   <td>广东</td>   <td>CN108257115A</td>   <td>2018-07-06</td>   <td>本发明公开了基于方向一致性卷积神经网络的图像增强检测方法,包括以下步骤：选择一幅待测图像,并裁剪为固定尺寸,裁剪选择中心裁剪；将裁剪后的图像输入到预先训练好的基于方向一致性卷积神经网络模型,计算待测图像经过图像增强操作和未经过图像增强操作的概率；比较待测图像经过图像增强操作和未经过图像增强操作的概率大小,最终判断待测图像是否经过图像增强操作。本发明还公开了基于方向一致性卷积神经网络的图像增强检测系统,包括获取模块、计算模块、判断模板。本发明针对特定的图像增强操作进行取证,实现了较高的图像检测率,解决了现有的训练方法费时费力且极易造成过拟合的缺陷。</td>   <td>1.基于方向一致性卷积神经网络的图像增强检测方法,其特征在于,包括以下步骤：S1：选择一幅待测图像,并裁剪为固定尺寸,裁剪选择中心裁剪；S2：将裁剪后的图像输入到预先训练好的基于方向一致性卷积神经网络模型,计算待测图像经过图像增强操作和未经过图像增强操作的概率；S3：比较待测图像经过图像增强操作和未经过图像增强操作的概率大小,最终判断待测图像是否经过图像增强操作。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         滕家宁;                   张东       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于卷积神经网络的中餐食物识别方法</td>   <td>广东</td>   <td>CN108256571A</td>   <td>2018-07-06</td>   <td>本发明公开了一种基于卷积神经网络的中餐食物识别方法,先采集中餐食物的图像数据,然后生成中餐食物的图像数据集,按照一定的比例将图像数据集分成训练集和测试集,然后根据训练集内的图像数据对构建好的卷积神经网络模型进行训练,训练的过程中采用均匀分步学习策略进行训练,训练完成后生成模型文件,根据模型文件可以对中餐食物图像进行识别,由于在训练卷积神经网络时采用均匀分步学习策略进行训练,节省了一定的训练时间,随着训练的进行,均匀分步学习策略逐步调小学习率,从而使得卷积神经网络的精确率更高,本发明识别食物类别的精确率较高,并且识别的时间较短。</td>   <td>1.一种基于卷积神经网络的中餐食物识别方法,其特征在于：包括以下步骤：A、采集中餐食物的图像数据,并生成中餐食物的图像数据集,然后将图像数据集分为训练集与测试集；B、构建卷积神经网络模型；C、采用均匀分步学习策略,根据训练集对卷积神经网络进行训练,并生成模型文件；D、根据模型文件对中餐食物图像进行识别。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭明锦;              陈荣军;              谢舜道;                   朱雄泳       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种复杂环境下的QR码检测定位方法</td>   <td>广东</td>   <td>CN108241860A</td>   <td>2018-07-03</td>   <td>本发明公开了一种复杂环境下的QR码检测定位方法,通过第一卷积神经网络判断获取到的图片是否含有QR码,若没有,则可以停止识别以避免不必要的运算,若有,则随机选取待检测的图片的任一局部块送到第二卷积神经网络中,当第二卷积神经网络识别到该局部块为QR码区域,即代表随机选取时命中了QR码区域时,以该命中的QR码区域为中心对其上下左右的局部块进行识别,并不断向外扩散,直至扩散到四个方向上都识别到背景区域时停止,并以此四个边缘初步定位出QR码区域,最后再检测出寻位图形,并通过透视变换矫正得到最终的QR码,本发明的方法适用于复杂环境下的检测定位,不仅检测过程快速高效,还能减少不必要的流程,提高识别效率。</td>   <td>1.一种复杂环境下的QR码检测定位方法,其特征在于：包括以下步骤：A、获取图片,并对图片进行预处理；B、训练第一卷积神经网络,将图片整体送入已训练好的第一卷积神经网络中,第一卷积神经网络判断图片是否含有QR码或类似QR码的图形；C、训练第二卷积神经网络,将含有QR码或类似QR码的图形的待检测图片送入到已训练好的第二卷积神经网络中,以随机命中的方式进行局部识别得到整个QR码区域；D、基于QR码的三个寻位图形的特征进行定位后得到最终的QR码。</td>   <td>G06K9/32;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              郭浩翀;                   林谋广       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的图像去雨滴方法</td>   <td>广东</td>   <td>CN108230278A</td>   <td>2018-06-29</td>   <td>本发明实施例公开了一种基于生成对抗网络的图像去雨滴方法。该方法主要通过构建生成对抗网络,利用深度去雨算法,提供一种更加高效显著的图像去雨方法,在实际使用中只需要把图片输入生成式网络中,通过一次前向传播即可得到结果图片,相比起传统的图像处理方法会有更高效的效果,此外,在模型中引入特征空间上的感知相关性,可以调整部分去雨效果的细节,使得生成的图像更加清晰直观,在图像增强方面可以提供更好的效果。</td>   <td>1.一种基于生成对抗网络的图像去雨滴方法,其特征在于,所述方法包括：从数据库中获取外景图片集；图像预处理,为所获取到的外景图片集加入下雨效果,构建训练集和测试集；构建生成式网络,其输入为带雨场景图像,输出为清晰场景图像；根据像素空间上的误差训练生成式网络；加入特征空间上的误差再次训练生成式网络；构建判别式网络,其输入为真实样本或者由生成器生成的样本,输出为真或假的单个标识；把判别式网络加入到模型之中,采用误差反向传播算法训练所述的生成式网络；将测试集中的带雨场景图输入训练好的生成式网络中,输出为对应的清晰场景图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王学钦;              罗燕;                   吕林       </td>   <td>中山大学;中山大学中山眼科中心</td>   <td>眼底彩照血管及动静脉的识别方法</td>   <td>广东</td>   <td>CN108230306A</td>   <td>2018-06-29</td>   <td>本发明公开了一种眼底彩照血管及动静脉的识别方法。对眼底彩照中各部位的自动定位以及测量,达到疾病预筛选的效果,将有病变嫌疑的图片自动筛选出,以能够准确有效地对血管轮廓与血管动静脉进行标记识别,然后通过计算静动脉的直径比,可以辅助诊断视网膜血管等疾病,减少医生工作量；并且其结果不依赖于医生经验,更加客观,能够有效的协助医生进行疾病的诊断,实现远程会诊的目的。</td>   <td>1.一种眼底彩照血管及动静脉的识别方法,其特征在于包括以下步骤：图片质量检测,输入原始图像,进行图像特征的提取,并进行训练,对图片质量进行预测,检测出图片质量过关的眼底图像进行后续处理；图像预处理,在所有的图像中选择一张识别效果最好的,并提取其RGB三个轨道的灰度分布,将其作为标准图；读入图片,去掉圆形眼底图片周围的边框；图片处理,先处理去噪音,之后中值滤波、阈值去噪处理,得到大致的血管轮廓；得到血管轮廓,预处理得到的血管轮廓,进行多次腐蚀操作,得到血管的大致分布范围,接着对得到的不连续的断裂的血管进行像素链接及对角线填充,得到连续的血管,然后对得到的粗糙的血管进行去毛刺处理,到血管轮廓；血管识别,首先找到血管的中心线,利用中心线两侧向外的灰度梯度变化,确定血管边界,最后将识别的血管画在原图片上。</td>   <td>G06T7/00;G06T7/12;G06T7/136;G06T7/181;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈家炜;              陈静雯;              朝红阳;                   杨铭       </td>   <td>中山大学</td>   <td>图像去噪方法、装置、设备及存储介质</td>   <td>广东</td>   <td>CN108198154A</td>   <td>2018-06-22</td>   <td>本发明公开了一种图像去噪方法,包括：获取待去噪图像的平滑块集；将所述平滑块集中的每一平滑块减去对应的均值,以得到噪声块集；获取所述噪声块集中的第一噪声图像；根据生成对抗网络对所述噪声块集进行噪声建模,以得到可生成与所述待去噪图像同类型噪声的生成器；根据所述生成器获取第二噪声图像；根据所述无噪声图像、所述第一噪声图像及所述第二噪声图像构造训练集；根据所述训练集及判别学习方法训练出图像去噪网络模型；将所述待去噪图像输入到所述图像去噪网络模型,获取去噪后的图像。本发明还提供了图像去噪装置、设备及存储介质。能提升对现实生活中的未知真实噪声的去噪效果,提高了去噪效率。</td>   <td>1.一种图像去噪方法,其特征在于,包括：获取噪声块集；获取所述噪声块集中的第一噪声图像；根据所述第一噪声图像和无噪声图像构造训练集；根据所述训练集及判别学习方法模型训练出图像去噪网络模型；将所述待去噪图像输入到所述图像去噪网络模型,获取去噪后的图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         涂雨龙;              林淑金;                   林格       </td>   <td>中山大学</td>   <td>一种实现血管动态仿真的三维可视化方法</td>   <td>广东</td>   <td>CN108198239A</td>   <td>2018-06-22</td>   <td>本发明实施例公开了一种实现血管动态仿真的三维可视化方法。其中,该方法包括：获取医学影像,进行提取处理,获得图像序列信息；获取图像序列信息通过三维空间区域生长法进行提取血管轮廓的像素信息；对血管轮廓的像素信息进行统一化处理,建立血管表面模型；根据血管轮廓点的物理特性及血管结构的还原进行对血管动态仿真在本发明实施例中,能够简便地、快捷地以三维方式展示出人体血管动态,不仅大大提高还原精度,也真实还原血管表面受到力的作用时的实时变化情况,增强用户体验感。</td>   <td>1.一种实现血管动态仿真的三维可视化方法,其特征在于,所述方法包括：获取医学影像,进行提取处理,获得图像序列信息；获取图像序列信息通过三维空间区域生长法进行提取血管轮廓的像素信息；对血管轮廓的像素信息进行统一化处理,建立血管表面模型；根据血管轮廓点的物理特性及血管结构的还原进行对血管动态仿真。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李汉锋;              苏卓;                   林格       </td>   <td>中山大学</td>   <td>一种服装属性可编辑的服装图像检索的方法</td>   <td>广东</td>   <td>CN108197180A</td>   <td>2018-06-22</td>   <td>本发明实施例公开了一种服装属性可编辑的服装图像检索的方法。该方法包括：提取现有的服装数据库中的服装图像的特征向量；获取用户输入的用于搜索的服装图像；提取用户用于搜索的服装图像的特征向量；用服装属性判别方法得到服装图像的服装属性；将服装属性以及可选的修改选项展示给用户,并获取用户修改过的服装属性项；用原搜索的服装图像的特征向量和用户修改后的服装属性项,形成新的服装特征向量；计算新形成的服装属性特征和服装数据库中服装属性特征间的相似度；展示相似度最高的前k件服装图像。实施本发明实施例,可以使得用户根据自身喜好修改待检索服装图像的属性再进行基于图像内容的服装检索,获得满意的查询结果。</td>   <td>1.一种服装属性可编辑的服装图像检索的方法,其特征在于,所述方法包括：提取现有的服装数据库中的服装图像的特征向量；获取用户输入的用于搜索的服装图像；提取用户用于搜索的服装图像的特征向量；用服装属性判别方法得到服装图像的服装属性；将服装属性以及可选的修改选项展示给用户,并获取用户修改过的服装属性项；用原搜索的服装图像的特征向量和用户修改后的服装属性项,形成新的服装特征向量；计算新形成的服装属性特征和服装数据库中服装属性特征间的相似度；展示相似度最高的前k件服装图像。</td>   <td>G06F17/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄姝仪;              陈湘萍;                   林格       </td>   <td>中山大学</td>   <td>一种基于安卓应用的控件布局推荐方法及其系统</td>   <td>广东</td>   <td>CN108197183A</td>   <td>2018-06-22</td>   <td>本发明实施例公开了一种基于安卓应用的空间布局推荐方法及其系统。其中,该方法包括：获取运行时动态界面的数据集,进行解析、提取处理,获得空间数据库后建立索引；对用户提供的关键词进行匹配检索、提取、离散化处理,获得备选布局方案；对备选布局方案进行评分,按照从评分高至低推荐相应的布局给用户。实施本发明实施例,实现了量化控件布局推荐的代表性和稳定性的方法,使得用户根据两个指标以及综合评分,对推荐的结果有更清晰的了解,比起只用频率推荐对设计人员有更好的辅助作用。</td>   <td>1.一种基于安卓应用的控件布局推荐方法,其特征在于,所述方法包括：获取运行时动态界面的数据集,进行解析、提取处理,获得空间数据库后建立索引；对用户提供的关键词进行匹配检索、提取、离散化处理,获得备选布局方案；对备选布局方案进行评分,按照从评分高至低推荐相应的布局给用户。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         尹杰丽;              陈翔;              李勇;                   叶家恒       </td>   <td>中山大学;清华大学</td>   <td>基于大规模基站移动APP使用行为的运营商消费者定价方法</td>   <td>广东</td>   <td>CN108198010A</td>   <td>2018-06-22</td>   <td>本发明公开了一种基于大规模基站移动APP使用行为的运营商消费者定价方法,相比于基于传统粗犷式的流量定价方法,基于大规模基站APP使用行为的运营商消费者定价方法能够根据实际基站APP的使用地点、时间和类别制定出精细化的定价方案,具有很好的实用价值。本方法先根据APP的使用地点、时间和类别三维信息构建消费者期望函数；再构建消费者的效用函数以及运营商的利润函数；最后通过联合求解效用函数和利润函数得到消费者最优流量消费和运营商的最佳定价策略。相比于简单的基于使用流量的定价方法,该方法在提高运营商利润的同时,能有效提升消费者满意度,特别是在APP使用活跃的时间段内,能有效缓解流量拥塞问题。</td>   <td>1.一种基于大规模基站移动APP使用行为的运营商消费者定价方法,其特征在于,所述的方法包括下列步骤：S1、初始化参数,确定基站j∈[1,J]的APP使用类别i∈[1,I],APP使用时间t∈[1,T]和<br />APP使用特征的排序<img id="icf0001" file="FDA0001590744570000011.TIF" wi="323" he="73" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>其中,J是总的基站数目,T是总的时间数目,I是总的APP<br />类别数目；<br />S2、根据APP使用特征,其中,所述的APP使用特征包括APP的使用地点j、时间t和类别i<br />三维信息,评估消费者对每类APP的使用期望值<img id="icf0002" file="FDA0001590744570000012.TIF" wi="230" he="79" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>其中ε为不为0的任意常数；<br />S3、定义消费者对每类APP使用的满意度函数<img id="icf0003" file="FDA0001590744570000013.TIF" wi="379" he="80" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>以及期望函数<br /><img id="icf0004" file="FDA0001590744570000014.TIF" wi="410" he="84" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>其中,<img id="icf0005" file="FDA0001590744570000015.TIF" wi="54" he="71" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>是每个基站下每类APP在不同时刻的最大流量消费,<img id="icf0006" file="FDA0001590744570000016.TIF" wi="74" he="75" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>是每个<br />基站下每类APP在不同时刻的实际流量消费,<img id="icf0007" file="FDA0001590744570000017.TIF" wi="287" he="85" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>为实际流量消费与最大流量消费<br />比值,<img id="icf0008" file="FDA0001590744570000018.TIF" wi="288" he="80" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>β<sub>i</sub>为APP类别流量敏感度,0＜β<sub>i</sub>＜1；<br />S4、假定基站j的单位时间流量价格为<img id="icf0009" file="FDA0001590744570000019.TIF" wi="80" he="78" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>构建消费者在不同时间单位的效用函数<br /><img id="icf0010" file="FDA00015907445700000110.TIF" wi="700" he="122" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/><br />S5、构建基站容量服务能力有限情况下的运营商在不同时间单位的利润函数<br /><img id="icf0011" file="FDA00015907445700000111.TIF" wi="290" he="140" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>流量使用情况满足约束<img id="icf0012" file="FDA00015907445700000112.TIF" wi="317" he="140" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>其中<img id="icf0013" file="FDA00015907445700000113.TIF" wi="35" he="46" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>为基站的最大容量；<br />S6、联合求解最大化效用函数<img id="icf0014" file="FDA00015907445700000114.TIF" wi="51" he="71" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>和最大化利润函数<img id="icf0015" file="FDA00015907445700000115.TIF" wi="75" he="71" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>得到基站j在t时刻的流量使用<br />和定价策略最优解为<img id="icf0016" file="FDA00015907445700000116.TIF" wi="197" he="79" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/>其中<img id="icf0017" file="FDA00015907445700000117.TIF" wi="478" he="80" img-content="drawing" img-format="TIF" orientation="portrait" inline="no"/><br /></td>   <td>G06Q30/02;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张志权;              林淑金;                   周凡       </td>   <td>中山大学</td>   <td>一种基于教育视频自动提取不重复的幻灯片方法</td>   <td>广东</td>   <td>CN108182391A</td>   <td>2018-06-19</td>   <td>本发明实施例公开了一种基于教育视频自动提取不重复的幻灯片方法,所述方法包括：获取视频,按照一定时间间隔,截取图像；将截取图像灰度化生成二值图,找出边缘点的所有连通区域,进行检测,获得二值图中所有线段,并延长成直线,进行迭代合并相等的直线,获取任意两条不相等直线,计算两直线之间的交叉点,获取4个交叉点组成四边形,进行判断识别,获得合法四边形,进行透视变换,提取5张候选幻灯片图像并进行过滤提取冗余幻灯片图像,获得所需要的幻灯片。实施本发明实施例,在没有明显降低提取幻灯片的召回率的同时,很大程度减少了处理时间,提高了准确率。为用户提供了方便。</td>   <td>1.一种基于教育视频自动提取不重复的幻灯片方法,其特征在于,所述方法包括：获取视频,按照一定时间间隔,截取图像；将截取图像灰度化生成二值图,找出边缘点的所有连通区域,进行检测,获得二值图中所有线段,并延长成直线；获取所述直线,进行迭代合并相等的直线,获得不相等直线；获取任意两条不相等直线,计算两直线之间的交叉点,取其一；获取4个交叉点组成四边形,进行判断识别,循环迭代直至获得合法四边形；获取周长最大的5个四边形进行透视变换,提取5张候选幻灯片图像；获取候选幻灯片图像进行过滤提取冗余幻灯片图像,获得不重复的幻灯片。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         辜祥宏;                   杨然       </td>   <td>中山大学</td>   <td>基于深度学习算法的细菌性与病毒性儿童肺炎的分类方法</td>   <td>广东</td>   <td>CN108171232A</td>   <td>2018-06-15</td>   <td>本发明提供一种基于深度学习算法的细菌性与病毒性儿童肺炎的分类方法,该方法首先对源数据集进行人工标注,再在全卷积网络语义分割与卷积神经网络算法的基础上,先采用全卷积网络语义分割算法对图像进行前景分割肺部区域得到感兴趣区域,将提取到的感兴趣区域输入到卷积神经网络模型中训练分类器,从而预测未知胸部X线图像所属类别提取感兴趣区域的高维特征,同时采用传统的图像处理方法提取感兴趣区域的低维特征,分别将高、低维特征用于训练非线性分类器,并预测未知X线图像的类别,从而判断患者所患肺炎的类型。采用主成成分分析算法对特征降维,减少计算量,然后将混合降维后的特征输入到非线性分类器中,对未知X线图像预测类别。 1</td>   <td>1.一种基于深度学习算法的细菌性与病毒性儿童肺炎的分类方法,其特征在于,包括<br />
以下步骤：<br /></td>   <td>G06K9/32;G06K9/62;G06N3/04;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李坤宏;              林淑金;                   周凡       </td>   <td>中山大学</td>   <td>一种提取新闻事件发生时间的方法</td>   <td>广东</td>   <td>CN108170671A</td>   <td>2018-06-15</td>   <td>本发明实施例公开了一种提取新闻事件发生时间的方法,其中,该方法包括：获取新闻报道文章,进行提取所述新闻报道文章中每一个词语,与新闻报道文章的标题进行计算,获得两者之间的相关度；获取所述新闻报道文章中的词语,进行计算,获取词语分布的位置；对所述新闻报道文章中的词语通过识别处理,获取所述新闻报道文章中的关键词；根据所述新闻报道文章中的关键词组织概括整篇新闻报道文章的主要内容,利用搜索引擎来获取所述新闻报道文章的发生时间节点。实施本发明实施例,得以使提取新闻事件发生时间更加智能化、准确率得以提高；操作更加简便,并且大大降低了工作成本。 1</td>   <td>1.一种提取新闻事件发生时间的方法,其特征在于,所述方法包括：<br /></td>   <td>G06F17/27;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   秦福平       </td>   <td>中山大学</td>   <td>一种家居仓储物品的精确定位方法及系统</td>   <td>广东</td>   <td>CN108170781A</td>   <td>2018-06-15</td>   <td>本发明涉及一种家居仓储物品的精确定位方法,在室内设置嵌入式的拍摄设备,利用拍摄设备对室内的相应位置进行拍摄,将拍摄的图片传输至云服务器,云服务器利用图片分割识别分类算法对图片中的物品进行分类,并记录物品在图片中的位置和物品的图像；当用户要查找物品时,可通过终端访问云服务器,在分类结果中查找该物品,并输出它在图片中的位置及物品的图像。 1</td>   <td>1.一种家居仓储物品的精确定位方法,其特征在于：在室内设置嵌入式的拍摄设备,利<br />
用拍摄设备对室内的相应位置进行拍摄,将拍摄的图片传输至云服务器,云服务器利用图<br />
片分割识别分类算法对图片中的物品进行分类,并记录物品在图片中的位置和物品的图<br />
像；当用户要查找物品时,可通过终端访问云服务器,在分类结果中查找该物品,并输出它<br />
在图片中的位置及物品的图像。<br /></td>   <td>G06F17/30;G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              朱婷;                   马天俊       </td>   <td>中山大学</td>   <td>一种基于多Agent的人群疏散仿真模型</td>   <td>广东</td>   <td>CN108153945A</td>   <td>2018-06-12</td>   <td>一种基于多Agent的人群疏散仿真模型,包括行为层模型、情绪层模型以及指引模型；基于X状态机思想设计情绪层更新机制和行为层更新机制,重新定义情绪X状态机,同时加入指引模型；所述的指引模型对行人的情绪产生影响,降低行人的负面情绪,帮助行人找到出口,在更新情绪的同时设计的情绪层更新机制；提出情绪反作用于行为的机制,建立“环境#情绪#行为”之间的交互,在行为层运算输出的数据传递到情绪层,情绪产生的反馈会作用于行为层。通过将该人群疏散仿真模型应用于实际生活中,解决了一旦发生突发事件,将可以快速进行实施人群疏散的问题。</td>   <td>一种基于多Agent的人群疏散仿真模型,其特征在于,包括行为层模型、情绪层模型以及指引模型；基于X状态机思想设计情绪层更新机制和行为层更新机制,重新定义情绪X状态机,同时加入指引模型；所述的指引模型对行人的情绪产生影响,降低行人的负面情绪,帮助行人找到出口,在更新情绪的同时设计的情绪层更新机制；提出情绪反作用于行为的机制,建立“环境#情绪#行为”之间的交互,在行为层运算输出的数据传递到情绪层,情绪产生的反馈会作用于行为层。</td>   <td>G06F17/50;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              郑宇杰;              骆海锋;                   陈仕雄       </td>   <td>中山大学</td>   <td>基于GPU的多出口势能场模型人群实时疏散仿真方法</td>   <td>广东</td>   <td>CN108153966A</td>   <td>2018-06-12</td>   <td>本发明提供了一种基于GPU的多出口势能场模型人群实时疏散仿真方法,所述方法根据实际模型应用场景,提供相关的计算方法计算各个单出口模型的势能场、各个出口的宽度系数、宽度权重系数、运动个体与各出口的距离系数、距离权重系数、各出口的人群密度系数、人群密度权重系数,运动个体选择各出口的可能性、运动个体的多出口势能场。通过模拟各运动个体移动与碰撞避免,多次计算选择最佳疏散口。本发明方法应用到现实人群疏散中,有效解决现实疏散演练的弊端,并为疏散每个运动个体选择最优的疏散出口,提高疏散率,切合实际需求。</td>   <td>基于GPU的多出口势能场模型人群实时疏散仿真方法,其特征在于,包括以下步骤：S1：根据实际模型应用场景,计算各个单出口模型的势能场；S2：计算各个出口的宽度系数和宽度权重系数；S3：对于M个运动个体,在GPU中开启M个并行独立线程,计算运动个体与各出口的距离系数和距离权重系数；S4：根据在GPU中开启的M个并行独立线程,计算各出口的人群密度系数和人群密度权重系数；S5：计算运动个体选择各出口的可能性；S6：根据在GPU中开启的M个并行独立线程,计算运动个体的多出口势能场；S7：各运动个体移动与碰撞避免,根据计算得到的每个运动个体自身的多出口势能场,选择相对于当前位置势能减少最快的方向移动,包括左上角、上、右上角、右、右下角、下、左下角、左八个方向,上下左右四个方向的势能值变化为：<img file="FDA0001519331400000011.TIF" wi="389" he="55" />四个角落的势能值变化为：<img file="FDA0001519331400000012.TIF" wi="396" he="134" />其中：P<sub>now</sub>表示当前势能值,P<sub>next</sub>表示下一时刻的势能值；GPU并行计算得到多个运动个体可能同时移动到同一个位置,对比多个碰撞运动个体的<img file="FDA0001519331400000013.TIF" wi="75" he="47" /><img file="FDA0001519331400000014.TIF" wi="62" he="47" />最大的运动个体保持移动后的位置,其余运动个体按照以下方法选择向该格子未被占领的邻格子移动或者回到原地,方法如下：<img file="FDA0001519331400000015.TIF" wi="789" he="262" />其中D为整个仿真场景的面积,w为静止指数,通过设置该值来修改碰撞冲突时选择原地静止的概率；S8：判断每一个运动个体是否到达出口区,若到达出口区则执行步骤S9,否则跳回步骤S5继续执行；S9：多次计算判断该出口区域是否为最佳疏散口,运动个体到达出口区域后,回到步骤S5循环执行,多次计算；S10：通过步骤S9计算后,若该出口区域的出口仍为选择可能性最高的出口,则等待离开,否则回到步骤S7重新寻找另一个更优的出口。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余阳;              陈秀;              吴晓鹏;                   陈家文       </td>   <td>广州天源信息科技股份有限公司;中山大学</td>   <td>一种结合社会网络和位置的线下商户推荐方法</td>   <td>广东</td>   <td>CN108154425A</td>   <td>2018-06-12</td>   <td>本发明涉及一种结合社会网络和位置的线下商户推荐方法,用于电信电子商务公共服务综合支撑平台,包括以下步骤：数据预处理,对电信数据进行处理,得到所需数据表；根据用户通话详单,构建社会关系网络；采用CNM社区发现算法对社会网络进行层次聚类；基于用户位置,根据距离阈值筛选商户,得到候选商户列表；分析用户上网日志信息,构建用户商户二维偏好矩阵；采用基于用户的融合社会关系的协同过滤算法进行推荐。本发明利用用户通话信息构建社会关系网络,并对社会网络进行挖掘,找到联系紧密的用户团体,再结合用户位置,利用基于用户的融合社会关系的协同过滤算法进行推荐,降低计算复杂度,提高推荐的准确性。</td>   <td>一种结合社会网络和位置的线下商户推荐方法,其特征在于,包括以下步骤：步骤S1、数据预处理,对信令数据和用户商户数据进行处理,得到用户信息表、用户轨迹表、用户上网日志表、用户通话详单和商户信息表；步骤S2、根据用户通话详单,量化用户之间的社会关系,并构建社会关系网络；步骤S3、对所构建的社会关系网络进行层次聚类,发掘社会关系网络中联系紧密的用户团体；步骤S4、基于用户位置,根据距离阈值筛选商户,得到候选商户列表；步骤S5、基于S3中聚类的结果和S4中的候选商户列表,分析用户上网日志信息,构建用户商户二维偏好矩阵；步骤S6、对于步骤S5中构建的用户商户二维偏好矩阵,采用基于用户的融合用户社会关系的协同过滤算法进行推荐。</td>   <td>G06Q30/06;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              雷梦丫;                   毛慧凤       </td>   <td>中山大学</td>   <td>一种基于尺度自适应的头部检测和密度图的人群计数方法</td>   <td>广东</td>   <td>CN108154089A</td>   <td>2018-06-12</td>   <td>本发明公开一种基于尺度自适应的头部检测和密度图的人群计数方法,对图像进行特征训练和预测；首先提取图像的梯度信息和图像的前景；生成与图像对应的尺度和参数；然后分割前景图像,筛选样例；用样例进行训练得到头部的训练模型；利用训练模型进行预测,得到预测结果；根据预测结果生成多尺度密度图,将密度图加和得到预测总人数。用尺度自适应的方法结合头部检测对图片中的行人进行计数,弥补了普通的检测方法对于透视变换问题上的不足；自适应的尺度筛选方法和密度图的应用,使得本发明有更好的鲁棒性,可以适用于不同的场景。对于patch的筛选以及分类使得训练出来的模型分类能力更强,保障了人群计数的准确性。</td>   <td>一种基于尺度自适应的头部检测和密度图的人群计数方法,对图像进行特征训练和预测,其特征在于,包括以下步骤：S1：提取图像的梯度信息和图像的前景；S2：生成与图像对应的尺度和参数；S3：分割前景图像,筛选样例；S4：用样例进行训练得到头部的训练模型；S5：利用训练模型进行预测,得到预测结果；S6：根据预测结果生成多尺度密度图,将密度图加和得到预测总人数。</td>   <td>G06K9/00;G06K9/62;G06T7/194;G06T7/269</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              陈添水;              王州霞;              李冠彬;              余伟浩;                   许琳       </td>   <td>中山大学</td>   <td>一种多标签图像识别方法及装置</td>   <td>广东</td>   <td>CN108133233A</td>   <td>2018-06-08</td>   <td>本发明公开了一种多标签图像识别方法及装置,所述方法包括如下步骤：步骤S1,获取多标签图像,提取图片特征,获得所述多标签图像的特征图；步骤S2,于所述特征图上进行剪切获得区域特征,多次调用已训练好的循环注意感知模块进行处理,以获得所有区域的标签分数；步骤S3,融合每一次循环注意感知模块得到的各区域的标签分数,获得最终的标签分布,输出最终结果,本发明通过将循环注意力机制和增强学习相结合的方法应用到多标签图像的识别中,提高了多标签图像识别的计算效率和分类精度。</td>   <td>一种多标签图像识别方法,包括如下步骤：步骤S1,获取多标签图像,提取图片特征,获得所述多标签图像的特征图；步骤S2,于所述特征图上进行剪切获得区域特征,多次调用已训练好的循环注意感知模块进行处理,以获得所有区域的标签分数；步骤S3,融合每一次循环注意感知模块得到的各区域的标签分数,获得最终的标签分布,输出最终结果。</td>   <td>G06K9/62;G06K9/46;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄敏;              刘芳;                   张腾       </td>   <td>中山大学</td>   <td>一种基于BMO算法的新建过江通道指引优化方法</td>   <td>广东</td>   <td>CN108122053A</td>   <td>2018-06-05</td>   <td>本发明涉及一种基于BMO算法的新建过江通道指引优化方法,包括以下步骤：S1.选取布设范围,在布设范围的缓冲带内选取布设起点；S2.建立针对新建过江通道情境下的基于成本最优的指引优化数学模型；S3.利用BMO算法求解上述数学模型；S4.得到指引优化方案。</td>   <td>一种基于BMO算法的新建过江通道指引优化方法,其特征在于：包括以下步骤：S1.选取布设范围,在布设范围的缓冲带内选取布设起点；S2.建立针对新建过江通道情境下的基于成本最优的指引优化数学模型；S3.利用BMO算法求解上述数学模型；S4.得到指引优化方案。</td>   <td>G06Q10/04;G06Q50/26;G06N3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐永键;              陆许明;              谭洪舟;                   景嘉帅       </td>   <td>中山大学花都产业科技研究院;中山大学</td>   <td>一种基于箱式滤波器的局部边缘保持色调映射算法</td>   <td>广东</td>   <td>CN108122211A</td>   <td>2018-06-05</td>   <td>本发明提供一种基于箱式滤波器的局部边缘保持色调映射算法,该方法先对图像进行预处理；然后再利用LEP滤波器对预处理后的图像分层；紧接着计算分层后的图像的加速均值、方差,将得到的均值、方差输入箱式滤波器得到滤波结果；再对滤波结果进行动态压缩；最后对压缩后的图像进行色彩恢复；该方法在较好的保留图像的细节信息的基础上,降低了算法了复杂度。根据图像梯度值信息对图像进行分层处理,再对图像进行色调映射的同时保留图像的边缘信息,同时,利用箱式滤波器降低求梯度值时的复杂度。</td>   <td>一种基于箱式滤波器的局部边缘保持色调映射算法,其特征在于,包括以下步骤：S1：对图像进行预处理；S2：利用LEP滤波器对预处理后的图像分层；S3：计算分层后的图像的加速均值、方差,将得到的均值、方差输入箱式滤波器得到滤波结果；S4：对滤波结果进行动态压缩；S5：对压缩后的图像进行色彩恢复。</td>   <td>G06T5/00;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              吴垚明;                   陈亮       </td>   <td>中山大学</td>   <td>一种基于多模型堆栈融合的社交媒体用户人口属性预测方法</td>   <td>广东</td>   <td>CN108090607A</td>   <td>2018-05-29</td>   <td>本发明涉及一种基于多模型堆栈融合的社交媒体用户人口属性预测方法,对用户的性别、年龄、地区三个人口属性进行预测。三个人口属性的预测均经过以下步骤：S1、用户特征提取；S2、模型训练；S3、多模型融合得出预测结果；本发明中特征的提取不只针对用户微博的文本内容,还涉及到统计类特征、时间信息类特征以及社交关系特征,保证了预测的准确度。采取多模型堆栈融合的方式来对逻辑回归、随机森林以及XGBoost三个模型进行融合,能有效地降低泛化误差,大大提高预测的准确率。</td>   <td>一种基于多模型堆栈融合的社交媒体用户人口属性预测方法,对用户的性别、年龄、地区三个人口属性进行预测,其特征在于：所述三个人口属性的预测均经过以下步骤：S1、用户特征提取；S2、模型训练；S3、多模型融合得出预测结果；所述步骤S1中：进行性别属性预测时,性别特征提取包括TFIDF特征、统计类特征以及时间信息类特征的提取；进行年龄属性预测时,年龄特征提取包括TFIDF特征、统计类特征、时间信息类特征以及社交关系特征的提取；进行地区属性预测时,地区特征提取包括TFIDF特征、统计类特征、时间信息类特征、社交关系特征以及用户所发博文中包含的省、市名的提取；所述步骤S2中：所述步骤S2模型训练包括逻辑回归模型、随机森林模型以及XGBoost模型,通过利用逻辑回归模型、随机森林模型以及XGBoost模型分别对TFIDF特征进行训练,分别得出一份stacking特征。</td>   <td>G06Q10/04;G06K9/62;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李占潮;              邹小勇;                   戴宗       </td>   <td>广东药科大学;中山大学</td>   <td>一种药物-疾病关系识别方法、系统和装置</td>   <td>广东</td>   <td>CN108062556A</td>   <td>2018-05-22</td>   <td>本发明公开了一种药物#疾病关系识别方法、系统及装置。所述方法包括获取待识别药物#疾病关系对对应的疾病关系二维矩阵和/或灰度图,将其输入到卷积神经网络中进行处理,得到识别结果。所述系统包括用于获取药物#疾病关系二维矩阵和/或灰度图的获取模块,以及用于将药物#疾病关系二维矩阵和/或灰度图输入到卷积神经网络中进行处理,从而输出识别结果的处理模块。所述装置包括存储至少一个程序的存储器和执行至少一个程序的处理器。本发明利用卷积神经网络的处理功能,快速高效地识别药物#疾病治疗关系,识别潜在的药物#疾病相互作用,开展先导化合物识别和药物重定位研究。本发明广泛用于计算机辅助药物设计领域。</td>   <td>一种药物#疾病关系识别方法,其特征在于,包括以下步骤：获取待识别药物#疾病关系对所对应的药物#疾病关系二维矩阵和/或灰度图；将获得的药物#疾病关系二维矩阵和/或灰度图输入到卷积神经网络中进行处理,从而输出药物#疾病关系识别结果。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G16H20/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         成慧;              郑卓祺;              何晋豪;                   陈崇雨       </td>   <td>中山大学</td>   <td>一种用于三维重建的快速深度恢复方法</td>   <td>广东</td>   <td>CN108062769A</td>   <td>2018-05-22</td>   <td>本发明涉及计算机视觉中的立体视觉的技术领域,更具体地,涉及一种用于三维重建的快速深度恢复方法。利用通过运动恢复结构(Structure#From#Motion,SFM)得到图像中稀疏特征点的深度后,基于这些稀疏的特征点,结合灰度图像,通过多层下采样利用联合双边滤波器对深度进行扩散,从低分辨到高分辨率,由粗到精地、分层地快速恢复出精准的稠密深度图。该方法结果准确且计算量少,可以用于基于特征点法的同步定位与建图系统(Simultaneous#Localization#and#Mapping,SLAM),将系统中计算得到的稀疏特征点恢复成稠密的深度图,以重建出三维的稠密地图。</td>   <td>一种用于三维重建的快速深度恢复方法,其特征在于,包括以下步骤：(1)通过SFM方法计算得到基于Harris角点的特征点的深度,由特征点组成的稀疏的深度图,该深度图与图X+1所示的灰度图分辨率一致,为dim<sub>x</sub>×dim<sub>y</sub>像素；(2)对稀疏的深度图中有深度值的像素进行预处理；在具有深度值的特征点的八连通区域进行深度值扩散；此步骤保证对稀疏深度图进行下采样的时候深度信息不丢失；(3)利用高斯金字塔向下降采样灰度图,记原分辨率dim<sub>x</sub>×dim<sub>y</sub>的灰度图为I<sup>0</sup>,每一轮下采样倍数为2,经过N轮下采样得到N+1张不同分辨率的灰度图：I<sup>0</sup>,I<sup>1</sup>,I<sup>2</sup>...I<sup>N</sup>,其中I<sup>N</sup>的分辨率为dim<sub>x</sub>/2<sup>N</sup>×dim<sub>y</sub>/2N；(4)经过预处理的稀疏深度图利用最邻近方法进行下采样；记原分辨率dim<sub>x</sub>×dim<sub>y</sub>的稀疏深度图为D<sup>0</sup>,稀疏深度图的下采样倍数为2<sup>N</sup>,下采样后的稀疏深度图记为D<sup>N</sup>.其分辨率与I<sup>N</sup>同为dim<sub>x</sub>/2<sup>N</sup>×dim<sub>y</sub>/2<sup>N</sup>；(5)通过联合双边滤波器,以灰度图I<sup>N</sup>作为引导,将低分辨下的稀疏深度图D<sup>N</sup>中的特征点的深度扩散到无特征点区域,所得深度图为<img file="FDA0001519331590000011.TIF" wi="83" he="61" />根据标准的联合双边滤波器,滤波后低分辨稀疏深度图中<img file="FDA0001519331590000012.TIF" wi="95" he="78" />计算方法如下：<maths num="0001"><math><![CDATA[<mrow><msubsup><mover><mi>D</mi><mo>^</mo></mover><mi>p</mi><mi>N</mi></msubsup><mo> =</mo><msub><mi>k</mi><mrow><mi>p</mi><mo>,</mo><mi>q</mi></mrow></msub><munder><mo>&Sigma;</mo><mrow><mi>q</mi><mo>&Element;</mo><mi>S</mi></mrow></munder><msub><mi>w</mi><mrow><mi>p</mi><mo>,</mo><mi>q</mi></mrow></msub><msubsup><mi>D</mi><mi>q</mi><mi>N</mi></msubsup><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>0.1</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001519331590000013.TIF" wi="1222" he="158" /></maths>其中,<img file="FDA0001519331590000021.TIF" wi="422" he="236" />为归一化系数,S为插值窗口大小,每一个像素p的深度<img file="FDA0001519331590000022.TIF" wi="95" he="103" />是该像素滤波前在插值窗口中所有深度<img file="FDA0001519331590000023.TIF" wi="241" he="102" />的加权平均；该权重w<sub>p,q</sub>由空间相似性与灰度相似性计算：<img file="FDA0001519331590000024.TIF" wi="1429" he="202" />上式中,函数s·为空间相似性权重,为灰度相似性权重；具体计算方法如下：(a)空间相似性权重s·表示的是插值窗口内像素距离之间的相似性,用高斯核函数来表达,计算方法为：<img file="FDA0001519331590000025.TIF" wi="677" he="198" />其中σ<sub>s</sub>为空间相似性权重的标准差；(b)灰度相似性权重r·表示的是插值窗口内像素灰度之间的相似性,用高斯核函数来表达,计算方法式为：<img file="FDA0001519331590000026.TIF" wi="758" he="214" />其中σ<sub>r</sub>为灰度相似性权重的标准差；(6)步骤(5)所得到的<img file="FDA0001519331590000027.TIF" wi="66" he="55" />使用双三次插值方法上采样得到D<sup>N#1</sup>；(7)重复步骤(5)与步骤(6),直至得到清晰稠密的深度图<img file="FDA0001519331590000028.TIF" wi="83" he="61" />(8)最后将深度图<img file="FDA0001519331590000029.TIF" wi="73" he="77" />上采样至原图分辨率大小,得到恢复后的深度图D。</td>   <td>G06T7/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曹妤;              林淑金;                   周凡       </td>   <td>中山大学</td>   <td>一种基于中文教育视频提取拓展词的方法</td>   <td>广东</td>   <td>CN108052630A</td>   <td>2018-05-18</td>   <td>本发明公开了一种基于中文教育视频提取拓展词的方法,其中,所述方法包括：获取中文教育视频,生成视频内容文本,将其备份标记为文本集1和文本集2；将文本集1去停用词、词性标注,保留名词；并提取关键词和关键短语,获得关键词集1；根据关键词集1中的关键词对文本集1中的文本信息进行分类；根据不同类别信息,爬取相关类别的文章,将该类别的典型文章构建类别语料库；将文本集2进行分词,根据类别语料库提取关键词,获得关键词集2；将其和关键词集1取并集,对其重叠关键词按照视频内容文本长短重新分配权重；根据权重倒序排序,获得对应数量和难度的拓展词。实现本发明实施例,能全面准确的提取出视频中需要进行知识拓展的词条来帮助观看者在理解和学习。</td>   <td>一种基于中文教育视频提取拓展词的方法,其特征在于,所述方法包括：获取中文教育视频,生成视频内容文本,并将视频内容文本备份、标记为文本集1和文本集2；对文本集1进行去停用词处理,并对去停用词处理后的文本集1进行词性标注,获得保留名词的文本集1；对所述保留名词的文本集1进行提取关键词和关键短语,获得关键词集1；根据关键词集1中的关键词对文本集1中的文本信息进行分类,获得不同类别信息；根据不同类别信息,进行爬取相关类别的文章,并将该类别的典型文章构建类别语料库；获取文本集2,进行分词,根据类别语料库进行提取关键词,获得关键词集2；获取关键词集1和关键词集2进行取并集,对重叠的关键词按照视频内容文本长短重新分配权重；根据权重倒序排序,获得对应数量和难度的拓展词。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   崔嘉辉       </td>   <td>中山大学</td>   <td>基于区块链的传感器网络共享方法</td>   <td>广东</td>   <td>CN108053239A</td>   <td>2018-05-18</td>   <td>本发明涉及基于区块链的传感器网络共享方法,采用去中心化合约执行方法,自动执行智能合约,给予需求方相应的权限,避免了中心化的把控机构以及单点故障,而且执行过程中没有一个结点能伪造运算结果,或是控制运算进程,具有不可篡改的特性。需求方和提供方基于传感器网络共享的交易账本采用去中心化账本维护方法进行维护,可以免除提供方以及需求方对账本的维护成本以及对账导致的重复存储问题。采用信誉评价机制,为其他供求用户提供参考。提供方经过传感器网络抽象层发现需求方提出的需求内容,使需求方更容易得到其所需,提供方更容易理解其所提供的能否适合需求者所需。每个中间过程的有序触发均需要签名,保证多方均对交易进行了确认。</td>   <td>基于区块链的传感器网络共享方法,其特征在于：包括以下步骤：S1、撮合传感器网络的需求方和提供方；S2、部署智能合约；S3、共享传感器网络；S4、信誉评价。</td>   <td>G06Q30/02;G06Q30/06;G06Q20/38;H04L29/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         龚子霄;              王若梅;                   周凡       </td>   <td>中山大学</td>   <td>一种基于特征提取的服装相似度判定方法及其系统</td>   <td>广东</td>   <td>CN108052952A</td>   <td>2018-05-18</td>   <td>本发明实施例公开了一种基于特征提取的服装相似度判定方法及其系统,其中,该方法包括：获取进行服装相似度判定的图像数据；解析服装的上装和下装特点,进行服装图像特征提取；根据输入的图像进行服装相似度的判断,给出相似度级别。在本发明实施例中,建立了服装的上装和下装的解析方法,对影响服装相似度的关键特征进行标定,并建立了服装多属性下的深度学习网络,进而对服装进行多特征下的相似度判定,通过相似度度量数据表征服装的相似性程度,更加符合个性化的服装选择和推荐功能。</td>   <td>一种基于特征提取的服装相似度判定方法,其特征在于,所述方法包括：获取进行服装相似度判定的图像数据；解析服装的上装和下装特点,进行服装图像特征提取；根据输入的图像进行服装相似度的判断,给出相似度级别。</td>   <td>G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              李凝;                   马天俊       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的特征提取与目标跟踪方法</td>   <td>广东</td>   <td>CN108038435A</td>   <td>2018-05-15</td>   <td>本发明公开一种基于卷积神经网络的特征提取与目标跟踪方法,首先通过线下预训练的方法,提高网络在特征提取与前景分割时的性能；之后将标定有的视频序列第一帧放入到网络中进行线上训练,对网络模型的参数进行微调,从而提升卷积神经网络在具体问题中的处理能力。通过增加随机二维掩膜和多次迭代的方法,既提高了网络预测的准确率,同时也避免了过拟合的问题。多尺度的可选性也使得本方法在目标跟踪过程中能够自适应地选择目标的尺度大小。在网络参数更新方面,通过设置阈值的方式实时进行更新,提升了目标跟踪方法的精度和鲁棒性。</td>   <td>一种基于卷积神经网络的特征提取与目标跟踪方法,其特征在于,包括以下步骤：S1：构建并预训练网络模型；S2：根据视频序列,线上训练网络模型；S3：输入视频序列,计算跟踪结果；S4：对视频序列中上一帧的跟踪结果进行评估,选取正样本结果放入网络中迭代以更新网络参数。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              孙雪冬       </td>   <td>中山大学</td>   <td>一种支持个性化教学过程自动生成的教学资源建模方法及系统</td>   <td>广东</td>   <td>CN108038238A</td>   <td>2018-05-15</td>   <td>本发明公开了一种支持个性化教学过程自动生成的教学资源建模方法及系统。该方法首先对研究对象进行界定#主要对自然科学类的图书及相关的教学资源进行建模；其次,通过分析教学资源的知识内容组成,根据资源内部的知识聚集程度进行知识单元及知识元划分,并应用图论对知识元间的关系进行图形化描述；第三,根据教学资源对知识的讲授(或讲解、展示)方式、方法,应用活动对知识的表达进行描述；第四,论述了该方法如何支持个性化的教学过程优化。本发明把教学过程描述和资源描述统一,支持快速、准确地根据学习者的学习目标和知识背景进行教学资源的选择,同时自动生成相应的优化的教学过程。本发明的方法是进一步教学过程分析、学习方案编制的基础。</td>   <td>一种支持个性化教学过程自动生成的教学资源建模方法,其特征在于：该方法包括以下步骤：步骤1,确定描述对象；主要研究对象为自然科学类的教学资源；步骤2,对资源进行分解,分解为知识单元和知识元,应用有向超图对资源知识结构进行描述；步骤3,对知识元进行分解描述,用知识表达活动对其进行分解描述；步骤4,个性化教学过程的自动生成,利用资源中包含的知识元及个性化知识路径中的知识元之间的关系及资源中知识元表达活动的关系,生成优化的教学过程。</td>   <td>G06F17/30;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢铮;              王若梅;              周凡;                   林格       </td>   <td>中山大学</td>   <td>基于低维图像编码与集成学习的白胚布平整度分级方法</td>   <td>广东</td>   <td>CN108038516A</td>   <td>2018-05-15</td>   <td>本发明实施例公开了基于低维图像编码与集成学习的白胚布平整度分级方法。该方法主要通过特征提取来生成图像编码,然后通过机器学习来生成学习器,最后通过集成学习的思想来综合多个基学习器的结果得到最后结果。实施本发明实施例,使用计算机自动化的方法来对图像平整度进行客观、准确的评级,利用特征中心直方图作为图像编码,极大降低了编码维数,减少学习器计算量；使用集成学习的策略为最后结果提供可靠的保证,从而在节省人工成本的同时降低主观误差,并且在分级结果上能达到资深工程师的评级能力。</td>   <td>基于低维图像编码与集成学习的白胚布平整度分级方法,其特征在于,所述方法包括：图像和标签预处理；基于预处理结果提取图像的皱褶特征中心；基于特征中心对数据集中图像进行编码；评级参考系的建立与验证。</td>   <td>G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金涛;              徐劲;              李阳春;                   陈国辉       </td>   <td>广州中山大学出版社有限公司</td>   <td>一种图片中选择文本信息的方法及装置</td>   <td>广东</td>   <td>CN108021611A</td>   <td>2018-05-11</td>   <td>本发明涉及一种图片中选择文本信息的方法,包括有以下步骤：S1.服务器根据作品的内容及排版信息生成对应的图片；S2.服务器重新编码作品内容及根据作品内容的字体信息生成新字体文件；S3.客户端获取编码后的内容、新字体文件及生成的图片,并根据获取的内容生成最终的阅读环境；S4.客户端根据读者选择文本所在的位置信息向服务器获取具体文本信息。</td>   <td>一种图片中选择文本信息的方法,其特征在于：包括有以下步骤：S1.服务器根据作品的内容及排版信息生成对应的图片；S2.服务器重新编码作品内容及根据作品内容的字体信息生成新字体文件；S3.客户端获取编码后的内容、新字体文件及生成的图片,并根据获取的内容生成最终的阅读环境；S4.客户端根据读者选择文本所在的位置信息向服务器获取具体文本信息。</td>   <td>G06F17/30;G06F17/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;                   谭骏朗       </td>   <td>中山大学</td>   <td>一种基于对数映射函数分块处理融合的色调映射方法</td>   <td>广东</td>   <td>CN108022223A</td>   <td>2018-05-11</td>   <td>本发明涉及一种基于对数映射函数分块处理融合的色调映射方法,包括以下步骤：步骤100：获得一幅高动态图像；步骤200：将所述高动态图像划分为多个大小相等的局部块；步骤300：将划分的局部块分别使用对数压缩函数进行亮度压缩处理；步骤400：将所述经过亮度压缩处理的局部块使用高斯融合函数进行图像融合；步骤500：将所述图像融合得到的图像使用双边滤波进行细节增强；步骤600：将所述经过细节增强的图像进行伽马校正后输出低动态图像。</td>   <td>一种基于对数映射函数分块处理融合的色调映射方法,其特征在于：包括以下步骤：步骤100：获得一幅高动态图像；步骤200：将所述高动态图像划分为多个大小相等的局部块；步骤300：将划分的局部块分别使用对数压缩函数进行亮度压缩处理；步骤400：将所述经过亮度压缩处理的局部块使用高斯融合函数进行图像融合；步骤500：将所述图像融合得到的图像使用双边滤波进行细节增强；步骤600：将所述经过细节增强的图像进行伽马校正后输出低动态图像。</td>   <td>G06T5/00;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱庆棠;              戚剑;              闫立伟;              姚执;                   刘小林       </td>   <td>中山大学附属第一医院</td>   <td>人体周围神经束型结构的可视化三维重建方法</td>   <td>广东</td>   <td>CN108022291A</td>   <td>2018-05-11</td>   <td>本发明提供一种人体周围神经束型结构的可视化三维重建方法,包括以下步骤：获取人体周围神经并制备周围神经样本；将该周围神经样本浸泡于液体中；设置Micro#MRI的扫描参数,应用Micro#MRI对该周围神经样本进行扫描,获取该周围神经样本在该液体环境下的图像数据；基于该图像数据进行三维重建周围神经样本的结构模型。本发明的方法确保在不破坏周围神经的形态和理化性质的前提下获得高质量的扫描图像,以获得精准的周围神经束型的可视化三维模型。</td>   <td>一种人体周围神经束型结构的可视化三维重建方法,包括以下步骤：S1、获取人体周围神经,并制备周围神经样本；S2、将所述周围神经样本浸泡于液体中；S3、设置Micro#MRI的扫描参数,并应用Micro#MRI对所述周围神经样本进行扫描,获取所述周围神经样本在所述液体环境下的图像数据；S4、基于所述图像数据进行三维重建所述周围神经样本的可视化结构模型。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              朱志华;                   谢璐       </td>   <td>中山大学</td>   <td>一种海绵城市水文计算方法</td>   <td>广东</td>   <td>CN108022047A</td>   <td>2018-05-11</td>   <td>本发明涉及水文计算领域,更具体地,涉及一种海绵城市水文计算方法。包括以下步骤：S1.采集研究区设定时限内的与降雨相关的基础数据；S2.结合所采集的数据,构建适于研究区域的SWMM模型；S3.构建不同降雨情景,结合SWMM排水模型分析不同降雨情景下LID措施调控前后区域排水系统响应特征,对比LID措施的调控效果；S4.建立区域雨洪特征评估体系,探讨不同降雨情景下LID措施调控前后雨洪的空间变化特征。本发明提供的一种海绵城市水文计算方法,构建区域排水模型,模拟多种极端降水情景下区域经LID措施调控前后的子汇水区域高峰径流、排水管网排泄压力、积水时间和积水量,有助于把握LID措施对区域雨洪的调控效果,方便海绵城市建设中的LID措施设置。</td>   <td>一种海绵城市水文计算方法,其特征在于,包括以下步骤：S1.采集研究区设定时限内的与降雨相关的基础数据；S2.结合所采集的数据,构建适于研究区域的SWMM模型；S3.构建不同降雨情景,结合SWMM排水模型分析不同降雨情景下LID措施调控前后区域排水系统响应特征,对比LID措施的调控效果；S4.建立区域雨洪特征评估体系,探讨不同降雨情景下LID措施调控前后雨洪的空间变化特征。</td>   <td>G06Q10/06;G06Q50/26;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈佩;              卢德辉;                   谢晓明       </td>   <td>中山大学</td>   <td>一种基于Census变换和局部图优化的RGB-D视觉里程计方法</td>   <td>广东</td>   <td>CN108010081A</td>   <td>2018-05-08</td>   <td>本发明涉及一种基于Census变换和局部图优化的RGB#D视觉里程计方法,包括以下步骤：通过RGB#D传感器获取环境的彩色和深度图像信息,使用彩色图像计算Census描述图；基于Census描述图,使用直接法对当前帧进行运动估计,计算当前帧与局部图中最新关键帧的相对位姿；对于局部图中梯度信息显著但缺少深度信息的点,在当前帧中进行深度跟踪估计；根据当前帧的位姿估计结果,生成新的关键帧,并插入到局部图中,对局部图进行图优化和关键帧管理操作。本发明使用Census描述图进行直接法运动估计,并结合局部图的优化和管理,提高了视觉里程计在彩色图像亮度发生变化和深度图像深度信息不足时的实时鲁棒性。</td>   <td>一种基于Census变换和局部图优化的视觉里程计方法,其特征在于,包括以下步骤：S1.通过RGB#D传感器获取环境的彩色和深度图像信息,使用彩色图像计算Census描述图；S2.基于Census描述图,使用直接法对当前帧进行运动估计,计算当前帧与局部图中最新关键帧的相对位姿；S3.对于局部图中梯度信息显著但缺少深度信息的点,在当前帧中进行深度跟踪估计；S4.根据当前帧的位姿估计结果,生成新的关键帧,并插入到局部图中,对局部图进行图优化和关键帧管理操作。</td>   <td>G06T7/73;G06T7/207;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑华滨;                   潘嵘       </td>   <td>中山大学</td>   <td>一种基于计数聚焦模型的新型文本识别方法</td>   <td>广东</td>   <td>CN108009539A</td>   <td>2018-05-08</td>   <td>本发明涉及一种基于计数聚焦模型的新型文本识别方法,所述计数聚焦模型包括编码器和解码器,所述识别方法包括以下步骤：S1.采用基于卷积神经网络的编码器对输入图像的高层特征进行抽取,得到高层特征图；S2.基于长短期记忆网络和聚焦机制的解码器从高层特征图中按序解码出从左到右的字符。</td>   <td>一种基于计数聚焦模型的新型文本识别方法,所述计数聚焦模型包括编码器和解码器,其特征在于：所述识别方法包括以下步骤：S1.采用基于卷积神经网络的编码器对输入图像的高层特征进行抽取,得到高层特征图；S2.基于长短期记忆网络和聚焦机制的解码器从高层特征图中按序解码出从左到右的字符,具体如步骤S21~S30所示：S21.将高层特征图沿着横向维度从左到右进行切分,得到W个内容向量v_1,#v_2,#…,#v_W,其中W为高层特征图的宽度；S22.将内容向量序列分别输入至长LSTM模块中,得到对应的W个状态向量s_1,#s_2,#…,#s_W；S23.将状态向量序列输入至全连接层中,并用线性整流函数保证其数值非负,得到W个计数累加标量c_1,#c_2,#…,#c_W；S24.设置一个初始计数标量k_0；S25.按照从左到右的方向,在计数标量上不断叠加步骤S23获得的累加标量,得到W个计数标量,即k_w#=#k_{w–1}#+#c_k,其中1≤#w#≤#W；S26.设置最大解码长度L,代表解码器需要从高层特征图里解码出的字符数目；S27.解码第q个字符,q≤L,将索引q与所有计数标量分别进行比对操作,计算它们的差值的绝对值的反,得到聚焦分数s_w,即：s_w#=###|#k_w#–#q#|,#1≤#w#≤#W；S28.使用softmax函数对W个聚焦分数进行归一化,得到聚焦权重a_w：a_w#=#e<sup>#(s_w)</sup>#/#[e#<sup>(s_1)#</sup>+#e#<sup>(s_2)#</sup>+#…#+#e#<sup>(s_W)</sup>]；S29.使用聚焦权重对内容向量进行加权求和,得到第q个字符对应的特征向量o_q：o_q#=#a_1#*#v_1#+#a_2#*#v_2#+#…#+#a_W#*#v_W；S30.利用全连接层从o_q预测出第q个字符的概率分布。</td>   <td>G06K9/20;G06K9/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;                   苏程佳       </td>   <td>中山大学</td>   <td>一种水文水资源特征空间变异性识别的方法</td>   <td>广东</td>   <td>CN108009562A</td>   <td>2018-05-08</td>   <td>本发明涉及水文水资源领域,更具体地,涉及一种水文水资源特征空间变异性识别的方法。包括以下步骤：S1.采集河网区水文站点的同步实测水位数据并对网河区进行网格布设；S2.结合所采集的数据及网格布设,计算各方向的水位半变异函数,研究水位在各方向的变异性；S3.运用模型叠加的方法,将不同变程的半变异函数进行叠加构成一个新的套合结构半变异函数模型,根据该套合结构半变异函数模型可方便获得区域内任意两点间的半变异函数值,并对研究区域待估点的水位进行估算。本发明计算复杂度较低、计算效率高、预测准确度高,操作简单,可对河网区水位特征进行空间变异性分析,并对水位在网河区进行空间点估计模拟。</td>   <td>一种水文水资源特征空间变异性识别的方法,其特征在于,包括以下步骤：S1.采集河网区水文站点的同步实测水位数据并对网河区进行网格布设；S2.结合所采集的数据及网格布设,计算各方向的水位半变异函数,研究水位在各方向的变异性；S3.运用模型叠加的方法,将不同变程的半变异函数进行叠加构成一个新的套合结构半变异函数模型,根据该套合结构半变异函数模型可方便获得区域内任意两点间的半变异函数值,并对研究区域待估点的水位进行估算。</td>   <td>G06K9/62;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              唐亦汉;                   苏程佳       </td>   <td>中山大学</td>   <td>一种变异环境下河网区设计洪水位计算方法</td>   <td>广东</td>   <td>CN108009565A</td>   <td>2018-05-08</td>   <td>本发明涉及水文水利工程领域,更具体地,涉及一种变异环境下河网区设计洪水位计算方法。包括以下步骤：S1.采集并提取网河区不同位置站点的年最大洪潮水位数据；S2.根据网河区各站洪潮水位序列统计特征进行分区；S3.基于S2步骤的分区结果进行站点特征分布识别；S4.基于主要环境影响要素进行特定分区站点的设计洪水位计算分析。本发明提供的一种变异环境下河网区设计洪水位计算方法,充分考虑了网河区复杂的河道影响及环境变化作用,可提高设计洪水位计算精度,可广泛应用于水文统计计算中。</td>   <td>一种变异环境下河网区设计洪水位计算方法,其特征在于,包括以下步骤：S1.采集并提取网河区不同位置站点的年最大洪潮水位数据；S2.根据网河区各站洪潮水位序列统计特征进行分区；S3.基于S2步骤的分区结果进行站点特征分布识别；S4.基于主要环境影响要素进行特定分区站点的设计洪水位计算分析。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         程思锦;                   黄方军       </td>   <td>中山大学</td>   <td>基于二维直方图修改的JPEG图像可逆信息隐藏方法</td>   <td>广东</td>   <td>CN108009975A</td>   <td>2018-05-08</td>   <td>本发明提供一种基于二维直方图修改的JPEG图像可逆信息隐藏方法,通过解码产生DCT系数；将量化的系数分成对,构建二维直方图；根据嵌入信息长度计算阈值Th,根据自适应选择JPEG图像嵌入信息的最佳频段计算阈值Tp；通过二维直方图映射方式,将可逆信息嵌入在阈值范围内的系数。本发明方法隐藏了嵌入信息,维持原始JPEG图像的文件大小,保证在嵌入信息后无损恢复原始JPEG图像。</td>   <td>一种基于二维直方图修改的JPEG图像可逆信息隐藏方法,其特征在于,包括以下步骤：S1：将原始JPEG图像进行熵解码得到量化的DCT系数,对于每一个8*8块,将量化的DCT系数分为32对,舍弃第一对,构造基于DCT系数的二维直方图；S2：计算每个8*8块中零系数个数,根据所嵌入秘密信息的长度确定阈值Th,自适应选择JPEG图像嵌入信息的最佳频段,其最佳频段阈值设为Tp；S3：当该块中零系数个数不小于阈值Th,所处频段小于阈值Tp的DCT系数对用来嵌入信息,将辅助信息与秘密信息通过构造的二维直方图映射方式一起嵌入到JPEG图像中；S4：在所有信息被嵌入后,将DCT系数进行熵编码得到含秘JPEG图像。</td>   <td>G06T1/00;G06T5/40;G06F21/16;G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡继华;              陈静萍;              钟洪桢;              程智锋;                   伍丽华       </td>   <td>中山大学</td>   <td>一种基于无人机的道路交叉口车辆跟踪方法</td>   <td>广东</td>   <td>CN108009494A</td>   <td>2018-05-08</td>   <td>本发明涉及一种基于无人机的道路交叉口车辆跟踪方法,包括有以下步骤：S1.将无人机悬停在道路交叉口中心的上方,对交叉口区域进行垂直拍摄,获取无人机视频；S2.对无人机视频中的每一帧视频帧中的车辆进行检测,获得车辆在视频帧中的影像区域；S3.对于相邻的两帧视频帧,分别计算前一帧中的车辆影像区域与后一帧中所有的车辆影像区域的直方图相似度、速度相似度和方向相似度,然后基于直方图相似度、速度相似度和方向相似度分别计算前一帧中的车辆影像区域与后一帧中所有的车辆影像区域的车辆影像置信度；S4.比较前一帧中的车辆影像区域与后一帧中的车辆影像区域的置信度的大小,选择后一帧中置信度最大的车辆影像区域作为同一车辆的影像。</td>   <td>一种基于无人机的道路交叉口车辆跟踪方法,其特征在于：包括有以下步骤：S1.将无人机悬停在道路交叉口中心的上方,对交叉口区域进行垂直拍摄,获取无人机视频；S2.对无人机视频中的每一帧视频帧中的车辆进行检测,获得车辆在视频帧中的影像区域；S3.对于相邻的两帧视频帧,分别计算前一帧中的车辆影像区域与后一帧中所有的车辆影像区域的直方图相似度、速度相似度和方向相似度,然后基于直方图相似度、速度相似度和方向相似度分别计算前一帧中的车辆影像区域与后一帧中所有的车辆影像区域的车辆影像置信度；S4.比较前一帧中的车辆影像区域与后一帧中的车辆影像区域的置信度的大小,选择后一帧中置信度最大的车辆影像区域作为同一车辆的影像。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;                   苏程佳       </td>   <td>中山大学</td>   <td>河口区咸潮上溯含氯度模拟预报方法</td>   <td>广东</td>   <td>CN107992960A</td>   <td>2018-05-04</td>   <td>本发明涉及环境数据模型技术领域,更具体地,涉及一种河口区咸潮上溯含氯度模拟预报方法。包括以下步骤：S1.收集实测流量、水位、含氯度、河道地形数据；S2.构建模型库,包括水流数学模型和含氯度数学模型,且两者之间通过耦合关系实现有机结合；S3.模型参数率定；S4.利用实测流量、水位以及含氯度数据对模型进行验证；S5.模型应用及输出。本发明通过将含氯度数学模型与水流数学模型有机结合,实现了在水流数学模型的基础上对大型复杂网河区河流含氯度的模拟,这种前后继承关系的模块化设计实现了模型的有机结合,确保了模型的高效运行及稳定性。</td>   <td>一种河口区咸潮上溯含氯度模拟预报方法,其特征在于,包括以下步骤：S1.收集实测流量、水位、含氯度、河道地形数据；S2.构建模型库,包括水流数学模型和含氯度数学模型,且两者之间通过耦合关系实现有机结合；S3.模型参数率定；S4.利用实测流量、水位以及含氯度数据对模型进行验证；S5.模型应用及输出。</td>   <td>G06Q10/04;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张晋斌;                   潘嵘       </td>   <td>中山大学</td>   <td>一种基于CNN-LSTM的汉字拼写错别字改正方法</td>   <td>广东</td>   <td>CN107992211A</td>   <td>2018-05-04</td>   <td>本发明提供一种基于CNN#LSTM的汉字拼写错别字改正方法,该方法主要是利用了文本的上下文来纠错,即每一个汉字根据其上下文来判断该汉字正确与否,若该汉字是错别字的话则会根据其上下文来纠正错误。并且在模型训练中用到了随机改错的训练方式,提高了改正的准确率。</td>   <td>一种基于CNN#LSTM的汉字拼写错别字改正方法,其特征在于,包括以下步骤：S1：对于输入的句子进行编码,并对错别字进行过滤；S2：根据获得的过滤后的信息以及上下文信息解码出当前时间节点对应的正确的汉字。</td>   <td>G06F3/023</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何兆成;                   钟嘉明       </td>   <td>中山大学</td>   <td>基于张量分解的城市交通缺失数据填补方法</td>   <td>广东</td>   <td>CN107992536A</td>   <td>2018-05-04</td>   <td>本发明涉及一种基于张量分解的城市交通缺失数据填补方法,包括有以下步骤：S1.构建城市交通数据基于路段、日期和时段维度的张量；S2.对缺失数据进行预填补,完成缺失数据的初始化；S3.对预填补得到的缺失数据进行截断奇异值分解,挖掘得到缺失数据在路段、日期和时段维度的左奇异向量；S4.利用路段、日期和时段维度的左奇异向量,计算得到核心张量；S5.构建缺失数据填补模型,输入路段、日期和时段维度的左奇异向量及核心张量训练缺失数据填补模型,并结合优化算法不断优化缺失数据填补模型,优化完毕后通过缺失数据填补模型实现缺失数据的填补。</td>   <td>一种基于张量分解的城市交通缺失数据填补方法,其特征在于：包括有以下步骤：S1.构建城市交通数据基于路段、日期和时段维度的张量；S2.对缺失数据进行预填补,完成缺失数据的初始化；S3.对预填补得到的张量进行截断奇异值分解,挖掘得到张量在路段、日期和时段维度的左奇异向量；S4.利用路段、日期和时段维度的左奇异向量,计算得到核心张量；S5.构建缺失数据填补模型,输入路段、日期和时段维度的左奇异向量及核心张量训练缺失数据填补模型,并结合优化算法不断优化缺失数据填补模型,优化完毕后通过缺失数据填补模型实现缺失数据的填补。</td>   <td>G06F17/30;G06Q10/06;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   黄炼楷       </td>   <td>中山大学</td>   <td>一种基于主题模型的相似文章推荐方法</td>   <td>广东</td>   <td>CN107992542A</td>   <td>2018-05-04</td>   <td>本发明涉及一种基于主题模型的相似文章推荐方法,首先通过文章原始文本预处理,提取单纯的文章内容；然后对文章内容进行分词、词性分析,筛选出名词词性的词语,词袋抽取,形成文章主要的词语特征向量；跟着利用所有文章的词语特征向量训练TFIDF模型,基于该TFIDF模型对每篇文章的词语特征向量计算,形成TFIDF特征向量；再之,利用所有文章的TFIDF特征向量训练LSI主题模型；最后使用LSI模型计算得到该文章的潜在主题特征向量,由向量相似度计算可以得到相似文章。本发明能帮助互联网用户高效挖掘感兴趣文章,具有适用范围较大、人工标记成本较低、推荐多样性较好等优点。</td>   <td>一种基于主题模型的相似文章推荐方法,其特征在于：包括以下步骤：S1.文章原始文本预处理,提取单纯的文章内容；S2.获取文章的词语特征向量；S3.利用所有文章的词语特征向量训练TFIDF模型,基于该TFIDF模型计算每篇文章的词语特征向量,形成TFIDF特征向量；S4.利用所有文章的TFIDF特征向量训练LSI主题模型；S5.使用LSI模型计算得到文章的潜在主题特征向量,由向量相似度计算得到相似文章。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              刘家豪;                   陈川       </td>   <td>中山大学</td>   <td>一种基于社交网络有向图的社区发现方法</td>   <td>广东</td>   <td>CN107993156A</td>   <td>2018-05-04</td>   <td>本发明涉及一种基于社交网络有向图的社区发现方法,根据三角形的不同类型,提取出其特征,并将其量化作为点与点之间的边权值；然后直接将有向无权图转化为无向有权图,再用改进的标签传播算法来进行社区发现。本发明不仅能解决社交网络中传统社区发现算法不适用于有向图的问题,并且通过算法改进,能极大地提高社区划分的准确性。</td>   <td>一种基于社交网络有向图的社区发现方法,其特征在于：根据三角形的不同类型,提取出其特征,并将其量化作为点与点之间的边权值；然后直接将有向无权图转化为无向有权图,再用改进的标签传播算法来进行社区发现。</td>   <td>G06Q50/00;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   林星彤       </td>   <td>中山大学</td>   <td>一种用于中文文本定级以及计算中文文本难度评分的方法</td>   <td>广东</td>   <td>CN107977362A</td>   <td>2018-05-01</td>   <td>本发明涉及一种用于中文文本定级以及计算中文文本难度评分的方法,进行首先文本获取及等级标注,获取具有分类标签的作为训练集的文章,然后进行特征提取,获取每篇文章所对应的全部语言学特征的特征值；再之,进行模型的建立与检验,得出预测准确率达到预期的模型,最后采用得到的模型预测文本难度。本发明适用于各种需要评价文本易读性的场景之中,采用的支持向量回归算法模型通过提高特征的维度空间来达到更好的评分效果,优于传统的线性模型。</td>   <td>一种用于中文文本定级以及计算中文文本难度评分的方法,其特征在于：包括以下步骤：S1、文本获取及等级标注,获取具有分类标签的作为训练集的文章；S2、特征提取,获取每篇文章所对应的全部语言学特征的特征值；S3、模型的建立与检验,得出预测准确率达到预期的模型；S4、采用步骤S3得到的模型预测文本难度。</td>   <td>G06F17/27;G06F17/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              叶泳坚;                   周晓聪       </td>   <td>中山大学</td>   <td>基于下载行为数据及向量表征学习的移动应用推荐方法</td>   <td>广东</td>   <td>CN107967330A</td>   <td>2018-04-27</td>   <td>本发明涉及基于下载行为数据及向量表征学习的移动应用推荐方法,首先提取用户下载序列,然后训练得出App表征向量A以及计算出用户下载行为表征向量R,最后通过A、R推荐或R推荐两种方式得出推荐结果。本发明利用用户下载App的序列数据,无需App本身的信息以及用户的反馈信息,使数据来源的获取相对容易很多；同时模型的复杂性不高,不会出现过拟合的现象且准确性较高,训练速度较快。</td>   <td>基于下载行为数据及向量表征学习的移动应用推荐方法,其特征在于：包括以下步骤：S1、从用户下载App记录数据中提取每个用户的下载App序列{x<sub>1</sub>,x<sub>2</sub>,…,x<sub>k</sub>}；S2、将下载序列输入到word2vec模型当中,得到每个App的表征向量,{a<sub>1</sub>,a<sub>2</sub>,…a<sub>N</sub>},假设a为T维向量,再对其进行归一化,得到A＝Norm(a)；S3、将每个用户的下载序列{x<sub>1</sub>,x<sub>2</sub>,…,x<sub>k</sub>}中的App对应出相应的向量,得到T*K矩阵,B＝{X<sub>1</sub>,X<sub>2</sub>,…,X<sub>K</sub>}；通过该矩阵得到每个用户的用户行为表征向量r后,对r进行归一化,得到R＝Norm(r)；S4、对每个用户计算R和A的相似度,得到相似度向量{S<sub>1</sub>,S<sub>2</sub>,…,S<sub>N</sub>},对其进行排序,按从大到小的顺序推荐给用户；S5、计算用户行为表征向量R与其他用户行为表征向量R<sub>N</sub>的相似度,得到相似度向量{S'<sub>1</sub>,S'<sub>2</sub>,…,S'<sub>N</sub>},对其进行排序,选取S'较高的用户对应下载过的App,在该些App中选取S值较高者推荐给用户。</td>   <td>G06F17/30;G06Q30/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              何艳虎;                   李佩怡       </td>   <td>中山大学</td>   <td>基于用水总量控制的水资源优化配置报童方法</td>   <td>广东</td>   <td>CN107944603A</td>   <td>2018-04-20</td>   <td>本发明涉及水利工程领域,更具体地,涉及一种基于用水总量控制的水资源优化配置报童方法。包括以下步骤：S1.根据配水传输条件和需水要求,采集各供水量数据和需水量数据；S2.结合S1步骤所采集的数据,以经济、社会和生态环境综合效益为最大目标,确定目标函数和配水系数；S3.依据水资源模拟系统中的数据条件组成水资源优化配置的约束条件；S4.对用水总量控制的水资源优化配置报童模型进行求解。本发明紧密地结合了当前用水总量控制的社会命题和水价水市场的动态变化信息,反映了不同用水总量控制指标方案对用水户净收益的影响,有效地协调了流域来水、需水、用水总量控制与配水指标之间的关系,符合南方高强度用水区用水特点。</td>   <td>一种基于用水总量控制的水资源优化配置报童方法,其特征在于,包括以下步骤：S1.根据配水传输条件和需水要求,采集各供水量数据和需水量数据；S2.结合S1步骤所采集的数据,以经济、社会和生态环境综合效益为最大目标,确定目标函数和配水系数；S3.依据水资源模拟系统中的数据条件组成水资源优化配置的约束条件；S4.对用水总量控制的水资源优化配置报童模型进行求解。</td>   <td>G06Q10/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡继华;              林军记;              张力越;              程智锋;                   伍丽华       </td>   <td>中山大学</td>   <td>一种基于无人机的路口斑马线识别方法</td>   <td>广东</td>   <td>CN107944407A</td>   <td>2018-04-20</td>   <td>本发明涉及一种基于无人机的路口斑马线识别方法,包括以下步骤：S1.将无人机悬停在路口的正上方,对路口范围进行视频拍摄,获取包含斑马线的视频图像；S2.采用混合高斯背景建模方法提取图像中路口的背景图像；S3.对提取出的背景图像进行图像分块处理,计算各图块的灰度的最大值、最小值,并作为输入参数计算各图块的双极系数,将各图块的双极系数进行合并操作,得到背景图像的双极系数图；S4.对双极系数图进行二值化操作,并进行数字图像形态学处理,得到候选的斑马线区域；S5.设定面积阈值和长宽比阈值,将各个候选斑马线区域进行对比过滤,将不符合面积阈值和长宽比阈值候选斑马线区域删除,而将符合条件的候选斑马线区域作为识别结果进行保留。</td>   <td>一种基于无人机的路口斑马线识别方法,其特征在于：包括以下步骤：S1.将无人机悬停在路口的正上方,对路口范围进行视频拍摄,获取包含斑马线的视频图像；S2.采用混合高斯背景建模方法提取图像中路口的背景图像；S3.对提取出的背景图像进行图像分块处理,计算各图块的灰度的最大值、最小值,并作为输入参数计算各图块的双极系数,将各图块的双极系数进行合并操作,得到背景图像的双极系数图；S4.对双极系数图进行二值化操作,并进行数字图像形态学处理,得到候选的斑马线区域；S5.设定面积阈值和长宽比阈值,将各个候选斑马线区域进行对比过滤,将不符合面积阈值和长宽比阈值候选斑马线区域删除,而将符合条件的候选斑马线区域作为识别结果进行保留。</td>   <td>G06K9/00;G06K9/38;G06T7/155;G06T7/187;G06T7/194</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何兆成;                   钟嘉明       </td>   <td>中山大学</td>   <td>基于公交APP用户数据的公交乘客候车时间计算方法</td>   <td>广东</td>   <td>CN107944700A</td>   <td>2018-04-20</td>   <td>本发明利用实时公交App中海量的用户数据,通过时间关联的方法,构建公交信息查询链,并结合数据挖掘的方法,从中发现用户在公交出行中的节点时刻,如规划公交出行时刻、到站时刻和离站时刻,依此计算该用户候车时间。对于无法计算候车时间的不完整公交信息查询链,如无法识别或缺失到站行为或离站行为等记录,则利用与其相似的完整公交信息查询链,采取随机森林算法对缺失的行为记录进行修补,最终实现候车时间的计算。</td>   <td>基于公交APP用户数据的公交乘客候车时间计算方法,其特征在于：包括有以下步骤：S1.记录用户使用公交APP时留下的对应服务的请求数据和用户进行位置类服务请求留下的定位数据,若请求数据的请求时间与定位数据的请求时间相差在k秒以内,则将定位数据及请求数据进行时间关联,形成一个公交信息查询节点；S2.记录用户使用公交APP出行留下的对应服务的请求数据和用户进行位置类服务请求留下的定位数据,然后按照步骤S1的方法进行处理,得到多个公交信息查询节点；S3.得到的多个公交信息查询节点按发生时间顺序进行排序,形成一条公交信息查询链；S4.根据公交信息查询链上的公交信息查询节点的定位数据分别计算各个节点与目标公交车站间的距离,以及根据定位数据确定用户在各个节点的移动速度,然后根据计算的各个节点与目标公交车站间的距离、用户在各个节点的移动速度确定公交信息查询链上的到站节点、离站节点,从而确定用户出行的到站时刻T<sub>2</sub>和离站时刻T<sub>3</sub>,从而计算得到候车时间：T<sub>候车时间</sub>＝T<sub>3</sub>#T<sub>2</sub>。</td>   <td>G06Q10/06;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡延庆;              贾寒;              孙嘉辰;              谢家荣;                   刘荣       </td>   <td>中山大学</td>   <td>一种在线社交网络中有影响力传播者识别与量化的方法</td>   <td>广东</td>   <td>CN107945036A</td>   <td>2018-04-20</td>   <td>本发明属于信息领域,特别涉及一种在线社交网络中有影响力传播者识别与量化的方法。本发明基于SIR家族传播模型,将社交网络抽象为一张图G(V,E),V代表节点的集合；E代表边的集合,每条边表示节点之间的关系；包括：利用基于渗流理论的贪心算法,计算出所述图G(V,E)中所有节点的传播能力S,并按每个节点传播能力S大小排序,找出传播能力最强的前M个顶点。本发明的有益效果是通过局部网络结构来度量全局网络传播影响力,降低了降低算法的时间复杂度。</td>   <td>一种在线社交网络中有影响力传播者识别与量化的方法,基于SIR家族传播模型,将社交网络抽象为一张图G(V,E),V代表节点的集合；E代表边的集合,每条边表示节点之间的关系；包括：利用基于渗流理论的贪心算法,计算出所述图G(V,E)中所有节点的传播能力S,并按每个节点传播能力S大小排序,找出传播能力最强的前M个顶点。</td>   <td>G06Q50/00;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              陶鹏;                   周晓聪       </td>   <td>中山大学</td>   <td>一种结合情境信息的个性化餐厅推荐方法</td>   <td>广东</td>   <td>CN107944007A</td>   <td>2018-04-20</td>   <td>本发明涉及一种结合情境信息的个性化餐厅推荐方法,包括建立规则库、冷启动阶段以及用户数据分析阶段；其中,建立的规则库中含有短期偏好规则和固定偏好规则。在冷启动阶段,使用冷数据为新用户提供推荐,尽量让用户在冷启动期间做到少输入甚至不输入,从而降低移动用户的操作复杂性。在用户数据分析阶段,结合了丰富的情境信息,包括环境,天气条件,时间季节,并根据用户的短期偏好和固定偏好为用户提供最有效的推荐。当系统累积足够的数据时,应用协同过滤算法来改进推荐结果。本发明结合情境类信息,并考虑系统冷启动问题,应用协同过滤算法以及基于规则的推荐算法,使为用户推荐个性化餐厅的精准度大大提高。</td>   <td>一种结合情境信息的个性化餐厅推荐方法,其特征在于：包括建立规则库、冷启动阶段以及用户数据分析阶段；其中,建立的规则库中含有短期偏好规则和固定偏好规则；在冷启动阶段,先将情境信息与规则库里的短期偏好规则匹配,获取用户的短期偏好；再将用户资料与规则库里的固定偏好规则匹配,获取用户的固定偏好；最后通过获取到的短期偏好和固定偏好与餐厅的属性相匹配计算出餐厅的推荐概率；在用户数据分析阶段,首先修改冷启动阶段的规则,然后进行基于用户和基于情景的协同过滤算法,得出协同过滤结果,最后将基于规则的推荐算法所获得的结果与协同过滤结果混合起来,得出最终推荐结果并将该结果的餐厅推荐给目标用户。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈纪凯;              潘炎;              赖韩江;              印鉴;                   高静       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种基于关键点检测的衣服种类和属性分类方法</td>   <td>广东</td>   <td>CN107918780A</td>   <td>2018-04-17</td>   <td>本发明提供一种基于关键点检测的衣服种类和属性分类方法,该方法先采集训练样本的数据；然后构建可配置的检测衣服关键点的深度模型,并将训练样本的数据输入深度模型,以对深度模型进行训练；接着利用训练后的检测关键点的深度模型对衣服图像进行分析,预测衣服图像中每个关键点的位置；最后根据S3中预测关键点的结果,以此提取相关局部信息,再融合全局的图片信息,再通过深度模型对衣服种类和属性进行训练、预测。该方法实现了能够更好融合衣服局部和全局特征。</td>   <td>一种基于关键点检测的衣服种类和属性分类方法,其特征在于,包括以下步骤：S1：采集训练样本的数据；S2：构建可配置的检测衣服关键点的深度模型,并将训练样本的数据输入深度模型,以对深度模型进行训练；S3：利用训练后的检测关键点的深度模型对衣服图像进行分析,预测衣服图像中每个关键点的位置；S4：根据S3中预测关键点的结果,以此提取相关局部信息,再融合全局的图片信息,再通过深度模型对衣服种类和属性进行训练、预测。</td>   <td>G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              郑炎辉;                   房春艳       </td>   <td>中山大学</td>   <td>一种平原感潮河网区纳污能力计算方法</td>   <td>广东</td>   <td>CN107885958A</td>   <td>2018-04-06</td>   <td>本发明涉一种平原感潮河网区纳污能力计算方法。包括：S1.#收集水文资料、水质资料、入河排污口资料、河道断面地形数据；S2.#根据流域或区域规划要求,以规划管理目标所确定的污染物作为计算河段纳污能力的污染物；S3.#确定设计边界,上游边界采用90%保证率最枯月平均流量或近十年最枯月平均流量作为设计流量,下边界以多年平均潮位作为设计潮位过程；S4.#构建大型感潮网河区的纳污能力计算数学模型,包括建立网河区一维水动力模型和建立网河区一维水质模型；S5.#将S1步骤收集的数据代入纳污能力计算模型后,计算获得各水功能区的纳污能力。本发明提供的计算模型结构十分简单；主要特点是简便、通用,模拟精度较高,尤其适用于感潮复杂河网水流水环境模拟。</td>   <td>一种平原感潮河网区纳污能力计算方法,其特征在于,包括以下步骤：S1.收集水文资料、水质资料、入河排污口资料、河道断面地形数据；S2.根据流域或区域规划要求,以规划管理目标所确定的污染物作为计算河段纳污能力的污染物；S3.确定设计边界,上游边界采用90％保证率最枯月平均流量或近十年最枯月平均流量作为设计流量,下边界以多年平均潮位作为设计潮位过程；S4.构建大型感潮网河区的纳污能力计算数学模型,包括建立网河区一维水动力模型和建立网河区一维水质模型；S5.将S1步骤收集的数据代入纳污能力计算模型后,计算获得各水功能区的纳污能力。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         宋振华;              刘焱;              杨建勇;              蒋乐伦;              宋嵘;              张超;                   蒋庆       </td>   <td>中山大学</td>   <td>基于稀疏性随机池化的卷积神经网络的图像识别方法</td>   <td>广东</td>   <td>CN107871136A</td>   <td>2018-04-03</td>   <td>本发明所述基于稀疏性随机池化卷积神经网络的图像识别方法,该方法利用稀疏性随机池化的卷积神经网络来对图像进行特征提取并联结分类器分类识别,所述稀疏性随机池化的池化策略是：首先判别池化区域的稀疏程度来动态选取该区域的最佳特征值,并通过该最佳值使用高斯分布分配池化区域每个激活值概率权重,最后通过概率权重进行随机取值作为池化的输出值；本发明所述基于稀疏性随机池化卷积神经网络的图像识别方法的有益效果是：不仅能够优化特征提取阶段的特征信息,而且使模型在训练中一定程度上避免陷入局部最小值,增强了识别模型的泛化性与识别精度。</td>   <td>一种基于稀疏性随机池化卷积神经网络的图像识别方法,其特征在于包括如下步骤：1)构建图像样本集,包括训练集与测试集以及每张图片对应的标签集,其中设定好图像每一类别在分类器中的编码方式；2)搭建卷积神经网络框架,包括特征提取框架与训练分类框架,特征提取阶段由多个卷积层与池化层交迭进行,训练分类阶段由全连接层与分类器层构成,用于将前端提取的图像特征经由全连阶层并以向量形式输入分类器；3)训练过程中设置超参数,构造代价函数,利用BP算法每次根据最小批次的误差反向更新网络的权重；所述超参数包括学习率参数、Dropout层、带momentum的SGD、ReLu激活函数等；所述构造代价函数,即计算所得值与目标标签值的误差函数；然后利用BP算法每次根据最小批次的误差反向更新网络的权重；4)图像输入识别模型的卷积层进行特征提取,输出特征图并连接下一个神经元作为新的输入数据进行操作,每个神经元只对图像的局部区域进行感知,两个相邻滑动窗口之间的距离称为步长,每个特征图谱上所有节点具有权重共享特性；5)在卷积神经网络结构中的池化层采用稀疏随机池化操作,池化策略是根据池化区域的稀疏程度来动态得到该区域的最佳特征值,并通过该最佳特征值利用高斯分布以最佳特征值为中央分配区域其余激活值的权重,最后通过带权重的随机取值作为池化的输出值；6)图像数据前向传播经过卷积层、池化层、非线性层和全连接层最后连接softmax分类器,计算交叉熵代价函数,并使用随机梯度下降法反向传播逐层调整权重减小误差；7)重复步骤6),经由网络的输入端到输出端不断的训练调整,使代价函数不断收敛,直至达到设定的训练次数或测试集上准确率不再提升则终止训练,获得CNN图像识别模型；8)如图3(b)所示,使用训练好的网络对新的图像样本进行识别,得到最终分类结果。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴增程;              张东;                   李禹源       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的织带断痕缺陷检测方法</td>   <td>广东</td>   <td>CN107862692A</td>   <td>2018-03-30</td>   <td>本发明涉及一种织带断痕缺陷检测方法,更具体地,涉及一种基于卷积神经网络的织带断痕缺陷检测方法。利用卷积神经网络对织带图片特征自动实现最有效的提取,提出局部连接方式,大大减少了神经网络参数量,降低计算的复杂度；采用卷积核的权值共享的方式,减少需要训练的权重数量,不仅进一步降低了计算的复杂度,而且可以避免过多的连接导致的严重的过拟合,减少连接数可以提升模型的泛化性；利用池化层对卷积层输出的特征图进行聚合统计,通过将池化区域的特征进行整合,对相同特征进行筛选,从而达到降低模型规模,加速训练的目的。</td>   <td>一种基于卷积神经网络的织带断痕缺陷检测方法,其特征在于,包括以下步骤：S1.图片采集,利用工业摄像头采集织带图片,通过Flycaputer#SDK对摄像头拍摄区域大小进行设置,对上述样本图片进行分类和标记,分别得到织带有断痕缺陷样本集和无断痕缺陷样本集；S2.图片预处理,分别将有断痕缺陷样本集、无断痕缺陷样本集按照一定比例分为两份,取数目较多的一份作为训练集,数目较少的一份作为测试集,分别按照i_1,i_2,i_3......对图片进行编号,其中,i＝0对应有断痕缺陷样本集,i＝t对应无断痕缺陷样本集；同时,将图片随机裁剪成预定像素的图片,将图片均转化为lmdb格式的数据集,对数据集进行镜像操作,并对每一张图片RGB三通道分别减去所有训练图片的三通道均值；S3.图片训练,采用AlexNet网络结构,并对相应的求解器进行设置,通过命令行输入训练命令指引计算机对图片进行训练；通过前五层卷积层、池化层和激活函数层对图片特征的提取,将原始数据映射到隐层特征空间,再经过后三层全连接层的作用,将学习到的“分布式特征表示”映射到样本标记空间,根据对损失函数值的大小对训练结果进行优化；S4.图片分类,将待分类图片进行S2步骤所述的预处理,输入S3步骤训练得到的模型中进行特征提取和分类,输出分类结果,即输出采集的图片是有断痕缺陷或无断痕缺陷的结果。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         聂照昌;              潘炎;              印鉴;                   潘文杰       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司</td>   <td>一种排序整合问题的求解方法</td>   <td>广东</td>   <td>CN107832321A</td>   <td>2018-03-23</td>   <td>本发明提供一种排序整合问题的求解方法,该方法是一种具有健壮性的排序整合方法,该排序整合方法同时考虑了排序列表存在缺失值和噪声的情况。本发明首先通过输入的排序列表构造一个成对比较矩阵,然后将该矩阵能够分解成一个低秩矩阵和一个偏移误差矩阵的和。且该偏移误差矩阵是由行稀疏矩阵与列稀疏矩阵组合成的。最后本发明将利用增广拉格朗日乘子法进行该形式的问题求解。</td>   <td>一种排序整合问题的求解方法,其特征在于,包括以下步骤：S1：将排序整合问题数学模型化；S2：将S1中得到的目标数学公式转成拉格朗日式子；S3：将拉格朗日式子利利用学习算法进行更更新参数求解。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴惜娟;              韦宝典;              田海博;              杜育松;                   马啸       </td>   <td>中山大学</td>   <td>一种基于区块链的公平电子投票协议</td>   <td>广东</td>   <td>CN107833135A</td>   <td>2018-03-23</td>   <td>本发明属于信息安全领域,提出一种基于区块链的公平电子投票协议。本发明使用区块链,门限签名方案,承诺机制,零知识证明等技术和密码学方法,基于时间承诺和支付押金的方式,提出一种基于区块链和素数的无可信第三方电子投票方案,可以支持多个候选者的投票情况。本发明由初始阶段,承诺阶段,投票阶段,审计阶段四个部分组成,每个投票者通过选择不同的与候选者唯一对应的素数来对不同候选者进行投票,投票者先支付一笔押金再进行投票,如果投票过程中有不诚实的行为,该投票者的押金会用于赔偿其他投票者,以此来保证投票过程的公平性。本发明可用于实现公平和安全的电子投票。</td>   <td>一种基于区块链技术的公平电子投票协议,包括：投票者V<sub>i</sub>,i∈{1,...,n},和候选者S<sub>j</sub>,j∈{1,...,k},其中n和k均为大于等于1的自然数；以及投票组织机构RA；其特征在于包括如下步骤：S1.初始阶段具体为：投票者V<sub>i</sub>在投票组织机构RA注册；所述投票者V<sub>i</sub>的投票地址为与所述投票者V<sub>i</sub>对应的比特币公钥pk<sub>i</sub>的哈希值；投票组织机构RA选取任意k个不同奇素数并平均分配给k个候选者,使每个候选者与唯一的素数相关联,假设m是所述k个素数的最大值,定义一个大于m<sup>n</sup>的以2为底的最小幂数作为参数M；所述候选者S<sub>j</sub>的候选地址为与所述候选者S<sub>j</sub>对应的比特币公钥pk<sub>j</sub>的哈希值；投票者通过选择与候选者相对应的的素数来对不同候选者进行投票；S2.承诺阶段具体为：每个投票者V<sub>i</sub>都有一张个人秘密选票O<sub>i</sub>∈{3,5,7,...},所述秘密选票O<sub>i</sub>是所述投票者V<sub>i</sub>选择的某个候选者对应的素数；投票者V<sub>i</sub>和其他投票者通过投票承诺协议合作生成随机数R<sub>i</sub>,并计算自己的投票<img file="FDA0001449139210000011.TIF" wi="255" he="71" />所述投票承诺协议如下：每个投票者都有zk_SNARKs证明和验证密钥,对于每个i∈{1,...,n},投票者V<sub>i</sub>做如下操作:(S2.1)对于每一个x∈{1,...,n},生成n个秘密随机数r<sub>ix</sub>∈Z<sub>M</sub>,使其乘积等于1(modM),Z<sub>M</sub>为从0到(M#1)范围内的整数集合；V<sub>i</sub>对r<sub>ix</sub>进行检查,确保不含有候选人的素数因子；(S2.2)对于每一个x∈{1,...,n},生成承诺(c<sub>ix</sub>,k<sub>ix</sub>)←Commit(r<sub>ix</sub>),其中k<sub>ix</sub>是打开承诺c<sub>ix</sub>的密钥；(S2.3)使用zk_SNARKs生成零知识证明,证明∏<sub>x</sub>r<sub>ix</sub>＝1(modM)；(S2.4)向所有其他投票者广播承诺和零知识证明；(S2.5)接受承诺并验证所有其他投票者的零知识证明；(S2.6)对于所有的x∈{1,...,n}\{i},发送打开密钥k<sub>ix</sub>给V<sub>x</sub>；符号V<sub>x</sub>表示不同于投票者V<sub>i</sub>的其他投票者；(S2.7)对于所有的x∈{1,...,n}\{i},在接收到V<sub>x</sub>发送的打开密钥k<sub>xi</sub>时,检查r<sub>xi</sub>＝Open(c<sub>xi</sub>,k<sub>xi</sub>)≠⊥；(S2.8)计算R<sub>i</sub>←∏<sub>x</sub>r<sub>xi</sub>和<img file="FDA0001449139210000021.TIF" wi="267" he="71" />并承诺(C<sub>i</sub>,K<sub>i</sub>)←Commit(R<sub>i</sub>)和<img file="FDA0001449139210000022.TIF" wi="494" he="71" />其中K<sub>i</sub>,<img file="FDA0001449139210000023.TIF" wi="61" he="70" />分别是相应的打开密钥；(S2.9)广播承诺C<sub>i</sub>和<img file="FDA0001449139210000029.TIF" wi="75" he="70" />(S2.10)使用zk_SNARKs生成和广播以下语句的零知识证明：(S2.10a)R<sub>i</sub>:＝∏<sub>x</sub>r<sub>xi</sub>(modM)；(S2.10b)<img file="FDA0001449139210000024.TIF" wi="46" he="70" />中承诺值与C<sub>i</sub>中承诺值的商是出现在所有候选者相对应的素数所构成的集合中的；(S2.11)接收并验证其他投票者的所有证明；S3.投票阶段的具体过程如下：(S3.1)假设至少有一半的投票者是诚实的,投票者V<sub>i</sub>拥有群体公钥<img file="FDA0001449139210000025.TIF" wi="66" he="70" />和各自的私钥<img file="FDA0001449139210000026.TIF" wi="86" he="70" />(pk<sub>i</sub>,sk<sub>i</sub>)表示比特币系统中投票者V<sub>i</sub>的地址对应的公钥和私钥；(S3.2)假设t<sub>1</sub>,t<sub>2</sub>为大于6个区块的将来时间,且t<sub>1</sub>＜t<sub>2</sub>；所有投票者共同运行以下协议：(S3.2a)n个投票者共同生成一个交易JOIN；所述交易JOIN有n个输入,每个输入都分别对应于在交易<img file="FDA00014491392100000210.TIF" wi="64" he="59" />中输入投票者V<sub>i</sub>拥有的(1+d)比特币；所述交易JOIN有n+1个输出,包括对于每个投票者V<sub>i</sub>都具有d比特币押金的out#deposit<sub>i</sub>,i∈{1,...,n},以及具有n比特币的out#winner；(S3.2b)投票者V<sub>i</sub>使用自己的私钥sk<sub>i</sub>依次签署交易JOIN；共创建了n个签名；(S3.2c)对于i∈{1,...,n},每个投票者生成交易PAY<sub>i</sub>,所述交易PAY<sub>i</sub>的输入是对应的out#deposit<sub>i</sub>；在t<sub>2</sub>时间之后,所述交易PAY<sub>i</sub>的输出脚本可以把投票者V<sub>i</sub>的押金分享给其他诚实的投票者；(S3.2d)投票者V<sub>i</sub>完成上述步骤(S3.3a)(S3.3b)(S3.3c)的验证,便将所述交易JOIN交易提交给区块链；S4.审计阶段具体过程为：交易JOIN出现在区块链后,投票者V<sub>i</sub>通过提交一个交易CLAIM<sub>i</sub>来赎回他的d比特币押金,提供打开密钥<img file="FDA0001449139210000027.TIF" wi="56" he="71" />来公布投票<img file="FDA0001449139210000028.TIF" wi="75" he="71" />如果所有投票者都提交了交易CLAIM<sub>i</sub>,则计算输出脚本中的函数<img file="FDA0001449139210000031.TIF" wi="275" he="71" />最后函数<img file="FDA0001449139210000032.TIF" wi="243" he="68" />返回票数最高者的公钥pk<sub>w</sub>,w取值为1≤w≤k的整数,确定所述票数最高者为获胜候选者；并且通过交易Winner从out#winner中兑换n比特币,所述交易Winner的输入是交易JOIN的输出out#winner中的n比特币,输出是所述获胜候选者的公钥pk<sub>w</sub>地址；如果至少有一个投票者没有公布他的投票,则无法计算出最终投票结果,原本给获胜候选者的n比特币将被所有投票者通过交易Redeem直接赎回,所述交易Redeem的输入是所述交易JOIN的输出out–winner中的n比特币,输出是所有投票者的公钥地址,每个投票者都能拿回原来给获胜者的1比特币。</td>   <td>G06Q40/04;H04L9/30;H04L9/32</td>  </tr>        <tr>   <td>中国专利</td>   <td>         肖侬;              陈地长;              陈志广;              卢宇彤;                   杜云飞       </td>   <td>中山大学</td>   <td>一种用于分布式文件系统的文件读写方法</td>   <td>广东</td>   <td>CN107832423A</td>   <td>2018-03-23</td>   <td>本发明公开了一种用于分布式文件系统的文件读写方法,文件读采用客户端#&gt;元数据服务器#&gt;数据服务器#&gt;客户端的文件读取IO路径,文件写时客户端获取需要进行文件写的待写文件数量,如果待写文件数量超过预设阈值,则判定高性能计算场景,且针对高性能计算场景下大量的线程同时写文件采用“先写数据后创建元数据”的策略以降低元数据服务器上的突发负载；否则,针对每一个待写的目标文件采用客户端#&gt;数据服务器#&gt;元数据服务器#&gt;客户端的文件写入IO路径。本发明具有文件读写速度快,效率高,减少了客户端和元数据服务器交互的次数,降低了通信开销的优点。</td>   <td>一种用于分布式文件系统的文件读写方法,其特征在于,文件读的实施步骤包括：A1)客户端向分布式文件系统的元数据服务器通信发送读取文件的请求；A2)元数据服务器在收到客户端的请求后向客户端返回通信查询元数据信息、且向读取文件的文件块所在的数据服务器发送客户端请求信息及通信地址,客户端根据元数据服务器返回信息找到读取文件的文件块所在的数据服务器；A3)数据服务器收到客户端请求信息及通信地址后,和客户端建立连接并开始向客户端发送读取文件的文件块数据；A4)客户端以文件块为单位接收数据,先在本地缓存、然后写入目标文件,将后面的文件块和前面的文件块合并成最终所需要的文件,完成数据读取。</td>   <td>G06F17/30;H04L29/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐承佩;              王剑涛;              刘为飞;              王善庆;              谭杜康;              张臣友;                   赵森       </td>   <td>中山大学;中建钢构有限公司;广州汇数信息科技有限公司</td>   <td>一种用于生产车间的电能监控与管理方法及系统</td>   <td>广东</td>   <td>CN107832946A</td>   <td>2018-03-23</td>   <td>本发明实施例公开一种用于生产车间的电能监控与管理方法,其特征在于,包括步骤：(1)智能电表采集设备上各时段用电数据,并生成数据信号；(2)WIFI模块将接收到的所述数据信号传输给路由器；(3)路由器汇集所述数据信号并通过交换机发送给所述服务器；(4)服务器接收所述数据信号并进行分析处理。本发明实施例还公开一种用于生产车间的电能监控与管理系统。与现有技术相比,本发明通过对各个车间单位的用电需求进行统筹调度,使生产车间用电更节能、高效和安全；同时、根据设备运行状态及利用率,可以及时有效的对设备进行维护和增添。</td>   <td>一种用于生产车间的电能监控与管理方法,其特征在于,包括步骤：(1)智能电表采集设备上各时段用电数据,并生成数据信号；(2)WIFI模块将接收到的所述数据信号传输给路由器；(3)路由器汇集所述数据信号并通过交换机发送给所述服务器；(4)服务器接收所述数据信号并进行分析处理。</td>   <td>G06Q10/06;G06Q50/06;G01R31/00;G01R22/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              李晓杰;                   吴向军       </td>   <td>中山大学</td>   <td>一种字符级的基于嵌套深度网络的文本分类方法</td>   <td>广东</td>   <td>CN107832458A</td>   <td>2018-03-23</td>   <td>本发明涉及一种字符级的基于嵌套深度网络的文本分类方法,包括以下步骤：S1、构造字符向量矩阵表；S2、短文本预处理；S3、改进Resnet提取高维序列特征；S4、LSTM网络分类。本发明基于字符级的文本转换能有效的对所有的文本进行转换,相对于传统的向量空间模型,维度下降明显,而且对于所有的文本都能有效的转换,不会忽略低频词；另外,改进Resnet能够自学习特征提取方法,相对于传统的TF#IDF公式,互信息量,信息增益,χ2统计量等方法,其提取的特征更加有效,更加抽象；最后,LSTM网络分类能够考虑词与词之间的顺序关系,从而能够更加准确地进行文本分类。</td>   <td>一种字符级的基于嵌套深度网络的文本分类方法,其特征在于：包括以下步骤：S1、构造字符向量矩阵表：假设C为文本中所用的字符集,构造一个字符向量矩阵Q∈R<sup>|C|×|C|</sup>,记录下每一个字符对应的行编号；S2、短文本预处理；S3、改进Re#snet提取高维序列特征；S4、LSTM网络分类。</td>   <td>G06F17/30;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              富明慧       </td>   <td>中山大学</td>   <td>一种基于半方盲文数字编码的手写汉字输入法</td>   <td>广东</td>   <td>CN107831918A</td>   <td>2018-03-23</td>   <td>本发明提供了一种基于半方盲文数字编码的手写汉字输入法,包括以下步骤：S1、将盲文拆分成左右半方,并根据半方盲文图案进行数字编码；S2、在手写输入设备上设置一手写输入区域；S3、用户在手写输入区域内通过手写手势输入代表一方盲文的两位数字编码；S4、通过手写输入设备识别用户的手写手势,获取用户输入的两位数字编码；S5、将两位数字编码分别还原为对应的半方盲文图案,并按照左右顺序将左右半方盲文图案拼合成一方盲文；S6、将盲文转换为汉字。本发明中,将半方盲文中可能出现的8种不同图案分别映射到8个不同的数字上；用户只需记住映射关系,省去了记忆大量手写图形的麻烦,大大降低了盲文手写输入法的记忆及书写难度。</td>   <td>一种基于半方盲文数字编码的手写汉字输入法,其特征在于,包括以下步骤：S1、将盲文拆分成左右半方,并根据半方盲文图案进行数字编码：将一方盲文拆分成左右两个半方,则每个半方有3个点位、8种变化图案；将半方盲文的8种变化图案分别映射到1～9之间的任意8个数字上,则一方盲文可以用两位数的数字编码表示；S2、在手写输入设备上设置一手写输入区域；S3、用户在手写输入区域内通过手写手势输入代表一方盲文的两位数字编码；S4、通过手写输入设备识别用户的手写手势,获取用户输入的两位数字编码；S5、将两位数字编码分别还原为对应的半方盲文图案,并按照左右顺序将左右半方盲文图案拼合成一方盲文；S6、将盲文转换为汉字；其中,S3具体包括：S301、在输入一方盲文的过程中,当用户起手点中手写输入区域的任一位置时,将该位置作为初始位置,以初始位置为中心,按照九宫格数字键盘中各数字按键的方位分布,在手写输入区域中生成数字1～9的虚拟按键区域；其中,初始位置所在的区域为数字“5”的虚拟按键区域；S302、用户通过继续在数字1～9的虚拟按键区域内滑动或点击,输入分别代表左右两个半方盲文图案的两位数字编码。</td>   <td>G06F3/023</td>  </tr>        <tr>   <td>中国专利</td>   <td>         原尉峰;              郭佳明;              杨红杰;                   苏卓       </td>   <td>中山大学</td>   <td>一种基于着装解析及人体检测的多人服装检索方法</td>   <td>广东</td>   <td>CN107818489A</td>   <td>2018-03-20</td>   <td>本发明实施例公开了一种基于着装解析及人体检测的多人服装检索方法,其中,该方法包括：对街拍图像进行多人着装解析处理；对图像中的人脸进行识别、计算,获取人脸位置的数据；结合多人着装解析数据集通过双通道人体检测神经网络,转化出对应的人体分布热度检测图；将其进行离散化处理；用户可以通过前端展示中选择衣物,后端进行数据检索,得出检索结果。对实施本发明实施例,能够满足用户便捷地利用街拍的图像去检索网上商城相似服装的需求。</td>   <td>一种基于着装解析及人体检测的多人服装检索方法,其特征在于,所述方法包括：对街拍图像进行多人着装解析处理,分割图像中的衣物,获取多人服装解析结果；对图像中的人脸进行识别,计算得出图像中人脸的数据；获取人脸数据及所述街拍图像,逐个输入双通道人体检测神经网络当中,得出每个人脸对应人体的分布热度检测图；对人体分布热度检测图设定一定阈值,进行离散化处理,将离散化处理后的人体分布图点结合多人着装解析数据集,获得所有服装区域；将服装区域在前端展示给用户,用户根据需求选择需要检索的衣物；后端接收前端传输过来的需检索衣物的数据,逐个输入到检索系统中,获得检索衣物。</td>   <td>G06Q30/06;G06K9/34;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蒋庆;              郑杰文;                   宋振华       </td>   <td>中山大学</td>   <td>一种基于随机游走结合像素点周围局部结构信息的图像分割方法</td>   <td>广东</td>   <td>CN107818566A</td>   <td>2018-03-20</td>   <td>本发明一种基于随机游走结合像素点周围局部结构信息的图像分割方法,本发明对图像分割效果好,准确性高,尤其对含有局部结构复杂图像的分割问题具有较高的准确性。本发明属于图像处理、图像分割算法领域。解决了一般图像分割方法由于局部信息复杂而分割失准问题。本发明不仅适用于一般轮廓清晰结构明显图像的分割,也适用于对局部结构信息复杂图像的分割,对含有细长部分分割对象也具有良好效果。</td>   <td>一种基于随机游走结合像素点周围局部结构信息的图像分割方法,具体算法流程包括以下步骤：S1：输入原始图像,程序读取待分割的图像；S2：在待分割的图像中辅助涂鸦以添加分类标签并添加辅助标签节点和连结分类标签节点,所述分类标签分为背景标签和前景标签；S3：利用像素点信息和结构张量,构成新型局部结构信息定义图论中像素点间的相似性权重函数w<sub>ij</sub>,以表示它们间的相似程度；S4：以马尔科夫性质在添加辅助标签节点的图像中设定随机游走者在像素节点之间的转移概率；S5：利用组合的狄利克雷边界函数来求解随机游走者像素之间的转移概率；S6：利用公式计算出随机游走者从无标签的节点出发到所有标签节点中的概率中的最大值；以到达标签节点概率最大为原则为每一个像素点的分配分类标签；S7：循环至所有无标签节点都分配得到分类标签为止；对每一个像素点分配的分类标签对图像完成最终分割。</td>   <td>G06T7/11;G06T7/143;G06T7/194</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;              欧阳效源;              刘洁;              刘希;              刘耀辉;                   王鑫       </td>   <td>中山大学</td>   <td>一种基于数据转换之间保持最大依赖关系的域自适应降维方法</td>   <td>广东</td>   <td>CN107818345A</td>   <td>2018-03-20</td>   <td>本发明涉及机器学习中域自适应相关问题,提出了一种基于数据转换之间保持最大依赖关系的域自适应降维方法。为了减少源域与目标域之间的分布差异性,本方法对数据进行两次再生核希尔伯特空间映射,这两个希尔伯特空间分别记为H<sub>1</sub>和H<sub>2</sub>,其中H<sub>2</sub>被称为源域与目标域共同的潜在空间。为了方便测量源域与目标域之间边缘分布的差异性,本发明使用最大均值差异(MMD)的方法实现测量。H<sub>2</sub>由H<sub>1</sub>映射得来,为了测量数据映射在H<sub>1</sub>和H<sub>2</sub>空间中的相关性,本发明使用了希尔伯特#施密特独立准则(HSIC)方法测量。本方法的主要目的是使得源域和目标域在H<sub>2</sub>中的分布差异最小化,即MMD值最小化,且在H<sub>1</sub>和H<sub>2</sub>空间中数据转换之间的依赖关系最大化,即HSIC值最大化。</td>   <td>一种基于数据转换之间保持最大依赖关系的域自适应降维方法,其特征在于：A.令X表示数据样本的特征空间,X＝X<sub>S</sub>∪X<sub>T</sub>＝{x<sub>i</sub>|i＝1,…,N}表示N个样本的训练数据集,<img file="FSA0000152918380000011.TIF" wi="154" he="42" />其中X<sub>S</sub>表示源域数据样本,X<sub>T</sub>表示目标域数据样本,并且X<sub>S</sub>与X<sub>T</sub>具有不同的边缘概率分布；通过核映射的方法,把源域和目标域的样本共同映射到希尔伯特再生核空间H<sub>1</sub>＝span{φ(x<sub>1</sub>),...,φ(x<sub>N</sub>)},即把X映射到H<sub>1</sub>中,H<sub>1</sub>中的φ(x<sub>1</sub>),...,φ(x<sub>N</sub>)分别对应X中的N个样本；然后在H<sub>1</sub>中,通过内积的计算方式得到核矩阵K；定义一个转移矩阵,表示为W,把H<sub>1</sub>映射到再生核希尔伯特空间H<sub>2</sub>,<img file="FSA0000152918380000012.TIF" wi="979" he="114" />把φ(x<sub>i</sub>)映射到H<sub>2</sub>,得到H<sub>2</sub>中的投影<img file="FSA0000152918380000013.TIF" wi="704" he="113" />同样地,通过内积的计算方式得到核矩阵L；在H<sub>2</sub>中计算投影后的源域与目标域的分布差异,用最大均值差异(MMD)测量,记为MMD(X<sub>S</sub>,X<sub>T</sub>)；前面的操作过程进行了两次核映射变换,为了最大化保持前后两次映射的依赖关系,这里添加了一个正则项,使用希尔伯特#施密特独立准则(HSIC)测量H<sub>1</sub>和H<sub>2</sub>的前后的依赖性,记为HSIC(H<sub>1</sub>,H<sub>2</sub>),H<sub>1</sub>与H<sub>2</sub>的HSIC值为<img file="FSA0000152918380000014.TIF" wi="631" he="99" />其中C<sub>N</sub>表示中心化矩阵；然后得到无监督的目标函数：<maths num="0001"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><mrow><munder><mrow><mi>arg</mi><mi>min</mi></mrow><mrow><mi>W</mi><mo>,</mo></mrow></munder><mi>M</mi><mi>M</mi><mi>D</mi><mrow><mo>(</mo><msub><mi>X</mi><mi>S</mi></msub><mo>,</mo><msub><mi>X</mi><mi>T</mi></msub><mo>)</mo></mrow><mo>+</mo><mi>&mu;</mi><mo>&CenterDot;</mo><mi>t</mi><mi>r</mi><mrow><mo>(</mo><msup><mi>W</mi><mi>T</mi></msup><mi>W</mi><mo>)</mo></mrow><mo>-</mo><mi>&lambda;</mi><mo>&CenterDot;</mo><mi>H</mi><mi>S</mi><mi>I</mi><mi>C</mi><mrow><mo>(</mo><msub><mi>H</mi><mn>1</mn></msub><mo>,</mo><msub><mi>H</mi><mn>2</mn></msub><mo>)</mo></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><msup><mi>WKW</mi><mi>T</mi></msup><mo> =</mo><msub><mi>I</mi><mi>d</mi></msub></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FSA0000152918380000015.TIF" wi="1037" he="154" /></maths>对于任意的输入样本点x,令k<sub>x</sub>＝[k(x<sub>1</sub>,x)#k(x<sub>2</sub>,x)#…#k(x<sub>n</sub>,x)]<sup>T</sup>,x的降维表示为<img file="FSA0000152918380000016.TIF" wi="158" he="48" />B.进一步地,令Y表示样本的类别空间,Y表示与X对应的类别集合,<img file="FSA0000152918380000017.TIF" wi="446" he="64" />y<sub>i</sub>∈{1,2,…,c},n<sub>l</sub>表示Y中值为l的元素个数,则源域的类内距离可以表示为<maths num="0002"><math><![CDATA[<mrow><mi>I</mi><mi>n</mi><mrow><mo>(</mo><msub><mi>X</mi><mi>S</mi></msub><mo>)</mo></mrow><mo> =</mo><mfrac><mn>1</mn><mi>c</mi></mfrac><munderover><mo>&Sigma;</mo><mrow><mi>l</mi><mo> =</mo><mn>1</mn></mrow><mi>c</mi></munderover><mfrac><mn>1</mn><mrow><msub><mi>n</mi><mi>l</mi></msub><mrow><mo>(</mo><msub><mi>n</mi><mi>l</mi></msub><mo>-</mo><mn>1</mn><mo>)</mo></mrow><mo>/</mo><mn>2</mn></mrow></mfrac><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mrow><msub><mi>n</mi><mi>l</mi></msub><mo>-</mo><mn>1</mn></mrow></munderover><munderover><mo>&Sigma;</mo><mrow><mi>j</mi><mo> =</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><msub><mi>n</mi><mi>l</mi></msub></munderover><mo>|</mo><mo>|</mo><msub><mi>f</mi><msub><mi>l</mi><mi>i</mi></msub></msub><mo>-</mo><msub><mi>f</mi><msub><mi>l</mi><mi>j</mi></msub></msub><mo>|</mo><msup><mo>|</mo><mn>2</mn></msup></mrow>]]></math><img file="FSA0000152918380000018.TIF" wi="804" he="121" /></maths>与步骤A所述相结合,得到半监督的目标函数：<maths num="0003"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><mrow><munder><mrow><mi>arg</mi><mi>min</mi></mrow><mi>W</mi></munder><mi>M</mi><mi>M</mi><mi>D</mi><mrow><mo>(</mo><mrow><msub><mi>X</mi><mi>S</mi></msub><mo>,</mo><msub><mi>X</mi><mi>T</mi></msub></mrow><mo>)</mo></mrow><mo>+</mo><mi>&mu;</mi><mo>&CenterDot;</mo><mi>t</mi><mi>r</mi><mrow><mo>(</mo><mrow><msup><mi>W</mi><mi>T</mi></msup><mi>W</mi></mrow><mo>)</mo></mrow><mo>-</mo><mi>&lambda;</mi><mo>&CenterDot;</mo><mi>H</mi><mi>S</mi><mi>I</mi><mi>C</mi><mrow><mo>(</mo><mrow><msub><mi>H</mi><mn>1</mn></msub><mo>,</mo><msub><mi>H</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow><mo>+</mo><mi>&alpha;</mi><mo>&CenterDot;</mo><mi>I</mi><mi>n</mi><mrow><mo>(</mo><msub><mi>X</mi><mi>S</mi></msub><mo>)</mo></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo><msup><mi>WKW</mi><mi>T</mi></msup><mo> =</mo><msub><mi>I</mi><mi>d</mi></msub></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FSA0000152918380000019.TIF" wi="1255" he="157" /></maths>对于任意的输入样本点x,令k<sub>x</sub>＝[k(x<sub>1</sub>,x)#k(x<sub>2</sub>,x)#…#k(x<sub>n</sub>,x)]<sup>T</sup>,x的降维表示为<img file="FSA00001529183800000110.TIF" wi="164" he="48" /></td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              商家煜;              许瑶婷;                   李仕仁       </td>   <td>广州智慧城市发展研究院;中山大学</td>   <td>一种基于卷积神经网络自压缩的图像降噪方法及系统</td>   <td>广东</td>   <td>CN107808365A</td>   <td>2018-03-16</td>   <td>本发明公开了一种基于卷积神经网络自压缩的图像降噪方法及系统,其中,所述图像降噪方法包括：将待降噪图像输入第一神经网络模型中；采用所述第一神经网络模型中的卷积层对所述待降噪图像进行神经网络隐式信息提取处理,获取待降噪图像的图像轮廓信息；采用所述第一神经网络模型中的降维采样层对所述轮廓图像信息进行降维采样处理,最后输出底层输出图像；将所述底层输出图像输入第二神经网络模型中；在所述第二神经网络模型中对所述底层输出图像进行图像升采样处理,并在所述图像升采样处理过程中同时采用最相邻像素点进行插值处理,输出复原降噪图像；将最后输出的复原降噪图像作为降噪图像。在本发明实施例中,可以保证图像降噪质量和高效性。</td>   <td>一种基于卷积神经网络自压缩的图像降噪方法,其特征在于,所述图像降噪方法包括：将待降噪图像输入第一神经网络模型中；采用所述第一神经网络模型中的卷积层对所述待降噪图像进行神经网络隐式信息提取处理,获取待降噪图像的图像轮廓信息；采用所述第一神经网络模型中的降维采样层对所述轮廓图像信息进行降维采样处理,判断降维采样处理后输出的图像轮廓信息是否为底层输出图像,若否,则返回上一步骤,若是,则进行下一步骤；将所述底层输出图像输入第二神经网络模型中；在所述第二神经网络模型中对所述底层输出图像进行图像升采样处理,并在所述图像升采样处理过程中同时采用最相邻像素点进行插值处理,输出复原降噪图像；判断所述复原降噪图像是否恢复至原图像大小,若否,则返回上一步,若是,则将所述复原降噪图像作为降噪图像。</td>   <td>G06T5/00;G06T7/13;G06T3/40;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朝红阳;              吴俊宇;                   徐炜       </td>   <td>中山大学</td>   <td>一种低分辨率图像的人脸识别方法</td>   <td>广东</td>   <td>CN107784296A</td>   <td>2018-03-09</td>   <td>本发明涉及一种低分辨率图像的人脸识别方法,包括有以下步骤：S1.构建并训练残差卷积神经网络；S2.计算残差卷积神经网络的联合损失函数L；S3.根据联合损失函数L利用反向传播算法对残差卷积神经网络的网络参数进行优化；S4.判定计算得到的联合损失函数L是否低于所设定的阈值,若是则结束训练过程；S5.训练好残差卷积神经网络后向残差卷积神经网络输入测试样本,得到识别结果。</td>   <td>一种低分辨率图像的人脸识别方法,其特征在于：包括有以下步骤：S1.构建残差卷积神经网络,训练样本向残差卷积神经网络输入的元组在输入至残差卷积神经网络之前,经过3个额外的卷积操作；S2.计算残差卷积神经网络的联合损失函数L：<maths num="0001"><math><![CDATA[<mrow><msub><mi>L</mi><mi>s</mi></msub><mo> =</mo><mo>-</mo><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>log</mi><mfrac><msup><mi>e</mi><mrow><msub><mi>M</mi><msub><mi>c</mi><mi>i</mi></msub></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><msub><mi>b</mi><msub><mi>c</mi><mi>i</mi></msub></msub></mrow></msup><mrow><msubsup><mi>&Sigma;</mi><mrow><mi>j</mi><mo> =</mo><mn>1</mn></mrow><mi>k</mi></msubsup><msup><mi>e</mi><mrow><msub><mi>M</mi><mi>j</mi></msub><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><msub><mi>b</mi><mi>j</mi></msub></mrow></msup></mrow></mfrac></mrow>]]></math><img file="FDA0001476545460000011.TIF" wi="991" he="244" /></maths><maths num="0002"><math><![CDATA[<mrow><msub><mi>L</mi><mi>c</mi></msub><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>|</mo><mo>|</mo><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><msub><mi>m</mi><msub><mi>c</mi><mi>i</mi></msub></msub><mo>|</mo><msup><mo>|</mo><mn>2</mn></msup></mrow>]]></math><img file="FDA0001476545460000012.TIF" wi="706" he="236" /></maths>L<sub>f</sub>＝α<sub>1</sub>L<sub>s</sub>+α<sub>2</sub>L<sub>c</sub><maths num="0003"><math><![CDATA[<mrow><msub><mi>L</mi><mi>r</mi></msub><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>n</mi></munderover><mo>|</mo><mo>|</mo><mi>F</mi><mrow><mo>(</mo><msub><mi>I</mi><mi>i</mi></msub><mo>;</mo><mi>W</mi><mo>)</mo></mrow><mo>-</mo><msub><mi>H</mi><mi>i</mi></msub><mo>|</mo><msup><mo>|</mo><mn>2</mn></msup></mrow>]]></math><img file="FDA0001476545460000013.TIF" wi="898" he="229" /></maths>L＝α<sub>3</sub>L<sub>r</sub>+α<sub>4</sub>L<sub>f</sub>其中n表示训练样本数,k表示训练样本中的个体数,x<sub>i</sub>表示训练样本I<sub>i</sub>的特征,c<sub>i</sub>表示I<sub>i</sub>的个体,e是自然对数,M和b表示全联接层矩阵和偏移量,M<sub>j</sub>表示矩阵M的j<sup>th</sup>列,b<sub>j</sub>表示偏移量b的j<sup>th</sup>元素,m<sub>ci</sub>表示个体c<sub>i</sub>的特征中心；α<sub>1</sub>、α<sub>2</sub>、α<sub>3</sub>、α<sub>4</sub>表示手工设定的常数；F(I<sub>i</sub>；W)表示3个额外的卷积操作中,最后的一个卷积操作输出的特征；W表示网络的参数；L<sub>s</sub>表示交叉墒损失,Lc表示中心损失,L<sub>r</sub>表示超分辨率重建损失；S3.根据联合损失函数L利用反向传播算法对残差卷积神经网络的网络参数进行优化；S4.判定计算得到的联合损失函数L是否低于所设定的阈值,若是则结束训练过程；S5.训练好残差卷积神经网络后向残差卷积神经网络输入测试样本,得到识别结果。</td>   <td>G06K9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡庆玲;              裴海军;              梁伟霞;                   吕律       </td>   <td>中山大学</td>   <td>一种为有向有序多类不平衡数据分类的样本合成方法</td>   <td>广东</td>   <td>CN107766875A</td>   <td>2018-03-06</td>   <td>本发明公开了一种为有向有序多类不平衡数据分类的样本合成方法,包括：Step1、构建初始数据集；Step2、基础训练；Step3、基础测试；Step4、计算再合成指数；Step5、构建增长训练数据集；Step6、增长训练；Step7、增长测试；Step8、错误率判断。本发明解决了医学信息等有向有序多类不平衡数据分类的序列性和方向性问题,确保增长分类模型更倾向于错误分类代价为正及代价敏感度高的分类等级,以降低分类错误造成的代价,并且,本发明的样本合成方法不需要人工设立代价的先验概率,其可以缺省自动赋予不同的代价敏感因子即类不平衡指数和错误分类代价因子,解决了人工设立代价先验概率准确性难以确保的问题。</td>   <td>一种为有向有序多类不平衡数据分类的样本合成方法,其特征在于：所述的样本合成方法包括以下步骤：Step1、构建初始数据集：从样本数据集S中,采用不放回抽样方式依次随机抽取N<sub>t</sub>个、N<sub>s</sub>个、N<sub>gs</sub>个样本,以依次生成基础训练数据集S<sub>t</sub>、基础测试数据集S<sub>s</sub>、增长测试数据集S<sub>gs</sub>,其中,所述样本数据集S中的样本总数量为N<sub>t</sub>+N<sub>s</sub>+N<sub>gs</sub>个,且所述样本数据集S中的样本均为有向有序多类不平衡数据,每一个所述样本均包含属性数据向量X和对应该属性数据向量X的正确分类等级c,该属性数据向量X是由多个属性数据组成的有序序列,该正确分类等级c为自然数；Step2、基础训练：使用所述基础训练数据集S<sub>t</sub>,训练通用分类算法uCM<sub>b</sub>,以生成基础分类模型CM<sub>b</sub>,该基础分类模型CM<sub>b</sub>表达的是所述属性数据向量X与所述正确分类等级c之间的对应关系；Step3、基础测试：将所述基础训练数据集S<sub>t</sub>和基础测试数据集S<sub>s</sub>组成原始样本集S<sub>p</sub>＝(S<sub>t</sub>,S<sub>s</sub>),并将所述原始样本集S<sub>p</sub>中每一个样本的属性数据向量X分别代入所述基础分类模型CM<sub>b</sub>,以计算出对应的分类等级,记为分类等级计算值c’；Step4、计算再合成指数：按照以下公式一、公式二和公式三,计算所述原始样本集S<sub>p</sub>中每一个样本的再合成指数β<sub>c</sub>：μ<sub>ci</sub>＝n<sub>ci</sub>/((N<sub>t</sub>+N<sub>s</sub>+N<sub>gs</sub>)÷m)##[公式一]式中,μ<sub>ci</sub>表示所述原始样本集S<sub>p</sub>中第i个样本x<sub>i</sub>的类不平衡指数,i为整数且1≤i≤N<sub>t</sub>+N<sub>s</sub>,样本x<sub>i</sub>的正确分类等级c记为c<sub>i</sub>,n<sub>c</sub>表示所述样本数据集S中正确分类等级c为c<sub>i</sub>的样本数量,m表示所述样本数据集S中的样本所划分的等级数；λ<sub>i</sub>＝c<sub>i</sub>’#c<sub>i</sub>##[公式二]式中,λ<sub>i</sub>表示所述原始样本集S<sub>p</sub>中第i个样本x<sub>i</sub>的错误分类代价因子,样本x<sub>i</sub>在所述Step3中计算出的分类等级计算值c’记为c<sub>i</sub>’；<img file="FDA0001408327560000021.TIF" wi="1675" he="517" />式中,β<sub>ci</sub>表示所述原始样本集S<sub>p</sub>中第i个样本x<sub>i</sub>的再合成指数,β<sub>ci</sub>’为中间计算值,ρ<sub>1</sub>和ρ<sub>2</sub>均为预设的分类等级权重系数,且ρ<sub>2</sub>≤ρ<sub>1</sub>；Step5、构建增长训练数据集：使所述原始样本集S<sub>p</sub>中的每一个样本均合成数量与其再合成指数β<sub>c</sub>相等的增长训练样本,并用所述原始样本集S<sub>p</sub>中的全部样本所合成的增长训练样本作为元素生成增长训练数据集S<sub>gt</sub>；其中,所述原始样本集S<sub>p</sub>中第i个样本x<sub>i</sub>合成其β<sub>ci</sub>个增长训练样本x<sub>ij</sub>的方法为：首先,按照k最近邻算法,从所述原始样本集S<sub>p</sub>的正确分类等级c等于为c<sub>i</sub>的样本中找出与所述样本x<sub>i</sub>最近邻的k个样本,k为所述k最近邻算法中的预设值,然后,在所述k个样本中随机选一个出来,记为样本x<sub>j</sub>,最后,用所述样本x<sub>i</sub>与所述样本x<sub>j</sub>合成所述β<sub>ci</sub>个增长训练样本x<sub>ij</sub>,即：所述样本x<sub>i</sub>合成的增长训练样本x<sub>ij</sub>同样包含由多个属性数据有序组成的属性数据向量X和对应该属性数据向量X的正确分类等级c,并且,所述β<sub>ci</sub>个增长训练样本x<sub>ij</sub>的正确分类等级c均取值为所述样本x<sub>i</sub>的正确分类等级c<sub>i</sub>,所述增长训练样本x<sub>ij</sub>与所述样本x<sub>i</sub>中组成它们属性数据向量X的属性数据数量和属性排序相同,且对于所述样本x<sub>i</sub>、样本x<sub>j</sub>和所述β<sub>ci</sub>个增长训练样本x<sub>ij</sub>位于同一个属性排序的属性数据来说,所述β<sub>ci</sub>个增长训练样本x<sub>ij</sub>的属性数据取值为在所述样本x<sub>i</sub>的属性数据取值与所述样本x<sub>j</sub>的属性数据取值之间的β<sub>ci</sub>个随机值；Step6、增长训练：使用所述增长训练数据集S<sub>gt</sub>,训练所述基础分类模型CM<sub>b</sub>,以生成增长分类模型CM<sub>g</sub>,该增长分类模型CM<sub>g</sub>表达的是所述属性数据向量X与所述正确分类等级c之间的对应关系；Step7、增长测试：将所述增长测试数据集S<sub>gs</sub>中每一个样本的属性数据向量X分别代入所述增长分类模型CM<sub>g</sub>,以计算出对应的分类等级,记为增长测试分类等级计算值c”,并且,将所述增长测试数据集S<sub>gs</sub>中每一个样本的正确分类等级c与其增长测试分类等级计算值c”进行对比,如果该两者相等,则将对应的样本归属于增长测试正确测试数据集S<sub>grt</sub>,否则,将对应的样本归属于增长测试错误测试数据集S<sub>ger</sub>；Step8、错误率判断：计算错误率R<sub>err</sub>＝N<sub>ger</sub>/N<sub>gs</sub>,N<sub>ger</sub>为所述增长测试错误测试数据集S<sub>ger</sub>所包含样本的数量,N<sub>gs</sub>为所述增长测试数据集S<sub>gs</sub>所包含样本的数量；如果满足R<sub>err</sub>≤Ac,Ac为预设的最大错误率,则停止学习,并认定所述增长分类模型CM<sub>g</sub>能够正确表达出所述属性数据向量X与所述正确分类等级c之间的对应关系,否则,学习次数加1,并重新进行学习,即返回所述Step1以重新执行所述Step1至Step8,直至所述学习次数的累加值达到预设的最大学习次数L<sub>max</sub>时,停止学习,并认定最后一次学习所生成的增长分类模型CM<sub>g</sub>能够正确表达出所述属性数据向量X与所述正确分类等级c之间的对应关系。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何兆成;              卢昱寰;                   陈一贤       </td>   <td>中山大学</td>   <td>基于子图划分的知识图谱降维表达方法</td>   <td>广东</td>   <td>CN107766583A</td>   <td>2018-03-06</td>   <td>本发明涉及一种基于子图划分的知识图谱降维表达方法,对知识图谱进行子图的划分；对划分的子图进行CP张量分解,得到实体编码向量和关系编码向量作为降维表达的结果输出。</td>   <td>基于子图划分的知识图谱降维表达方法,其特征在于：对知识图谱进行子图的划分；对划分的子图进行CP张量分解,得到实体编码向量和关系编码向量作为降维表达的结果输出。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘镇;              樊进;              周翠英;                   杜子纯       </td>   <td>中山大学</td>   <td>一种基于ArcGIS的地下空间适宜性评价模型</td>   <td>广东</td>   <td>CN107730426A</td>   <td>2018-02-23</td>   <td>本发明涉及地下空间评价领域,具体涉及一种基于ArcGIS的地下空间适宜性评价模型,包括如下内容：(1)将各评价指标要素添加至ArcMap中,得到所有要素的初始条件；(2)将初始条件中的各指标要素进行栅格化操作,根据特征字段计算并输出栅格数据,得到所有评价指标要素的中间栅格数据；(3)根据评价指标的类型,将相同或相近类型的要素栅格数据通过加权求和得到最终的要素指标；(4)根据不同类型的要素指标和输入的权重进行加权求和,得到最终的综合评价结果。本发明的有益效果：通过简化后的若干个评价指标全面系统地评价了地下空间的适宜性情况,与传统评价方法相比较,本发明的模型评价方法能够直观完整地显示评价过程及结果。</td>   <td>一种基于ArcGIS的地下空间适宜性评价模型,其特征在于：将各评价指标图层添加至ArcMap中,作为评价模型的初始条件,经过一系列栅格计算得到最终要素指标,输入各指标权重,运行模型得到最终的评价结果数据,并显示在ArcMap中作为地下空间适宜性评价的依据；所述的初始条件为：在ArcMap添加各评价指标,包括坡度、孔隙水埋深、浅层水富水性、软土厚度、基岩埋深、承载力、采空区、地质灾害、断层、砂土液化等要素图层,并统一坐标系及比例尺,得到包含所有要素的初始条件；所述的最终要素指标为：通过Feature#to#Raster工具将初始条件的各指标要素进行栅格化操作,根据该要素特征字段计算并输出中间栅格数据,然后根据评价指标的类型,将同类型的中间栅格数据加权求和得到最终的要素指标数据；所述的评价结果数据为：输入各指标类型所占的权重,分别与对应的最终要素指标数据进行加权求和,得到评价结果数据。根据显示在ArcMap中评价结果数据图层,对比图例颜色,可实现对地下空间的适宜性等级进行评价。</td>   <td>G06Q50/26;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              吴炆芳;              朱雄泳;              陈荣军;              谢舜道;                   刘付康       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>基于压缩感知的高动态范围图像去伪影融合方法</td>   <td>广东</td>   <td>CN107730479A</td>   <td>2018-02-23</td>   <td>本发明公开了一种基于压缩感知的高动态范围图像去伪影融合方法。首先,对输入的多曝光图像序列进行压缩采样；接着,使用重构方法进行重构得到压缩感知后的多曝光图像序列；然后归一化经过压缩感知的图像集,对图像集使用基于PatchMatch和秩最小化算法进行多曝光图像去伪影融合得到目标的高动态(high#dynamic#range,HDR)图像。本发明利用K#SVD字典学习、压缩感知和去伪影融合的最新研究成果,能够有效降低采样率、存储空间和计算复杂度,得到去除伪影和模糊的HDR图像。</td>   <td>一种基于压缩感知的高动态范围图像去伪影融合方法,其特征在于包括有如下步骤：1)对输入多曝光图像序列进行分块压缩采样；2)对压缩采样后的图像块进行LDR图像序列的重构；3)对经过压缩感知后的多曝光图像序列进行高动态范围图像的去伪影融合。</td>   <td>G06T5/50;G06T7/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              张运鸿;              孙永丞;              张承灏;                   王焕宇       </td>   <td>中山大学</td>   <td>一种基于机器学习的视频目标检测方法</td>   <td>广东</td>   <td>CN107705324A</td>   <td>2018-02-16</td>   <td>本发明公开一种基于机器学习的视频目标检测方法,包括,1)对输入的视频采用SSD目标检测算法,得到待跟踪的目标检测框,并在图像上标出bounding#box,确定跟踪的目标。2)对输入视频每一帧采用两种跟踪方法,一是光流跟踪算法,利用概率预测下一帧的跟踪点,并通过欧氏距离和所设阈值精确确定下一帧跟踪点。二是采用全卷积神经网络,提取神经网络中高层和底层的特征进行分别卷积,最后通过分类器融合成特征图,从而精确确定下一帧跟踪点。3)对光流跟踪和全卷积神经网络跟踪的结果提取HOG特征,通过支持向量机(SVM)将两个结果进行有效性判别最终确定下一帧的目标位置。</td>   <td>一种基于机器学习的视频目标检测方法,其特征在于,包括以下步骤：(1)对于待跟踪的视频,利用SSD目标检测算法得到待跟踪的目标检测框,并在图像上标出bounding#box；对于每一张标记的图片分别利用光流跟踪法和全卷积神经网络独立地进行追踪；其中光流跟踪法进行追踪的具体过程为：对于给出目标检测框的目标,均匀采集M个点作为跟踪点；根据两帧之间的光流来计算这M个点在下一帧的目标点；当目标点与当前帧中M个点所对应的点的欧氏距离小于设定的阈值则保留下来,作为跟踪点；基于所获得的下一帧中的跟踪点,计算下一帧的目标检测框的位置；全卷积神经网络独立地进行追踪的具体过程为,采用VGG16模型,13个卷积层,3个全连接层,使用主成分分析法提取其主要特征,分别提取卷积神经网络中的高层和底层特征,选出和当前跟踪目标最相关的特征图管道,分别输入到两个两层卷积的卷积网络SNet和Gnet,得到两个预测的热图,并根据是否有错误选择决定使用哪个热图生成最终的跟踪结果；(2)对于光流算法检测出的结果,和全卷积神经网络检测的结果,提取其HOG特征,通过SVM将两个结果进行有效性的判断,最终选出跟踪目标的准确位置。</td>   <td>G06T7/246;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              颜吉超;                   林谋广       </td>   <td>中山大学</td>   <td>一种基于混合先验学习模型的去雾方法</td>   <td>广东</td>   <td>CN107705262A</td>   <td>2018-02-16</td>   <td>本发明实施例公开了一种基于混合先验学习模型的去雾方法,其中,该方法包括：利用人工合成的有雾图数据集来建立透射率预测模型；输入待处理的有雾图,提取该有雾图中的混合先验信息；利用待处理的有雾图中的混合先验信息与透射率预测模型,预测待处理的有雾图的透射率值；将待处理的有雾图的透射率值代入到大气光散射模型中,获得去雾结果。实施本发明实施例,能够弥补当前去雾方法对天空区域或浓度过高雾区域失效与颜色偏差等缺陷。</td>   <td>一种基于混合先验学习模型的去雾方法,其特征在于,所述方法包括：利用人工合成的有雾图数据集来建立透射率预测模型；输入待处理的有雾图,提取该有雾图中的混合先验信息；利用待处理的有雾图中的混合先验信息与透射率预测模型,预测待处理的有雾图的透射率值；将待处理的有雾图的透射率值代入到大气光散射模型中,获得去雾结果。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孔方圆;              丁圣勇;                   朝红阳       </td>   <td>中山大学</td>   <td>一种通过神经网络实现人脸属性转换的方法</td>   <td>广东</td>   <td>CN107665339A</td>   <td>2018-02-06</td>   <td>本发明提供一种通过神经网络实现人脸属性转换的方法,该方法通过训练生成网络G#Net,其中,生成网络G#Net负责生成图像,即输入一个随机向量获得一个视觉上真实的人脸图像；训练属性判别网络E#Net,其中,属性判别网络E#Net负责判别属性,即判断当前图片是否具有限定的属性；在生成网络G#Net和属性判别网络E#Net完成训练后,把生成网络G#Net和属性判别网络E#Net串联在一起,即G#Net的输出为E#Net的输入,进行人脸属性转换操作；该方法可以快速生成效果自然的图片,解决生成结果可能是不自然人脸或者不是人脸的问题,不需要手工二次修改。</td>   <td>一种通过神经网络实现人脸属性转换的方法,其特征在于,包括以下步骤：S1：训练生成网络G#Net,其中,生成网络G#Net负责生成图像,即输入一个随机向量获得一个视觉上真实的人脸图像；S2：训练属性判别网络E#Net,其中,属性判别网络E#Net是一个二分类网络,负责判别属性,即判断当前图片是否具有限定的属性；S3：在生成网络G#Net和属性判别网络E#Net完成训练后,把生成网络G#Net和属性判别网络E#Net串联在一起,即G#Net的输出为E#Net的输入,进行人脸属性转换操作。</td>   <td>G06K9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杜婷婷;                   常会友       </td>   <td>中山大学</td>   <td>一种基于字和词两个层面特征信息的文本分类方法</td>   <td>广东</td>   <td>CN107656990A</td>   <td>2018-02-02</td>   <td>本发明公开了一种基于字和词两个层面特征信息的文本分类方法。步骤包括：利用神经网络模型进行字词向量联合预训练,得到词语的初始化词向量和汉字的初始化字向量表示；将短文本表示成其中各个词语词向量组成的矩阵,利用卷积神经网络进行特征提取,得到词语层特征；将短文本表示成其中各个汉字字向量组成的矩阵,利用卷积神经网络进行特征提取,得到汉字层特征；将词语层特征和汉字层特征进行连接,得到短文本的特征向量表示；利用全连接层对文本进行分类,采用随机梯度下降法进行模型的训练,得到分类模型。本发明能够提取字的表示和词的表示两个层面的特征,改善短文本语义信息不足的问题,充分挖掘短文本的语义信息,使短文本的分类更加准确。</td>   <td>一种基于字和词两个层面特征信息的文本分类方法,其特征在于,所述方法包括以下步骤：A、利用神经网络对字词进行联合预训练,得到词语和字的初始化向量；B、将词语的词向量连接成矩阵,同时将字向量连接成矩阵,利用卷积核对词向量连接成矩阵和字向量连接成矩阵分别进行卷积操作提取对应的局部特征；C、利用最大池化操作提取步骤B中得到的词语层面局部特征的最优值和字层面局部特征的最优值；D、将步骤C中得到的词语层面特征向量与字层面特征连接,形成短文本的特征向量表示；E、利用全连接神经网络对短文本进行分类,使用随机梯度下降算法对模型参数进行训练,得到分类模型和调整之后的字向量和词向量；F、将需要分类的新的短文本输入模型进行分类,得到分类结果。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         费行健;                   潘嵘       </td>   <td>中山大学</td>   <td>基于深度神经网络的端到端的图像多字符定位和匹配方法</td>   <td>广东</td>   <td>CN107657256A</td>   <td>2018-02-02</td>   <td>本发明涉及一种基于深度神经网络的端到端的图像多字符定位和匹配方法,其具有以下有益效果：1)方法的运行效率更高,整个方法流程在深度神经网络训练好之后,每次使用,只需要经过一次深度神经网络的前向传播计算,而不像现有方法有多个神经网络需计算多次,还有用聚类算法做字符提取等比较耗时的步骤。2)方法的准确率更高。整个方法流程就是直接优化最终目标的准确率,通过深度神经网络可以很好的做到这一点。而现有技术,最终目标的准确率依赖于各个步骤流程的准确率,由于只能分别优化各个步骤的准确率,没法直接优化最终目标,导致准确率较低,也很难改进。</td>   <td>基于深度神经网络的端到端的图像多字符定位和匹配方法,其特征在于：包括有以下步骤：S1.令查询图片与对应的被查询图片为一对图片对,收集大量的图片对作为数据集,并对图片对中查询图片中的字符在被查询图片中的位置进行标注；S2.将数据集按照一定比例划分为三部分,分别为训练集、验证集和测试集；S3.搭建深度神经网络,利用训练集中的图片对作为输入对深度神经网络进行训练,并利用Adam算法对深度神经网络进行优化；S4.使用验证集中的图片对作为输入对优化后的深度神经网络进行验证,深度神经网络输出图片对中查询图片中的字符在被查询图片中的定位及匹配结果,由于步骤S1已经对图片对中查询图片中的字符在被查询图片中的位置进行标注,因此可计算深度神经网络在验证集上的准确率；S5.重复步骤S3~S4直至深度神经网络在验证集上的准确率满足设定的条件；S6.将测试集中的图片对作为输入对步骤S5训练好的深度神经网络进行测试,并根据深度神经网络输出的测试结果对深度神经网络的在测试集上的准确率进行统计,作为对深度神经网络的评估结果；S7.对于新的一对图片对,将其作为深度神经网络的输入,即可通过深度神经网络得到图片对中查询图片中的字符在被查询图片中的定位及匹配结果。</td>   <td>G06K9/32;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              江倩殷;              邓育新;              李国鸣;                   欧炎丹       </td>   <td>中山大学</td>   <td>一种基于融合特征的视频车辆重识别方法与系统</td>   <td>广东</td>   <td>CN107622229A</td>   <td>2018-01-23</td>   <td>本发明公开了一种基于融合特征的视频车辆重识别方法与系统,方法包括：确定目标车辆与匹配范围；根据目标车辆与匹配范围采用基于颜色直方图的相似度计算方法,计算目标车辆图像与待匹配车辆图像的颜色特征相似度；根据目标车辆与匹配范围采用基于局部线性约束编码和加权空间金字塔的方向梯度直方图特征相似度计算方法,计算目标车辆图像与待匹配车辆图像的编码方向梯度直方图特征相似度；将计算的颜色特征相似度和编码方向梯度直方图特征相似度进行加权融合。本发明通过将计算的颜色特征相似度和编码方向梯度直方图特征相似度进行加权融合来得到车辆重识别的相似度结果,准确率更高,鲁棒性更强,通用性更高。本发明可广泛应用于图像处理领域。</td>   <td>一种基于融合特征的视频车辆重识别方法,其特征在于：包括以下步骤：确定目标车辆与匹配范围；根据目标车辆与匹配范围采用基于颜色直方图的相似度计算方法,计算目标车辆图像与待匹配车辆图像的颜色特征相似度；根据目标车辆与匹配范围采用基于局部线性约束编码和加权空间金字塔的方向梯度直方图特征相似度计算方法,计算目标车辆图像与待匹配车辆图像的编码方向梯度直方图特征相似度,所述加权空间金字塔的权重能根据不同车辆特征进行调整；将计算的颜色特征相似度和编码方向梯度直方图特征相似度进行加权融合,得到车辆重识别的相似度结果,所述加权融合时的权重能根据不同环境条件进行自适应调整。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘冶;              刘宇琛;              彭楠;              陈宇恒;              杨泽锋;                   印鉴       </td>   <td>广州赫炎大数据科技有限公司;中山大学</td>   <td>一种基于手机游戏商店的用户流失预测方法及系统</td>   <td>广东</td>   <td>CN107609708A</td>   <td>2018-01-19</td>   <td>本发明提供一种基于手机游戏商店的用户流失预测方法及系统,包括以下步骤：从服务器日志中采集用户的基本信息、行为信息和游戏信息,并分为训练集用户和预测集用户；对训练集用户建立流失用户标签,并对原始数据进行预处理；对训练集用户和预测集用户的基本信息、行为信息和游戏信息进行特征提取、选择及规范化；根据训练集用户的特征和流失用户标签,训练梯度提升决策树算法得到用户流失预测模型；根据预测集用户的特征,通过用户流失预测模型识别出手机游戏商店的流失用户。本发明基于手机游戏商店的业务场景,能够快速准确识别潜在流失用户,为手机游戏商店及时召回流失用户提供决策支持。</td>   <td>一种基于手机游戏商店的用户流失预测方法,其特征在于,包括以下步骤：S1：从服务器日志中采集训练集用户和预测集用户的基本信息、行为信息和游戏信息,对训练集用户建立流失用户标签,并对原始数据进行预处理；S2：对训练集用户和预测集用户的基本信息、行为信息和游戏信息进行特征提取、选择及规范化；S3：根据训练集用户的特征和流失用户标签,训练梯度提升决策树算法得到用户流失预测模型；S4：根据预测集用户的特征,通过用户流失预测模型识别出手机游戏商店的流失用户。</td>   <td>G06Q10/04;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              周勤乐;                   林谋广       </td>   <td>中山大学</td>   <td>一种基于瞳孔信息的情感精神状态检测系统及方法</td>   <td>广东</td>   <td>CN107610099A</td>   <td>2018-01-19</td>   <td>本发明实施公开了一种基于瞳孔信息的情感精神状态检测系统及方法,该系统包括：情感诱发模块,用于对测试者进行情感诱发；信息采集模块,用于采集每一帧摄像头拍摄的图像；信息处理模块,用于图像处理、计算瞳孔信息以及判断该信息是否属于中性信息；中性信息处理模块,用于整合并计算中性信息中瞳孔直径的平均值；信息反馈模块,用于转化非中性信息为测试情感信息并反馈至远程服务端,判定和诊断测试者的情感精神状态并发送给测试者。实施本发明实施例,不仅克服了光瞳孔检测中强烈的光对不同老化程度瞳孔的影响,能够有效地检测出基于瞳孔信息的情感精神状态,同时可以将这种检测方式应用到移动设备当中,在移动医疗方面具有重要意义。</td>   <td>一种基于瞳孔信息的情感精神状态检测系统,其特征在于,所述系统包括：情感诱发模块,用于对测试者进行情感诱发；信息采集模块,用于采集每一帧摄像头拍摄的图像；信息处理模块,用于进行每一帧图像的图像处理、瞳孔信息的计算以及该信息是否属于中性信息的判断；中性信息处理模块,用于整合并计算中性信息的瞳孔直径信息,获得其平均值以作为中性瞳孔直径参考值,其范围作为中性瞳孔直径阈值；信息反馈模块,用于将所有瞳孔信息转化为测试情感信息并反馈至远端服务器,判定和诊断测试者的情感精神状态并将其结果发送至测试者。</td>   <td>G06T7/00;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              彭林;              曾衍瀚;              陈翔;              廖裕兴;              张浩;              张鑫;              陈荣军;                   路崇       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;佛山市顺德区中山大学研究院;中山大学</td>   <td>基于二进制散列的ALOHA防碰撞方法</td>   <td>广东</td>   <td>CN107590408A</td>   <td>2018-01-16</td>   <td>本发明提供的基于二进制散列的ALOHA防碰撞方法通过引入二进制散列处理来对发生碰撞的标签进行时分处理,整个方法过程中无需频繁地下发QueryAdjust或者QueryRep指令来进行重置,因此其识别效率与现有技术相比得到了提高。</td>   <td>基于二进制散列的ALOHA防碰撞方法,其特征在于：包括有以下步骤：(1)阅读器向发送Query(Q)指令,开始一个清点周期,其中Q为时隙计数器参数值,每个标签在[0,2<sup>Q</sup>#1]间随机产生一个整数SC并载入自身的时隙计数器中；(2)整数SC为0的标签立刻响应,并反向反射一个随机数RN16给阅读器；(3)阅读器检测是否有碰撞发生：a.若当前时隙没有标签响应,即为空闲时隙,令Q<sub>fp</sub>＝Q<sub>fp</sub>#C,Q<sub>fp</sub>为Q的浮点形式,C的取值区间为0.1&lt;C&lt;0.5；b.若只有一个标签响应,即为有效时隙,令Q<sub>fp</sub>保持不变,阅读器向响应的标签发送ACK(RN16)指令,响应的标签收到正确的ACK指令,立即转换到应答状态,并将EPC码回送给阅读器,成功识别标签；c.若存在两个或两个以上的标签响应,即为碰撞时隙,此时判断响应的标签的数量是否大于碰撞处理门限,若是则令Q<sub>fp</sub>＝Q<sub>fp</sub>+C,然后进入步骤(4),若否则令Q<sub>fp</sub>＝Q<sub>fp</sub>+C,然后进行二进制散列处理：c1.将响应的标签的整数SC随机置0或置1,其余未响应的标签的整数SC加1；c2.进行二进制散列处理后,若整数SC为0的标签数还大于或等于2,即执行步骤c1；若进行二进制散列处理后整数SC为0的标签数为1,此时执行步骤b；(4)当前时隙识别结束后,阅读器对Q<sub>fp</sub>四舍五入取整得到整数Q’,若整数Q’与整数Q相比其值发生了变化,阅读器发送QueryAdjust指令更新Q值,并重置所有标签的整数SC值；否则发送QueryRep指令使标签的整数SC值自减,继续识别后续标签,进入步骤(2)。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              范蕾;              张朝强;                   黎丹       </td>   <td>中山大学</td>   <td>平面监督的图像色彩深度信息协同修复的方法</td>   <td>广东</td>   <td>CN107578389A</td>   <td>2018-01-12</td>   <td>本发明涉及图像的技术领域,更具体地,涉及平面监督的图像色彩深度信息协同修复的方法。在具体实现过程中,该算法主要通过基于样本的图像修复算法对色彩图像修复的同时为深度修复提供线索,然后对初步修复完善的色彩图像使用超像素分割方法进行分割。同时将斜平面平滑方法运用到深度图修复过程中,使用平面拟合方法得到的平面方程估算视差值。以阻塞面或者铰面为分割边界的分割块以及平面拟合过程中得到的局外点将会在下一次迭代过程中重新计算。修复完善的深度图对色彩图像重新修复给予反馈。最后不断迭代以上步骤优化得到最佳的色彩图像及深度图像的修复结果,从而达到对色彩深度信息的协同修复。</td>   <td>平面监督的图像色彩深度信息协同修复的方法,其特征在于,包括色彩图像修复模块、图像分割模块、深度图修复模块和色彩图像在深度图指导下重新修复模块四大部分；色彩图像修复模块：使用基于样本的图像修复方法从色彩图像中未受损区域得到的色彩信息填充到受损区域中,得到视觉上合理的修复结果；图像分割块模块：对于色彩图像修复模块得到的色彩图像使用简单的线性迭代聚类算法进行超像素分割,得到分割区域；深度图修复模块：对于图像分割块模块得到的每一个分割区域,使用随机抽样一致算法拟合出一平面方程；使用该平面方程估算出丢失的视差值；同时将分割区域之间的边界进行分类处理；以阻塞面或者铰面为分割边界的分割区域以及平面拟合过程中得到的局外点将会在下一次迭代过程中重新计算；色彩图像在深度图指导下重新修复模块：对于从深度图修复模块中反馈得到的重新需要修复区域,从未受损区域获取色彩信息所依据的相似性需要将平面间的差异性考虑在内。</td>   <td>G06T5/00;G06T7/11;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;                   李国鸣       </td>   <td>中山大学</td>   <td>一种基于时空分类的动态背景差分检测方法、系统及装置</td>   <td>广东</td>   <td>CN107578424A</td>   <td>2018-01-12</td>   <td>本发明公开了一种基于时空分类的动态背景差分检测方法、系统及装置,方法包括：在时间序列上通过分组采样对图像中的每个像素建立对应的背景模型,并根据待检测像素对背景模型内的像素进行分类,得到粗糙的前景掩模图像；以粗糙的前景掩模图像中的前景像素点为中心,将中心像素点设定邻域范围内的像素点进行分类,并根据设定邻域范围内与中心像素点同类的像素点中属于背景像素点的数目,将中心像素点修正为背景像素点或继续保持为前景像素点。本发明采用了分组采样的方法,增强了对动态背景描述的能力；只采用了与中心像素点同类的像素点来确定前景像素点是否为真实的前景像素点,有利于提高检测的正确率。本发明可广泛应用于运动目标检测领域。</td>   <td>一种基于时空分类的动态背景差分检测方法,其特征在于：包括以下步骤：在时间序列上通过分组采样对图像中的每个像素建立对应的背景模型,并根据待检测像素对背景模型内的像素进行分类,得到粗糙的前景掩模图像；以粗糙的前景掩模图像中的前景像素点为中心,将中心像素点设定邻域范围内的像素点进行分类,并根据设定邻域范围内与中心像素点同类的像素点中属于背景像素点的数目,将中心像素点修正为背景像素点或继续保持为前景像素点,从而得到准确的前景掩模图像。</td>   <td>G06T7/215;G06T7/246;G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>              周世平       </td>   <td>中山大学</td>   <td>一种智能景区旅游服务公平性游客评价控制系统</td>   <td>广东</td>   <td>CN107578258A</td>   <td>2018-01-12</td>   <td>本发明属于旅游服务评价领域,公开了一种智能景区旅游服务公平性游客评价控制系统。该智能景区旅游服务公平性游客评价控制系统包括云端、无线网络、移动终端。其中,移动终端包括监测模块、更新模块、数据处理模块、统计模块和无线通信模块。本发明运用云端的方式可以保护用户数据的安全并且节约成本,为我们的生活带来了极大的便利。并且该系统评价功能较全,展示信息较为丰富,服务人员也可以用移动终端登陆云端,及时查看评价信息,了解自己的不足之处,使消费者权益得到及时的保障。</td>   <td>一种智能景区旅游服务公平性游客评价控制系统,其特征在于,所述智能景区旅游服务公平性游客评价控制系统包括包括：云端、无线网络、移动终端；移动终端通过无线网络与云端通过蓝牙或WIFI进行无线通信；所述无线网络的转发节点组的选择方法包括：节点h发送数据包给目的节点,h+i是节点h的一个邻居节点,如果其靠近最远邻居节点并且有更多的剩余能量,则邻居节点h+i可作为候选转发节点；对这些合适的候选节点依据到能量等效节点的距离和每个节点的剩余能量排序：<maths num="0001"><math><![CDATA[<mrow><mi>P</mi><mrow><mo>(</mo><mi>h</mi><mo>+</mo><mi>i</mi><mo>)</mo></mrow><mo> =</mo><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><mfrac><msub><mi>E</mi><mrow><mi>h</mi><mo>+</mo><mi>i</mi></mrow></msub><msup><mrow><mo>|</mo><mrow><msub><mi>d</mi><mrow><mi>h</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>-</mo><mi>R</mi><mo>+</mo><mn>1</mn></mrow><mo>|</mo></mrow><mn>2</mn></msup></mfrac><mo>*</mo><msup><mrow><mo>(</mo><msub><mi>d</mi><mrow><mi>h</mi><mo>+</mo><mi>i</mi></mrow></msub><mo>-</mo><msub><mi>d</mi><mi>h</mi></msub><mo>)</mo></mrow><mn>2</mn></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo>(</mo><mi>h</mi><mo>+</mo><mi>i</mi><mo>)</mo><mo>&Element;</mo><mi>N</mi><mo>(</mo><mi>h</mi><mo>)</mo><mo>,</mo><mo>-</mo><mi>R</mi><mo>&le;</mo><mi>i</mi><mo>&le;</mo><mi>R</mi></mrow></mtd></mtr></mtable></mfenced><mo>;</mo></mrow>]]></math><img file="FDA0001409694300000011.TIF" wi="590" he="167" /></maths>d<sub>h+i</sub>#d<sub>h</sub>为节点h和其邻居节点h+i之间的距离；E<sub>h+i</sub>代表节点h+i的剩余能量；N(h)为选出的节点h的候选转发节点；P(h+i)的值越大,节点优先级越高；最高优先级的候选转发节点作为下一个转发节点；所述移动终端的时频重叠信号的归一化高阶累积量方程组构建方法包括：接收信号的信号模型表示为：r(t)＝x<sub>1</sub>(t)+x<sub>2</sub>(t)+…+x<sub>n</sub>(t)+v(t)<maths num="0002"><math><![CDATA[<mrow><msub><mi>x</mi><mi>i</mi></msub><mo> =</mo><munder><mi>&Sigma;</mi><mi>k</mi></munder><msub><mi>A</mi><mrow><mi>k</mi><mi>i</mi></mrow></msub><mi>c</mi><mi>o</mi><mi>s</mi><mrow><mo>(</mo><mn>2</mn><msub><mi>&pi;f</mi><mi>c</mi></msub><mi>t</mi><mo>+</mo><msub><mi>&theta;</mi><mrow><mi>k</mi><mi>i</mi></mrow></msub><mo>)</mo></mrow><mo>&CenterDot;</mo><mi>g</mi><mrow><mo>(</mo><mi>t</mi><mo>-</mo><msub><mi>kT</mi><mrow><mi>s</mi><mi>i</mi></mrow></msub><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001409694300000012.TIF" wi="774" he="103" /></maths>其中,x<sub>i</sub>(t)为时频重叠信号的各个信号分量,各分量信号独立不相关,n为时频重叠信号分量的个数,θ<sub>ki</sub>表示对各个信号分量载波相位的调制,f<sub>ci</sub>为载波频率,A<sub>ki</sub>为第i个信号在k时刻的幅度,T<sub>si</sub>为码元长度,p<sub>i</sub>(t)为滚降系数为α的升余弦成形滤波函数,且<img file="FDA0001409694300000013.TIF" wi="659" he="135" />n(t)是均值为0,方差为σ<sup>2</sup>的平稳高斯白噪声；混合信号的高阶累积量公式如下：<maths num="0003"><math><![CDATA[<mrow><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><mi>r</mi></mrow></msub><mo> =</mo><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></msub><mo>+</mo><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></msub><mo>+</mo><mo>...</mo><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></msub><mo>+</mo><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><mi>v</mi></mrow></msub><mo>;</mo></mrow>]]></math><img file="FDA0001409694300000014.TIF" wi="678" he="63" /></maths>两边同时除以混合信号的二阶矩k/2次方：<maths num="0004"><math><![CDATA[<mrow><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><mi>r</mi></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo> =</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>+</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>+</mo><mn>...</mn><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>+</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><mi>v</mi></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>;</mo></mrow>]]></math><img file="FDA0001409694300000021.TIF" wi="1110" he="143" /></maths>进一步变形为：<maths num="0005"><math><![CDATA[<mrow><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><mi>r</mi></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo> =</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><mfrac><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>+</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><mfrac><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>+</mo><mo>...</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mi>n</mi></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><mfrac><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mi>n</mi></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>+</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><mi>v</mi></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>v</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><mfrac><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>v</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac></mrow>]]></math><img file="FDA0001409694300000022.TIF" wi="1758" he="143" /></maths>其中<img file="FDA0001409694300000023.TIF" wi="106" he="127" />和<img file="FDA0001409694300000024.TIF" wi="94" he="127" />表示各分量信号功率与总功率的比值和噪声功率与总功率的比值,分别表示为<img file="FDA0001409694300000025.TIF" wi="51" he="64" />和λ<sub>v</sub>；由于高斯白噪声的高阶累积量为0,所以上式可以表示为：<maths num="0006"><math><![CDATA[<mrow><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><mi>r</mi></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo> =</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><msup><msub><mi>&lambda;</mi><msub><mi>x</mi><mn>1</mn></msub></msub><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup><mo>+</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><msup><msub><mi>&lambda;</mi><msub><mi>x</mi><mn>2</mn></msub></msub><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup><mo>+</mo><mo>...</mo><mfrac><msub><mi>C</mi><mrow><mi>k</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mi>n</mi></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><msup><msub><mi>&lambda;</mi><msub><mi>x</mi><mi>n</mi></msub></msub><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup><mo>;</mo></mrow>]]></math><img file="FDA0001409694300000026.TIF" wi="1319" he="143" /></maths>由此,构建归一化高阶累积量方程组：<maths num="0007"><math><![CDATA[<mrow><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><mfrac><msub><mi>C</mi><mrow><mn>4</mn><mo>,</mo><mi>r</mi></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><mi>r</mi><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mn>2</mn></msup></mfrac><mo> =</mo><mfrac><msub><mi>C</mi><mrow><mn>4</mn><mo>,</mo><msub><mi>x</mi><mn>1</mn></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mn>2</mn></msup></mfrac><mo>&CenterDot;</mo><msup><msub><mi>&lambda;</mi><msub><mi>x</mi><mn>1</mn></msub></msub><mn>2</mn></msup><mo>+</mo><mfrac><msub><mi>C</mi><mrow><mn>4</mn><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mn>2</mn></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><msup><msub><mi>&lambda;</mi><msub><mi>x</mi><mn>2</mn></msub></msub><mn>2</mn></msup><mo>+</mo><mn>...</mn><mfrac><msub><mi>C</mi><mrow><mn>4</mn><mo>,</mo><msub><mi>x</mi><mi>N</mi></msub></mrow></msub><msup><mrow><mo>(</mo><msub><mi>m</mi><mrow><msub><mi>x</mi><mi>N</mi></msub><mo>,</mo><mn>2</mn></mrow></msub><mo>)</mo></mrow><mrow><mi>k</mi><mo>/</mo><mn>2</mn></mrow></msup></mfrac><mo>&CenterDot;</mo><msup><msub><mi>&lambda;</mi><msub><mi>x</mi><mi>N</mi></msub></msub><mn>2</mn></msup></mrow></mtd>...</td>   <td>G06Q30/00;G06Q10/06;G06Q50/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              王州霞;              李冠彬;              陈添水;                   成慧       </td>   <td>中山大学</td>   <td>一种循环发现关注区域识别多标签图像的方法</td>   <td>广东</td>   <td>CN107577983A</td>   <td>2018-01-12</td>   <td>本发明提供一种循环发现关注区域识别多标签图像的方法,本方法提出的多标签图像识别框架,不仅与候选区域无关,而且可以自动地在图像中发现语义相关的尺度不同的区域,并同时获取这些区域间的上下文依赖；对于空间变换网络,我们还提出了三个约束。它们不仅有助于定位更具语义信息的区域,而且可以进一步提高多标签图像识别的精确度；该发明不仅有效地提高了多标签图像的识别精确度,而且在很大程度上提高了识别的效率。</td>   <td>一种循环发现关注区域识别多标签图像的方法,其特征在于,包括以下步骤：S1：采用一个卷积神经网络提取样本的特征表达；S2：利用上一时刻预测的变换矩阵通过空间变换网络在步骤S1获取的特征图中截取受关注的区域；S3：将关注区域输入长短时记忆单元,该单元根据输入信息及上一时刻的隐藏状态和记忆状态生成当前时刻的隐藏状态和记忆状态；S4：根据当前时刻的隐藏状态预测该关注区域的分类分数向量,并预测下一时刻空间变换网络所需的变换矩阵；S5：循环执行步骤S2#S4,直到第K次,融合2至K时刻预测的分数向量,得到该图像最终的分类结果。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              樊进;              刘镇;                   杜子纯       </td>   <td>中山大学</td>   <td>一种基于Jsoup的网页新闻列表的抓取及保存方法</td>   <td>广东</td>   <td>CN107562936A</td>   <td>2018-01-09</td>   <td>本发明涉及一种基于Jsoup的网页新闻列表的抓取及保存方法,包括：建立保存新闻列表的txt文档,设置写入txt中的新闻列表的编码方式；写入待抓取的新闻列表网页的URL地址；用Jsoup解析器将网页的HTML语言格式解析成能被后台直接处理的文本格式；将解析后的文本格式数据封装成对象或数组类型,通过遍历生成流文件；将流文件导出至txt中,实现网页新闻列表的抓取及保存。本发明的有益效果：直接在本地创建txt文档保存抓取内容,避免了安装及创建数据库的麻烦,大大减小了程序的运行负担与操作难度,节约了时间；使用Jsoup解析器,采用内置的选择器方法,能够更加简单直观地抓取新闻的标题、链接及发布时间等内容。</td>   <td>基于Jsoup的网页新闻列表的抓取及保存方法,其特征在于：在本地服务器中建立txt空文档,在Java程序中给txt文档构造一个文件对象(FileWriter),并设置写入内容的编码格式；使用Jsoup解析器解析新闻列表页面URL的Html,创建Document对象获取解析后的文本内容；对Document对象进一步解析,采用select的方法,包括table、div等,实现对指定元素的过滤,返回Elements对象,继续使用select方法或getElementsByClass/Tag方式将对象中的各元素节点的数据进行细化识别,区分标题内容、链接地址及发布时间；定义若干字符串分别获取Elements对象中的标题内容、链接地址及发布时间,并使用流文件写入的方式将其内容以一定顺序保存到txt中,同时利用for循环导出列表中所有的标题内容、链接地址及发布时间；程序运行完成后清除缓存,并关闭文件流,实现整个新闻抓取过程。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              晏斌;                   丁颜玉       </td>   <td>广州智慧城市发展研究院;中山大学</td>   <td>一种基于区块链积分服务平台的个性化推荐方法及系统</td>   <td>广东</td>   <td>CN107563833A</td>   <td>2018-01-09</td>   <td>本发明公开了一种基于区块链积分服务平台的个性化推荐方法及系统,其中,所述个性化推荐方法包括：对用户购买的商品数据进行预处理,获取预处理结果；根据预处理结果构建商品用户倒排序和用户商品关联表；根据商品用户倒排序进行用户相似度计算处理,获取用户相似度矩阵；根据用户商品关联表进行特征向量提取处理,获取用户商品特征向量信息；根据用户相似度矩阵和用户商品特征向量信息对目标用户的用户商品特征向量信息进行修正,获取修正后的目标用户的用户商品特征向量信息根据修正后的目标用户的用户商品特征向量信息向目标用户进行商品推送。在本发明实施例中,通过本发明实施例有效地利用区块链技术带来的数据优势实现更精确的个性推荐。</td>   <td>一种基于区块链积分服务平台的个性化推荐方法,其特征在于,所述个性化推荐方法包括：对用户购买的商品数据进行预处理,获取预处理结果；根据所述预处理结果构建商品用户倒排序和用户商品关联表；根据所述商品用户倒排序进行用户相似度计算处理,获取用户相似度矩阵；根据所述用户商品关联表进行特征向量提取处理,获取用户商品特征向量信息；根据所述用户相似度矩阵和所述用户商品特征向量信息对目标用户的用户商品特征向量信息进行修正,获取修正后的目标用户的用户商品特征向量信息；根据所述修正后的目标用户的用户商品特征向量信息向目标用户进行商品推送。</td>   <td>G06Q30/06;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏方晨;                   许银亮       </td>   <td>佛山市顺德区中山大学研究院;中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>基于机器学习模型的短期和中长期电力负荷预测方法</td>   <td>广东</td>   <td>CN107563539A</td>   <td>2018-01-09</td>   <td>本发明公开了一种基于机器学习模型的短期和中长期电力负荷预测方法。首先对数据进行预处理,即平滑异常数据和填补缺失数据,分析影响负荷变化的因素,包括历史数据、时间周期性、天气变量特征。为了加快学习速度和提高预测精度对所有输入变量进行归化。本发明比较了线性回归、支持向量回归和梯度提升回归在短期和中长期电力负荷预测中的表现。随着预测时间的延长,梯度提升回归模型的性能优于其他两种模型的性能。本发明提出了一种将梯度提升回归树作为基分类器的AdaBoost算法,进行负荷预测,有效提高了电力负荷预测的精度。</td>   <td>基于机器学习模型的短期和中长期电力负荷预测方法,其特征在于,包括以下步骤：S1：输入电力负荷的历史数据并进行预处理,预处理包括对异常数据的平滑处理和对缺失值的填充；S2：分析影响电力负荷变化的因素,包括：分析时间和天气对电力负荷的影响；S3：输入负荷预测模型并对负荷预测模型的变量进行离差标准化,将数据映射到[0,1]区间；S4：在负荷预测分析中,运用线性回归、支持向量回归和梯度提升回归构建预测模型；S5：将梯度提升回归树作为基分类器,采用AdaBoost迭代算法预测未来的电力负荷。</td>   <td>G06Q10/04;G06Q50/06;G06K9/62;G06F17/18;G06F17/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              蓝子钦;              王海波;                   张智伟       </td>   <td>中山大学</td>   <td>一种大区域网络三维噪声地图的快速渲染方法</td>   <td>广东</td>   <td>CN107564098A</td>   <td>2018-01-09</td>   <td>本发明提出一种大区域网络三维噪声地图的快速渲染方法。按TMS的分割规则将大区域的地图分割成多个小区域地图,并将大区域的基础数据按照地理位置存储到小区域所对应的数据块单元中。在渲染前,使用瓦片地图服务功能,根据地图浏览范围加载相应瓦片区域的基础数据。在渲染时,根据不同的噪声值大小,为各个噪声接收点赋予颜色值,并使用插值的方法对矩形网格内部的颜色进行填充,按照同样渲染绘制方式绘制同一表面的其他网格。该法使用的以地图瓦片形式存储基础数据的方式有利于数据的快速读取和查询。该法使用的按需加载地图瓦片基础数据的方法能减少渲染绘制在同一时间内的数据量和工作量,能快速、流畅地渲染绘制网络三维噪声地图。</td>   <td>一种大区域网络三维噪声地图的快速渲染方法,其特征在于,所述方法包括以下步骤：a、以地图瓦片的形式存储大区域的基础数据；b、根据当前地图浏览范围加载相应区域的基础数据；c、根据噪声接收点的噪声值使用插值的方法对矩形网格内部的颜色进行填充,以此渲染绘制网络三维噪声地图。</td>   <td>G06T17/05;G06T19/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐晓颖;                   杨浦城       </td>   <td>佛山市顺德区中山大学研究院;中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于LDDMM曲线匹配的人脸情感识别方法</td>   <td>广东</td>   <td>CN107563292A</td>   <td>2018-01-09</td>   <td>本发明提供的方法利用LDDMM曲线匹配所具有的能够反映物体几何形变的特点来对人脸的表情实行精确的识别,因而能够实现精确的情感识别。同时,本发明提供的方法在进行LDDMM曲线匹配时,是分别通过被识别样本的中性表情轮廓的曲线与被识别样本的有特征表情轮廓的曲线、被识别样本的有特征表情轮廓的曲线与每种类型表情的平均有特征表情轮廓G的曲线进行匹配的,然后利用两种匹配所产生的微分同胚映射来进行特征的提取。两种特征的提取及融合使得本发明提供的方法能够充分挖掘被识别样本、识别样本之间的联系并用于后续的识别,因此,本发明提供的方法能够实现对情感的精确识别。</td>   <td>一种基于LDDMM曲线匹配的人脸情感识别方法,其特征在于：包括以下步骤：S1.构建识别样本集：为每个样本构建图像序列,所述图像序列包括了由中性表情变化到有特征表情的多帧图像；S2.对图像序列中的每帧图像进行特征点的提取,然后将每帧图像提取的特征点根据其所在的脸部区域进行划分,将划分的各个脸部区域内的特征点连接起来,得到一条曲线；所述每帧图像的表情轮廓通过所有脸部区域的曲线进行表征；S3.对于所有的图像序列中的中性表情轮廓,将其标记为N<sub>i</sub>,i＝1,2,…,n,i表示图像序列的序号；以N<sub>1</sub>作为参考,对其他所有的中性表情轮廓进行普氏变换,得到变换后的中性表情轮廓N<sub>j</sub>′,j＝2,…,n；S4.将N<sub>1</sub>和N<sub>2</sub>′、N<sub>3</sub>′、…、N<sub>n</sub>′进行求平均处理,得到识别样本集的平均中性表情轮廓M；S5.对于所有的图像序列中的中性表情轮廓和有特征表情轮廓,以平均中性表情轮廓M进行普氏变换,完成预处理；S6.对于每种类型表情的所有图像序列中的有特征表情轮廓进行求平均处理,得到该类型表情的平均有特征表情轮廓G；S7.对于被识别样本的图像序列,通过步骤S2的方法得到表征其每帧图像的表情轮廓的曲线；然后将被识别样本的中性表情轮廓和有特征表情轮廓以平均中性表情轮廓M进行普氏变换,完成预处理；S8.将被识别样本的中性表情轮廓的曲线分别与被识别样本的有特征表情轮廓的曲线进行LDDMM曲线匹配,得到一个微分同胚映射<img file="FDA0001368935280000011.TIF" wi="73" he="62" />q表示表情轮廓的曲线号；S9.将被识别样本的有特征表情轮廓的曲线分别与每种类型表情的平均有特征表情轮廓G的曲线进行LDDMM曲线匹配,得到一个微分同胚映射<img file="FDA0001368935280000014.TIF" wi="97" he="51" />k表示表情的类别号；S10.分别从<img file="FDA0001368935280000012.TIF" wi="185" he="63" />中进行特征的提取；S11.使用线性组合的方法对分别从<img file="FDA0001368935280000013.TIF" wi="185" he="63" />中提取的特征进行融合；S12.使用SVM分类器进行学习识别,输出被识别样本所属的表情类型,进而实现情感识别。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡庆玲;              邓少风;              吕律;                   李海良       </td>   <td>中山大学</td>   <td>基于SFp#Link的半结构化数据频繁模式挖掘方法</td>   <td>广东</td>   <td>CN107562800A</td>   <td>2018-01-09</td>   <td>本发明公开了一种基于SFp#Link的半结构化数据频繁模式挖掘方法,其为半结构化数据建立半结构化数据频繁模式链表SFp#Link,并基于该半结构化数据频繁模式链表SFp#Link进行频繁模式挖掘,能够按挖掘目的有效的提取出半结构化数据中的频繁项集。由于本发明在建立半结构化数据频繁模式链表SFp#Link时,仅需对被挖掘样本数据库进行一次扫描,且仅需对所包含项目组合首次被扫描到的样本项集进行存储,对于所包含项目组合再次被扫描到的样本项集,仅需对相应的样本频数累计一次即可,因此,本发明具有所需消耗的存储空间小、所需消耗的挖掘时间短、挖掘效率高的优点。</td>   <td>一种基于SFp#Link的半结构化数据频繁模式挖掘方法,其特征在于：所述的半结构化数据频繁模式挖掘方法包括：步骤一、对被挖掘样本数据库进行数据预处理,即：提取所述被挖掘样本数据库中每一条半结构化数据的样本项集,该样本项集为相应半结构化数据中与挖掘目的相关的有效数据的集合,该样本项集所包含的每一个有效数据为该样本项集的一个项目；步骤二、扫描所述被挖掘样本数据库的全部样本项集,在扫描过程中,对所包含项目组合首次被扫描到的样本项集进行存储,并记为被存储样本项集,并且,计算每一个所述被存储样本项集在所述被挖掘样本数据库中的相同样本项集数量,以及计算每一个所述被存储样本项集在所述被挖掘样本数据库中的真子集数量,以建立下述半结构化数据频繁模式链表SFp#Link：所述半结构化数据频繁模式链表SFp#Link由项集链表头qSetHead和m个等级的项集链表组成：所述项集链表头qSetHead为由m个指针组成的指针数组,该指针数组中的第i个指针为等级为i的项集链表qSetLink<sub>i</sub>的头指针,其中,i为整数且1≤i≤m,m为所述被挖掘样本数据库的全部样本项集的长度中的最大值,所述样本项集的长度即为所述样本项集所包含项目的数量；等级为i的所述项集链表qSetLink<sub>i</sub>由N<sub>i</sub>个项集链表结点SpcNode组成,其中,i为整数且1≤i≤m,N<sub>i</sub>为所述被挖掘样本数据库中长度为i的所述样本项集的数量；等级为i的所述项集链表qSetLink<sub>i</sub>的第j个所述项集链表结点SpcNode由样本项集地址qSet<sub>ij</sub>、样本频数sCnt<sub>ij</sub>、支持频数tCnt<sub>ij</sub>和链表指针link<sub>ij</sub>组成,其中,i为整数且1≤i≤m,j为整数且1≤j≤N<sub>i</sub>；所述样本项集地址qSet<sub>ij</sub>为与被扫描样本项集相同的所述被存储样本项集的存储地址,其中,所述被扫描样本项集为：在对所述被挖掘样本数据库的扫描过程中,第j个被扫描到的长度为i的样本项集；所述样本频数sCnt<sub>ij</sub>为：在所述被挖掘样本数据库的全部样本项集中,与存储在所述样本项集地址qSet<sub>ij</sub>的被存储样本项集相同的样本项集的数量；所述支持频数tCnt<sub>ij</sub>为：在所述被挖掘样本数据库的全部样本项集中,作为存储在所述样本项集地址qSet<sub>ij</sub>的被存储样本项集的真子集的样本项集的数量；所述链表指针link<sub>ij</sub>为指向等级为i的所述项集链表qSetLink<sub>i</sub>的第j+1个所述项集链表结点SpcNode的指针,其中,当j＝N<sub>i</sub>时,所述链表指针link<sub>ij</sub>为null；步骤三、基于所述半结构化数据频繁模式链表SFp#Link对所述被挖掘样本数据库中的半结构化数据进行频繁模式挖掘,即：按所述挖掘目的需要设置支持频数阈值s<sub>min</sub>,并由高等级向低等级逐条扫描所述m个等级的项集链表,以提取出支持频数tCnt<sub>ij</sub>在所述支持频数阈值s<sub>min</sub>以上的被存储样本项集,这些被提取出来的被存储样本项集即为频繁项集。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              周检根;              王金鹏;                   吴明华       </td>   <td>广州智慧城市发展研究院;中山大学</td>   <td>一种基于复杂环境下的人脸识别方法及系统</td>   <td>广东</td>   <td>CN107563328A</td>   <td>2018-01-09</td>   <td>本发明公开了一种基于复杂环境下的人脸识别方法及系统,其中,所述人脸识别方法包括：对待识别人脸图像进行预处理,获取预处理后的待识别人脸图像；对预处理后的待识别人脸图像进行人脸对齐处理,获取人脸对齐后的待识别正面人脸图像；对所述人脸对齐后的待识别正面人脸图像进行卷积神经网络训练处理,获取训练后的待识别样本特征集合；采用留存样本特征集合对所述待识别样本特征集合进行特征识别处理,获取待识别人脸图像的识别结果。在本发明实施例中,本发明实施例针对训练样本较少,而且待测图像在复杂环境条件下,依然能够实现准确识别,对硬件要求不高,满足实时性要求,推广经济可行。</td>   <td>一种基于复杂环境下的人脸识别方法,其特征在于,所述人脸识别方法包括：对待识别人脸图像进行预处理,获取预处理后的待识别人脸图像；对预处理后的待识别人脸图像进行人脸对齐处理,获取人脸对齐后的待识别正面人脸图像；对所述人脸对齐后的待识别正面人脸图像进行卷积神经网络训练处理,获取训练后的待识别样本特征集合；采用留存样本特征集合对所述待识别样本特征集合进行特征识别处理,获取待识别人脸图像的识别结果。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨红杰;              周凡;                   王若梅       </td>   <td>中山大学</td>   <td>一种基于运动特征的三维动态网格简化方法及其系统</td>   <td>广东</td>   <td>CN107527384A</td>   <td>2017-12-29</td>   <td>本发明实施例公开了一种基于运动特征的三维动态网格简化方法及其系统,其中,该方法包括：获取简化处理所需的相关输入参数；进行三维模型中顶点的动态连通性的计算,得到三维动态模型上的运动特征；进行动态模型中各条边的折叠代价的计算,建立边折叠操作表；根据边折叠操作表选取折叠代价最小的一条边进行折叠操作,重复进行折叠操作,直到达到简化要求。实施本发明实施例,由于考虑了原始模型的运动特征,不仅可以有效地简化三维动态模型,同时也降低了在简化过程中的计算复杂度,有助于提高三维动态网格数据的传输效率,节省数据存储空间,对于三维模型的存储、传输、处理和形状分析等应用,特别是实时绘制具有极为重要的意义。</td>   <td>一种基于运动特征的三维动态网格简化方法,其特征在于,所述方法包括：获取简化处理所需的相关输入参数；进行三维模型中顶点的动态连通性的计算,得到三维动态模型上的运动特征；进行动态模型中各条边的折叠代价的计算,建立边折叠操作表；根据边折叠操作表选取折叠代价最小的一条边进行折叠操作,重复进行折叠操作,直到达到简化要求。</td>   <td>G06T17/20;G06T7/246</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              彭林;              曾衍瀚;              廖裕兴;              张浩;              张鑫;              陈翔;              陈荣军;                   路崇       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;佛山市顺德区中山大学研究院;中山大学</td>   <td>基于时隙预测的ALOHA防碰撞方法</td>   <td>广东</td>   <td>CN107506674A</td>   <td>2017-12-22</td>   <td>本发明公开一种基于时隙预测的ALOHA防碰撞方法。本发明提供的防碰撞方法通过对下一个时隙进行预测,并根据预测的结果来对标签的SC值进行调整,从而加速识别进程,因此本发明提供的方法能够有效提高RFID系统的识别效率。</td>   <td>一种基于时隙预测的ALOHA防碰撞方法,其特征在于：包括有以下步骤：(1)阅读器向识别范围内的标签发送Query(Q)指令,开始一个清点周期,其中整数Q为时隙计数器参数值,每个标签在[0,2<sup>Q</sup>#1]间随机产生一个整数SC并载入自身的时隙计数器中；(2)整数SC为0的标签立刻响应,并反向反射一个16位的随机数RN16给阅读器；而整数SC为1的标签回传其随机数RN16的首位数据给阅读器；(3)阅读器检测是否有碰撞发生：a.若当前时隙没有标签响应,即为空闲时隙,令Q<sub>fp</sub>＝Q<sub>fp</sub>#C,Q<sub>fp</sub>为Q的浮点形式,C的取值区间为0.1&lt;C&lt;0.5；b.若只有一个标签响应,即为有效时隙,令Q<sub>fp</sub>保持不变,阅读器向响应的标签发送ACK(RN16)指令,响应的标签收到正确的ACK指令,立即转换到应答状态,并将EPC码回送给阅读器,成功识别标签；c.若存在两个或两个以上的标签响应,即为碰撞时隙,此时令Q<sub>fp</sub>＝Q<sub>fp</sub>+C；(4)当前时隙识别结束后,阅读器对Q<sub>fp</sub>四舍五入取整得到整数Q’,若整数Q’与整数Q相比其值发生了变化,阅读器发送QueryAdjust指令利用Q’对Q进行更新,并重置标签的SC值,然后进入步骤(2)；否则阅读器将对SC＝1的标签所回送的随机数RN16的首位数据进行处理,并以此预测下一时隙标签分布情况：d.若(2)中整数SC为1的标签的数量为1,则阅读器发送QueryRep(SC#1)指令,继续识别阅读器范围内的剩余标签,进入步骤(2)；e.若(2)中整数SC为1的标签的数量为0,预测下一个时隙为空闲时隙,此时令Q<sub>fp</sub>＝Q<sub>fp</sub>#C；f.若(2)中整数SC为1的标签的数量为2个或2个以上,预测下一个时隙为碰撞时隙,此时令Q<sub>fp</sub>＝Q<sub>fp</sub>+C；(5)完成对下一个时隙的预测后,阅读器对Q<sub>fp</sub>四舍五入取整得到整数Q”,若整数Q”与整数Q相比其值发生了变化,阅读器向标签发送QueryAdjust指令利用Q”对Q进行更新,并重置标签的SC值,然后进入步骤(2)；否则阅读器向标签发送QueryRep(SC#2)指令,继续识别阅读器工作范围内的剩余标签,进入步骤(2)。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐晓颖;              黄念微;                   李婧媛       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>低磁场磁共振图像的皮层下结构子区域的自动分割方法</td>   <td>广东</td>   <td>CN107492104A</td>   <td>2017-12-19</td>   <td>本发明涉及一种低磁场磁共振图像的皮层下结构子区域的自动分割方法,包括以下步骤：(1)基于已进行子区域分割的皮层下结构进行模板的构建；(2)将低磁场磁共振图像中待进行子区域分割的皮层下结构A进行基于平移和旋转的刚性变换；(3)将步骤(2)进行刚性变换的皮层下结构A通过高度形变微分同胚度量映射算法进行形变,得到形变后的皮层下结构B；(4)对皮层下结构B进行基于提升采样的表面细化；(5)找到皮层下结构B表面与模板表面之间距离最短的各对顶点对,然后将模板各个顶点所属的子区域赋给经过表面细化后的皮层下结构A表面相应的顶点,皮层下结构A根据顶点完成子区域的分割。</td>   <td>低磁场磁共振图像的皮层下结构子区域的自动分割方法,其特征在于：包括以下步骤：(1)基于已进行子区域分割的皮层下结构进行模板的构建；(2)将低磁场磁共振图像中待进行子区域分割的皮层下结构A进行基于平移和旋转的刚性变换；(3)将步骤(2)进行刚性变换的皮层下结构A通过高度形变微分同胚度量映射算法进行形变,得到形变后的皮层下结构B；(4)对皮层下结构B进行基于提升采样的表面细化；(5)找到皮层下结构B表面与模板表面之间距离最短的各对顶点对,然后将模板各个顶点所属的子区域赋给经过表面细化后的皮层下结构A表面相应的顶点,皮层下结构A根据顶点完成子区域的分割。</td>   <td>G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   冯展祥       </td>   <td>中山大学</td>   <td>一种基于视角关联与深度网络学习的行人再识别方法</td>   <td>广东</td>   <td>CN107480631A</td>   <td>2017-12-15</td>   <td>本发明提供了一种基于视角关联与深度网络学习的行人再识别方法,其通过对每个视角建立视角关联的深度网络从而提取视角相关的底层视角特征,通过迭代的跨视角欧氏距离约束和跨视角中心度量约束(ICV#ECCL)约束不同网络之间的特征以减少不同视角之间行人特征的差异。实验表明,本发明能较大幅度地提高现有的深度网络在行人再识别上的性能,具有广泛的应用价值。</td>   <td>一种基于视角关联与深度网络学习的行人再识别方法,其特征在于：包括以下步骤：S1.通过行人图像预训练一个深度网络,并将该深度网络作为深度网络的初始化模型；S2.为摄像头的各个监控视角分别以步骤S1的初始化模型为基础构建一个深度网络,然后分别使用各个监控视角下的行人图像对相应监控视角的深度网络进行训练,训练过程中,利用迭代的跨视角欧氏距离约束和跨视角中心度量约束方法对不同视角的深度网络进行联合训练,减少来自不同视角的行人图像间的特征差距,直至深度网络的参数收敛；S3.对于某个监控视角下的目标行人图像及行人图像库,首先使用相应监控视角的深度网络对目标行人图像及行人图像库中的行人图像分别进行特征的提取,然后将从目标行人图像中提取的特征依次与从图像库中的行人图像中提取的特征进行匹配,基于匹配的结果确定目标行人图像的身份。</td>   <td>G06K9/00;G06K9/62;G06K9/46;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐伟嘉;              冯梦思;              刘永红;              卢志想;              黄建彰;                   陈群       </td>   <td>广东旭诚科技有限公司;中山大学</td>   <td>基于多个监测指标的质量控制方法</td>   <td>广东</td>   <td>CN107480698A</td>   <td>2017-12-15</td>   <td>本发明涉及一种基于多个监测指标的质量控制方法,主要包括：首先通过决策树的基本原理,利用控制变量对预测变量进行分类；然后利用分类结果对测试集进行测算,依据预测结果进行模型调整和优化。输出最终模型结果作为质控标准反向验证多个监测指标的检测样本是否对应决策树中所属类别的区间范围；如果多个监测指标的检测样本对应决策树所属类别的各区间范围内判断为正常监测值反之为异常值。本发明实现了自动化、智能化的可疑数据筛选和判断以及数据质量分析预判等功能,保障了数据的质量,为后期数据使用和环境预报预警提供有力支撑。</td>   <td>一种基于多个监测指标的质量控制方法,其特征在于,主要包括以下步骤：S1.首先对历史数据进行训练集和测试集的划分；S2.利用训练集的数据构建决策树；S3.构建好决策树后利用测试集数据进行验证,验证决策树构建的效果,并根据测试结果不断优化和调整模型；S4.构建最终模型树型结构,输出分类结果中每个类别对应的监测指标取值范围以及每个树枝预测的准确率；S5.选取决策树中预测准确率大于85％的树型作为质控标准,输出各树型对应的监测参数范围,利用反推过程对多个监测指标的检测样本进行质量控制；如果多个监测指标的检测样本的某个参数对应标准范围之外判断为异常值,反之为正常监测；S6.对于预测率小于85％的树枝重新进行样本的选择和决策树的训练,给予预测率较低的级别以较大的权重进入到训练集中,重复步骤S1#S4,直到预测变量所有类别的预测准确率均在85％以上再进行S5。</td>   <td>G06K9/62;G06Q10/06;G01N33/00;G01W1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              张国豪;              杜子纯;                   刘镇       </td>   <td>中山大学</td>   <td>一种基于网页的数据库通用管理系统</td>   <td>广东</td>   <td>CN107480262A</td>   <td>2017-12-15</td>   <td>本发明是一种基于网页的数据库通用管理系统,属数据库网络管理领域。其特征在于基于网页,通过浏览器,可进行数据查看,同时具有添加、删除、修改、撤销、条件检索、数据导出与批量导入功能,实现对于数据的管理。当访问数据表时,系统先后台获取该表的展示名作为表头。没有配置展示名的字段不予显示。前端数据容器装载表头后,向后台请求数据,装载到数据容器中。本系统数据管理功能通过java后台连接数据库,使用JDBC方式执行sql语句实现。本系统通过数据库中的两个表进行数据表管理：数据表信息,内容为要展示的每一个数据表的展示名,表名；数据表字典,内容为每一个数据表要对外展示的字段与字段名。</td>   <td>一种基于网页的数据库通用管理系统,其特征在于：基于网页,可通过浏览器进行数据查看,具有数据添加与数据修改、删除、撤销、数据条件检索、数据导出和数据批量导入,实现对于数据的查看与管理。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              孔令华;              刘镇;                   杜子纯       </td>   <td>中山大学</td>   <td>一种三维地质建模的无网格法</td>   <td>广东</td>   <td>CN107481320A</td>   <td>2017-12-15</td>   <td>本发明公开了一种三维地质建模的无网格法,包括利用离散点插值建立地层界面的方法、利用地质剖面中所获得的数据校对优化地层界面的方法、利用地层线延伸优化特殊地质情况的方法,利用BSP(二叉空间分割Binary#Space#Partitioning)矢量剪切技术裁剪模型边界的方法以及利用空间离散点插值赋予相关属性值的方法。本发明能快速实现三维地质模型的构建,兼顾建模精度的同时还能表达地质体内部的某些复杂性特征,如尖灭、透镜体以及岩土体密度变化等。本发明与传统以网格为基础的建模方法相区别,直接利用离散点作为基本单元,省去了网格划分与建模重构的繁杂,提高建模效率。</td>   <td>一种三维地质建模的无网格法,包括结构建模和属性建模两个部分；结构建模包括利用离散点插值直接生成地层界面,地层界面连接生成三维地质体,实现无网格建模；属性建模包括利用已知数据点的属性值插值,赋予三维地质体内部未知位置各相关属性值,实现对地质体不均一性的表达。</td>   <td>G06T17/05;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         钟任新;              张沛;                   蔡恒兴       </td>   <td>中山大学</td>   <td>基于时空感知神经网络的共享单车目的地预测方法及装置</td>   <td>广东</td>   <td>CN107480807A</td>   <td>2017-12-15</td>   <td>本发明公开了一种基于时空感知神经网络的共享单车目的地预测方法及装置,该方法包括：获取共享单车数据；将获取得到的共享单车数据输入至深度学习神经网络进行处理后,输出目的地数据。该装置包括存储器以及用于获取共享单车数据；将获取得到的共享单车数据输入至深度学习神经网络进行处理后,输出目的地数据的处理器。本发明结合利用时空感知神经网络所获取的周期性信息以及在每个时间区间内的短期信息,对目的地进行预测,提高了预测的准确性。本发明作为一种共享单车目的地预测方法及装置可广泛应用于车辆调度平台中。</td>   <td>基于时空感知神经网络的共享单车目的地预测方法,其特征在于：该方法包括以下步骤：获取共享单车数据；将获取得到的共享单车数据输入至深度学习神经网络进行处理后,输出目的地数据；其中,所述共享单车数据包含骑行起始日期时间以及骑行起始区块位置。</td>   <td>G06Q10/04;G06Q50/30;G06N3/08;G07F17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              郭春梅;                   谢晓华       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于神经网络的图像光照估计方法</td>   <td>广东</td>   <td>CN107464244A</td>   <td>2017-12-12</td>   <td>本发明提供一种基于神经网络的图像光照估计方法,可以很好的估计图像中光源方向、光源距离和光源能量。该方法通过3D模型的渲染方式产生带有光照标签的数据集,然后利用数据集训练具有强大学习能力的深度卷积神经网络,其中神经网络的输入是带有光照标签的图像,输出是光照值。对给定的任意图像,都可以通过该神经网络得到其光照值。首先本发明方法大大减少了采集光照数据集的成本和工作量,很好的解决了神经网络训练时需要大量样本问题。同时减少了人工标定的视觉误差,使神经网络的估计性能增强。其次本发明方法首次将深度卷积神经网络用到图像光照估计,给图像光照估计方法提供了新思路。</td>   <td>一种基于神经网络的图像光照估计方法,其特征在于,包括以下步骤：S1：采用随机方式生成一系列光照参数,光照参数为光源能量、光照距离、光源方位角、光源仰角；S2：三维模型渲染,在渲染通道加入光照参数生成二维图像,形成带有光照标签的合成图像集；S3：将合成图像集中的每张图像进行裁剪,形成已知光照值的训练数据集；S4：利用训练数据集训练深度卷积神经网络,其中带有光照标签的图像是神经网络的输入,光照值是神经网络的输出,对任意一幅图像,输入到训练好的神经网络中,可以得到其光照值。</td>   <td>G06T7/10;G06T7/46;G06T11/00;G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              王波超;              李冠彬;                   王青       </td>   <td>中山大学</td>   <td>一种基于深度增强学习的人物图像搜索方法</td>   <td>广东</td>   <td>CN107463881A</td>   <td>2017-12-12</td>   <td>本发明提供了一种基于深度增强学习的人物图像搜索方法,包括：S1、定义多种对目标图像中的搜索区域进行调整的动作；S2、构建可配置的深度模型；S3、采集训练样本,并使用训练样本对策略选择网络和价值网络进行训练；S4、向深度模型输入参考图像及待测的目标图像,并初始化目标图像的搜索区域为全图；S5、通过特征提取网络提取参考图像的特征；S6、通过特征提取网络提取目标图像的搜索区域内的特征,并将其与参考图像的特征进行融合,形成融合特征。本发明所提出的方法将行人检测和人物重识别结合看做是一个任务,不需要额外的候选框,只需要若干次动作选择就可以判断是否找到目标人物,具有很高的时间效率。</td>   <td>一种基于深度增强学习的人物图像搜索方法,用于从目标图像中搜索出参考图像中所包含的目标人物,其特征在于,包括以下步骤：S1、定义多种对目标图像中的搜索区域进行调整的动作,其中包括一停止动作,即保持搜索区域不变的动作；S2、构建可配置的深度模型,所述深度模型包括特征提取网络、策略选择网络和价值网络；特征提取网络用于分别提取目标图像的搜索区域内的特征和参考图像的特征,并将两者的特征进行融合,形成融合特征；策略选择网络用于根据融合特征,分别给出所有动作的概率；价值网络用于根据融合特征计算出一状态值；S3、采集训练样本,并使用训练样本对策略选择网络和价值网络进行训练；S4、向深度模型输入参考图像及待测的目标图像,并初始化目标图像的搜索区域为全图；S5、通过特征提取网络提取参考图像的特征；S6、通过特征提取网络提取目标图像的搜索区域内的特征,并将其与参考图像的特征进行融合,形成融合特征；S7、通过策略选择网络,根据S6中的融合特征,分别给出所有动作的概率,并采用贪心策略,选择概率最高的动作；S8、若选择的动作不是停止动作,则对当前搜索区域执行该动作以更新目标图像中的搜索区域,并重复执行S6至S8,直至选择的动作为停止动作；S9、当选择的动作为停止动作时,则价值网络根据当前的融合特征计算出一状态值；如果所述状态值大于一设定的阈值,则判定当前搜索区域为目标图像中包含目标人物的区域；否则判定目标图像中不包含目标人物。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              富明慧       </td>   <td>中山大学</td>   <td>一种基于新型汉字全息编码规则的明盲文转换系统</td>   <td>广东</td>   <td>CN107451105A</td>   <td>2017-12-08</td>   <td>本发明提供了一种基于新型汉字全息编码规则的明盲文转换系统,包括：文本采集模块,用于从外部获取汉字文本；读音数据库,用于存储汉字的读音；分词预处理模块,用于向文本采集模块从外部获取的汉字文本中,自动或手动插入分词标记；汉字全息码预编译模块,用于将所述汉字文本编译成汉字全息码的编码格式,并存储到汉字全息文件存储模块中；汉字全息文件存储模块,用于存储汉字全息码格式的文件。本发明采用新型的汉字全息码作为文件存储格式,在确定汉字字形的同时,也唯一确定了其读音,还明确了是否与后面汉字分词,包含了明盲文转换时所需的全部信息。利用本发明,能从根本上克服目前汉字盲文阅读中普遍存在的“费解”、“误解”等问题。</td>   <td>一种基于新型汉字全息编码规则的明盲文转换系统,其特征在于,包括：文本采集模块,用于从外部获取汉字文本；读音数据库,用于存储汉字的读音；其中,每个多音字的多个不同读音被按照一定顺序进行编号,且其中一个读音被设定为默认读音；分词预处理模块,用于向文本采集模块从外部获取的汉字文本中,自动或手动插入分词标记；汉字全息码预编译模块,用于结合读音数据库中设定的默认读音以及分词预处理模块中插入的分词标记,将所述汉字文本编译成汉字全息码的编码格式,并存储到汉字全息文件存储模块中；汉字全息文件存储模块,用于存储汉字全息码格式的文件；其中,所述汉字全息码的编码格式为：一个汉字全息码对应一个汉字；汉字全息码的前2字节为该汉字的内码；汉字全息码第3字节的其中一位定义为分词标识码,以分词标识码的不同数值标识该汉字是否与下一个汉字组成分词；汉字全息码的第4字节定义为读音标识码,以读音标识码的数值大小标识该汉字在上下文中正确读音所对应的编号；所述系统还包括：文本编辑模块,用于从汉字全息文件存储模块中读取汉字全息码格式的文件,对汉字全息码中的汉字信息和分词信息进行解译,显示出对应的汉字文本及分词标记,供用户进行审阅和修改；当用户对汉字文本或分词标记进行修改时,同步修改汉字全息文件存储模块中存储的汉字全息码；注音编辑模块,用于从汉字全息文件存储模块中读取汉字全息码格式的文件,对汉字全息码中的汉字信息和读音信息进行解译,显示出对应的汉字文本和多音字的读音信息,结合读音数据库,供用户审阅并修正多音字的正确读音；当用户对多音字的读音进行更改时,同步修改汉字全息文件存储模块中存储的汉字全息码；盲文转换模块,用于从汉字全息文件存储模块中读取汉字全息码格式的文件,对汉字全息码中的分词信息和读音信息进行解译,并结合读音数据库确定各汉字的读音,以将汉字全息码中的汉字信息转换为盲文供用户审阅及修改；当用户对盲文进行修改时,同步修改汉字全息文件存储模块中存储的汉字全息码。</td>   <td>G06F17/22;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邹超;                   龙冬阳       </td>   <td>中山大学</td>   <td>一种基于MPI计算框架的并行PLSA算法</td>   <td>广东</td>   <td>CN107451170A</td>   <td>2017-12-08</td>   <td>本发明涉及一种基于MPI计算框架的并行PLSA算法,其在每次并行迭代时无需进行读写硬盘的操作,而且从主题维度多机并行,因此能够加快并行PLSA算法的执行速度。</td>   <td>一种基于MPI计算框架的并行PLSA算法,其特征在于：包括以下步骤：S1.输入词频矩阵；S2.MPI计算框架环境初始化；S3.初始化MPI计算框架的执行环境并标识MPI计算框架的各个进程；S4.MPI计算框架的各个子进程读入词频矩阵；S5.MPI计算框架的主进程初始化初始概率矩阵P(d|z)、P(w|z)和p(z),并将这三个矩阵的数据广播到不同的子进程中；其中P(d|z)表示给定主题z下文档d的概率,P(w|z)表示给定主题z下单词w的概率,P(z)表示主题z的概率；S6.MPI计算框架的主进程计算P(d,w)并广播给所有子进程,P(d,w)表示文档d和单词w的联合概率；S7.各个子进程根据其所读入词频矩阵的主题分别计算后验概率P(z|d,w),然后更新其所读入词频矩阵的主题z的p(d|z)、p(w|z)、p(z)；S8.各个子进程将其更新的p(d|z)、p(w|z)、p(z)发送给主进程,主进程更新整体的p(d|z)、p(w|z)、p(z)；S9.根据似然函数的计算公式计算出当前迭代中的p(d|z)、p(w|z)、p(z)然后计算似然函数值,并判断是否满足迭代终止条件,若是则输出p(d|z)、p(w|z)、p(z),否则重复执行步骤S6～S9。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张熙;              杨伟伟;              赖韩江;              印鉴;                   高静       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种基于哈希编码的无监督图像检索方法</td>   <td>广东</td>   <td>CN107451189A</td>   <td>2017-12-08</td>   <td>本发明提供一种基于哈希编码的无监督图像检索方法,本发明对视频进行处理得到图片库数据,然后在图片库上训练一个分类器,然后利用这个分类器在训练集上筛选出前一半优质的图片；用筛选出的图片重新训练一个分类器,再用这个分类器对图片库进行筛选；再用从图片库中筛选出的图片训练分类器,以此类推,对分类器进行迭代交替训练得到检索模型。</td>   <td>一种基于哈希编码的无监督图像检索方法,其特征在于,包括以下步骤：S1：采集图片库数据；S2：建立训练集完成对图片库过滤噪声的操作,得到检索模型；S3：进行图像检索的训练进而完成检索。</td>   <td>G06F17/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王磊;              范新娟;              邱建平;              孟晓春;              罗倩欣;              刘占振;                   蔡健       </td>   <td>中山大学附属第六医院</td>   <td>CT图像的三维融合方法和系统</td>   <td>广东</td>   <td>CN107451983A</td>   <td>2017-12-08</td>   <td>本发明涉及一种CT图像的三维融合方法,其方法包括以下步骤：获取多期的二维CT图像；选取多期的二维CT图像中任意一期的二维CT图像为参考图像,其他期的二维CT图像为待配准图像；提取参考图像和待配准图像的特征信息,其中特征信息为血管中心线点集；利用迭代就近点算法对参考图像的血管中心线点集和待配准图像的血管中心线点集进行点集配准；在参考图像的血管中心线点集与待配准图像的血管中心线点集进行点集配准成功时,对参考图像和待配准图像进行融合,建立三维CT图像。本发明对多期二维CT图像进行配准,融合建立三维CT图像,实现了对CT图像的可视化,有利于提高医学诊断的准确性。</td>   <td>一种CT图像的三维融合方法,其特征在于,包括以下步骤：获取多期的二维CT图像；选取所述多期的二维CT图像中任意一期的二维CT图像为参考图像,其他期的二维CT图像为待配准图像；提取所述参考图像和所述待配准图像的特征信息,其中所述特征信息为血管中心线点集；利用迭代就近点算法对所述参考图像的血管中心线点集和所述待配准图像的血管中心线点集进行点集配准；在所述参考图像的血管中心线点集与所述待配准图像的血管中心线点集进行点集配准成功时,对所述参考图像和所述待配准图像进行融合,建立三维CT图像。</td>   <td>G06T5/50;G06T7/00;G06T7/33;G06T11/00;G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              李凯祥;              晏斌;                   李仕仁       </td>   <td>广州智慧城市发展研究院;中山大学</td>   <td>一种基于大数据平台的大型建筑能耗管理系统及方法</td>   <td>广东</td>   <td>CN107424079A</td>   <td>2017-12-01</td>   <td>本发明公开了一种基于大数据平台的大型建筑能耗管理系统及方法,其中,大型建筑能耗管理系统包括：设备层、数据匹配层、数据层、服务层、应用层和数据展示层；其中,所述设备层集成的子系统对外提供不同类型的接口,用于与外部连接和大型建筑能耗数据采集；所述数据匹配层为所述大型建筑能耗管理系统的数据转换器；所述数据层用于对所述设备层中的子系统采集到的数据进行格式转换；所述服务层用于向各类应用或对外提供公开服务,所述服务层独立存在或作为合成服务；所述应用层用于所述大型建筑能耗管理系统向用户提供应用功能；所述数据展示层用于所述大型建筑能耗管理系统向用户提供客户端。通过本发明实施例,实现对大型建筑的能耗实时管理。</td>   <td>一种基于大数据平台的大型建筑能耗管理系统,其特征在于,所述大型建筑能耗管理系统包括设备层、数据匹配层、数据层、服务层、应用层和数据展示层；其中,所述设备层集成了可编程控制器/集散控制子系统、数据采集与监视控制子系统、楼宇设备自控子系统、视频监控子系统、MES子系统、ERP子系统、OA子系统,所述设备层集成的子系统对外提供不同类型的接口,用于与外部连接和大型建筑能耗数据采集,所述设备层协议处理采用独立插件形式,保证所述大型建筑能耗管理系统在协议处理上的灵活性和可靠性；所述数据匹配层为所述大型建筑能耗管理系统的数据转换器,为所述服务层提供所需的数据适配器,包括OPC适配器、DB适配器；所述数据匹配层将通讯服务和数据库访问服务做成单独的适配器,通过XML文件映射、IOC控制反转技术完成数据配置工作,保证所述大型建筑能耗管理系统在数据库访问和通讯方式上的灵活性和可靠性；所述数据层用于对所述设备层中的子系统采集到的数据进行格式转换,统一数据格式,将统一数据格式的数据存储到实时数据库中或历史数据库中；所述服务层用于向各类应用或对外提供公开服务,所述服务层独立存在或作为合成服务；所述应用层用于所述大型建筑能耗管理系统向用户提供应用功能；所述数据展示层用于所述大型建筑能耗管理系统向用户提供客户端。</td>   <td>G06Q50/06;G06Q50/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              曾国军       </td>   <td>中山大学</td>   <td>一种旅游攻略管理控制系统</td>   <td>广东</td>   <td>CN107424088A</td>   <td>2017-12-01</td>   <td>本发明属于旅游管理领域,公开了一种旅游攻略管理控制系统,包括：时节旅游模块,提供不同季节的适宜的旅游景点,便于用户选择；特色旅游模块提供了不同风格的旅游景点,便于用户选择；自定义旅游模块可添加所述时节旅游模块和特色旅游模块的任一单元组成自定义单元；虚拟现实模块,用于实时在线体验旅游景点,使人们产生对此景点的乐趣和向往；连接自定义旅游模块和推荐路线模块,当用户选好自己想要的旅游路线时,使用虚拟现实模块,进行实时在线体验旅游景点；推荐路线模块,通过手机GPRS实现定位,为人们提供最佳的旅游地点。本发明具有设计优化、结构新颖、使用稳定、选择性强、方便实用等优点,有着广泛的市场前景。</td>   <td>一种旅游攻略管理控制系统,其特征在于,该旅游攻略管理控制系统包括：时节旅游模块,用于提供不同季节的适宜的旅游景点,便于用户选择；特色旅游模块,用于提供不同风格的旅游景点,便于用户选择；自定义旅游模块,分别连接时节旅游模块和特色旅游模块；所述自定义旅游模块可添加所述时节旅游模块和特色旅游模块的任一单元组成自定义单元；虚拟现实模块,与自定义旅游模块连接,用于实时在线体验旅游景点,使人们产生对此景点的乐趣和向往；连接自定义旅游模块和推荐路线模块,当用户选好自己想要的旅游路线时,使用虚拟现实模块,进行实时在线体验旅游景点,使人们产生对此景点的乐趣和向往；所述虚拟现实模块的信号处理方法包括：步骤一：近端通信节点的接收信号<img file="FDA0001409694200000011.TIF" wi="827" he="79" />为：t<sup>R</sup>(n)＝H<sup>FE</sup>(n)t<sup>FE</sup>(n)+H<sup>NE</sup>(n)t<sup>NE</sup>(n)+w(n)；其中,<img file="FDA0001409694200000012.TIF" wi="805" he="79" />为来自远端节点的有用目标接收信号；而<img file="FDA0001409694200000013.TIF" wi="786" he="71" />为近端节点自身发射信号,即回波自干扰信号；<img file="FDA0001409694200000014.TIF" wi="311" he="71" />分别表示近端和远端第j(j＝N<sub>1</sub>,…,N<sub>T</sub>)条自定义旅游模块上的发送信号；<img file="FDA0001409694200000015.TIF" wi="941" he="79" />与<img file="FDA0001409694200000016.TIF" wi="965" he="79" />分别为远端和近端发射信号的信道转移函数；w(n)为信道加性高斯白噪声；其中,N<sub>T</sub>表示通信节点发射自定义旅游模块数目,N<sub>R</sub>是接收自定义旅游模块数目,N<sub>f</sub>是信号每帧长度,(·)<sup>T</sup>表示对矩阵或矢量的转置运算符号；步骤二：在接收端通过利用归一化最小均方误差NLMS算法对混有自干扰、信道噪声的接收信号进行自干扰抑制,定义算法的代价函数为:<maths num="0001"><math><![CDATA[<mrow><mi>M</mi><mi>i</mi><mi>n</mi><mo>{</mo><mi>E</mi><mo>&lsqb;</mo><msup><mrow><mo>(</mo><msup><mi>e</mi><mrow><mi>N</mi><mi>E</mi></mrow></msup><mo>(</mo><mi>n</mi><mo>)</mo><mo>)</mo></mrow><mn>2</mn></msup><mo>&rsqb;</mo><mo>}</mo><mo> =</mo><mi>M</mi><mi>i</mi><mi>n</mi><mo>{</mo><mi>E</mi><mo>&lsqb;</mo><msup><mrow><mo>&lsqb;</mo><msup><mi>t</mi><mrow><mi>N</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>-</mo><msup><mover><mi>t</mi><mo>^</mo></mover><mrow><mi>N</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>&rsqb;</mo></mrow><mn>2</mn></msup><mo>&rsqb;</mo><mo>}</mo><mo>,</mo></mrow>]]></math><img file="FDA0001409694200000017.TIF" wi="1094" he="127" /></maths>其中,Min表示取最小值,n表示第n时刻,E(e<sup>NE</sup>(n))<sup>2</sup>表示近端误差信号<img file="FDA0001409694200000021.TIF" wi="502" he="79" />的平均功率,E[·]表示期望运算符,t<sup>NE</sup>(n)表示近端发送自定义旅游模块的实际发送信号,<img file="FDA0001409694200000022.TIF" wi="142" he="79" />表示对近端总接收信号滤波后,获得的对近端发送信号t<sup>NE</sup>(n)的估计值；步骤三：设置采用归一化最小均方误差NLMS算法进行自干扰抑制的相关初始值：令初始迭代次数k＝1,并设置最大迭代次数K及根据近端输入信号的自相关矩阵设置收敛步长因子μ<sup>NE</sup>,自适应滤波器的初始化权值矢量α<sup>NE</sup>(0)以及滤波器的长度M,开始迭代过程,分别设置K＝25、M＝11、<img file="FDA0001409694200000023.TIF" wi="1270" he="80" />μ<sup>NE</sup>＝1；步骤四：根据公式<img file="FDA0001409694200000024.TIF" wi="542" he="79" />按照以下公式求出近端的估计信号<img file="FDA0001409694200000025.TIF" wi="171" he="77" />具体过程如下：<maths num="0002"><math><![CDATA[<mrow><mtable><mtr><mtd><mrow><msubsup><mover><mi>t</mi><mo>^</mo></mover><mi>j</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo> =</mo><msup><mrow><mo>(</mo><mrow><msup><mi>&alpha;</mi><mrow><mi>N</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow></mrow><mo>)</mo></mrow><mi>T</mi></msup><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><msup><mrow><mo>(</mo><mrow><msubsup><mi>&alpha;</mi><mn>1</mn><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo><mn>...</mn><mo>,</mo><msubsup><mi>&alpha;</mi><mi>i</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo><mn>...</mn><mo>,</mo><msubsup><mi>&alpha;</mi><mi>M</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mi>T</mi></msup></mrow><mo>)</mo></mrow><mi>T</mi></msup><mo>&CenterDot;</mo><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo><mn>...</mn><mo>,</mo><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mrow><mo>(</mo><mrow><mi>n</mi><mo>-</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow><mo>,</mo><mn>...</mn><mo>,</mo><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><msup><mrow><mo>(</mo><mrow><mi>n</mi><mo>-</mo><mi>M</mi><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow><mi>T</mi></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><msubsup><mi>&alpha;</mi><mn>1</mn><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo><mn>...</mn><mo>,</mo><msubsup><mi>&alpha;</mi><mi>i</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo><mn>...</mn><mo>,</mo><msubsup><mi>&alpha;</mi><mi>M</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>&CenterDot;</mo><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo><mn>...</mn><mo>,</mo><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mrow><mo>(</mo><mrow><mi>n</mi><mo>-</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow><mo>,</mo><mn>...</mn><mo>,</mo><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><msup><mrow><mo>(</mo><mrow><mi>n</mi><mo>-</mo><mi>M</mi><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow><mi>T</mi></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>M</mi></munderover><msubsup><mi>&alpha;</mi><mi>i</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mo>(</mo><mrow><mi>n</mi><mo>-</mo><mi>i</mi><mo>+</mo><mn>1</mn></mrow><mo>)</mo></mrow></mtd></mtr></mtable><mo>,</mo></mrow>]]></math><img file="FDA0001409694200000026.TIF" wi="1614" he="479" /></maths>其中j＝N<sub>1</sub>,…,N<sub>T</sub>,N<sub>T</sub>表示发送自定义旅游模块总数目,M为自适应滤波器的长度,α<sup>NE</sup>(n)在表示n时刻的权值矢量,<img file="FDA0001409694200000027.TIF" wi="150" he="71" />为n时刻第j条接收自定义旅游模块经自适应滤波后获得的近端误差信号,<img file="FDA0001409694200000028.TIF" wi="125" he="71" />为第j条近端接收自定义旅游模块上的接收信号；j&lt;N<sub>T</sub>,则令j＝j+1,估计下一接收自定义旅游模块上的估计信号<img file="FDA0001409694200000029.TIF" wi="210" he="79" />j＝N<sub>T</sub>,则前进至步骤五；步骤五：根据下式,更新n时刻的权值矢量<img file="FDA00014096942000000210.TIF" wi="715" he="80" />并根据迭代结果输出近端发送信号t<sup>NE</sup>(n)的估计信号<img file="FDA0001409694200000031.TIF" wi="171" he="79" />具体过程如下：如下式更新下一时刻的权值矢量：<maths num="0003"><math><![CDATA[<mrow><msup><mi>&alpha;</mi><mrow><mi>N</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow><mo> =</mo><msup><mi>&alpha;</mi><mrow><mi>N</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>+</mo><mfrac><msup><mi>&mu;</mi><mrow><mi>N</mi><mi>E</mi></mrow></msup><mrow><msup><mrow><mo>(</mo><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mo>(</mo><mi>n</mi><mo>)</mo><mo>)</mo></mrow><mi>T</mi></msup><mrow><mo>(</mo><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mo>(</mo><mi>n</mi><mo>)</mo><mo>)</mo></mrow><mo>+</mo><mi>&epsiv;</mi></mrow></mfrac><msubsup><mi>e</mi><mi>j</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><msubsup><mi>t</mi><mi>j</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo></mrow>]]></math><img file="FDA0001409694200000032.TIF" wi="1214" he="167" /></maths>其中,j＝1,…,N<sub>T</sub>,N<sub>T</sub>表示发送自定义旅游模块总数目,ε表示的是权值矢量α<sup>NE</sup>(n)在迭代过程中的调整因数,仿真中设置的大小为0.001,<img file="FDA0001409694200000033.TIF" wi="123" he="71" />为第j条近端接收自定义旅游模块上的接收信号,<img file="FDA0001409694200000034.TIF" wi="150" he="71" />为n时刻第j条接收自定义旅游模块经NLMS自适应滤波后获得的近端误差信号,μ<sup>NE</sup>表示收敛步长因子,(·)<sup>T</sup>表示对矩阵或矢量的转置运算符；步骤六：根据最佳权值矢量α<sup>NE</sup>(n)以及公式：<maths num="0004"><math><![CDATA[<mrow><msubsup><mover><mi>t</mi><mo>^</mo></mover><mi>j</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo> =</mo><msup><mrow><mo>(</mo><msup><mi>&alpha;</mi><mrow><mi>N</mi><mi>E</mi></mrow></msup><mo>(</mo><mi>n</mi><mo>)</mo><mo>)</mo></mrow><mi>T</mi></msup><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>M</mi></munderover><msubsup><mi>&alpha;</mi><mi>i</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><msubsup><mi>t</mi><mi>j</mi><mi>R</mi></msubsup><mrow><mo>(</mo><mi>n</mi><mo>-</mo><mi>i</mi><mo>+</mo><mn>1</mn><mo>)</mo></mrow><mo>,</mo></mrow>]]></math><img file="FDA0001409694200000035.TIF" wi="1062" he="127" /></maths>由下式得近端估计信号<img file="FDA0001409694200000036.TIF" wi="147" he="71" />的最终表达式：<maths num="0005"><math><![CDATA[<mrow><msup><mover><mi>t</mi><mo>^</mo></mover><mrow><mi>N</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo> =</mo><msup><mrow><mo>&lsqb;</mo><msubsup><mover><mi>t</mi><mo>^</mo></mover><msub><mi>N</mi><mn>1</mn></msub><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo><mo>...</mo><mo>,</mo><msubsup><mover><mi>t</mi><mo>^</mo></mover><mi>j</mi><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo><mo>...</mo><mo>,</mo><msubsup><mover><mi>t</mi><mo>^</mo></mover><msub><mi>N</mi><mi>T</mi></msub><mrow><mi>N</mi><mi>E</mi></mrow></msubsup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>&rsqb;</mo></mrow><mi>T</mi></msup><mo>,</mo></mrow>]]></math><img file="FDA0001409694200000037.TIF" wi="862" he="79" /></maths>其中,j＝1,…,N<sub>T</sub>,N<sub>T</sub>表示发送自定义旅游模块总数目,α<sup>NE</sup>(n)表示n时刻权值矢量,<img file="FDA0001409694200000038.TIF" wi="158" he="71" />表示n时刻的权值,其中i＝1,…,M,M表示滤波器的长度,<img file="FDA0001409694200000039.TIF" wi="110" he="71" />表示第j条接收自定义旅游模块上的接收信号；步骤七：从总体接收信号t<sup>R</sup>(n)中滤除估计出的回波自干扰信号,以获得来自远端节点的有用传输信号,将该信号送入后续的MIMO译码检测单元,以获得对远端发送信号的准确估计,具体包括：第一步,从接收信号t<sup>R</sup>(n)中减去回波自干扰估计信号<img file="FDA00014096942000000310.TIF" wi="177" he="72" />得到来自远端节点的有用传输信号t<sup>ES</sup>(n),即：<maths num="0006"><math><![CDATA[<mrow><msup><mi>t</mi><mrow><mi>E</mi><mi>S</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo> =</mo><msup><mi>H</mi><mrow><mi>F</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><msup><mi>t</mi><mrow><mi>F</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo> =</mo><msup><mi>t</mi><mi>R</mi></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>-</mo><msup><mover><mi>t</mi><mo>^</mo></mover><mrow><mi>N</mi><mi>E</mi></mrow></msup><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><mo>,</mo></mrow>]]></math><img file="FDA00014096942000000311.TIF" wi="870" he="78" /></maths>第二步,将信号t<sup>ES</sup>(n)送入后续的MIMO译码检测单元,以获得对远端发送信号t<sup>FE</sup>(n)的估计；推荐路线模块,通过手机GPRS实现定位,为人们提供最佳的旅游地点；所述推荐路线模块中多网关终端快速漫游方法包括一个新的对应表和三个数据包劫持机制；对应表,即终端mac地址和DNS服务器地址的对应表；mac地址是STA的mac地址,DNS服务器地址是STA的DNS服务器地址,即STA所选MPP节点的IP地址；三个数据包劫持机制包括：普通数据包的劫持转发机制、ARP请求包的劫持与应答机制和DNS查询应答包的劫持转发机制；普通数据包的劫持转发机制,Mesh节点收到STA的普通数据包后,截获该数据包,提取数据包源mac地址,根据源mac地址判断是否是接入本Mesh节点的STA,只对接入本Mesh节点的STA的数据包进行劫持处理,然后判断数据包是发往外网还是内网,只对发往外网的数据包进行劫持处理；数据包是接入本Mesh节点的STA的且发往外网,则将数据包目的mac地址修改为Mesh网络中一个通信条件最佳的MPP节点的mac地址；ARP请求包的劫持与应答机制,L2P协议是分布式ARP表DAT机制,该机制的核心是存储网络中传播的所有ARP响应内容在一些特定的节点组中,给定一个IP地址,客户端发起一个ARP请求,Mesh节点收到ARP请求包后,截获并直接将它转发到存储有响应条目的节点组中的节点,请求被作为单播分组发送,对于使用DAT机制仍无法获得响应条目的ARP请求,协议将按普通ARP请求包广播出去；当STA的默认网关MPP1无法正常工作时,由于STA发往外网的数据包是使用默认网关mac地址作为数据包目的mac地址,会发起ARP请求去获取默认网关的mac地址,在STA接入的Mesh节点处截获STA对默认网关的ARP请求包,查找本地DAT表中是否有响应条目,有,则直接生成一个ARP应答包进行应答；否则使用一个通信条件最佳MPP节点的mac地址进行响应,STA收到ARP应答后,就将发往外网的数据包发出；DNS查询应答包的劫持转发机制,STA会先发送一个DNS查询包给DNS服务器,查找该域名对应的IP地址,得到应答之后才能访问该网址,STA的DNS服务器地址和IP地址是自动获取的,通常STA的DNS服务器地址即是默认网关的IP地址,STA的默认网关无法正常工作,STA的DNS服务器故障了,无法给STA提供域名解析服务,无法通过访问域名的方式上网,在STA接入的Mesh节点将STA的DNS查询包进行劫持并将DNS查询包中的目的IP地址由STA的默认网关IP地址修改为一个公网DNS服务器地址,然后将DNS查询包转发到通信条件最佳MPP节点,由该MPP节点发送出去,对于DNS应答包,将数据包中源IP地址由公网服务器地址修改回STA的默认网关的IP地址。</td>   <td>G06Q50/14;G06Q30/02;H04L29/06;H04L29/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   牛向东       </td>   <td>中山大学</td>   <td>一种基于功能隐含关系及聚类的Mashup推荐方法</td>   <td>广东</td>   <td>CN107423396A</td>   <td>2017-12-01</td>   <td>本发明涉及一种基于功能隐含关系及聚类的Mashup推荐方法,步骤如下：S1、从Mashup在线平台爬取带有API和Mashup描述、标签及API调用信息的数据；S2、对步骤S1爬取到的描述信息进行预处理；S3、API及Mashup相似性计算；S4、API及Mashup聚类；S5、API推荐。本发明采用对Mashup及API聚类的方法,一方面减轻了数据集的稀疏性,另一方面从较粗粒度的类别来归类,然后再回到具体的API更容易发现适合Mashup功能完善的API。</td>   <td>一种基于功能隐含关系及聚类的Mashup推荐方法,其特征在于：包括以下步骤：S1、从Mashup在线平台爬取带有API和Mashup描述、标签及API调用信息的数据；S2、对步骤S1爬取到的描述信息进行预处理；S3、API及Mashup相似性计算；S4、API及Mashup聚类；S5、API推荐。</td>   <td>G06F17/30;H04L29/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘冶;              李宏浩;              桂进军;              傅自豪;              彭楠;                   印鉴       </td>   <td>火烈鸟网络(广州)股份有限公司;中山大学</td>   <td>基于用户画像行为分析的应用推荐方法及系统,储存介质及计算机设备</td>   <td>广东</td>   <td>CN107423442A</td>   <td>2017-12-01</td>   <td>本发明提供一种基于用户画像行为分析的游戏推荐方法及系统。通过构建特征采集器,对用户画像数据、应用列表数据、客户端上报的数据进行处理,获得规范化且符合数学建模要求的特征向量。利用多个基础推荐模型进行预测,生成初步的用户应用推荐列表及相应下载概率；结合下载概率及实际标签训练融合模型,生成最终的应用推荐列表。通过对用户历史行为日志的多维度分析,进行特征提取构建用户画像数据仓库。对于基础推荐模型,创新性地引入长短期记忆网络学习用户行为的时序关系,更好地刻画用户对物品的喜好程度,所推荐游戏应用与用户的需求匹配度高。加入集成学习进行模型融合,整合各个模型的学习结果,提高推荐算法的稳定性和泛化能力。</td>   <td>一种基于用户画像行为分析的应用推荐方法,其特征在于：包括如下步骤：获取客户端上报的用户行为日志,并存储在服务器基础数据库中；通过构建特征采集器,对用户画像数据、原始应用列表数据以及所述用户行为日志数据进行数据采集、清洗、标准化处理以及特征组合和提取,获得统一规范且符合数学建模要求的特征向量；调用多个预设的基础推荐模型分别对所述特征向量进行运算,获得各个基础推荐模型下相应用户的初步应用推荐列表,以及相应用户对所述初步应用推荐列表中各种应用的下载概率；将各个所述基础推荐模型得到的下载概率作为新的特征向量输入,并以实际下载所述应用与否作为融合推荐模型的标签,训练预先设置的融合推荐模型；调用所述融合推荐模型对用户的新增特征向量进行处理,获得对用户的最终应用推荐列表。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              甘宇康;              李冠彬;                   王青       </td>   <td>中山大学</td>   <td>一种RGBD图像语义分割方法</td>   <td>广东</td>   <td>CN107403430A</td>   <td>2017-11-28</td>   <td>本发明提供了一种RGBD图像语义分割方法,包括以下步骤：S1、采集训练样本的数据；S2、构建可配置的深度模型,并将训练样本的数据输入深度模型,以对深度模型进行训练；S3、获取需要进行语义分割的彩色图及其对应的深度图,利用训练后的深度模型对彩色图和深度图进行分析,预测RGBD图像中每个像素所属的物体类别；S4、根据S3的结果,形成并输出预测的图像语义分割图。本发明利用深层次的卷积神经网络和长短时记忆网络以及大数据,能有效地融合彩色图像和深度图像的特征,并且能有效地挖掘图像中的上下文信息,拥有很高的准确率。</td>   <td>一种RGBD图像语义分割方法,其特征在于,包括以下步骤：S1、采集训练样本的数据；S2、构建可配置的深度模型,并将训练样本的数据输入深度模型,以对深度模型进行训练；S3、获取需要进行语义分割的彩色图及其对应的深度图,利用训练后的深度模型对彩色图和深度图进行分析,预测RGBD图像中每个像素所属的物体类别；S4、根据S3的结果,形成并输出预测的图像语义分割图；其中,所述深度模型包括三个依次串联的子网络；第一子网络用于对彩色图像和深度图像数据的基础表达进行提取和学习,包括用于提取彩色图的特征的第一卷积神经网络,以及用于提取深度图的特征的第二卷积神经网络；第二子网络用于融合彩色图和深度图的特征以及学习图像的全局上下文信息,包括用于提取彩色图的上下文信息的第一长短时记忆网络,用于提取深度图像的上下文信息的第二长短时记忆网络,以及用于融合彩色图和深度图的上下文信息的第三长短时记忆网络；第三子网络包括第三卷积神经网络,用于融合局部特征和全局特征,进而预测图像像素所属的物体类别；彩色图依次经过第一卷积神经网络、第一长短时记忆网络处理后汇入第三长短时记忆网络；深度图依次经过第二卷积神经网络、第二长短时记忆网络处理后汇入第三长短时记忆网络；第三子网络根据第二子网络的输出和第一卷积神经网络的输出层叠得到的特征,输出RGBD图像中每个像素属于每一物体类别的概率值,进而预测RGBD图像像素所属的物体类别,最终输出图像语义分割图。</td>   <td>G06T7/10;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         成慧;              杜径舟;                   吴华栋       </td>   <td>中山大学</td>   <td>一种基于深度图像的人物轮廓快速检测与跟踪方法</td>   <td>广东</td>   <td>CN107403436A</td>   <td>2017-11-28</td>   <td>本发明涉及深度图像的实时人物轮廓检测与跟踪的技术领域,更具体地,涉及一种基于深度图像的人物轮廓快速检测与跟踪方法。一种基于深度图像的人物轮廓快速检测与跟踪方法,其特征在于,包括人物轮廓快速检测和人物轮廓掩模实时跟踪步骤,所述的人物轮廓快速检测步骤如下：S1.#通过人物运动确定背景区域；S2.#背景模型更新策略依据背景区域深度图像像素值变化的大小与方向进行更新；S3.#通过背景减除得到人物轮廓区域,并依赖其区域再次进行背景更新；所述的人物轮廓掩模实时跟踪步骤如下：S4.#基于深度信息对人物轮廓掩模区域进快速分割；S5.#对分割后轮廓进行基于轮廓掩模重叠性跟踪；S6.#重检测策略。</td>   <td>一种基于深度图像的人物轮廓快速检测与跟踪方法,其特征在于,包括人物轮廓快速检测和人物轮廓掩模实时跟踪步骤,所述的人物轮廓快速检测步骤如下：S1.#通过人物运动确定背景区域；S2.#背景模型更新策略依据背景区域深度图像像素值变化的大小与方向进行更新；S3.#通过背景减除得到人物轮廓区域,并依赖其区域再次进行背景更新；所述的人物轮廓掩模实时跟踪步骤如下：S4.#基于深度信息对人物轮廓掩模区域进快速分割；S5.#对分割后轮廓进行基于轮廓掩模重叠性跟踪；S6.#重检测策略。</td>   <td>G06T7/12;G06T7/149;G06T7/194;G06T7/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         聂琳;              王可泽;              林木得;              成慧;                   王青       </td>   <td>中山大学</td>   <td>一种单目彩色视频的三维人体关节点定位方法</td>   <td>广东</td>   <td>CN107392097A</td>   <td>2017-11-24</td>   <td>本发明提供了一种单目彩色视频的三维人体关节点定位方法,包括以下步骤：S1、构建可配置的深度模型,并在该深度模型中引入时序信息；S2、采集训练样本,并利用训练样本学习出深度模型的参数；S3、利用S2中学习得到的参数对深度模型进行初始化,将需要进行三维人体关节点定位的单目彩色视频数据转化为连续多帧二维图像,输入深度模型以进行分析；针对每帧二维图像,输出其中人物的三维人体关节点坐标。本发明利用深度学习,构建深层次的卷积神经网络,来从大量的训练样本中自动学习出有效的时空特征,而不再依赖人工设计的先验条件和人体关节结构约束；通过学习出的有效特征,直接回归出人体的关节点位置。</td>   <td>一种单目彩色视频的三维人体关节点定位方法,其特征在于,包括以下步骤：S1、构建可配置的深度模型,并在该深度模型中引入时序信息；其中,所述深度模型包括互相串联的卷积神经网络和长短时记忆网络；所述卷积神经网络用于对视频数据进行逐帧处理,提取二维图像中人物的二维人体关节点特征,并将二维图像中人物的二维人体关节点特征转化到三维人体关节点坐标相关的特征空间；所述长短时记忆网络用于结合当前帧及其之前的连续多帧二维图像的特征信息,预测出当前帧二维图像的三维人体关节点坐标；S2、采集训练样本,并利用训练样本学习出深度模型的参数；所述训练样本包括：被转换成连续多帧二维图像的视频数据、每帧二维图像对应的真实的二维人体关节点坐标和三维人体关节点坐标；其中,视频数据和二维人体关节点坐标用于供深度模型学习出构建卷积神经网络的参数,视频数据和三维人体关节点坐标用于供深度模型学习出构建长短时记忆网络的参数；S3、利用S2中学习得到的参数对深度模型进行初始化,将需要进行三维人体关节点定位的单目彩色视频数据转化为连续多帧二维图像,输入深度模型以进行分析；针对每帧二维图像,输出其中人物的三维人体关节点坐标。</td>   <td>G06K9/00;G06K9/46;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              吴明华;              林培祥;              王金鹏;                   李仕仁       </td>   <td>广州智慧城市发展研究院;中山大学</td>   <td>一种基于联合分块的人脸识别方法及系统</td>   <td>广东</td>   <td>CN107392134A</td>   <td>2017-11-24</td>   <td>本发明公开了一种基于联合分块的人脸识别方法及系统,其中,所述方法包括：对获取的人脸图像进行分块处理,获取分块后的人脸图像分块组成类集合；对人脸图像分块组成类集合进行k#mean算法聚类处理,将聚类结果转换成聚类矩阵；对人脸图像分块组成类集合进行标记并计算每个人脸图像分块之间的距离,获取每个集合中距离最短的两个人脸图像分块；根据每个集合中距离最短的两个人脸图像分块对聚类矩阵进行扩展,根据扩展结果进行类别稀疏表示计算,获取计算后的联合分块字典矩阵；对计算后的联合分块字典矩阵进行重构误差最小分类处理,根据重构结果进行人脸识别,获取人脸识别结果。在本发明实施例中,可以快速准确的实现人脸识别。</td>   <td>一种基于联合分块的人脸识别方法,其特征在于,所述人脸识别方法包括：对获取的人脸图像进行分块处理,获取分块后的人脸图像分块组成类集合；对所述人脸图像分块组成类集合进行k#mean算法聚类处理,将聚类结果转换成聚类矩阵；对所述人脸图像分块组成类集合进行标记并计算每个人脸图像分块之间的距离,获取每个集合中距离最短的两个人脸图像分块；根据所述每个集合中距离最短的两个人脸图像分块对聚类矩阵进行扩展,获取联合分块字典矩阵；对所述联合分块字典矩阵进行类别稀疏表示计算,获取计算后的联合分块字典矩阵；对所述计算后的联合分块字典矩阵进行重构误差最小分类处理,获取重构误差最小化联合分块字典矩阵；根据所述重构误差最小化联合分块字典矩阵进行用户人脸识别,获取人脸识别结果。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐承佩;              潘麒元;              王善庆;                   谭杜康       </td>   <td>中山大学;广州汇数信息科技有限公司</td>   <td>一种基于物联网的身高体重测量系统和方法</td>   <td>广东</td>   <td>CN107392681A</td>   <td>2017-11-24</td>   <td>本发明公开了一种基于物联网的身高体重测量系统和方法,使用更方便,功能更完善。该系统包括智能移动终端、云端服务器和测量平台模块,所述测量平台模块包括无线通信模块、中央处理器CPU、测量模块其中,所述测量模块包括以下至少一项单元：站立平台、身高测量模块、体重测量模块、摄像头模块、显示屏、音频播放模块；其中,所述智能移动终端,用于与所述云端服务器进行通信；所述云端服务器,用于分别与所述智能移动终端和所述无线通信模块通信；所述无线通信模块,用于与所述中央处理器CPU和所述云端服务器进行通信；所述CPU,用于接收所述无线通信模块的通信信息,控制和协调所述测量模块中的各个单元的运行。</td>   <td>一种基于物联网的身高体重测量系统,其特征在于：所述系统包括智能移动终端、云端服务器和测量平台模块,所述测量平台模块包括无线通信模块、中央处理器CPU、测量模块；其中,所述测量模块包括以下至少一项单元：站立平台、身高测量模块、体重测量模块、摄像头模块、显示屏、音频播放模块；其中,所述智能移动终端,用于与所述云端服务器进行通信,其中所述智能移动终端安装有扫码功能的小程序；所述云端服务器,用于分别与所述智能移动终端和所述无线通信模块通信；所述无线通信模块,用于与所述中央处理器CPU和所述云端服务器进行通信,通过无线方式与云端服务器连接,接收云端服务器发出的指令信息,并把测量模块获得的测量信息上传到云端服务器；所述CPU,用于接收所述无线通信模块的通信信息,控制和协调所述测量模块中的各个单元的运行。</td>   <td>G06Q30/02;A61B5/107</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李晋豪;              谢庆辉;              蔡旭东;              黄嘉兴;              梁永康;              李祖森;              李佳;                   莫伟健       </td>   <td>中山大学新华学院</td>   <td>自行车智能租借系统</td>   <td>广东</td>   <td>CN107392706A</td>   <td>2017-11-24</td>   <td>本发明公开了一种自行车智能租借系统,包括后台管理系统、大数据云平台、自行车租赁点管理系统和用户手机,自行车租赁点管理系统与后台管理系统之间通过WiFi通信模块实现数据通信,自行车租赁点管理系统由站点管理箱、锁桩控制箱、自行车控制器组成,自行车控制器基于STM32微控制器进行控制,通过NFC模块与用户手机进行信息交互,微控制器STM32控制锁桩控制箱控制车辆的租还,并获取车辆的基本信息,将这些控制信息和车辆信息通过WiFi通信模块实时传输至后台管理系统；用户手机作为桥梁中介,通过APP软件连接自行车控制器及后台管理系统,实现信息交互。本发明规范、完善了共享自行车的使用,营造了更好的用户体验。</td>   <td>自行车智能租借系统,包括后台管理系统、大数据云平台、自行车租赁点管理系统和用户手机,其特征在于,自行车租赁点管理系统与后台管理系统之间通过WiFi通信模块实现数据通信,租赁点设有一热点设备,WiFi通信模块通过连接该热点,将租赁车辆信息实时发送至后台管理系统,自行车租赁点管理系统由站点管理箱、锁桩控制箱、自行车控制器组成,所述自行车控制器基于STM32微控制器进行控制,还包括NFC模块、车锁和电源模块,所述NFC模块用于与用户手机进行信息交互,所述车锁用于负责车辆控制,所述WiFi通信模块与微控制器STM32相连,所述微控制器STM32用于控制锁桩控制箱从而控制车辆的租还,并获取车辆的基本信息,将这些控制信息和车辆信息通过WiFi通信模块实时传输至后台管理系统；所述用户手机作为桥梁中介,通过APP软件连接自行车控制器及后台管理系统,实现信息交互。</td>   <td>G06Q30/06;G06Q10/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              吴明华;              林培祥;              王金鹏;                   李仕仁       </td>   <td>广州智慧城市发展研究院;中山大学</td>   <td>一种基于类别稀疏表示的人脸识别方法及系统</td>   <td>广东</td>   <td>CN107368803A</td>   <td>2017-11-21</td>   <td>本发明公开了一种基于类别稀疏表示的人脸识别方法及系统,其中,所述人脸识别方法包括：对所述待识别人脸图像信息进行一维数组提取预处理,获取表示待识别人脸图像信息的一维数组信息；采用基本字典和核扩展字典对所述一维数组信息进行构建类别稀疏表示的计算处理,获取所述一维数组信息的类别稀疏表示；根据所述基本字典、所述核扩展字典和所述类别稀疏表示计算所述残差分类,获取残差分类集合；对所述残差分类集合内的残差分类进行排序处理,根据排序结果获取待识别人脸图像信息的识别结果。在本发明实施例中,通过本发明实施例可以在人脸被遮挡的情况下也有较高的识别准确率,并且在实施过程中,降低特征维度,有效增加了识别速度。</td>   <td>一种基于类别稀疏表示的人脸识别方法,其特征在于,所述人脸识别方法包括：对所述待识别人脸图像信息进行一维数组提取预处理,获取表示待识别人脸图像信息的一维数组信息；采用基本字典和核扩展字典对所述一维数组信息进行构建类别稀疏表示的计算处理,获取所述一维数组信息的类别稀疏表示；根据所述基本字典、所述核扩展字典和所述类别稀疏表示计算所述残差分类,获取残差分类集合；对所述残差分类集合内的残差分类进行排序处理,根据排序结果获取待识别人脸图像信息的识别结果。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>              万香波       </td>   <td>万香波;陈浩;王磊;范新娟;林黄靖;冯莉莉;窦琪;王平安;朱亚希;黄艳;中山大学附属第六医院;深圳视见医疗科技有限公司</td>   <td>基于大数据深度学习的胃肠间质瘤病理诊断支持系统和方法</td>   <td>广东</td>   <td>CN107369151A</td>   <td>2017-11-21</td>   <td>本发明公开了一种基于大数据深度学习的胃肠间质瘤病理诊断支持系统和方法,该系统包括：图像数据获得单元,用于获得正常胃肠组织切片图像和已确诊的胃肠间质瘤病例的病理切片图像作为已输入图像数据；图像数据标注单元,用于对已输入图像数据进行标注；图像数据库构建单元,用于对图像数据标注单元提供的已标注图像数据分类、整理,构建病理图像数据库；卷积神经网络(CNN)构造单元,用于构造第一卷积神经网络模型；以及卷积神经网络模型训练单元,获得理想的卷积神经网络模型。通过本发明的胃肠间质瘤病理诊断支持系统和方法可实现精准和高效的智能读片,以辅助临床上胃肠间质瘤的病理诊断工作,提高其准确率、工作效率及工作持续状态。</td>   <td>胃肠间质瘤病理诊断支持系统,其特征在于,所述支持系统包括：图像数据获得单元,用于获得正常胃肠组织切片图像和已确诊的胃肠间质瘤病例的病理切片图像作为已输入图像数据；图像数据标注单元,用于对所述已输入图像数据进行标注,以及保证图像的标签和图像的真实病理诊断结果一致；图像数据库构建单元,用于对所述图像数据标注单元提供的已标注图像数据分类、整理,构建病理图像数据库；卷积神经网络构造单元,用于构造第一卷积神经网络模型；以及卷积神经网络模型训练单元,利用所述病理图像数据库的图像数据对所述第一卷积神经网络模型的参数进行调节,以及训练所述第一卷积神经网络模型,获得可用于检测患者病理图像数据的第二卷积神经网络模型。</td>   <td>G06T7/00;G06K9/62;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              张国豪;              杜子纯;                   刘镇       </td>   <td>中山大学</td>   <td>一种用于ARCGIS Web地图的多折线绘制方法</td>   <td>广东</td>   <td>CN107369198A</td>   <td>2017-11-21</td>   <td>本发明涉及一种用于ARCGIS#Web地图的多折线绘制方法,属于地质地理工程信息化领域。其特征在于通过任意点击地图或手动输入坐标的方式生成标记点与标记点间连线,可通过点击标记点以删除该点,以该点为端点的线段以及所有在该点之后添加的图形,从而达到编辑折线的目的。再通过标记点生成折线并清除标记点与标记点间连线。通过监听事件获取被点击的折线图形,用户决定是否执行删除该图形的操作。实现多条折线的在线绘制,编辑与删除。本方法适用于在网络地理信息系统中方便快捷地绘制多条折线。</td>   <td>一种用于ARCGIS#Web地图的多折线绘制方法,其特征在于：在基于ARCGIS#Web的网络地图应用中,通过点击或输入坐标的方式绘制并连接点；通过点击点修改当前折线绘制；获取所有的点图形,生成折线；删除指定折线；重复以上步骤,绘制多条折线。</td>   <td>G06T11/80;G09B29/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余阳;              朱李设;                   吴晓鹏       </td>   <td>广州天源信息科技有限公司;中山大学</td>   <td>一种面向精准营销的电信用户消费画像的构建方法</td>   <td>广东</td>   <td>CN107358269A</td>   <td>2017-11-17</td>   <td>本发明涉及一种面向精准营销的电信用户消费画像的构建方法,包括以下步骤：对用户话单数据做数据预处理,得到用户消费行为数据；将用户话单数据和新套餐计费规则作为离线计费引擎输入,计算用户在新套餐下消费额,利用新旧套餐下消费额给用户标定类标签；训练新套餐的随机森林模型；根据随机森林模型筛选重要特征；针对每个重要特征,计算新套餐的非潜在用户和潜在用户的分裂点；利用重要特征和相应分裂点构建潜在用户的用户画像。本发明利用离线计费引擎,计算用户在新套餐下消费额,为用户标类标签,利用随机森林模型筛选重要特征并构建用户画像,利于新套餐的精准营销。</td>   <td>一种面向精准营销的电信用户消费画像的构建方法,其特征在于,包括以下步骤：步骤S1、对用户话单数据做数据预处理,得到用户消费行为数据；步骤S2、将用户话单数据和新套餐计费规则作为离线计费引擎的输入,计算用户在新套餐下消费额,利用新旧套餐下消费差额给用户标定类标签；步骤S3、利用用户消费行为数据和所标定的相应类标签,训练新套餐的随机森林模型；步骤S4、通过随机森林模型筛选重要特征,得到重要特征集合；步骤S5、针对每个重要特征,计算新套餐的非潜在用户和潜在用户的分裂点；步骤S6、利用重要特征和相应分裂点构建新套餐的潜在用户的用户画像。</td>   <td>G06K9/62;G06Q30/02;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭栋;                   吕中荣       </td>   <td>中山大学</td>   <td>一种轴向功能梯度梁的损伤识别方法</td>   <td>广东</td>   <td>CN107357980A</td>   <td>2017-11-17</td>   <td>本发明公开一种轴向功能梯度梁的损伤识别方法,实现过程为：①通过有限单元法建立功能梯度梁损伤结构的有限元模型,提取结构的固有频率、模态等参数；②计算并比较各节点的残余应变能值,选出可疑单元；③基于可疑单元的损伤参数α,计算混合灵敏度矩阵S及待修正模型和真实模型的响应差值ΔH；④求解修正方程SΔα＝ΔH；⑤更新可疑单元的损伤参数α＝α+Δα；⑥若未达到预设精度要求,则回到③循环迭代,否则输出损伤参数作为识别结果。该方法定义了残余力向量的概念,对损伤进行定位,减少了需要识别参数的数量；并采用了含频率与动态响应的混合灵敏度矩阵,相较于普通的灵敏度矩阵,在噪声情况下仍有相当高的识别精度,对功能梯度梁这一较为复杂结构也能成功识别。</td>   <td>一种轴向功能梯度梁的损伤识别方法,其特征在于,包括以下步骤：1)用有限元方法将轴向功能梯度梁结构进行简化建模,并把结构划分为nel个单元；2)提取损伤结构的频率和模态,根据如下所示的式子得到损伤后结构的残余力向量f<sub>i</sub>,对应得到RFV值：<maths num="0001"><math><![CDATA[<mrow><msub><mi>f</mi><mi>i</mi></msub><mo> =</mo><mrow><mo>(</mo><mi>K</mi><mo>-</mo><msubsup><mi>&omega;</mi><mrow><mi>d</mi><mi>i</mi></mrow><mn>2</mn></msubsup><mi>M</mi><mo>)</mo></mrow><msub><mi>V</mi><mrow><mi>d</mi><mi>i</mi></mrow></msub></mrow>]]></math><img file="FDA0001337016580000011.TIF" wi="374" he="86" /></maths>其中ω<sub>di</sub>,V<sub>di</sub>分别为损伤结构第i阶测量得到的频率和振型数据,K,M分别为结构完好状态下的刚度矩阵及质量矩阵；比较f<sub>i</sub>所对应各节点的值,在局部RFV值不等于零的节点所对应的单元,定义为有可能出现损伤的可疑单元,共有n个可疑单元,并将其损伤参数初值设为α<sub>i</sub>＝1,i＝1,2,…,n,α＝{α<sub>1</sub>,α<sub>2</sub>,…,α<sub>n</sub>}；3)对步骤2)中得到的可疑单元对应的损伤参数α进行进一步的精确识别；将损伤参数α代入到计算刚度矩阵K<sub>c</sub>,计算得到修正结构的计算频率ω<sub>c</sub>和计算加速度R<sub>c</sub>；4)利用损伤结构的测量频率ω<sub>d</sub>与测量加速度R<sub>d</sub>,由Δω＝ω<sub>c</sub>#ω<sub>d</sub>,ΔR＝R<sub>c</sub>#R<sub>d</sub>得到<img file="FDA0001337016580000012.TIF" wi="267" he="148" />5)建立模型修正方程SΔα＝ΔH,其中S是由特征值灵敏度和加速度灵敏度组成的混合灵敏度矩阵；利用Tikhonov正则化方法和L#curve方法求解该方程,得到Δα的值；6)可疑单元的损伤参数更新为α＝α+Δα；若损伤参数改变量Δα没有达到设定精度要求,则回到步骤3)继续迭代；否则,步骤6)中得到的损伤参数α为最终识别结果；其中α＝1表示没有损伤,α＝0表示彻底损坏；通过查看损伤参数对应的有限元模型单元编号,得到结构损伤的精确位置以及详细损伤程度。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>              郑子彬       </td>   <td>腾讯科技(深圳)有限公司;中山大学</td>   <td>信息推荐方法和装置</td>   <td>广东</td>   <td>CN107357793A</td>   <td>2017-11-17</td>   <td>本发明涉及一种信息推荐方法和装置,所述方法包括：根据跨领域的用户数据提取用户标签；将相同用户的所述用户标签形成用于描述所述用户的用户标签集；根据主题生成模型和所述用户标签集确定所述用户标签集所属主题,并将所述用户标签集所属主题作为用户所属用户社区；根据所述用户所属用户社区进行信息推荐。本发明提供的信息推荐方法和装置,在数据稀疏度高的情况下可根据跨领域的用户数据,利用主题生成模型准确地确定用户所属用户社区,从而再利用用户所属用户社区进行信息推荐,可以在数据稀疏度高的情况下仍然进行准确的信息推荐。</td>   <td>一种信息推荐方法,所述方法包括：根据跨领域的用户数据提取用户标签；将相同用户的所述用户标签形成用于描述所述用户的用户标签集；根据主题生成模型和所述用户标签集确定所述用户标签集所属主题,并将所述用户标签集所属主题作为用户所属用户社区；根据所述用户所属用户社区进行信息推荐。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   马璐       </td>   <td>中山大学</td>   <td>基于区块链的评价排序方法</td>   <td>广东</td>   <td>CN107358500A</td>   <td>2017-11-17</td>   <td>本发明涉及基于区块链的评价排序方法,包括以下步骤：1、构建一条区块链；2、对已存在用户各自分发一单位币；3、完成一笔给该新注册用户账户一单位币的交易；4、当有评论增加时,获取发表评论的用户的币天销毁数值,并完成一笔给该用户账户一单位币的交易；5、根据此评价用户的币天销毁值、该用户的历史评价得分、评价时的信用值及用户在此平台的等级计算用户总的现时评价得分；6、根据总的现时评价得分给出最终排序。本发明能有效地避免刷单刷好评或恶意差评给评价排序带来的影响,利于用户在消费时对商品的质量有个较明确的认识,也有助于电商平台对商户的管理,一定程度上保证出现在该平台上的商品质量,利于电商平台的健康发展。</td>   <td>基于区块链的评价排序方法,其特征在于：包括以下步骤：S1、对于传统中心化的电商平台,构建一条区块链；S2、对已存在用户各自分发一单位币；S3、对新注册用户,完成一笔给该新注册用户账户一单位币的交易；S4、当有评论增加时,获取发表评论的用户的币天销毁数值,并完成一笔给该用户账户一单位币的交易；S5、根据此评价用户的币天销毁值、该用户的历史评价得分、评价时的信用值及用户在此平台的等级计算用户总的现时评价得分；S6、根据步骤S5得出的总的现时评价得分给出最终排序。</td>   <td>G06Q30/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              陈佳捷;                   欧阳楚旭       </td>   <td>中山大学</td>   <td>一种基于分段特征选择的虹膜识别方法</td>   <td>广东</td>   <td>CN107358198A</td>   <td>2017-11-17</td>   <td>本发明提供的基于分段特征选择的虹膜识别方法将所有的特征向量进行分段,能够更精确地挑选出每一段特征向量里能够有效区分类内样本和类间样本的特征向量,将每段选择出来的特征向量结合起来作为虹膜最终的特征描述,从实验结果可以看出,本发明所选择出来的特征向量相对于经典的特征选择方法能取得更好的识别性能。</td>   <td>一种基于分段特征选择的虹膜识别方法,其特征在于：包括以下步骤：S1.输入训练样本对,对每对训练样本中的两张虹膜图片分别进行虹膜的定位得到虹膜所在的环形区域,然后将虹膜的环形区域展开成矩形图像；S2.将虹膜的矩形图像划分为多个互不重叠的子区域,然后构建多个不同滤波参数的多叶差分滤波器；S3.每一个子区域与多叶差分滤波器卷积后,得到滤波结果,对滤波结果中每一个像素点根据其值的符号做0#1编码,符号为正的编码为1,符号为负的编码为0,将滤波结果中的像素点的编码按照顺序进行拼接后得到一多维向量,作为子区域的特征向量；S4.每个子区域分别与步骤S2的多个多叶差分滤波器执行步骤S3的操作后,得到由多个特征向量组成的特征集；S5.各个子区域执行步骤S3、S4的操作后得到相应的特征集；S6.将所有子区域特征集包含的所有特征向量分成T段,每段有D个特征；S7.将每对训练样本进行S1～S6的处理；S8.对于所有训练样本对中的每段特征向量,使用线性规划的方法进行特征向量的选择；S9.基于每对训练样本选择出来的特征向量之间的汉明距离进行支持向量机的训练,然后对测试样本对按照步骤S1～S7的处理后,根据S8获得选择出来的特征向量,将测试样本对中获得的经过选择的特征向量之间的汉明距离输入至训练好的支持向量机内,从而进行虹膜的识别。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   李友       </td>   <td>中山大学</td>   <td>一种基于地理位置的网络重构方法</td>   <td>广东</td>   <td>CN107357858A</td>   <td>2017-11-17</td>   <td>本发明涉及一种基于地理位置的网络重构方法,包括以下步骤：S1、计算节点网络结构相似度；S2、计算用户地理位置相似度；S3、结合节点网络结构相似度和用户地理位置相似度,建立统一的相似度；S4、采用阈值处理的方法,对步骤S3得到的统一的相似度进行过滤,根据过滤结果重新构建一个有权网络。本发明结合用户地理位置这一动态特征对社交网络进行重构,重构后的网络图更容易获得有位置特征的网络特性；基于有权值的网络结构进行社区发现的结果具有地理位置信息的社区划分；构造后进行社区发现,可以得到在地理位置上面分布比较集中的社区。</td>   <td>一种基于地理位置的网络重构方法,其特征在于：以下步骤：S1、计算节点网络结构相似度；S2、计算用户地理位置相似度；S3、结合节点网络结构相似度和用户地理位置相似度,建立统一的相似度；S4、采用阈值处理的方法,对步骤S3得到的统一的相似度进行过滤,根据过滤结果重新构建一个有权网络。</td>   <td>G06F17/30;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              翁灵玲;                   周育人       </td>   <td>中山大学</td>   <td>一种基于新闻数据的个股情绪汇聚方法</td>   <td>广东</td>   <td>CN107357860A</td>   <td>2017-11-17</td>   <td>本发明涉及一种基于新闻数据的个股情绪汇聚方法,包括以下步骤：1.爬取新闻信息,形成新闻文档后存入文档储存数据库中；2.计算得出每篇文章的热度,去除重复文档；3.对新闻文档中的内容项进行预处理,形成文本集合；4.针对每个文本集合综合情绪分析和主题分析形成二元组集合,进行文本主题聚类分组；5.整合所有相关财经新闻,形成基于个股的三元组集合；6.将上述结果以个股为核心进行汇聚；7.选用可视化系统将结果展示给用户。本发明能为金融市场的投资者提供准确且可读性较高的精简主题情绪信息,帮助投资者花费更短的时间理解以及更好地做出投资判断,为量化基金公司提供重要的预测模型辅助信息。</td>   <td>一种基于新闻数据的个股情绪汇聚方法,其特征在于：包括以下步骤：S1.采用爬虫工具从各大新闻网站中爬取相关新闻信息的标题、时间、来源、内容、转载次数、评论次数,形成新闻文档d<sub>i</sub>；S2.将形成的新闻文档d<sub>i</sub>储存在文档储存数据库中；S3.计算得出每篇文章的热度,并去除重复文档；S4.以文档为单位对数据库中的新闻文档d<sub>i</sub>中的内容content<sub>i</sub>项进行预处理,形成文本集合wordSet<sub>i</sub>；S5.针对每个文本集合wordSet<sub>i</sub>综合情绪分析和主题分析,形成二元组集合{(topic<sub>1</sub>,sentiment<sub>1</sub>),(topic<sub>2</sub>,sentiment<sub>2</sub>),…,(topic<sub>k</sub>,sentiment<sub>k</sub>)}；S6.针对个股,整合所有相关财经新闻,求得某一支个股关于某一主题的情绪倾向以及其热度,形成基于个股的三元组集合{(topic<sub>2</sub>,sentiment<sub>2</sub>,heat<sub>1</sub>),(topic<sub>2</sub>,sentiment<sub>2</sub>,heat<sub>2</sub>),…,(topic<sub>k</sub>,sentiment<sub>k</sub>,heat<sub>k</sub>)}；S7.将S3#S6的结果以个股为核心进行汇聚,并存入文档储存数据库；S8.选用可视化系统将结果展示给用户。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄林冲;              黄帅;              梁禹;                   陶臣园       </td>   <td>中山大学</td>   <td>一种图像增强方法、装置及设备</td>   <td>广东</td>   <td>CN107358586A</td>   <td>2017-11-17</td>   <td>本发明公开了一种图像增强方法,包括：对原图像进行二值化处理,将原图像分割背景类图像和目标类图像；根据分割后的图像的种类,对分割后的图像采用相应尺度的retinex算法计算处理；对计算处理后的图像中包括的亮度图像进行双边滤波处理,对计算处理后的图像中包括的反射图像进行小波去噪处理；对双边滤波处理后的图像和小波去噪处理后的图像合成并进行伽马校正,得到增强后的图像。通过对两个尺度进行变换,有利于减少卷积计算量,对亮度图像进行双边滤波,以及对反射图像进行小波去噪,有利于去除图像的噪声且较少的损失图像细节,通过对合成的图像进行伽马校正,有利于增强图像全局。</td>   <td>一种图像增强方法,其特征在于,所述图像增强方法包括：对原图像进行二值化处理,将原图像分割背景类图像和目标类图像；根据分割后的图像的种类,对分割后的图像采用相应尺度的retinex算法计算处理；对计算处理后的图像中包括的亮度图像进行双边滤波处理,对计算处理后的图像中包括的反射图像进行小波去噪处理；对双边滤波处理后的图像和小波去噪处理后的图像合成并进行伽马校正,得到增强后的图像。</td>   <td>G06T5/00;G06T5/50;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         衣杨;              赵小蕾;              王玉娟;                   石晓红       </td>   <td>中山大学新华学院</td>   <td>基于插件的发票识别方法、及识别与管理系统</td>   <td>广东</td>   <td>CN107358232A</td>   <td>2017-11-17</td>   <td>本发明公开了一种基于插件的发票识别方法、及识别与管理系统；其中,识别方法包括：将预先创建的识别插件导入到动态链接库中；其中,识别插件基于适应于对应类型的发票的识别算法创建；获取待识别的发票的图像信息,及其类型；根据该待识别的发票的类型从动态链接库中调取对应的识别插件以对该待识别的发票的图像信息进行识别,进而获取所需的发票信息。本发明的优点是：1、员工能够自行录入发票信息,把发票信息提交到后台,供财务人员处理,从而减少财务人员的负担；2、每当有新类型的发票出现时,可以动态地向系统中添加针对该类型发票的识别算法,使系统能够识别新类型的发票,从工程角度解决多种发票识别问题。</td>   <td>一种基于插件的发票识别方法,其特征是,包括：将预先创建的识别插件导入到动态链接库中；其中,所述识别插件基于适应于对应类型的发票的识别算法创建；获取待识别的发票的图像信息,及其类型；根据该待识别的发票的类型从所述动态链接库中调取对应的识别插件以对该待识别的发票的图像信息进行识别,进而获取所需的发票信息。</td>   <td>G06K9/32;G06K9/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄俊艺;                   任传贤       </td>   <td>中山大学</td>   <td>一种基于正样本平衡约束的深度行人再标识方法</td>   <td>广东</td>   <td>CN107330355A</td>   <td>2017-11-07</td>   <td>本发明提供一种基于正样本平衡约束的深度行人再标识方法,该方法使用的残差网网络结构简洁并且得到广泛应用,足够深的网络结构增强了特征表达能力,并且不需要对网络结构进行特别设计；发现用残差网分类器进行图像特征提取,行人再标识的准确率便可以高于大部分的精心设计的方法；相比于二元组损失和三元组损失的方法,提升结构损失不需要特意生成有效的样本便可以达到类似的效果,并且利用整体的分布信息,学习到的梯度方向更加稳健有效；在提升结构损失的基础上,增加了正样本平衡约束,不仅可以控制正样本对的距离,并且可以平衡正样本对距离和负样本对距离的梯度,使得算法更容易训练以及提升算法性能。</td>   <td>一种基于正样本平衡约束的深度行人再标识方法,其特征在于,包括以下步骤：S1：输入数据训练数据集<img file="FDA0001292289730000011.TIF" wi="633" he="63" />其中,<img file="FDA0001292289730000012.TIF" wi="285" he="70" /><img file="FDA0001292289730000013.TIF" wi="71" he="55" />N是样本数量,d是图像像素,c是训练集中不同行人的数量,x<sub>i</sub>是d维的列向量,y<sub>i</sub>＝[y<sub>i1</sub>,y<sub>i2</sub>,y<sub>i3</sub>,…,y<sub>ic</sub>]<sup>T</sup>是c维的列向量,其中的元素等于1或0,并且<img file="FDA0001292289730000014.TIF" wi="266" he="70" />X＝[x<sub>1</sub>,x<sub>2</sub>,x<sub>3</sub>,…,x<sub>N</sub>],X是d行N列的矩阵；S2：使用softmax分类模型对网络进行预训练；S3：使用基于正样本平衡约束的提升结构损失对网络进行训练；S4：对测试样本图像进行特征提取；S5：利用得到的特征对测试样本进行最近邻KNN分类进而得到再标识结果。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         倪江群;                   叶健       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的数字图像隐写分析方法</td>   <td>广东</td>   <td>CN107330845A</td>   <td>2017-11-07</td>   <td>本发明设计一种基于卷积神经网络的数字图像隐写分析方法,包括以下步骤：S1.构建由多层卷积层串联形成的卷积神经网络；S2.对于第一层卷积层,采用高通滤波器对其卷积核进行初始化,然后采用截断线性单元激活函数作为卷积层的激活函数；S3.将数字图像输入至卷积神经网络中,卷积神经网络输出其是否经过隐写的结果。</td>   <td>一种基于卷积神经网络的数字图像隐写分析方法,其特征在于：包括以下步骤：S1.构建由多层卷积层串联形成的卷积神经网络；S2.对于第一层卷积层,采用高通滤波器对其卷积核和偏置进行初始化,然后采用截断线性单元激活函数作为卷积层的激活函数；S3.将数字图像输入至卷积神经网络中,卷积神经网络输出其是否经过隐写的结果。</td>   <td>G06T1/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         熊会元;                   罗志鹏       </td>   <td>中山大学;东莞中山大学研究院</td>   <td>一种用于榫卯结构节点力学建模的方法和系统</td>   <td>广东</td>   <td>CN107330230A</td>   <td>2017-11-07</td>   <td>本发明公开了一种用于榫卯结构节点力学建模的方法,包括：获得榫卯结构的节点相应的每一挤压区的挤压深度和挤压长度分别与节点转角之间的函数关系,其中,所述节点转角为所述节点在载荷作用下榫头围绕转动中心转动的角度；获得每一所述挤压区分别在弹性阶段和弹塑性阶段这两个阶段的挤压力和静摩擦力；获得所述节点的弯矩与所述节点的转角的函数关系；基于所述节点在变形过程的两个特征点,获得每一所述特征点处的节点的转角和弯矩,计算所述挤压区各阶段的刚度,获取简化模型。本发明所提供的用于榫卯结构节点力学建模的方法能够为榫卯结构节点的截面设计以及优化提供模型基础。</td>   <td>一种用于榫卯结构节点力学建模的方法,其特征在于,包括步骤：获得榫卯结构的节点相应的每一挤压区的挤压深度和挤压长度分别与节点转角之间的函数关系,其中,所述榫卯结构的榫头和卯口过盈配合,所述节点转角为所述节点在载荷作用下榫头围绕转动中心转动的角度；获得每一所述挤压区分别在弹性阶段和弹塑性阶段这两个阶段的挤压力和静摩擦力；获得所述节点的弯矩与所述节点的转角的函数关系；基于所述节点在变形过程的两个特征点,获得每一所述特征点处的节点的转角和弯矩,计算所述挤压区各阶段的刚度,获取简化模型；其中,所述节点在变形过程的两个特征点为所述挤压区刚好进入塑性阶段的屈服点和所述挤压区达到极限压应变的极限点。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              谢国栋;              崔明月;                   黄凯       </td>   <td>中山大学</td>   <td>基于CUDA实现的实时立体匹配及优化的方法</td>   <td>广东</td>   <td>CN107316324A</td>   <td>2017-11-03</td>   <td>本发明涉及计算机视觉的技术领域,更具体地,涉及基于CUDA实现的实时立体匹配及优化的方法。本发明是一种利用CUDA并行化处理来对左右输入图像进行密集的立体匹配,并且生成实时的视差图的方法。包括：对左右两图做census转换,生成一个字符序列,用汉明码距得到一个初始的cost,动态规划每个像素点8条路径,取一个最短的路径和来得到最终的cost,得到最初的一个密集的视差图；对左图利用k#means算法进行超像素分割,得到一个个超像素平面块,利用超像素平面拟合来优化初始视差进行优化。本发明还涉及到多任务GPU并行加速,具体涉及在NVIDA的CUDA架构并行实现多个任务,属于GPGPU计算领域。通过GPU多线程处理优化极大的缩小了计算时间,得到实时的视差图。</td>   <td>基于CUDA实现的实时立体匹配及优化的方法,其特征在于,包括以下步骤：S1.#选定一个框大小,对左右图像除边缘部分的每个像素都做census转换为字符序列；S2.#在给定的视差范围内,选定左图像素点,遍历右图范围内各个字符序列,计算汉明码距,得到初始的cost；S3.#路径聚合,通过动态规划找到每一个点的路径聚合值最小,得到能量函数；S4.#用WTA选取能量函数最小所对应的视差值；S5.#左右一致性检查进行后期校验,得到初始的密集视差图；S6.#将左图每个像素由RGB颜色空间转换为CIElab颜色空间；S7.#通过k#means聚合算法划分出超像素平面块,迭代几次直至收敛,并融合超像素平面块；S8.#对每个超像素平面多次采样,计算平面参数；S9.#用得到的平面参数计算得到新的视差值；S10.#对新的视差做插值运算,减小黑色块,平滑视差图。</td>   <td>G06T7/33;G06T7/55;G06T1/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              林培祥;              黄家诚;              邓成谦;              晏斌;                   李凯祥       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于权重的非极大值抑制的方法及装置</td>   <td>广东</td>   <td>CN107301431A</td>   <td>2017-10-27</td>   <td>本发明公开一种基于权重的非极大值抑制的方法,包括如下步骤：对检测目标的特征通过不同检测模型进行检测,检测后每个检测模型生成不同的检测信心分,及不同检则模型之间产生检测冗余；建立检测信心分的线性关系,求出最高检测信心分的最终值；根据所求出的最高检测信心分的最终值,更新检测模型中最高检测信心分；消除所产生的检测冗余,确定检测目标位置。本发明还公开了一种基于权重的非极大值抑制的装置,以实现上述方法。本发明技术方案提高行人检测的精准度及效率。</td>   <td>一种基于权重的非极大值抑制的方法,其特征在于,包括如下步骤：S10对检测目标的特征通过不同检测模型进行检测,检测后每个检测模型生成不同的检测信心分,及不同检则模型之间产生检测冗余；S20建立检测信心分的线性关系,求出最高检测信心分的最终值；S30根据所求出的最高检测信心分的最终值,更新检测模型中最高检测信心分；S40消除所产生的检测冗余,确定检测目标位置。</td>   <td>G06K9/62;G06K9/46;G06K9/03;G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁文平;                   刘伟       </td>   <td>中山大学</td>   <td>基于水体指数变异系数的水稻亚像元识别方法</td>   <td>广东</td>   <td>CN107273797A</td>   <td>2017-10-20</td>   <td>本发明公开了一种基于水体指数变异系数的水稻亚象元识别方法,包括如下步骤：S1.构建水体指数、植被指数、地表温度时序数据集；S2.剔除研究区域内非耕地像元；S3.根据地表温度确定作物生长季的时期；S4.计算各像元生长季内水体指数的变异系数；S5.确定水体指数变异系数与水稻种植面积比例的关系；S6.依据水体指数的变异系数进行水稻种植面积比例计算。该方法利用水稻的需水特性,根据水体指数变异系数随水稻种植面积比例的增加而降低,二者具有显著的线性相关性。通过设计水体指数的变异系数,用于水稻亚像元识别并计算种植面积的比例,具有不依赖于先验知识、鲁棒性好、分类精度高、识别能力强等特点。</td>   <td>一种基于水体指数变异系数的水稻亚象元识别方法,其特征在于,包括如下步骤：S1.构建水体指数、植被指数、地表温度时序数据集；S2.剔除研究区域内非耕地像元；S3.根据地表温度确定作物生长季的时期；S4.计算各像元生长季内水体指数的变异系数；S5.确定水体指数变异系数与水稻种植面积的比例的关系；S6.依据水体指数的变异系数进行水稻种植面积比例计算。</td>   <td>G06K9/00;G06Q50/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         闫立伟;              朱爽;              刘小林;              戚剑;              朱庆棠;              陆遥;              郭永泽;              喻莎;              卢宇彤;              张曦;              杜云飞;                   林焘       </td>   <td>中山大学附属第一医院;中山大学数据科学与计算机学院;中山大学国家超级计算广州中心</td>   <td>人体周围神经内部束型结构三维重建可视化集成方法</td>   <td>广东</td>   <td>CN107278316A</td>   <td>2017-10-20</td>   <td>一种人体周围神经内部束型结构三维重建可视化集成方法。该方法包括：获取人的周围神经,用碘剂染色联合冷冻干燥法制备离体神经标本；利用Micro#CT扫描经前期处理的周围神经,获得二维图像,并对所述二维图像进行二值化处理再根据纹理特征进行图像分割,获取神经束图像；将所述分割的图像利用超级计算机重建为可视化模型。该获取图像的方法使扫描精度达到了重建神经束的要求；可视化模型可为临床达到神经束间吻合提供立体化的解剖图谱；同时获取的三维数据可为生物制造神经生物材料到达精准修复建立了模板。</td>   <td>一种人周围神经束可视化模型的构建方法,所述构建方法包括：获取人的周围神经,用碘剂染色联合冷冻干燥方法处理所述周围神经；利用Micro#CT扫描预处理的周围神经,获得二维图像,并对所述二维图像进行二值化处理,再根据纹理特征进行图像分割,获取神经束图像；将所述神经束图像重建为可视化模型。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘冶;              张允聪;              莫伟铸;              曾广健;              林志远;              李宏浩;              郑燕璇;                   印鉴       </td>   <td>广州赫炎大数据科技有限公司;中山大学</td>   <td>一种网络数据采集、存储及处理方法及系统</td>   <td>广东</td>   <td>CN107273409A</td>   <td>2017-10-20</td>   <td>本发明涉及一种网络数据采集、存储及处理方法,包括以下步骤：S1：对网络数据进行采集；S2：对采集到的数据进行存储；S3：将存储的数据进行处理。其中,所述步骤S1中具体包括：S11：对URL进行存储管理分析；S12：进行自动化任务调度；S13：生成并行化爬取任务,将抓取的HTML文件进行保存；S14：解析HTML文档树,提取需要的字段信息。本发明还提供了一种用于实现上述方法的网络数据采集、存储及处理系统。相比于现有技术,本发明可以实现了对网络信息中有价值数据的采集,并通过离线解析文档提取结构化信息,比现有的网络数据采集装置有更好的采集效率和稳定性。</td>   <td>一种网络数据采集、存储及处理方法,其特征在于：包括以下步骤：S1：对网络数据进行采集；S2：对采集到的数据进行存储；S3：将存储的数据进行处理；其中,所述步骤S1中具体包括：S11：对URL进行存储管理分析；S12：进行自动化任务调度；S13：生成并行化爬取任务,将抓取的HTML文件进行保存；S14：解析HTML文档树,提取需要的字段信息；其中,所述步骤S11具体包括以下步骤：S111：通过URL数据库存储每个URL的访问量、有效访问量、正确解析入库次数、是否需要User#Agent参数、URL类型、URL平台；S112：通过白名单URL表格和黑名单URL表格将URL进行划分；所述白名单URL表示可正常爬取,所述黑名单URL表示不可正常爬取；S113：分析爬取黑名单中的URL的错误输出日志,并进行优化处理,优化处理后的URL转化为白名单。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              黄家诚;              林培祥;              晏斌;              邓成谦;                   李凯祥       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种用于人脸识别的特征提取方法</td>   <td>广东</td>   <td>CN107273793A</td>   <td>2017-10-20</td>   <td>本发明提供一种用于人脸识别的特征提取方法,采用同步局部二进制特征学习与编码(SLBFLE)的方法,提取人脸图像的像素差向量,设映射矩阵W把像素差向量转换成低维度的局部二进制码矩阵B,然后通过字典矩阵D转换为特征直方图,通过迭代的方法来优化映射矩阵W、字典矩阵D和系数矩阵A,从而得到特征直方图。通过本发明可以更好的防止灯光变化和表情微变带来的影响,提高了对人脸识别的正确率,而且抗干扰性比LBP方法要好,更适用于环境复杂的场所,可以很好的应用于教室人脸签到系统的特征提取。</td>   <td>一种用于人脸识别的特征提取方法,其特征在于,包括以下步骤：S1：设N个训练样本图像为X＝[x<sub>1</sub>,x<sub>2</sub>,…,x<sub>N</sub>]∈R<sup>d×N</sup>,x<sub>n</sub>∈R<sup>d</sup>,其中d为特征值个数,提取出图像的像素差向量；S2：设映射矩阵W把像素差向量转换成维度为K的局部二进制码矩阵B,然后通过字典矩阵D转换为特征直方图；训练样本的二进制码矩阵为：B＝0.5×(sgn(W<sup>T</sup>X)+1)∈{0,1}<sup>K×N</sup>###(1)其中当W<sup>T</sup>X&lt;0时,sgn(W<sup>T</sup>X)＝0,否则,sgn(W<sup>T</sup>X)＝1；S3：令矩阵A＝[a<sub>1</sub>,a<sub>2</sub>…,a<sub>N</sub>]为相应的系数矩阵,制定以下损失函数J优化问题：<maths num="0001"><math><![CDATA[<mrow><mo>&CenterDot;</mo><mtable><mtr><mtd><mrow><munder><mrow><mi>min</mi><mi>J</mi></mrow><mrow><mi>W</mi><mo>,</mo><mi>D</mi><mo>,</mo><mi>A</mi></mrow></munder><mo> =</mo><msub><mi>J</mi><mn>1</mn></msub><mo>+</mo><msub><mi>&lambda;</mi><mn>1</mn></msub><msub><mi>J</mi><mn>2</mn></msub><mo>+</mo><msub><mi>&lambda;</mi><mn>2</mn></msub><msub><mi>J</mi><mn>3</mn></msub><mo>+</mo><msub><mi>&lambda;</mi><mn>3</mn></msub><msub><mi>J</mi><mn>4</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><mo>|</mo><mo>|</mo><mrow><mo>(</mo><mrow><mi>B</mi><mo>-</mo><mn>0.5</mn></mrow><mo>)</mo></mrow><mo>-</mo><mi>D</mi><mi>A</mi><mo>|</mo><msubsup><mo>|</mo><mi>F</mi><mn>2</mn></msubsup><mo>+</mo><mi>&kappa;</mi><mo>|</mo><mo>|</mo><mi>A</mi><mo>|</mo><msub><mo>|</mo><mn>1</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><msub><mi>&lambda;</mi><mn>1</mn></msub><mo>|</mo><mo>|</mo><mrow><mo>(</mo><mrow><mi>B</mi><mo>-</mo><mn>0.5</mn></mrow><mo>)</mo></mrow><mo>-</mo><msup><mi>W</mi><mi>T</mi></msup><mi>X</mi><mo>|</mo><msubsup><mo>|</mo><mi>F</mi><mn>2</mn></msubsup></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><msub><mi>&lambda;</mi><mn>2</mn></msub><mo>|</mo><mo>|</mo><mrow><mo>(</mo><mrow><mi>B</mi><mo>-</mo><mn>0.5</mn></mrow><mo>)</mo></mrow><mo>&times;</mo><msup><mn>1</mn><mrow><mi>N</mi><mo>&times;</mo><mn>1</mn></mrow></msup><mo>|</mo><msubsup><mo>|</mo><mi>F</mi><mn>2</mn></msubsup></mrow></mtd></mtr><mtr><mtd><mrow><mo>-</mo><msub><mi>&lambda;</mi><mn>3</mn></msub><mi>t</mi><mi>r</mi><mrow><mo>(</mo><mrow><mrow><mo>(</mo><mrow><mi>B</mi><mo>-</mo><mn>0.5</mn></mrow><mo>)</mo></mrow><msup><mrow><mo>(</mo><mrow><mi>B</mi><mo>-</mo><mn>0.5</mn></mrow><mo>)</mo></mrow><mi>T</mi></msup></mrow><mo>)</mo></mrow></mrow></mtd></mtr></mtable></mrow>]]></math><img file="FDA0001282449110000011.TIF" wi="777" he="374" /></maths>其中,λ<sub>1</sub>、λ<sub>2</sub>、λ<sub>3</sub>是优化时的权重参数；S4：通过迭代的方法来优化映射矩阵W、字典矩阵D和系数矩阵A,从而通过得到的最优的映射矩阵W和字典矩阵D计算得到特征直方图。</td>   <td>G06K9/00;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   汤梦玥       </td>   <td>中山大学</td>   <td>一种基于图像分割的深度图像修复方法</td>   <td>广东</td>   <td>CN107248143A</td>   <td>2017-10-13</td>   <td>本发明涉及一种基于图像分割的深度图像修复方法,通过分割对应的彩色图像作为指导信息,结合数据拟合方法,进行缺失的深度信息的估算工作。本发明提供的基于图像分割的深度图像修复方法,得到的深度图像修复结果,无论是在图像的边缘区域还是非边缘区域,都与现实中物体的深度信息更为接近。</td>   <td>一种基于图像分割的深度图像修复方法,其特征在于：通过分割对应的彩色图像作为指导信息,结合数据拟合方法,进行缺失的深度信息的估算工作。</td>   <td>G06T5/00;G06T7/10;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              陈江滔;              陈荣军;              谢舜道;              朱雄泳;              曾衍瀚;                   路崇       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>一种可视化二维码的编码方法</td>   <td>广东</td>   <td>CN107247984A</td>   <td>2017-10-13</td>   <td>本发明公开一种可视化二维码的编码方法,包括输入模块、图片预处理模块、图片通道提取模块、图片编码模块、图片通道合成模块和输出模块,提供基于信息隐藏的可视化二维码的编码方法,采用单位图像块的平均值作为运算目标,通过排序的方法确定编码的比特的方法。从美观性角度,此编码方法在保证解码鲁棒性的同时改善了图片编码的美观性,更符合人眼特性；从速度角度,此编码和解码方法节约了编码和解码的时间,更能适应现实环境的使用情况。</td>   <td>一种可视化二维码的编码方法,其特征在于,包括以下步骤：S1：输入模块：输入图像、输入信息和输入阈值δ；S2：图像预处理模块：根据比特流的长度重新调整图像的大小；S3：图像通道提取模块：在重新调整形成的图像上提取图像通道作为处理的对象；S4：图片编码模块：利用比特流对图像块编码；S5：图像通道合成模块：将图像通道进行合成,所有比特都编码后,得到一个编码后的图像<img file="FDA0001297831780000011.TIF" wi="59" he="62" />与原来图像的CbCr颜色通道合成新的图像；S6：输出模块：在新的图像基础上加上可视化二维码的定位模块,形成可视化二维码。</td>   <td>G06K19/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         葛鹏飞;                   任传贤       </td>   <td>中山大学</td>   <td>一种基于竞争学习的深度聚类方法</td>   <td>广东</td>   <td>CN107229945A</td>   <td>2017-10-03</td>   <td>本发明公开一种基于竞争学习的深度聚类方法,该方法的深度聚类模型使用竞争性聚类损失做为深度网络额外的损失,对网络加以聚类的约束,在目标优化过程中使得误差极小。竞争性聚类损失使得任意一个样例到其聚类中心的距离比不同聚类的样例到该聚类中心的距离大一个正的常数,通过额外的竞争性聚类损失,深度网络学习到的特征空间是簇内紧凑、簇间稀疏的,因此更加适合于聚类任务。最后,引入有效聚类集的概念加强模型的稳定性,有效聚类集由贝叶斯框架计算高后验概率的样例组成。</td>   <td>一种基于竞争学习的深度聚类方法,其特征在于,引入竞争性聚类损失和有效聚类集,包括以下步骤：S1.输入数据和网络参数,并进入网络循环体；其中输入的数据和网络参数包括：样本集D＝{x<sub>1</sub>,x<sub>2</sub>,…,x<sub>N</sub>}、聚类中心数K、最大迭代次数T、聚类可信阈值γ和最小间隔α；其中样本集D＝{x<sub>1</sub>,x<sub>2</sub>,…,x<sub>N</sub>}是一组不含类别属性或标签的数据；S2.使用网络本身的自编码机的最小重构损失加上额外的竞争聚类损失更新网络参数,使用更新网络参数后的网络提取深度特征,用于S3中的聚类；S3.将S2中提取的深度特征输入已有的聚类模型进行聚类,更新聚类结果,利用更新的聚类结果,计算可信聚类集以筛选出聚类可信度高的样例,其中聚类可信度高是指其聚类可信值大于聚类可信阈值γ；S4.在交替进行S2和S3更新轮数达到最大迭代次数T之前,将S3中的可信聚类集输入到S2进行新一轮的更新；当达到最大迭代次数T时,输出S3得到的更新后的聚类结果。</td>   <td>G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              伍鹏飞;              周育人;                   刘树郁       </td>   <td>中山大学</td>   <td>一种针对地理位置敏感app的个性化推荐方法</td>   <td>广东</td>   <td>CN107220269A</td>   <td>2017-09-29</td>   <td>本发明涉及一种针对地理位置敏感app的个性化推荐方法,具体实施主要包括以下步骤:步骤1、原始数据的获取和处理；步骤2、城市对应app敏感度计算；步骤3、评分矩阵预测并给出app推荐。通过对地理位置敏感app的敏感度计算,带地理位置权重的矩阵分解方法,通过这两个方面的技术改进,使得推荐评分的预测更加准确。</td>   <td>一种针对地理位置敏感app的个性化推荐方法,其特征在于包括以下步骤:步骤1、原始数据的获取和处理；步骤2、城市对应app敏感度计算；步骤3、评分矩阵预测并给出app推荐。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              晏斌;              林培祥;              邓成谦;              黄家诚;                   李凯祥       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于防伪溯源系统的用户群体划分方法及系统</td>   <td>广东</td>   <td>CN107220831A</td>   <td>2017-09-29</td>   <td>本发明提供一种基于防伪溯源系统的用户群体划分方法及系统,用户通过防伪溯源系统查询商品真伪能结合用户自身的特征信息,商品的特征信息,查询信息,对用户群体进行划分,使后期商家的营销,厂家的生产更具有针对性。将防伪溯源系统中得到的信息充分挖掘,提高系统的创造性。</td>   <td>一种基于防伪溯源系统的用户群体划分方法,其特征在于,包括以下步骤：S1：获取用户的特征信息,商品的特征信息和查询的特征信息；S2：根据获取的信息,利用数据清洗、数据集成、数据变换和数据归约方法对数据进行预处理,得到的样本集D,D＝{x<sub>1</sub>,x<sub>2</sub>,...,x<sub>m</sub>}包含m个无标记样本,每个样本x<sub>i</sub>＝(x<sub>i1</sub>；x<sub>i2</sub>,...,x<sub>in</sub>)是一个n维特征向量,反映了用户的相关特征信息；S3：根据预处理得到的样本集,利用改进的模糊聚类算法对用户群体进行划分并标记,同时得到分类模型；S4：根据分类模型对新用户进行划分,并修正模型参数和更新所有用户的划分结果；S5：发送用户群体划分结果到数据库,分类储存信息。</td>   <td>G06Q30/00;G06Q30/02;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              孙黎波;              黎丹;                   黄凯       </td>   <td>中山大学</td>   <td>基于色彩图像和红外图像融合的即时定位与建图系统</td>   <td>广东</td>   <td>CN107204015A</td>   <td>2017-09-26</td>   <td>本发明公开了一种基于色彩图像和红外图像融合的即时定位与建图算法,该算法可以适用于在光照充足环境以及低光照环境下的即时定位与建图。在具体实现过程中该算法主要通过提取色彩图像和红外图像中的特征点来创建同时包含色彩图像地图点和红外图像地图点的地图,并且在达到新的位置时通过获取到的新的信息来不断地更新已经创建好的地图,同时利用现有的地图定位出当前的位置。该算法由于同时使用了色彩图像和红外图像,因此综合考虑了周围环境的色彩信息和红外信息,从而使得该算法与传统的基于色彩图像的算法相比具有更高的光照鲁棒性、更好的适用范围,能够适用于使用色彩图像定位失败的低光照环境。</td>   <td>基于色彩图像和红外图像融合的即时定位与建图系统,其特征在于,包括定位模块、建图模块、优化模块三大部分,定位模块基于已经被创建出来的包含红外特征地图点和色彩特征地图点的地图来进行,并且通过获取的色彩图像和红外图像来不断更新已经被创建的地图用于后续定位；建图模块创建同时包含色彩图像特征和红外图像特征的地图点,并在定位完成时根据新的数据源不断的更新现有地图,以及对地图点中错误的坏点进行剔除；回环优化模块通过回环探测的方式对创建好的全局地图进行优化,在进行回环探测时同时使用色彩图像和红外图像进行回环探测。</td>   <td>G06T7/73;G06T11/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;              陈军祥;              高凯诗;              刘勤意;                   秦景辉       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于知识点目标集的学习路径规划方法</td>   <td>广东</td>   <td>CN107203584A</td>   <td>2017-09-26</td>   <td>本发明提供一种基于知识点目标集的学习路径规划方法,本发明所提供的基于目标集的学习路径规划方法是在复杂的知识网络之下,规划所要学习的目标知识点集,然后根据学习者当前的学习状态,采用搜索算法找出覆盖完整目标知识点集的知识网络,进而制定出最佳的学习路径。在学习过程中系统对学习者的学习状态进行分析,动态地改变学习路径,达到学习指导的效果。实现快速掌握点目标知识点集,提高学习者的学习效率。</td>   <td>一种基于知识点目标集的学习路径规划方法,其特征在于,包括以下步骤：S1：构建一个三维知识网络,设置成有向无权图G＝{V,E},其中V对应知识点集合,E对应知识点之间的前后驱或者父子关系集合；S2：在三维知识网络G下,对于某种人才培养或者学习目标,按规划提取目标所需要掌握的知识点集合,形成学习者的目标学习知识点集T<sub>A</sub>；S3：对某个具体学习者A,依据历史数据或者在线评测确定该学习者在知识网络G下已经掌握的学习知识点集合S<sub>A</sub>,即学习者的当前学习状态或初始学习状态；S4：对比学习者A当前的学习知识点集合S<sub>A</sub>与目标学习知识点集合T<sub>A</sub>在三维知识网络G下的位置分布,设定从当前知识点集合S<sub>A</sub>为起点,以目标集知识点T<sub>A</sub>为目标,在此三维知识网络G下,基于某种搜索算法计算或者规划一个能够覆盖所有目标知识点集合的知识子网G<sub>A</sub>,这个知识子网是学习者A必须要完成学习的知识点集合；S5：依据G<sub>A</sub>充分考虑知识点的前后关系及可并发性,规划一个学习路径R<sub>A</sub>,这路径支持非相关知识点的并行性,确保前后或父子关系知识点的学习顺序；S6：学习者A依据R<sub>A</sub>学习,实时监控并记录其学习进度和状态,对比其与其他同等级学习者的进度并反馈,以指引其是否需要调整学习速度或者时间。</td>   <td>G06F17/30;G06N5/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭开华;              马金晶;                   张少敏       </td>   <td>中山大学</td>   <td>一种LNG港口安全风险评估系统</td>   <td>广东</td>   <td>CN107194537A</td>   <td>2017-09-22</td>   <td>本发明涉及风险分析技术领域,公开了一种LNG港口安全风险评估系统,包括：系统用户管理模块,用于用户登录和保密功能；工作选择模块,可选择的分析模块包括个人风险分析模块和社会风险分析模块；其中,个人风险分析模块,用于个人风险值的分析计算,并绘制整体个人风险分布图,然后以图纸的形式输出；社会风险分析模块,用于区域社会风险的分析计算,并绘制出区域社会风险图,然后以图纸的形式输出。本发明可以对LNG多危险源区域、LNG运输航道进行定量风险分析,为LNG港区应急能力配置、区域安全规划与布局工作提供科学支撑,对监管部门决策、安全投资和效益最优化、减少人员伤亡和财产损失等都具有十分重要的意义。</td>   <td>一种LNG港口安全风险评估系统,其特征在于,包括：系统用户管理模块,用于用户登录和保密功能；工作选择模块,用于分析模块的选择,可选择的分析模块包括：个人风险分析模块和社会风险分析模块；其中,个人风险分析模块,用于LNG多危险源区域或LNG运输航道的个人风险值的分析计算,并绘制出LNG多危险源区域的整体个人风险分布图、LNG运输航道的整体个人风险分布图,将绘制出的个人风险分布图以图纸的形式输出；社会风险分析模块,用于区域社会风险的分析计算,并绘制出区域社会风险图,将绘制的社会风险图以图纸的形式输出。</td>   <td>G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭远祥;                   叶涛       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于LED调制的实体图片水印生成方法及系统</td>   <td>广东</td>   <td>CN107194862A</td>   <td>2017-09-22</td>   <td>本发明涉及一种基于LED调制的实体图片水印生成方法,在图片的周围布置LED灯,然后为LED灯调制一组控制信号；将调制的控制信号输入至LED灯中使LED灯发生闪烁,并使闪烁的LED灯发出的灯光投射在实体图片上,此时闪烁的LED灯在时序上形成亮暗相间的条纹,亮暗相间的条纹作为相应的水印信息。</td>   <td>一种基于LED调制的实体图片水印生成方法,其特征在于：在图片的周围布置LED灯,然后为LED灯调制一组控制信号；将调制的控制信号输入至LED灯中使LED灯发生闪烁,并使闪烁的LED灯发出的灯光投射在实体图片上,此时闪烁的LED灯在时序上形成亮暗相间的条纹,亮暗相间的条纹作为相应的水印信息。</td>   <td>G06T1/00;H05B33/08;F21Y115/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;              占明明;              葛又铭;                   戴戈南       </td>   <td>中山大学</td>   <td>面向搜索引擎的中英混合查询纠错的方法及系统</td>   <td>广东</td>   <td>CN107193921A</td>   <td>2017-09-22</td>   <td>本发明涉及一种面向搜索引擎的中英混合查询纠错的方法及系统,该方法或系统基于N#gram语言模型以及多种纠错策略,实现对搜索引擎中带有部分错误的中英文混合查询的纠错。</td>   <td>一种面向搜索引擎的中英混合查询纠错的方法,其特征在于：包括以下步骤：S1.运用爬虫技术爬取互联网网页内容；S2.将步骤S1爬取的网页内容和搜索日志作为语料构建出语言模型,以及构建基于拼音的字典树、英文索引表和分词词典；S3.对于用户输入的查询串,首先运用语言模型对其进行评估,计算其合理性概率,若其合理性概率低于设定的阈值A,或者基于查询串得到的搜索结果的数量少于阈值B,则转入步骤S4的纠错处理；S4.(1)若查询串中只包含有中文,则执行以下纠错过程：S101.若输入的查询串为单字,则不执行纠错过程或执行步骤S104,否则执行步骤S102；S102.将查询串转换成拼音,然后利用编辑距离算法、最大模糊匹配算法在字典树中查找匹配的的候选集合,将查找匹配的候选集合作为纠错建议；若在字典树中查到不到匹配的候选集合,则执行步骤S103；S103.将查询串进行N元切分,将切分得到的所有子串分别利用编辑距离算法、最大模糊匹配算法在字典树中查找匹配的候选集合；若某一子串查找到匹配的候选集合,则将该子串前面部分的字符串和后面部分的字符串分别作为两个查询串执行步骤S101,进入递归搜索；S104.递归搜索结束后,得到多个候选集合,此时采用语言模型对各个候选集合进行合理性评分,将评分最高的候选集合作为纠错建议；(2)若输入的查询串包含有中文和字母,则执行以下纠错过程：S201.首先将字符串按照S101~S103的步骤进行匹配的候选集合的查找,若查找得到匹配的候选集合,则给出相应的纠错建议；否则将查询串分割成中文和字母串,将中文按照(1)进行纠错处理,而至于字母串,则执行以下处理：S202.将字母串以空格为分隔符进行分割,得到字符串集合,将字符串集合中的每个字符串按照步骤S101~S103的步骤进行候选集合的匹配查找,若某一字符串查找得到匹配的候选集合,则给出相应的纠错建议,否则该字符串进入步骤S203的英文纠错流程；S203.判断字符串是否为一个正确的英文单词,若是则进行下一字符串是否属于正确的英文单词的判断,否则根据预先建立的英文索引表查找出候选集合,然后利用最小编辑距离算法计算候选集合与字符串的相似度,将相似度最高的单词作为纠错建议；(3)若输入的查询串值只包含有字母,则执行以下纠错过程：S301.将查询串以空格为分隔符进行分割,得到字符串集合,将字符串集合中的每个字符串按照步骤S101~S103的步骤进行候选集合的匹配查找,若某一字符串查找得到匹配的候选集合,则给出相应的纠错建议；若某一字符串查找不到匹配的候选集合,则按照步骤S203的内容进行英文纠错的处理；S302.当字符串集合中所有的字符串采纳纠错建议进行纠错处理后,将经过纠错处理的字符串按照顺序拼接起来,将拼接的结果作为查询串的纠错建议。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张晓娜;              江明;              李正鹏;              区志行;                   张朝婷       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;广州极汇信息科技有限公司;中山大学</td>   <td>一种用于可见光成像定位的条纹识别和信息检测方法</td>   <td>广东</td>   <td>CN107169952A</td>   <td>2017-09-15</td>   <td>本发明提供一种用于可见光成像定位的条纹识别和信息检测方法,该方法在接收机CMOS传感器前面放置一层减光材料来产生清晰的明暗条纹图像；从得到的明暗条纹图片中,获取有效的条纹区域；将得到的条纹区域转换为灰度图像,对灰度图像进行处理得到明暗条纹所对应的总像素行数；根据S3中得到的明暗条纹所对应的总像素行数计算得到灰度图像的估计行数值,利用该估计行数值计算出估计的FSOOK信号频率。提高了经FSOOK调制的可见光信号所产生的明暗条纹的清晰度,避免了明暗条纹图片中的高光干扰问题,具有较好的信息检测性能,从而可增加正确解调可见光信号的距离,同时还具有很低的实现复杂度。</td>   <td>一种用于可见光成像定位的条纹识别和信息检测方法,该方法用于采用FSOOK调制的LED发射机,且LED灯具安装有灯罩和基于CMOS图像传感器的接收机所组成的可见光通信系统,其特征在于,包括以下步骤：S1：在接收机CMOS传感器前面放置一层减光材料来产生清晰的明暗条纹图像；S2：从得到的明暗条纹图片中,获取有效的条纹区域；S3：将得到的条纹区域转换为灰度图像,对灰度图像进行处理得到明暗条纹所对应的总像素行数；S4：根据S3中得到的明暗条纹所对应的总像素行数计算得到灰度图像的估计行数值,利用该估计行数值计算出估计的FSOOK信号频率。</td>   <td>G06T7/00;H04B10/116</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗洁;                   韦妙鸾       </td>   <td>中山大学</td>   <td>一种通过力台压力中心数据提取身体平衡振荡起始时间的方法</td>   <td>广东</td>   <td>CN107169406A</td>   <td>2017-09-15</td>   <td>本发明涉及一种通过力台压力中心数据提取身体平衡振荡起始时间的方法,包括以下步骤：S1.基于力台压力中心数据重建身体平衡振荡信号；S2.特征点检测及其第一次筛选；S3.特征点的第二次筛选,将通过筛选的发生时刻最早的特征点对应的发生时刻确定为身体平衡振荡的起始时间。</td>   <td>一种通过力台压力中心数据提取身体平衡振荡起始时间的方法,其特征在于：包括以下步骤：S1.基于力台压力中心数据重建身体平衡振荡信号；S2.特征点检测及其第一次筛选；S3.特征点的第二次筛选,将通过筛选的发生时刻最早的特征点对应的发生时刻确定为身体平衡振荡的起始时间。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   马伟       </td>   <td>中山大学</td>   <td>基于深度局部特征的人脸属性识别方法</td>   <td>广东</td>   <td>CN107169455A</td>   <td>2017-09-15</td>   <td>本发明提供的方法是基于局部区域特征来进行人脸属性识别的,局部区域特征与全部区域特征相比更有鲁棒性和判别力；再者,利用降维和多尺度特征融合,比传统的降维方式和仅使用最后一层特征的方式,能得到更多有用的深度层级视觉特征；利用局部区域定位、分类和局部属性识别,能够更好的找到各属性所对应的人脸关键特征区域。</td>   <td>基于深度局部特征的人脸属性识别方法,其特征在于：包括以下步骤：一、训练阶段S1.对于训练集中的每一幅人脸图像,利用深度卷积神经网络的不同卷积层计算得到多个尺度下的特征图；S2.利用得到的多个尺度下的特征图和人脸图像N个局部区域的边界框类标,分别为N个局部区域训练相应的局部区域定位网络；其中N为大于2的整数；S3.根据训练集中的每一幅人脸图像的多尺度特征图和N个局部区域的边界框类标,计算各个局部区域的多尺度特征图；S4.将计算得到的各个局部区域的多尺度特征图进行降维,然后将降维后得到的各个局部区域的特征图按其局域区域所在的位置拼接在一起然后进行特征融合；S5.将步骤S4得到的融合特征送入各局部区域的识别网络,训练局部属性分类器；二、测试阶段S6.利用步骤S1提取测试集中人脸图像多个尺度下的特征图,然后利用步骤S2得到的局部区域定位网络从多个尺度下的特征图中定位出N个局部区域；S7.利用定位出的N各局部区域的边界框类标及人脸图像多个尺度下的特征图算各个局部区域的多尺度特征图；S8.对计算得到的各个局部区域的多尺度特征图进行降维,然后将降维后得到的各个局部区域的特征图按其局域区域所在的位置拼接在一起然后进行特征融合；S9.利用步骤S5训练好的局部属性分类器对融合特征进行属性识别,得到各局部区域相关的人脸属性,将各个局部区域相关的人脸属性组合起来,得到测试集中人脸图像的人脸属性。</td>   <td>G06K9/00;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐冰;                   张东       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种中餐食物图像的分割方法</td>   <td>广东</td>   <td>CN107154044A</td>   <td>2017-09-12</td>   <td>本发明提供的方法通过采集中餐食物图像的纹理图像进行后续处理来实现对图像的分割,分割的过程中无需采集多种图像特征,且应用该方法可以提高中餐食物图像分割的准确率,从而助于中餐食物图像的识别。</td>   <td>一种中餐食物图像的分割方法,其特征在于：包括以下步骤：S1.使用纹理增强滤波器对拍摄的中餐食物图像进行m个不同尺度参数下的滤波,得到图像在m个不同尺度参数下的纹理图像；所述m的取值范围为8～16；S2.对于步骤S1得到的16幅纹理图像分别计算其均值,并利用计算得到的均值作为阈值来对相应的纹理图像进行二值化,获得纹理图像在阈值条件下的前景区域和背景区域；S3.对于每张纹理图像分别求取其前景区域的中心点,以用作放置高斯函数的位置,以前景区域包含的像素点数量的k倍作为标准差,构造对应的高斯掩膜函数,其中k的取值范围为0.3～0.5；将得到的16个高斯掩膜函数乘以相对应的权重参数后相加,得到最终的高斯掩膜；S4.将得到的高斯掩膜与中餐食物图像在纹理增强滤波器尺度参数为[0.5m]时所产生的纹理图像相乘,将其得到的结果记为图G,其中[0.5m]表示对0.5m进行取整操作；采用SLIC方法对图G进行超像素分割,分割之后,得到对图像中每个像素点所属的块的类别,称为标记矩阵L,把L记作图G的标记图；S5.对图G中的每个像素具有相同类别标记的像素区域计算出其均值Gk,将均值Gk与图G的整体均值Gu进行比较,若Gk&gt;Gu,则将具有相同标记的像素区域的各个像素点的像素值设为1,并将具有相同标记的像素区域标记为前景区域,否则将具有相同标记的像素区域的各个像素点的像素值设为0,并将具有相同标记的像素区域标记为背景区域；S6.对前景区域和背景区域进行形态学的开运算和闭运算,以平滑前景区域和背景区域的边缘区域,然后对前景区域和背景区域进行分割。</td>   <td>G06T7/11;G06T7/194</td>  </tr>        <tr>   <td>中国专利</td>   <td>              富明慧       </td>   <td>中山大学</td>   <td>一种将汉字语句转换为盲文的方法</td>   <td>广东</td>   <td>CN107145478A</td>   <td>2017-09-08</td>   <td>本发明提供了一种将汉字语句转换为盲文的方法,包括以下步骤：S1、将汉字语句中的每个汉字转换为计算机可识别的4个字节的汉字全息码；S2、根据汉字全息码中第3字节和第4字节记录的信息,利用计算机将每个汉字的汉字全息码转换为盲文。本发明采用汉字全息码作为中间转换格式,在确定汉字字形的同时,也唯一确定了其读音,还明确了是否与后面汉字分词,包含了汉字明盲转换时所需的全部信息。利用本发明中的汉字全息码作为中间转换方式,能从根本上克服目前汉字盲文阅读中普遍存在的“费解”、“误解”等问题。</td>   <td>一种将汉字语句转换为盲文的方法,其特征在于,包括以下步骤：S1、将汉字语句中的每个汉字转换为计算机可识别的4个字节的汉字全息码；其中,将单个汉字转换为计算机可识别的4个字节的汉字全息码的方法为：将该汉字的内码作为所述汉字全息码的前2字节；将汉字全息码第3字节的其中一位定义为分词标识码,以分词标识码的不同数值标识该汉字是否与下一个汉字组成分词；将汉字全息码的第4字节定义为读音标识码,统计该汉字的所有读音并进行编号,以读音标识码的数值大小标识该汉字在上下文中正确读音的编号；S2、根据汉字全息码中第3字节和第4字节记录的信息,利用计算机将每个汉字的汉字全息码转换为盲文。</td>   <td>G06F17/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              朱亚星;              陈荣军;              谢舜道;              朱雄泳;                   曾衍瀚       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>一种海量图片存储和搜索的方法</td>   <td>广东</td>   <td>CN107145502A</td>   <td>2017-09-08</td>   <td>本发明公开一种海量图片存储和搜索的方法,其架构为两级索引方式,在服务器上建立两级索引机制,由服务器接收来自于客户端的请求；所述索引机制的第一层为哈希桶,第二层为红黑树。本发明旨在解决大规模图片快速和便捷存储和搜索的问题,缩短图片数据索引时间,提高海量图片数据存取检索效率,本发明的算法稳定性和扩展性良好,使得使用者可以快速方便地进行图片的存储和搜索。</td>   <td>一种海量图片存储和搜索的方法,其架构为两级索引方式,其特征在于,在服务器上建立两级索引机制,由服务器接收来自于客户端的请求；所述索引机制的第一层为哈希桶,第二层为红黑树。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              黄德亮;              姚磊;              王作辉;                   袁德胜       </td>   <td>中山大学;上海汇纳信息科技股份有限公司</td>   <td>基于深度学习及多特征点融合的行人检测方法</td>   <td>广东</td>   <td>CN107145845A</td>   <td>2017-09-08</td>   <td>本发明涉及一种基于深度学习及多特征点融合的行人检测方法,在训练阶段首先采集应用场景下的行人图像并标注图像中行人的头肩部位然后将这些行人样本用于模型训练,模型训练分为两个步骤：1)以行人的头肩图像作为训练样本并训练一个行人头肩部位的二分类模型；2)用步骤1)训练得到的模型参数来以迁移学习的方式来初始化行人检测模型的部分参数。本发明可以在一定程度上克服行人相互遮挡的问题；采用深度学习方法来提取行人特征,可以更好地克服行人衣着、姿态、所处背景、光照条件等因素发生改变的实际应用问题；还可以有效地克服行人多姿态,行人多尺度以及行人相互遮挡等问题,大大提高了行人检测的准确率和鲁棒性。</td>   <td>一种基于深度学习及多特征点融合的行人检测方法,包含训练阶段和检测阶段,其特征在于：训练阶段首先采集应用场景下的行人图像并标注图像中行人的头肩部位然后将这些行人样本用于模型训练,其中模型训练分为两个步骤：1)以行人的头肩图像作为训练样本并采用Triplet#Loss的方式来训练一个行人头肩部位的二分类模型；2)用步骤1)训练得到的模型参数来以迁移学习的方式来初始化行人检测模型的部分参数；该行人检测模型作为最后检测阶段使用的模型,采用了端到端的训练方式,包含了候选区域提取、行人特征提取及特征分类的功能。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              何娜;              陈佳捷;              罗子泉;                   朱睿       </td>   <td>中山大学;佛山市新东方电子技术工程有限公司</td>   <td>一种基于方向梯度特征学习的目标检测方法</td>   <td>广东</td>   <td>CN107145894A</td>   <td>2017-09-08</td>   <td>一种基于方向梯度特征学习的目标检测方法。本发明提供的方法以图像块中不同大小矩形区域内梯度大小之和为特征,基于boosting进行筛选,产生图像块的方向梯度特征,可替代手工设计的HOG特征。对不同目标的检测结果也表明,本发明所提出的方向梯度特征相对于传统的HOG特征能获得更好的检测效果。</td>   <td>一种基于方向梯度特征学习的目标检测方法,其特征在于：包括以下步骤：(1).方向梯度特征学习S1.采集N<sub>+</sub>个只含目标的图像区域和N<sub>#</sub>个不含目标的图像区域构成图像区域训练集X,在图像区域上每隔s个像素定义一个大小为w×h像素的图像块；S2.对于训练集X中的每个图像区域,计算其每个像素点的梯度大小及方向；S3.将梯度方向分成l个连续的方向区间,然后为每个图像区域生成l幅方向梯度图,其具体过程如下：S31.对于方向区间g的方向梯度图,若图像区域某个位置像素点的梯度方向在方向区间g内,则该方向梯度图在相同位置的取值设为步骤S2计算得到的像素点的梯度大小,否则将该方向梯度图在此处的取值置为0；S32.通过对每个像素点进行步骤S31的操作得到训练集X中每个图像区域在方向区间g的方向梯度图；S33.通过对每个方向区间进行步骤S31、S32的操作得到训练集X中每个图像区域的l幅方向梯度图；S4.对图像区域的每幅方向梯度图,基于S1中所述分块方式得到对应的方向梯度图像块集合；S5.对于每个方向区间的方向梯度图像块集合,执行以下操作：S51.从方向区间g的方向梯度图像块集合中选出若干方向梯度图像块形成方向梯度特征学习的训练集；S52.设方向梯度图像块训练集为<img file="FDA0001244304580000011.TIF" wi="331" he="87" />其中N为训练集P中正样本、负样本的总数,x<sub>i</sub>表示第i个方向梯度图像块,y<sub>i</sub>表示第i个方向梯度图像块的类标；当x<sub>i</sub>属于正样本时,y<sub>i</sub>＝1；当x<sub>i</sub>属于负样本时,y<sub>i</sub>＝#1；设x<sub>i</sub>上包括有若干不同位置与大小的矩形区域,这些矩形区域的特征用矩形区域内的梯度大小之和来表示；令<img file="FDA0001244304580000012.TIF" wi="54" he="62" />表示第i个方向梯度图像块中第m个矩形区域的特征,m＝1:M,M表示x<sub>i</sub>中所有的矩形区域的总数,对应的训练集P中每个方向梯度图像块都会得到M个矩形区域；S53.初始化训练集P中所有样本的权重：w<sub>1,i</sub>＝1/N,i＝1,...,N；S54.初始化迭代参数t＝1；S55.为方向梯度图像块中的各矩形区域训练弱分类器；S56.计算每个弱分类器在训练集P中所有样本上的加权总误差,挑选出使加权总误差最小的弱分类器<img file="FDA0001244304580000021.TIF" wi="65" he="76" /><maths num="0001"><math><![CDATA[<mrow><msub><mover><mi>h</mi><mo>^</mo></mover><mi>t</mi></msub><mo> =</mo><mi>arg</mi><mi> </mi><msub><mi>min</mi><mrow><msub><mi>h</mi><mi>m</mi></msub><mo>&Element;</mo><mi>H</mi></mrow></msub><msub><mi>&epsiv;</mi><mi>m</mi></msub></mrow>]]></math><img file="FDA0001244304580000022.TIF" wi="382" he="86" /></maths><maths num="0002"><math><![CDATA[<mrow><msub><mi>&epsiv;</mi><mi>m</mi></msub><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>w</mi><mrow><mi>t</mi><mo>,</mo><mi>i</mi></mrow></msub><mi>&delta;</mi><mrow><mo>(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>&NotEqual;</mo><msub><mi>h</mi><mi>m</mi></msub><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001244304580000023.TIF" wi="521" he="127" /></maths>其中h<sub>m</sub>表示基于训练集P中方向梯度图像块的第m个矩形区域训练得到的弱分类器,H表示所有矩形区域弱分类器的集合；δ(·)为指示函数,当其参数为真时函数值为1,否则函数值为0；S57.计算<img file="FDA0001244304580000024.TIF" wi="37" he="78" />的权重α<sub>t</sub>：<img file="FDA0001244304580000025.TIF" wi="429" he="79" />其中<img file="FDA0001244304580000026.TIF" wi="42" he="60" />表示最小的加权总误差；S58.更新训练集P中所有样本的权重：<maths num="0003"><math><![CDATA[<mrow><msub><mi>w</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn><mo>,</mo><mi>i</mi></mrow></msub><mo> =</mo><mo>&lsqb;</mo><msub><mi>w</mi><mrow><mi>t</mi><mo>,</mo><mi>i</mi></mrow></msub><mi>exp</mi><mrow><mo>(</mo><mo>-</mo><msub><mi>&alpha;</mi><mi>t</mi></msub><msub><mi>y</mi><mi>i</mi></msub><msub><mover><mi>h</mi><mo>^</mo></mover><mi>t</mi></msub><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo><mo>)</mo></mrow><mo>&rsqb;</mo><mo>/</mo><msub><mi>Z</mi><mi>t</mi></msub></mrow>]]></math><img file="FDA0001244304580000027.TIF" wi="684" he="100" /></maths><maths num="0004"><math><![CDATA[<mrow><msub><mi>Z</mi><mi>t</mi></msub><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>w</mi><mrow><mi>t</mi><mo>,</mo><mi>i</mi></mrow></msub><mi>exp</mi><mrow><mo>(</mo><mo>-</mo><msub><mi>&alpha;</mi><mi>t</mi></msub><msub><mi>y</mi><mi>i</mi></msub><msub><mover><mi>h</mi><mo>^</mo></mover><mi>t</mi></msub><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo><mo>)</mo></mrow><mo>;</mo></mrow>]]></math><img file="FDA0001244304580000028.TIF" wi="606" he="134" /></maths>S59.令t＝t+1然后重复执行步骤S55～S58,直至t&gt;T；S510.执行完毕步骤S59后将训练过程中选中的前r个弱分类器对应的矩形区域在方向梯度图像块中的位置进行输出；S511.方向区间g的方向梯度图像块集合中的各个方向梯度图像块按照步骤S510输出的位置信息提取相应方向梯度图像块中的r个矩形区域；S512.对各个方向区间的方向梯度图像块集合进行步骤S51～S511的操作,此时图像区域中各个图像块对应的l个方向区间的方向梯度图像块都分别提取有r个矩形区域,计算每个矩形区域内的梯度大小之和,最后图像块就可以用一个lr维的方向梯度特征向量表示；(2).训练级联目标检测器S6.设定全局的假阳率F<sub>t</sub>及最小真阳率d<sub>min</sub>,以及初始化级联次数j＝1,初始化全局假阳率F<sub>j</sub>＝1.0,全局真阳率D<sub>j</sub>＝1.0；S7.基于(1)中提取的方向梯度特征向量,为图像区域中的每个图像块训练弱分类器,以AUC为收敛准则进行若干次boosting迭代,每次迭代挑选出一个最优的弱分类器；S8.采用Gentle#Adaboost整合步骤S7选中的所有弱分类器得到强分类器H<sup>j</sup>(x)；S9.利用H<sup>j</sup>(x)预测训练集X中所有图像区域的得分,并生成ROC曲线；在ROC曲线上查找使d<sub>j</sub>＝d<sub>min</sub>的点(d<sub>j</sub>,f<sub>j</sub>),其中d<sub>j</sub>表示真阳率,f<sub>j</sub>表示假阳率；S10.令j＝j+1,然后更新F<sub>j</sub>、D<sub>j</sub>,F<sub>j+1</sub>＝F<sub>j</sub>×f<sub>j</sub>,,D<sub>j+1</sub>＝D<sub>j</sub>×d<sub>j</sub>；S11.当F<sub>j</sub>&gt;F<sub>t</sub>时,重复执行步骤S7#S11；F<sub>j</sub>小于或等于F<sub>t</sub>时,输出级联目标检测器；(3).目标检测S12.使用多个窗口扫描可能包含目标的待检测图像,提取每个扫描窗口的方向梯度特征；S13.采用训练好的级联目标检测器对扫描窗口进行二分类检测,输出检测到的结果。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘红梅;              张凤君;                   卢伟       </td>   <td>中山大学</td>   <td>基于L0正则化和模糊核后处理的图像盲去模糊的方法</td>   <td>广东</td>   <td>CN107146202A</td>   <td>2017-09-08</td>   <td>本发明公开一种基于L0正则化和模糊核后处理的图像盲去模糊的方法,在图像复原的最优化模型中引入关于图像梯度、模糊核像素以及模糊核梯度稀疏性的先验信息,并以L0正则项的形式表现；其次,对最优化计算所得的模糊核根据其客观特性进行后处理,人为干预弥补最优化模型带来的不足,使复原所得的模糊核和中间图像更符合现实,最终复原图像质量进一步提高；最后,采用半二次分裂方法求解最优化模型,解法简洁,减少计算量,同时结合金字塔模型分层计算,所以本发明具有较高的鲁棒性,适用范围广。</td>   <td>一种基于L0正则化和模糊核后处理的图像盲去模糊的方法,其特征在于,包括以下步骤：S1：判断输入的原始模糊图像是否为灰度图像,若不是,则变换为灰度图像；S2：构造最优化模型求解模糊核,在模型中引入L0正则项,模型如公式(1)所示：<img file="FDA0001248157940000011.TIF" wi="1367" he="94" />其中β、μ及λ为权重参数,x是模糊图像,y是清晰图像,k是模糊核,*是卷积运算符,▽表示梯度运算；S3：对步骤S2得到的模糊核进行骨架提取,并根据各非零点到骨架的距离进行加权,重新计算模糊核中各点大小；S4：利用步骤S3得到的新的模糊核采用非盲去模糊方法,对原始模糊图像中每个通道进行复原,再将每个通道的复原结果进行合成求得最终复原图形。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              赵兰杰;                   谢晓华       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于偏微分方程学习的本征图像分解方法</td>   <td>广东</td>   <td>CN107133953A</td>   <td>2017-09-05</td>   <td>本发明提供一种基于偏微分方程学习的本征图像分解方法,本发明在处理图像本征成分估计上不依赖于确定的先验约束,且采用数据驱动的方式构建偏微分方程；利用共轭梯度法来决定搜索方向,相对于最速下降法和牛顿法,该方法将共轭性与最速下降法相结合；利用已知点处的梯度构造一组共轭方向,并沿着这组方向进行搜索,求出目标函数的极小点,来确定最佳的搜索方向；该方法可有效实现不同光照条件的图像进行本征分解得到该图像的反射成分和阴影成分。</td>   <td>一种基于偏微分方程学习的本征图像分解方法,其特征在于,包括以下步骤：S1：输入训练数据对；S2：初始化控制函数,由于目标函数是非凸的,最小化过程的收敛朝向取决于初始化的局部最小值,当初始化过程不收敛的时候转向步骤S3,执行循环；否则转向步骤S8；S3：求解具有PDE约束的最优控制方程；S4：求解伴随函数取特定值时的伴随方程；S5：利用下式计算j＝0,1,...,16时的平移旋转不变量的导数：<img file="FDA0001242032750000011.TIF" wi="1006" he="303" />其中,J是平移旋转不变量,j是平移旋转不变量的个数,a<sub>j</sub>,b<sub>j</sub>是控制函数,λ<sub>j</sub>和u<sub>j</sub>是正的加权参数,<img file="FDA0001242032750000012.TIF" wi="58" he="47" />和φ<sub>m</sub>是伴随函数,u是输出图像,Ω是输入图像所占据的矩形区域,f<sub>Ω</sub>是Ω的初始函数,m＝1,2,...,M,M为输入的数据样本对数,inv(u,v)表示对矩阵(u,v)求逆,v是指示函数,引入指示函数的目的是收集图像中的大规模信息,以便指导u的演变。S6：使用共轭梯度法来决定搜索方向；S7：沿着搜索方向执行黄金分割搜索,并不断更新系统函数,进行下一个循环,直到j＝16,进行训练；S8：终止循环,输出系统函数；S9：准备应用数据,数据图片特点是背景黑色,目标物单一且突出；S10：利用得到的系统函数,对所给数据进行本征分解应用,得到图像的反射成分和阴影成分。</td>   <td>G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘红梅;              何李域;                   卢伟       </td>   <td>中山大学</td>   <td>一种基于扰动失真和像素选择的二值图像隐写方法</td>   <td>广东</td>   <td>CN107133991A</td>   <td>2017-09-05</td>   <td>本发明提供一种基于扰动失真和像素选择的二值图像隐写方法,通过更合适的扰动度量方法计算二值图像像素点翻转带来的失真情况,通过STC编码嵌入秘密信息,提高秘密信息的嵌入容量,得到载密图像,最后通过像素选择策略对载密图像进行后处理,得到用于信道传输的二值隐写图像。本发明得到的二值隐写图像相比以前的方法,视觉质量更高,安全性、抗检测能力更强。本发明考虑翻转像素点之间存在相互影响,还提出一种像素选择的后处理策略,得到视觉质量更高,更安全的二值隐写图像。本发明可用于信息安全特别是二值图像秘密信息传输方面。</td>   <td>一种基于扰动失真和像素选择的二值图像隐写方法,其特征在于,包括以下步骤：S1：计算二值图像的扰动失真分数；S2：根据二值图像的扰动失真分数选择嵌入秘密信息的像素位置；S3：使用STC编码方法嵌入秘密信息；S4：通过像素选择策略对载密图像进行后处理,得到用于信道传输的二值隐写图像。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              王晓;                   王广聪       </td>   <td>中山大学</td>   <td>一种基于深度学习和条件随机场的多目标跟踪方法</td>   <td>广东</td>   <td>CN107122735A</td>   <td>2017-09-01</td>   <td>本发明公开了一种基于深度学习和条件随机场的多目标跟踪方法,主要包括下述步骤：用训练集训练深度网络；用网络提取目标的表观特征；在时间滑窗内将数据集给出的检测结果连接成可能的跟踪片段；将每个目标的跟踪片段集合作为点进行条件随机场建模；计算随机场中点与边的势能；利用联合树求解条件随机场得到滑窗内的跟踪结果；移动窗口,重复跟踪过程。主要贡献包括：(1)提出一种基于深度网络提取特征的多目标跟踪方法；(2)提出一种新的跟踪片段相似性度量方法；(3)实现一种基于跟踪片段集的半在线跟踪算法。通过利用深度网络提取表观特征,将检测结果连接为可能的跟踪片段,并利用条件随机场对片段进行关联,完成了多目标跟踪。</td>   <td>一种基于深度学习和条件随机场的多目标跟踪方法,其特征在于,包括步骤：S1、训练网络：利用给定的训练集,训练一个深度网络；S2、应用阶段：输入待处理视频的目标检测结果,对检测结果进行筛选,得到筛选后的检测结果；S3、提取特征：将筛选后的检测结果输入深度网络中,得到检测结果的表观特征；S4、产生跟踪片段：根据滑动窗口中检测结果和检测结果之间、目标与检测结果之间的表观特征相似度和位置关系,将可能为同一目标的检测结果连接成跟踪片段；S5、建模：将跟踪片段集合进行建模得到条件随机场模型,其中条件随机场中的点代表某一跟踪目标的可能的跟踪片段集合,集合的大小为跟踪片段的个数；点与点之间存在的边表示不同目标的跟踪片段之间共存的可能性；S6、计算：计算条件随机场中点的势能与边的势能；S7、求解：利用联合树算法求解,得到每个目标的跟踪片段索引,作为该滑动窗口内的跟踪结果；S8、滑动窗口,设定滑动步长,计算滑动窗口内的跟踪结果,依次循环,得到整个视频的跟踪结果。</td>   <td>G06K9/00;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              嵇志辉;              陈荣军;              谢舜道;              周达敏;              李小敏;              朱雄泳;                   曾衍瀚       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学;中山大学花都产业科技研究院</td>   <td>一种自定义寻像图形二维码及生成方法</td>   <td>广东</td>   <td>CN107122816A</td>   <td>2017-09-01</td>   <td>本发明公开一种自定义寻像图形二维码及生成方法,其中寻像图形是由三个相同的位置探测图形组成,分别位于符号的左上角、右上角和左下角,生成方法包括数据分析、数据信息编码、RS编码、确定二维码矩阵尺寸、矩阵中布置同心圆寻像图形、矩阵中布置其他模块、添加掩码图形以及添加格式与版本信息；解码方法包括检测寻像图形、图片校正、读取二维码矩阵、格式及版本信息译码、数据码字纠错以及数据码字译码。生成方法中每个位置探测图形采用同心圆代替现有的正方形,改变了QR码矩阵布块的方式；寻像图形的检测方法采用了自主算法检测同心圆；其中,同心圆作为位置探测图形,相对正方形来讲,检测速度更快、检测算法复杂度更低和算法闭源等优点。</td>   <td>一种自定义寻像图形二维码及生成方法,其特征在于,包括二维码生成和二维码解码,所述二维码生成包括以下步骤：S1：数据分析：分析输入的数据流,对QR码符号选择数据编码的数据模式；同时,选择相应的纠错等级和版本信息；S2：数据信息编码：根据所选择的数据模式及其对应的数据变换方法,将数据字符转变为二进制位流,即数据码字；S3：RS编码：将二进制位流进行RS编码生成纠错码字,数据码字和纠错码字组合成最终信息码字；S4：确定二维码的矩阵尺寸：根据格式与版本信息确定二维码矩阵尺寸；S5：布置同心圆寻像图形：在二维码矩阵中布置三个同心圆位置探测图形,同心圆寻像图形包括位于二维码矩阵的三个顶角处的同心圆；S6：布置其他模块：将分隔符图形、校正图形和码字区域布置在二维码矩阵中；S7：添加掩码图形：将掩模图形用于码字区域,使得QR码图形中的深色和浅色区域呈现比率最优的分布；S8：添加格式与版本信息：生成格式信息和版本信息放入相应区域内。</td>   <td>G06K19/06;G06K7/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         焦安坤;              韩凌波;                   农革       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于历史记录的代码审核人推荐方法</td>   <td>广东</td>   <td>CN107122391A</td>   <td>2017-09-01</td>   <td>本发明提供一种基于历史记录的代码审核人推荐方法,该方法利用历史审核记录中对代码的反馈信息,综合时间因素,依次确定不同审核人在不同时间对一段代码的专业度权重,同时结合路径相似度分析,最终确定审核人的推荐序列；该方法提供了一种鲁棒高效的代码审核人推荐方法,它首先提取历史纪录中不同审核人对某一段代码的反馈,综合反馈的数量、日期、频率等信息,确定不同审核人对一段代码的专业性,然后使用基于路径相似度的字符串对比方法,结合时间因素,利用传播学原理,构建基于权重的路径相似度模型,最后得到不同审核人对一段代码的优先级次序。</td>   <td>一种基于历史记录的代码审核人推荐方法,其特征在于,包括以下步骤：S1：基于历史审核记录,提取代码更新日期、反馈和路径信息,构建专业性度量模型；S2：针对当前输入的待审核代码,提取路径信息之后,通过字符串对比技术,获取当前代码与历史纪录中已审核代码路径的相似度；S3：利用S1中得到的专业度模型,结合S2中得到的相似度,并提取已审核代码的时间信息来计算其时间权重,构建基于权重的路径相似度模型并输出审核人的推荐序列。</td>   <td>G06F17/30;G06F11/36;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              李传俊;                   谢晓华       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种在垂直视角下基于深度学习的客流计数方法</td>   <td>广东</td>   <td>CN107103279A</td>   <td>2017-08-29</td>   <td>本发明提供一种在垂直视角下基于深度学习的客流计数方法,该方法垂直视角下进行人流统计,相比于斜拍视角,这个视角更容易应对商场、超市、地铁等公共场所人流很密集的情况；提出利用深度学习检测头肩,利用深度学习强大的学习能力,不需要对视频进行背景建模和前景提取,也不需要对前景进行行人切割,能够更精确更鲁棒地检测到头肩信息；进行匹配跟踪利用的是深度卷积特征,相对于HOG、LBP等手动设计的特征,深度卷积特征有更好的表达能力,能够更好的应对各种场景；本发明是直接将某一层的深度卷积特征拿来做匹配,避免了特征的重复计算,使得更加省时。</td>   <td>一种在垂直视角下基于深度学习的客流计数方法,其特征在于,包括以下步骤：S1：在视频画面内绘制进出统计线；S2：利用深度学习方法在当前画面内进行行人头肩检测；S3：判断当前画面是否存在头肩,如果是则转到步骤S4；如果不是则转到步骤S2,对下一帧继续检测；S4：将当前帧检测到的头肩与跟踪列表里的头肩进行匹配更新；S5：判断跟踪目标起始点和终止点是否在进出线两侧,如果是则转到步骤S6；如果不是则转到步骤S2,对下一帧继续检测；S6：更新进出的人数信息,接着转到步骤S2,对下一帧继续检测。</td>   <td>G06K9/00;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              黄锐;              谢晓华;                   冯展祥       </td>   <td>中山大学</td>   <td>基于聚集损失深度度量学习的人脸识别方法</td>   <td>广东</td>   <td>CN107103281A</td>   <td>2017-08-29</td>   <td>本发明公开了一种基于聚集损失深度度量学习的人脸识别方法,步骤：1)对训练图像进行预处理；2)用预处理过的图像对深度卷积神经网络进行预训练,采用softmax损失作为损失函数,引入关键点池化技术；3)将所有训练图像输入预训练好的模型,计算每个类的初始类中心；4)利用聚集损失对预训练好的模型进行精调,经过迭代更新网络参数和类中心,使得每类样本向类中心聚集,同时增大不同类中心之间的间距,从而学习到鲁棒的有判别性的人脸特征表达。5)应用时,对输入图像进行预处理,分别输入到训练好的网络模型提取特征表达,通过计算不同人脸之间的相似度,实现人脸识别。本发明仅利用小规模数据进行训练即可达到较高的人脸识别准确率。</td>   <td>基于聚集损失深度度量学习的人脸识别方法,其特征在于,包括如下步骤：步骤S1,对训练图像进行预处理,得到规格一致的人脸图像作为网络输入；步骤S2,用预处理过的人脸图像对深度卷积神经网络进行预训练,采用softmax损失作为网络的损失函数,在网络结构方面引入关键点池化技术,利用人脸结构信息辅助人脸识别,得到预训练的基于关键点池化的深度卷积神经网络模型；步骤S3,将所有训练图像输入所述预训练的基于关键点池化的深度卷积神经网络模型,计算每个类的初始类中心；步骤S4,利用聚集损失这一深度度量学习函数对上述预训练的基于关键点池化的深度卷积神经网络进行精调,使得每类样本向类中心聚集,同时增大不同类中心之间的间距,初始类中心由步骤S3所述方法得到；经过反复迭代更新网络参数和类中心,直至网络收敛,人脸识别准确率达到最高,得到最终的深度卷积神经网络模型；步骤S5,对待识别人脸图像进行预处理,预处理后的图像输入最终的深度卷积神经网络模型以提取高层人脸特征表达,通过比较不同人脸间的相似度得分,实现人脸识别。</td>   <td>G06K9/00;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓秋君;              张东;                   方圳河       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于图像轮廓特征的目标识别方法</td>   <td>广东</td>   <td>CN107103323A</td>   <td>2017-08-29</td>   <td>本发明公开一种基于图像轮廓特征的目标识别方法,对模板图像和待测物体图像进行预处理生成二值图像；建立物体模板轮廓的特征库：提取物体模板二值图像的完整轮廓,在轮廓上等间隔取一定数目的特征点,利用特征点的上下文特征对物体轮廓进行描述；对待检测物体图像进行目标识别：提取待检测二值图像的轮廓边缘；并选取一定的特征点；对待测物体的形状方向进行转换变成模板的取向；用选定点的上下文特征描述转换取向后的待测物体轮廓；通过匹配代价来衡量待测物体与模板物体的相似度。本发明相对于现有的技术,解决了在轮廓匹配过程中的旋转不变性的问题,使轮廓匹配过程中的旋转具有不变性,并有效的应用于图像中的目标识别。</td>   <td>一种基于图像轮廓特征的目标识别方法,其特征在于,包括以下步骤：S1：图像二值化：对待测物体图像和若干的模板图像进行预处理生成二值化图像,所述模板图像为确定物体的图像,所述待测物体图像为待测物体的图像；S2：建立模板轮廓的特征库：提取二值化模板图像中物体的完整轮廓,在轮廓上等间隔取若干数目的特征点,利用特征点的上下文特征对物体轮廓进行描述；S3：待测图像特征描述：提取二值化待测物体图像的轮廓边缘,在轮廓上选取若干的特征点；对待测物体的形状方向进行转换变成模板的取向；用选定的特征点的上下文特征描述转换取向后的待测物体轮廓；S4：对待测物体图像的特征描述与模板图像中物体轮廓的特征描述进行匹配,通过匹配代价来衡量待测物体与模板物体的相似度,进而识别待测物体。</td>   <td>G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;              刘勤意;              白微;              陈军祥;                   秦景辉       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于三维知识网络的学习者学习轨迹量化方法</td>   <td>广东</td>   <td>CN107103384A</td>   <td>2017-08-29</td>   <td>一种基于三维知识网络的学习者学习轨迹量化方法。本发明提供的方法包括以下实现步骤：1、构建完整的基于知识点的知识网络；2、依据教学要求构建基于知识网络的教学大纲；3、依据教学大纲构建学习路径；4、详细记录个体学习者依据学习路径学习的轨迹并反馈到系统；5、系统通过记录每个学习者的学习轨迹形成所有学习者的历史学习轨迹；系统对所有学习者的学习轨迹做多维数据分析,推断学习者群体总体学习能力,评估大纲覆盖知识点的难度、内容覆盖的广度与深度与学习群体匹配的合理性,量化评估教学大纲的难度合理性；6、依据个人学习轨迹与群体的学习轨迹及对其进行分析的结果,量化评估某个学习者的学习投入时间、投入效果及学习能力,从而优化规划或调整该学习者的个性化学习路径中需要覆盖的知识点的广度与深度。</td>   <td>一种基于三维知识网络的学习者学习轨迹量化方法,其特征在于,包括以下步骤：S1：利用知识点构建一个三维知识网络,三维知识网络使用有向无权图G＝{V,E}表示,其中V表示知识点集合,E表示知识点之间的前后驱或者父子关系集合；S2:依据学习群体M的教学要求构建基于三维知识网络的教学大纲P<sub>M</sub>；S3:依据教学大纲P<sub>M</sub>为学习者S构建学习路径R<sub>MS</sub>；S4:学习者S依据学习路径R<sub>MS</sub>及其个人达到的学习状态挑选新知识点V<sub>k</sub>进行学习；S5:通过与学习者S进行交互,详细记录和保存学习者S依据学习路径R<sub>MS</sub>学习知识点的轨迹并反馈到系统；S6:依据学习者S的学习轨迹与群体的学习轨迹以及对它们进行多维数据分析的结果,量化评估学习者S的学习投入时间、投入效果及学习能力并提供与学习群体的量化性比较指标,优化规划或调整学习者S的学习路径R<sub>MS</sub>中需要覆盖的知识点的广度与深度；S7:依据所有学习者的学习轨迹,由量化模型更新学习知识点的难度量化值和测试阈值；S8:系统按照预先设定的条件满足时,对所有学习者的学习轨迹做多维数据分析,推断学习者群体总体学习能力,评估教学大纲覆盖知识点的难度、内容覆盖的广度和深度与学习群体匹配的合理性,量化评估教学大纲的难度合理性；按系统建议及专家意见更新教学大纲,然后跳转回S3；如果系统预先设定的条件还不满足,跳转回到S4。</td>   <td>G06Q10/04;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王甲海;              袁两胜;                   印鉴       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种求解多目标带时间窗异构车型选址#路径问题的算法</td>   <td>广东</td>   <td>CN107092977A</td>   <td>2017-08-25</td>   <td>本发明提供一种求解多目标带时间窗异构车型选址#路径问题的算法,该算法主要应用智能优化算法求解多目标带时间窗异构车型选址#路径(MOFSMLRPTW)问题,涉及物流运输和智能优化算法两大领域。算法主要包括三个部分：第一,利用当前种群目标间的冲突信息将目标空间分解成若干组互不重叠的子目标空间；第二,对新产生的解进行局部搜索,加快算法的收敛速度；第三,更新存档,利用存档收集优化过程中产生的非占优解。本发明通过对存在的非对称样例和对称样例进行测试,证明了该发明的方法的有效性。</td>   <td>一种求解多目标带时间窗异构车型选址#路径问题的算法,其特征在于,包括以下步骤：S1：令t＝0,初始化产生种群大小为N的种群P<sub>t</sub>,并且初始化目标分组Ψ＝{f<sub>1</sub>,f<sub>2</sub>,f<sub>3</sub>,f<sub>4</sub>,f<sub>5</sub>,f<sub>6</sub>},其中f<sub>1</sub>代表总的开放的仓库花费,f<sub>2</sub>代表总的异构车队的固定花费,f<sub>3</sub>代表总的行驶距离,f<sub>4</sub>代表最长工作时间,f<sub>5</sub>代表总的等待时间,f<sub>6</sub>代表总的延迟时间；S2：以种群P<sub>t</sub>中的个体初始化存档A,该存档用于收集在优化过程中产生的非占优解；S3：将种群P<sub>t</sub>中的个体复制给外部种群Q<sub>t</sub>,通过Q<sub>t</sub>临时保存P<sub>t</sub>中的个体；S4：从P<sub>t</sub>中随机选择两个个体p<sub>1</sub>和p<sub>2</sub>,通过交叉操作产生一个子代个体c,并用个体c更新存档A,重复该过程直到产生大小为N的子种群C<sub>t</sub>；S5：使用领域操作优化C<sub>t</sub>中的个体,得到优化的子种群C′<sub>t</sub>,并以C′<sub>t</sub>中的个体更新存档A；S6：基于Ψ的每组目标Ψ<sub>i</sub>,利用快速非占优排序以及拥挤距离从P<sub>t</sub>∪C′<sub>t</sub>中选择数目为N/|Ψ|的子种群<img file="FDA0001261579020000011.TIF" wi="123" he="79" />令<img file="FDA0001261579020000012.TIF" wi="315" he="87" />S7：t＝t+1,判断是否达到了终止条件,若是,转步骤S11；S8：判断t是否为It<sub>C</sub>的倍数,若是,转步骤S9；若否,转步骤S4；S9：基于所有的目标{f<sub>1</sub>,f<sub>2</sub>,f<sub>3</sub>,f<sub>4</sub>,f<sub>5</sub>,f<sub>6</sub>},利用快速非占优排序以及拥挤距离从P<sub>t</sub>∪Q<sub>t</sub>中选择数目为N的种群O<sub>t</sub>；S10：根据种群O<sub>t</sub>中目标的冲突性,重新计算目标分组,得到新的目标分组为Ψ,令P<sub>t</sub>＝O<sub>t</sub>,转步骤S3；S11：基于存档A,得到帕累托最优解集并输出,算法终止。</td>   <td>G06Q10/04;G06Q10/08;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉岚;                   兀琼       </td>   <td>中山大学</td>   <td>适用于显式分析的三维无限元人工边界建立方法</td>   <td>广东</td>   <td>CN107092730A</td>   <td>2017-08-25</td>   <td>本发明涉及一种适用于显式分析的三维无限元人工边界建立方法,包括以下步骤：S1.创建三维土体几何模型,然后从三维土体几何模型中截取出部分的土体作为近场区域,剩余的土体作为远场区域；S2.建立三维无限元人工边界,使用无限元模拟远场区域,而采用有限元模拟近场区域；S3.将外源波动转化为等效的节点力,然后将其施加在构建的人工边界的节点上。</td>   <td>适用于显式分析的三维无限元人工边界建立方法,其特征在于：包括以下步骤：S1.创建三维土体几何模型,然后从三维土体几何模型中截取出部分的土体作为近场区域,剩余的土体作为远场区域；S2.建立三维无限元人工边界,使用无限元模拟远场区域,而采用有限元模拟近场区域；S3.将外源波动转化为等效的节点力,然后将其施加在构建的人工边界的节点上。</td>   <td>G06F17/50;G06T17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         温武少;              徐富秀;              秦景辉;                   王诗萌       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种知识网络构建及可视化方法和系统</td>   <td>广东</td>   <td>CN107085596A</td>   <td>2017-08-22</td>   <td>本发明涉及一种知识网络构建及可视化方法,包括以下步骤：S1.使用知识点的关系属性和非关系属性对知识点进行表示；S2.使用知识点的表示构建知识库；S3.基于知识库进行知识网络的构建；S4.利用知识网络引擎获取知识网络中知识点的关系属性,传递给可视化插件进行可视化处理。</td>   <td>一种知识网络构建及可视化方法,其特征在于：包括以下步骤：S1.使用知识点的关系属性和非关系属性对知识点进行表示；S2.使用知识点的表示构建知识库；S3.基于知识库进行知识网络的构建；S4.利用知识网络引擎获取知识网络中知识点的关系属性,传递给可视化插件进行可视化处理。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              黄秋筱;              李国鸣;                   邓院昌       </td>   <td>中山大学</td>   <td>融合脸部检测与跟踪的汽车乘员计数方法</td>   <td>广东</td>   <td>CN107085703A</td>   <td>2017-08-22</td>   <td>本发明涉及一种融合脸部检测与跟踪的汽车乘员计数方法,其特征在于：包括以下步骤：S1.对于车载摄像头拍摄的图像序列,首先采用AdaBoost脸部检测算法检测并获取乘员脸部在当前帧图像的位置；S2.使用Kalman滤波跟踪算法对乘员脸部在下一帧图像的位置进行预测；S3.使用AdaBoost脸部检测算法在下一帧图像预测的位置对乘员脸部进行检测；S4.通过步骤重复执行S2、S3实现对乘员脸部连续的跟踪；S5.统计跟踪的乘员脸部的数量,从而得到汽车内的乘员数量。</td>   <td>一种融合脸部检测与跟踪的汽车乘员计数方法,其特征在于：包括以下步骤：S1.对于车载摄像头拍摄的图像序列,首先采用AdaBoost脸部检测算法检测并获取乘员脸部在当前帧图像的位置；S2.使用Kalman滤波跟踪算法对乘员脸部在下一帧图像的位置进行预测；S3.使用AdaBoost脸部检测算法在下一帧图像预测的位置对乘员脸部进行检测；S4.通过步骤重复执行S2、S3实现对乘员脸部连续的跟踪；S5.统计跟踪的乘员脸部的数量,从而得到汽车内的乘员数量。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              毛亚芳;              李伟宏;                   吴伟基       </td>   <td>中山大学</td>   <td>基于相关滤波的端对端快速行人再识别方法</td>   <td>广东</td>   <td>CN107085713A</td>   <td>2017-08-22</td>   <td>本发明涉及一种基于相关滤波的端对端快速行人再识别方法,其能够克服现有的行人再识别方法需要手动标注大量候选行人然后进行再识别的问题,直接从大量的包含行人的图片中进行目标行人再识别,此过程中无需结合行人检测即可实现端到端的行人再识别。</td>   <td>基于相关滤波的端对端快速行人再识别方法,其特征在于：包括以下步骤：S1.分别提取目标行人图片和包含有背景与其他行人的图片的颜色特征和梯度方向直方图特征；其中目标行人图片提取的颜色特征和梯度方向直方图特征作为正样本特征数据,包含有背景与其他行人的图片提取的颜色特征和梯度方向直方图特征作为负样本特征数据；S2.将正负样本特征数据进行傅立叶变换后,作为输入的训练样本训练线性学习器,得到目标行人的线性相关滤波矩阵；S3.对监控场景图片进行不同尺度的缩放,然后分别对每个缩放尺度下的监控场景图片提取颜色特征和梯度方向直方图特征；S4.将从不同缩放尺度下的监控场景图片中提取的颜色特征和梯度方向直方图特征与训练好的线性相关滤波矩阵进行卷积操作,每个缩放尺度对应的监控场景图片响应度最高的地方即为目标行人可能匹配的位置；S5.利用非极大值抑制的方法从不同缩放尺度下的监控场景图片目标行人可能的匹配位置中确定目标行人最可能的匹配位置和行人大小作为最终的匹配结果。</td>   <td>G06K9/00;G06K9/46;G06K9/66</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   汤梦玥       </td>   <td>中山大学</td>   <td>一种基于图像的彩铅画风格绘制方法</td>   <td>广东</td>   <td>CN107085859A</td>   <td>2017-08-22</td>   <td>本发明提供了一种基于图像的彩铅画风格绘制方法,其步骤包括：获取输入图像的边缘图像；用具有不同长度的笔画作为卷积核,对边缘图像进行自适应卷积,生成铅笔轮廓线图像；对输入图像进行颜色滤波处理,获得彩铅底色图像；对彩铅底色图像进行伽马校正,获得增强了暗部细节的彩铅色调图像；对增强了暗部细节的彩铅色调图像进行纹理渲染,获得彩铅纹理图像；将铅笔轮廓线图像与彩铅纹理图像结合,得到最终结果。与现有技术相比,本方法得到的彩铅画结果,无论从轮廓线、色调还是纹理方面,都与现实中由画家创作的彩铅画效果更加接近,且具有较高的时间效率。</td>   <td>一种基于图像的彩铅画风格绘制方法,其特征在于：分别获取输入图像的铅笔轮廓线图像以及输入图像的彩铅纹理图像,再将所述铅笔轮廓线图像以及所述彩铅纹理图结合,得到最终的结果。</td>   <td>G06T11/00;G06T11/40;G06T11/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李明;                   倪志东       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>融合多种端到端神经网络结构的说话人感冒症状识别方法</td>   <td>广东</td>   <td>CN107068167A</td>   <td>2017-08-18</td>   <td>本发明涉及一种融合多种端到端神经网络结构的说话人感冒症状识别方法,包括以下步骤：S1.构建及训练输入为语音,识别网络为卷积神经网络和长短期记忆网络的端到端神经网络A；S2.构建及训练输入为语音频谱,识别网络为卷积神经网络和长短期记忆网络的端到端神经网络B；S3.构建及训练输入为语音频谱,识别网络为卷积神经网络和全连接网络的端到端神经网络C；S4.构建及训练输入为语音MFCC特征/CQCC特征,识别网络为长短期记忆网络的端到端神经网络D；S5.融合以上四种训练好的端到端神经网络进行说话人感冒症状识别。</td>   <td>融合多种端到端神经网络结构的说话人感冒症状识别方法,其特征在于：包括以下步骤：S1.构建及训练输入为语音,识别网络为卷积神经网络和长短期记忆网络的端到端神经网络A；S2.构建及训练输入为语音频谱,识别网络为卷积神经网络和长短期记忆网络的端到端神经网络B；S3.构建及训练输入为语音频谱,识别网络为卷积神经网络和全连接网络的端到端神经网络C；S4.构建及训练输入为语音MFCC特征/CQCC特征,识别网络为长短期记忆网络的端到端神经网络D；S5.融合以上四种训练好的端到端神经网络进行说话人感冒症状识别。</td>   <td>G10L25/66;G10L25/30;G10L25/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   彭权华       </td>   <td>中山大学</td>   <td>一种车道线检测方法</td>   <td>广东</td>   <td>CN107066952A</td>   <td>2017-08-18</td>   <td>本发明公开一种车道线检测方法,包括以下步骤：采集道路图像,图像分辨率为I*Y；图像预处理：对采集到的道路图像进行预处理,去除干扰信息,加强车道线信息；Hough变换直线检测：采用Hough变换检测经过预处理的图像中的直线；去除干扰线：根据车道线的角度和灰度值去除干扰线；显示已检测到的车道线。本方法在图像预处理阶段能够动态并快速地计算出感兴趣区域的分界线,在车道线确认时根据车道线角度和灰度值去除干扰线,达到实时准确地识别车道线的要求。</td>   <td>一种车道线检测方法,其特征在于,包括以下步骤：A、采集道路图像,图像分辨率为I*Y；B、图像预处理：对采集到的道路图像进行预处理,去除干扰信息,加强车道线信息；C、Hough变换直线检测：采用Hough变换检测经过预处理的图像中的直线；D、去除干扰线：根据车道线的角度和灰度值去除干扰线；E、显示已检测到的车道线；所述步骤B进行图像预处理的过程为：B2、对步骤A采集到的彩色图像进行灰度化,得到灰度图像；B3、采用3*3卷积核对灰度图像进行中值滤波；B4、二值化,阈值Threshold为150,<maths num="0001"><math><![CDATA[<mrow><mi>P</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><mrow><mo>(</mo><mrow><mi>x</mi><mo>,</mo><mi>y</mi></mrow><mo>)</mo></mrow><mo> =</mo><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><mn>255</mn><mo>,</mo></mrow></mtd><mtd><mrow><mi>P</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><mo>&GreaterEqual;</mo><mi>T</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>h</mi><mi>o</mi><mi>l</mi><mi>d</mi></mrow></mtd></mtr><mtr><mtd><mrow><mn>0</mn><mo>,</mo></mrow></mtd><mtd><mrow><mi>P</mi><mi>i</mi><mi>x</mi><mi>e</mi><mi>l</mi><mo>&lt;</mo><mi>T</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>h</mi><mi>o</mi><mi>l</mi><mi>d</mi></mrow></mtd></mtr></mtable></mfenced></mrow>]]></math><img file="FDA0001246557350000011.TIF" wi="758" he="142" /></maths>B5、膨胀处理：采用3*3矩阵,内核中心点为(#1,#1),膨胀迭代1次；B6、腐蚀处理：采用3*3矩阵,内核中心点为(#1,#1),腐蚀迭代1次；B7、将道路图像划分为感兴趣的道路区域和非感兴趣的背景区域,去除非感兴趣区域,保留感兴趣区域；B8、边缘检测过程中,使用Canny算子进行提取边缘。</td>   <td>G06K9/00;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              晏斌;              邓成谦;              林培祥;              黄家诚;                   李凯祥       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于防伪溯源系统的异常数据处理方法及系统</td>   <td>广东</td>   <td>CN107038593A</td>   <td>2017-08-11</td>   <td>本发明提供一种基于防伪溯源系统的异常数据处理方法及系统,所述方法在用户通过防伪溯源平台查询商品真伪的过程中,当判定商品为假冒时,系统将得到的用户信息(性别、年龄)、查询信息(空间位置、时间)以及用户反馈的商品信息(价格、种类、用途)和购买途径信息(线上(网站、店铺)、线下(店铺))等进行数据预处理。接着对数据进行异常检测,然后对线下数据集利用基于距离分类方法进行分析,根据位置信息查找假冒源,或者针对线上数据集基于频率分类方法进行分析,达到阈值即判定为假冒源。本发明利用防伪溯源系统的信息进行有效挖掘,为用户、店铺管理者和政府监管部门提供有效参考。</td>   <td>一种基于防伪溯源系统的异常数据处理方法,其特征在于,包括以下步骤：S1：获取用户信息,查询产品真伪情况；S2：根据获取的信息,利用数据清洗、数据集成、数据变换和数据归约方法对数据进行预处理；S3：针对数据集进行异常检测,去除异常点干扰；S4：针对线下数据集利用基于距离的方法找到最可疑假冒源；针对线上数据集采用基于频率的分类方法,找出最可疑假冒源；S5：标记不良店铺,并发送标记结果到数据库。</td>   <td>G06Q30/00;G06K9/62;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨溢;              赖斯龑;              郭梦含;                   林小拉       </td>   <td>中山大学</td>   <td>一种基于蒙特卡洛方法逆向求解PageRank的算法</td>   <td>广东</td>   <td>CN107038212A</td>   <td>2017-08-11</td>   <td>本发明提供一种基于蒙特卡洛方法逆向求解PageRank的算法,该发明通过对蒙特卡洛算法的参数进行初始化,并读取待处理图的信息,将图的信息进行处理并储于GPU的显存中,利再用GPU多线程计算图对应的概率转移数组,启动GPU的多线程功能,利用图对应的概率转移数组通过蒙特卡洛的方法仿真计算图的解的每个分量对应的PageRank值,将每个线程求解的PageRank值进行求和,得出最终的结果。本发明加速效果十分明显且节省了很大的存储空间。</td>   <td>一种基于蒙特卡洛方法逆向求解PageRank的算法,其特征在于,包括以下步骤：S1：对蒙特卡洛算法的参数进行初始化,并读取待处理图的信息；S2：将图的信息进行处理并储于GPU的显存中,利再用GPU多线程计算图对应的概率转移数组；S3：启动GPU的多线程功能,利用图对应的概率转移数组通过蒙特卡洛的方法仿真计算图的解的每个分量对应的PageRank值,将每个线程求解的PageRank值进行求和,得出最终的结果。</td>   <td>G06F17/30;G06T1/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邵长飞;                   劳斌       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于后缀数组的短信查找方法及系统</td>   <td>广东</td>   <td>CN107038230A</td>   <td>2017-08-11</td>   <td>本发明涉及一种基于后缀数组的短信查找方法,包括以下步骤：S1.为短信列表中的每条短信构建后缀数组,然后对构造得到的所有后缀数组中的各个后缀数组项进行排序；S2.当接收到一个查找短信的关键词时,按照接收字符的顺序,将接收到的关键词中的各个字符依次作为二分查找的索引；S3.使用关键词中的第i个字符作为索引在已排序的所有后缀数组项中进行二分查找,将首字符为该索引的后缀数组项对应的后缀数组作为第i次查找的结果；S4.令i=i+1然后使用关键词中的第i个字符作为索引在第i#1次查找结果包含的后缀数组项中进行二分查找,然后将首字符为该索引的后缀数组项对应的后缀数组作为第i次查找的结果；S5.重复执行步骤S4直至第i&gt;n,此时将第i次查找的结果对应的短信作为短信查找结果进行输出,n为关键词包含的字符数。</td>   <td>一种基于后缀数组的短信查找方法,其特征在于：包括以下步骤：S1.为短信列表中的每条短信根据其短信字符串内容构建后缀数组,然后按照预设的规则对构造得到的所有后缀数组中的各个后缀数组项进行排序；S2.当接收到一个查找短信的关键词时,按照接收字符的顺序,将接收到的关键词中的各个字符依次作为二分查找的索引；S3.使用关键词中的第i个字符作为索引在已排序的所有后缀数组项中进行二分查找,将首字符为该索引的后缀数组项对应的后缀数组作为第i次查找的结果；i的初始值为1；S4.令i＝i+1然后使用关键词中的第i个字符作为索引在第i#1次查找结果包含的后缀数组项中进行二分查找,然后将首字符为该索引的后缀数组项对应的后缀数组作为第i次查找的结果；S5.重复执行步骤S4直至第i&gt;n,此时将第i次查找的结果对应的短信作为短信查找结果进行输出,n为关键词包含的字符数。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韩凌波;              农革;                   徐文涛       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种后缀数组的正确性验证方法及系统</td>   <td>广东</td>   <td>CN107015951A</td>   <td>2017-08-04</td>   <td>本发明涉及一种后缀数组的正确性验证方法和系统,所述方法包括：从右向左扫描一遍T,按照后缀类型的定义比较当前扫描的字符T[i]与后继字符T[i+1]的大小,计算T的字符T[i]和suf(T,i)的类型,记录于t[i]中；从左向右扫描一遍T,找出其中所有LMS字符出现的位置,从而获取所有LMS子串的首字符指针,用数组P1来记录；根据数组P1、B和SA,使用归纳排序的方法对T的LMS子串进行排序,结果保存在数组SA1；从左向右扫描SA,如果SA[i]为LMS类型,将SA[i]保存至SA1中；判断T1中的字符是否唯一,若是则直接根据T1的名字计算出SA1,且用SA1更新C数组；根据T1和SA1归纳计算T的后缀数组SA,计算过程中使用C数组验证SA的正确性,如果SA正确,用SA更新C数组。</td>   <td>一种后缀数组的正确性验证方法,其特征在于,包括：从右向左扫描一遍字符串T,按照后缀类型的定义比较当前扫描的字符T[i]与后继字符T[i+1]的大小,计算字符串T的字符T[i]和suf(T,i)的类型,记录于t[i]中；从左向右扫描一遍字符串T,找出其中所有LMS字符出现的位置,从而获取所有LMS子串的首字符指针,用数组P1来记录；根据数组P1、B和SA,使用归纳排序的方法对字符串T的LMS子串进行排序,结果保存在数组SA1；从左向右扫描SA,如果SA[i]为LMS类型,将SA[i]保存至SA1中；判断T1中的字符是否唯一；若是则直接根据T1的名字计算出SA1,且用SA1更新C数组；根据T1和SA1归纳计算字符串T的后缀数组SA,计算过程中使用C数组验证SA的正确性,如果SA正确,用SA更新C数组,其中C数组保存的是当前递归层已有序的LMS后缀地址。</td>   <td>G06F17/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韩凌波;              农革;                   吴裔       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种后缀数组和最长公共前缀的正确性验证方法及系统</td>   <td>广东</td>   <td>CN107015952A</td>   <td>2017-08-04</td>   <td>本发明涉及一种后缀数组和最长公共前缀的正确性验证方法及系统。该方法包括：从右向左扫描一遍T,按照后缀类型定义比较字符T[i]及其后继字符T[i+1]的大小,计算T的字符T[i]和后缀suf(T,i)的类型,记录于t[i]中；将SA1和LCPA1中的元素初始化为#1。从左到右扫描一遍SA,根据数组t找出SA中所有LMS后缀及其LCP值,分别依次记录在SA1和LCPA1中；根据字符串T、数组t、SA1和LCPA1,对SA1中相邻LMS后缀及其LCP值进行正确性验证；根据字符串T、数组t、B、C、SA1和LCPA1,归纳排序T的L型后缀及其LCP值；根据字符串T、数组t、B、C、SA1和LCPA1,归纳排序T的S型后缀及其LCP值；顺序扫描SA、SA1、LCPA和LCPA1一次,比较SA与SA1和LCPA与LCPA1是否相同,如果两组比较全部相同则T的SA和LCPA正确。</td>   <td>一种后缀数组和最长公共前缀的正确性验证方法,其特征在于,包括：从右向左扫描一遍T,按照后缀类型定义比较字符T[i]及其后继字符T[i+1]的大小,计算T的字符T[i]和后缀suf(T,i)的类型,记录于t[i]中；将SA1和LCPA1中的元素初始化为#1,从左到右扫描一遍SA,根据数组t找出SA中所有LMS后缀及其LCP值,分别依次记录在SA1和LCPA1中；根据字符串T、数组t、SA1和LCPA1,对SA1中相邻LMS后缀及其LCP值进行正确性验证；根据字符串T、数组t、B、C、SA1和LCPA1,归纳排序T的L型后缀及其LCP值；根据字符串T、数组t、B、C、SA1和LCPA1,归纳排序T的S型后缀及其LCP值；顺序扫描SA、SA1、LCPA和LCPA1一次,比较SA与SA1和LCPA与LCPA1是否相同,如果两组比较全部相同则T的SA和LCPA正确,否则错误。</td>   <td>G06F17/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭虎;              陈翔;                   陈晓春       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;深圳清华大学研究院;中山大学</td>   <td>一种交叉纤维特征点匹配方法</td>   <td>广东</td>   <td>CN107016394A</td>   <td>2017-08-04</td>   <td>本发明公开一种交叉纤维特征点匹配方法,该方法主要流程为：生成纤维原始图像进行预处理操作,提取边缘纤维轮廓线,计算边缘纤维轮廓线上各点的曲率值并判断纤维轮廓线角点,构建动态支撑域删除伪角点,使用两点法确定凹点并标注,计算各个凹点的左右斜率和各个凹点与凹点之间的斜率并进行比较查找匹配点。本发明克服现有技术所述的传统人工识别纤维技术的缺陷,通过交叉重叠纤维特征点的匹配检测纤维成分含量及参数测量,不受人为主观情绪影响,操作简单,智能化程度高。</td>   <td>一种交叉纤维特征点匹配方法,其特征在于,包括步骤：S1：生成纤维原始图像,读入并将其二值化,将二值化后纤维灰度图像经开、闭运算、图像填充和增强预处理操作；S2：提取经预处理操作后的图像纤维边缘并对其进行平滑处理,抽取图像纤维轮廓线；S3:计算图像纤维轮廓线上各像素点的曲率值,通过与预设的第一阈值比较来确定角点；S4：在确定角点的基础上使用两点法确定凹点,把同一交叉区域内的凹点归类为同一集合,并对该集合的所有凹点进行标注；S5：在同一集合内,计算两相邻凹点P<sub>i</sub>和P<sub>j</sub>(i≠j)之间的斜率K<sub>ij</sub>,在纤维轮廓线上计算凹点P<sub>i</sub>与距离其左边n个像素的点P<sub>L</sub>斜率K<sub>iL</sub>,记为凹点P<sub>i</sub>左斜率；在纤维轮廓线上计算凹点P<sub>i</sub>与距离其右边n个像素的点P<sub>R</sub>斜率K<sub>iR</sub>,记为凹点P<sub>i</sub>右斜率；同时记凹点P<sub>j</sub>与点P<sub>L</sub>之间斜率为K<sub>jL</sub>；记凹点P<sub>j</sub>与点P<sub>R</sub>之间斜率为K<sub>jR</sub>；S6：若凹点P<sub>i</sub>相邻的凹点P<sub>j</sub>斜率K<sub>ij</sub>与P<sub>i</sub>的左斜率K<sub>iL</sub>相减差值h<sub>1</sub>在预设的第二阈值范围之内；若斜率K<sub>jL</sub>与两相邻凹点P<sub>i</sub>和P<sub>j</sub>(i≠j)之间的斜率K<sub>ij</sub>相减差值h<sub>2</sub>在预设的第三阈值范围之内；取最小的h<sub>1</sub>和h<sub>2</sub>,则该凹点判为凹点P<sub>i</sub>左匹配点,即<img file="FDA0001233584690000011.TIF" wi="777" he="159" />S7：若凹点P<sub>i</sub>相邻的凹点P<sub>j</sub>斜率K<sub>ij</sub>与P<sub>i</sub>的右斜率K<sub>iR</sub>相减差值h<sub>3</sub>在预设的第二阈值范围之内；若斜率K<sub>jR</sub>与两相邻凹点P<sub>i</sub>和P<sub>j</sub>(i≠j)之间的斜率K<sub>ij</sub>相减差值h<sub>4</sub>在预设的第三阈值范围之内；取最小的h<sub>3</sub>和h<sub>4</sub>,则该凹点判为凹点P<sub>i</sub>右匹配点,即<img file="FDA0001233584690000012.TIF" wi="798" he="159" /></td>   <td>G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘冶;              傅自豪;              刘荻;              李宏浩;              陈宇恒;                   印鉴       </td>   <td>火烈鸟网络(广州)股份有限公司;中山大学</td>   <td>一种广告信息的推送方法及系统</td>   <td>广东</td>   <td>CN106997549A</td>   <td>2017-08-01</td>   <td>本发明涉及一种广告信息的推送方法,包括以下步骤：服务器端获取客户端的广告推送请求；服务器端向广告池模块发送广告请求,由所述广告池模块从数据库中获取广告；服务器端接收由广告池模块返回的广告；服务器端调用算法策略模块,对广告数据进行点击率预估,并进行筛选和排序；服务器端将筛选排序后的广告发回客户端。相比于现有技术,本发明针对移动终端的特点,提供了一种对移动设备用户进行个性化广告推荐的方法。通过本发明可以针对用户的需求,更加精确地挑选更加适合的广告数据,并相应地推送给用户。本发明还提供了一种用于实现上述方法的广告信息的推送系统。</td>   <td>一种广告信息的推送方法,其特征在于,包括以下步骤：服务器端获取客户端的广告推送请求；服务器端向广告池模块发送广告请求,由所述广告池模块从数据库中获取广告；服务器端接收由广告池模块返回的广告；服务器端调用算法策略模块,对广告数据进行点击率预估,并进行筛选和排序；服务器端将筛选排序后的广告发回客户端。</td>   <td>G06Q30/02;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              蔡珉枫;              陈荣军;              谢舜道;                   朱雄泳       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>一种QR码快速定位检测算法</td>   <td>广东</td>   <td>CN106991460A</td>   <td>2017-07-28</td>   <td>本发明提供一种QR码快速定位检测算法,该方法对图像进行二值化,提取二值图形,然后采用Canny算法提取二值图形的边缘图形,在边缘图形中搜索轮廓图形用于定位,并获取轮廓的嵌套关系,之后根据轮廓嵌套信息,判断有三个轮廓嵌套的图形为二维码的位置探测图形,若检测到的位置探测图形为三个,则计算其最外围轮廓的中心距,作为QR码的定位点,最后提取出QR码；该方法利用QR码轮廓进行定位,而后根据轮廓顶点的关系确定QR码的四个顶点,最后采用透视变换的方法对QR码进行了提取；该方法原理易于理解,准确性高,识别速度快,可以很好的部署与生产环境中使用。</td>   <td>一种QR码快速定位检测算法,其特征在于,包括以下步骤：S1：对图像进行二值化,提取二值图形；S2：采用Canny算法提取二值图形的边缘图形；S3：在边缘图形中搜索轮廓图形用于定位,并获取轮廓的嵌套关系；S4：根据轮廓嵌套信息,判断有三个轮廓嵌套的图形为二维码的位置探测图形,若检测到的位置探测图形为三个,则计算其最外围轮廓的中心距,作为QR码的定位点；S5：提取出QR码。</td>   <td>G06K19/06;G06K7/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              李林静;                   谢晓华       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于归一化像素差特征的人脸姿势分类方法</td>   <td>广东</td>   <td>CN106980825A</td>   <td>2017-07-25</td>   <td>本发明提供一种基于归一化像素差特征的人脸姿势分类方法,该方法读取待测人脸图片,提取人脸检测窗口的NPD特征,并进行人脸检测；对所有检测出的人脸窗口利用基于NPD特征的改进的稀疏表示的分类算法进行人脸姿势分类,该归一化像素差特征的提取方法仅是通过任意两个像素值计算得来,并且具有尺度不变性,克服了姿势分类问题中的遮挡、光照变化,低分辨率和模糊等困难,并且降低了特征提取的时间复杂度和计算复杂度。</td>   <td>一种基于归一化像素差特征的人脸姿势分类方法,其特征在于,包括以下步骤：S1：读取一张待测人脸图片；S2：提取人脸检测窗口的归一化像素差特征,并进行人脸检测；S3：对所有检测出的人脸窗口利用基于归一化像素差特征的改进的稀疏表示的分类算法进行人脸姿势分类。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         龚剑;                   方艳梅       </td>   <td>中山大学</td>   <td>一种人脸图像的自动分类方法</td>   <td>广东</td>   <td>CN106980834A</td>   <td>2017-07-25</td>   <td>本发明提供一种人脸图像的自动分类方法,将待分类的人脸图像裁剪为统一尺寸；对所有人脸图像进行局部二值模式操作,得到局部二值模式图像；将局部二值模式图像两两进行尺度不变特征变换,得出两张人脸图像相似特征点的数目；若所求得相似特征点数目小于预设的阈值,则判定这两个局部二值模式图像所代表的人脸图像不属于同一人脸；若所求得的相似特征点数目大于该预设的阈值,则判定这两个局部二值模式图像所代表的人脸图像属于同一人脸。本发明提出一种基于局部二值模式对人脸图像进行预处理然后采用尺度不变特征变换进行辨识的人脸识别算法,用于对没有输入训练图像的人脸图像进行人脸图像分类。</td>   <td>一种人脸图像的自动分类方法,其特征在于,包括以下步骤：S1：将待分类的人脸图像裁剪为统一尺寸；S2：对所有人脸图像进行局部二值模式操作,得到局部二值模式图像；S3：将局部二值模式图像两两进行尺度不变特征变换,得出两张人脸图像相似特征点的数目；S4：若所求得相似特征点数目小于预设的阈值,则判定这两个局部二值模式图像所代表的人脸图像不属于同一人脸；若所求得的相似特征点数目大于该预设的阈值,则判定这两个局部二值模式图像所代表的人脸图像属于同一人脸。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王成建;                   印鉴       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>基于时间空间上下文的循环神经网络预测位置的方法</td>   <td>广东</td>   <td>CN106960256A</td>   <td>2017-07-18</td>   <td>本发明涉及一种基于时间空间上下文的循环神经网络预测下一个时间的位置的方法；提供的方法通过融入了时间因子和空间因子信息,同时,对循环神经网络进行递归学习保留上一层状态信息,参数自主学习优化；时空循环神经网络能更好地对时空上下文建模而且提供更精准的位置预测。</td>   <td>基于时间空间上下文的循环神经网络预测位置的方法,其特征在于：包括以下步骤：S1.基于循环神经网络进行建模；S2.基于步骤S1,将时间信息和空间信息融入到循环神经网络模型；S3.基于步骤S2,将循环神经网络模型进行参数学习优化；S4.基于步骤S1～S3,计算时间t时的位置信息,完成对位置信息的预测。</td>   <td>G06Q10/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘洁;              林少斌;              刘希;              欧阳效源;                   马争鸣       </td>   <td>中山大学</td>   <td>一种基于测地线保持的非线性数据降维方法</td>   <td>广东</td>   <td>CN106960000A</td>   <td>2017-07-18</td>   <td>本发明公开了一种基于测地线保持的非线性数据降维方法。首先对输入样本点集取随机最短路径,找到样本点集的一个测地线集合。每条测地线的低维嵌入的全局坐标为该测地线在高维流形中的局部坐标通过一定的旋转变换得到,因此,中心化的低维嵌入的全局坐标可用中心化的高维流形中的局部坐标表示。由于每条测地线的全局坐标可以用选择矩阵与所有样本点的低维嵌入坐标表示,再根据实际值和估计值的平方误差和最小原则,使得低维嵌入全局坐标与经过旋转变换后的局部坐标的平方误差和最小,从而解得样本点在低维嵌入的全局坐标。</td>   <td>一种基于测地线保持的非线性数据降维方法,其特征在于该方法的步骤如下：A.对于一个高维数据样本点集为X＝[x<sub>1</sub>#…#x<sub>N</sub>]∈R<sup>D×N</sup>,其映射到低维空间中的样本点集为Y＝[x<sub>1</sub>#…#x<sub>N</sub>]∈R<sup>d×N</sup>,其中：D为高维空间的维数；d(d＜＜D)为低维空间的维数；X为高维数据模型的输入,是高维空间R<sup>D×N</sup>中的N个D维实数列向量；Y为高维数据映射到低维空间中的输出样本集,是低维空间R<sup>d×N</sup>中的N个d维实数列向量；B.以存在于高维空间中的样本点集中的一个随机样本点为当前样本点计算以该点作为起点,到样本点集中其余点的最短路径中覆盖点最多的一条路径作为所求测地线,并将该测地线所覆盖的点从样本点集中剔除；重复以上步骤,得到测地线集合,并对每条测地线局部保持处理,得到其在低维流形上的嵌入坐标,操作步骤如下：B1、计算样本点集中邻近点对i,j之间的欧式距离d<sub>x</sub>(i,j),构建一个反映样本点集邻近关系的带权流通图,根据带权流通图,计算样本点集相应的测地距离矩阵；对输入样本点集构建K近邻邻接图,从样本点集中取一个随机点,计算从该点到样本点集中其余点之.间的最短路径集合,再从此测地线集合中选出一条覆盖点最多的路径<img file="FSA0000140130040000011.TIF" wi="604" he="100" />其中<img file="FSA0000140130040000012.TIF" wi="71" he="54" />为测地线P中的第N<sub>p</sub>个样本点,<img file="FSA0000140130040000013.TIF" wi="431" he="65" />p＝1,…,P,将以上所获得的一条路径所覆盖的点从样本点集中去除；重复以上步骤,直到样本点集为空集,得到所求测地线集合；B2、每条测地线都可以用一个该测地线所覆盖到的点的点集形式来表示成局部坐标的形式<img file="FSA0000140130040000014.TIF" wi="613" he="91" />其中<img file="FSA0000140130040000015.TIF" wi="510" he="79" />i＝2,…,N<sub>p</sub>,<img file="FSA0000140130040000016.TIF" wi="249" he="78" />表示<img file="FSA0000140130040000017.TIF" wi="121" he="49" />之间的测地距离；B3、不失一般性地,使θ<sub>p,1</sub>＝0,v<sub>p</sub>＝[1#0#…#0]<sup>T</sup>表示将每条测地线的局部坐标Θ<sub>p</sub>进行中心化处理并且通过一定的变换投影到各局部坐标中以的一个坐标轴,即有：<img file="FSA0000140130040000019.TIF" wi="407" he="80" />从而得到中心化后的局部坐标<img file="FSA00001401300400000110.TIF" wi="77" he="69" />B4、同样,将测地线的全局坐标<img file="FSA00001401300400000111.TIF" wi="560" he="102" />进行相应的中心化处理,得到<img file="FSA00001401300400000112.TIF" wi="964" he="102" />其中<img file="FSA00001401300400000113.TIF" wi="260" he="84" />是每条测地线相应的选择矩阵,表示为：<img file="FSA0000140130040000021.TIF" wi="593" he="433" />其中<img file="FSA0000140130040000022.TIF" wi="418" he="61" />i＝1,…,N<sub>p</sub>#1；B5、由于全局坐标<img file="FSA0000140130040000023.TIF" wi="42" he="69" />是局部坐标<img file="FSA0000140130040000024.TIF" wi="54" he="69" />的仿射变换,即；<img file="FSA0000140130040000025.TIF" wi="223" he="69" />A<sub>p</sub>表示对Θ<sub>p</sub>进行旋转和缩放的变换矩阵；就几何意义而言,在d维欧氏空间R<sup>d</sup>中,把局部坐标Θ<sub>p</sub>向全局坐标<img file="FSA0000140130040000026.TIF" wi="43" he="67" />平移,使得平移后的局部坐标的中心与全局坐标Y<sub>p</sub>的起点<img file="FSA0000140130040000027.TIF" wi="52" he="48" />重合,然后再围绕着全局坐标Y<sub>p</sub>的起点<img file="FSA0000140130040000028.TIF" wi="52" he="48" />进行旋转和缩放；根据<img file="FSA0000140130040000029.TIF" wi="194" he="69" />可得：<img file="FSA00001401300400000210.TIF" wi="224" he="69" /><img file="FSA00001401300400000211.TIF" wi="60" he="68" />表示<img file="FSA00001401300400000212.TIF" wi="54" he="68" />的右伪逆,也即<img file="FSA00001401300400000213.TIF" wi="58" he="68" />是<img file="FSA00001401300400000214.TIF" wi="373" he="96" />最小二乘问题的解；B6、根据<img file="FSA00001401300400000215.TIF" wi="486" he="69" />可以得到<img file="FSA00001401300400000216.TIF" wi="433" he="87" />综合考虑所有测地线的情况,有：<img file="FSA00001401300400000217.TIF" wi="967" he="126" />B7、根据实际值和估计值的平方误差和最小原则,有<img file="FSA00001401300400000218.TIF" wi="1783" he="130" />B8、令<img file="FSA00001401300400000219.TIF" wi="445" he="87" />因此只需要求解：<maths num="0001"><math><![CDATA[<mrow><mi>arg</mi><munder><mi>min</mi><mi>Y</mi></munder><munderover><mi>&Sigma;</mi><mrow><mi>p</mi><mo> =</mo><mn>1</mn></mrow><mi>P</mi></munderover><mo>|</mo><mo>|</mo><msub><mi>YL</mi><mi>p</mi></msub><mo>|</mo><msup><mo>|</mo><mn>2</mn></msup><mo> =</mo><mi>arg</mi><munder><mi>min</mi><mi>Y</mi></munder><munderover><mi>&Sigma;</mi><mrow><mi>p</mi><mo> =</mo><mn>1</mn></mrow><mi>P</mi></munderover><mi>t</mi><mi>r</mi><mrow><mo>(</mo><msub><mi>YL</mi><mi>p</mi></msub><msubsup><mi>L</mi><mi>p</mi><mi>T</mi></msubsup><msup><mi>Y</mi><mi>T</mi></msup><mo>)</mo></mrow><mo> =</mo><mi>arg</mi><munder><mi>min</mi><mi>Y</mi></munder><mi>t</mi><mi>r</mi><mrow><mo>(</mo><mi>Y</mi><mo>(</mo><mrow><munderover><mi>&Sigma;</mi><mrow><mi>p</mi><mo> =</mo><mn>1</mn></mrow><mi>P</mi></munderover><msub><mi>L</mi><mi>p</mi></msub><msubsup><mi>L</mi><mi>p</mi><mi>T</mi></msubsup></mrow><mo>)</mo><msup><mi>Y</mi><mi>T</mi></msup><mo>)</mo></mrow><mo>.</mo></mrow>]]></math><img file="FSA00001401300400000220.TIF" wi="1454" he="147" /></maths></td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              杨君;                   谢晓华       </td>   <td>中山大学</td>   <td>一种三维京剧脸谱自动化妆方法</td>   <td>广东</td>   <td>CN106952221A</td>   <td>2017-07-14</td>   <td>本发明公开了一种三维京剧脸谱自动化妆方法,包括步骤：从输入源获取图像输入,进行人脸检测和人脸特征点定位并将特征点标注在图像上；对特征点进行人脸归一化处理；计算归一化后的人脸图像的深度信息,并根据深度信息重建三维点云；根据特征点信息对人脸图像进行三角分块操作；在准备好的京剧脸谱图片上,手工标注特征点,并对京剧脸谱进行相同的三角分块操作；将所述京剧脸谱上的每个三角块着色到人脸图像上；使用京剧脸谱将所述三维点云进行重新着色,并展现给用户。本发明自动计算出人脸特征点的坐标和人脸三维模型,运用计算机视觉和图像处理相关的技术,将事先手工标定好特征点的京剧脸谱描绘到目标人脸的三维模型上。</td>   <td>一种三维京剧脸谱自动化妆方法,其特征在于,包括步骤S1：从输入源获取图像输入,进行人脸检测和人脸特征点定位,如果输入图像中存在人脸,则将特征点标注在图像上；S2：对所述特征点进行人脸归一化处理；S3：计算归一化后的人脸图像的深度信息,并根据所述深度信息重建三维点云；S4：根据所述特征点信息对人脸图像进行三角分块操作；S5：在准备好的京剧脸谱图片上,手工标注特征点,并对京剧脸谱进行和所述人脸图像相同的三角分块操作；S6：将所述京剧脸谱上的每个三角块进行仿射变化,着色到人脸图像上；S7：根据人脸图像和三维点云的坐标对应关系,使用京剧脸谱将所述三维点云进行重新着色,并展现给用户。</td>   <td>G06T3/00;G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              朱允全;                   谢晓华       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于颜色和距离聚类的多目标跟踪方法</td>   <td>广东</td>   <td>CN106951841A</td>   <td>2017-07-14</td>   <td>本发明提供一种基于颜色和距离聚类的多目标跟踪方法,该方法减少了跟踪目标形变带来的影响,增加目标之间的区分度,并降低了对检测器的依赖程度；该方法结合前后帧的位置信息和目标的直方图信息通过对前景点进行聚类,并计算前景点得分,最后定位目标位置,并不断更新目标的直方图特征和位置信息。</td>   <td>一种基于颜色和距离聚类的多目标跟踪方法,其特征在于,包括以下步骤：S1：计算距离得分；S2：计算颜色得分；S3：加权得分；S4：聚类；S5：目标回归；S6：更新距离和直方图模型。</td>   <td>G06K9/00;G06K9/38;G06K9/46;G06K9/62;G06T7/143</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王军;              谢启超;                   陈谋奇       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于BP神经网络的鱼眼镜头拍摄图像畸变矫正方法</td>   <td>广东</td>   <td>CN106952236A</td>   <td>2017-07-14</td>   <td>本发明提供的方法应用BP神经网络来对鱼眼镜头拍摄的图像进行畸变矫正,矫正畸变的效率与现有相比得到了提高。并且神经网络具有很强的自学习性、自组织性、高度非线性和鲁棒性等特点使得其在解决非线性拟合等问题上有着独特的优势,能够解决多层次的复杂问题。本发明采用神经网络解决图像畸变矫正,打破传统的图像畸变矫正技术的束缚,在非线性畸变矫正方面正有着无可替代的优越性。</td>   <td>一种基于BP神经网络的鱼眼镜头拍摄图像畸变矫正方法,其特征在于：包括以下步骤；S1.设纸张A上均匀分布有m行、n列的特征点,使用鱼眼镜头对纸张A进行拍摄,获得拍摄的图像；S2.对图像进行预处理；S3.对经过预处理的图像进行特征点的提取；S4.提取的特征点中,水平距离最大的相邻的两个特征点间的水平距离x为每列特征点间的距离,垂直距离最大的相邻的两个特征点间的垂直距离y为每行特征点间的距离；S5.利用x、y、m、n构建起理想的特征点分布图；S6将提取的图像特征点与理想的特征点分布图中的特征点按照特征点的排列顺序进行匹配；S7.得到匹配结果后,将提取的图像特征点和理想的特征点分布图中的特征点作为BP神经网络的输入和输出,得到神经网络的网络层间加权系数wki和wij；S8.将拍摄的图像中每个像素点作为BP神经网络的输入,即可得到其矫正后的坐标,像素点的像素值保持为拍摄的图像中该像素点的像素值；通过以上操作完成拍摄图像的畸变矫正。</td>   <td>G06T5/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              陈志宇;                   袁陶希       </td>   <td>中山大学</td>   <td>一种基于特征点及邻域特征匹配的掌纹认证方法</td>   <td>广东</td>   <td>CN106951874A</td>   <td>2017-07-14</td>   <td>本发明以掌纹验证为应用背景,提出一种基于特征点和邻域特征匹配的掌纹认证方法,通过对注册样本和问询样本的SIFT特征点与其包含的邻域特征进行结合,提高特征点匹配的可靠性。同时进一步针对掌纹的非线性形变,将其分解为若干个局部线性变换,解决了现有方法在所采集掌纹存在形变时认证准确率下降的问题,提高掌纹认证的准确率。</td>   <td>一种基于特征点及邻域特征匹配的掌纹认证方法,其特征在于：包括以下步骤：S1.对于问询样本I<sub>2</sub>和注册样本I<sub>1</sub>,分别使用尺度不变特征变换方法对其进行SIFT特征点的检测；S2.得到问询样本I<sub>2</sub>和注册样本I<sub>1</sub>的SIFT特征点后,将问询样本I<sub>2</sub>的SIFT特征点与注册样本I<sub>1</sub>的SIFT特征点进行SIFT特征点对的匹配,得到若干对SIFT特征点对,并将其存储在匹配点集合S中；S3.对于匹配点集合S中的每对SIFT特征点对,通过步骤S31～S331的方法分别计算其包括的两个SIFT特征点的邻域特征：S31.设其中任一SIFT特征点为X,遍历其周围的SIFT特征点,选取与SIFT特征点X欧氏距离最近的n个SIFT特征点作为近邻点；其中n为正整数；S32.以欧氏距离最近的SIFT特征点为起点,按照顺时针方向排列这n个近邻点；S33.基于排列好的n个近邻点依次提取其几何特征描述,如步骤S331所示：S331.设当前近邻点为A,顺时针顺序的下一个近邻点为B,提取当前近邻点A的以下几何特征描述：1)相对距离：分别计算SIFT特征点X和近邻点A、近邻点B的距离,其比值为相对距离R<sub>1</sub>,<img file="FDA0001254276760000011.TIF" wi="211" he="135" />2)相对方向：SIFT特征点X中包含特征点X的主方向信息,设SIFT特征点X的主方向和近邻点A、近邻点B的主方向之间的夹角分别为<img file="FDA0001254276760000014.TIF" wi="150" he="47" />其比值定义为相对方向R<sub>2</sub>：<img file="FDA0001254276760000012.TIF" wi="222" he="159" />3)相对夹角：SIFT特征点X和近邻点A、近邻点B形成三角形ΔAXB,其中∠XBA和∠XAB的比值定义为相对夹角R<sub>3</sub>：<img file="FDA0001254276760000013.TIF" wi="295" he="143" />S34.经过步骤S33后得到n组几何特征描述,所述每组几何特征描述使用三元组r<sub>i</sub>＝(R<sub>1</sub>,R<sub>2</sub>,R<sub>3</sub>)表示,i＝1,2,…,n,则SIFT特征点X的邻域特征以3n维几何特征描述向量进行表示；S4.对于每对SIFT特征点对,计算得到SIFT特征点对的两个SIFT特征点的邻域特征后,计算两个SIFT特征点的基于邻域特征的距离：<maths num="0001"><math><![CDATA[<mrow><mi>R</mi><mo> =</mo><mfrac><mn>1</mn><mrow><mn>3</mn><mi>n</mi></mrow></mfrac><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>n</mi></munderover><munderover><mo>&Sigma;</mo><mrow><mi>j</mi><mo> =</mo><mn>1</mn></mrow><mn>3</mn></munderover><mfrac><msqrt><msup><mrow><mo>(</mo><msub><mi>R</mi><mrow><mi>i</mi><mi>j</mi><mn>1</mn></mrow></msub><mo>-</mo><msub><mi>R</mi><mrow><mi>i</mi><mi>j</mi><mn>2</mn></mrow></msub><mo>)</mo></mrow><mn>2</mn></msup></msqrt><mrow><mo>|</mo><msub><mi>R</mi><mrow><mi>i</mi><mi>j</mi><mn>1</mn></mrow></msub><mo>|</mo></mrow></mfrac></mrow>]]></math><img file="FDA0001254276760000021.TIF" wi="595" he="190" /></maths>其中R<sub>ij1</sub>和R<sub>ij2</sub>分别表示两个SIFT特征点的第i个近邻点的第j个几何特征描述；S5.当R&lt;t时,在匹配点集合S中保留该SIFT特征点对,否则在匹配点集合S中删除这对SIFT特征点对,其中t为设定的阈值；S6.计算匹配点集合S中每对SIFT特征点对的相对偏角；S7.对于匹配点集合S中的任意两对SIFT特征点对,它们的距离Q定义为：<maths num="0002"><math><![CDATA[<mrow><mi>Q</mi><mo> =</mo><mfrac><mrow><mo>|</mo><msub><mi>&Delta;&theta;</mi><mi>a</mi></msub><mo>-</mo><msub><mi>&Delta;&theta;</mi><mi>b</mi></msub><mo>|</mo></mrow><mrow><msub><mi>&Delta;&theta;</mi><mi>a</mi></msub></mrow></mfrac></mrow>]]></math><img file="FDA0001254276760000022.TIF" wi="318" he="143" /></maths>其中Δθ<sub>a</sub>与Δθ<sub>b</sub>分别表示两对SIFT特征点对的相对偏角；若Q&lt;τ即Q小于设定的阈值,则认为这两对SIFT特征点对属于同一线性变换模型；S8.基于步骤S7将匹配点集合S划分为M个集合S<sub>1</sub>,S<sub>2</sub>,...,S<sub>M</sub>；S9.对于集合S<sub>m</sub>,其对应的线性变换模型用相对偏角<img file="FDA0001254276760000025.TIF" wi="52" he="69" />和相对位移<img file="FDA0001254276760000026.TIF" wi="63" he="70" />刻画,其中m＝{1,2...M},<img file="FDA0001254276760000027.TIF" wi="52" he="70" />和<img file="FDA0001254276760000028.TIF" wi="67" he="70" />的计算方式如下：<maths num="0003"><math><![CDATA[<mrow><msub><mover><mi>&theta;</mi><mo>&OverBar;</mo></mover><mi>m</mi></msub><mo> =</mo><mfrac><mrow><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>q</mi></munderover><msub><mi>&Delta;&theta;</mi><mi>i</mi></msub></mrow><mi>q</mi></mfrac></mrow>]]></math><img file="FDA0001254276760000023.TIF" wi="286" he="230" /></maths><maths num="0004"><math><![CDATA[<mrow><msub><mover><mi>D</mi><mo>&RightArrow;</mo></mover><mi>m</mi></msub><mo> =</mo><mrow><mo>(</mo><msub><mover><mi>x</mi><mo>&OverBar;</mo></mover><mrow><mi>m</mi><mn>1</mn></mrow></msub><mo>-</mo><msub><mover><mi>x</mi><mo>&OverBar;</mo></mover><mrow><mi>m</mi><mn>2</mn></mrow></msub><mo>,</mo><msub><mover><mi>y</mi><mo>&OverBar;</mo></mover><mrow><mi>m</mi><mn>1</mn></mrow></msub><mo>-</mo><msub><mover><mi>y</mi><mo>&OverBar;</mo></mover><mrow><mi>m</mi><mn>2</mn></mrow></msub><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001254276760000024.TIF" wi="590" he="79" /></maths>其中q表示集合S<sub>m</sub>中包含的SIFT特征点对的数量,Δθ<sub>i</sub>表示第i对SIFT特征点对的相对偏角,<img file="FDA0001254276760000029.TIF" wi="195" he="63" />和<img file="FDA00012542767600000210.TIF" wi="208" he="63" />分别表示在注册样本I<sub>1</sub>和问询样本I<sub>2</sub>中,集合S<sub>m</sub>包含的SIFT特征点的质心坐标；S10.依据<img file="FDA00012542767600000211.TIF" wi="53" he="70" />和<img file="FDA00012542767600000212.TIF" wi="64" he="71" />对问询样本进行矫正,得到问询图像I'<sub>m2</sub>；S11.将注册样本I<sub>1</sub>和问询图像I'<sub>m2</sub>划分成n×n个方块单元格；S12.将包含有SIFT特征点的单元格作为种子单元格,然后将注册样本I<sub>1</sub>和问询图像I'<sub>m2</sub>中的种子单元格分别添加进像素区域集合R<sub>m</sub>和R'<sub>m</sub>；S13.将注册样本I<sub>1</sub>和问询图像I'<sub>m2</sub>中的种子单元格的8邻域单元格分别添加进像素区域集合R<sub>m</sub>和R'<sub>m</sub>中；S14.对像素区域集合R<sub>m</sub>和R'<sub>m</sub>进行以单元格为单位的膨胀和腐蚀的操作,直至R<sub>m</sub>和R'<sub>m</sub>形成完整的封闭区域,得到一组对应的匹配区域；S15.对M个集合分别进行步骤S9～S14的处理,共得到M组对应的匹配区域；S16.对M组对应的匹配区域进行像素级的特征提取,然后基于提取的特征分别计算每组对应的匹配区域之间的距离；进一步统计M组对应的匹配区域之间的距离之和；S17.判断距离之和是否小于所设定的阈值,若是则认定问询样本I<sub>2</sub>和注册样本I<sub>1</sub>匹配,否则则认定问询样本I<sub>2</sub>和注册样本I<sub>1</sub>不匹配。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              梁方殷;                   郭雪梅       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于线特征描述的无标识增强现实注册方法</td>   <td>广东</td>   <td>CN106952312A</td>   <td>2017-07-14</td>   <td>本发明提供一种基于线特征描述的无标识增强现实注册方法,该方法利用颜色差分直方图获取当前帧中兴趣目标所在的局部区域,然后对当前帧中的兴趣目标使用高斯滤波来除去噪声和图像亮度调整；再对区域中目标进行轮廓特征提取,按检测到的线特征提取描述符,进行线特征匹配；再通过当前帧中二维和三维的对应关系计算虚实坐标系变换矩阵,获取采集当前帧的计算摄像机外部参数并确定摄像机位姿；最后根据计算摄像机计算的上一帧得到的计算摄像机外部参数和摄像机位姿以及当前帧中目标的线特征信息更新当前的投影矩阵,进而实现实时注册；该方法缩小了当前帧对于目标所在区域的检测范围,提高了目标检测的效率和虚实物体位置匹配的效率。</td>   <td>一种基于线特征描述的无标识增强现实注册方法,其特征在于,包括以下步骤：S1：利用颜色差分直方图获取当前帧中兴趣目标所在的局部区域；S2：对当前帧中的兴趣目标使用高斯滤波来除去噪声和图像亮度调整；S3：对区域中目标进行轮廓特征提取,按检测到的线特征提取描述符,进行线特征匹配；S4：通过当前帧中二维和三维的对应关系计算虚实坐标系变换矩阵,获取采集当前帧的计算摄像机外部参数并确定摄像机位姿；S5：根据计算摄像机计算的上一帧得到的计算摄像机外部参数和摄像机位姿以及当前帧中目标的线特征信息更新当前的投影矩阵,进而实现实时注册。</td>   <td>G06T7/80;G06T7/543;G06T7/13;G06T7/12;G06T7/564;G06T7/44;G06T7/33;G06T19/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         贾江龙;                   刘聪       </td>   <td>中山大学</td>   <td>一种基于递归神经网络的摘要生成方法</td>   <td>广东</td>   <td>CN106933785A</td>   <td>2017-07-07</td>   <td>本发明涉及一种基于递归神经网络的摘要生成方法,在当前时刻t,将递归神经网络解码器的状态向量s<sub>t</sub>与递归神经网络编码器的每个时刻的状态向量进行对比,找出与状态向量s<sub>t</sub>关联性最强的状态向量H,然后利用状态向量H及状态向量H左右两侧的d个状态向量计算得到状态向量c<sub>t</sub>,利用状态向量c<sub>t</sub>、状态向量s<sub>t</sub>计算得到新的状态向量d<sub>t</sub>,然后根据状态向量d<sub>t</sub>解码得到输出序列的下一个字或者词,其中d为大于或等于1的整数。</td>   <td>一种基于递归神经网络的摘要生成方法,其特征在于：在当前时刻t,将递归神经网络解码器的状态向量s<sub>t</sub>与递归神经网络编码器的每个时刻的状态向量进行对比,找出与状态向量s<sub>t</sub>关联性最强的状态向量H,然后利用状态向量H及状态向量H左右两侧的d个状态向量计算得到状态向量c<sub>t</sub>,利用状态向量c<sub>t</sub>、状态向量s<sub>t</sub>计算得到新的状态向量d<sub>t</sub>,然后根据状态向量d<sub>t</sub>解码得到输出序列的下一个字或者词,其中d为大于或等于1的整数。</td>   <td>G06F17/22;G06N3/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         安孝杰;                   任江涛       </td>   <td>中山大学</td>   <td>一种基于概率图模型的个性化旅游游记推荐方法</td>   <td>广东</td>   <td>CN106934056A</td>   <td>2017-07-07</td>   <td>本发明提供一种基于概率图模型的个性化旅游游记推荐方法,该发明采用伽马分布,泊松分解算法,对未知的用户偏好,地点特征进行很好的估算,能够利用文本信息及地点,是否点评游记等三个信息挖掘出这些隐特征,不用考虑读者的地理位置,景点的位置等一些无法获取的信息,能够提高推荐的准确率；采用联合的概率图模型,对于推荐系统中常见的“冷启动”问题,以及对于多图少字的游记能够很好的解决。</td>   <td>一种基于概率图模型的个性化旅游游记推荐方法,其特征在于,包括以下步骤：S1：游记主题初始化：对游记文章进行分词,采用标准的文章主题模型,通过吉布斯采样,得到每篇游记的主题分布,以及每个词的主题分布,用计算出的主题分布对游记和词伽马分布的相关参数进行赋值,此外对用户偏好,地点隐特征的相关参数用随机数进赋初值；S2：对每篇游记中的每个词,通过词主题与文章主题的分布,计算词频关系的对数值,并更新每篇游记及该游记中词的伽马分布参数中的形状参数；S3：针对每个用户评论的每篇游记,根据用户偏好分布,游记主题分布与地点隐特征,计算用户参与游记评论的对数值,并更新用户,游记,地点伽马分布参数中的形状参数S4：更新所有伽马分布的尺度参数；S5：通过训练集训练出来的用户偏好,地点隐特征,从验证数据集中进行预测。</td>   <td>G06F17/30;G06F17/27;G06Q50/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王军;              李日富;                   江伟鑫       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种可靠的青光眼患者自我检测方法</td>   <td>广东</td>   <td>CN106934365A</td>   <td>2017-07-07</td>   <td>本发明提供一种可靠的青光眼患者自我检测方法,人脸定位：采集人脸图像并通过肤色分割识别出人脸区域,确定人脸边界并提取人脸；人眼检测：在提取人脸后,对人眼区域进行识别；提取瞳孔中心#眼角位置矢量,判断视线方向是否发生了移动,并借助于提前标定各个主要方向的方法来实时根据瞳孔中心#眼角位置矢量的值预估实际视线方向,从而对青光眼进行检测。本发明为visualFieldseasy提供检测数据有效性的验证,以提高判断检测者是否患有青光眼的准确性。</td>   <td>一种可靠的青光眼患者自我检测方法,其特征在于,包括以下步骤：S1：人脸定位：采集人脸图像并通过肤色分割识别出人脸区域,确定人脸边界并提取人脸；S2：人眼检测：在提取人脸后,对人眼区域进行识别；S3：提取瞳孔中心#眼角位置矢量,判断视线方向是否发生了移动,并借助于提前标定各个主要方向的方法来实时根据瞳孔中心#眼角位置矢量的值预估实际视线方向,从而对青光眼进行检测。</td>   <td>G06K9/00;G06K9/34;G06K9/62;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李喆超;              张一帆;                   吴维刚       </td>   <td>中山大学</td>   <td>一种基于缓存的虚拟机启动方法</td>   <td>广东</td>   <td>CN106933654A</td>   <td>2017-07-07</td>   <td>本发明提供的方法的物理节点在收到申请虚拟机的请求时,首先通过查找自身或兄弟节点中是否缓存有目标镜像,若缓存有目标镜像且自身或兄弟节点能够满足资源要求的话则直接在自身或兄弟节点中启动虚拟机。因此本发明提供的方法能够最大程度上减少镜像传输的发生。而后,步骤S5和S6从各个源点选取和中间交换机的选择来规划传输路径,这优化了整个网络上的带宽利用率。因此,本发明提供的方法能够有效地提高传输速度。再者,步骤S8在启动虚拟机后,还包括有判断是否需要缓存目标镜像的内容。这使得目标物理所在簇包括的物理节点中肯定缓存有目标镜像。为后续的虚拟机启动减少镜像传输的发生。因此本发明提供的方法能够有效地加快虚拟机的启动速度。</td>   <td>一种基于缓存的虚拟机启动方法,其特征在于：包括以下步骤：S1.物理节点A收到申请虚拟机的请求,如果物理节点A缓存有目标镜像并且物理节点A的资源满足申请的需求,则直接利用目标镜像在物理节点A的本地启动虚拟机；否则执行步骤S2；S2.查找物理节点A的父节点,然后将父节点的儿子节点中与物理节点A处于同一个簇并且缓存有目标镜像的节点加入到列表PM_list中；S3.a)PM_list不为空,且PM_list中存在物理节点B的资源满足申请的需求,则利用物理节点B缓存的目标镜像在物理节点B启动虚拟机；b)PM_list为空,则从物理节点A父节点的儿子节点中选择资源能够满足申请需求的物理节点C作为虚拟机放置的节点,然后执行步骤S4；c)若a)、b)两种情况均无法找到资源能够满足申请需要的物理节点,则将这个请求转发给其他簇的物理节点进行处理；S4.从物理节点C出发,递归地搜索父节点的儿子节点缓存的镜像信息,得到所有缓存有目标镜像的物理节点的簇；S5.遍历步骤S4得到的簇,根据簇中数据传输的拥挤程度从相应的簇中选择相应的物理节点作为数据源；S6.循环胖树中的所有层,在每一层的所有同等地位的交换机中选择工作负载最小的交换机构建从数据源到物理节点C的传输路径,然后将目标镜像通过传输路径从数据源传输至物理节点C；S7.物理节点C利用目标镜像在本地启动虚拟机；然后判断其自身是否还具有足够的空间来存放目标镜像,若是则直接缓存目标镜像,否则执行步骤S8；S8.计算物理节点C所在簇包括的物理节点缓存有的各种镜像的出现频率,若目标镜像的出现频率高于其余镜像的出现频率,则不缓存目标镜像,否则将出现频率最高的镜像进行删除,然后将目标镜像缓存进物理节点C所在簇包括的物理节点中。</td>   <td>G06F9/455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陆遥;                   周元品       </td>   <td>中山大学</td>   <td>一种基于图像修复的自动水印去除方法</td>   <td>广东</td>   <td>CN106934780A</td>   <td>2017-07-07</td>   <td>本发明公开了一种基于图像修复的自动水印去除方法,包括下述步骤：(1)批量导入具有相同分辨率且具有相同水印区域的图片；(2)将导入的图像由RGB模型转换为灰度模型；(3)对转化为灰度模型后的一系列图片进行叠加得到一张叠加灰度图片；(4)对叠加灰度图片应用阈值分割方法获得水印区域；(5)对水印区域膨胀一个像素点获得更大轮廓的区域作为最终水印区域；(6)应用图像修复算法对最终水印区域进行修复并输出修复后的图像。本发明有效地实现了自动识别水印区域并完成自动去除水印的工作,从而提高了水印去除的效率。</td>   <td>一种基于图像修复的自动水印去除方法,其特征在于,包括下述步骤：(1)批量导入具有相同分辨率且具有相同水印区域的图片；(2)将导入的图片由RGB模型转换为灰度模型；(3)对转化为灰度模型后的一系列图片进行叠加得到一张叠加灰度图片；所述叠加灰度图片：是把转换为灰度模型的一系列图片看作二维矩阵,做矩阵的加运算,把累加后得到的二维矩阵看作灰度图像；(4)对叠加灰度图片应用阈值分割方法获得水印区域；(5)对水印区域膨胀一个像素点获得更大轮廓的区域作为最终水印区域,保证最终水印区域完全覆盖真实图像中对应的水印区域；(6)应用图像修复算法对最终水印区域进行修复并输出修复后的图像。</td>   <td>G06T5/00;G06T1/00;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>         阳可欣;              王美华;                   印鉴       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种结合主题模型的文档向量生成方法</td>   <td>广东</td>   <td>CN106919557A</td>   <td>2017-07-04</td>   <td>本发明提供一种结合主题模型的文档向量生成方法,该方法获取文档集合并对其进行预处理,然后用LDA对文档集合进行训练,得到每篇文档中每个词的主题,并将词和主题组成&lt;词,主题&gt;对,将&lt;词,主题&gt;对组成的文档集合输入到Doc2vec文档向量模型中,训练生成主题文档向量,该过程将文档中词的主题信息融入到文档向量的训练过程中,能够训练出包含主题信息的主题文档向量,从而提升文本分类、文本相似度计算等自然语言处理任务的准确度。</td>   <td>一种结合主题模型的文档向量生成方法,其特征在于,包括以下步骤：S1：获取文档集合并对其进行预处理；S2：用LDA对文档集合进行训练,得到每篇文档中每个词的主题；S3：将词和主题组成&lt;词,主题&gt;对；S4：将&lt;词,主题&gt;对组成的文档集合输入到Doc2vec文档向量模型中,训练生成主题文档向量。</td>   <td>G06F17/27;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              尚保林;              许沥文;              黄开德;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种基于探测信号的3D成像与人体识别方法</td>   <td>广东</td>   <td>CN106919931A</td>   <td>2017-07-04</td>   <td>本发明公开了一种基于探测信号的3D成像与人体识别方法,是基于无线探测网络中采集到的探测信号强度值进行3D成像与人体识别,首先通过记录信号接收器检测到的信号强度值,将数据上传到上位机进行反投影,然后进行规范化标准操作,将得到随时间变化的剖面图合并起来输出3D成像图,最后将成像图与数据库存储的图像进行比照,得到识别结果。总之,相比现有技术,本发明方法简单、新颖,能很好地得到3D成像结果并有效识别目标。</td>   <td>一种基于探测信号的3D成像与人体识别方法,其特征在于：首先,通过记录信号接收器检测到的信号强度值,将数据上传到上位机进行3D成像,并将成像图与数据库存储的图像进行比照,最后输出成像以及识别结果；其具体包括以下步骤：1)在兴趣区域部署信号发生器与信号接收器,每一个信号接收器均能接收到至少一个信号发生器产生的信号,采集并存储每个信号发生器标识ID和对应的信号强度值读数；其中,在兴趣区域部署信号发生器与信号接收器需要满足预定条件：在兴趣区域范围内,存在信号发生器生成的信号穿过被成像目标；2)将数据传送到上位机进行预处理,包括清洗、过滤；3)兴趣区域里没有兴趣目标,即在空场景离线条件下,采集并保存传感器的数据,作为区域信号强度的基准值y<sub>0</sub>；4)兴趣区域存在兴趣目标,即在线条件下,采集并保存t时刻信号接收器数据,作为区域信号强度的实时测量值<img file="FDA0001243761870000011.TIF" wi="115" he="86" />即在线条件下的信号强度观测值；5)向量化处理信号传输网络中的信号强度值,得到相应的观测值,然后采用信号强度在空场景离线条件以及存在目标的在线条件下的变差值作为观测值y；具体地,<maths num="0001"><math><![CDATA[<mrow><mi>y</mi><mo> =</mo><msub><mi>y</mi><mn>0</mn></msub><mo>-</mo><mover><mi>y</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001243761870000012.TIF" wi="846" he="93" /></maths>式中,<img file="FDA0001243761870000013.TIF" wi="86" he="63" />为在线条件下的信号强度观测值,y<sub>0</sub>为基准值,维度均为R<sup>N×1</sup>,N为门竖直平面上的从信号发生器到信号接收器形成的信号链路总数；6)将兴趣区域分为满足预定条件大小的像素块,根据信号发生器与信号接收器的个数,计算出穿过第x像素块的直射信号个数,记为cnt(x)；其中,所述预定条件大小为使获得成像效果最好的像素块大小；7)将当前t时刻检测到的信号强度值<img file="FDA0001243761870000021.TIF" wi="86" he="62" />与基准数据进行比较,得到信号强度变化量y；8)利用信号的传播特性得出的椭圆模型设计测量矩阵,构建出成像的数学模型y＝φx+n,得到在t时刻第x像素的衰减值；其中,y为步骤7)变差法得到的当前时刻信号强度的变化量,φ为根据椭圆模型设计的测量矩阵,x为t时刻待重构的成像图,具体地,为步骤6)中像素块的衰减图,n为测量噪声；由椭圆模型设计得到的测量矩阵,其具体地表示及含义为：<img file="FDA0001243761870000022.TIF" wi="400" he="88" />φ的每个列向量表示特定某像素对所有链路的权重因子,T为对向量求转置,N为门禁竖直平面上的从信号发生器到信号接收器形成的信号链路总数；9)将上述反投影得到衰减值进行规范化标准操作,所述规范化标准操作是指为减小因步骤6)中每个像素块的cnt(x)不一致给衰减值带来的影响,设定第一阈值,进行均值处理,其中具体阴影衰落密度估计为：<maths num="0002"><math><![CDATA[<mrow><mover><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow><mo> =</mo><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><mfrac><mrow><msup><mi>p</mi><mo>&prime;</mo></msup><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow></mrow><mi>&alpha;</mi></mfrac><mo>,</mo></mrow></mtd><mtd><mrow><mi>c</mi><mi>n</mi><mi>t</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>&le;</mo><mi>&alpha;</mi></mrow></mtd></mtr><mtr><mtd><mrow><mfrac><mrow><msup><mi>p</mi><mo>&prime;</mo></msup><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow></mrow><mrow><mi>c</mi><mi>n</mi><mi>t</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow></mfrac><mo>,</mo></mrow></mtd><mtd><mrow><mi>c</mi><mi>n</mi><mi>t</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo>&gt;</mo><mi>&alpha;</mi></mrow></mtd></mtr></mtable></mfenced><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001243761870000023.TIF" wi="1126" he="295" /></maths>式中,p′(x,t)为直接反投影得到的阴影衰减值,cnt(x)为穿过该像素的信号链路条数,α为设定的第一阈值；10)设定第二阈值去除伪影,以提高成像质量,其具体表达式为：<maths num="0003"><math><![CDATA[<mrow><mover><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow><mo> =</mo><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><mi>0</mi><mo>,</mo></mrow></mtd><mtd><mrow><mover><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow><mo>&le;</mo><mi>&beta;</mi></mrow></mtd></mtr><mtr><mtd><mrow><mover><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow><mo>,</mo></mrow></mtd><mtd><mrow><mover><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>x</mi><mo>,</mo><mi>t</mi><mo>)</mo></mrow><mo>&gt;</mo><mi>&beta;</mi></mrow></mtd></mtr></mtable></mfenced><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>3</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001243761870000024.TIF" wi="1086" he="188" /></maths>式中,β为设定的第二阈值,阴影衰落密度不大于β时,认为该处为伪影,将其密度置0,从而提高成像质量；11)利用不同t时刻的数据得到随时间变化的剖面图,将所有剖面图合并起来就能够获得运动目标的3D影像,即为：<maths num="0004"><math><![CDATA[<mrow><mi>I</mi><mo> =</mo><mo>{</mo><mover><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>x</mi><mo>,</mo><msub><mi>t</mi><mn>1</mn></msub><mo>)</mo></mrow><mo>,</mo><mover><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>x</mi><mo>,</mo><msub><mi>t</mi><mn>2</mn></msub><mo>)</mo></mrow><mo>,</mo><mo>...</mo><mover><mi>p</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>x</mi><mo>,</mo><msub><mi>t</mi><mi>M</mi></msub><mo>)</mo></mrow><mo>}</mo><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>4</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001243761870000031.TIF" wi="1182" he="102" /></maths>式中,<img file="FDA0001243761870000032.TIF" wi="589" he="63" />分别为在时刻t<sub>1</sub>,t<sub>2</sub>,…t<sub>M</sub>时的阴影衰落密度；12)建立3D影像数据库,将当前3D影像与数据库中的影像比对以识别目标身份,计算模块将3D影像数据传送到控制模块,并由控制模块决定是否触发警报模块以及确定警报级别；其中,所述计算模块完成信号存储、计算、成像任务；所述控制模块完成配置、判断、定时任务；所述警报模块完成提醒、警告、紧急、报警任务；所述影像比对方式为提取当前3D影像的形状特征与运动边缘直方图特征,形成该运动3D影像的最终表达方式,并与数据库作比较,最高相似度低于阈值,则认为能触发警报模块。</td>   <td>G06K9/00;G06T15/00;G06K9/32</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;                   刘文奇       </td>   <td>中山大学</td>   <td>一种基于纹理缝合的图像十字绣风格化方法及装置</td>   <td>广东</td>   <td>CN106920209A</td>   <td>2017-07-04</td>   <td>本发明公开一种基于纹理缝合的图像十字绣风格化方法及装置,其方法包括：抽象化输入图像,获得抽象化图像；对抽象化图像进行背景剔除操作,获得背景遮蔽图和抽象化前景图；对抽象化前景图进行颜色简化及规范化处理,获得颜色规范化图像；对颜色规范化图像进行绣谱提取操作,获得十字绣绣谱图；对十字绣绣谱图进行绣谱指导的纹理合成处理,获得十字绣风格图。采用本发明可对图像进行风格化处理,合成具有十字绣风格的图像,这样人们就能够在开始绣制前得到大致的视觉反馈,了解绣制后的十字绣的大致外观。并且,在风格化处理的过程中,还能够自动化的提取出该幅十字绣的绣谱,从而减去了设计师的一些枯燥繁冗的劳动,大大加快了创作过程。</td>   <td>一种基于纹理缝合的图像十字绣风格化方法,其特征在于,所述方法包括：S1、抽象化输入图像,获得抽象化图像；S2、对抽象化图像进行背景剔除操作,获得背景遮蔽图和抽象化前景图；S3、对抽象化前景图进行颜色简化及规范化处理,获得颜色规范化图像；S4、对颜色规范化图像进行绣谱提取操作,获得十字绣绣谱图；S5、对十字绣绣谱图进行绣谱指导的纹理合成处理,获得十字绣风格图。</td>   <td>G06T3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何俊华;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于异构信息的评分推荐方法</td>   <td>广东</td>   <td>CN106909536A</td>   <td>2017-06-30</td>   <td>本发明提供了一种基于异构信息的评分推荐方法,其包括以下步骤：S1、获取物品的用户ID、物品ID、评分信息、评论信息和物品描述信息；S2、将评分信息、评论信息和物品描述信息分别转化成评分向量、评论向量和物品描述向量；S3、将评分向量、评论向量和物品描述向量代入损失函数中,并通过梯度下降的方法进行求解；S4、根据S3中的计算得到最终的变量,通过公式得到用户对于物品的推荐度。通过本发明提供的一种基于异构信息的评分推荐方法,解决了文字信息的短文本问题,能够更加有效地整合不同空间表达下的不同信息,让评分信息、物品信息、评论信息得到更好的融合,最后做出更加精准的推荐。</td>   <td>一种基于异构信息的评分推荐方法,其特征在于,包括以下步骤：S1、获取物品的用户ID、物品ID、评分信息、评论信息和物品描述信息；S2、将评分信息、评论信息和物品描述信息分别转化成评分向量、评论向量和物品描述向量；S3、将评分向量、评论向量和物品描述向量代入以下损失函数中,并通过梯度下降的方法进行求解；其中,评论向量和物品描述向量为常量,评分向量为变量；<maths num="0001"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><mrow><mi>L</mi><mi>o</mi><mi>s</mi><mi>s</mi><mo> =</mo><mi>F</mi><mo>-</mo><mfrac><msub><mi>&alpha;</mi><mrow><msub><mi>r</mi><mi>p</mi></msub><mo>,</mo><msub><mi>r</mi><mi>q</mi></msub></mrow></msub><mi>e</mi></mfrac><munder><mi>&Sigma;</mi><mrow><mi>p</mi><mo>&gt;</mo><mi>q</mi></mrow></munder><mi>ln</mi><mi> </mi><mi>C</mi><mrow><mo>(</mo><mrow><mo>|</mo><mo>|</mo><msub><mi>r</mi><mi>p</mi></msub><mo>|</mo><msubsup><mo>|</mo><mn>2</mn><mn>2</mn></msubsup><mo>-</mo><mo>|</mo><mo>|</mo><msub><mi>r</mi><mi>q</mi></msub><mo>|</mo><msubsup><mo>|</mo><mn>2</mn><mn>2</mn></msubsup></mrow><mo>)</mo></mrow></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><mfrac><msub><mi>&alpha;</mi><mi>r</mi></msub><mi>e</mi></mfrac><munder><mi>&Sigma;</mi><mrow><mrow><mo>(</mo><mrow><mi>u</mi><mo>,</mo><mi>r</mi><mo>,</mo><mi>v</mi></mrow><mo>)</mo></mrow><mo>&Element;</mo><msub><mi>R</mi><mi>r</mi></msub></mrow></munder><mfrac><msup><mrow><mo>(</mo><mrow><msubsup><mi>w</mi><mi>r</mi><mi>T</mi></msubsup><mi>r</mi></mrow><mo>)</mo></mrow><mn>2</mn></msup><mrow><mo>|</mo><mo>|</mo><mi>r</mi><mo>|</mo><msubsup><mo>|</mo><mn>2</mn><mn>2</mn></msubsup></mrow></mfrac><mo>+</mo><mfrac><msub><mi>&alpha;</mi><mi>c</mi></msub><mi>e</mi></mfrac><munder><mi>&Sigma;</mi><mrow><mrow><mo>(</mo><mrow><mi>u</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>v</mi></mrow><mo>)</mo></mrow><mo>&Element;</mo><msub><mi>R</mi><mi>c</mi></msub></mrow></munder><mfrac><msup><mrow><mo>(</mo><mrow><msubsup><mi>w</mi><mi>c</mi><mi>T</mi></msubsup><mi>c</mi></mrow><mo>)</mo></mrow><mn>2</mn></msup><mrow><mo>|</mo><mo>|</mo><mi>c</mi><mo>|</mo><msubsup><mo>|</mo><mn>2</mn><mn>2</mn></msubsup></mrow></mfrac><mo>+</mo><mfrac><msub><mi>&alpha;</mi><mi>d</mi></msub><mi>e</mi></mfrac><munder><mi>&Sigma;</mi><mrow><mrow><mo>(</mo><mrow><mi>d</mi><mo>,</mo><mi>v</mi></mrow><mo>)</mo></mrow><mo>&Element;</mo><msub><mi>R</mi><mi>d</mi></msub></mrow></munder><mfrac><msup><mrow><mo>(</mo><mrow><msubsup><mi>w</mi><mi>d</mi><mi>T</mi></msubsup><mi>d</mi></mrow><mo>)</mo></mrow><mn>2</mn></msup><mrow><mo>|</mo><mo>|</mo><mi>d</mi><mo>|</mo><msubsup><mo>|</mo><mn>2</mn><mn>2</mn></msubsup></mrow></mfrac></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FDA0001220485650000011.TIF" wi="1386" he="341" /></maths>其中,u表示用户特征向量,v表示物品特征向量,r表示评分向量,w<sub>r</sub>表示评分向量所处超平面的单位法向量；c表示评论向量,w<sub>c</sub>表示评论向量所处超平面的单位法向量；d表示物品描述向量,w<sub>d</sub>表示物品描述向量所处超平面的单位法向量,r<sub>p</sub>,r<sub>q</sub>分别指评分为p和q的评分向量,<img file="FDA0001220485650000013.TIF" wi="126" he="62" />α<sub>r</sub>,α<sub>c</sub>,α<sub>d</sub>分别代表r<sub>p</sub>和r<sub>q</sub>、r、c、d所占损失函数的权重,R<sub>r</sub>,R<sub>c</sub>,R<sub>d</sub>分别表示已经存在的评分关系集合、评论关系集合、物品描述关系集合,e是超参数,C(x)取sigmoid函数；进一步地,损失函数中的函数F为：<maths num="0002"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><mrow><mi>F</mi><mo> =</mo><munder><mi>&Sigma;</mi><mrow><mrow><mo>(</mo><mrow><mi>u</mi><mo>,</mo><mi>r</mi><mo>,</mo><mi>v</mi></mrow><mo>)</mo></mrow><mo>&Element;</mo><msub><mi>R</mi><mi>r</mi></msub></mrow></munder><mi>d</mi><mi>i</mi><mi>s</mi><msup><mrow><mo>(</mo><mrow><mrow><mo>(</mo><mrow><mi>u</mi><mo>-</mo><msubsup><mi>w</mi><mi>r</mi><mi>T</mi></msubsup><msub><mi>uw</mi><mi>r</mi></msub></mrow><mo>)</mo></mrow><mo>+</mo><mi>r</mi><mo>-</mo><mrow><mo>(</mo><mrow><mi>v</mi><mo>-</mo><msubsup><mi>w</mi><mi>r</mi><mi>T</mi></msubsup><msub><mi>vw</mi><mi>r</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><msub><mi>&lambda;</mi><mi>c</mi></msub><munder><mi>&Sigma;</mi><mrow><mrow><mo>(</mo><mrow><mi>u</mi><mo>,</mo><mi>c</mi><mo>,</mo><mi>v</mi></mrow><mo>)</mo></mrow><mo>&Element;</mo><msub><mi>R</mi><mi>c</mi></msub></mrow></munder><mi>d</mi><mi>i</mi><mi>s</mi><msup><mrow><mo>(</mo><mrow><mrow><mo>(</mo><mrow><mi>u</mi><mo>-</mo><msubsup><mi>w</mi><mi>c</mi><mi>T</mi></msubsup><msub><mi>uw</mi><mi>c</mi></msub></mrow><mo>)</mo></mrow><mo>+</mo><mi>c</mi><mo>-</mo><mrow><mo>(</mo><mrow><mi>v</mi><mo>-</mo><msubsup><mi>w</mi><mi>c</mi><mi>T</mi></msubsup><msub><mi>vw</mi><mi>c</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mtd></mtr><mtr><mtd><mrow><mo>+</mo><msub><mi>&lambda;</mi><mi>d</mi></msub><munder><mi>&Sigma;</mi><mrow><mrow><mo>(</mo><mrow><mi>d</mi><mo>,</mo><mi>v</mi></mrow><mo>)</mo></mrow><mo>&Element;</mo><msub><mi>R</mi><mi>d</mi></msub></mrow></munder><mi>d</mi><mi>i</mi><mi>s</mi><msup><mrow><mo>(</mo><mrow><mi>c</mi><mo>-</mo><mrow><mo>(</mo><mrow><mi>v</mi><mo>-</mo><msubsup><mi>w</mi><mi>d</mi><mi>T</mi></msubsup><msub><mi>vw</mi><mi>d</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow><mn>2</mn></msup></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FDA0001220485650000012.TIF" wi="1038" he="502" /></maths>其中,dis(x)表示向量x的欧几里得距离,λ<sub>c</sub>和λ<sub>d</sub>是权重参数,分别代表在函数F中评论信息和物品描述信息所占的比重；S4、根据S3中的计算得到最终的变量u,v,w<sub>r</sub>,w<sub>c</sub>,w<sub>d</sub>,通过以下公式得到用户u对于物品v的推荐度p：<maths num="0003"><math><![CDATA[<mrow><mi>p</mi><mo> =</mo><mn>1</mn><mo>/</mo><mrow><mo>(</mo><mo>|</mo><mo>|</mo><mo>(</mo><mrow><mi>v</mi><mo>-</mo><msubsup><mi>w</mi><mi>r</mi><mi>T</mi></msubsup><msub><mi>vw</mi><mi>r</mi></msub></mrow><mo>)</mo><mo>-</mo><mo>(</mo><mrow><mi>u</mi><mo>-</mo><msubsup><mi>w</mi><mi>r</mi><mi>T</mi></msubsup><msub><mi>uw</mi><mi>r</mi></msub></mrow><mo>)</mo><mo>|</mo><msubsup><mo>|</mo><mn>2</mn><mn>2</mn></msubsup><mo>+</mo><mn>1</mn><mo>)</mo></mrow><mo>.</mo></mrow>]]></math><img file="FDA0001220485650000021.TIF" wi="854" he="97" /></maths></td>   <td>G06F17/27;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗嘉文;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于主题模型和向量空间的一词多义分析方法</td>   <td>广东</td>   <td>CN106909537A</td>   <td>2017-06-30</td>   <td>本发明提供了一种基于主题模型和向量空间的一词多义分析方法,包括：S1、以式(1)作为目标函数,建立一词多义的主题模型；S2、读取整个文档集合D的数据；S3、主题#词分布<img file="DDA0001221638640000011.TIF" wi="43" he="43" />初始化；S4、主题采样；S5、主题向量更新；S6、词向量训练；S7、循环执行S4至S6若干次,以进行若干次迭代；S8、将得出的词向量和主题向量输出并存储；S9、判断是否一词多义。本发明提供的一种基于主题模型和向量空间的一词多义分析方法,可以训练出更优质的词向量、主题向量,使其在一词多义的研究分析中表现出更合理的解释,而且主题模型的表现也明显优于原始模型LDA。本发明通过主题模型、词向量、主题向量这三者的交叉学习来相互提高,能够有效应用于相似性评估、文档分类、主题相关性等任务。</td>   <td>一种基于主题模型和向量空间的一词多义分析方法,其特征在于,包括以下步骤：S1、以式(1)作为目标函数,建立一词多义的主题模型：<img file="FDA0001221638610000011.TIF" wi="1763" he="269" />其中<img file="FDA0001221638610000013.TIF" wi="46" he="44" />为文本文档集合,M为集合中的文档数,N<sub>m</sub>为第m篇文档的词的数量,c为上下文信息窗口大小,w<sub>m,n</sub>表示第m篇文档第n个词,K表示主题数目,t<sub>k</sub>表示第k个主题向量,<img file="FDA0001221638610000014.TIF" wi="38" he="40" />表示主题模型中的主题#词分布,<img file="FDA0001221638610000015.TIF" wi="84" he="54" />表示w<sub>m,n</sub>的主题编号；S2、读取整个文档集合<img file="FDA0001221638610000016.TIF" wi="44" he="43" />的数据；S3、主题#词分布<img file="FDA0001221638610000017.TIF" wi="37" he="40" />初始化：首先,采用GibbsLDA算法对文本文档集合<img file="FDA0001221638610000018.TIF" wi="42" he="43" />中的每个词进行主题采样；然后,对主题模型的主题#词分布<img file="FDA0001221638610000019.TIF" wi="38" he="40" />进行初始化估计；S4、主题采样：针对文档中的每一个词w<sub>m,n</sub>,计算出该词属于每个主题的概率,然后采用累加分布的方式采样出其对应的主题编号z<sub>m,n</sub>∈[1,K]；S5、主题向量更新：对于每个主题向量t<sub>k</sub>,k∈[1,K],根据式(5)重新计算出其向量表示：<img file="FDA0001221638610000012.TIF" wi="1358" he="327" />其中,<img file="FDA00012216386100000110.TIF" wi="99" he="54" />为指示函数,当x取值为真,其结果为1,否则为0。<img file="FDA00012216386100000111.TIF" wi="94" he="71" />表示词w<sub>m,n</sub>所对应的词向量表示,W表示文档集合的词汇表大小,n<sub>k,w</sub>表示词w被分配到主题k下的数目；S6、词向量训练：构造一棵哈夫曼树,叶子节点为词汇表中的每个词w,非叶子结点作为辅助向量u,采用随机梯度下降的方式求解式(1)所示的目标函数；S7、循环执行S4至S6若干次,以进行若干次迭代；S8、将得出的词向量和主题向量输出并存储；S9、判断是否一词多义：将待分析的词的词向量和主题向量相拼接,组成一个新向量,代表整个上下文环境,然后计算该新向量的余弦值,当余弦值小于设定阈值时,认定该词具有一词多义现象；反之认定该词不具有一词多义现象。</td>   <td>G06F17/27;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;              江倩殷;              李熙莹;                   张瑞娟       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种基于视频图像的车头间距测量方法及系统</td>   <td>广东</td>   <td>CN106898023A</td>   <td>2017-06-27</td>   <td>本发明公开了一种基于视频图像的车头间距测量方法及系统,方法包括：确定摄像机参数；在待测量车辆上确定测量点；根据摄像机参数计算测量点的世界坐标；根据测量点的世界坐标计算每辆待测量车辆的车头位置；根据每辆待测量车辆的车头位置计算相邻两辆车辆的车头间距。本发明基于视频图像来测量车头间距,误差更小；只需确定摄像机参数、测量点及其世界坐标,再结合现有车辆定位、车牌定位和车辆分割的方法,即可实现车头间距的自动测量,不再需人工操作,通过自动化测量的方式大大减小了人工工作量且成本较低；能精确计算相邻两辆车辆的车头间距而不是一个车队或者一个路段上的平均车头间距,更加可靠。本发明可广泛应用于智能交通领域。</td>   <td>一种基于视频图像的车头间距测量方法,其特征在于：包括以下步骤：确定摄像机参数,所述摄像机参数指能确定并表示摄像机姿态以及位置的参数；在待测量车辆上确定测量点,其中,测量点为待测量车辆的车体上一个高度已知且距离待测量车辆车头距离已知的点；根据摄像机参数计算测量点的世界坐标；根据测量点的世界坐标计算每辆待测量车辆的车头位置；根据每辆待测量车辆的车头位置计算相邻两辆车辆的车头间距。</td>   <td>G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁禹;                   黄林冲       </td>   <td>中山大学</td>   <td>一种浅覆水下盾构隧道最小覆土层厚度确定方法及其系统</td>   <td>广东</td>   <td>CN106897475A</td>   <td>2017-06-27</td>   <td>本发明公开了一种浅覆水下盾构隧道最小覆土层厚度确定方法及其系统,根据极限平衡的思想,由∑Y＝0建立隧道上覆土处于极限平衡状态时的平衡方程；根据隧道上覆土处于极限平衡状态时的平衡方程,综合考虑隧道管片外径和内径、管片重度、管片环间螺栓连接的螺栓预紧力、管片环间摩擦系数、同步注浆浆液重度、地层饱和重度、地层摩擦角和静止侧压力系数得到最小覆土厚度的计算公式；在考虑最大注浆压力条件下和不考虑注浆压力条件下,得到最小覆土层厚度取值范围,结合包括地层围岩种类、两岸接线难度和安全系数储备因素,最终确定最小覆土层厚度。</td>   <td>一种浅覆水下盾构隧道最小覆土层厚度确定方法,其特征在于,包括：步骤S1：根据极限平衡的思想,由∑Y＝0建立隧道上覆土处于极限平衡状态时的平衡方程；步骤S2：根据所述平衡方程,综合考虑隧道管片外径和内径、管片重度、管片环间螺栓连接的螺栓预紧力、管片环间摩擦系数、同步注浆浆液重度、地层饱和重度、地层摩擦角和静止侧压力系数得到最小覆土厚度的计算公式；步骤S3：根据所述最小覆土厚度的计算公式,分别计算在最大注浆压力条件下和忽略注浆压力条件下的最小覆土层厚度值,得到最小覆土层厚度取值范围的大小边界值,结合包括地层围岩种类、两岸接线难度和安全系数储备因素,最终确定最小覆土层厚度。</td>   <td>G06F17/50;G06F17/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李晓苗;              周凡;                   韩冠亚       </td>   <td>中山大学</td>   <td>一种工程供应链中工程调度的处理方法及系统</td>   <td>广东</td>   <td>CN106886882A</td>   <td>2017-06-23</td>   <td>本发明实施例公开了一种工程供应链中工程调度的处理方法及系统,其中,该方法包括：从前端接收业主需求数据、承包商工程规划数据、系统资源数据、子活动模式数据,将接收的数据传送至系统数据库中并存储；对业主需求数据、承包商工程规划数据、系统资源数据、子活动模式数据进行综合和预处理,获得项目参数、资源情况数据、每种活动的具体信息；读取预处理后得到的项目参数、资源情况数据、每种活动的具体信息,利用多目标遗传算法对工程项目进行优化,得出一系列较优的工程可执行方案；读取优化得到的可执行解,并在前端显示。实施本发明实施例,可以解决资源受限的工程调度问题,提高方案执行的效率。</td>   <td>一种工程供应链中工程调度的处理方法,其特征在于,所述方法包括：从前端接收业主需求数据、承包商工程规划数据、系统资源数据、子活动模式数据,将接收的数据传送至系统数据库中并存储；从系统数据库中读取项目中业主需求数据、承包商工程规划数据、系统资源数据、子活动模式数据；对业主需求数据、承包商工程规划数据、系统资源数据、子活动模式数据进行综合和预处理,获得项目参数、资源情况数据、每种活动的具体信息；读取预处理后得到的项目参数、资源情况数据、每种活动的具体信息,利用多目标遗传算法对工程项目进行优化,得出一系列较优的工程可执行方案；读取优化得到的可执行解,并在前端显示。</td>   <td>G06Q10/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         潘子潇;              谢晓华;                   尹冬生       </td>   <td>中山大学</td>   <td>一种跨摄像头的行人轨迹匹配方法</td>   <td>广东</td>   <td>CN106887014A</td>   <td>2017-06-23</td>   <td>本发明涉及一种跨摄像头的行人轨迹匹配方法,包括以下步骤：S1.提取目标摄像头的一条行人轨迹作为目标轨迹,然后将其余摄像头在该时间段内出现的所有行人轨迹作为候选轨迹；S2.使用中国连锁餐厅过程训练分层狄利克雷过程,提取所有轨迹的全局运动模式特征,同时获得目标轨迹和各条候选轨迹在全局运动模式特征上的特征权重；S3.分别计算目标轨迹特征权重与各条候选轨迹特征权重之间的余弦距离作为相似性度量,然后将余弦距离最小的候选轨迹作为目标轨迹的匹配轨迹。</td>   <td>一种跨摄像头的行人轨迹匹配方法,其特征在于：包括以下步骤：S1.提取目标摄像头的一条行人轨迹作为目标轨迹,然后将其余摄像头在该时间段内出现的所有轨迹作为候选轨迹；S2.使用中国连锁餐厅过程训练分层狄利克雷过程,提取所有轨迹的全局运动模式特征,同时获得目标轨迹和各条候选轨迹在全局运动模式特征上的特征权重；S3.分别计算目标轨迹特征权重与各条候选轨迹特征权重之间的余弦距离作为相似性度量,然后将余弦距离最小的候选轨迹作为目标轨迹的匹配轨迹。</td>   <td>G06T7/292;G06T7/246;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陆遥;              孙颖;              喻莎;              田皎;              林丽;                   李赋       </td>   <td>中山大学</td>   <td>一种基于互关联规则的鼻咽癌原发病灶临床靶区自动勾画方法</td>   <td>广东</td>   <td>CN106875367A</td>   <td>2017-06-20</td>   <td>本发明公开了一种基于互关联规则的鼻咽癌原发病灶临床靶区自动勾画方法,包括下述步骤：生成鼻咽原发肿瘤区域的二值图像；去掉肿瘤最外层的不稳定数据；对模板CT的图像序列进行数据离散操作,将图像序列划分并生成对应三维网格；在三维的肿瘤区域内,对体素联合出现的频数进行统计,建立关联规则的数据库；读入需要勾画临床靶区的新病人大体肿瘤数据,使用胡关联规则,模拟肿瘤生长,自动勾画出临床放疗靶区。与目前人工勾画相比,本系统实现了勾画自动化,提高了医生的工作效率。勾画结果达到医生要求的勾画标准,局部的调整将作为后处理,提供给医生选择。</td>   <td>一种基于互关联规则的鼻咽癌原发病灶临床靶区自动勾画方法,其特征在于,包括下述步骤：S1、生成鼻咽原发肿瘤区域的二值图像,所述二值图像为：读入医生勾画好的肿瘤轮廓文件,对应肿瘤区域的图像像素格点置1,不含肿瘤区域的像素格点置0；S2、去掉二值图像中肿瘤表面的不稳定数据,所述的不稳定数据是指：肿瘤表面的数据,由于拍片时间不同,会导致肿瘤表面最外层体素联合出现的频数计算出现误差；S3、对模板CT的图像序列进行数据离散操作,将图像序列划分并生成对应三维网格；S4、在三维的肿瘤区域内,对体素联合出现的频数进行统计,建立关联规则的数据库；S5、读入需要勾画临床靶区的新病人大体肿瘤数据,使用胡关联规则,模拟肿瘤生长,自动勾画出临床放疗靶区,具体为：以肿瘤边界处的三个相邻体素为索引,在频繁项集合数据库中,找出与该索引相关联的候选体素,再根据互关联规则,判断肿瘤下一步将侵犯的体素位置。</td>   <td>G06T5/00;G06T15/00;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王立;                   林小拉       </td>   <td>中山大学</td>   <td>一种利用软件定义网络优化的共识算法</td>   <td>广东</td>   <td>CN106875165A</td>   <td>2017-06-20</td>   <td>本发明提供一种利用软件定义网络优化的共识算法,该明使用SDN设计网络层,保证数据传输的有序性后,简化了应用层算法的设计,改进后的Raft拥有更高的响应速度。使用Raft作为私有链的共识算法,避免了PoW等共识算法对算力资源的浪费,缩短了生成区块的时间,大大提高了共识机制的效率和单位时间可处理的交易量。</td>   <td>一种利用软件定义网络优化的共识算法,包括以下步骤：S1：客户端向服务器集群广播请求,服务器处理请求后将结果返回给客户端；服务器收到请求后会根据角色产生不同的响应,服务器的角色包括：追随者Follower、申请者Candidate和领导者Leader,服务器处理请求并将结果存储到日志后,追随者Follower将结果发送到领导者Leader,Leader直接发送给客户端；服务器完成Candidate角色时,在选举过程才会出现,Leader宕机后进入选举过程,选举过程中服务器不响应客户端的请求；S2：服务器间同步请求执行结果,保证一致性。</td>   <td>G06Q20/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁湘国;              苏卓;              李波;              冷成财;                   罗笑南       </td>   <td>中山大学;南昌航空大学</td>   <td>一种基于卷积神经网络的灰阶图像着色方法及其装置</td>   <td>广东</td>   <td>CN106855996A</td>   <td>2017-06-16</td>   <td>本发明实施例公开了一种基于卷积神经网络的灰阶图像着色方法及其装置,其中,该方法包括：收集图片集；选择向量化的卷积神经网络模型VCNN,并构造相应的网络结构；修改所述向量化的卷积神经网络模型VCNN；对所述图片集中的图片进行转换,获得相应YUV颜色空间的图片,从中随机抽取64x64的Y值块,同时抽取相应位置的U值块和V值块；训练网络,利用反向传播算法和随机梯度下降法更新网络参数；得到经过训练的网络后,利用网络进行着色,输入灰度块,输出相应的U值和V值,获得彩色图片。实施本发明实施例,解决了需要人为提供涂鸦或样例图片的缺点,实现全自动的图片着色,并解决了着色速度慢、着色效果不稳定的缺点,使得着色效果较自然而且稳定。</td>   <td>一种基于卷积神经网络的灰阶图像着色方法,其特征在于,所述方法包括：收集图片集；选择向量化的卷积神经网络模型VCNN,并构造相应的网络结构；修改所述向量化的卷积神经网络模型VCNN；对所述图片集中的图片进行转换,获得相应YUV颜色空间的图片,从中随机抽取64x64的Y值块,同时抽取相应位置的U值块和V值块；训练网络,利用反向传播算法和随机梯度下降法更新网络参数；得到经过训练的网络后,利用网络进行着色,输入灰度块,输出相应的U值和V值,获得彩色图片。</td>   <td>G06T1/20;G06T1/60;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马璇;                   林小拉       </td>   <td>中山大学</td>   <td>一种基于MCMC过程的无向图重排序算法</td>   <td>广东</td>   <td>CN106844702A</td>   <td>2017-06-13</td>   <td>本发明提供一种基于MCMC过程的无向图重排序算法,该算法充分利用马尔科夫链可以收敛到平稳分布的特性,经过一段时间的迭代过程,算法最终达到的分布与初始值无关,也就是算法最终的结果与图的初始社区{1,...,n}<sup>n</sup>无关；本发明在迭代过程中引入随机化因数,一定程度上可以避免了算法陷入局部最优解,从而达到全局最优解,算法具有较好的鲁棒性,迭代过程具有多样性；本发明每次迭代过程中概率数组P的计算与邻接矩阵A的计算和更新都只与当前节点i及其邻接节点有关,很大程度上减少了算法计算量,另外,随着迭代的进行,社区的数量是逐步减少的,迭代过程也会越来越快。</td>   <td>一种基于MCMC过程的无向图重排序算法,其特征在于,包括以下步骤：S1：将图G＝(V,E)中的每个节点看成一个独立的社区,社区的数目等于节点个数,记C<sub>i</sub>为节点i所属的社区；S2：选择图G的节点i,对于它的每个邻居节点j,若C<sub>i</sub>不等于C<sub>j</sub>,把i分配至节点j所在的社区,计算此时模块度ΔQ<sub>ij</sub>的变化,然后计算：<maths num="0001"><math><![CDATA[<mrow><msub><mi>P</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo> =</mo><msubsup><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow><mi>I</mi></msubsup><mo>*</mo><mi>exp</mi><mrow><mo>(</mo><mi>&beta;</mi><mo>*</mo><msub><mi>&Delta;Q</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001212595810000011.TIF" wi="462" he="71" /></maths>其中β＞0,A为图G＝(V,E)的邻接矩阵；S3：对步骤S2中数组P进行归一化处理,得到把节点i分配至其邻居节点的概率数组,然后根据概率数组,取样P<sub>ij</sub>最大的一个邻居节点并且把i合并至其所在的社区,并把这次合并通过系统树图记录起来；S4：重复步骤S2直到算法收敛或者达到最大的迭代次数；S5：根据系统树图,采用深度优先搜索方法对节点进行重新排序。</td>   <td>G06F17/30;G06N7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              王伟轩;              张俊轩;              杨梁;                   王腾       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于FCN特征提取的多模态循环神经网络图像描述方法</td>   <td>广东</td>   <td>CN106844442A</td>   <td>2017-06-13</td>   <td>本发明提供一种基于FCN特征提取的多模态循环神经网络图像描述方法,通过对海量已标注文本描述的图像训练得到一个由三部分(循环神经网络RNN,全卷积神经网络FCN,多模态层)组成的多模态模型,并实现对任意输入测试图像的文本描述的自动生成,该发明能够有效地提取图像特征,并保留图像更多的细节信息,能更好建立文本描述中单词和图像的联系。对基于语义上,图像显著目标或场景间的描述有很好的表现。</td>   <td>一种基于FCN特征提取的多模态循环神经网络图像描述方法,其特征在于,包括构建每一时间帧的多模态循环神经网络模型,过程如下：S1：构造与训练全卷积网络FCN；S2：构造与训练多模态循环神经网络M#RNN；S3：利用得到的全卷积网络FCN和多模态循环神经网络M#RNN自动生成图像描述。</td>   <td>G06F17/30;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              李昊曦;              顾建权;                   谢斯岳       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于贝叶斯概率与神经网络的图像分割方法</td>   <td>广东</td>   <td>CN106846321A</td>   <td>2017-06-13</td>   <td>本发明公开一种基于贝叶斯概率与神经网络的图像分割方法,包括：为每个像素定义一个后验概率能量函数,通过利用基于贝叶斯概率计算的形态学膨胀方法对每个像素的相邻像素进行计算,然后对该像素的进行膨胀,使具有相似或者相同的后验概率分布的像素作为对分割分类的神经网络的输入。通过将该像素及其自适应的相邻像素输入到一个多层的神经网络中,提取判别性的特征判断是否为待分割图像的前景或背景,达到有效分割的效果。</td>   <td>一种基于贝叶斯概率与神经网络的图像分割方法,其特征在于,包括以下步骤：(1)对于图像的每一个像素,计算该像素的后验概率能量函数,得到该像素的能量值；(2)以该像素为中心,向该像素的邻域扩展,利用贝叶斯概率计算其相邻像素与该像素的相邻关系,选择后验概率大的M个像素；(3)设定高斯分布函数作为被选择的M个像素的条件概率密度函数,然后使用K#means聚类算法对M个像素进行聚类,包括中心点的初始化和聚类收敛；(4)根据聚类结果,选择类别大的一类的聚类中心点为中心,计算N个到该中心最近的像素点作为神经网络的输入数据；(5)将最终被选取的N个像素点作为神经网络的输入数据,提取判别性特征,根据SVM分类器判断该像素属于前景还是背景,实现图像分割。</td>   <td>G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              肖翔;                   李昊曦       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于深度卷积特征多通道金字塔池化的动作识别方法</td>   <td>广东</td>   <td>CN106845329A</td>   <td>2017-06-13</td>   <td>本发明公开一种基于深度卷积特征多通道金字塔池化的动作识别方法,包括：1)对输入视频每一帧采用空间流深度网络模型,得到每帧的表观特征；对视频中每连续M帧采用时间流深度网络模型,提取视频的运动特征；2)对空间流深度网络模型和时间流深度网络模型得到的多通道深度特征图采用4层空间金字塔结构,得到的每个局部块用最大池化方法计算该块的最大值表达,获取特征图在不同尺度下的局部信息；3)将深度特征图中在相同时空位置的多通道局部块的表达连接起来,形成视频的特征描述子；4)采用增强型局部级联描述子向量方法进行特征表示,得到视频的中层表示；4)采用线性支持向量机进行特征分类,得到识别准确率。</td>   <td>一种基于深度卷积特征多通道金字塔池化的动作识别方法,其特征在于,包括以下步骤：(1)输入待识别的视频,采用two#stream深度网络模型得到多通道深度卷积图；其中two#stream网络模型包括空间流(spatial#stream)深度网络模型和时间流(temporal#stream)深度网络模型。具体是：对输入视频的每一帧采用空间流网络,得到帧的表观特征；对输入视频的每连续M帧,利用时间流网络模型得到运动特征；其中空间流网络和时间流网络模型均包含5个卷积层,3个池化层,以及3个全连接层；(2)对空间流深度网络模型和时间流深度网络模型得到的多通道深度特征图采用4层空间金字塔结构,得到的每个局部块用最大池化方法计算该局部块的最大值表达,获取特征图在不同尺度下的局部信息；(3)将深度特征图中在相同时空位置的多通道局部块的表达连接起来,形成视频的特征描述子；(4)对步骤(3)提取的描述子特征采用局部级联描述子向量方法(VLAD)进行特征建模,形成该视频最终的向量表示；(5)采用支持向量机(SVM)进行特征分类,最终输出分类结果,获取视频的动作识别结果。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              林大钧;              许丹丹;              林梓健;                   柯博       </td>   <td>中山大学</td>   <td>一种结合时空拓扑估计的跨摄像机目标匹配与跟踪方法</td>   <td>广东</td>   <td>CN106846378A</td>   <td>2017-06-13</td>   <td>本发明提供的方法主要有两个发明点,一是研究基于特征匹配的目标匹配跟踪算法,采用多种具有互补性质的表观特征建立匹配模型,并将多种特征的匹配结果进行决策级的融合；二是提出一种无监督的拓扑估计算法,使系统能够在匹配与跟踪的过程中自动建立监控网络的时空拓扑关系,同时利用时空拓扑约束极大地提高了匹配与跟踪的准确度。本发明对跨摄像机目标匹配中由于遮挡、环境、光照等变化带来的干扰具有较强的鲁棒性,有利于实现多摄像机视频监控系统对目标的鲁棒协同跟踪。</td>   <td>一种结合时空拓扑估计的跨摄像机目标匹配与跟踪方法,其特征在于：包括以下步骤：S1.将两两摄像机之间的转移概率初始化为<img file="FDA0001217649430000011.TIF" wi="91" he="118" />M为监控网络中摄像机的数量；时间窗口设置为TW＝τ,τ为预设值,两两摄像机间的转移计数器初始化为0；S2.设当前摄像机为C<sub>i</sub>,摄像机C<sub>i</sub>内的行人目标表示为O<sub>i,a</sub>；在设定的时间窗口内搜索其他摄像机中出现的行人目标；S3.设在摄像机C<sub>j</sub>中搜索得到的行人目标为O<sub>j,b</sub>,i≠j,1≤j≤M,计算行人目标O<sub>i,a</sub>、O<sub>j,b</sub>之间的匹配概率：<maths num="0001"><math><![CDATA[<mrow><msub><mi>P</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mrow><mo>(</mo><msubsup><mi>k</mi><mrow><mi>i</mi><mo>,</mo><mi>a</mi></mrow><mrow><mi>j</mi><mo>,</mo><mi>b</mi></mrow></msubsup><mo>|</mo><msub><mi>O</mi><mrow><mi>i</mi><mo>,</mo><mi>a</mi></mrow></msub><mo>,</mo><msub><mi>O</mi><mrow><mi>j</mi><mo>,</mo><mi>b</mi></mrow></msub><mo>)</mo></mrow><mo> =</mo><mfrac><mrow><msub><mi>P</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mrow><mo>(</mo><msub><mi>O</mi><mrow><mi>i</mi><mo>,</mo><mi>a</mi></mrow></msub><mo>,</mo><msub><mi>O</mi><mrow><mi>j</mi><mo>,</mo><mi>b</mi></mrow></msub><mo>|</mo><msubsup><mi>k</mi><mrow><mi>i</mi><mo>,</mo><mi>a</mi></mrow><mrow><mi>j</mi><mo>,</mo><mi>b</mi></mrow></msubsup><mo>)</mo></mrow><msub><mi>P</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mrow><mo>(</mo><msubsup><mi>k</mi><mrow><mi>i</mi><mo>,</mo><mi>a</mi></mrow><mrow><mi>j</mi><mo>,</mo><mi>b</mi></mrow></msubsup><mo>)</mo></mrow></mrow><mrow><msub><mi>P</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mrow><mo>(</mo><msub><mi>O</mi><mrow><mi>i</mi><mo>,</mo><mi>a</mi></mrow></msub><mo>,</mo><msub><mi>O</mi><mrow><mi>j</mi><mo>,</mo><mi>b</mi></mrow></msub><mo>)</mo></mrow></mrow></mfrac></mrow>]]></math><img file="FDA0001217649430000012.TIF" wi="995" he="166" /></maths><img file="FDA0001217649430000013.TIF" wi="70" he="69" />为表示O<sub>i,a</sub>、O<sub>j,b</sub>之间转移关系的变量,当O<sub>i,a</sub>、O<sub>j,b</sub>之间存在转移关系时,<img file="FDA0001217649430000014.TIF" wi="70" he="70" />取1,否则取0；<img file="FDA0001217649430000015.TIF" wi="377" he="79" />表示目标O<sub>i,a</sub>、O<sub>j,b</sub>存在转移关系的后验概率,对应了目标O<sub>i,a</sub>、O<sub>j,b</sub>的匹配概率；<img file="FDA0001217649430000016.TIF" wi="382" he="86" />表示在转移关系<img file="FDA0001217649430000017.TIF" wi="70" he="71" />的条件下目标O<sub>i,a</sub>、O<sub>j,b</sub>的表观特征分布似然函数,定义为与目标表观相似度函数L(O<sub>i,a,</sub>O<sub>j,b</sub>)成正比,<img file="FDA0001217649430000018.TIF" wi="186" he="79" />表示两个目标存在转移关系的先验概率,通过计算摄像机C<sub>i</sub>到摄像机C<sub>j</sub>的目标转移概率得到；P<sub>i,j</sub>(O<sub>i,a</sub>,O<sub>j,b</sub>)表示目标O<sub>i,a</sub>,O<sub>j,b</sub>的联合概率分布,是后验概率的归一化因子；S4.对监控网络中除摄像机C<sub>i</sub>外的所有摄像机执行步骤S2、S3,然后对得到的各个摄像机的行人目标与摄像机C<sub>i</sub>的行人目标的匹配概率进行排序,将匹配概率最高的前m个行人目标作为候选匹配目标,对应的摄像机作为候选匹配摄像机,m的取值为1或2：<img file="FDA0001217649430000019.TIF" wi="598" he="155" />其中,s<sub>1</sub>为最高的匹配概率,s<sub>2</sub>为次高的匹配概率,s<sub>τ</sub>为设定的阈值；S5.计算摄像机之间的转移次数w<sub>p</sub>：<img file="FDA0001217649430000021.TIF" wi="685" he="175" />s<sub>p</sub>表示最高的匹配概率或次高的匹配概率,1≤p≤m；当m＝1时,将摄像机C<sub>i</sub>到摄像机C<sub>g</sub>之间的转移计数N<sub>ig</sub>增加w<sub>1</sub>；当m＝2时,将摄像机C<sub>i</sub>到摄像机C<sub>g</sub>之间的转移计数N<sub>ig</sub>增加w<sub>1</sub>,然后将摄像机C<sub>i</sub>到摄像机C<sub>k</sub>之间的转移计数N<sub>ik</sub>增加w<sub>2</sub>；其中摄像机C<sub>g</sub>、摄像机C<sub>k</sub>分别为与C<sub>i</sub>匹配概率最高、次高的摄像机；S6.将各个摄像机作为当前摄像机然后执行步骤S2～S5；S7.计算摄像机C<sub>i</sub>到摄像机C<sub>j</sub>之间的转移概率：<maths num="0002"><math><![CDATA[<mrow><mi>P</mi><mrow><mo>(</mo><msub><mi>C</mi><mi>j</mi></msub><mo>|</mo><msub><mi>C</mi><mi>i</mi></msub><mo>)</mo></mrow><mo> =</mo><mfrac><msub><mi>N</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><msubsup><mo>&Sigma;</mo><mrow><mi>k</mi><mo> =</mo><mn>0</mn><mo>,</mo><mi>k</mi><mo>&NotEqual;</mo><mi>i</mi></mrow><mi>M</mi></msubsup><msub><mi>N</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub></mrow></mfrac><mo>;</mo></mrow>]]></math><img file="FDA0001217649430000022.TIF" wi="508" he="158" /></maths>S8.根据步骤S7计算两两摄像机之间的转移概率；S9.记录摄像机C<sub>i</sub>到摄像机C<sub>j</sub>所有匹配的行人目标之间的时间间隔,构成时间序列T<sub>ij</sub>,然后利用自适应的Parzen窗算法估计出摄像机C<sub>i</sub>与摄像机C<sub>j</sub>之间的转移时间分布的概率密度曲线,取与曲线峰值对应的时间差值作为时间窗口大小T(C<sub>j</sub>|C<sub>i</sub>)的估计值；S10.根据步骤S9估算出两两摄像机之间的时间窗口大小；S11.更新摄像机C<sub>i</sub>、摄像机C<sub>j</sub>之间的转移概率：P<sub>ij</sub>(k)＝(1#α)P<sub>ij</sub>(k#1)+αP(C<sub>j</sub>|C<sub>i</sub>)P<sub>ij</sub>(k)表示第k次迭代得到的摄像机C<sub>i</sub>到摄像机C<sub>j</sub>的转移概率,α是更新因子,0≤α≤1,P<sub>ij</sub>(k#1)表示第k#1次迭代得到的摄像机C<sub>i</sub>到摄像机C<sub>j</sub>的转移概率,当k＝1时,<img file="FDA0001217649430000023.TIF" wi="317" he="111" />S12.根据步骤S11对两两摄像机之间的转移概率进行更新；S13.更新摄像机C<sub>i</sub>与摄像机C<sub>j</sub>之间的时间窗口：T<sub>ij</sub>(k)＝(1#η)T<sub>ij</sub>(k#1)+ηT(C<sub>j</sub>|C<sub>i</sub>)其中T<sub>ij</sub>(k)表示第k次迭代得到的摄像机C<sub>i</sub>与摄像机C<sub>j</sub>之间的时间窗口,T<sub>ij</sub>(k#1)表示第k#1次迭代得到的摄像机C<sub>i</sub>与摄像机C<sub>j</sub>之间的时间窗口,当k＝1时,T<sub>ij</sub>(k#1)＝τ,η表示更新因子；S14.判断是否达到了设定的迭代次数,若是则输出转移概率以及时间窗口估计值,完成拓扑结构估计,结束迭代,否则令k＝k+1然后执行步骤S6～S14。</td>   <td>G06T7/292;G06T7/246;G06T7/277;H04N7/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              黄玉婷;              徐伟嘉;                   杨鹏史       </td>   <td>中山大学</td>   <td>考虑动态交通流影响的城市高架桥附近流场数值模拟方法</td>   <td>广东</td>   <td>CN106844856A</td>   <td>2017-06-13</td>   <td>本发明提供一种考虑动态交通流影响的城市高架桥附近流场数值模拟方法,该方法主要针对高架桥道路场景进行简化的物理模型构建,将交通流的动态特性进行物理参数化的表征,采用计算流体力学方法,对实际道路场景中流场进行数值模拟；首先将实际交通场景进行简化的模型构建；其次利用湍流脉动物理量参数化地表征交通流的动态特性；然后将交通流引起的湍流脉动量加载到计算流体力学的求解方程对流场进行模拟；最后以流场矢量图和速度分布云图展示道路场景中的流场情况和扩散条件,可以为城市污染热点区域的空气污染评估提供依据,并为城市交通规划和空气环境改善提供有效参考。</td>   <td>一种考虑动态交通流影响的城市高架桥附近流场数值模拟方法,其特征在于,包括以下步骤：S1：构建高架桥和其周边环境的简化物理模型；S2：参数化交通流动态特性对流场的影响；S3：划分交通流运动对流场产生作用的范围；S4：将交通流引起的湍流动能加载到数值模拟的控制方程中；S5：应用计算流体力学方法,求解控制方程,进行数值模拟。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              连丽娜;                   董佳羽       </td>   <td>中山大学</td>   <td>一种基于稀疏编码的人脸识别方法</td>   <td>广东</td>   <td>CN106845376A</td>   <td>2017-06-13</td>   <td>本发明涉及一种基于稀疏编码的人脸识别方法,传统的稀疏编码方法往往事先假定编码残余满足一定的概率分布形式,如拉普拉斯分布或高斯分布,在此基础上提出了<i>l</i><sub><i>1</i></sub>或<i>l</i><sub><i>2</i></sub>范式来求解稀疏编码系数。这样的处理手段在一些情况下会严重影响人脸识别的鲁棒特性,特别是当存在遮挡、噪声或其他形式的干扰时。本发明提供的方法针对传统稀疏编码方法的不足之处,引入迭代优化思想,其主要解决了以下两个问题：一是无需预先假定残差的分布形式,避免了不合理的残差分布函数对人脸识别鲁棒性带来的影响；二是有选择地保留了一部分有用的像素点进行识别,在大大减少了计算量的同时,更好地解决了遮挡和像素损坏等问题,获得了更鲁棒的识别性能。</td>   <td>一种基于稀疏编码的人脸识别方法,其特征在于：包括以下步骤：S1.设训练样本集中包括有k个已知对象,其中第i个对象所包含的n<sub>i</sub>个训练样本表示为矩阵<img file="FDA0001204666090000011.TIF" wi="611" he="71" />其中i＝1,2,…,k,v<sub>ij</sub>∈R<sup>m</sup>,j＝1,2,...,n<sub>i</sub>,v<sub>ij</sub>表示第i个对象的第j个训练样本对应的列向量,m表示v<sub>ij</sub>的维度,则训练样本集A可表示为：<maths num="0001"><math><![CDATA[<mrow><mi>A</mi><mo> =</mo><mo>&lsqb;</mo><msub><mi>A</mi><mn>1</mn></msub><mo>,</mo><msub><mi>A</mi><mn>2</mn></msub><mo>,</mo><mo>...</mo><mo>,</mo><msub><mi>A</mi><mi>k</mi></msub><mo>&rsqb;</mo><mo> =</mo><mo>&lsqb;</mo><msub><mi>v</mi><mn>11</mn></msub><mo>,</mo><msub><mi>v</mi><mn>12</mn></msub><mo>,</mo><mo>...</mo><mo>,</mo><msub><mi>v</mi><mrow><msub><mi>kn</mi><mi>k</mi></msub></mrow></msub><mo>&rsqb;</mo><mo>&Element;</mo><msup><mi>R</mi><mrow><mi>m</mi><mo>&times;</mo><mi>n</mi></mrow></msup><mo>,</mo></mrow>]]></math><img file="FDA0001204666090000012.TIF" wi="908" he="71" /></maths>其中<img file="FDA0001204666090000013.TIF" wi="173" he="133" />表示训练样本的总个数；S2.设测试样本表示为y,令重构样本y<sub>rec</sub>初始化为所有训练样本的均值；S3.计算y与y<sub>rec</sub>之间的残差e＝y#y<sub>rec</sub>；S4.定义对角矩阵P＝diag(p<sub>1</sub>,p<sub>2</sub>,…,p<sub>m</sub>)；其中<img file="FDA0001204666090000014.TIF" wi="395" he="142" />e<sub>d</sub>表示残差e的第d个分量,d＝1,2,…,m,τ表示设定的判决阈值；S5.定义Ψ＝{d|p<sub>d</sub>＝1,d∈{1,2,…,m}}为重构误差小于判决阈值的像素点位置集合,设Ψ中有c个元素,即Ψ＝{ψ<sub>1</sub>,ψ<sub>2</sub>,…,ψ<sub>c</sub>}；S6.从对角矩阵P中选择第ψ<sub>1</sub>,ψ<sub>2</sub>,…,ψ<sub>c</sub>行的元素构造投影矩阵P*∈R<sup>c×m</sup>；S7.计算编码向量x：<img file="FDA0001204666090000015.TIF" wi="678" he="87" />其中P*y#P*Ax用来衡量鲁棒编码后的重构人脸向量与输入人脸向量y之间的偏差,λ代表拉格朗日乘子,||·||<sub>1</sub>表示l<sub>1</sub>范式约束；S8.计算重构样本y<sub>rec</sub>：y<sub>rec</sub>＝Ax；S9.如已收敛或达到最大迭代次数,则输出最后一次迭代得到的编码向量x：<img file="FDA0001204666090000016.TIF" wi="510" he="71" />其中x<sub>i</sub>表示对象i的系数,<img file="FDA0001204666090000017.TIF" wi="550" he="78" />否则再次执行步骤S3～S8；S10.将编码向量x中除x<sub>i</sub>外的成员替换为0,得到向量δ<sub>i</sub>∈R<sup>n</sup>,i的初始值为1,然后对测试样本y进行重构：<maths num="0002"><math><![CDATA[<mrow><msub><mover><mi>y</mi><mo>~</mo></mover><mi>i</mi></msub><mo> =</mo><msub><mi>A&delta;</mi><mi>i</mi></msub><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001204666090000018.TIF" wi="238" he="62" /></maths><img file="FDA0001204666090000019.TIF" wi="46" he="62" />表示对象i重构的测试样本；S11.令i＝i+1,然后重复执行步骤S10,直至i&gt;k；S12.求取<img file="FDA0001204666090000021.TIF" wi="234" he="55" />与测试样本y的重构误差,测试样本y所属的对象为重构误差最小的<img file="FDA0001204666090000022.TIF" wi="48" he="55" />对应的对象：<maths num="0003"><math><![CDATA[<mrow><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>t</mi><mi>y</mi><mrow><mo>(</mo><mi>y</mi><mo>)</mo></mrow><mo> =</mo><mi>arg</mi><munder><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mi>i</mi></munder><mo>|</mo><mo>|</mo><msup><mi>P</mi><mo>*</mo></msup><mi>y</mi><mo>-</mo><msup><mi>P</mi><mo>*</mo></msup><msub><mover><mi>y</mi><mo>~</mo></mover><mi>i</mi></msub><mo>|</mo><msub><mo>|</mo><mn>1</mn></msub><mo>.</mo></mrow>]]></math><img file="FDA0001204666090000023.TIF" wi="710" he="95" /></maths></td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              岑杰鹏;                   王敬       </td>   <td>中山大学</td>   <td>一种基于动态时间规整与多核学习的动作识别方法</td>   <td>广东</td>   <td>CN106845386A</td>   <td>2017-06-13</td>   <td>本发明针对视频的人体动作识别问题,提供了一种基于动态时间规整与多核学习的动作识别方法,该方法能充分利用动作序列的全局时间结构信息和局部特征的频率分布信息,主要的改进点在于：1)基于动态时间规整方法创建了动作平均模板,这一模板包含了BoW模型表示中忽略掉的动作序列的时间信息；2)通过增广特征多核学习的方法对动作平均模板表示和BoW表示进行结合,并通过引入学习权重调整两者的贡献度；通过以上两点改进,提高动作识别的准确率。</td>   <td>一种基于动态时间规整与多核学习的动作识别方法,其特征在于：包括以下步骤：一、建立BoW表示S11.记动作类别总数为C,令第j类动作的训练动作样本集为<img file="FDA0001210749510000011.TIF" wi="414" he="78" />j＝1,2,..,C,其中<img file="FDA0001210749510000012.TIF" wi="59" he="70" />表示第j类动作的第i个训练动作样本,i＝1,2,..,N<sub>j</sub>,N<sub>j</sub>表示第j类动作的训练动作样本数；定义包含C类训练动作样本的集合<img file="FDA0001210749510000013.TIF" wi="507" he="110" />其中<img file="FDA0001210749510000014.TIF" wi="211" he="135" />为训练动作样本总数；S12.对训练动作样本T<sub>i</sub>的每帧图像提取底层描述子,基于提取的底层描述子建立起训练动作样本T<sub>i</sub>的自相似矩阵SSM,然后基于自相似矩阵对每帧图像进行Z个不同时间尺度的SSM描述子提取；训练动作样本T<sub>i</sub>各帧图像提取的SSM描述子按照各帧顺序形成描述子序列<img file="FDA0001210749510000015.TIF" wi="410" he="71" />其中Q<sub>i</sub>表示训练动作样本T<sub>i</sub>的帧数目,<img file="FDA0001210749510000016.TIF" wi="51" he="62" />表示第k帧的Z个SSM描述子；S13.对各个训练动作样本进行步骤S12的操作；S14.从所有训练动作样本的Z个时间尺度下的描述子中随机选取e个SSM描述子,然后利用k#means算法将其聚类成p个簇,p&lt;&lt;e,得到包含有p个词汇的码本；S15.计算训练动作样本T<sub>i</sub>中各个SSM描述子与码本各个词汇之间的距离,然后将训练动作样本T<sub>i</sub>中的各个SSM描述子分别与距离最接近的词汇关联起来,即利用码本对SSM描述子进行量化,码本各个词汇关联的SSM描述子的数量形成一个直方图表示,即为训练动作样本T<sub>i</sub>的BoW表示；S16.对各个训练动作样本进行步骤S15的操作获取各个训练动作样本的BoW表示；二、建立动作平均模板表示S21.初始化j的值为1；S22.为第j类动作构建一个初始的空的平均模板<img file="FDA0001210749510000017.TIF" wi="83" he="62" />初始化i的值为1；S23.若i＝1,令<img file="FDA0001210749510000018.TIF" wi="183" he="62" />其中<img file="FDA0001210749510000019.TIF" wi="50" he="62" />为训练动作样本<img file="FDA00012107495100000110.TIF" wi="59" he="62" />的SSM描述子序列,跳到步骤S26；否则,利用动态时间规整方法计算平均模板<img file="FDA00012107495100000111.TIF" wi="73" he="63" />与描述子序列<img file="FDA00012107495100000112.TIF" wi="57" he="63" />的累加距离：<maths num="0001"><math><![CDATA[<mrow><mi>D</mi><mrow><mo>(</mo><msub><mi>c</mi><mi>k</mi></msub><mo>)</mo></mrow><mo> =</mo><munder><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><msub><mi>c</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub></munder><mo>&lsqb;</mo><mi>D</mi><mrow><mo>(</mo><msub><mi>c</mi><mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>)</mo></mrow><mo>+</mo><mi>d</mi><mrow><mo>(</mo><msub><mi>c</mi><mi>k</mi></msub><mo>)</mo></mrow><mi>&omega;</mi><mrow><mo>(</mo><msub><mi>c</mi><mi>k</mi></msub><mo>)</mo></mrow><mo>&rsqb;</mo><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001210749510000021.TIF" wi="950" he="93" /></maths>其中c<sub>k</sub>＝(i<sub>k</sub>,j<sub>k</sub>)表示第k对帧,表示平均模板<img file="FDA0001210749510000022.TIF" wi="75" he="67" />中的第i<sub>k</sub>帧与描述子序列<img file="FDA0001210749510000023.TIF" wi="54" he="63" />中的第j<sub>k</sub>帧对齐,d(c<sub>k</sub>)表示第k对帧的SSM描述子的欧式距离,ω(c<sub>k</sub>)表示加权系数且ω(c<sub>k</sub>)＝i<sub>k</sub>#i<sub>k#1</sub>+j<sub>k</sub>#j<sub>k#1</sub>；S24.基于公式(1),由最后一对对齐帧回溯至最早一对对齐帧,获得最优路径p＝{c′<sub>l</sub>},其中c′<sub>l</sub>＝(i′<sub>l</sub>,j′<sub>l</sub>),表示平均模板<img file="FDA0001210749510000024.TIF" wi="75" he="63" />中的第i′<sub>l</sub>帧与描述子序列<img file="FDA0001210749510000025.TIF" wi="59" he="62" />中的第j<sub>l</sub>′帧对齐,对应的描述子映射集为<img file="FDA0001210749510000026.TIF" wi="427" he="79" />S25.利用平均模板<img file="FDA0001210749510000027.TIF" wi="99" he="62" />描述子序列<img file="FDA0001210749510000028.TIF" wi="50" he="62" />计算新的平均模板<img file="FDA0001210749510000029.TIF" wi="83" he="61" /><maths num="0002"><math><![CDATA[<mrow><msubsup><mi>R</mi><mi>i</mi><mi>j</mi></msubsup><mrow><mo>(</mo><mi>l</mi><mo>)</mo></mrow><mo> =</mo><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>&beta;</mi><mo>)</mo></mrow><msubsup><mi>R</mi><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow><mi>j</mi></msubsup><mrow><mo>(</mo><msubsup><mi>i</mi><mi>l</mi><mo>&prime;</mo></msubsup><mo>)</mo></mrow><mo>+</mo><msubsup><mi>&beta;S</mi><mi>i</mi><mi>j</mi></msubsup><mrow><mo>(</mo><msubsup><mi>j</mi><mi>l</mi><mo>&prime;</mo></msubsup><mo>)</mo></mrow><mo>,</mo><mi>l</mi><mo> =</mo><mn>1</mn><mo>,</mo><mo>...</mo><mo>,</mo><mi>L</mi><mo>.</mo></mrow>]]></math><img file="FDA00012107495100000210.TIF" wi="885" he="71" /></maths>其中,<img file="FDA00012107495100000211.TIF" wi="110" he="63" />表示新的平均模板的第l帧的描述子,<img file="FDA00012107495100000212.TIF" wi="138" he="70" />表示平均模板<img file="FDA00012107495100000213.TIF" wi="75" he="63" />第i′<sub>l</sub>帧的描述子,<img file="FDA00012107495100000214.TIF" wi="131" he="71" />表示描述子序列<img file="FDA00012107495100000215.TIF" wi="54" he="62" />第j′<sub>l</sub>帧的描述子,L表示最优路径上对齐帧的数目,β＝1/i；S26.令i＝i+1然后执行步骤S23～S25,直至i＞N<sub>j</sub>,得到第j类动作的最终的平均模板R<sub>j</sub>；S27.令j＝j+1然后执行步骤S22～S26,直至j＞C；S28.通过步骤S21～S27的计算,获得C个平均模板组成的平均模板集合R＝{R<sub>1</sub>,R<sub>2</sub>...,R<sub>C</sub>},其中R<sub>j</sub>表示第j类动作的最终的平均模板；S29.对平均模板和训练动作样本进行量化：S291.从所有训练动作样本的描述子中随机选取e′个SSM描述子,然后利用k#means算法将其聚类成p′个簇,p′＝e′,得到包含有p′个词汇的码本；S292.分别计算训练动作样本T<sub>i</sub>的描述子序列中每帧的SSM描述子与步骤S291中获得的码本的各个词汇之间的距离,将每帧的SSM描述子分别与距离最接近的词汇关联起来,得到训练动作样本T<sub>i</sub>量化的描述子序列；S293.对各个训练动作样本进行步骤S292的操作；通过步骤S292中同样的方式对各个平均模板进行量化,可得到各个平均模板量化的描述子序列；S210.对训练动作样本T<sub>i</sub>的量化描述子序列利用动态时间规整方法计算其与各个平均模板的量化描述子序列的平均距离,训练动作样本T<sub>i</sub>的量化描述子序列到各个平均模板的量化描述子序列的平均距离构成一个C维向量,该C维向量为训练动作样本T<sub>i</sub>的平均模板表示；对动作样本集合T中各训练动作样本进行同样操作获取各训练动作样本的平均模板表示；S211.为Z个不同时间尺度分别建立平均模板表示,具体地,针对每一个时间尺度,在步骤S21～S210中利用该时间尺度的描述子进行该时间尺度下的动作平均模板的构建、码本的构建以及平均模板表示的构建；将某个训练动作样本在Z个时间尺度下分别获得的平均模板表示拼接成一个向量,作为该训练动作样本最终的平均模板表示；三、结合BoW表示和平均模板表示的动作表示S31.利用增广特征多核学习(AFMKL)结合BoW表示和平均模板表示,增广特征多核学习的决策函数如下：<img file="FDA0001210749510000031.TIF" wi="719" he="78" />其中x表示BoW表示,x′表示平均模板表示,ω和β表示学习权重,<img file="FDA0001210749510000032.TIF" wi="37" he="45" />表示对BoW表示的非线性映射函数,φ表示对平均模板表示的非线性映射函数,b为偏置项,d<sub>1</sub>和d<sub>2</sub>为对BoW表示、平均模板表示进行加权的系数；S32.通过最小化结构风险函数,建立以下的最优化问题：<maths num="0003"><math><![CDATA[<mrow><munder><mi>min</mi><mi>d</mi></munder><mi>J</mi><mrow><mo>(</mo><mi>d</mi><mo>)</mo></mrow><mo>+</mo><mi>r</mi><mrow><mo>(</mo><mi>d</mi><mo>)</mo></mrow><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001210749510000033.TIF" wi="605" he="87" /></maths><maths num="0004"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><mrow><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo></mrow></mtd><mtd><mrow><munderover><mo>&Sigma;</mo><mrow><mi>m</mi><mo> =</mo><mn>1</mn></mrow><mn>2</mn></munderover><msub><mi>d</mi><mi>m</mi></msub><mo> =</mo><mn>1</mn></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FDA0001210749510000034.TIF" wi="269" he="127" /></maths>d<sub>m</sub>≥0,m＝1,2.其中<img file="FDA0001210749510000035.TIF" wi="1062" he="150" /><maths num="0005"><math><![CDATA[<mrow><mtable><mtr><mtd><mrow><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo></mrow></mtd><mtd><mrow><msub><mi>y</mi><mi>i</mi></msub><mover><mi>f</mi><mo>^</mo></mover><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>;</mo><msubsup><mi>x</mi><mi>i</mi><mo>&prime;</mo></msubsup><mo>)</mo></mrow><mo>&GreaterEqual;</mo><mn>1</mn><mo>-</mo><msub><mi>&xi;</mi><mi>i</mi></msub><mo>,</mo><msub><mi>&xi;</mi><mi>i</mi></msub><mo>&GreaterEqual;</mo><mn>0</mn><mo>,</mo><mi>i</mi><mo> =</mo><mn>1</mn><mo>,</mo><mo>...</mo><mo>,</mo><mi>N</mi></mrow></mtd></mtr></mtable><mo>.</mo></mrow>]]></math><img file="FDA0001210749510000036.TIF" wi="805" he="75" /></maths>s.t.表示服从后面的约束,d＝[d<sub>1</sub>,d<sub>2</sub>]<sup>T</sup>表示加权系数向量,<img file="FDA0001210749510000037.TIF" wi="253" he="111" />表示二次正则化项,x<sub>i</sub>表示第i个训练动作样本的BoW表示,x′<sub>i</sub>表示第i个训练动作样本的平均模板表示,y<sub>i</sub>∈{+1,#1}表示第i个训练动作样本的正负标签,ξ＝(ξ<sub>1</sub>,ξ<sub>2</sub>,...,ξ<sub>N</sub>)<sup>T</sup>表示松弛变量向量,ξ<sub>i</sub>表示第i个训练动作样本的松弛变量,λ表示惩罚参数,N为训练动作样本的数目；S33.为式(3)中每个不等式约束引入拉格朗日乘子α<sub>i</sub>,并记α＝(α<sub>1</sub>,α<sub>2</sub>,...,α<sub>N</sub>)<sup>T</sup>为对偶变量,将式(3)中的优化问题转换为其对偶形式：<maths num="0006"><math><![CDATA[<mrow><munder><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow><mi>&alpha;</mi></munder><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>&alpha;</mi><mi>i</mi></msub><mo>-</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo> =</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>&alpha;</mi><mi>i</mi></msub><msub><mi>&alpha;</mi><mi>j</mi></msub><msub><mi>y</mi><mi>i</mi></msub><msub><mi>y</mi><mi>j</mi></msub><mo>&lsqb;</mo><msub><mi>d</mi><mn>1</mn></msub><msub><mi>k</mi><mn>1</mn></msub><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo>)</mo></mrow><mo>+</mo><msub><mi>d</mi><mn>2</mn></msub><msub><mi>k</mi><mn>2</mn></msub><mrow><mo>(</mo><msubsup><mi>x</mi><mi>i</mi><mo>&prime;</mo></msubsup><mo>,</mo><msubsup><mi>x</mi><mi>j</mi><mo>&prime;</mo></msubsup><mo>)</mo></mrow><mo>&rsqb;</mo><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>4</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001210749510000041.TIF" wi="1158" he="135" /></maths><maths num="0007"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><mrow><mi>s</mi><mo>.</mo><mi>t</mi><mo>.</mo></mrow></mtd><mtd><mrow><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>&alpha;</mi><mi>i</mi></msub><msub><mi>y</mi><mi>i</mi></msub><mo> =</mo><mn>0</mn></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FDA0001210749510000042.TIF" wi="285" he="125" /></maths>0≤α<sub>i</sub>≤λ,i＝1,...,N.其中,α<sub>i</sub>和α<sub>j</sub>分别表示对第i个训练动作样本、第j个训练动作样本构成的不等式约束所引入的拉格朗日乘子；<img file="FDA0001210749510000043.TIF" wi="973" he="71" />为核函数；S34.对公式(2)在训练动作样本集上进行优化求解：S341.固定加权系数d,(4)中的对偶问题转换成关于对偶变量α的优化问题,此时利用标准的SVM的求解方法对对偶变量α进行求解；S342.固定对偶变量α,利用梯度下降的方法对加权向量d进行求解；S343.迭代地进行S341和S342,直至式(2)收敛或达到最大迭代数。S35.利用步骤S34确定加权系数d和对偶变量α后,得到最终的决策函数：<img file="FDA0001210749510000044.TIF" wi="1030" he="134" />四、对测试动作样本进行动作识别S41.利用第一部分的内容求取测试动作样本的BoW表示；S42.利用第二部分的内容求取测试动作样本的平均模板表示；S43.将测试动作样本的BoW表示、平均模板表示输入至最终的决策函数中,决策函数输出分类结果。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏晓恒;                   万海       </td>   <td>中山大学</td>   <td>一种中文文本知识图谱自动构建方法及系统</td>   <td>广东</td>   <td>CN106844658A</td>   <td>2017-06-13</td>   <td>本发明提供的方法能够实现中文文本知识图谱的构建,并且该方法在使用时随着使用次数的增长,其各个领域的文本库、关系库、实体库也逐步得到扩充,构建知识图谱的效果越好。</td>   <td>一种中文文本知识图谱自动构建方法,其特征在于：包括以下步骤：S1.从网上百科爬取各个领域的文档,然后按照百科页面的知识组织结构抽取出实体和关系存入相应领域的实体库和关系库中,所述爬取的各个领域的文档也存入相应领域的文本库中；S2.若一个文档j需要进行构建知识图谱的操作,则对其执行以下处理;S3.对文档j进行分词处理；S4.对文档j进行核心词的提取；S5.使用TF#IDF的技术对文档j的重要词进行提取；S6.确定文档j所属的领域：S61.找出文档j的所有词语,然后分别计算它们的TF#IDF值,按照词语的顺序得到文档j的词汇向量表达式；S62.使用步骤S61的方法得到各个领域的文档的词汇向量表达式,然后计算文档j的词汇向量表达式与各个领域的文档的词汇向量表达式的余弦值,余弦值最大的文档对应的领域为文档j所属的领域；然后将文档j存入所述领域的文本库内；S7.提取文档j中的实体、关系和实体的三元组：S71.从文档j中挑选出领域词汇出现的句子作为事务,事务指的是挑选出来的句子中的所有词条的集合；其中所述领域词汇为文档j所属领域的实体库和关系库汇总的词条；S72.计算事务中每个词条的支持度,然后将支持度高于阈值的词条看做频繁项；S73.计算任意两个频繁项之间的置信度,若两个频繁项之间的置信度高于阈值,则提取两个频繁项作为词对；S74.将词对的词、核心词、重要词组成一个词条集合,定位文档j中所有含有该词条集合中词条的句子,然后对这些句子进行指代消解及删除句子中的次要成分,得到提取实体、关系和实体的三元组需要的名词和动词；S75.首先找到句子中的动词,然后将句子中动词前面和后面的名词组成一个候选的(名词,动词,名词)三元组,然后利用相似性分析来计算文档j所属领域的关系库中的关系与候选三元组中的动词的相似性,若相似性大于阈值,则将动词放入文档j所属领域的关系库中,同时将候选三元组中的名词放入文档j所属领域的实体库中；此时,候选的(名词,动词,名词)三元组为文档j提取的正式的实体、关系和实体的三元组；S76.若步骤S75提取不到实体、关系和实体的三元组,则找到句子中除核心词外的另一个名词,然后使用相似性分析来计算文档j所属领域的实体库中的实体与该名词的相似性,若相似性大于阈值,则寻找两个名词之间的词语,然后利用相似性分析来计算它与文档j所属领域的关系库中的关系的相似性,若相似性大于阈值,则将该词语放入文档j所属领域的关系库中,而将步骤S75提取的名词放入文档j所属领域的实体库中；此时,获得文档j提取的实体、关系和实体的三元组；S8.利用提取的实体、关系和实体的三元组生成文档j的知识图谱。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田晗;                   卓汉逵       </td>   <td>中山大学</td>   <td>一种基于引用关系分布式表达的论文推荐方法</td>   <td>广东</td>   <td>CN106844665A</td>   <td>2017-06-13</td>   <td>本发明公开一种基于引用关系分布式表达的论文推荐方法。利用分布式向量来表达论文在权重引用网络当中的上下文,然后利用该向量计算论文之间的相似度,达到论文推荐的目的。之前的基于引用的论文推荐的方法,都局限于使用论文引用和被引用的论文集合的重合度,对于重合度为0的论文之间无法计算相似度。本发明通过论文之间的权重引用网络,充分利用了论文之间“间接引用”的信息,再使用矩阵分解方法,获得表达论文在引用网络中的位置的分布式向量,使用其内积作为论文之间的相似度表达。该分布式表达可以用来作为学术推荐系统的一种基准特征,能够妥善的解决现有模型存在的问题,并且能够进一步的提高相似度度量的正确性。</td>   <td>一种基于引用关系分布式表达的论文推荐方法,其特征在于,包括以下步骤：步骤1：基于所有待研究论文生成ID字典,即为每篇论文赋予一个唯一的索引键,同时利用论文的相互引用关系生成论文引用网络,并建立论文引用权重矩阵M,权重矩阵M是基于论文索引标识构建的n行n列的矩阵；步骤2：使用最小化代价函数的方法,对权重矩阵M做矩阵分解,将矩阵M拟合成W*T的形式,其中W是n行m列的矩阵,T是m行n列的矩阵；其中m&lt;n,以达到降维的作用；用随机梯度下降法求出W和T矩阵；其中W的行向量与T的列向量等价的包含了每篇论文的分布式向量的表达,且互为对偶；使用W的行向量来作为分布式向量,其中第i行表示论文索引键i所代表的论文的分布式向量的表达；步骤3：通过分布式向量之间的内积,计算出两篇论文之间的基于引用的相似度值；步骤4：对候选论文按照计算出的相似度从大到小排序,得到作为论文推荐的排序列表。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         庞宇明;                   任江涛       </td>   <td>中山大学</td>   <td>一种基于Xgboost分类算法的文本分类方法</td>   <td>广东</td>   <td>CN106815369A</td>   <td>2017-06-09</td>   <td>本发明提供的方法通过Labeled#LDA提取特征字来计算特征值,然后用Xgboost分类算法来进行文本分类。其与普通的向量空间模型来做特征空间,普通的分类算法来进行文本分类的方法相比所需耗费的内存得到了降低,这是由于中文文本中所包含的词成百上千万,维度较高,若以词为特征,耗费内存巨大,甚至无法单机处理,而常用汉字不超过一万个,经常出现的甚至只有两三千个,维度大大降低,而且Xgboost支持以字典而不是矩阵形式作为输入。同时本发明提出一种新颖的具有潜在语义的有监督特征选择算法Labeled#LDA算法,用Labeled#LDA来做特征选择既能利用LDA来挖掘大量语料的语义信息又能利用文本所包含的类别信息。而且预处理简单,不需要精心提取特征,加上强大的支持分布式的集成学习算法Xgboost,提高了分类的准确性和性能。</td>   <td>一种基于Xgboost分类算法的文本分类方法,其特征在于：包括以下步骤：S1.获取多个样本,所述每个样本包括文本内容和文本的标签；S2.将步骤S1获取的所有样本按照一定比例划分成训练样本和预测样本,其中训练样本组成训练集,预测样本组成预测集；S3.对于每个训练样本,将其文本内容中任意相邻的两个字用空格隔开,然后将该训练样本的标签作为Labeled#LDA的标签输入,并该训练样本的文本内容作为Labeled#LDA的文本输入；S4.设置Labeled#LDA迭代次数为K,然后对训练样本进行迭代训练；S5.每个训练样本经过迭代后得到两份文档,一份是关于字及其对应字编码的,一份是关于主题与字编码的,即每个主题下相应字编码出现的次数；整合两份文档,得到训练样本中每个字在每个主题下出现的次数；对于每个主题,按照对应的字的出现次数排序,选取与该主题最相关的m个字作为训练样本的LLDA字；S6.对于每个训练样本,统计其经过步骤S5得到的各个LLDA字在其文本内容中的出现次数,并将该次数作为该特征的值,将得到每个样本关于每个LLDA字的值,输入至Xgboost分类算法中,然后对Xgboost分类算法进行训练；S7.至此模型已经训练好,需要对预测集进行预测,即对预测集进行步骤S3～S5的步骤,然后利用训练好的模型对预测集中的每个预测样本进行预测分类。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              谈志超;              许沥文;                   郭雪梅       </td>   <td>中山大学</td>   <td>基于多传感网络的室内活动检测识别方法及系统</td>   <td>广东</td>   <td>CN106815603A</td>   <td>2017-06-09</td>   <td>本发明涉及一种基于多传感网络的室内活动检测识别方法及系统,其中,该方法主要通过所有触发式传感器在目标室内环境中的位置信息和触发信息,在进行活动类型识别前对KNN最近邻算法训练进行处理并得到识别库,在实际应用中再根据触发信息、异构信息素残留率掩膜和单帧图片变化处理得到相应的信息素图矩阵,最终基于识别库实现对人体活动类型的识别。由此本发明通过在室内环境中布置多个触发式传感器,记录触发信息和每个触发式传感器的位置信息,大大提高了活动识别结果的准确性和可靠性。</td>   <td>一种基于多传感网络的室内活动检测识别方法,其特征在于：包括以下步骤：记录所有触发式传感器在目标室内环境中的位置信息；记录所有触发式传感器的触发信息；根据所有触发式传感器的位置信息生成相应的二维平面图；根据触发时间顺序依序读取触发信息,并根据当前读取到的触发信息所对应的触发式传感器的位置信息在所述二维平面图上作出触发时刻t对应的单帧图片变化Δs(t)；根据单帧图片变化Δs(t)和高斯卷积核h(t)生成触发时刻t的子信息素矩阵s(t),<img file="FDA0001207195520000011.TIF" wi="389" he="55" />根据当前读取到的触发信息所对应的触发式传感器的位置信息生成基于欧氏距离的异构信息素残留率掩膜ρ(t)；根据子信息素矩阵s(t)和异构信息素残留率掩膜ρ(t)生成触发时刻t的信息素图矩阵S(t),S(t)＝ρ(t)*S(t#1)+s(t)；通过十折交叉验证法,对KNN最近邻算法进行训练,得到KNN识别样本和相应的活动类型识别库；将信息素图矩阵S(t)输入到KNN识别样本中,计算得到相应的识别数据,并结合所述活动类型识别库实现对当前活动类型的识别,得到识别结果。</td>   <td>G06K9/62;H04W4/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘海亮;              吴义斌;                   苏航       </td>   <td>中山大学深圳研究院</td>   <td>一种基于Spark平台的个性化推荐系统</td>   <td>广东</td>   <td>CN106815325A</td>   <td>2017-06-09</td>   <td>本发明提出了一种基于Spark平台的个性化推荐系统,主要是为用户提供个性化以及精准化的信息推荐。本发明所提出的推荐模型和构建方法为：首先从用户偏好入手,结合具体的推荐系统选择合适的推荐算法；接着使用大数据处理平台Spark,提高推荐系统的性能。最后结合推荐算法和Spark平台为用户提供个性化和精准化的信息推荐服务。</td>   <td>一种基于Spark平台的个性化推荐系统,主要有以下模块构成：用户历史行为信息收集模块、相应的推荐算法模块、Spark平台推荐算法并行化实现模块；其中,用户历史行为信息收集模块主要是通过网络获取互联网平台上用户的信息以及相应的用户评价,对信息进行评估分析。在推荐算法模块,根据相应的系统,选择合适的推荐算法。在Spark平台推荐算法并行化实现模块中,在Spark平台上实现推荐算法的并行化。最后整合推荐系统,为用户推荐个性化和精准化的推荐信息。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐永健;              徐广建;              陆许明;              谭洪舟;                   陈远川       </td>   <td>中山大学花都产业科技研究院;中山大学</td>   <td>一种用于消除网络声音传输的回音和啸叫的系统和方法</td>   <td>广东</td>   <td>CN106782592A</td>   <td>2017-05-31</td>   <td>本发明公开了一种用于消除网络声音传输的回音和啸叫的系统和方法,一方面,本发明提供了一种用于消除网络声音传输的回音和啸叫的方法,实时将远端输入的音频信号进行降采样得到第一处理音频信号；实时将麦克风采集到的音响发出的声音和近端输入的声音的混合音频信号进行降采样得到第二处理音频信号；实时将第二处理音频信号中与第一处理音频信号相关的信号进行提取升采样得到第三处理音频信号；实时将麦克风采集到的混合音频中与第三处理音频信号相关的信号消除得到消除了回音和啸叫的输出音频信号。另一方面,本发明提供了一种用于消除网络声音传输的回音和啸叫的系统。本发明可有效消除网络声音传输的回音和啸叫,保证音频质量。</td>   <td>一种用于消除网络声音传输的回音和啸叫的方法,运用到音响(1)和麦克风(6),其特征在于,该方法包括如下处理步骤：步骤1.1：实时将远端输入的音频信号进行降采样得到设定采样率的第一处理音频信号；步骤1.2：实时将麦克风(6)采集到的音响(1)发出的声音和近端输入的声音的混合音频信号进行降采样得到设定采样率的第二处理音频信号；步骤1.3：实时将第二处理音频信号中与第一处理音频信号相关的音频信号进行提取升采样得到设定采样率的第三处理音频信号；步骤1.4：实时将麦克风(6)采集到的混合音频信号中与第三处理音频信号相关的音频信号消除得到消除了回音和啸叫的输出音频信号。</td>   <td>G10L21/0208;G10L21/0264</td>  </tr>        <tr>   <td>中国专利</td>   <td>         缪伟宏;                   潘嵘       </td>   <td>中山大学</td>   <td>一种基于词向量语义分析的海量短文本聚类方法</td>   <td>广东</td>   <td>CN106776713A</td>   <td>2017-05-31</td>   <td>本发明提供一种基于词向量语义分析的海量短文本聚类方法,该方法针对海量短文本提供一种基于词向量语义分析的聚类方法。首先利用使用海量文本数据进行word2vec的训练,将文本单词映射到256维的向量空间,然后对需要聚类的文本进行单词tfidf值的计算作为权重,将预处理后的文本进行加权求和,将短文本的向量化,相对于传统的tfidf模型,加入了word2vec训练好的词向量语义信息。得到更高质量的“文本向量”,从而提高聚类效果,采用大数据实时流处理框架Spark进行K#means或Dbscan算法进行聚类,加速得到聚类结果。</td>   <td>一种基于词向量语义分析的海量短文本聚类方法,其特征在于,包括以下步骤：S1：收集海量文本数据,并对每一文本数据进行预处理；S2：对预处理后的文本进行word2vec模型训练得到词向量模型；S3：将待处理的文本利用得到的词向量模型处理得到该待处理的文本的向量；S4：对待处理的文本的向量利用K#Means聚类算法或Dbscan聚类算法进行聚类处理得到聚类结果。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张梓滨;                   潘嵘       </td>   <td>中山大学</td>   <td>一种基于深度多任务学习的文本分类方法</td>   <td>广东</td>   <td>CN106777011A</td>   <td>2017-05-31</td>   <td>本发明提供一种基于深度多任务学习的文本分类方法,该发明利用其它任务训练得到的循环神经网络,结合卷积神经网络的学习能力,得到额外的文档表示,相当于引入了大量外部信息,扩展了文档的语义表示,有效地解决了训练数据不足的问题。本文相较于传统的多任务学习方法,使用了卷积神经网络对辅助任务的底层特征进行特征抽取,能够利用其它任务的特征有效地迁移到本任务,改善了文本分类的性能。</td>   <td>一种基于深度多任务学习的文本分类方法,其特征在于,包括以下步骤：S1：利用词向量和双向循环网络学习当前任务的文档表示；S2：利用卷积神经网络,从其他任务的文档表示抽取特征；S3：利用当前任务的文档表示、其他任务的特征学习分类器。</td>   <td>G06F17/30;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;              陈润源;              叶国桥;                   古旭宏       </td>   <td>中山大学</td>   <td>一种基于转账交易流水的客户资金关系圈划分方法</td>   <td>广东</td>   <td>CN106779650A</td>   <td>2017-05-31</td>   <td>本发明提供一种基于转账交易流水的客户资金关系圈划分方法,该方法根据客户的资金转账流水和客户关系数据,抽象出带权重的资金图模型,然后根据已有的圈子评价标准进行改进,设计出新的圈子评价模型,并且抽象出的资金图模型和改进的圈子评价模型对客户进行初步的圈子划分,得到一个初步的客户圈子集合,最后利用圈子的相似度对初步的客户圈子集合进行过滤,把相似度过高的圈子过滤掉,得到最终的客户圈子集合；该方法利用了模块度和聚合度这两个指标从宏观和微观上保证了资金关系圈的可靠性。</td>   <td>一种基于转账交易流水的客户资金关系圈划分方法,其特征在于,包括以下步骤：S1：根据客户的资金转账流水和客户关系数据,抽象出带权重的资金图模型；S2：根据已有的圈子评价标准进行改进,设计出新的圈子评价模型；S3：根据抽象出的资金图模型和改进的圈子评价模型对客户进行初步的圈子划分,得到一个初步的客户圈子集合；S4：利用圈子的相似度对初步的客户圈子集合进行过滤,把相似度过高的圈子过滤掉,得到最终的客户圈子集合。</td>   <td>G06Q20/10;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;                   李嘉豪       </td>   <td>中山大学</td>   <td>一种基于SEHM特征图序列的动作识别方法</td>   <td>广东</td>   <td>CN106778576A</td>   <td>2017-05-31</td>   <td>本发明提供的动作识别方法在进行动作识别时,是以本发明提出的SEHM(segment#energy#history#maps)特征图作为底层特征进行动作识别的。通过合理选择算法中时间片长度等参数,计算相应的SEHM特征图序列并应用到神经网络进行预测,能够在动作识别上实现离线识别和在线识别的功能。且由于构建的SEHM特征图是与动作整体姿态的前后变化相关的,因此可以充分地利用动作变化过程中的动作信息,提高动作识别的准确度。同时,在进行SEHM特征图计算时对原始数据进行了一定的压缩,方法的复杂度和硬件的要求较低,并能做到在线的实时动作识别。</td>   <td>一种基于SEHM特征图序列的动作识别方法,其特征在于：包括以下步骤：S1.针对视频中选定的时间段长度为N帧的深度图序列,将深度图序列中每一帧的深度图投影到三个正交坐标系的不同平面中,得到三个正交的视角图：正视图、侧视图和俯视图；S2.对于每个视角图下的深度图序列,计算其相邻两帧的差值作为能量图,其中每帧能量图代表着前后帧的距离变化；然后根据能量图的具体数值和设定的阈值将能量图分为三种状态图：向前状态的二进制图、向后状态的二进制图或静态的二进制图。具体如下：<maths num="0001"><math><![CDATA[<mrow><msubsup><mi>EM</mi><mi>t</mi><mi>i</mi></msubsup><mo> =</mo><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><mrow><mo>(</mo><mrow><mrow><mo>(</mo><mrow><msubsup><mi>map</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>v</mi></msubsup><mo>-</mo><msubsup><mi>map</mi><mi>t</mi><mi>v</mi></msubsup></mrow><mo>)</mo></mrow><mo>&gt;</mo><mi>&epsiv;</mi></mrow><mo>)</mo></mrow><mo> =</mo><mn>1</mn><mo>,</mo><mi>i</mi><mo> =</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mo>(</mo><mrow><mrow><mo>(</mo><mrow><msubsup><mi>map</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>v</mi></msubsup><mo>-</mo><msubsup><mi>map</mi><mi>t</mi><mi>v</mi></msubsup></mrow><mo>)</mo></mrow><mo>&lt;</mo><mo>-</mo><mi>&epsiv;</mi></mrow><mo>)</mo></mrow><mo> =</mo><mn>1</mn><mo>,</mo><mi>i</mi><mo> =</mo><mn>2</mn></mrow></mtd></mtr><mtr><mtd><mrow><mrow><mo>(</mo><mrow><mn>0</mn><mo>&lt;</mo><mi>a</mi><mi>b</mi><mi>s</mi><mrow><mo>(</mo><mrow><msubsup><mi>map</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><mi>v</mi></msubsup><mo>-</mo><msubsup><mi>map</mi><mi>t</mi><mi>v</mi></msubsup></mrow><mo>)</mo></mrow><mo>&lt;</mo><mi>&epsiv;</mi></mrow><mo>)</mo></mrow><mo> =</mo><mn>1</mn><mo>,</mo><mi>i</mi><mo> =</mo><mn>3</mn></mrow></mtd></mtr></mtable></mfenced></mrow>]]></math><img file="FDA0001172412180000011.TIF" wi="964" he="183" /></maths>其中<img file="FDA0001172412180000012.TIF" wi="127" he="63" />为在视角图v下第t帧的能量图；ε为所设的阈值；<img file="FDA0001172412180000013.TIF" wi="310" he="63" /><img file="FDA0001172412180000014.TIF" wi="147" he="55" />表示后一帧减去前一帧的差值的绝对值；i＝1,2,3,分别代表向前状态的二进制图、向后状态的二进制图和静态的二进制图；第t帧的状态图<img file="FDA0001172412180000015.TIF" wi="395" he="63" />通过一个三通道矩阵EM<sub>t</sub>进行表示；S3.执行步骤S2后分别得到三个视角图下的状态图序列；将三个视角图的N帧状态图序列分别按照前后顺序平均分为S个时间片,S＝N/K,其中K表示每个时间片的长度；对于每个视角图下的状态图序列,按照从前到后的顺序依次选取一个时间片的状态图序列进行SEHM特征图的计算：S31.设第p次选择进行计算的时间片的状态图序列是从N帧状态图序列的第(p#1)*K+1帧开始而在第p*K帧结束的,则该时间片的SEHM特征图由以下公式和步骤S32计算得到：SEHM<sub>p</sub>＝max(SEHM<sub>p</sub>,EM<sub>(p#1)*K+k</sub>·k)其中,k的初始值为1,SEHM<sub>p</sub>是初始值被设为零的三通道矩阵；S32.令k＝k+1然后执行步骤S31的公式直至k&gt;K,最后经过标准化处理后输出SEHM<sub>p</sub>作为第p次选择进行计算的时间片的SEHM特征图；S4.通过步骤S31、S32得到三个视角图下各个时间片的SEHM特征图；S5.将三个视角图下相互对应的时间片的SEHM特征图进行融合,得到融合的以时间片为单位的SEHM特征图；S6.融合后的各个时间片的SEHM特征图构成SEHM特征图序列,将SEHM特征图序列输入到神经网络中,神经网络输出一列代表各个动作可能性的概率向量P,根据输出的概率向量P确定当前N帧深度图序列的动作识别结果。</td>   <td>G06K9/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈正梁;                   潘嵘       </td>   <td>中山大学</td>   <td>一种基于深度学习的非对称文本哈希方法</td>   <td>广东</td>   <td>CN106776553A</td>   <td>2017-05-31</td>   <td>本发明提供一种基于深度学习的非对称文本哈希方法,该方法使用了最小化文本之间语义相似度和二进制哈希编码相似度之间的差值保持哈希编码的语义一致性,使得二进制编码具有相似信息保存性；采用异构的神经网络分别对检索文本和被检索文本进行哈希学习,能够提高文本哈希学习的效率。</td>   <td>一种基于深度学习的非对称文本哈希方法,其特征在于,包括以下步骤：S1：提取训练集文本语义标签,计算样本之间的语义相似度；S2：根据训练集样本语义标签和语义相似度计算训练集文本的二进制哈希编码,该二进制哈希编码具有保持在训练集上有最佳的语义保持的性能,即期望哈希编码；S3：将训练集文本输入到神经网络中,计算出文本对应的哈希编码；S4：计算神经网络输出的哈希编码和S2中得到的期望哈希编码的偏差,并通过反向传播算法训练神经网络参数。</td>   <td>G06F17/27;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张志勇;                   任江涛       </td>   <td>中山大学</td>   <td>混合的深度神经网络CNN和RNN的主题句识别方法</td>   <td>广东</td>   <td>CN106776580A</td>   <td>2017-05-31</td>   <td>本发明方法利用搜狗实验室中的全网新闻数据集训练出词向量,使得每个相近词在空间上的距离相近；并从百度旅游网站和蚂蜂窝旅游网站各爬取600篇的游记,对游记分割成句子,将这些句子分为训练集和测试集并按照8：2的比例进行划分,然后对于训练集根据信息熵和互信息的计算公式计算出每个词的信息熵值和互信息值；然后,对于训练集中每个句子根据计算出的词向量和计算出的信息熵和互信息来构建特征,作为构建的混合深度神经网络CNN<sub>R</sub>NN的输入,获取到参数；同时,对测试集中每个句子根据计算出的词向量和计算出的信息熵和互信息来构建特征,输入到CNN<sub>R</sub>NN中,利用得到的参数计算出类别,得出标准结果和预测的误差,评价其性能。</td>   <td>一种混合的深度神经网络CNN和RNN的主题句识别方法,其特征在于,包括以下步骤：S1：利用搜狗实验室中的全网新闻数据集训练出词向量,使得每个相近词在空间上的距离相近；S2：从百度旅游网站和蚂蜂窝旅游网站各爬取600篇的游记,对游记分割成句子,将这些句子分为训练集和测试集并且按照8：2的比例进行划分,然后对于训练集根据信息熵和互信息的计算公式计算出每个词的信息熵值和互信息值；S3：对于训练集中每个句子根据S1计算出的词向量和S2计算出的信息熵和互信息来构建特征,作为构建的混合深度神经网络CNN_RNN的输入,获取到参数；S4：同样的对测试集中每个句子根据S1计算出的词向量和S2计算出的信息熵和互信息来构建特征,输入到深度神经网络CNN_RNN中,利用S3得到的参数,计算出其类别,得出标准结果和预测的误差,评价其性能。</td>   <td>G06F17/27;G06N3/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              杨梁;              王腾;              张俊轩;                   王伟轩       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于神经网络及图像关注点的图像描述生成方法</td>   <td>广东</td>   <td>CN106777125A</td>   <td>2017-05-31</td>   <td>本发明提供一种基于神经网络及图像关注点的图像描述生成方法,该方法采用两层字嵌入结构,而不是原先的一层嵌入结构,这样更有效的学习字表达；图像的特征表达是直接作为m#RNN模型的输入的,这样能充分利用循环层的容量,允许使用小维度的循环层；借助决策软关注机制,本发明将图像显著区域的关注度体现出来,并作为多模态层的一个输入。通过这个方式,有效地利用了目标或场景间的轻重关系,针对性地描绘图像的语义特性。</td>   <td>一种基于神经网络及图像关注点的图像描述生成方法,其特征在于,包括以下步骤：S1：构建每一时刻帧t的图像的多模态模型：1)训练集中已标注图像的文本描述信息分成单个字集,用one#hot向量表示对应字,作为模型的文本模块的输入,并经过两个嵌入层投影至一个稠密字表达空间,成为具有语义的字表达向量W<sub>t</sub>；2)字表达向量用于循环卷积神经网络RNN某时刻帧t的输入进行循环卷积神经网络RNN计算,该时刻帧t的循环层激活R<sub>t</sub>是由当前时刻帧的字表达向量和之前时刻帧t#1的循环层R<sub>t#1</sub>共同决定的；3)已标注图像经过一个卷积神经网络CNN,并提取图像的L个显著特征；4)图像的特征作为LSTM的输入,LSTM中的隐藏层信息采取一种决策‘soft’关注机制可以获得指定区域特征在全局图像的重要程度,其重要程度和其特征通过求期望可以算出包含区域关注信息的上下文向量；5)将以上的字表达向量、循环层信息、图像特征和上下文向量通过转换矩阵投影至同一维度的多模态空间上并直接元素相加,再用元素比例双曲线正切函数激活,最后通过softmax层得到下一字的概率分布；S2：对构建的模型进行训练：整个模型的损失函数是对应图片的文本标注的混乱度,其等价于字集的平均对数似然值,对其使用标准梯度下降算法,通过反向传播算法学习模型参数。</td>   <td>G06F17/30;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              孙雪冬       </td>   <td>中山大学</td>   <td>基于知识图谱的个性化学习过程的自动生成方法及系统</td>   <td>广东</td>   <td>CN106777127A</td>   <td>2017-05-31</td>   <td>本发明公开了一种基于知识图谱的个性化学习过程的自动生成方法及系统。该方法在有向超图描述的个性化知识图谱的基础上,利用知识元和学习活动之间的关系,根据学习者的学习性能目标、学习能力、学习习惯和学习方式等个性化特点自动生成相应的学习过程框架；基于此框架,根据学习者的特点、活动所学知识元及活动类别自动生成活动所有可能的支持资源；利用学习资源、学习者和学习活动属性的关系,活动属性与过程属性之间的关系以及学习者的个性化目标,进行过程结构和学习资源的优选,生成优化的学习过程。该方法能自动地生成大型个性化学习过程；该方法用于根据学习者的具体情况进行学习过程结构与学习资源的优选,从总体的角度对学习进行分析优化。此外,本发明的研究成果也是进一步个性化学习方案制定的基础。</td>   <td>一种基于知识图谱的个性化学习过程的自动生成方法,其特征在于,包括以下步骤：步骤1,进行相关建模,其中包括：基于知识的学习者描述,基于有向超图的学习内容描述,基于有向超图的学习过程描述,基于知识的资源分类描述；步骤2,由知识图谱向通用学习过程框架的映射,包括：知识元向活动的映射,知识元之间的逻辑关系向活动之间逻辑关系的映射；开始知识元和目标知识元的处理；步骤3,过程模型的个性化处理,根据学习者的学习习惯、学习能力进行相应的处理；步骤4,可能支持资源的生成；根据活动所处理的知识元、学习者的类别、资源所包含的知识元以及资源的类别生成活动可能的支持资源。步骤5,建立活动属性、学习者、学习资源之间的关系模型；根据活动属性与过程属性之间的关系及学习者的性能目标,利用遗传算法进行活动与资源的优选,生成相对于学习者的个性化的优化的学习过程。步骤6,监测资源环境及学习者本身,若二者任一出现变化时,则进行相关性判断以及相应处理。</td>   <td>G06F17/30;G06Q10/04;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王海波;              蔡铭;                   钟舒琦       </td>   <td>中山大学</td>   <td>一种基于建筑物属性的城市人口分布方法</td>   <td>广东</td>   <td>CN106708962A</td>   <td>2017-05-24</td>   <td>本发明公开一种基于建筑物属性的城市人口分布方法,具体为：根据城市经纬度坐标范围,获得电子地图中所有建筑物信息和建筑物周边兴趣点信息；针对某一人口统计区域,查询电子地图,确定人口统计区域坐标,并查询区域人口总数；根据建筑物位置和人口统计区域边界角点坐标,筛选出该人口统计区域的所有建筑物；推断该建筑物的社会活动属性；设定不同社会活动属性类型建筑物不同时间单位面积人口吸引系数,将人口统计区域内的人口分配到区域内每栋建筑物中,获得建筑物等级的人口分布；再遍历城市各个人口统计区域,获得城市人口分布。本发明应用于建筑物等级的城市人口分布,可有效的解决城市人口分布尺度粗糙的问题并体现人口分布时间性差异。</td>   <td>一种基于建筑物属性的城市人口分布方法,其特征在于,包含以下步骤：(a)根据城市经纬度坐标范围,使用建筑物查询的方式获得电子地图中所有建筑物信息和建筑物周边兴趣点信息；(b)针对某一人口统计区域,以区域名为关键词进行电子地图查询,确定人口统计区域坐标,并从城市人口普查年鉴中查询区域人口总数；(c)根据建筑物位置和人口统计区域边界角点坐标,筛选出该人口统计区域的所有建筑物；(d)根据建筑物周围最近的若干个兴趣点的类型、影响权重和离建筑物的距离,推断该建筑物不同时间段的社会活动属性；(e)设定不同社会活动属性类型建筑物单位面积人口吸引系数,将人口统计区域内的人口分配到区域内每栋建筑物中,获得建筑物等级的人口分布；(f)针对各个人口统计区域,重复步骤(b)、(c)、(d)和(e),获得城市人口分布。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭梦含;              赖斯;              杨溢;                   林小拉       </td>   <td>中山大学</td>   <td>一种蒙特卡洛逆向求解PageRank问题的加速方法</td>   <td>广东</td>   <td>CN106708973A</td>   <td>2017-05-24</td>   <td>本发明提供一种蒙特卡洛逆向求解PageRank问题的加速方法,该方法使用拟随机序列代替伪随机序列进行PageRank仿真求解,拟随机序列一次生成后,可以用于每个分量的求解过程中,而使用伪随机序列则需要在每个分量的求解过程中重新生成,另外,拟随机序列可以在GPU上高效并行的生成,在随机序列的生成上可以节约不少时间；引入松弛法进行求解,通过将目标函数进行转换,并进行松弛化,减少迭代矩阵的谱半径来加快收敛速度；充分利用GPU的共享内存作为缓存,并在累积汇总每个马尔科夫链计算的结果时进行高效地reduce并行化操作,无需多次访问读取速度较慢的全局内存,从而提高效率。</td>   <td>一种蒙特卡洛逆向求解PageRank问题的加速方法,其特征在于,包括以下步骤：S1：确定初始方向数,由初始方向数得到拟随机序列的方向数,然后计算得到拟随机数列；S2：将PageRank迭代公式进行转换,得到新的迭代矩阵G和其对应的线性方程组系数矩阵A,计算矩阵<img file="FDA0001172279180000011.TIF" wi="104" he="71" />特征值极值,根据特征值的分布得到松弛因子,利用该松弛因子对PageRank迭代公式进行松弛化处理,再利用S1中得到的拟随机数列,对松弛化后的PageRank迭代公式使用马尔科夫蒙特卡洛方法进行仿真,得到求解的目标分量x<sub>i</sub>的每条马尔科夫链仿真结果；S3：对求解的目标分量x<sub>i</sub>的每条马尔科夫链仿真结果,首先申请分配GPU共享内存进行缓存,接着在GPU共享内存中对各个仿真结果进行归约并行求和,然后将汇总的结果除以仿真的链数,求得目标分量x<sub>i</sub>的期望值。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄敏;              郑健;              刘芳;              张腾;                   毛峰       </td>   <td>中山大学</td>   <td>基于区域整体指引可达最大化的道路指路标志布设方法</td>   <td>广东</td>   <td>CN106709599A</td>   <td>2017-05-24</td>   <td>本发明涉及一种基于区域整体指引可达最大化的道路指路标志布设方法,包括以下步骤：S1.针对区域内的单条道路,构建指引该条道路的指路标志布设方案；S2.将区域内指引每条道路的指路标志布设方案进行叠加,获取区域道路指路标志叠加布设方案；S3.构建人工蜂群算法优化模型,以区域道路整体指引可达最大化为目标,对叠加布设方案进行优化,获取最优的区域道路指路标志布设方案。</td>   <td>基于区域整体指引可达最大化的道路指路标志布设方法,其特征在于：包括以下步骤：S1.针对区域内的单条道路,构建指引该条道路的指路标志布设方案；S2.将区域内指引每条道路的指路标志布设方案进行叠加,获取区域道路指路标志叠加布设方案；S3.构建人工蜂群算法优化模型,以区域道路整体指引可达最大化为目标,对叠加布设方案进行优化,获取最优的区域道路指路标志布设方案。</td>   <td>G06Q10/04;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         衣杨;              胡攀;              邓小康;              张念旭;              谢韬;                   郑镇贤       </td>   <td>中山大学</td>   <td>一种基于显著轨迹空间信息的视频人体行为识别方法</td>   <td>广东</td>   <td>CN106709419A</td>   <td>2017-05-24</td>   <td>本发明提供一种基于显著轨迹空间信息的视频人体行为识别方法,该方法重新定义了视频中轨迹的显著性,有效地剔除视频中背景和人体非运动部位的轨迹,留下了前景中运动显著性高的轨迹,这些轨迹误差更小,表达能力也更强；另外该方法将不同人体部位的运动部件以及交互物体区分开来,并通过多核学习来利用他们之间的空间和语义关系,提高了算法的识别效果。</td>   <td>一种基于显著轨迹空间信息的视频人体行为识别方法,其特性在于,包括以下步骤：S1：提取视频帧,构建图像金字塔,然后对视频进行超像素分割,在图像金字塔上计算光流,然后利用帧的颜色,空间分布,以及光流的对比性来计算动态和静态显著性,将他们融合为总的显著性；S2：将轨迹显著性定义为轨迹每点在组合显著性图像中显著性的均值；然后计算自适应阈值,当轨迹显著性小于阈值时,则认为是背景轨迹或者非运动区域的轨迹而予以删除,从而有效提取显著轨迹；S3：首先对视频的所有显著轨迹进行随机采样,然后对采样得到轨迹利用其空间信息进行AP聚类,得到不定数量的聚类中心,接着用k#means将聚类中心调整为固定的数目C,最后将视频所有的轨迹分类到距离最近的聚类中心去,从而得到了视频的轨迹分类；S4：对一个视频C个类的轨迹进行编码,得到了C个向量,该向量就是视频的表示。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曹彦;                   凌应标       </td>   <td>中山大学</td>   <td>基于历史搜索信息的动态物流最佳配送线路的优化方法</td>   <td>广东</td>   <td>CN106709680A</td>   <td>2017-05-24</td>   <td>本发明提供一种基于历史搜索信息的动态物流最佳配送线路的优化方法,该方法在动态物流配送问题中具有较高效率且能够在配送中心和配送客户之间找到一条最短且满足每个客户配送要求的最佳配送线路。传统物流问题中的配送客户和客户之间的路径值都是固定的,这种建模方式不符合一些以此为模型的实际问题的需要,也就是说,配送客户所代表的配送结点以及它们之间的配送路径的长度都可能是变化的。尽管是变化的,但在不同时刻,最优配送线路包含一些公共子线路,这些最优子线路可以被后续时刻的搜索算法学习,避免重复搜索,从而提高最优配送线路的搜索效率。</td>   <td>一种基于历史搜索信息的动态物流最佳配送线路的优化方法,其特征在于,包括以下步骤：S1：构建动态物流配送模型；S2：对构建的动态物流配送模型利用粒子群算法在离散空间下进化；S3：引入粒子群历史最优解对进化后的动态物流配送模型进行再学习得到优配送线路。</td>   <td>G06Q10/08;G06Q50/28</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王自鑫;              陈弟虎;              衣杨;                   张晓强       </td>   <td>中山大学</td>   <td>一种高层次综合工具中的多操作数加法优化方法及系统</td>   <td>广东</td>   <td>CN106682258A</td>   <td>2017-05-17</td>   <td>本发明公开了一种高层次综合工具中的多操作数加法优化方法及系统,该方法步骤包括：获取电路设计的高层次功能描述,进而得到该电路设计所包含的运算操作以及操作数；分析上述运算操作,判断是否出现3个或3个以上的操作数连续相加,若是继续执行下面,否则结束；读取用户配置文件中的优化目标并根据优化目标建立压缩树,并保存压缩树信息；根据压缩树信息生成可综合的压缩树HDL代码。本发明可以在高层次综合阶段,根据用户配置文件中的优化目标进行多操数加法的设计空间优化,有助于生成性能更优的多操作数加法电路和提升高层次综合工具的性能。本发明作为一种高层次综合工具中的多操作数加法优化方法及系统可广泛应用于计算机与电路设计领域。</td>   <td>一种高层次综合工具中的多操作数加法优化方法,其特征在于：包括有以下步骤：A、获取电路设计的高层次功能描述,进而得到该电路设计所包含的运算操作以及操作数；B、判断步骤A中得到的运算操作是否出现3个或3个以上的操作数连续相加,若是,则载入加法优化处理单元,并进入步骤C执行此处理单元,反之则结束；C、读取用户配置文件中的优化目标数据,根据优化目标数据建立压缩树,并保存压缩树信息；D、根据步骤C中保存的压缩树信息生成可综合压缩树HDL代码。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              林梓健;                   马东宏       </td>   <td>中山大学</td>   <td>一种单摄像头的行人跟踪方法</td>   <td>广东</td>   <td>CN106682573A</td>   <td>2017-05-17</td>   <td>本发明公开一种单摄像头的行人跟踪方法。本发明采用分层次跟踪的策略,先把检测目标连接成稳定可靠的小段运动轨迹,然后通过匹配小段运动轨迹并填充小段运动轨迹间的空白段,形成最终的跟踪轨迹。该策略有利于解决跟踪过程中由于行人被短时间遮挡而引起的轨迹中断问题。在小段运动轨迹的构造中,本发明提出了基于级联思想的两步匹配方法,先采用高效的直方图匹配方法处理匹配难度小的情况,再进一步采用鲁棒的稀疏表示分类器解决目标表观相似引起的混淆问题。在小段运动轨迹之间的匹配中,本发明提出了基于稀疏表示的轨迹距离度量方法,对由环境变化和目标形变引起的目标表观变化情况有较好的鲁棒性。另外,本发明还提出计算量小的基于层次聚类的轨迹匹配方法,提高全局多轨迹匹配的效率。</td>   <td>一种单摄像头的行人跟踪方法,其特征在于：包括以下步骤：S1.对视频图像进行检测,将检测出来的行人称为观察目标；S2.设在当前帧t检测到有n个观察目标,提取这n个观察目标的特征；S3.设在当前帧t,同时存在若干条在当前帧t之前的运动轨迹,T＝{d<sup>s</sup>,d<sup>s+1</sup>,...,d<sup>e</sup>}表示一条运动轨迹,其中s、e分别为轨迹T的起始时刻和终止时刻；对于运动轨迹<img file="FDA0001153163970000011.TIF" wi="459" he="63" />通过位置约束条件选出在当前帧t可能关联的观察目标,然后计算运动轨迹T<sub>i</sub>与可能关联的观察目标的相似度,将与运动轨迹T<sub>i</sub>相似度最高的观察目标作为该运动轨迹的最佳观察目标；S4.经过步骤S3的匹配后,每个观察目标遇到以下三种情况之一：A.观察目标不是任何运动轨迹的的最佳观察目标,因而未能成功配对；B.观察目标仅是一条运动轨迹的最佳观察目标,则将该观察目标与该运动轨迹配对；C.观察目标是多条运动轨迹的最佳观察目标,则利用稀疏表示分类器对观察目标进行分类,利用分类器确定该观察目标所属的运动轨迹,将观察目标与该运动轨迹配对；S5.执行步骤S4后,对运动轨迹进行更新：A.对于未成功配对到运动轨迹的观察目标,新建立一条以该观察目标为起点的运动轨迹；B.对于成功配对到运动轨迹的观察目标,将该观察目标连接到运动轨迹的末端；C.对于未成功配对到观察目标的运动轨迹,则利用该运动轨迹在当前帧t之前m帧的位置线性预测出其在当前帧t的位置,并将其称之为预测目标,若预测目标和运动轨迹的相似度大于阈值,则将预测目标连接到运动轨迹的末端；S6.重复执行步骤S3#S5,直到遍历完图像序列,低层次数据关联过程结束；S7.通过时空约束条件选出有可能关联的运动轨迹对(T<sub>a</sub>,T<sub>b</sub>)；S8.采集足够数量的行人图像；若图像中行人腿部是呈靠拢状态的,则标记为正样本,否则标记为负样本；对图像中行人腿部计算梯度方向直方图,并且以此作为特征,离线训练一个能够区分图像中行人腿部是否呈靠拢状态的支持向量机；S9.使用支持向量机判别T<sub>a</sub>、T<sub>b</sub>的每张图像中行人腿部是否呈靠拢状态,并选出判别结果为正的图像作为T<sub>a</sub>、T<sub>b</sub>的代表性图像子集(A<sub>a</sub>,A<sub>b</sub>)；S10.对运动轨迹对(T<sub>a</sub>,T<sub>b</sub>)的代表性图像子集(A<sub>a</sub>,A<sub>b</sub>)进行图像特征提取,然后基于提取的特征使用双向重构的策略来计算运动轨迹对(T<sub>a</sub>,T<sub>b</sub>)的距离,若运动轨迹对(T<sub>a</sub>,T<sub>b</sub>)的距离大于指定阈值,则舍弃该运动轨迹对；S11.基于层次聚类的轨迹匹配：将运动轨迹视为点,将S10得到的运动轨迹对视为边,边的权值取运动轨迹对的距离,由此构成一个无向图G＝(V,E),其中V＝{T<sub>1</sub>,T<sub>2</sub>,...,T<sub>n</sub>},E＝{(T<sub>a</sub>,T<sub>b</sub>,D(T<sub>a</sub>,T<sub>b</sub>))|D(T<sub>a</sub>,T<sub>b</sub>)＜θ<sub>D</sub>且1≤a,b≤n},n为运动轨迹数；聚类开始时,设类别数为n,每个类只包含一个点；每个点具有一个时间跨度Z<sub>i</sub>＝{s<sub>i</sub>,s<sub>i</sub>+1,...,e<sub>i</sub>}；每个类的时间跨度为该类所有点的时间跨度的并集；然后进行如下聚类：A.从边集中选出权值最小的边l；B.若边l的两端点所属类的时间跨度没有交集,则把这两个类聚合成一个类；C.从边集中删除边l,若边集为空集,聚类结束,否则返回A；D.聚类结束后,每一类表示一个行人目标；S12.轨迹修复：对于S11得到的每一个类,把所有观察目标的垂直坐标x、水平坐标y、检测窗口高度h分开处理,使用样条线分别拟合x#t曲线、y#t曲线、h#t曲线,以填补缺失的轨迹点并对轨迹进行平滑。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              曾碧怡;              李波;              冷成财;                   颜吉超       </td>   <td>中山大学;南昌航空大学</td>   <td>一种基于双边核回归的相对约减纹理分解方法及其装置</td>   <td>广东</td>   <td>CN106683129A</td>   <td>2017-05-17</td>   <td>本发明实施例公开了一种基于双边核回归的相对约减纹理分解方法及其装置,其中,该方法包括：输入所要处理的输入图像；对所述输入图像的每一个像素计算相对约减率；根据软阈值构造结构核描述子；将所述结构核描述子作为联合双边滤波的引导图像与双边核进行回归融合,获得滤波结果。在本发明实施例中,采用基于局部全变分的结构核描述子并结合核回归模型来进行构建,采用相对减少的纹理分解来构造结构核描述子,将该描述子与双边核回归融合来获得期望的结构感知滤波输出,能够弥补当前边缘感知滤波在提取图像结构时所出现的结构和纹理分解不完全的缺陷。</td>   <td>一种基于双边核回归的相对约减纹理分解方法,其特征在于,所述方法包括：输入所要处理的输入图像；对所述输入图像的每一个像素计算相对约减率；根据软阈值构造结构核描述子；将所述结构核描述子作为联合双边滤波的引导图像与双边核进行回归融合,获得滤波结果。</td>   <td>G06T7/49</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              张俊轩;              王腾;              杨梁;                   王伟轩       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于知识迁移的多模态循环神经网络的图像文本描述方法</td>   <td>广东</td>   <td>CN106650756A</td>   <td>2017-05-10</td>   <td>本发明提供一种基于知识迁移的多模态循环神经网络的图像文本描述方法,该方法通过多模态单元中的知识转移模型,很好地利用了现成图像分类器对大多数对象的识别能力以及现成语料库中的语法结构和语义关联性,能更准确地描述出图像中的目标对象以及使生成的句子描述语法结构更丰富,语义贴切,可读性更强。</td>   <td>一种基于知识迁移的多模态循环神经网络的图像文本描述方法,其特征在于,包括以下步骤：S1：在服务器中训练图像语义分类器；S2：在服务器中训练语言模型；S3：在服务器中预训练文本描述生成模型并生成描述句子。</td>   <td>G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡继华;                   高立晓       </td>   <td>中山大学</td>   <td>一种公交线网规划方法</td>   <td>广东</td>   <td>CN106651034A</td>   <td>2017-05-10</td>   <td>本发明提供的公交线网规划方法以最小化乘客的出行时间和换乘次数,最大化线网的需求密度为目标,综合考虑了乘客的利益和线网的运营效率,通过在OD对之间搜索客流量最大的线路,有效的提高了线路的利用效率。避免了传统模型仅局限在乘客的出行时间或者直达需求密度方面目标的不足,使得线路和客流更加一致,提高了公交线网的服务水平。</td>   <td>一种公交线网规划方法,其特征在于：包括以下步骤：S1.根据公交刷卡数据和报站数据,建立公交OD矩阵和节点间的路段行驶时间矩阵；S2.基于OD矩阵和初始解集生成算法生成满足约束条件的初始线网作为当前解；S3.基于流量分配算法对当前解进行需求量分配；S4.根据目标函数值计算方法计算当前解的目标函数值Z1：<maths num="0001"><math><![CDATA[<mrow><mi>min</mi><mi> </mi><mi>Z</mi><mn>1</mn><mo> =</mo><mi>&alpha;</mi><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo> =</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>d</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>t</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><mi>&beta;</mi><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi><mo> =</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>d</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>tr</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><mi>&gamma;</mi><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mi>N</mi></munderover><mfrac><mrow><msub><mi>&omega;d</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>x</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><msub><mi>l</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mfrac></mrow>]]></math><img file="FDA0001190615350000011.TIF" wi="1205" he="183" /></maths>其中d<sub>ij</sub>为节点i到节点j的需求量；t<sub>ij</sub>为节点i到节点j的出行时间,可由路段行驶时间矩阵求取得到；tr<sub>ij</sub>为节点i到节点j的换乘次数；l<sub>ij</sub>为节点i到节点j的线路长度；ω为换乘参数,α、β、γ为效率均衡系数；<img file="FDA0001190615350000012.TIF" wi="178" he="143" />当x<sub>ij</sub>为0时,表示节点i到节点j之间的路径为换乘路径,当x<sub>ij</sub>为1时,表示节点i到节点j之间的路径为直达路径；S5.采用邻域解集生成算法生成满足约束条件的邻域解；S6.基于流量分配算法对邻域解进行需求量分配；S7.根据目标函数值计算方法计算邻域解的目标函数值Z2；S8.计算当前解和邻域解的目标函数值之差dz；若dz大于0,将邻域解作为当前解,若dz小于0,按照Metropolis准则将邻域解作为当前解；S9.重复步骤S5～S8直至达到设定的迭代次数,此时将当前解作为最终的规划方案进行输出。</td>   <td>G06Q10/04;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王甲海;              翁太耀;                   印鉴       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种求解多目标多车场带时间窗车辆路径问题的智能算法</td>   <td>广东</td>   <td>CN106651043A</td>   <td>2017-05-10</td>   <td>本发明提供一种求解多目标多车场带时间窗车辆路径问题的智能算法,第一步使用基于极值拥挤距离的带精英策略非占优排序遗传算法混合局部搜索,在决策空间中寻找极值解,第二步使用基于分解的多目标进化算法混合局部搜索,在第一步求解得的最终种群的基础上,进一步优化得到一组兼顾收敛性及多样性的解。两步过程使得算法的收敛性及多样性得到很好的平衡,提升了算法求解多目标多车场带时间窗车辆路径问题的质量。</td>   <td>一种求解多目标多车场带时间窗车辆路径问题的智能算法,其特征在于,包括以下步骤：S1：在决策空间中寻找极值解；S2：利用寻找到的极值解,在整个决策空间中搜索一组兼顾收敛性与多样性的解。</td>   <td>G06Q10/04;G06Q10/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王甲海;              任文彬;                   印鉴       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>求解多目标带时间窗周期性车辆路径问题的智能调度算法</td>   <td>广东</td>   <td>CN106651044A</td>   <td>2017-05-10</td>   <td>本发明提供一种求解多目标带时间窗周期性车辆路径问题的智能调度算法,该算法运用于多目标带时间窗周期性车辆路径问题的设计和优化中,主要涉及物流运输和智能计算两大领域。发明的方法将优化过程包括：第一,从存档中选择解,对解在不同的目标上进行局部搜索,提高解的质量；第二,使用搜索得到的解更新存档。在多目标局部搜索算法中设计了多种邻域操作,避免陷入局部最优,提高算法的收敛速度。本发明对公开的对称样例和非对称样例进行了测试,证明了发明的方法是真实有效的。</td>   <td>一种求解多目标带时间窗周期性车辆路径问题的智能调度算法,其特征在于,包括以下步骤：S1：从存档中选择解,对解在不同的目标上进行局部搜索,提高解的质量；S2：使用搜索得到的解更新存档。</td>   <td>G06Q10/04;G06Q10/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         柳林;              谭敏;                   刘凯       </td>   <td>中山大学</td>   <td>一种基于随机森林模型的人口数据空间化方法</td>   <td>广东</td>   <td>CN106650618A</td>   <td>2017-05-10</td>   <td>本发明公开一种基于随机森林模型的人口数据空间化方法,选取地表覆盖数据、灯光数据等与人口分布相关的变量因子,经过预处理后输入到随机森林模型中,利用随机森林模型确定人口密度与变量因子之间的关系和变量因子重要性,并基于这个关系反演出每个网格的人口密度,最后通过分区密度制图对估算结果进行修正,得到网格化的人口分布结果。该方法能进一步提高人口数据空间化的精度并解释变量因子的重要性。</td>   <td>一种基于随机森林模型的人口数据空间化方法,其特征在于,所述方法的基本步骤为：(1)获取行政区的常住人口数、灯光数据以及其它对人口分布具有影响的自然和社会经济因素的原始数据,对数据进行预处理,得到变量因子距离数据、灯光数据、行政区人口密度的对数和二值化栅格转换后的变量因子数据；(2)统计各个行政区内的每个变量因子的平均值或最常出现的值并匹配到行政区边界；(3)将步骤(1)预处理后得到的变量因子距离数据、灯光数据和行政区人口密度的对数、二值化变量因子栅格数据、步骤(2)得到的变量因子的平均值或最常出现值作为随机森林模型的输入,来寻找变量因子与人口密度的对数之间的关系并输出变量因子重要性,基于这个关系反演出L×L米网格的人口数,得到人口数据空间化的初步结果；(4)利用分区密度制图修正人口数据空间化的初步结果,最终实现基于随机森林模型的L米网格的人口数据空间化。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢箫;              朱京希;              李嘉;                   赖博雅       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种复合材料薄膜三维多相同步生长的模拟方法及系统</td>   <td>广东</td>   <td>CN106650008A</td>   <td>2017-05-10</td>   <td>本发明提供的方法基于蒙特卡洛方法模拟粒子形成薄膜的随机过程。根据所选多相材料的特点设定参与随机事件的粒子数量和相关的能量参数,并对薄膜基底的材料和形貌进行选择和定义,获得三维薄膜生长模拟的过程信息。通过改变沉积相的参数,沉积条件(如,温度,基底表面形貌)等模拟条件,可以帮助技术人员发掘复合多相薄膜结构形态形成的机理。</td>   <td>一种复合材料薄膜三维多相同步生长的模拟方法,其特征在于：包括以下步骤：S1.设定薄膜生长的基底的三维结构形态信息,包括基底形貌和基底材料；S2.设定模拟体系内各种材料的本征参数,包括基底和薄膜材料的；S3.定义模拟体系的模拟参数；S4.按S1所定义的基底材料和形貌,在系统内导入或生成所需基底；S5.定义薄膜生长前沿的扫描面；S6.按S5的设定激活欲扫描的薄膜中的体积元层,并随机赋予该层中每个体积元一种身份参数,启动蒙特卡洛步骤,执行设定数量的Monte#Carlo#steps,使该薄膜层结构从初始随机生成的无序态达到稳态；S7.重复步骤S5～S6直至扫描完所设定的薄膜厚度所包括的体积元。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              李晓苗;                   韩冠亚       </td>   <td>中山大学</td>   <td>一种基于数字家庭高清媒体的内容分析方法及系统</td>   <td>广东</td>   <td>CN106649660A</td>   <td>2017-05-10</td>   <td>本发明实施例公开了一种基于数字家庭高清媒体的内容分析方法及系统,其中,该方法包括：对视频进行结构化处理及关键帧提取,获取视频中各人物特征以及人物之间的共生性特征；将整个视频中每集的人物脉络特征内容提取,并根据内容展示接口中的脉络特征格式呈现；根据搜索目标检索所有集目下的视频显现率,并在内容展现接口呈现出对应角色在每一集下出现的频率大小,同时视频显现率较高的视频链接以平铺形式展现以供点击浏览；以视频相册形式显示当前选定的视频的各个关键帧。实施本发明实施例,可以应用于电视连续剧等故事性强的多集数字家庭高清媒体,帮助连续剧用户快速把握多集视频的人物脉络和情感发展,最终实现快速预览和目标定位。</td>   <td>一种基于数字家庭高清媒体的内容分析方法,其特征在于,所述方法包括：对视频进行结构化处理及关键帧提取,获取视频中各人物特征以及人物之间的共生性特征；将整个视频中每集的人物脉络特征内容提取,并根据内容展示接口中的脉络特征格式呈现；根据搜索目标检索所有集目下的视频显现率,并在内容展现接口呈现出对应角色在每一集下出现的频率大小,同时视频显现率较高的视频链接以平铺形式展现以供点击浏览；以视频相册形式显示当前选定的视频的各个关键帧。</td>   <td>G06F17/30;G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              宋启炎;                   陈湘萍       </td>   <td>中山大学</td>   <td>一种视频图像目标检测与分割方法及系统</td>   <td>广东</td>   <td>CN106651923A</td>   <td>2017-05-10</td>   <td>本发明实施例公开了一种视频图像目标检测与分割方法及系统,其中,该方法包括：获取视频图像,根据视频图像获得差分图像；对差分图像进行插值处理,获得插值处理后的图像；对插值处理后的图像进行二值化处理,获得二值化图像；对二值化图像进行连通性检测及判别,获得运动目标的检测结果。实施本发明实施例,可以提升帧间差分法的准确性,减少帧间差分法使用时的限制,可以使得图像跟踪和图像分割更加准确。</td>   <td>一种视频图像目标检测与分割方法,其特征在于,所述方法包括：获取视频图像,根据视频图像获得差分图像；对差分图像进行插值处理,获得插值处理后的图像；对插值处理后的图像进行二值化处理,获得二值化图像；对二值化图像进行连通性检测及判别,获得运动目标的检测结果。</td>   <td>G06T7/292;G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         戚鑫;              林淑金;                   赵宝全       </td>   <td>中山大学</td>   <td>一种基于内容的电影可视化处理方法及其系统</td>   <td>广东</td>   <td>CN106649713A</td>   <td>2017-05-10</td>   <td>本发明实施例公开了一种基于内容的电影可视化处理方法及其系统,其中,该方法包括：提取电影的音视频信息,对所述音视频信息进行结构化处理,获取对应的音视频结构化内容信息；根据所述电影音视频结构化内容信息检测电影语义边界,将电影分割为内容独立的情节,并概括语义主题,归纳电影情节信息；根据所述电影语义边界、归纳的电影情节信息,以及对应的音视频信息构建可视化框架,生成可视化界面。在本发明实施例中,通过视频语义分割和情节概括,多角度、集中地呈现电影内容和整体结构,用户交互友好,有效帮助用户快速抓住电影重要情节,理解电影风格、主题,提高用户筛选电影的效率和使用体验感。</td>   <td>一种基于内容的电影可视化处理方法,其特征在于,所述方法包括：提取电影的音视频信息,对所述音视频信息进行结构化处理,获取对应的音视频结构化内容信息；根据所述电影音视频结构化内容信息检测电影语义边界,将电影分割为内容独立的情节,并概括语义主题,归纳电影情节信息；根据所述电影语义边界、归纳的电影情节信息,以及对应的音视频信息构建可视化框架,生成可视化界面。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   常华健       </td>   <td>中山大学</td>   <td>一种社交网络中社团话题演化挖掘方法</td>   <td>广东</td>   <td>CN106649726A</td>   <td>2017-05-10</td>   <td>本发明公开了一种社交网络中社团话题演化挖掘的方法,包括下述步骤：S1、采集社交网络数据,并对数据进行预处理；S2、分析话题数据,在考虑突发性、连续性、密集性的基础上建立特征值计算模型,建立话题#时间树,抽取话题时间,并对文本进行聚类分析；S3、实现话题演化序列的输出。话题演化序列是文本聚类的结果,能够显示话题演化轨迹,具有现实意义。本发明综合考虑话题演化过程中的突发性、连续性和密集性,准确提取话题时间,通过层次聚类的方式获得聚类结果并输出演化序列。</td>   <td>一种基于社交网络中社团话题的演化挖掘方法,其特征在于,包括下述步骤：S1、采集社交网络数据,并对数据进行预处理；S2、分析话题数据,在考虑突发性、连续性、密集性的基础上建立特征值计算模型,建立话题#时间树,抽取话题时间,并对文本进行聚类分析；S3、实现话题演化序列的输出。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   邱章成       </td>   <td>中山大学</td>   <td>一种基于社交网络短文本流的用户聚类和短文本聚类方法</td>   <td>广东</td>   <td>CN106649730A</td>   <td>2017-05-10</td>   <td>本发明目的在于解决当前基于语义的用户聚类和短文本聚类方法中未考虑社交因素,“词义漂移”和短文本稀疏性问题。提出一种基于社交网络短文本流主题建模的用户聚类和文本聚类方法,包括下述步骤：S1、语料获取；S2、语料预处理；S3、基于社交网络中的短文本数据流主题建模；S4、推导及采样；S5、对用户进行聚类；S6、对短文本进行聚类。本发明综合考虑“词义漂移”,“短文本稀疏性”和“社交网络”三个影响主题建模的因素,解决通过社交网络短文本流分析用户和文本聚类缺失社交语义信息的问题,大大提高现有聚类算法的精度。</td>   <td>基于社交网络短文本流的用户聚类和短文本聚类方法,其特征在于,包括下述步骤：S1、语料获取,通过实现爬虫或社交网络平台公司开放的API获取该社交网络平台的语料库抑或通过自建社交网络系统收集用户语料；S2、语料预处理,包含分词,去停用词,提取词干和提取实体；S3、基于社交网络中的短文本数据流主题建模,针对语料中文本作者之间存在的社交关系,文本内“词义漂移”问题和短文本稀疏性问题,对语料中的文本进行主题建模,以抽取每个文本的主题；S4、推导及采样,根据已建立的概率图模型,推导该模型的主题联合概率分布,并以此作为吉布斯抽样的联合概率分布,最后抽样收敛时,统计用户和文本的主题分布；S5、对用户进行聚类,将得到的用户主题作为语料中用户的特征,并执行K#Means聚类,得到用户聚类结果；S6、对短文本进行聚类,将得到的短文本主题作为短文本的特征,对执行K#Means聚类,得到短文本聚类结果。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   蒙在桥       </td>   <td>中山大学</td>   <td>一种基于大规模属性网络的节点相似性搜索方法</td>   <td>广东</td>   <td>CN106649731A</td>   <td>2017-05-10</td>   <td>本发明公开了一种基于路径采样的大规模属性网络节点相似性搜索方法。该方法基于富含节点属性的属性网络,构建属性增广图,并在增广图中采样R条路径,基于Katz指标的原则,根据采样的路径计算节点的相似性,最终返回请求节点的前k个最相似性节点。本发明综合考虑了节点的结构相似性和属性相似性,可以更准确衡量大规模属性网络中的节点相似性；运用路径采样的技术计算节点之间的相似性,提高了算法在大规模网络中的相似性搜索效率,并且能在一定置信度下保证相似性的误差范围。采用本发明的方案将能对上亿节点的属性网络进行快速有效地节点相似性检索。</td>   <td>一种基于路径采样的大规模属性网络节点相似性搜索方法,所述包括下述步骤：S1、根据给定的属性网络,构建出一个属性增广图；S2、根据构建出的属性增广图,初始化传播概率；S3、根据传播概率,在属性增广图中进行单源路径采样,当路径数量达到R值时停止采样,并对这些路径进行索引；S4、运用索引的路径计算出节点相似性；S5、对相似性进行排序,返回搜索节点。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;                   张家铭       </td>   <td>中山大学</td>   <td>一种基于无线接入点情境分类与感知的在线视频推荐方法</td>   <td>广东</td>   <td>CN106649733A</td>   <td>2017-05-10</td>   <td>本发明提供一种基于无线接入点情境分类与感知的在线视频推荐方法,该方法通过对SSID进行关键字提取,找出与用户情境相关的关键字,从而确定部分AP的情境。然后再以确定情境的AP作为种子,通过矩阵分解提取AP的特征,并根据这些特征使用k#means聚类算法将情境相似的AP聚合在一起,解决了用户所在AP的情境如何确定的问题；针对每个情境,利用该情境中的视频流行度排名,基于后过滤方法,对上述协同过滤模型计算得出的视频推荐列表进行重排与过滤,使得情境中观看量更大的视频的排名更高,从而实现根据情境自适应调整视频推荐列表的方法,为用户提供更为良好的个性化视频推荐服务。</td>   <td>一种基于无线接入点情境分类与感知的在线视频推荐方法,其特征在于,包括以下步骤：S1：根据用户观看记录,训练出协同过滤推荐模型和AP分类模型；S2：根据训练好的协同过滤推荐模型计算出给定用户的视频推荐列表；S3：根据AP分类模型对用户所在情境进行估计；S4：针对每个情境,利用该情境中的视频流行度排名,对上述协同过滤模型计算得出的视频推荐列表进行重排与过滤得到最终的视频推荐列表。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;                   陈思嘉       </td>   <td>中山大学</td>   <td>一种基于彩色立体标定物的无人机标定方法及系统</td>   <td>广东</td>   <td>CN106651961A</td>   <td>2017-05-10</td>   <td>本发明公开了一种基于彩色立体标定物的无人机标定方法及系统,方法包括：将彩色棋盘格立体标定物放置到待拍摄场景内；采用无人机至少从3个不同的方位拍摄彩色棋盘格立体标定物的图像；根据拍摄的彩色棋盘格立体标定物的图像采用灭点理论线性求解出无人机摄像机内参数；根据无人机摄像机内参数采用坐标投影变换方法确定无人机摄像机的空间位置和图像几何约束关系。本发明采用了彩色棋盘格立体标定物来进行摄像机标定,易于准确测量、检测精度高、便于安放和通用性强；只需至少从3个不同的方位拍摄彩色棋盘格立体标定物的图像并结合灭点理论得到无人机摄像机内参数来完成摄像机内参数的标定,使用起来更方便。本发明可广泛应用于计算机视觉领域。</td>   <td>一种基于彩色立体标定物的无人机标定方法,其特征在于：包括以下步骤：将彩色棋盘格立体标定物放置到待拍摄场景内,所述彩色棋盘格立体标定物为封闭式立体结构,所述彩色棋盘格立体标定物包含有至少一个顶面和一个侧面,所述彩色棋盘格立体标定物的每个表面采用彩色与白色相间、彩色与黑色相间、不同彩色相间或黑色与白色相间的棋盘格图案且任意相邻两个表面的棋盘格图案的颜色组合均不相同；采用无人机至少从3个不同的方位拍摄彩色棋盘格立体标定物的图像；根据拍摄的彩色棋盘格立体标定物的图像采用灭点理论线性求解出无人机摄像机内参数；根据无人机摄像机内参数采用坐标投影变换方法确定无人机摄像机的空间位置和图像几何约束关系。</td>   <td>G06T7/80;G06T7/90;G01C11/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              吴永波;              李昊曦;                   杜灵双       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种跨年龄人脸识别方法</td>   <td>广东</td>   <td>CN106650650A</td>   <td>2017-05-10</td>   <td>本发明提供一种跨年龄人脸识别方法,该方法通过大量包含四个年龄段的人脸图像训练得到一个由两大模块(最大熵特征描述模块和老化感知去噪自动编码模块)组成的跨年龄人脸识别系统,实现对任意两幅不同年龄人脸图像的识别。最大熵特征描述模块利用决策树的最大熵分裂来实现包含最大信息量的编码分配,老化感知去噪自动编码模块将一个任意年龄段的特征描述符重构成四个不同年龄段的特征描述符,综合这些描述符获得一个消除老化影响的人脸综合特征向量,最后计算不同人脸的综合特征向量的余弦距离实现人脸识别。本发明能够很好地减少一些传统描述符的信息丢失问题,并且消除了跨年龄人脸识别中老化因素的影响,在跨年龄人脸识别问题中有很好的表现。</td>   <td>一种跨年龄人脸识别方法,其特征在于,包括以下步骤：S1：对要识别的人脸图像进行密集采样,即将人脸图像划分为多个互相重叠的块,对每一块进行像素矢量的提取,划分时块的重叠半径采取多个值来尽可能保留人脸的局部信息；S2：对于已提取的像素矢量,建立一棵决策树,将树的根节点概率值设置为1,采用最大熵的原则递归扩展树,最后为树的每个叶子节点分配一个编码,其中,每个叶子节点代表了一个局部特征；S3：对每一幅人脸图像,将获取的最大熵特征描述编码串联成一个特征向量,对该特征向量重新进行分割,采用主成分分析等方法对特征向量进行降维,获得的低维特征向量v作为老化感知自动编码器的输入；S4：用老化感知自动编码器对特征向量v进行编码,生成4个年龄段的人脸特征向量v'<sub>i</sub>(i＝1,...,4),其中4个年龄段包括：幼年,青年,成年,老年；S5：将两幅人脸合成的特征向量按照年龄段串联成一个长向量,同时原始人脸的特征向量也合并入该向量,通过计算两向量的余弦距离来判断两幅人脸是否来自同一人；S6：模型训练时,提取同一个人的四个年龄段的人脸最大熵特征,将特征向量v加入一定噪声后映射到隐含层得到一个有损压缩码h,然后用h来预测四个年龄段的特征向量v'<sub>i</sub>,通过最小化损失函数得到自动编码器,通过多次上述地映射与重构过程生成多层老化感知去噪自动编码器,在构造多层去噪自动编码器时,需要用严格玻尔兹曼机以非监督的方式逐层地进行预训练。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              杜灵双;                   李昊曦       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于深度学习的人脸识别和年龄合成联合模型的构建方法</td>   <td>广东</td>   <td>CN106650653A</td>   <td>2017-05-10</td>   <td>本发明提供一种基于深度学习的人脸识别和年龄合成联合模型的构建方法,该方法通过对输入的一对图像进行对齐和PCA和LDA降维的预处理；并通过一个经过训练得到的自动编码器,得到用于身份表示的特征和不同年龄段表示的特征共6组,然后对6对结果经过平行CNN,输出图像相似度,之后加权融合得到匹配结果；该发明对单独的人脸识别或者年龄检测以及共同任务均能得到很好的效果,对光照、姿势影响下的人脸识别也额能取得很好的效果；由于区分开了年龄与人脸身份的特征,因此对跨年龄的人脸识别也具有鲁棒性。并且,可视要求而定调整一些参数和权值,因此非常有灵活性。</td>   <td>一种基于深度学习的人脸识别和年龄合成联合模型的构建方法,其特征在于,包括以下步骤：S1：对图像进行切片预处理：根据双眼中心进行对齐,采用PCA和LDA的方式进行降维,以及达到增大类间差距的目的；S2：编码：通过训练数据得到的一个自动编码器对输入特征向量进行编码。该编码器的目的是将原图特征通过某种编码方式合成新的特征,用于表达身份或者年龄的相关信息,对任何输入的图片,该编码器将生成六组不同的表达：第一组为身份表达,对原特征减去平均脸后的映射编码,反映个体的身份的稳定信息；第二组至第六组分别为幼年、少年、成年、中年、老年五个年龄段下原图像的合成图像的表达,这一部分的编码过程与上述相似,不同的是输入是原图信息,这五组编码器的作用是模拟老化过程来合成特定年龄组的图片,然后通过损失函数和一定的约束规则来控制消除年龄对身份表达的影响,即在年龄合成中起到重要作用的特征,降低它在身份表达中起的作用；S3：对每对图像进行身份匹配验证：测试图像与一幅训练图像作为一对,由编码器得到的六对特征分别通过平行CNN,Softmax层将给出输入的一对特征的相似度的大小；令I<sub>a</sub>,I<sub>b</sub>为一对输入图像,则相似得分表示为：s(I<sub>a</sub>,I<sub>b</sub>)＝soft#max(Ws|o(I<sub>a</sub>)#o(I<sub>b</sub>)|+b<sub>s</sub>)其中,o()表示CNN中全连接层的输出,Ws和b<sub>s</sub>为softmax层的参数；对这六个结果进行加权平均即可得到验证结果,其中身份表达占的比重较大；五对年龄合成的相似度表示在五个年龄段里的相似度,作为参考因素,占的比重比身份表达要小,由此将得到两幅图像匹配的概率：score＝as<sub>1</sub>+(1#a)(s<sub>2</sub>+s<sub>3</sub>+s<sub>4</sub>+s<sub>5</sub>+s<sub>6</sub>)；S4：对所有特征得到的相似得分结果进行余弦相似度融合,即可得到最终的结果。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;                   陈靖       </td>   <td>中山大学</td>   <td>一种彩色素描模拟方法</td>   <td>广东</td>   <td>CN106652009A</td>   <td>2017-05-10</td>   <td>本发明提供的彩色素描模拟方法在线积分卷积生成黑白素描的基础上,通过研究彩色素描的绘制特点,结合双色调映射技术实现了基于色彩定制的彩色素描绘制。该策略首先对图像进行区域分割,而后按照上下叠加的方式,用一个主色调和一个副色调进行色彩融合来表现每个分割的区域。每个特定的区域可以自动地、也可以由用户交互地指定颜色集。此外,本发明所提供的方法通过增设纸肌理,使得能够将真实的素描纸肌理添加到计算机生成的图像当中,使得最终的效果更接近真实的绘画。本发明在对图像进行分割方面采用的是基于k#means聚类的分割方法,在保证分割效率的同时还使得分割结果更好地适应彩色素描的绘制。</td>   <td>一种彩色素描模拟方法,其特征在于：包括以下步骤：S1.使用K#means聚类分割方法对图像进行分割,将图像分割成若干个区域；S2.以图像所分割区域原来的颜色为依据,为每个区域指定主色调和副色调；各个分割区域所确定的主色调和副色调联结在一起形成图像的主色调层和副色调层；S3.依据随机赋值算法对主色调层和副色调层进行赋值处理,分别生成主色调层和副色调层的噪声图像；S4.对每个区域围绕其中心建立边长为m的窗口,将该窗口转换到频域；然后将频域分成几个不同的角度区间,并计算每个角度区间的能量值和总体均值；将计算获得的最大能量值与总体均值进行比较,若两者之间的比例大于所设定的阈值,则判定该区域的纹理走向与最大能量值所对应的角度垂直；S5.对主色调层和副色调层噪声图像中的每个像素点,以其为中心沿其所属区域的纹理走向的正、反两个方向查找与其相邻的n个像素点以形成流线,利用卷积核对流线上各个像素点的噪声值进行卷积计算,并将计算得到的结果赋值给主色调层或副色调层噪声图像中的原像素点；S6.使用霓虹变换的方法对图像进行处理,得到素描轮廓；S7.将步骤S5得到的主色调层和副色调层噪声图像按照上下次序使用双色调映射的方法进行融合,得到彩色素描的纹理图,在纹理图的基础上叠加素描轮廓,即可得到彩色素描的效果。</td>   <td>G06T15/02;G06T7/11;G06T7/49;G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;                   肖翔       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于混合池化策略的深度卷积特征的动作识别方法</td>   <td>广东</td>   <td>CN106650674A</td>   <td>2017-05-10</td>   <td>本发明公开一种基于混合池化策略的深度卷积特征的动作识别方法,包括：1)对输入视频每一帧采用空间流深度网络模型,得到每帧的表观特征；对视频中每连续10帧采用时间流深度网络模型,提取视频的运动特征；2)对空间流和时间流深度网络的最后一层卷积层输出的深度卷积图采用时间滤波器池化方法得到对应的特征表示,采用主成分分析方法进行降维得到第一描述子特征；对空间流和时间流深度网络的最后一层卷积层输出的深度卷积图采用时空金字塔池化方法得到对应的特征表示,用主成分分析方法进行降维得到第二描述子特征；3)将步骤2)得到的第一、二描述子特征级联起来,形成输入视频的特征描述子,并采用线性支持向量机进行特征分类,得到识别准确率。</td>   <td>一种基于混合池化策略的深度卷积特征的动作识别方法,其特征在于,包括以下步骤：(1)输入待识别的视频,对输入视频的每一帧,利用空间流深度网络模型得到每帧的表观特征；同时对输入视频的每连续M帧,利用时间流深度网络模型得到运动特征；其中空间流深度网络模型和时间流深度网络模型均包括5个卷积层,3个池化层,以及3个全连接层；(2)对空间流深度网络模型和时间流深度网络模型得到的最后一层卷积层输出的深度卷积图采用时间滤波器池化方法得到对应的特征表示,采用不同长度间隔的时间序列,以获取视频的全局和局部运动,并采用主成分分析方法对特征进行降维,得到第一描述子特征；同时,对空间流深度网络模型和时间流深度网络模型得到的最后一层卷积层输出的深度卷积图采用时空金字塔池化方法得到对应的特征表示,采用4层的时空金字塔结构来获取深度特征图中的局部信息,并对于目标和几何变形具有鲁棒性；同样的也采用主成分分析进行特征降维,得到第二描述子特征；(4)对步骤(2)提取的第一、二描述子特征级联起来,形成该视频最终的向量表示；采用支持向量机(SVM)进行特征分类,最终输出分类结果,获取视频的动作识别结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   吴家淮       </td>   <td>中山大学</td>   <td>基于批装箱问题的虚拟机调度方法</td>   <td>广东</td>   <td>CN106648834A</td>   <td>2017-05-10</td>   <td>本发明公开了一种基于批装箱问题的虚拟机调度方法,该方法包括以下步骤：S1：虚拟机调度器定期接收用户提交的新的虚拟机请求,同时收集系统中每台物理机上运行的虚拟机的状态信息,包括即将结束运行的虚拟机信息；S2：针对新的每一组虚拟机请求,虚拟机调度器采用批装箱算法进行调整,得出新的虚拟机与物理机的对应关系表；S3：虚拟机调度器比较算法调度前后对应关系表之间的差异,制定并发送迁移指令给指定物理机,相关物理机根据指令完成虚拟机迁移。与现有技术相比,本发明方法关闭了空闲服务器以降低能耗,同时有效减少了虚拟机迁移次数提高了分配效率。</td>   <td>基于批装箱问题模型的虚拟机调度方法,其特征在于,包括下述步骤：S1：虚拟机调度器定期接收用户提交的新的虚拟机请求,同时收集系统中每台物理机上运行的虚拟机的状态信息,包括即将结束运行的虚拟机信息；S2：针对新的虚拟机请求和发生变化的虚拟机信息,虚拟机调度器采用装箱算法进行调整,得出新的虚拟机与物理机的对应关系表；S3：虚拟机调度器比较算法调度前后对应关系表之间的差异,制定并发送迁移指令给指定物理机,相关物理机根据指令完成虚拟机迁移。</td>   <td>G06F9/455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              袁帅;              何娜;                   陈至宇       </td>   <td>中山大学</td>   <td>一种鲁棒的车牌、车标识别方法</td>   <td>广东</td>   <td>CN106650731A</td>   <td>2017-05-10</td>   <td>本发明公开一种鲁棒的车牌、车标识别方法。采用基于Adaboost检测、SVM筛选以及纹理分析去边的方法进行车牌精确检测,以有效应对不同场景、光照、视角、分辨率等,检测出的车牌区域只包含较少的背景。以最大稳定极值区域检测为主、滑动窗检测为辅,配合能量优化进行车牌识别,不仅能够有效地检测出传统的基于字符分割方法难以处理的车牌污损、分辨率不足等情况下的字符,而且使得字符检测与识别同步进行,打破传统的“先分割再识别”的模式。采用基于置信度加权的特征编码表达车标样本,利用基于组稀疏的判别性字典对模型识别编码的车标特征,对包含复杂背景的车标样本具有较强的鲁棒性。</td>   <td>一种鲁棒的车牌识别方法,其特征在于,包括车牌检测阶段和车牌识别阶段,在车牌检测阶段实现车牌区域的定位,基于定位后的车牌区域再进行车牌识别,其中车牌识别阶段具体实现过程为：11)对定位后车牌区域进行灰度化；12)利用最大稳定极值区域MSER检测方法在灰度化的车牌区域中寻找最大稳定极值区域,并对其检测结果进行候选字符窗口的排序,具体是根据每个候选字符窗口左上角起点的横坐标进行排序；13)对MSER的检测结果进行非字符窗口的初步滤除；14)记录并保存初步过滤后的每个候选字符窗口的置信度、中心点坐标以及宽和高,进而得到该特定车牌的字符宽、高均值；15)利用保存的候选字符窗口的中心点坐标以及该特定车牌的字符宽、高的均值进行字符窗口恢复；16)利用基于滑动窗的检测方法和该特定车牌字符宽、高的均值,进一步检测基于MSER的方法可能漏检的字符；17)利用能量优化的方法对候选字符窗口进行识别,输出最终车牌识别的结果；能量优化方程如下式所示：<maths num="0001"><math><![CDATA[<mrow><mi>E</mi><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>i</mi><mo> =</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>E</mi><mi>i</mi></msub><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>+</mo><munder><mo>&Sigma;</mo><mi>&epsiv;</mi></munder><msub><mi>E</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001190174490000011.TIF" wi="654" he="118" /></maths>其中,x＝{x<sub>i</sub>|i＝1,2,...,n}为窗口类标的集合,x<sub>i</sub>表示第i个窗口的类标,E<sub>i</sub>(x<sub>i</sub>)＝1#p(x<sub>i</sub>|c<sub>i</sub>)为一元项,表示自能量,其中c<sub>i</sub>表示第i个窗口,p(x<sub>i</sub>|c<sub>i</sub>)为窗口c<sub>i</sub>属于x<sub>i</sub>类的概率；E<sub>ij</sub>(x<sub>i</sub>,x<sub>j</sub>)为二元项,表示互能量,当x<sub>i</sub>与x<sub>j</sub>均为背景类时,E<sub>ij</sub>(x<sub>i</sub>,x<sub>j</sub>)＝0,否则E<sub>ij</sub>(x<sub>i</sub>,x<sub>j</sub>)＝λexp(#[100#Overlap(x<sub>i</sub>,x<sub>j</sub>)]<sup>2</sup>),其中Overlap(x<sub>i</sub>,x<sub>j</sub>)表示窗口之间重叠部分占窗口总面积的百分数,λ为调整互能量权重的参数；ε表示互有交集的窗口对的集合。</td>   <td>G06K9/32;G06K9/34;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘文奇;              曾坤;              龚永义;                   罗笑南       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的图像头发识别方法及其装置</td>   <td>广东</td>   <td>CN106611160A</td>   <td>2017-05-03</td>   <td>本发明实施例公开了一种基于卷积神经网络的图像头发识别方法及其装置,其中,该方法包括：收集图集；对图集中的每一张图片进行标记；对图集中的每一张图片进行预处理；检测图集中每一张图片的人像头部位置,获得训练图集对应的头部位置信息和测试图集对应的头部位置信息；基于全卷积网络构造头发全卷积网络；对头发全卷积网络进行训练；将输出的结果与头发区域遮蔽测试图集相比较,获得对头发全卷积网络的评估结果；将欲获取头发遮蔽图的图片输入头发全卷积网络,获得该图像头发区域的遮掩图。可以解决现有技术中难以处理背景颜色与头发颜色相似的情况,以及无法在图像人脸偏转角度很大或人背面的情况下无法识别头发的问题。</td>   <td>一种基于卷积神经网络的图像头发识别方法,其特征在于,所述方法包括：收集图集,该图集包括训练图集和测试图集；对图集中的每一张图片进行标记,获得训练图集对应的头发区域遮掩训练图集和测试图集对应的头发区域遮蔽测试图集；对图集中的每一张图片进行预处理,获得与训练图集对应的YCrCb训练图集和频率遮蔽训练图集、与测试图集对应的YCrCb测试图集和频率遮蔽测试图集；检测图集中每一张图片的人像头部位置,获得训练图集对应的头部位置信息和测试图集对应的头部位置信息；基于全卷积网络构造头发全卷积网络HFCN；将YCrCb训练图集、频率遮蔽训练图集及训练图集的头部位置信息进行编码,输入到头发全卷积网络,同时,将头发区域遮蔽训练图集输入头发全卷积网络,对头发全卷积网络进行训练,获得训练好的头发全卷积网络；将YCrCb测试图集、频率遮蔽测试图集及测试图集的头部位置信息进行编码,并输入到训练好的头发全卷积网络,将输出的结果与头发区域遮蔽测试图集相比较,获得对头发全卷积网络的评估结果；将欲获取头发遮蔽图的图片输入头发全卷积网络,获得该图像头发区域的遮掩图。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              吴捷;              张俊轩;              杨梁;                   王伟轩       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种多级联结循环神经网络的图像描述方法</td>   <td>广东</td>   <td>CN106599198A</td>   <td>2017-04-26</td>   <td>本发明提供一种多级联结循环神经网络的图像描述方法,该方法从标注语句训练集中构建属性词汇表,采用VGGNet模型作为CNN模型,采用带标签的数据集进行CNN的参数训练与调整,输入待描述的图像,得到语义属性预测概率,将图像送入CNN网络中提取出描述释义向量并计算出每个释义对应的权重,再根据释义向量以及其对应权重计算出上下文向量,将语义属性预测概率及上下文向量输入到多级联结的循环神经网络中,输出的结果的组合即为该图像的自然语言描述。</td>   <td>一种多级联结循环神经网络的图像描述方法,其特征在于,包括以下步骤：S1：从标注语句训练集中提取语义属性,构建属性词汇表；S2：采用VGGNet模型作为CNN初始模型,采用单标签的ImageNet数据集进行CNN的参数预训练,然后再用多标签数据集MS#COCO进行CNN参数的精细调整；S3：输入待描述的图像,将其分割成不同的区域,输入到训练好的CNN中,将图像信息表达成高等级的语义信息,得到语义属性预测概率；S4：将图像送入CNN网络中提取出描述不同区域的释义向量；S5：根据前一步系统的隐变量的信息计算出每个释义对应的权重,再根据释义向量以及其对应权重计算出上下文向量；S6：将语义属性预测概率及上下文向量输入到多级联结的循环神经网络中,输出的结果的组合即为该图像的自然语言描述。</td>   <td>G06F17/30;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              孙雪冬       </td>   <td>中山大学</td>   <td>基于有向超图的个性化学习路径的抽取与拼接方法及系统</td>   <td>广东</td>   <td>CN106600065A</td>   <td>2017-04-26</td>   <td>本发明公开了一种基于有向超图的个性化学习路径的抽取与拼接方法及系统。该方法根据知识元之间的依赖关系、利用有向超图理论对相关领域知识进行建模,获得相关知识图谱；根据学习者的知识背景和知识目标对相关知识图谱进行相应的处理,得到个性化知识图谱；利用超图的性质和模型上所附加的知识语义,通过逆向回溯找到从开始知识元集到学习目标的个性化学习路径集；给出逆向回溯中学习背景、多输入/输出以及多目标的处理规则；并给出从变化发展的角度进行路径优选的算法。本发明能根据学习者的知识目标及背景给出相对稳定的、优化的学习内容及知识路径；并能根据学习目标和知识背景的变化进行学习内容和学习路径调整。</td>   <td>一种基于有向超图的个性化学习路径的抽取与拼接方法,其特征在于：具体包括以下步骤：步骤1,根据知识元之间的关系,利用有向超图建立相关知识图谱；步骤2,基于相关知识图谱,根据学习者知识目标和知识背景创建个性化的知识图谱；步骤3,基于个性化知识图谱,以目标知识元集为起点,采用逆向搜索的方式来进行可达路径的抽取和拼接；步骤4,根据模型的语义进行学习路径的优选；步骤5,监测学习目标及知识背景。如果学习目标发生变化,则进行新路径集与原路径集相关性判断,并进行相应处理；如果相关知识背景发生变化,则根据原知识路径的执行情况进行处理。</td>   <td>G06Q10/04;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡丹蔚;              陈金坤;              蔡炜诚;                   李明       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于改进的LSDA算法进行信道补偿的说话人识别方法</td>   <td>广东</td>   <td>CN106601258A</td>   <td>2017-04-26</td>   <td>本发明提供的说话人识别方法引入改进的LSDA算法代替之前的LDA算法来进行信道补偿,改进的LSDA算法通过引入自适应k近邻的概念,跟据每个类的大小自适应地寻找k个类内近邻与βk个类间近邻；并且引入每一说话人类对算法贡献均等的概念,对每一说话人类在目标方程中的贡献进行归一化处理。使得方法更适用于说话人识别任务的数据分布,从而在说话人识别准确率上得到比原始LSDA算法更好的性能提升。</td>   <td>一种基于改进的LSDA算法进行信道补偿的说话人识别方法,其特征在于：包括以下步骤：S1.对训练数据中所有的语音进行语音信号检测,并提取MFCC特征；S2.使用神经网络声学模型对MFCC特征进行处理,一个MFCC帧通过神经网络声学模型的处理后,得到多维的音素层单元后验概率向量,对得到的音素层单元后验概率向量进行取对数、主成分分析降维、均值方差归一化处理之后,得到一个多维的向量,将这个向量拼接到与其对应的MFCC特征后,得到tandem特征；S3.利用tandem特征训练一个包含多个高斯分量的混合高斯模型作为通用背景模型,并将所有语音在这个通用背景模型上计算出充分统计量；对于训练数据中的任一条语音,基于充分统计量计算出其高维的超向量；S4.使用单因子分析方法对训练数据中所有的语音学习出一个低维的总体差异空间,即说话人空间；将训练数据中所有的语音的超向量在这个总体差异空间上投影得出每一条语音的身份向量{x<sub>1</sub>,x<sub>2</sub>,…,x<sub>m</sub>}；每条身份向量关联着说话人的身份信息,第i条身份向量x<sub>i</sub>对应的说话人标签为l(x<sub>i</sub>)；S5.使用改进的LSDA算法进行信道补偿：S51.对于每一条身份向量x<sub>i</sub>,寻找k个具有相同说话人类标的类内近邻子集N<sub>w</sub>(x<sub>i</sub>)与βk个具有不同说话人类标的类间近邻子集N<sub>b</sub>(x<sub>i</sub>),其中β为一个常量；当N<sub>w</sub>(x<sub>i</sub>)中对应的说话人的身份向量数n<sub>c</sub>小于k时,令k＝n<sub>c</sub>；S52.基于类内近邻子集N<sub>w</sub>(x<sub>i</sub>)与类间近邻子集N<sub>b</sub>(x<sub>i</sub>)构建身份向量的类内近邻图G<sub>w</sub>与类间近邻图G<sub>b</sub>,以及类内近邻图G<sub>w</sub>与类间近邻图G<sub>b</sub>的权值矩阵W<sub>w</sub>′与W<sub>b</sub>′：<img file="FDA0001177536350000011.TIF" wi="742" he="229" /><img file="FDA0001177536350000012.TIF" wi="758" he="223" />#其中,i、j表示矩阵W<sub>b</sub>′中第i行、第j列的元素；#为了满足对LSDA算法的两个目标方程的变形改写,最终的类内权值矩阵W<sub>w</sub>与类间权值矩阵W<sub>b</sub>为如下对称矩阵的形式：<maths num="0001"><math><![CDATA[<mrow><msub><mi>W</mi><mi>w</mi></msub><mo> =</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>(</mo><msubsup><mi>W</mi><mi>w</mi><mo>&prime;</mo></msubsup><mo>+</mo><msubsup><mi>W</mi><mi>w</mi><mrow><mo>&prime;</mo><mi>T</mi></mrow></msubsup><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001177536350000021.TIF" wi="430" he="117" /></maths><maths num="0002"><math><![CDATA[<mrow><msub><mi>W</mi><mi>b</mi></msub><mo> =</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>(</mo><msubsup><mi>W</mi><mi>b</mi><mo>&prime;</mo></msubsup><mo>+</mo><msubsup><mi>W</mi><mi>b</mi><mrow><mo>&prime;</mo><mi>T</mi></mrow></msubsup><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001177536350000022.TIF" wi="423" he="117" /></maths>S53.寻找一个在原数据流形与目标子流形之间的映射,使得在目标子流形中,G<sub>w</sub>内的连接点尽量地接近,G<sub>b</sub>内的连接点尽量地隔离开；令<img file="FDA0001177536350000023.TIF" wi="371" he="63" /><img file="FDA0001177536350000024.TIF" wi="346" he="55" />为一个最优的线性映射,则y<sub>i</sub>＝A<sup>T</sup>x<sub>i</sub>；其中,<img file="FDA0001177536350000025.TIF" wi="110" he="55" />表示n×d维的实数空间,<img file="FDA0001177536350000026.TIF" wi="65" he="47" />表示n维的实数空间,<img file="FDA0001177536350000027.TIF" wi="59" he="31" />表示映射；LSDA算法的两个目标方程可写为：min∑<sub>ij</sub>(a<sup>T</sup>x<sub>i</sub>#a<sup>T</sup>x<sub>j</sub>)<sup>2</sup>W<sub>w,ij</sub>max∑<sub>ij</sub>(a<sup>T</sup>x<sub>i</sub>#a<sup>T</sup>x<sub>j</sub>)<sup>2</sup>W<sub>b,ij</sub>其中a表示A＝(a<sub>1</sub>,…,a<sub>d</sub>)中的一个列向量；通过矩阵运算,LSDA算法的两个目标方程重写为：<maths num="0003"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mrow><mo>(</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><mo>)</mo></mrow><mn>2</mn></msup><msub><mi>W</mi><mrow><mi>w</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo>(</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><mi>a</mi><mo>-</mo><mn>2</mn><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><mo>+</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><msubsup><mi>x</mi><mi>j</mi><mi>T</mi></msubsup><mi>a</mi><mo>)</mo></mrow><msub><mi>W</mi><mrow><mi>w</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>(</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi>aW</mi><mrow><mi>w</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><msubsup><mi>x</mi><mi>j</mi><mi>T</mi></msubsup><msub><mi>aW</mi><mrow><mi>w</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub><mo>)</mo></mrow><mo>-</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><msub><mi>W</mi><mrow><mi>w</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi>aW</mi><mrow><mi>w</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><msub><mi>W</mi><mrow><mi>w</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>XD</mi><mi>w</mi></msub><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi><mo>-</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>XW</mi><mi>w</mi></msub><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FDA0001177536350000028.TIF" wi="1461" he="830" /></maths><maths num="0004"><math><![CDATA[<mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mrow><mo>(</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><mo>-</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><mo>)</mo></mrow><mn>2</mn></msup><msub><mi>W</mi><mrow><mi>b</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub><mo> =</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>XL</mi><mi>b</mi></msub><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi></mrow>]]></math><img file="FDA0001177536350000029.TIF" wi="854" he="134" /></maths><maths num="0005"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><mrow><mo> =</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mrow><mo>(</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><mi>a</mi><mo>-</mo><mn>2</mn><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><mo>+</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><msubsup><mi>x</mi><mi>j</mi><mi>T</mi></msubsup><mi>a</mi><mo>)</mo></mrow><msub><mi>W</mi><mrow><mi>b</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><mrow><mo>(</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi>aW</mi><mrow><mi>b</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub><mo>+</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><msubsup><mi>x</mi><mi>j</mi><mi>T</mi></msubsup><msub><mi>aW</mi><mrow><mi>b</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub><mo>)</mo></mrow><mo>-</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><msub><mi>W</mi><mrow><mi>b</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msubsup><mi>x</mi><mi>i</mi><mi>T</mi></msubsup><msub><mi>aW</mi><mrow><mi>b</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub><mo>-</mo><msub><mi>&Sigma;</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>i</mi></msub><msup><mi>a</mi><mi>T</mi></msup><msub><mi>x</mi><mi>j</mi></msub><msub><mi>W</mi><mrow><mi>b</mi><mo>,</mo><mi>i</mi><mi>j</mi></mrow></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>XD</mi><mi>b</mi></msub><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi><mo>-</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>XW</mi><mi>b</mi></msub><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi></mrow></mtd></mtr><mtr><mtd><mrow><mo> =</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>XL</mi><mi>b</mi></msub><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FDA0001177536350000031.TIF" wi="1438" he="727" /></maths>#其中,D<sub>w</sub>为对角阵,D<sub>w,ii</sub>＝∑<sub>j</sub>W<sub>w,ij</sub>；L<sub>b</sub>＝D<sub>b</sub>#W<sub>b</sub>,D<sub>b,ii</sub>＝∑<sub>j</sub>W<sub>b,ij</sub>；X＝(x<sub>1</sub>,x<sub>2</sub>,…,x<sub>m</sub>)是一个n×m的矩阵；#S54.当对角阵D<sub>w</sub>中的D<sub>w,ii</sub>很大时,表示数据点x<sub>i</sub>所在的类在数据点x<sub>i</sub>处很密集,因此这个点x<sub>i</sub>更加重要；引入一个限制条件,如下：#a<sup>T</sup>XD<sub>w</sub>X<sup>T</sup>a＝1#因此,LSDA算法的第一个目标方程可重写为：<maths num="0006"><math><![CDATA[<mrow><munder><mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow><mi>a</mi></munder><mn>1</mn><mo>-</mo><msup><mi>a</mi><mi>T</mi></msup><msub><mi>XW</mi><mi>w</mi></msub><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi></mrow>]]></math><img file="FDA0001177536350000032.TIF" wi="429" he="79" /></maths>#也即：<maths num="0007"><math><![CDATA[<mrow><munder><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow><mi>a</mi></munder><msup><mi>a</mi><mi>T</mi></msup><msub><mi>XW</mi><mi>w</mi></msub><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi></mrow>]]></math><img file="FDA0001177536350000033.TIF" wi="349" he="87" /></maths>#综合以上的公式推导,LSDA的最终目标方程为：<maths num="0008"><math><![CDATA[<mfenced open = "" close = ""><mtable><mtr><mtd><munder><mi>argmax</mi><mi>a</mi></munder></mtd><mtd><mrow><msup><mi>a</mi><mi>T</mi></msup><mi>X</mi><mo>&lsqb;</mo><msub><mi>&alpha;L</mi><mi>b</mi></msub><mo>+</mo><mrow><mo>(</mo><mn>1</mn><mo>-</mo><mi>&alpha;</mi><mo>)</mo></mrow><msub><mi>W</mi><mi>w</mi></msub><mo>&rsqb;</mo><msup><mi>X</mi><mi>T</mi></msup><mi>a</mi></mrow></mtd></mtr></mtable></mfenced>]]></math><img file="FDA0001177536350000034.TIF" wi="797" he="83" /></maths>a<sup>T</sup>XD<sub>w</sub>X<sup>T</sup>a＝1其中,α为调整类内图G<sub>w</sub>与类间图G<sub>b</sub>之间权值的参数,0≤α≤1；S55.使用拉格朗日乘子法,以上的目标方程写为：X[αL<sub>b</sub>+(1#α)W<sub>w</sub>]X<sup>T</sup>a＝λXD<sub>w</sub>X<sup>T</sup>a将上面公式右边的XD<sub>w</sub>X<sup>T</sup>化到公式左边,以上公式变为：(XD<sub>w</sub>X<sup>T</sup>)<sup>#1</sup>X[αL<sub>b</sub>+(1#α)W<sub>w</sub>]X<sup>T</sup>a＝λa因此,投影向量a的求解问题即可转变为以上公式的特征向量求解问题；寻找矩阵(XD<sub>w</sub>X<sup>T</sup>)<sup>#1</sup>X[αL<sub>b</sub>+(1#α)W<sub>w</sub>]X<sup>T</sup>的前d个特征向量{a<sub>1</sub>,…,a<sub>d</sub>},最终的LSDA变换矩阵为<img file="FDA0001177536350000035.TIF" wi="515" he="63" />S56.将身份向量通过LSDA变换矩阵A映射到目标身份向量；对于一条原身份向量x<sub>i</sub>,映射后的目标身份向量为y<sub>i</sub>＝A<sup>T</sup>x<sub>i</sub>；S6.使用PLDA算法对映射后的身份向量进行建模,得到PLDA模型；S7.对于两个需要判断其对应身份的语音,首先提取出其身份向量,然后计算出它们在PLDA模型上的似然得分,根据分数判断两个身份向量所对应的说话人是否为同一个。</td>   <td>G10L17/02;G10L17/18;G10L17/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗思伟;              林倞;              王青;                   聂琳       </td>   <td>中山大学</td>   <td>基于用户访问数据的用户画像形成方法</td>   <td>广东</td>   <td>CN106599022A</td>   <td>2017-04-26</td>   <td>本发明为基于用户访问数据的用户画像形成方法,利用爬虫工具、提取算法、中文分词方法对网页中的内容进行获取和自动处理,其智能化、自动化程度较高,很好地解决了现有技术的缺陷。且本发明提供的方法利用机器学习方法,学习出用户的特征,以表现出用户的生活、购物等行为偏好。</td>   <td>一种基于用户访问数据的用户画像形成方法,其特征在于：包括以下步骤：S1.对用户的访问数据进行过滤,将访问数据中无关的请求链接过滤掉,得到相关的访问链接；S2.使用爬虫工具抓取相关的访问链接对应的网页,然后使用提取算法将所抓取网页中的文本信息提取出来；S3.使用中文分词方法对提取出来的文本信息进行分词处理,其中每个网页的文本信息经过分词处理后得到的词汇列表存储在一个文档中；S4.对网络上公开的语料库进行分词处理,然后基于分词处理后的语料库使用词向量技术训练出词向量Word2Vec,得到中文词语的分布式表达；S5.创建Doc2Vec模型,利用词向量Word2Vec对Doc2Vec模型进行初始化,然后将每个文档中的词汇列表分别输入至Doc2Vec模型中,文档中的词汇列表对Doc2Vec模型进行训练,Doc2Vec模型的输出为该文档对应的网页的分布式表达；S6.对于每个标签,训练一个用于判断分布式表达中是否带有此标签的判断分类器；S7.将步骤S5中的每个网页的分布式表达分别输入至各个标签的判断分类器中,若标签的判断分类器的输出为肯定,则说明用户的网页访问带有该标签的属性；若标签的判断分类器的输出为否定,则说明用户的网页访问不带有该标签的属性。</td>   <td>G06F17/30;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王自鑫;              陈弟虎;              衣杨;                   黄侃       </td>   <td>中山大学</td>   <td>一种高层次综合工具中的指引文件自动生成方法及系统</td>   <td>广东</td>   <td>CN106599370A</td>   <td>2017-04-26</td>   <td>本发明公开了一种高层次综合工具中的指引文件自动生成方法及系统,该方法包括有以下步骤：A、获取代码中的循环信息,若存在人工定义的循环展开因子,则直接执行步骤C,否则执行步骤B；B、根据循环信息对循环进行展开处理,通过设计空间探索计算得到循环展开因子；C、根据步骤A或步骤B中得到的循环展开因子生成高层次综合工具的指引文件。本发明利用循环展开因子自动生成高层次综合工具的循环指引文件,进而供高层次综合工具使用,无需人工编写循环的处理代码,大大减少设计人员的工作量和压力,显著提高了高层次综合工具生成硬件的效果。本发明作为一种高层次综合工具中的指引文件自动生成方法及系统可广泛应用于计算机与电路设计领域。</td>   <td>一种高层次综合工具中的指引文件自动生成方法,其特征在于：包括有以下步骤：A、获取代码中的循环信息,若存在人工定义的循环展开因子,则直接执行步骤C,否则执行步骤B；B、根据循环信息对循环进行展开处理,通过设计空间探索计算得到循环展开因子；C、根据步骤A或步骤B中得到的循环展开因子生成高层次综合工具的指引文件。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;              丁卉;              刘永红;                   詹鹃铭       </td>   <td>中山大学</td>   <td>一种表征大气重污染过程变化的方法</td>   <td>广东</td>   <td>CN106599088A</td>   <td>2017-04-26</td>   <td>本发明提供一种表征大气重污染过程变化的方法,该方法首先定义出表征大气污染变化的指标体系、单位尺度、等级划分标准等衡量标准；其次,依据以上标准,提出大气重污染过程的定位方法,在重污染过程中提取具体变化特征、以及天气影响要素特征等信息；最后,建立所需基础底表框架,并在此框架之下,将提取到的信息进行描述标示,实现重污染变化过程的描述。</td>   <td>一种表征大气重污染过程变化的方法,其特征在于,包括以下步骤：S1：定义表征大气污染变化的指标体系、单位尺度、以及等级划分标准；S2：根据S1中所定义的标准,在时间序列中提取重污染过程；S3：提取描述重污染过程的特征及天气影响信息；S4：建立图示所需要的基础底表框架,依据S3中所得信息及基础底表框架实现大气重污染变化过程的描述。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李锋;                   蔡铭       </td>   <td>广东技术师范学院;中山大学</td>   <td>一种信号控制路口交通噪声概率预测方法</td>   <td>广东</td>   <td>CN106570238A</td>   <td>2017-04-19</td>   <td>本发明提出一种基于蒙特卡罗模拟的信号控制路口交通噪声概率预测方法,适用于对行人过街信号控制路口交通噪声的动态模拟计算。计算过程为：先用信号控制路口交通流蒙特卡罗模拟器模拟得到一系列任意时间点道路上的车辆数、车辆类型、位置和速度几个参数构成的数据集,然后将这些数据输入车辆噪声排放概率模型,得到车辆噪声源强及位置数据集,最后结合噪声传播衰减计算模型得到一系列接收点处的噪声值,从而统计得出噪声概率分布。该方法大大简化了交通流模拟的过程,具有建模简单,计算量小,模拟计算结果准确可靠的优点。</td>   <td>一种信号控制路口交通噪声概率预测方法,其特征在于,实现过程为：先用信号控制路口交通流蒙特卡罗模拟器模拟得到一系列任意时间点道路上的车辆数、车辆类型、位置和速度几个参数构成的数据集,将这些数据集输入车辆噪声排放概率模型,得到车辆噪声源强及位置数据集,最后结合噪声传播衰减计算模型得到一系列接收点处的噪声值,从而统计得出噪声概率分布；其中所述信号控制路口交通流蒙特卡罗模拟器根据路口交通量、几何参数及交通信号控制方案模拟道路交通流瞬时状态,输出道路上的车辆数、车辆类型、位置和速度几个参数构成的数据集；所述车辆噪声排放概率模型是一个包含不同车型在不同速度范围下的单辆车噪声正态分布模型。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              刘奕志;              骆仲舟;                   邓宇晴       </td>   <td>中山大学中山眼科中心</td>   <td>一种对睑板腺图像进行处理以获得腺体参数的信息的方法</td>   <td>广东</td>   <td>CN106530294A</td>   <td>2017-03-22</td>   <td>本发明提出一种对睑板腺图像进行处理以获得腺体的信息的方法,包括以下步骤：获取睑板腺图像,手动勾画出睑板腺图像中腺体的区域和睑板腺的区域；通过图像Convolution#Highlight#Detail算子增强腺体的轮廓,区分腺体和眼睑；通过图像Threshold算子调整参数值,提取出腺体；通过morphology算子进一步区分腺体,使每一条腺体都能清楚地分割,计算中央腺体的面积；手动勾画中央腺体的长度,自动计算腺体的平均长度,从而获得腺体的信息。采用该方法能够对睑板腺图片进行量化分析,准确计算缺失百分比,中央腺体均值等信息。同时该方法能准确区分每条腺体,为使用者提供精确的数据,进一步为MGD临床诊断提供科学的依据。</td>   <td>一种对睑板腺图像进行处理以获得腺体的信息的方法,其特征在于,主要包括以下步骤：S1、获取睑板腺图像,手动勾画出睑板腺图像中腺体的区域和睑板腺的区域；S2、通过图像Convolution#Highlight#Detail算子增强腺体的轮廓,区分腺体和眼睑；S3、通过图像Threshold算子调整参数值,提取出腺体；S4、通过morphology算子进一步区分腺体,使每一条腺体都能清楚地分割,计算中央腺体的面积；S5、手动勾画中央腺体的长度,自动计算腺体的平均长度,从而获得腺体的信息。</td>   <td>G06T7/00;G06T7/62;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙鹏;              王若梅;                   邓代国       </td>   <td>中山大学</td>   <td>一种基于无监督机器学习的织物平整度客评定方法及装置</td>   <td>广东</td>   <td>CN106529544A</td>   <td>2017-03-22</td>   <td>本发明实施例公开了一种基于无监督机器学习的织物平整度客评定方法及装置,其中,该方法包括：在标准评定环境下采集样品数据；对采集得到的样品数据进行预处理,去除图像的背景和干扰信息；利用计算机图像处理技术对预处理后的数据进行矢量化；对矢量化得到的数据进行归类,生成特征参照集；对特征参照集进行图像类别预测,获得评定结果。在本发明实施例中,通过底层特征的提取、抽象,矢量化织物图像,根据织物图像的特征进行聚类,对聚类的结果设置标签。通过统一的底层特征提和抽象,客观的参照类划分,进行织物评级预测,更加公正客观地获得评定结果,减小了由于人工采取用来训练的数据时引起的误差,并且避免了由于人工评定带来的主观误差。</td>   <td>一种基于无监督机器学习的织物平整度客评定方法,其特征在于,所述方法包括：在标准评定环境下采集样品数据；对采集得到的样品数据进行预处理,去除图像的背景和干扰信息；利用计算机图像处理技术对预处理后的数据进行矢量化；对矢量化得到的数据进行归类,生成特征参照集；利用SVM对特征参照集进行图像类别预测,获得评定结果。</td>   <td>G06K9/40;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              袁敏贤;              江倩殷;              罗东华;              吕硕;                   陈锐祥       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种基于深度学习的车辆品牌型号精细识别方法与系统</td>   <td>广东</td>   <td>CN106529578A</td>   <td>2017-03-22</td>   <td>本发明公开了一种基于深度学习的车辆品牌型号精细识别方法与系统,方法包括：获取原始车辆图像；对原始车辆图像进行空间金字塔划分,将原始车辆图像划分为三个层次共21个图像块,所述三个层次中图像块的数量分别是1、4以及16个；采用改进的卷积神经网络对划分后的各个图像块进行特征提取,得到各个图像块的特征向量,所述改进的卷积神经网络包括卷积层、最大池化层、架构层和平均池化层；根据各个图像块的特征向量采用权值空间金字塔的方法得到车辆图像的最终表达向量；将车辆图像的最终表达向量送入预先训练好的一个多类线性支持向量机分类器中进行车辆品牌型号识别。本发明具有鲁棒性好和识别准确率高的优点,可广泛应用于图像处理领域。</td>   <td>一种基于深度学习的车辆品牌型号精细识别方法,其特征在于：包括以下步骤：获取原始车辆图像；对原始车辆图像进行空间金字塔划分,将原始车辆图像划分为三个层次共21个图像块,所述三个层次中图像块的数量分别是1、4以及16个；采用改进的卷积神经网络对划分后的各个图像块进行特征提取,得到各个图像块的特征向量,所述改进的卷积神经网络包括卷积层、最大池化层、架构层和平均池化层；根据各个图像块的特征向量采用权值空间金字塔的方法得到车辆图像的最终表达向量；将车辆图像的最终表达向量送入预先训练好的一个多类线性支持向量机分类器中进行车辆品牌型号识别。</td>   <td>G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杜晓荣;              周成城;              余友鹏;                   刘洁       </td>   <td>中山大学</td>   <td>一种帧动画的生成方法</td>   <td>广东</td>   <td>CN106530372A</td>   <td>2017-03-22</td>   <td>本发明公开了一种帧动画生成方法,包括如下步骤：(1)在一张人物或动物图片中按设定顺序抠图指定的身体部位,从而得到各身体部位图片；(2)调整所述身体部位图片以符合人物或动物的自然站立姿势,并将调整后的身体部位图片保存；(3)根据预设文件逐一对各身体部位图片进行平移、旋转的位置调整,最后将各身体部位图片叠加,得到帧动画一帧；(4)重复步骤(3)多次,得到若干帧的帧动画。本发明帧动画生成方法只需提供想要制作的帧动画人物或动物角色静态图片,通过简单的抠图操作就能得到该角色各种各样动作的帧动画。相比于传统手工逐帧制作的帧动画,不仅节省了大量的时间,而且对用户本身的美工、Photoshop技术功底要求也不高,使用门槛很低。</td>   <td>一种帧动画生成方法,其特征在于,包括如下步骤：(1)在一张人物或动物图片中按设定顺序抠图指定的身体部位,从而得到各身体部位图片；(2)调整所述身体部位图片以符合人物或动物的自然站立姿势,并将调整后的身体部位图片保存；(3)根据预设文件逐一对各身体部位图片进行平移、旋转的位置调整,最后将各身体部位图片叠加,得到帧动画一帧；(4)重复步骤(3)多次,得到若干帧的帧动画。</td>   <td>G06T13/00;G06T13/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭军;                   张凯华       </td>   <td>中山大学</td>   <td>一种网络新词识别方法</td>   <td>广东</td>   <td>CN106528523A</td>   <td>2017-03-22</td>   <td>本发明提供的新词识别方法能够对重复串和文章关键词、超链接词、标点符号中间的词这些特殊格式的新词进行识别,因此能够很好地适应于网络新词的特点并将其识别出来,实验证明,本发明提供的新词识别方法能够有效地对网络新词进行识别。</td>   <td>一种网络新词识别方法,其特征在于：包括以下步骤：S1.使用网络蜘蛛对网页进行抓取,然后从抓取的网页中提取文本信息,并对提取文本信息进行预处理；S2.将文本信息中前后被空格隔开的候选新词提取出来,然后执行步骤S3；将文本信息中重复出现的候选新词提取出来,执行步骤S7；S3计算候选新词i的字串长度L,判断L是否大于1小于4,若是执行步骤S4,否则执行步骤S5；S4.判断候选新词i是否已经存储在词典中,若是则将候选新词i过滤掉,否则通过人工校对后将候选新词i添加入词典中；S5.判断候选新词i能否被分词词典切分,若是,则将候选新词i过滤掉,否则通过人工校对后将候选新词i添加入词典中；S6.令i＝i+1,然后执行步骤S3；S7.统计文本信息中候选新词j的左邻接词个数m和右邻接词个数n,判断m、n是否分别大于设定的阈值,若是则执行步骤S8,否则将候选新词j过滤掉；S8.统计候选新词j的构词强度,若构词强度大于所设定的阈值,则在通过人工校对后将候选新词j添加入词典中；否则将候选新词j过滤掉；S9.令j＝j+1然后执行步骤S7。</td>   <td>G06F17/27;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭军;                   张凯华       </td>   <td>中山大学</td>   <td>一种基于MMseg算法与逐点互信息算法的分词方法</td>   <td>广东</td>   <td>CN106528524A</td>   <td>2017-03-22</td>   <td>本发明涉及一种基于MMseg算法与逐点互信息算法的分词方法,基于词典使用MMseg算法对文本进行分词处理,获得分词结果后使用逐点互信息算法对分词结果进行校正；所述逐点互信息算法校正分词结果的具体过程如下：计算文本中相邻的字x与字y的逐点互信息,然后判断字x与字y的逐点互信息是否大于所设定的阈值,若是则将字x与字y作为一个独立的词语进行划分。</td>   <td>一种基于MMseg算法与逐点互信息算法的分词方法,其特征在于：基于词典使用MMseg算法对文本进行分词处理,获得分词结果后使用逐点互信息算法对分词结果进行校正；所述逐点互信息算法校正分词结果的具体过程如下：计算文本中相邻的字x与字y的逐点互信息,然后判断字x与字y的逐点互信息是否大于所设定的阈值,若是则将字x与字y作为一个独立的词语进行划分。</td>   <td>G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭泽颖;              柯戈扬;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司</td>   <td>一种快速的结构化支持向量机文本分类优化算法</td>   <td>广东</td>   <td>CN106528771A</td>   <td>2017-03-22</td>   <td>本发明提供一种快速的结构化支持向量机文本分类优化算法,该算法针对不平衡数据集的文本分类任务,用精确率、召回率、AUC等性能评估方法直接优化大类性能评价指标,该方法不同于大多数传统的文本分类算法：代替学习一个单一规则来预测单个样本的标签,该方法将学习问题形式化为在数据集中的所有样本上的一个多元预测问题,区别于传统方法将降低总体分类错误率为目标的思想,提高在文本数据集不平衡情况下的分类精度,有效提高分类性能；参考基于Structural#SVM的稀疏逼近算法,该方法不仅有较好的时间复杂度,可以用于从精确率、召回率计算出来的评价指标,如F值,以及AUC的优化,降低了时间复杂度并获得了更好的效果。</td>   <td>一种快速的结构化支持向量机文本分类优化算法,其特征在于,包括以下步骤：S1：对结构化支持向量机的目标函数进行扩展得出结构化支持向量机的对偶形式；S2：利用得出的对偶形式通过坐标上升法对结构化支持向量机的目标函数进行优化。</td>   <td>G06F17/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王昌栋;              赖剑煌;                   李玫       </td>   <td>中山大学</td>   <td>一种基于组合学习的群组推荐方法</td>   <td>广东</td>   <td>CN106528584A</td>   <td>2017-03-22</td>   <td>本发明提出一种基于组合学习的群组推荐方法,包括：方式1：基于K最近邻算法获得所有用户的个人推荐列表,挑选出组A成员的推荐列表,将组A成员的推荐列表中根据组合学习的方法得出组A的推荐列表；方式2：将组A内成员的评分列表累加,求平均值得到组A的评分列表,基于K最近邻算法,根据不在组A中成员的评分列表产生组A的推荐列表；方式3：构建组的喜好模型,将每个用户的喜好用特征因子向量表示,根据单个用户的喜好向量得到表示组喜好的特征因子向量,根据此产生组A的推荐列表；基于以上三种方式分别产生组A的三个推荐列表,并基于组合学习的方法组合出一个更准确的推荐列表。</td>   <td>一种基于组合学习的群组推荐方法,其特征在于,包括：方式1：基于K最近邻算法获得所有用户的个人推荐列表,挑选出组A内每个成员的推荐列表,将每个成员的推荐列表根据组合学习的方法得出一个组A的推荐列表；具体过程为：每个推荐列表中物品的排序与它们自身的影响力有关,首先将每个物品的影响力归一化,用0#1之间的数值表示,然后得到每个物品在不同列表中归一化后的影响力组成向量r＝(r<sub>1</sub>…,r<sub>n</sub>),r<sub>j</sub>代表在第j个推荐列表中物品的归一化后的影响力,利用物品的影响力向量得出最终物品在列表中所应占的影响力,并根据每个物品影响力的高低产生一个组合后的推荐列表；方式2：将组A内成员对每个物品的评分累加,取平均值以此代表组A对每个物品的评分,得到组A的评分列表,基于K最近邻算法,根据不在组A中成员的评分列表产生组A的推荐列表；方式3：构建组的喜好模型,将每个用户的喜好用特征因子向量表示,根据单个用户的喜好向量得到表示组喜好的特征因子向量,根据此产生组A的推荐列表；基于以上三种方式分别产生组A的三个推荐列表,并基于组合学习的方法组合出一个更准确的推荐列表,具体过程为：即将同一组中n个项排序的k个列表合并成一个完整列表的问题,合并后的列表最佳的描述了k个列表所代表的信息,具体采用的是排序整合中的鲁棒排序整合算法。</td>   <td>G06F17/30;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              江倩殷;              袁敏贤;              罗东华;                   余志       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种基于特征几何约束的车辆图像快速检索方法与系统</td>   <td>广东</td>   <td>CN106528662A</td>   <td>2017-03-22</td>   <td>本发明公开了一种基于特征几何约束的车辆图像快速检索方法与系统,方法包括：采用卷积神经网络对车辆图像进行定位,所述车辆图像包括查询图片和入库图片；对定位出的图像进行特征提取,得到图像特征；采用层次化聚类和最小哈希的方法对图像特征进行压缩编码,得到车辆图像特征的哈希编码；根据车辆图像的哈希编码采用几何属性保持的可视化短语来进行图像相似度计算,得到快速匹配检索结果；采用方向梯度直方图对快速匹配检索结果进行精确匹配,得到精确匹配检索结果。本发明具有检索精度高和检索速度快的优点,可广泛应用于图像处理领域。</td>   <td>一种基于特征几何约束的车辆图像快速检索方法,其特征在于：包括以下步骤：采用卷积神经网络对车辆图像进行定位,所述车辆图像包括查询图片和入库图片；对定位出的图像进行特征提取,得到图像特征；采用层次化聚类和最小哈希的方法对图像特征进行压缩编码,得到车辆图像特征的哈希编码；根据车辆图像的哈希编码采用几何属性保持的可视化短语来进行图像相似度计算,得到快速匹配检索结果；采用方向梯度直方图对快速匹配检索结果进行精确匹配,得到精确匹配检索结果。</td>   <td>G06F17/30;G06K9/46;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖蔚;                   周晓聪       </td>   <td>中山大学</td>   <td>一种软件易变性预测模型的构建方法</td>   <td>广东</td>   <td>CN106528428A</td>   <td>2017-03-22</td>   <td>本发明提供一种软件易变性预测模型的构建方法,该方法使用相似度来定义软件易变性,符合软件外部属性,如需求、功能变化时,体现在源代码上的变化,使用了目前所能定义的大部分度量,得到的度量信息更为全面,并对这些原始度量使用特征提取与选择的技术,提高了模型的计算性能,减少了因特征过多造成的信息冗余。即能够使用更多的度量信息,又能够避免过多的特征而影响模型性能。</td>   <td>一种软件易变性预测模型的构建方法,其特征在于,包括以下步骤：S1：以面向对象软件系统中的类为研究对象,提取软件源代码的结构信息；S2：通过S1中提取到的源代码结构信息,计算面向对象软件度量,包括规模类度量、耦合度度量、内聚度度量、继承类度量；S3：通过对比在软件演化中不同版本所对应的类的变化情况,通过类相似度来定义并解析出类的易变性信息,该易变性信息包括分类标签；S4：对S2中计算得到的面向对象软件度量,对得到的度量进行分类,分别对各类度量做进一步的特征提取和选择,得到新的特征集合；S5：使用S3中得到的分类标签与S4中得到的特征集合,生成软件易变性预测模型的训练集,使用前馈多层感知器算法训练出预测模型。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         詹宜巨;              吕律;              蔡庆玲;                   唐承佩       </td>   <td>中山大学</td>   <td>一种基于头部姿态的眼睛注视视角测定方法</td>   <td>广东</td>   <td>CN106529409A</td>   <td>2017-03-22</td>   <td>本发明公开了一种基于头部姿态的眼睛注视视角测定方法,其不需添加LED光源,仅采用一个摄像头、一个点激光器和布置在竖向实体标定平面上的标定点,即可完成训练过程,获得脸部模型数据库、三维头部姿态数据库和回归模型,再采用同一个摄像头获得用户在当前时刻的脸部图像,采用训练过程得到的数据通过实时测定过程,即可实时计算出用户的眼睛在当前时刻的眼睛注视视角,因此,本发明能够实现对用户眼睛注视视角进行测定,其对硬件的依赖小,能够有效的扩展眼睛注视视角测定的应用范围。</td>   <td>一种基于头部姿态的眼睛注视视角测定方法,包含训练过程和实时测定过程；所述的训练过程,包括：步骤1#1、原始数据获取步骤,包括：步骤1#1#1,在用户的头上佩戴一个朝向所述用户前方的点激光器(Laser),并在所述用户的前方安放一个摄像头、在所述用户前方的竖向实体标定平面(Wall)上设置多个标定点(Point),其中,所述用户的头部(Head)完全落在所述摄像头的拍摄范围之内,所述用户所在位置距离所述竖向实体标定平面(Wall)的距离、每一个所述标定点(Point)与用户的相对位置以及由所述距离和相对位置决定的用户二维头部姿态均为已知的预设值,该预设的二维头部姿态记为训练用二维头部姿态,所述训练用二维头部姿态以欧拉角表示,包括所述用户头部绕一个三维直角坐标系Y轴转动的Yaw旋转角和绕所述三维直角坐标系Z轴转动的Pitch旋转角,并且,所述用户头部绕所述三维直角坐标系X轴转动的欧拉角为Roll旋转角；步骤1#1#2,令所述用户在所述所在位置通过转动头部,使得所述点激光器(Laser)所发出的激光点分别落在所述各个标定点(Point)上,以用所述摄像头拍摄所述激光点落在每一个所述标定点(Point)时所述用户的脸部图像,并记为训练用脸部图像,其中,所述各个标定点(Point)中包含有正中标定点,当所述激光点落在正中标定点上时,所述激光器(Laser)的指向垂直于所述竖向实体标定平面(Wall),即所述用户头部的Yaw旋转角和Pitch旋转角均为0,将所述摄像头在所述激光点落在正中标定点上时拍摄到的训练用脸部图像记为正中训练用脸部图像；步骤1#2、将每一幅所述训练用脸部图像作为受处理脸部图像按以下步骤1#2#1至步骤1#2#5的方法进行处理,得到所述各幅训练用脸部图像的二维脸部特征,并保存在脸部模型数据库中,其中,所述二维脸部特征包含二维脸部特征像素点、眼部特征像素点、角膜缘特征像素点和瞳孔中心特征像素点；步骤1#2#1、对受处理脸部图像中的人脸进行定位；步骤1#2#2、用主动形状模型基于其默认的参数对所述受处理脸部图像中被定位出的人脸进行处理,得到所述受处理脸部图像中人脸的二维脸部特征像素点的坐标；步骤1#2#3、从所述受处理脸部图像的二维脸部特征像素点中提取出包围所述用户双眼眼部的特征像素点,记为眼部特征像素点,其中,所述用户的每一只眼睛对应有六个所述眼部特征像素点,位于中间位置的四个所述眼部特征像素点根据相互之间的相对位置分别记为左上方特征像素点、右上方特征像素点、右下方特征像素点和左下方特征像素点,其余两个所述眼部特征像素点根据相对位置分别记为内眼角特征像素点和外眼角特征像素点；步骤1#2#4、对所述受处理脸部图像位于所述用户每一只眼睛所对应眼部特征像素点围成区域内的图像区域进行处理,分别定位出所述受处理脸部图像中位于所述用户双眼角膜缘上的特征像素点,记为角膜缘特征像素点；步骤1#2#5、对所述受处理脸部图像的用户每一只眼睛对应的角膜缘特征像素点进行曲线拟合,得到所述受处理脸部图像中用户每一只眼睛对应的角膜缘曲线及该角膜缘曲线的中心像素点,将所述角膜缘曲线的中心像素点记为瞳孔中心特征像素点；步骤1#3、回归模型建立步骤,包括：步骤1#3#1、用所述主动形状模型基于所述脸部模型数据库计算每一所述训练用二维头部姿态所对应的用户头部的Roll旋转角,将所述训练用二维头部姿态及其对应的Roll旋转角记为训练用三维头部姿态,保存在三维头部姿态数据库中；并且,所述主动形状模型在训练过程即计算所述各个二维头部姿态所对应Roll旋转角的过程中自动对其默认的参数进行更新,使得主动形状模型的默认参数向适配于所述摄像头的参数变化,将所述主动形状模型完成所述训练过程后更新得到的参数记为适配参数；其中,在所述训练过程中计算得到的所述正中训练用脸部图像与用户本人的缩放比例记为s'；步骤1#3#2、将每一个所述训练用三维头部姿态及其对应的二维脸部特征作为输入,建立三维头部姿态与二维脸部特征的回归模型,并保存在所述三维头部姿态数据库中；所述的实时测定过程,包括：步骤2#1、用所述摄像头拍摄所述用户在当前时刻的脸部图像,并记为测定用脸部图像,其中,所述用户位于其头部(Head)能够完全落在所述摄像头拍摄范围之内的任意位置；步骤2#2、将所述测定用脸部图像作为受处理脸部图像按所述步骤1#2#1至步骤1#2#5的方法进行处理,并且,按所述步骤1#2#2的方法进行处理时,所述主动形状模型基于所述步骤1#3#1得到的适配参数对受处理脸部图像即所述测定用脸部图像中被定位出的人脸进行处理,得到所述测定用脸部图像的二维脸部特征、所述测定用脸部图像中人脸所对应的三维脸部特征点的坐标和测定用脸部图像与用户本人的缩放比例s,其中,所述二维脸部特征包含二维脸部特征像素点、眼部特征像素点、角膜缘特征像素点和瞳孔中心特征像素点；步骤2#4、将所述测定用脸部图像的二维脸部特征作为步骤1#3#2所建立回归模型的输入,计算出所述测定用脸部图像的三维头部姿态,即所述用户在拍摄该测定用脸部图像时的欧拉角,包括Yaw旋转角、Pitch旋转角和Roll旋转角,记为三维头部姿态欧拉角(φ<sub>Roll</sub>,φ<sub>Yaw</sub>,φ<sub>Pitch</sub>)；步骤2#5、用户的眼睛注视视角实时计算步骤,包括：步骤2#5#1、建立眼部模型,即：将所述用户的一只真实眼球视为一个球体,并将所述真实眼球按照所述步骤2#2得到的缩放比例s进行缩放后得到的球体记为图像眼球,其中,所述真实眼球的半径预设为R<sub>0</sub>、眼球中心至外眼角特征点与内眼角特征点所在直线的距离预设为L<sub>0</sub>,所述图像眼球的球心记为o；并且,将所述步骤2#2得到的三维脸部特征点中对应所述图像眼球的外眼角特征点、内眼角特征点和瞳孔中心特征点依次记为e1、e2和p,将所述外眼角特征点e1与内眼角特征点e2的中点记为m,所述球心o在所述外眼角特征点e1与内眼角特征点e2的连线上的垂足记为n；所述球心o与瞳孔中心特征点p之间的距离即为所述图像眼球的半径R,所述球心o到所述垂足n的方向即为所述用户在拍摄所述测定用脸部图像时的头部姿态方向V1,该头部姿态方向V1用欧拉角表示即为所述步骤2#4得到的三维头部姿态欧拉角(φ<sub>Roll</sub>,φ<sub>Yaw</sub>,φ<sub>Pitch</sub>),所述球心o到所述瞳孔中心特征点p的方向即为所述用户在拍摄所述测定用脸部图像时的眼睛注视方向V2,该眼睛注视方向V2用欧拉角表示即为所述用户的眼睛注视视角,记为(ω<sub>Roll</sub>,ω<sub>Yaw</sub>,ω<sub>Pitch</sub>)；步骤2#5#2、以所述测定用脸部图像的二维脸部特征、三维脸部特征点的坐标和三维头部姿态作为所述眼部模型的输入,按以下公式七至公式十一计算出所述用户在当前时刻即拍摄所述测定用脸部图像时的眼睛注视视角(ω<sub>Roll</sub>,ω<sub>Yaw</sub>,ω<sub>Pitch</sub>)：<img file="FDA0001127693830000041.TIF" wi="1713" he="134" /><img file="FDA0001127693830000042.TIF" wi="1704" he="142" /><img file="FDA0001127693830000043.TIF" wi="1702" he="223" /><img file="FDA0001127693830000044.TIF" wi="1694" he="95" /><img file="FDA0001127693830000045.TIF" wi="1686" he="159" />式中,L为所述球心o与垂足n之间的距离,T为所述中点m与垂足n之间的距离,s'为所述正中训练用脸部图像与用户本人的缩放比例,(p<sub>x</sub>,p<sub>y</sub>,p<sub>z</sub>)、(e1<sub>x</sub>,e1<sub>y</sub>,e1<sub>z</sub>)和(e2<sub>x</sub>,e2<sub>y</sub>,e2<sub>z</sub>)依次为所述步骤2#2得到的三维脸部特征点中对应所述图像眼球的瞳孔中心特征点p、外眼角特征点e1和内眼角特征点e2的坐标,(m<sub>x</sub>,m<sub>y</sub>,m<sub>z</sub>)为所述中点m的坐标,(o<sub>x</sub>,o<sub>y</sub>,o<sub>z</sub>)为所述球心o的坐标。</td>   <td>G06K9/00;A61B3/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              吕硕;              江倩殷;              罗东华;              袁敏贤;                   余志       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种基于选择性搜索算法的车标检测识别方法及系统</td>   <td>广东</td>   <td>CN106529424A</td>   <td>2017-03-22</td>   <td>本发明公开了一种基于选择性搜索算法的车标检测识别方法及系统,方法包括：对原始车辆图像进行车牌定位,获取车牌位置；根据车牌位置、车牌与车标空间位置关系和车窗边缘信息在原始车辆图像中对车标进行粗定位,得到车标粗定位图像；基于车辆中轴线在车标粗定位图像中选取车标候选区；采用选择性搜索算法对车标候选区进行目标定位,得到定位目标集；采用线性约束编码算法训练车标判断分类器来对定位目标集进行车标的判别,得到车标的位置；采用线性约束编码算法训练多类车标识别分类器来对车标进行具体的类型识别,得到车标识别结果。本发明具有适用性广、鲁棒性强和检测速度快的优点,可广泛应用于图像处理领域。</td>   <td>一种基于选择性搜索算法的车标检测识别方法,其特征在于：包括以下步骤：对原始车辆图像进行车牌定位,获取车牌位置；根据车牌位置、车牌与车标空间位置关系和车窗边缘信息在原始车辆图像中对车标进行粗定位,得到车标粗定位图像；基于车辆中轴线在车标粗定位图像中选取车标候选区；采用选择性搜索算法对车标候选区进行目标定位,得到定位目标集,所述选择性搜索算法综合根据颜色相似度、纹理相似度、大小相似度和吻合度相似度来进行区域合并；采用线性约束编码算法训练车标判断分类器来对定位目标集进行车标的判别,得到车标的位置；采用线性约束编码算法训练多类车标识别分类器来对车标进行具体的类型识别,得到车标识别结果。</td>   <td>G06K9/00;G06K9/32;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         衣杨;              程阳;              许楚萍;              兰天翔;                   王昭       </td>   <td>中山大学</td>   <td>基于显著轨迹和时空演化信息的视频人体行为识别方法</td>   <td>广东</td>   <td>CN106529477A</td>   <td>2017-03-22</td>   <td>本发明提供一种基于显著轨迹和时空演化信息的视频人体行为识别方法,该方法充分利用视频中的光流信息,在改进密集轨迹的基础上,通过定义轨迹的静态显著性和动态显著性,并以线性融合方式,计算得到轨迹的组合显著性,从而有效移除背景运动轨迹,提取前景运动轨迹；针对传统基于底层视觉特征表示方法忽略了行为视频中丰富的中高层语义信息问题,提出中层视觉特征表示即轨迹束,从中提取人体行为时空演化信息作为视频特征表示,有效去除背景轨迹,提取前景运动轨迹并显著提高算法的识别效果。</td>   <td>一种基于显著轨迹和时空演化信息的视频人体行为识别方法,其特征在于,包括以下步骤：S1：对每一帧视频图像进行人体检测并构建多尺度时空金字塔,再对视频帧中的时空兴趣点密集采样,并判断时空兴趣点所在后续帧的位置,将其加入到轨迹序列中,采用中心点#外围显著性方法计算视频帧的静态显著性和动态显著性,并通过线性融合方式得到视频帧的组合显著性；S2：将轨迹显著性定义为轨迹每点在组合显著性图像中显著性的均值,计算显著性阈值,当轨迹显著性小于该阈值时,则认为是背景轨迹而予以删除,从而有效提取前景运动轨迹；S3：采用最大似然估计算法建立高斯混合模型,对于每一视频帧序列,利用提取到的前景运动轨迹,生成中层视觉特征表示即轨迹束；S4：根据视频中所有的特征表示轨迹束,利用大数据线性分类模型,求解分类超平面,提取其中的运动时空演化信息作为视频特征表示。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              黄登;              朱雄泳;              陈荣军;                   李智文       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>一种图像增强方法</td>   <td>广东</td>   <td>CN106530237A</td>   <td>2017-03-22</td>   <td>本发明涉及图像处理领域,更具体地,涉及一种图像增强方法。其具体步骤包括：a)对输入图像进行去噪处理得到去噪图像；b)对去噪图像进行边缘提取得到边缘图像；c)对边缘图像进行图像增强处理得到去噪且边缘增强的图像；d)利用亮度可控的直方图均衡方法对去噪图像进行处理得到全局增强图像；e)对c和d步骤所得到的图像进行线性叠加,得到最终的输出图像。本发明通过亮度可控的直方图均衡方法结合UM(Unsharp#Masking,反锐化掩膜)算法思想,可以实现输出亮度可以跟进用户需求自动调节,而且通过设定合适的亮度值可以得到一幅对比度明显提升全局增强的输出图像,从而达到图像增强的目的。</td>   <td>一种图像增强方法,其特征在于,包括如下步骤：a)对输入图像进行去噪处理得到去噪图像；b)对去噪图像进行边缘提取得到边缘图像；c)对边缘图像进行图像增强处理得到去噪且边缘增强的图像；d)利用亮度可控的直方图均衡方法对去噪图像进行处理得到全局增强图像；e)对c和d步骤所得到的图像进行线性叠加,得到最终的输出图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王钢;              王杰;              李健;              范冰丰;              马学进;                   陈梓敏       </td>   <td>佛山市中山大学研究院;中山大学</td>   <td>一种MOCVD反应腔石墨盘均匀加热工艺参数的优化方法</td>   <td>广东</td>   <td>CN106503297A</td>   <td>2017-03-15</td>   <td>本发明涉及一种MOCVD反应腔石墨盘均匀加热工艺参数的优化方法,将计算机和传热学知识结合起来,对MOCVD反应腔中加热情况进行模拟,利用神经网络构建数学模型,再利用遗传算法进行寻优,找出石墨盘表面温度最均匀时的加热电流,从而有利于薄膜均匀沉积,提高薄膜生长质量。</td>   <td>一种MOCVD反应腔石墨盘均匀加热工艺参数的优化方法,其特征在于：a、在MOCVD反应腔中,利用加热片对石墨盘进行加热,通过控制加热片内圈、中圈和外圈的电流大小来进行若干组实验,加热完成后测量石墨盘表面若干个取样点的温度,得到若干组实验测量温度；b、根据MOCVD加热设备结构构建CFD数值模拟模型,利用上述加热片内圈、中圈和外圈的电流大小进行数值模拟计算,并对上述取样点进行监测,得到若干组模拟温度；c、实验测量温度和数值模拟温度对比,对其数值大小和变化趋势对比拟合,验证数值模拟的正确性；d、进行实验设计,控制加热片内圈、中圈和外圈输入电流的大小,随机选取若干组初始值进行数值模拟,相应的得到若干组石墨盘表面温度结果；e、利用上述若干组电流输入和石墨盘表面温度输出构建神经网络数学模型,得到输入和输出之间的对应关系；f、利用遗传算法对上述得到的神经网络数学模型进行优化,找出输出结果最均匀情况下的输入,得到优化结果。</td>   <td>G06F17/50;G06N3/02;C23C16/46;C23C16/52</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;                   付利青       </td>   <td>中山大学</td>   <td>一种基于区块链的公平合同签署方法</td>   <td>广东</td>   <td>CN106504008A</td>   <td>2017-03-15</td>   <td>本发明涉及一种基于区块链的公平合同签署方法,该方法涉及Alice和Bob两个用户实体和区块链系统。其步骤包括：1)Alice和Bob分别生成各自的有效合同认可条款PA<sub>A</sub>和PA<sub>B</sub>；2)Alice和Bob交换各自的有效合同认可条款PA<sub>A</sub>和PA<sub>B</sub>、各自对有效合同认可条款的签名以及各自从区块链系统读取的区块高度BH<sub>A</sub>和BH<sub>B</sub>；3)Alice和Bob交换各自生成的随机数和数字签名,并根据区块链系统和对方的有效合同认可条款验证是否生成了有效的合同,如果无效需要从步骤2)重新执行,否则结束。本发明不需要可信第三方、无需对区块链系统进行任何扩展,能够公平的完成双方的合同签署,解决了背景技术中需要签署合同的可信第三方、或者达不到公平性要求、或者需要修改区块链系统的问题。</td>   <td>一种基于区块链的公平合同签署方法,包括Alice和Bob两个用户实体以及一个区块链系统,特征在于包括以下三个步骤：S1)Alice和Bob分别生成各自的有效合同认可条款PA<sub>A</sub>和PA<sub>B</sub>；S2)Alice和Bob交换各自的有效合同认可条款PA<sub>A</sub>和PA<sub>B</sub>、各自对有效合同认可条款的签名以及各自从区块链系统读取的区块高度BH<sub>A</sub>和BH<sub>B</sub>；S3)Alice和Bob交换各自生成的随机数和数字签名,并根据区块链系统和对方的有效合同认可条款验证是否生成了有效的合同,若合同无效则从步骤S2)重新开始执行,若合同有效则完成合同签署。</td>   <td>G06Q30/00;G06Q50/18;G06F21/62;H04L9/32</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              白大伟;              吴江旭;                   梁津铨       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种基于时序的RFID主动防冲突方法</td>   <td>广东</td>   <td>CN106503600A</td>   <td>2017-03-15</td>   <td>本发明提供一种基于时序的RFID主动防冲突方法,该方法采用RFID卡自动发送方式,RFID读写器在成功接收到一个RFID卡的响应命令ATQC后,可以选择发送WTRD命令,使所有卡片进入Ready状态,停止其他卡片的发送,然后选中刚才接到响应命令ATQC代表的那张RFID卡进行操作,也可以不发送WTRD命令,继续接收卡片数据,完成对射频场内所有卡的寻卡；在RFID读写器读多张RFID卡时RFID读写器只存储有效的ATQC,而且RFID读写器在发送读卡REQC命令后,在接收到有效的相应命令ATQC前都不需要再发送命令了,节约了发送命令的时间,同时也节约了发送和接收的数据量节约了存储空间。</td>   <td>一种基于时序的RFID主动防冲突方法,其特征在于,包括以下步骤：S1：RFID读写器向其射频范围内的若干RFID卡发送读卡命令REQC,其中读卡命令REQC包括RFID卡片类型AFI、槽数N；S2：RFID卡接收到读卡命令REQC后判断其中的卡片类型AFI与自身是否相同,若相同,就判断读卡命令REQC中的槽数N的值,当判断出的槽数N的值为1时,RFID卡向RFID读写器发送响应命令ATQC,当判断出的槽数N的值不为1时,RFID卡在槽数N规定的取值范围内产生随机数M,其中,在接到下一个读卡命令REQC命令前,槽数N的值不变；S3：RFID卡判断是否接收到数据,若没有接收到数据,比较随机数M是否等于I,若M不等于I,RFID卡重新判断是否接收到数据；若M等于I,RFID卡向RFID读写器发送响应命令ATQC,其中,I为RFID卡上的计数器,每与随机数M对比一次I会加1,I的初始值为0；若接收到数据,RFID卡判断接收到的数据是读写器发送的命令还是其他RFID卡发送的命令,若为读写器发送的命令则执行该命令,若为其他RFID卡发送的命令,则等待TD时间后,RFID卡重新判断是否接收到数据,其中,响应响应命令ATQC中包括RFID卡的序列号PUPI；S4：RFID读写器接收响应命令ATQC,同时判断是否发生冲突,若发生冲突,将RFID读写器中CT位置1；若未发生冲突,则RFID读写器接收完整的响应命令ATQC；S5：RFID读写器再向其射频范围内的若干RFID发送选卡命令ATTRIC并选中与选卡命令ATTRIC中的序列号PUPI相同的RFID卡,被选中的RFID卡再完成选卡命令ATTRIC后,向RFID读写器发送响应命令REQRIC,RFID读写器接到响应命令REQRIC后,表示卡片已经完成选卡命令ATTRIC规定的操作,此时RFID读写器对该RFID卡发送停止命令HLTC,使该RFID卡进入停止状态。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              邹兵兵;              朱雄泳;              陈荣军;              李智文;                   黄登       </td>   <td>中山大学;中山大学花都产业科技研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>基于PatchMatch和秩最小化算法合成高动态图像的方法</td>   <td>广东</td>   <td>CN106504198A</td>   <td>2017-03-15</td>   <td>本发明公开了一种基于PatchMatch和秩最小化算法合成高动态图像的方法,首先,归一化输入图像集,对图像集使用PatchMatch算法实现图像配准；接着,对配准后的图像集使用伽马曲线对图像集进行辐射校准,然后使用秩最小化算法得到批量的对齐图像；最后,将对齐图像集合成得到目标的高动态(high#dynamic#range,HDR)图像。本发明利用秩最小化和PatchMatch算法的最新研究成果,能够得到有效去除融合后的HDR图像中的伪影和模糊问题。</td>   <td>一种基于PatchMatch和秩最小化算法合成高动态图像的方法,其特征在于,它包括：a)对输入图像集进行归一化处理,并使用PatchMatch算法实现图像配准；b)对配准后的图像集使用秩最小化算法得到批量的对齐图像；c)将对齐图像集进行合成得到目标高动态(high#dynamic#range,HDR)图像。</td>   <td>G06T5/00;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈叶彤;              汪静;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司;广东东软学院</td>   <td>一种基于典型度和信任网络的协同过滤推荐方法</td>   <td>广东</td>   <td>CN106484876A</td>   <td>2017-03-08</td>   <td>本发明提供一种基于典型度和信任网络的协同过滤推荐方法,该方法使用稠密的用户典型度矩阵和项目典型度矩阵代替原有稀疏的评分矩阵,并融合用户间的信任网络对传统协同过滤推荐算法的改进。通过使用项目在项目集中的典型度矩阵和用户在喜爱某类项目集的用户集上的典型度矩阵,缓解传统协同过滤推荐算法中由于用户评分数据数量少的稀疏性问题,融合用户信任网络进一步提高推荐精度,同时实现数据降维。推荐结果能够充分融合用户的社会信任关系对相似用户兴趣的影响。</td>   <td>一种基于典型度和信任网络的协同过滤推荐方法,其特征在于,包括以下步骤：S1：获取用户对项目的历史评分数据,项目的特征信息数据；S2：将每个项目的内容标签表示成文本向量的形式,设定隐含主题数目K,使用LDA主题模型对项目聚类产生项目集主题分布θ和主题#词分布Φ；S3：利用项目的项目#主题分布和主题词分布,计算项目在项目集中的典型度,构建项目#项目集典型度矩阵；利用用户对项目的评分数据,计算用户在某类主题对应的喜欢该类主题的用户集中的典型度,构建用户#用户集典型度矩阵；S4：对于用户Ui,使用阈值过滤算法计算用户见的相似度距离,构建最近邻居矩阵；S5：根据用户Ui的邻居对项目的评分,计算Ui所有近邻的信任度,构建用户Ui近邻的信任度矩阵；S6：利用典型度矩阵代替传统的评分矩阵,融合信任度的加权平均计算评分预测,根据评分预测产生推荐列表。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              梁宁;              刘镇;              陆仪启;              苏定立;                   杜子纯       </td>   <td>中山大学</td>   <td>一种基于非线性拟合控制的地质剖面图在线生成方法</td>   <td>广东</td>   <td>CN106484943A</td>   <td>2017-03-08</td>   <td>本发明提供一种基于非线性拟合控制地质剖面图的在线生成方法,可研究地下沿一定深度各土层的分布情况。通过编写网络脚本语言实现复杂地层的规范化处理,针对地层中出现的尖灭、倒转、缺失等地形,将钻孔地层编号进行重新编排、组合,添加虚拟编号,从而形成新的编号矩阵作为地层边界连线的依据。同时,基于三次贝塞尔曲线拟合进行地层边界的光滑连接。本发明能在网络平台上显示钻孔业务图层,并能实时调取存储于数据库的钻孔信息,用户可在线随机拾取钻孔点即可完成地质部面图的绘制,整个过程操作简捷、方便,成图效果好。</td>   <td>一种基于非线性拟合控制的地质剖面图在线生成方法,主要包括以下五个特征：基于GIS平台,将钻孔数据以GIS矢量数据形式发布为网络服务,区域化生成钻孔业务图层显示在网络前端页面,同时将图层赋于不同的属性与ID,用于钻孔数据的搜索与调取,方便系统直接录入数据,无需依靠其他制图软件,可在线独立完成整个绘制过程,实现钻孔图元的调出并与后台数据形成关联,能够为用户提供钻孔选取的操作界面；根据GIS平台发布的钻孔点,由后台建立数据库与各钻孔点相对应,将钻孔详细信息预先进行数据的录入、存储,以ID号区分不同钻孔,以不同字段识别钻孔分类信息,构造前后台联动机制,系统通过ID与字段匹配对应信息,智能化实时调取钻孔数据,方便数据的管理与更新,可实现数据的自主提取,直接导出到网络前端,为图件的绘制提供数据来源；用户在网络前端选取钻孔点后,系统即时以钻孔ID返回数据库的进行数据搜索,自动识别选取钻孔的信息与数据提取,能对钻孔的不同数据分类存储于矩阵,并对不同矩阵进行下一步处理,重新组装为可直接应用于绘图的数据矩阵,其运行速度快,计算效率高,精确度能够得到保障,实现不同类型的规范化存储,在后续的进一步处理中,能够明确、快速得到需要的数据；根据存储到的分类矩阵,以地层编号矩阵作为导向,依次对各个钻孔的地层编号逐层追踪与识别,两邻钻孔间对应地层编号若不相同,对地层编号做后处理,添加虚拟地层编号与高程,重新组装到原矩阵。经过多次反复的循环操作,使相邻两钻孔地层的编号、高程矩阵完全一致,能够解决尖灭、倒转、缺失等复杂地形,有效模拟实际地层；提取最终的地层编号、高程矩阵,通过调取三次贝塞尔参数方程,将地层边界从左往右、自上而下依次实现相同地层边界的无缝光滑连接。各地层层次分明,能直观看出地层的排序、高度、岩性等信息。</td>   <td>G06F17/50;G06T17/05</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              廖文苑;                   陈泳钊       </td>   <td>中山大学</td>   <td>基于交通运行数据和劣化率的轻型汽车排放速率计算方法</td>   <td>广东</td>   <td>CN106446398A</td>   <td>2017-02-22</td>   <td>本发明提供一种基于交通运行数据和劣化率的轻型汽车排放速率计算方法,该方法通过以VSP#v所定义的运行模式作为排放表征参数来建立了机动车MOVES排放模型,之后对MOVES排放模型进行多次输入输出测试得到中国的轻型汽油车的基础排放速率库；然后再对轻型汽油车进行劣化规律分析,建立车龄与污染物浓度的拟合方程,计算轻型汽油车的劣化率；最后利用机动车劣化规律中所得结论,对建立的轻型汽油车的基础排放速率库进行校准与修正得到修正后的排放速率,该方法对优化道路运行工况、降低机动车排放量、提高城市空气质量具有重要的意义,对我国机动车污染控制措施的制定与实施也具有一定的借鉴意义。</td>   <td>一种基于交通运行数据和劣化率的轻型汽车排放速率计算方法,其特征在于,包括以下步骤：S1：以VSP#v所定义的运行模式作为排放表征参数来建立MOVES排放模型,对MOVES排放模型进行多次输入输出测试得到轻型汽油车的基础排放速率库；S2：对轻型汽油车进行劣化规律分析,建立车龄与污染物浓度的拟合方程,计算轻型汽油车的劣化率；S3：利用机动车劣化规律中所得结论,对建立的轻型汽油车的基础排放速率库进行校准与修正得到修正后的排放速率。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄敏婕;                   张东       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种中餐食物图像特征提取方法</td>   <td>广东</td>   <td>CN106446909A</td>   <td>2017-02-22</td>   <td>本发明公开了一种中餐食物图像特征提取方法,涉及图像处理领域。所述方法包括步骤：(1)将中餐食物图像等距离截取若干图像小块；(2)对前述图像小块提取其颜色特征和纹理特征,得到每一个小块的局部描述符,记为y<sub>i</sub>；(3)将得到的训练数据集的所有图像的所有局部描述符通过利用KSVD算法学习得到一个过完备的稀疏字典D；(4)利用OMP算法根据上一步得到的稀疏字典的原子来线性表示上述步骤得到的每一个图像小块的局部描述符x<sub>i</sub>,其中y<sub>i</sub>≈Dx<sub>i</sub>；(5)得到所有图像的局部描述符后,再对每一张图的所有局部描述符统计其使用稀疏字典的每一个原子的频率,得到一个直方图,这个直方图就是图像的全局描述符,也就是图像的特征。此种提取方法可提高食物识别的准确率。</td>   <td>一种中餐食物图像特征提取方法,其特征在于,包括如下步骤：训练阶段：(1)获取训练数据集,并将其中的中餐食物图像等距离截取为若干图像小块；(2)提取所述图像小块的颜色特征和纹理特征,得到每一个图像小块的局部描述符,记为y<sub>i</sub>；(3)基于训练数据集的所有中餐食物图像的所有局部描述符,学习得到一个过完备的稀疏字典D；(4)利用OMP算法根据上一步得到的稀疏字典的原子来线性表示；上述步骤得到的每一个图像小块的局部描述符x<sub>i</sub>,其中y<sub>i#</sub>≈Dx<sub>i</sub>；(5)得到所有中餐食物图像的局部描述符后,再对每一张中餐食物图像的所有局部描述符统计其使用稀疏字典的每一个原子的频率,得到一个直方图,这个直方图就是中餐食物图像的全局描述符,也就是图像的特征；测试阶段：采用上述方法对测试图像提取局部特征,并利用训练图像生成的稀疏字典去表示测试图像的局部描述符,从而得到测试集图像的稀疏的局部描述符,再利用同样的方法得到全局描述符。</td>   <td>G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              黄春振;              杨亚涛;                   吴嘉婧       </td>   <td>中山大学</td>   <td>一种基于部分堆栈融合的用户信用评估模型</td>   <td>广东</td>   <td>CN106447489A</td>   <td>2017-02-22</td>   <td>本发明涉及一种基于部分堆栈融合的用户信用评估模型,包括：S1、对所有的用户数据建立N个模型,在所有模型中,选择AUROC值最高的一个最优模型〖Model〗<sub>b</sub>est；S2、选择一个与最优模型差异性最大的模型〖Model〗<sub>d</sub>iffer,根据两个模型对所有用户的排名作差值〖Rank〗<sub>b</sub>est#〖Rank〗<sub>d</sub>iffer,对于差值大于0的用户,说明〖Model〗<sub>d</sub>iffer比〖Model〗<sub>b</sub>est对这部分用户的排名能力要好；S3、选择这样的部分用户,用差异性模型重新训练,将这个模型的Top#K个用户直接置为信用良好的用户,这样可以将原本〖Model〗<sub>b</sub>est判别为信用较差的用户进行校正。</td>   <td>一种基于部分堆栈融合的用户信用评估模型,其特征在于包括以下步骤：S1、对所有的用户数据建立N个模型,在所有模型中,选择AUROC值最高的一个最优模型〖Model〗_best；S2、选择一个与最优模型差异性最大的模型〖Model〗_differ,根据两个模型对所有用户的排名作差值〖Rank〗_best#〖Rank〗_differ,对于差值大于0的用户,说明〖Model〗_differ比〖Model〗_best对这部分用户的排名能力要好；S3、选择这样的部分用户,用差异性模型重新训练,将这个模型的Top#K个用户直接置为信用良好的用户,这样可以将原本〖Model〗_best判别为信用较差的用户进行校正。</td>   <td>G06Q40/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾智彬;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司</td>   <td>一种使用Hadoop的极大频繁子图挖掘方法</td>   <td>广东</td>   <td>CN106446161A</td>   <td>2017-02-22</td>   <td>本发明提供一种使用Hadoop的极大频繁子图挖掘方法,该方法通过使用Hadoop来挖掘极大频繁子图,将频繁子树与候选边结合后,通过已保存的中间结果来判断其是否频繁并产生极大频繁子图,而不需要再次遍历数据库,极大频繁子图极大地降低了输出数量,可以在大数据的情况下挖掘极大频繁子图,同时由于生成的候选集只包括频繁子树及其候选边,降低了运行时间。</td>   <td>一种使用Hadoop的极大频繁子图挖掘方法,其特征在于,包括以下步骤：S1：使用两轮MapReduce找出频繁子树及其候选边；S2：使用一轮MapReduce将上述频繁子树及其候选边进行组合,并检验,产生极大频繁子图的候选集；S3：在候选集中找出极大频繁子图。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         路崇;              谭洪舟;              吴华灵;              陆许明;              陈凡;                   李浪兴       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>一种大规模数字集成电路时钟网格分布方法</td>   <td>广东</td>   <td>CN106446366A</td>   <td>2017-02-22</td>   <td>本发明提供一种大规模数字集成电路时钟网格分布方法,该方法将电路划分为若干个物理相邻的时钟域,使每个时钟域与周围四个时钟域相邻；之后在每个时钟域内设置一个延迟可调的延迟补偿单元,并在每两个相邻的时钟域之间设置一个相位检测单元；对各个时钟域之间的相位关系进行探测,得到向量f(N,S,W,E)代表一个时钟域与其四个相邻时钟域的相位关系对比结果,并得到向量g(N,S,W,E)表示时钟域与其相邻其他时钟域之间的相位差在时域上是否大于预先设定的阈值g；利用得到的两个向量通过最小邻域偏斜算法对延迟补偿单元进行调整,使得每两个相邻时钟区域之间的相位差都将小于g就完成电路的网格分布。</td>   <td>一种大规模数字集成电路时钟网格分布方法,其特征在于,包括以下步骤：S1：将电路划分为若干个物理相邻的时钟域,每个时钟域与周围四个时钟域相邻；S2：在每个时钟域内设置一个延迟可调的延迟补偿单元CU,并在每两个相邻的时钟域之间设置一个相位检测单元PDU；S3：对各个时钟域之间的相位关系使用PDU进行探测,并获得相位关系结果,以向量f(N,S,W,E)代表一个时钟域与其四个相邻时钟域的相位关系对比结果；S4：相位检测单元PDU探测时钟域与其相邻其他时钟域之间的相位差在时域上是否大于预先设定的阈值g,以g(N,S,W,E)进行表示；S5：利用向量f(N,S,W,E)和向量g(N,S,W,E)通过最小邻域偏斜算法对延迟补偿单元CU进行调整,使得每两个相邻时钟区域之间的相位差都将小于g就完成电路的网格分布。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   谷扬       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于深度学习的交通图像检索方法</td>   <td>广东</td>   <td>CN106407352A</td>   <td>2017-02-15</td>   <td>本发明在智能交通应用场景下,提出一种基于深度学习的交通图像检索方法,实现深度哈希编码进行交通监控视频图像检索。包括：将目标数据集分为训练集与测试集两部分；通过深度卷积神经网络得到目标类别、颜色的特征以及图像哈希编码；类别、颜色特征的分类损失与哈希编码损失经后向传播优化哈希函数；哈希函数对图像进行哈希编码,计算查询图像与测试数据集中图像的哈希编码之间的汉明距离以表征两者相似程度；根据汉明距离的大小进行相似度得分排序来检索图像。本方法进行图像检索即保留了图像中丰富的多级语义信息又利用了各图像中目标特有的属性信息,通过共享网络结构完成检索与图像属性分类多任务,利用分类任务辅助检索。</td>   <td>一种基于深度学习的交通图像检索方法,其特征在于,包括下述步骤：步骤1：将已经分离好且具有多属性标签的运动目标视频帧数据集分为训练集和测试集两部分；步骤2：把训练集图像输入深度卷积神经网络中,得到目标颜色、类别特征,同时根据哈希编码函数初始参数计算每张图的哈希编码；步骤3：对图像之间的类标进行相似度排序；步骤4：计算目标损失函数,先计算训练集中图像哈希编码之间的汉明距离并进行排序,与类标的相似度排序比较进行检索分支损失函数的计算；该目标损失函数由颜色及类别属性分类任务multihinge#loss与哈希函数学习任务的triplet#loss共同组成,经随机梯度下降法与后向传播改变网络参数以得到深度学习哈希编码函数；步骤5：对于新的查询图像,利用步骤4学习到的哈希编码函数对图像进行哈希编码,计算查询图像与测试集中图像的哈希编码之间的汉明距离,采用该汉明距离表征查询图像与测试集中图像之间的相似程度；步骤6：根据查询图像与测试集中图像的哈希编码之间的汉明距离得到距离的大小序列进行相似度得分排序来得到检索图像列表,根据被检索图像路径所属的视频段得到相应视频的搜索。</td>   <td>G06F17/30;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              杨亚涛;                   黄春振       </td>   <td>中山大学</td>   <td>一种基于多源异构数据的用户信用评估模型</td>   <td>广东</td>   <td>CN106408184A</td>   <td>2017-02-15</td>   <td>本发明涉及一种基于多源异构数据的用户信用评估模型,其包括以下步骤：(1)多源异构数据的获取及合并；(2)用户特征的处理；(3)模型的训练。本发明提出的模型框架在下面特征扩展与选择中,先对用户的数据维度进行扩展,然后再对有用的特征进行选择,从而减低特征的维度,减低模型的时间复杂性；同时在特征处理中对数据缺失与异常的情况进行处理,提供模型对缺失值的鲁棒性。</td>   <td>一种基于多源异构数据的用户信用评估模型,其包括以下步骤：(1)多源异构数据的获取及合并；(2)用户特征的处理；(3)模型的训练。</td>   <td>G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              王海波;                   杨炜俊       </td>   <td>中山大学</td>   <td>一种应用于大区域交通噪声计算的优化方法</td>   <td>广东</td>   <td>CN106407929A</td>   <td>2017-02-15</td>   <td>本发明公开一种应用于大区域交通噪声计算的优化方法,该方法可大大提高城市大区域交通噪声计算算法的效率。具体过程为：首先根据接收点到声源点之间的距离自动选取所需计算的交通源,忽略距离接收点较远的交通源；然后采用智能化自动划分网格的方法,在靠近交通源的地方划分比较密集的计算网格,在远离交通源的地方划分比较稀疏的计算网格；最后通过计算目标快速索引的方式,根据道路节点和建筑物角点自动识别计算区域并智能分区,将计算目标(交通源和建筑物)所在及周围共9个方块作为新的计算区域,并在新区域内进行交通噪声计算。本发明应用于大区域下交通噪声的传播衰减计算,可有效的解决大区域交通噪声计算时间效率过低的问题。</td>   <td>一种应用于大区域交通噪声计算的优化方法,其特征在于,主要包含以下步骤：(a)交通源自动筛选,基于接收点到交通源的距离自动筛选出需要计算的交通源；(b)智能化网格划分,以交通源为中心,在半径r内的计算区域划分密集的计算网格,在半径r外的计算区域划分稀疏的计算网格；(c)计算目标快速索引,根据道路节点和建筑物角点自动识别计算区域并智能分区,将以目标为中心的9方格计算区域作为新的计算区域,并在新的计算区域内进行交通噪声计算；其中所述目标是指交通源或建筑物。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈小辉;              周凡;                   王若梅       </td>   <td>中山大学</td>   <td>一种着装人体热质传递并行仿真方法及其系统</td>   <td>广东</td>   <td>CN106407532A</td>   <td>2017-02-15</td>   <td>本发明实施例公开了一种着装人体热质传递并行仿真方法及其系统,其中,该方法包括：对人体着装组合、外部环境、活动状态参数进行预处理；对人体和服装进行并行物理仿真计算；对并行仿真获取的人体体征参数结果进行可视化呈现。实施本发明实施例,能够通过用户信息的采集,环境信息的采集,活动相关参数的输入以及建立的人体和服装系统的数学模型对热质传递过程进行并行仿真,并将物理仿真得到的人体体征数据进行可视化处理并显示。</td>   <td>一种着装人体热质传递并行仿真方法,其特征在于,所述方法包括：对人体着装组合、外部环境、活动状态参数进行预处理；对人体和服装进行并行物理仿真计算；对并行仿真获取的人体体征参数结果进行可视化呈现。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              郑志恒;                   李阳       </td>   <td>中山大学</td>   <td>一种结合财经新闻的深度学习股市预测方法</td>   <td>广东</td>   <td>CN106384166A</td>   <td>2017-02-08</td>   <td>本发明涉及一种结合财经新闻的深度学习股市预测方法,主要包含如下步骤：S1：针对财经新闻,利用网络爬虫技术,从新浪财经新闻与网易财经新闻中爬取相应股票对应的相关财经信息,存储在本地数据库中,形成财经新闻文档数据库。S2：处理财经新闻信息,进行新闻情绪分析。S3：基于LSTM的RNN深度学习网络。S4：训练特征提取。S5：模型训练以及预测。本发明利用了新闻情绪分析技术,采用了基于LSTM的RNN深度学习预测,同时在本发明中结合了金融市场投资者最常用的技术指标作为特征向量预测,起到了很好的效果。</td>   <td>一种结合财经新闻的深度学习股市预测方法,其特征在于包括以下步骤：S1：针对财经新闻,利用网络爬虫技术,从财经新闻中爬取相应股票对应的相关财经信息,形成财经新闻文档数据库；S2：处理财经新闻信息,进行新闻情绪分析；S3：构建基于LSTM的RNN深度学习网络；S4：训练特征提取；S5：模型训练以及预测。</td>   <td>G06Q10/04;G06Q40/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘凯;              刘洋;              柳林;                   李想       </td>   <td>中山大学</td>   <td>基于Gram#Schmidt的无人机影像与多光谱影像融合方法</td>   <td>广东</td>   <td>CN106384332A</td>   <td>2017-02-08</td>   <td>本发明公开一种基于Gram#Schmidt变换的无人机影像与多光谱影像融合方法。其首先经过影像预处理获得具有相同像元尺寸的多光谱低空间分辨率遥感影像与三波段高空间分辨率无人机可见光影像这两套独立的多波段影像；之后对遥感影像进行多元线性回归、重构和Gram#Schmidt变换获得遥感影像GS成分,同时对无人机影像进行相同的重构和Gram#Schmidt变换得到无人机GS成分；之后对无人机GS成分进行梯度滤波得到纹理信息,并以一定权重叠加至遥感影像第1#4GS成分上；对增强结果进行Gram#Schmidt逆变换并去除冗余信息,即得到最终融合影像。本方法扩展了传统融合方法的单波段全色数据与多光谱影像融合的局限性,增加了融合数据的多样性,并实现了一种兼顾光谱保持性和信息质量的融合方法。</td>   <td>一种基于Gram#Schmidt变换的无人机影像与多光谱影像融合方法,其特征在于,包括：S1、影像预处理,包括影像配准、重采样至相同像元尺寸、相同空间范围裁剪,得到低空间分辨率多光谱遥感影像和相同范围的高空间分辨率三波段无人机光学影像；S2、对低空间分辨率多光谱遥感影像进行多元线性回归,获得模拟无人机影像；S3、对低空间分辨率多光谱遥感影像进行重构,并进行Gram#Schmidt变换得到遥感影像GS成分；S4、对相同范围的高空间分辨率三波段无人机影像进行重构,并进行Gram#Schmidt变换得到无人机影像GS成分；S5、对无人机影像GS成分进行梯度滤波得到纹理信息,并将其以权重w叠加至遥感影像的第1至4个GS成分上得到增强结果；S6、对增强结果进行Gram#Schmidt逆变换并去掉前4个冗余信息波段,即得到融合结果。</td>   <td>G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>              谭军       </td>   <td>中山大学</td>   <td>一种字频文本分类方法</td>   <td>广东</td>   <td>CN106372640A</td>   <td>2017-02-01</td>   <td>本发明提出一种字频文本分类方法,包括以下内容：对输入的文本进行预处理,对于处理后的文本进行汉字分割,形成语料库,去除语料库内的停用词,形成词汇文本矩阵,采用分类器对样本进行训练,计算字频的召回率,计算方式为：<img file="DDA0001084734580000011.TIF" wi="604" he="119" />本发明的分类方法,具有以下特点：字频的效果比词频要好很多,甚至在随机森林(RF),人工神经网络(NNET),已经组合分类器Bagging和Boosting算法中召回率都达到了100％。这证明在商品描述中,字频比词频更具有特征性。</td>   <td>一种字频文本分类方法,其特征在于,包括以下内容：对输入的文本进行预处理,对于处理后的文本进行汉字分割,形成语料库,去除语料库内的停用词,形成词汇文本矩阵,采用分类器对词汇文本矩阵进行训练,计算字频的召回率,计算方式为：<img file="FDA0001084734550000011.TIF" wi="622" he="140" />形成词汇文本矩阵的过程为：在R环境下,使用“tm”包中的TermDocumentMatrix函数形成词汇文本矩阵,词汇文本矩阵是根据向量空间模型建造的；向量空间模型是用一个向量来表示一个文本的信息,使得文本成为特征空间中的一个点,在向量空间模型中文本集合形成一个矩阵,也就是特征空间中点的集合；Word<sub>i</sub>是向量空间模型中的特征项,W<sub>ij</sub>是特征项的权重。对于模型中的特征项权重值,过TF#IDF权重计算法得到；TF#IDF权重计算公式为：<maths num="0001"><math><![CDATA[<mrow><mi>t</mi><mi>f</mi><mi>i</mi><mi>d</mi><mi>f</mi><mrow><mo>(</mo><mrow><msub><mi>t</mi><mi>k</mi></msub><mo>,</mo><msub><mi>d</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo> =</mo><mi>t</mi><mi>f</mi><mrow><mo>(</mo><mrow><msub><mi>t</mi><mi>k</mi></msub><mo>,</mo><msub><mi>d</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo>&CenterDot;</mo><mi>l</mi><mi>o</mi><mi>g</mi><mfrac><mrow><mo>|</mo><msub><mi>T</mi><mi>r</mi></msub><mo>|</mo></mrow><mrow><mo>#</mo><msub><mi>T</mi><mi>r</mi></msub><mrow><mo>(</mo><msub><mi>t</mi><mi>k</mi></msub><mo>)</mo></mrow></mrow></mfrac></mrow>]]></math><img file="FDA0001084734550000012.TIF" wi="883" he="127" /></maths>其中tf(t<sub>k</sub>,d<sub>j</sub>)表示关键词t<sub>k</sub>在文档d<sub>j</sub>中出现的频度；|T<sub>r</sub>|为数据全集中文档的总数,#T<sub>r</sub>(t<sub>k</sub>)为包含关键词t<sub>k</sub>的文档总数；其中<maths num="0002"><math><![CDATA[<mrow><mi>t</mi><mi>f</mi><mrow><mo>(</mo><mrow><msub><mi>t</mi><mi>k</mi></msub><mo>,</mo><msub><mi>d</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo> =</mo><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><mn>1</mn><mo>+</mo><mi>log</mi><mo>#</mo><mrow><mo>(</mo><mrow><msub><mi>t</mi><mi>k</mi></msub><mo>,</mo><msub><mi>d</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></mtd><mtd><mrow><mi>i</mi><mi>f</mi><mo>#</mo><mrow><mo>(</mo><mrow><msub><mi>t</mi><mi>k</mi></msub><mo>,</mo><msub><mi>d</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow><mo>&gt;</mo><mn>0</mn></mrow></mtd></mtr><mtr><mtd><mn>0</mn></mtd><mtd><mrow><mi>o</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>w</mi><mi>i</mi><mi>s</mi><mi>e</mi></mrow></mtd></mtr></mtable></mfenced></mrow>]]></math><img file="FDA0001084734550000013.TIF" wi="1070" he="159" /></maths>#(t<sub>k</sub>,d<sub>j</sub>)表示关键词t<sub>k</sub>在文档d<sub>j</sub>中出现的次数；最后余弦归一化得到最终的权重值：<maths num="0003"><math><![CDATA[<mrow><msub><mi>W</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo> =</mo><mfrac><mrow><mi>t</mi><mi>f</mi><mi>i</mi><mi>d</mi><mi>f</mi><mrow><mo>(</mo><msub><mi>t</mi><mi>k</mi></msub><mo>,</mo><msub><mi>d</mi><mi>j</mi></msub><mo>)</mo></mrow></mrow><msqrt><mrow><msubsup><mi>&Sigma;</mi><mrow><mi>s</mi><mo> =</mo><mn>1</mn></mrow><mrow><mo>|</mo><mi>T</mi><mo>|</mo></mrow></msubsup><mi>t</mi><mi>f</mi><mi>i</mi><mi>d</mi><mi>f</mi><msup><mrow><mo>(</mo><msub><mi>t</mi><mi>s</mi></msub><mo>,</mo><msub><mi>d</mi><mi>j</mi></msub><mo>)</mo></mrow><mn>2</mn></msup></mrow></msqrt></mfrac><mo>.</mo></mrow>]]></math><img file="FDA0001084734550000014.TIF" wi="523" he="149" /></maths></td>   <td>G06K9/34;G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李宇;              蔡彬;              谭洪舟;                   农革       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于遗传算法的高阶数字微分器设计方法</td>   <td>广东</td>   <td>CN106372342A</td>   <td>2017-02-01</td>   <td>本发明公开了一种基于遗传算法的高阶数字微分器设计方法,该方法通过不断进行遗传算法的选择、交叉和变异等操作,在有效频段内最小化误差的平方值,从而求解出对应的线性相位FIR微分器系数。该方法简单易行,鲁棒性强,结果令人满意。</td>   <td>一种基于遗传算法的高阶数字微分器设计方法,其特征在于,包括以下步骤：S1：确定高阶数字微分器的阶数k、长度N以及截止频率ω<sub>p</sub>,高阶数字微分器的期望传递函数为：<maths num="0001"><math><![CDATA[<mrow><mi>D</mi><mrow><mo>(</mo><mi>&omega;</mi><mo>)</mo></mrow><mo> =</mo><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><msup><mrow><mo>(</mo><mfrac><mrow><mi>j</mi><mi>&omega;</mi></mrow><mrow><mn>2</mn><mi>&pi;</mi></mrow></mfrac><mo>)</mo></mrow><mi>k</mi></msup><mo>,</mo></mrow></mtd><mtd><mrow><mn>0</mn><mo>&le;</mo><mi>&omega;</mi><mo>&le;</mo><msub><mi>&omega;</mi><mi>p</mi></msub></mrow></mtd></mtr><mtr><mtd><mrow><mo>-</mo><msup><mrow><mo>&lsqb;</mo><mfrac><mrow><mi>j</mi><mrow><mo>(</mo><mn>2</mn><mi>&pi;</mi><mo>-</mo><mi>&omega;</mi><mo>)</mo></mrow></mrow><mrow><mn>2</mn><mi>&pi;</mi></mrow></mfrac><mo>&rsqb;</mo></mrow><mi>k</mi></msup><mo>,</mo></mrow></mtd><mtd><mrow><mn>2</mn><mi>&pi;</mi><mo>-</mo><msub><mi>&omega;</mi><mi>p</mi></msub><mo>&le;</mo><mi>&omega;</mi><mo>&le;</mo><mn>2</mn><mi>&pi;</mi></mrow></mtd></mtr></mtable></mfenced></mrow>]]></math><img file="FDA0001109524000000011.TIF" wi="1060" he="286" /></maths>其中,k代表高阶数字微分器的阶数,当k为偶数时,为偶数阶数字微分器,当k为奇数时为奇数阶数字微分器；ω<sub>p</sub>为高阶数字微分器需要作用的截至频率；高阶数字微分器的系统函数表示为：<maths num="0002"><math><![CDATA[<mrow><mi>H</mi><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>n</mi><mo> =</mo><mn>0</mn></mrow><mrow><mi>N</mi><mo>-</mo><mn>1</mn></mrow></munderover><mi>h</mi><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow><msup><mi>z</mi><mrow><mo>-</mo><mi>n</mi></mrow></msup></mrow>]]></math><img file="FDA0001109524000000012.TIF" wi="430" he="172" /></maths>其中h(n)为对应的冲击响应；S2：根据k、N的奇偶性选择合适类型的FIR滤波器模型：S3：建立适应度函数表达式；S4：遗传算法初始化,建立初始种群；S5：采用遗传算法获得寻优结果向量B,寻优结果向量B为使适应度函数取最小的B向量；S6：根据向量B计算为微分器系数。</td>   <td>G06F17/50;G06N3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周炳光;                   王若梅       </td>   <td>中山大学</td>   <td>一种基于特征尺寸约束的三维服装变形方法及其系统</td>   <td>广东</td>   <td>CN106372344A</td>   <td>2017-02-01</td>   <td>本发明实施例公开了一种基于特征尺寸约束的三维服装变形方法及其系统,其中,该方法包括：建立服装的特征尺寸约束关系模型；根据所述特征尺寸约束关系模型对所述服装进行基于截面环的三维虚拟服装变形；对所述服装进行基于均值坐标的服装部位约束变形。在本发明实施例中,建立了服装的特征尺寸约束关系模型,对影响服装外形的关键尺寸进行分类,并建立服装细部尺寸和关键尺寸的约束关系,进而对三维虚拟服装进行基于截面环的三维虚拟服装变形,能够直接对已有的三维虚拟服装进行变形,来适应不同尺寸的人体模型的需要,可对不同的人尺寸体模型生成个性化服装。</td>   <td>一种基于特征尺寸约束的三维服装变形方法,其特征在于,所述方法包括：建立服装的特征尺寸约束关系模型；根据所述特征尺寸约束关系模型对所述服装进行基于截面环的三维虚拟服装变形；对所述服装进行基于均值坐标的服装部位约束变形。</td>   <td>G06F17/50;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              何粤;                   李宇       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于变步长NLMS算法的麦克风阵列自适应校准方法</td>   <td>广东</td>   <td>CN106373588A</td>   <td>2017-02-01</td>   <td>本发明提供的方法在每次校准完毕后,均根据校准的结果对校准滤波器的系数进行更新,因此,校准滤波器能够很好地贴合输出信号的特性,因此其校准的准确度与现有技术相比得到了提高,且由于校准滤波器的系数在整个的校准过程中是适应于输出信号的特性进行变化的,在麦克风阵列出现老化或环境变化等因素导致的麦克风阵列的输出特性变化较大的情况下,本发明提供的校准方法也能够很好地适应于这种变化,对输出信号进行有效的校准。同时,在校准的过程中,引入了变步长的NLMS算法对校准滤波器的系数进行调整,变步长NLMS算法对输出信号具有更快的误差收敛速度和更小的失真误差,实现了对校准的优化。</td>   <td>一种基于变步长NLMS算法的麦克风阵列自适应校准方法,其特征在于：包括以下步骤：S1.选取麦克风阵列N路麦克风的第n组输出信号x<sub>0</sub>(n)、x<sub>1</sub>(n)、x<sub>2</sub>(n)、…、x<sub>N#1</sub>(n)作为需校准的信号；S2.选取其中一路麦克风的第n组输出信号x<sub>i</sub>(n)输入至延时滤波器中进行时间延迟补偿,完成补偿后输出信号d(n)作为参考信号；S3.将输出信号x<sub>0</sub>(n)、x<sub>1</sub>(n)、x<sub>2</sub>(n)、…、x<sub>N#1</sub>(n)分别输入至校准滤波器W<sub>0</sub>[n]、校准滤波器W<sub>1</sub>[n]、…、校准滤波器W<sub>N#1</sub>[n]中进行校准,校准滤波器W<sub>0</sub>[n]、校准滤波器W<sub>1</sub>[n]、…、校准滤波器W<sub>N#1</sub>[n]分别输出校准后的输出信号y<sub>0</sub>(n)、y<sub>1</sub>(n)、…、y<sub>N#1</sub>(n)；S4.令校准滤波器W<sub>k</sub>[n]的输出信号y<sub>k</sub>(n)与d(n)相减,得到误差值e<sub>k</sub>(n)；k的初始值为0；S5.根据误差值e<sub>k</sub>(n)的大小对NLMS算法的步长进行调整,然后使用步长调整后的NLMS算法对校准滤波器W<sub>k</sub>[n]的系数进行更新；S6.令k＝k+1,然后重复执行步骤S4～S5,直至k&gt;N#1；S7.令n＝n+1,然后执行步骤S1～S6。</td>   <td>G10L21/0216</td>  </tr>        <tr>   <td>中国专利</td>   <td>         单汇丰;                   陈炬桦       </td>   <td>中山大学</td>   <td>基于细胞自动机和混沌映射的数字图像加密及其解密方法</td>   <td>广东</td>   <td>CN106373082A</td>   <td>2017-02-01</td>   <td>本发明提供一种基于细胞自动机和混沌映射的数字图像加密及其解密方法,加密方法首先利用288位的密钥生成加密算法所需的混沌映射参数和细胞自动机演化规则,然后对原始图像进行三维分解和分块等预处理、利用3D混沌映射对像素位置进行置乱,对待加密的图像块进行交叉异或运算,再利用本发明提出的生成边界的2D二阶细胞自动机对展开的明文块进行迭代加密,混淆像素,反复迭代直至满足迭代需求,最后逆向预处理,将分块后的密文图像组合为一个密文图像。</td>   <td>一种基于细胞自动机和混沌映射的数字图像加密方法,其特征在于,包括以下步骤：S1：产生秘钥来产生3D混沌映射的系数、迭代次数和细胞自动机演化规则；S2：对待加密的图像进行预处理；S3：利用S1中得到的3D混沌映射的系数对预处理后的图像的像素进行像素位置置乱；S4：利用S1中得到的细胞自动机演化规则对像素置乱后的图像的明文块进行迭代加密,反复迭代直至满足迭代需求,最后逆向预处理得到密文图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              刘颜;              陈荣军;              李智文;              朱雄泳;              黄登;              邹兵兵;              嵇志辉;                   谢舜道       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学;中山大学花都产业科技研究院</td>   <td>基于低秩矩阵恢复的多曝光图像去伪影融合方法</td>   <td>广东</td>   <td>CN106373105A</td>   <td>2017-02-01</td>   <td>本发明公开了一种基于低秩矩阵恢复的多曝光图像去伪影融合方法。首先,归一化输入多曝光图像序列；接着,使用相机响应函数对归一化后的图像序列进行辐射校准；然后向量化多曝光图像序列构成低秩矩阵恢复的数据矩阵；使用改进的低秩矩阵恢复算法得到低秩矩阵；从低秩矩阵数据中恢复目标的高动态范围(High#dynamic#range,HDR)图像。本发明利用低秩矩阵恢复的最新研究成果,能够得到有效去除融合后的HDR图像中的伪影和模糊问题。</td>   <td>一种基于低秩矩阵恢复的多曝光图像去伪影融合方法,其特征在于,包括：a)对输入多曝光图像序列进行归一化处理；b)对归一化处理后的多曝光图像序列使用相机响应函数实现辐射校准；c)向量化多曝光图像序列中每一幅辐射校正的图像作为数据矩阵的列向量；d)使用低秩矩阵恢复算法求解数据矩阵的低秩矩阵；e)由低秩矩阵重构出高动态范围图像。</td>   <td>G06T5/00;G06T5/50;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;              徐葎;              麦港林;                   戴戈南       </td>   <td>中山大学</td>   <td>一种含有多层次剪枝策略的位置查询优化方法</td>   <td>广东</td>   <td>CN106372265A</td>   <td>2017-02-01</td>   <td>本发明提出一种含有多层次剪枝策略的位置查询优化方法,包括：S1、获取所有顶点到达最近设施的距离,包括客户顶点和路网顶点；S2、划分路网为区域；S3、计算划分后各区域的上界,按上界从大到小将区域进行排序；S4、依序逐一选择区域进行筛选,如已知的最大效益值大于当前需要筛选的区域上界,结束；否则计算当前区域各边上界,按上界从大到小将边进行排序；S5、依序逐一筛选区域内的边,如当前边的上界小于已知的最大效益值,则,结束该区域的筛选进入下一区域返回S4,否则使用边上的顶点剪枝策略对当前边上的顶点进行筛选,并同步更新最大效益值及其所在位置,然后进入下一条边,返回S5。</td>   <td>一种含有多层次剪枝策略的位置查询优化方法,其特征在于,包括以下步骤：步骤一：获取所有顶点到达最近设施的距离,包括客户顶点和路网顶点；步骤二：划分路网为区域；步骤三：计算划分后各区域的上界,按上界从大到小将区域进行排序；步骤四：依序逐一选择区域进行筛选,如果已知的最大效益值大于当前需要筛选的区域上界,则说明最优位置已经全部找到,结束；否则进入步骤五；步骤五：计算当前区域各边上界,按上界从大到小将边进行排序；步骤六：依序逐一筛选区域内的边,如果当前边的上界小于已知的最大效益值,说明该区域中已没有其他边存在最优位置,结束该区域的筛选进入下一区域返回步骤四,否则进入步骤七；步骤七：使用边上的顶点剪枝策略对当前边上的顶点进行筛选,并同步更新最大效益值及其所在位置。然后进入下一条边,返回步骤六。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈湘萍;              马超;              林谋广;              郑贵锋;                   韩冠亚       </td>   <td>中山大学</td>   <td>一种交互式教育资源预览生成方法及系统</td>   <td>广东</td>   <td>CN106339410A</td>   <td>2017-01-18</td>   <td>本发明实施例公开了一种交互式教育资源预览生成方法及系统,其中,该方法包括：分析交互式教育资源,提取出资源中的可交互元素,生成事件集合,抽取出可交互元素之间的依赖关系；根据事件集合和依赖关系生成操作序列；通过操作序列对资源进行GUI遍历,得到交互操作视频和截图集合；对截图集合进行动画播放来为交互式教育资源提供细节信息的预览；根据事件集合和截图集合中的第一张图片,对交互式教育资源中的可交互区域进行渲染；对截图集合中的截图进行比对,对差异部分进行聚类来提取出交互式教育资源的动态内容,并将动态内容拼接到一张图片中。可以解决对交互式教育资源缺乏预览,与交互式教育资源交互繁琐,检索和理解资源内容耗时的问题。</td>   <td>一种交互式教育资源预览生成方法,其特征在于,所述方法包括：分析交互式教育资源,提取出资源中的可交互元素,生成事件集合,抽取出可交互元素之间的依赖关系；根据事件集合和依赖关系生成操作序列；通过操作序列对资源进行GUI遍历,将模拟用户与资源交互的过程进行保存,得到交互操作视频和截图集合；对截图集合进行动画播放来为交互式教育资源提供细节信息的预览；根据事件集合和截图集合中的第一张图片,对交互式教育资源中的可交互区域进行渲染；对截图集合中的截图进行比对,对差异部分进行聚类来提取出交互式教育资源的动态内容,并将动态内容拼接到一张图片中。</td>   <td>G06F17/30;G09B5/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭倩;              林倞;              万海;                   王青       </td>   <td>中山大学</td>   <td>一种基于人脸识别的ATM机身份验证方法</td>   <td>广东</td>   <td>CN106339673A</td>   <td>2017-01-18</td>   <td>本发明公开一种基于人脸识别的ATM机身份验证方法,包括以下步骤：(1)用户在ATM机上插卡并完成密码输入后,ATM机监控系统从数据库中获取该卡对应的持卡人人脸图像；(2)获取一张实时监控图像,然后对图像进行人脸检测,检测图像中是否有人脸出现；(3)如果未检测出人脸,则提醒用户调整姿势,对准摄像头,返回步骤(2)；如果只检测出一张人脸,则对这张用户人脸和持卡人的人脸进行人脸识别；如果检测出多张人脸,则选择尺寸最大的人脸和持卡人的人脸进行人脸识别；(4)如果用户人脸与持卡人的人脸不匹配,即判断用户和持卡人不是同一人,则触发报警装置报警。</td>   <td>一种基于人脸识别的ATM机身份验证方法,其特征在于,包括以下步骤：(1)用户在ATM机上插卡并完成密码输入后,ATM机监控系统从数据库中获取该卡对应的持卡人人脸图像；(2)获取一张实时监控图像,然后对图像进行人脸检测,检测图像中是否有人脸出现；(3)如果未检测出人脸,则提醒用户调整姿势,对准摄像头,返回步骤(2)；如果只检测出一张人脸,则对这张用户人脸和持卡人的人脸进行人脸识别；如果检测出多张人脸,则选择尺寸最大的人脸和持卡人的人脸进行人脸识别；(4)如果用户人脸与持卡人的人脸不匹配,即判断用户和持卡人不是同一人,则触发报警装置报警。</td>   <td>G06K9/00;G07F19/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭中华;              邓嘉仪;              伍冯杰;              蔡谨民;              魏志伟;              黄帅文;              向光臣;                   杨智       </td>   <td>中山大学南方学院</td>   <td>一种基于人脸识别的广告投放方法及装置</td>   <td>广东</td>   <td>CN106327245A</td>   <td>2017-01-11</td>   <td>本发明公开了一种基于人脸识别的广告投放方法及装置,该方法包括：获取N个摄像头所采集的图像信息,并在图像信息中提取用户的人脸信息；根据人脸信息,获取数据库中存储的用户的人物信息；其中,数据库中存储有若干个用户的人物信息,每个人物信息包括人脸信息、行踪信息和购买意向信息；根据图像信息以及N个摄像头的位置,确定用户当前的位置；根据用户当前的位置、行踪信息和购买意向信息,分析计算用户所需求的店铺类型；根据用户所需求的店铺类型,控制用户当前的位置内各广告投放显示屏播放所述店铺类型所对应的广告。采用本发明实施例,能自动识别人物并自动分析人物需求,从而自动切换适合其观看的广告,提高广告的效益。</td>   <td>一种基于人脸识别的广告投放方法,其特征在于,包括：获取N个摄像头所采集的图像信息,并在所述图像信息中提取用户的人脸信息；根据所述人脸信息,获取数据库中存储的所述用户的人物信息；其中,所述数据库中存储有若干个用户的人物信息,每个人物信息包括人脸信息、行踪信息和购买意向信息；根据所述图像信息以及所述N个摄像头的位置,确定所述用户当前的位置；根据所述用户当前的位置、所述行踪信息和所述购买意向信息,分析计算所述用户所需求的店铺类型；根据所述用户所需求的店铺类型,控制所述用户当前的位置内各广告投放显示屏播放所述店铺类型所对应的广告。</td>   <td>G06Q30/02;G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              李竺珊;                   李宇       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种修正先验信噪比过估计的语音增强方法</td>   <td>广东</td>   <td>CN106328155A</td>   <td>2017-01-11</td>   <td>本发明提供的方法通过对先验信噪比与后验信噪比进行修正或重估,使得先验信噪比与后验信噪比能够克服过估计的问题,从而语音增强方法在实际应用中能够起到很好的效果。</td>   <td>一种修正先验信噪比过估计的语音增强方法,其特征在于：包括以下步骤：S1.将带噪语音信号经过预处理后变换到频域,得到带噪语音信号的频谱分布图；S2.基于带噪语音信号的频谱分布图使用MMSE法对噪声功率谱<img file="FDA0001113580150000011.TIF" wi="170" he="69" />进行估计,其中<img file="FDA0001113580150000012.TIF" wi="174" he="71" />表示噪声信号n(t)的短时帧p的第k个频谱分量；S3.计算后验信噪比：<img file="FDA0001113580150000013.TIF" wi="692" he="155" />其中X(p,k)表示带噪语音信号x(t)的短时帧p的第k个频谱分量；S4.基于后验信噪比SNR<sub>post</sub>(p,k)使用判决引导法来对先验信噪比<img file="FDA0001113580150000014.TIF" wi="296" he="82" />进行估计；S5.对后验信噪比进行重估：<img file="FDA0001113580150000015.TIF" wi="1446" he="165" />其中δ、<img file="FDA0001113580150000016.TIF" wi="50" he="53" />为设定的参数；S6.对先验信噪比<img file="FDA0001113580150000017.TIF" wi="300" he="79" />进行修正：<img file="FDA0001113580150000018.TIF" wi="1508" he="189" />S7.基于重估的后验信噪比<img file="FDA0001113580150000019.TIF" wi="285" he="78" />与修正的先验信噪比<img file="FDA00011135801500000110.TIF" wi="283" he="79" />来计算频谱增益G<sub>MMSE</sub>(p,k)S8.将频谱增益作用于带噪语音信号,则得到增强语音信号<img file="FDA00011135801500000111.TIF" wi="170" he="85" /><maths num="0001"><math><![CDATA[<mrow><mo>|</mo><mover><mi>S</mi><mo>^</mo></mover><mrow><mo>(</mo><mi>p</mi><mo>,</mo><mi>k</mi><mo>)</mo></mrow><mo>|</mo><mo> =</mo><msub><mi>G</mi><mrow><mi>M</mi><mi>M</mi><mi>S</mi><mi>E</mi></mrow></msub><mrow><mo>(</mo><mi>p</mi><mo>,</mo><mi>k</mi><mo>)</mo></mrow><mo>|</mo><mi>X</mi><mrow><mo>(</mo><mi>p</mi><mo>,</mo><mi>k</mi><mo>)</mo></mrow><mo>|</mo><mo>:</mo></mrow>]]></math><img file="FDA00011135801500000112.TIF" wi="666" he="95" /></maths>S9.将<img file="FDA00011135801500000113.TIF" wi="140" he="87" />进行处理变换到时域从而输出增强的语音信号。</td>   <td>G10L21/0208;G10L21/0216</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              向中明;              张奥熙;              刘镇;              周逸红;              黎杰明;                   周斌       </td>   <td>中山大学</td>   <td>一种基于区间型层次分析的采空区稳定性在线评价方法</td>   <td>广东</td>   <td>CN106327054A</td>   <td>2017-01-11</td>   <td>本发明提供一种基于区间型层次分析的采空区稳定性在线评价方法,包括以下步骤：建立采空区稳定性评价指标体系,采用区间标度法进行采空区稳定性指标比较打分,构造区间判断矩阵,通过相对优势度法计算各指标权值；在网络页面对评价区域进行网格划分,计算各网格分数；对各网格进行颜色赋值并绘制分区图,实时显示于网络页面。本发明提供的一种基于区间型层次分析的采空区稳定性在线评价方法,与传统的层次分析法相比,更能体现评价过程中的不确定性；在结果输出上,本发明将评价结果实时显示于网络页面,更能快速直观地反映采空区稳定性的分布。</td>   <td>一种基于区间型层次分析的采空区稳定性在线评价方法,其特点在于不仅能实现基于网络浏览器的采空区稳定性在线评价,而且可实现稳定性评价结果实时、直观地在线显示,其具体包括：根据建立的采空区稳定性评价指标体系,采用区间标度法进行采空区稳定性指标比较打分,构造区间判断矩阵；然后将区间判断矩阵转换为误差分布形式矩阵,依据对数最小二乘法、误差传递算法求解得到权重区间向量,再利用相对优势度分析法创建相对优势度矩阵,由此计算得到各指标权值；利用关系运算函数判断各评价网格内所包含的采空区调查点并获取调查点编号,编写程序驱动计算机由所获取的评价区域内调查点编号自动检索数据库,返回各调查点数据至前台页面,再由编写的页面脚本程序处理前台数据,得出各网格内每个指标的量化分值；然后将网格内每个指标量化分值与其权值相乘,得到各指标贡献分值,再将各网格内所有指标的贡献分值相加,得到每个网格的评分值,并判断评分值所处区间,依据图例规范对各网格进行颜色赋值,实时显示于网络页面。</td>   <td>G06Q10/06;G06Q50/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王凯;                   李惠敏       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>采用单一器件实现显示驱动和指纹图像采集的方法</td>   <td>广东</td>   <td>CN106295540A</td>   <td>2017-01-04</td>   <td>本发明提供的显示驱动和指纹图像采集的方法,采用单一器件即可实现显示驱动和指纹图像采集,因此使得显示屏的生产装配过程与现有技术相比得到了简化。</td>   <td>一种采用单一器件实现显示驱动和指纹图像采集的方法,在于使用双栅极光电薄膜晶体管进行显示驱动和指纹图像采集,其特征在于：双栅极光电薄膜晶体管的源极与电容C<sub>LC</sub>的一端连接,电容C<sub>LC</sub>的另一端称之为共电极,所述双栅极光电薄膜晶体管包括有两个工作模式,分别为显示驱动模式和指纹图像采集模式,具体分别如下：(1)显示驱动模式当触摸启动开关检测不到触摸动作时,双栅极光电薄膜晶体管工作在显示驱动模式,其包括以下步骤：a)写入阶段：使双栅极光电薄膜晶体管的暗栅极设置为正电压,若双栅极光电薄膜晶体管上一个状态处于负极性驱动状态,则向双栅极光电薄膜晶体管的漏极施加正偏压,并使双栅极光电薄膜晶体管的光栅极、源极由负电压充电至正电压,并向共电极施加负电压；若双栅极光电薄膜晶体管上一个状态处于正极性驱动状态,则向双栅极光电薄膜晶体管的漏极施加负偏压,并使双栅极光电薄膜晶体管的光栅极、源极由正电压放电至负电压,并向共电极施加正电压；此时显示信号通过双栅极光电薄膜晶体管的漏极、源极输送至显示单元,显示信号对显示单元进行驱动；b)保持阶段：完成写入操作后,向双栅极光电薄膜晶体管的暗栅极施加负偏压,并使光栅极、源极、共电极的电压保持不变；c)调变阶段：保持阶段持续一定时间后进入调变阶段,调变阶段对共电极电压进行提高或降低,为显示单元下一状态的驱动做准备,并使双栅极光电薄膜晶体管暗栅极、漏极的偏压保持不变；(2)指纹图像采集模式当触摸启动开关检测到触摸动作时,双栅极光电薄膜晶体管工作在指纹图像采集模式,这个模式包括以下步骤：d)复位阶段：双栅极光电薄膜晶体管的暗栅极设置为负电压,光栅极、源极、漏极和共电极设置为正偏压,对光栅极进行复位；e)收集阶段：完成复位后,使双栅极光电薄膜晶体管的暗栅极、漏极、光栅极和源极设置为负偏压,双栅极光电薄膜晶体管完全关闭,并使共电极保持正偏压,从手指反射进来的光被光栅极吸收,激发光生载流子的产生并保存在光栅极内；f)读取阶段：完成收集阶段后,向双栅极光电薄膜晶体管的暗栅极、漏极施加正偏压,并向共电极、光栅极、源极施加负偏压,使得保存在光栅极的光生载流子能够通过双栅极光电薄膜晶体管的源极输出。</td>   <td>G06K9/00;G09G3/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡师艺;              林倞;              成慧;                   王青       </td>   <td>中山大学</td>   <td>一种结合可见光和红外图像的多模态目标跟踪方法</td>   <td>广东</td>   <td>CN106250878A</td>   <td>2016-12-21</td>   <td>本发明公开一种结合可见光和红外图像的多模态目标跟踪方法,步骤如下：分别获取可见光图像和红外图像；在任一模态下标定目标矩形框；两种模态下分别初始化目标模型；使用STRUCK算法分别跟踪T帧,在跟踪过程中判断是否要更新目标模型；跟踪T帧后,两种模态下分别往回跟踪T帧；分别计算两种模态下前向后向跟踪的误差；比较在这T帧两种模态下正向反向跟踪结果,选择可信度较高的模态作为这T帧的跟踪结果；这T帧下可信度比较小的模态位置更新为另一模态下的位置,并重新初始化目标模型；判断是否最后帧决定继续跟踪还是结束跟踪。本发明能在计算机上实现对视频的目标近乎实时跟踪,跟踪性能较普通方法也有很大的提高。</td>   <td>一种结合可见光和红外图像的多模态目标跟踪方法,其特征在于,步骤如下：分别获取可见光图像和红外图像；在任一模态下标定目标框；两种模态下分别初始化目标模型；使用STRUCK算法分别跟踪T帧,在跟踪过程中判断是否要更新目标模型；跟踪T帧后,两种模态下分别往回跟踪T帧；分别计算两种模态下前向后向跟踪的误差；比较在这T帧两种模态下正向反向跟踪结果,选择可信度较高的模态作为这T帧的跟踪结果；这T帧下可信度比较小的模态位置更新为另一模态下的位置,并重新初始化目标模型；判断是否最后帧决定继续跟踪还是结束跟踪。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              冷绵绵;                   印鉴       </td>   <td>中山大学;广州智海纵横信息科技有限公司;广州中大南沙科技创新产业园有限公司</td>   <td>一种基于改进的LBP算子的人群计数方法</td>   <td>广东</td>   <td>CN106250828A</td>   <td>2016-12-21</td>   <td>本发明公开一种基于改进的LBP算子的人群计数方法,采用基于圆形领域的自适应尺度的旋转不变等价模式的ASLBP算子描述图像的局部纹理特征实现人群计数。采用基于透视归一化图的自适应分块方案,对块提取旋转等价不变的LBP特征算子,特征提取中用灰度变化度确定自适应半径,根据半径确定采样频率,最后对块的归一化的特征描述符,联合BOF特征袋模型,形成场景的特征描述向量；最后用SVR支持向量回归机对图像的特征和场景中的人数之间的映射关系进行回归学习,用训练得到的模型对未知的图像中的人数进行预测。本方法具有良好的实时性,较好的准确度。可用于安防监控等领域。</td>   <td>一种基于改进的LBP算子的人群计数方法,其特征在于,包括以下步骤：S1：采集用于回归模型训练的训练图像集；S2：提取训练图像集中每幅图像的ASLBP特征向量,提取的步骤包括：(1)对图像采用基于摄像头透视关系的场景自适应分块处理,将场景划分成子图像块；(2)用灰度变化度确定圆形区域的自适应半径,根据半径确定采样像素点数目；(3)对于每个子图像块,采用自适应尺度的旋转不变等价模式的ASLBP特征算子提取场景信息,形成ASLBP特征直方图；(4)对于每个子图像块的ASLBP特征直方图采用归一化处理；(5)对归一化后特征描述符,联合特征袋模型的BOF,形成特征描述向量F<sub>lbp</sub>；S3：回归模型的训练：对于训练图像集,视每一幅图像得到的特征描述向量F<sub>lbp</sub>为一个训练样本数据X<sub>i</sub>,相应场景的实际人数为当前标签y<sub>i</sub>,构建样本数据库并获得回归模型SVR<sub>model</sub>；S4：回归模型的估计：对于待估计的图像,提取其场景特征描述向量F<sub>lbp</sub>,采用SVR<sub>model</sub>进行估计,得到当前场景的人数n<sub>people</sub>。</td>   <td>G06K9/00;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         衣杨;              李芳;              吴斯扬;              涂冠平;              陈新耿;                   赵勇宪       </td>   <td>中山大学</td>   <td>基于改进粒子群优化的总拖期运输计划调度算法</td>   <td>广东</td>   <td>CN106228265A</td>   <td>2016-12-14</td>   <td>一种基于改进粒子群优化的总拖期运输计划调度算法,步骤1,根据输入变量构建总拖期值数学模型,定义待加工工作数n和机器数m,以及每一待加工工作加工所需时间p<sub>j</sub>和交货期限d<sub>j</sub>,步骤2,根据总拖期值数学模型解构造图；步骤3,以构造图为依据,根据状态转移规则和信息素更新规则完成搜索,获得一使总拖期T最小的解。本发明在蚁群算法的基础上,针对并行多机总拖期运输计划调度问题(P//T)的特性,提出了基于启发式规则的改进蚁群算法(Heuristic#Ant#Colony#Optimization,hACO),并对算法进行了性能优化的研究,以提高事件最优解的确定精度,以及保证对内部数据的处理筛选效率。</td>   <td>一种基于改进粒子群优化的总拖期运输计划调度算法,其特征在于：步骤1,根据输入变量构建总拖期值数学模型,定义待加工工作数n和机器数m,以及每一待加工工作加工所需时间p<sub>j</sub>和交货期限d<sub>j,</sub>；步骤2,根据总拖期值数学模型解构造图；步骤3,以构造图为依据,根据状态转移规则和信息素更新规则完成搜索,获得一使总拖期T最小的解。</td>   <td>G06Q10/04;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              梅岭;                   陈军       </td>   <td>中山大学</td>   <td>一种基于MATV特征的人脸活体检测方法</td>   <td>广东</td>   <td>CN106228129A</td>   <td>2016-12-14</td>   <td>本发明涉及基于MATV特征的人脸活体检测方法,包括步骤：读取并分解训练集视频,提取每一帧的人脸区域并归一化做输入,采用基于幅度#角度变分法的MATV光流场特征,用统计直方图对特征进行编码得到MATV直方图特征,最后将MATV直方图特征输入SVM分类器进行训练,建立SVM模型；对于测试集的人脸视频帧序列,对每一帧进行人脸检测,然后提取其中的人脸区域并归一化得到测试集人脸帧样本,计算人脸帧样本的MATV直方图特征,最后将其输入训练好的SVM模型,预测出人脸活体检测的结果。本发明在传统的基于幅度特征的光流方法基础上,加入了角度特征,考虑了光流场的方向特性,从而得到更多活体和非活体人脸的运动细节,提高了人脸活体检测的准确率。</td>   <td>一种基于MATV特征的人脸活体检测方法,其特征在于,包括下述步骤：S1、训练阶段：读取并分解训练集视频,提取每一帧的人脸区域并归一化做输入,采用基于幅度#角度变分法的MATV光流场特征,用统计直方图对特征进行编码得到MATV直方图特征,最后将MATV直方图特征输入SVM分类器进行训练,建立SVM模型；S2、测试阶段：对于测试集的人脸视频帧序列,对每一帧进行人脸检测,然后提取其中的人脸区域并归一化得到测试集人脸帧样本,计算人脸帧样本的MATV直方图特征,最后将其输入训练好的SVM模型,预测出人脸活体检测的结果。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   李阳       </td>   <td>中山大学</td>   <td>一种基于上市公司公告摘要的自动提取方法</td>   <td>广东</td>   <td>CN106227722A</td>   <td>2016-12-14</td>   <td>本发明涉及一种基于上市公司公告摘要的自动提取方法,包括以下步骤：S1：从证券交易所中爬取上市公司公告文档形成公告文档数据库；S2：采用word2vec模型,从文本语料得到词向量；S3：计算句子之间相似度,构建句子图模型；S4：计算句子的权重；S5：根据句子位置调整句子权重矩阵；S6:选择权重最大且无冗余的句子组成摘要。基于上市公司公告摘要的自动提取技术,为金融市场的投资者提供准确且可读性较高的摘要文档,帮助投资者更短时间理解以及更好的做出投资判断,同时为量化基金公司提供重要的指标。</td>   <td>一种基于上市公司公告摘要的自动提取方法,其特征在于包括以下步骤：S1：从证券交易所中爬取上市公司公告文档形成公告文档数据库；S2：采用word2vec模型,从文本语料得到词向量；S3：计算句子之间相似度,构建句子图模型；S4：计算句子的权重；S5：根据句子位置调整句子权重矩阵；S6:选择权重最大且无冗余的句子组成摘要。</td>   <td>G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨达坤;              赖剑煌;                   梅岭       </td>   <td>中山大学</td>   <td>一种基于深度视觉词袋模型的人脸活体检测方法</td>   <td>广东</td>   <td>CN106203373A</td>   <td>2016-12-07</td>   <td>本发明公开了一种基于深度视觉词袋模型的人脸活体检测方法,该方法包括以下步骤：对于训练集中每一个人脸活体图像,计算其对应的LBP特征；利用深度稀疏自编码网络将LBP特征编码成高级特征；利用训练集的人脸图像的类标对整个深度稀疏自编码网络进行训练,得到更具有区分性的高级特征；将更具有区分性的高级特征输入到LIBSVM进行训练,从而建立SVM模型；将计算的LBP特征输入深度稀疏自编码网络得到高级特征,然后利用建立的SVM模型对其进行分类,得到人脸活体图像的类标。本发明能够得到更有鲁棒性、更有区别性的高级特征,从而对非控条件下的人脸活体检测具有更高的检测率。</td>   <td>一种基于深度视觉词袋模型的人脸活体检测方法,其特征在于,包括以下步骤：步骤a、对于训练集中每一个人脸活体图像,计算其对应的LBP特征；步骤b、利用深度稀疏自编码网络将LBP特征编码成高级特征；步骤c、利用训练集的人脸图像的类标对整个深度稀疏自编码网络进行训练,得到更具有区分性的高级特征；步骤d、将步骤c得到更具有区分性的高级特征输入到LIBSVM进行训练,从而建立SVM模型；步骤e、将步骤a计算的LBP特征输入步骤b的深度稀疏自编码网络得到高级特征,然后利用步骤d建立的SVM模型对其进行分类,得到人脸活体图像的类标。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              张智伟;                   马侠霖       </td>   <td>中山大学</td>   <td>结合离线存储与即时计算的三维交通噪声地图更新方法</td>   <td>广东</td>   <td>CN106202506A</td>   <td>2016-12-07</td>   <td>本发明提出一种结合离线存储与即时计算的三维交通噪声地图更新方法,将噪声的计算分成与交通流相关的噪声排放项和与交通流无关的噪声衰减项两个部分；将仅与地理要素相关的噪声衰减项提前计算好并将其离线存储于数据库中,当三维交通噪声地图需要进行更新时,根据城市道路交通流状态的变化,仅计算变化的噪声排放项,结合离线存储的噪声衰减项计算得到最终的噪声值,减少计算量。为加快三维交通噪声地图的更新速度,该法使用计算机集群并行计算的方式对噪声地图的噪声计算及更新进行加速。该法所结合使用的分布式计算系统具有负载均衡性好,灵活性高和扩展性强等特点,配合优化后的噪声地图更新算法能极大地减少计算时间,显著提升更新效率。</td>   <td>一种结合离线存储与即时计算的三维交通噪声地图更新方法,其特征在于,所述方法包括以下步骤：a、将噪声的计算分为计算噪声排放项和噪声衰减项两个部分；b、利用计算机集群分布式加速计算噪声衰项,并将噪声衰减项离线存储到数据库中；c、计算噪声排放项,并结合离线存储的噪声衰减项计算得到噪声接收点的噪声值,以此更新三维交通噪声地图。</td>   <td>G06F17/30;G06F9/50;G06T17/05;G06T19/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡生辉;              龙冬阳;              衣杨;              袁野;                   杨洋       </td>   <td>中山大学</td>   <td>一种网页表格信息抽取方法</td>   <td>广东</td>   <td>CN106202348A</td>   <td>2016-12-07</td>   <td>本发明公开了一种网页表格信息抽取方法,包括：用户预先对操作文件进行配置；用户输入所要抓取网页的URL地址,并由java系统对该网页进行抓取；java系统对抓取到的网页进行预处理；java系统根据用户手动输入的信息对网页进行解析和定位,同时,生成抽取规则并存入规则库进行维护；java系统根据抽取规则在页面抽取所需数据,并将抽取到的数据存入MySQL数据库；java系统根据操作文件的配置,利用JSP页面将抽取到的数据以动态页面的形式展示给用户,供用户操作。本发明减少了网页表格信息抽取过程中对系统资源的消耗,加快了网页表格信息抽取的速度,方便了用户对抽取出的网页表格数据进行二次处理,提高了用户对网页表格数据进行二次处理的效率。</td>   <td>一种网页表格信息抽取方法,其特征在于,包括以下步骤：用户预先对操作文件进行配置；用户输入所要抓取网页的URL地址,并由java系统对该网页进行抓取；java系统对抓取到的网页进行预处理；java系统根据用户手动输入的信息对网页进行解析和定位,同时,生成抽取规则并存入规则库进行维护；java系统根据抽取规则在页面抽取所需数据,并将抽取到的数据存入MySQL数据库；java系统根据操作文件的配置,利用JSP页面将抽取到的数据以动态页面形式展示给用户,供用户操作。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         衣杨;              曾青青;                   梁丽荣       </td>   <td>中山大学新华学院;中山大学</td>   <td>基于隐Markov模型的视频行为活动识别关键算法</td>   <td>广东</td>   <td>CN106203323A</td>   <td>2016-12-07</td>   <td>一种基于PSO的隐Markov模型参数学习算法以及基于事件概率法的视频轨迹行为识别系统框架和基于视频人体运动的行为活动建模,首先从视频序列中提取行为活动的目标运动轨线特征,利用隐Markov模型以语义事件概率的方式对行为活动进行表示,从而完成对行为活动的建模。同时,基于粒子群优化算法对隐Markov模型中的参数学习算法进行改进,使得HMM的学习问题可以跳出局部最优。然后,采用时间规整法对视频人体运动建模得到的事件概率序列进行匹配以识别目标行为活动。通过Central#Florida大学的人体运动数据集(UCF#Human#Action#Dataset)和来自UCI#KDD的ASL(Australia#Sign#Language)复杂运动轨迹数据集实验表明,本文提出的方法与Baum#Welch参数估计方法相比,在行为建模的学习性能上具有较高的优越性,在识别率上取得更好的结果。</td>   <td>一种PSO改进的HMM学习方法,其特征在于,步骤1,采用新的目标优化函数log(P(O|λ))构建优化模型；步骤2,对粒子位置的向量X＝(x1,…,x#N*N+3N*M*D+N),如果X满足约束条件,则跳出,如果xi&lt;Xmin,则xi＝Xmin#xi；若xi&gt;Xmax,则xi＝Xmax；步骤3,如果X满足约束条件,则跳出,若<img file="FDA0001042529510000011.TIF" wi="253" he="135" />则xi＝1/N,其中k＝{0,…,N#1}；步骤4,如果X仍然不满足约束条件,则采用归一化方法对粒子位置进行修正,定义X为违反约束条件的粒子位置,X*为修正后的粒子位置,其公式描述如下：对转移矩阵A,即粒子的前N2维：<img file="FDA0001042529510000012.TIF" wi="317" he="183" />1≤i≤N,k＝{0,…,N#1}；对表示权值系数c的维数,即粒子的N2+1到N2+N*M*D维：<img file="FDA0001042529510000013.TIF" wi="356" he="192" />N2+1≤i≤N2+N*M*D；对表示协方差矩阵Σ的维数,即粒子的N2+N*M*D+1到N2+2N*M*D维：<img file="FDA0001042529510000014.TIF" wi="189" he="83" />N2+N*M*D+1≤i≤N2+2N*M*D；对HMM的初始分布π,即粒子的后N维：<img file="FDA0001042529510000015.TIF" wi="397" he="195" />N2+3N*M*D+1≤i≤N2+3N*M*D+N。</td>   <td>G06K9/00;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              周斌;              刘镇;                   向中明       </td>   <td>中山大学</td>   <td>一种基于WebGIS系统的钻孔柱状图在线生成方法</td>   <td>广东</td>   <td>CN106202156A</td>   <td>2016-12-07</td>   <td>本发明涉及一种基于WebGIS系统的钻孔柱状图在线生成方法,属于地理信息技术与地质学的交叉领域。其特征是：在Web页面操作地图,调取后台服务器中的钻孔数据,在新生成的Web页面中在线生成钻孔柱状图并编辑修改,保存后以jpg格式下载到用户计算机。适用于在基于网络平台的地理信息系统中辅助生成钻孔柱状图。</td>   <td>一种基于WebGIS系统的钻孔柱状图在线生成方法,其特征在于：在WebGIS系统中,操作钻孔图元,查询钻孔信息,在线生成钻孔柱状图,实现在线绘制、编辑、保存以及下载钻孔柱状图的功能,包括以下步骤：(1)基于ArcGIS平台,将钻孔数据以GIS矢量数据的形式发布为网络服务,供WebGIS调用,用于显示钻孔图层、查询钻孔图层属性字段值；(2)将钻孔详细信息存储于部署在服务器的数据库,通过查询步骤(1)中WebGIS调用的GIS矢量数据的某字段值,以该字段值为主键从数据库检索,匹配相应钻孔点的钻孔数据,并以Json数组格式返回；(3)将图例图片存储于后台服务器,用于图例的匹配；(4)通过在Web页面中用HTML标签绘制钻孔柱状图表格,填入步骤(2)返回的Json数组格式钻孔数据,完成钻孔柱状图的绘制；(5)针对所绘制的钻孔柱状图,修改钻孔柱状图所涉及的HTML标签的可编辑属性,前端修改钻孔柱状图表格内容,并以表单的方式,将修正值递交到后台,实现钻孔柱状图的二次编辑与保存；(6)通过网页截图的方式,以jpg格式下载钻孔柱状图到本地计算机。</td>   <td>G06F17/30;G06T11/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;                   赵有婷       </td>   <td>中山大学</td>   <td>一种基于透视变换的角度车牌图像库搭建方法</td>   <td>广东</td>   <td>CN106169076A</td>   <td>2016-11-30</td>   <td>本发明公开一种基于透视变换的角度车牌图像库搭建方法,其具体实现过程为：1)建立针孔相机成像模型,获得三维车牌四个顶点的坐标值；2)对三维车牌进行空间几何变换,获得变换后的三维车牌四个顶点的坐标值；3)将三维车牌投影变换到二维图像,并获得车牌二维图像四个顶点的坐标值；同时获得正投影的车牌图像四个顶点的坐标值；4)计算二维图像变成不同形状二维图像的投影矩阵H；5)基于所得的投影矩阵H,将正投影的车牌图像变换成不同形状的车牌图像,建立不同成像形状的车牌图像库。本发明提出的建立车牌图像库的方法可以模拟实际的拍摄环境,能够明确成像属性,图像可扩充性强,并且成本低。</td>   <td>一种基于透视变换的角度车牌图像库搭建方法,其特征在于,其具体实现过程为：1)建立针孔相机成像模型,获得三维车牌四个顶点的坐标值；2)对三维车牌进行空间几何变换,获得变换后的三维车牌四个顶点的坐标值；3)将三维车牌投影变换到二维车牌图像,并获得二维车牌图像四个顶点的坐标值；同时可手动取点并且根据车牌的标准尺寸获得正投影的车牌图像四个顶点的坐标值,所述正投影的车牌图像是指当车牌平面平行于成像平面,并且车牌上下边缘平行于x轴的一种车牌投影图像；该车牌图像的形状为矩形,并且车牌没有变形；4)计算二维图像变成不同形状二维图像的投影矩阵H；5)基于所得的投影矩阵H,将正投影的车牌图像变换成不同形状的车牌图像,建立不同成像形状的车牌图像库。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王成建;                   印鉴       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>音乐数据推荐方法与系统</td>   <td>广东</td>   <td>CN106126591A</td>   <td>2016-11-16</td>   <td>本发明提供一种音乐数据推荐方法与系统,采集汽车周围环境数据以及汽车行驶状态数据,根据汽车周围环境数据以及汽车行驶状态数据,从预设音乐数据库中选择匹配的音乐数据,推送查找到的音乐数据。整个过程,考虑汽车周围环境数据和汽车行驶状态数据,基于这些应用环境的数据从预设音乐数据中查找并推荐适合当前场景音乐数据。</td>   <td>一种音乐数据推荐方法,其特征在于,包括步骤：采集汽车周围环境数据以及汽车行驶状态数据；根据所述汽车周围环境数据以及汽车行驶状态数据,从预设音乐数据库中选择匹配的音乐数据；推送查找到的音乐数据。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              徐颂华;              姜涛;                   林格       </td>   <td>中山大学</td>   <td>一种基于视频内容的视频检索方法及系统</td>   <td>广东</td>   <td>CN106126619A</td>   <td>2016-11-16</td>   <td>本发明公开了一种基于视频内容的视频检索方法及系统,其中,所述方法包括：将用户的检索关键词与背景主词题集合的主题词进行匹配,获取匹配中与检索关键词相近的主题词；根据所述与检索关键词相近的主题词进行视频检索,获取所述与检索关键词相近的主题词对应的视频；根据所述与检索关键词相近的主题词对应的视频,获取视频基本信息；根据所述视频基本信息对所述视频相似性进行估量,获取视频相似性估量结果；对所述视频相似性估量结果进行综合加权估量,获取视频相似性综合估量结果；根据获取视频相似性综合估量结果进行显示；在本发明实施例中,有效的解决基于名称的视频检索中存在的检索内容不准确问题,提高用户的使用体验感。</td>   <td>一种基于视频内容的视频检索方法,其特征在于,所述方法包括：将用户的检索关键词与背景主词题集合的主题词进行匹配,获取匹配中与检索关键词相近的主题词；根据所述与检索关键词相近的主题词进行视频检索,获取所述与检索关键词相近的主题词对应的视频；根据获取所述与检索关键词相近的主题词对应的视频,获取视频基本信息；根据所述视频基本信息对所述视频相似性进行估量,获取视频相似性估量结果；对所述视频相似性估量结果进行综合加权估量,获取视频相似性综合估量结果；根据获取视频相似性综合估量结果进行显示。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              曹向前;              顾建权;                   李昊曦       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于多特征的显著性检测方法</td>   <td>广东</td>   <td>CN106127210A</td>   <td>2016-11-16</td>   <td>本发明提供一种基于多特征的显著性检测方法,该方法首先运用多尺度对比、中央周围直方图和颜色空间分布这三种不同的显著性线索计算得到单独特征显著图,然后通过马尔科夫模型学习计算各个单独特征显著图的权重,并采用最大似然估计法获取模型参数估计最优解,最后利用马尔科夫模型检测测试图像。</td>   <td>一种基于多特征的显著性检测方法,其特征在于,包括以下步骤：S1：采集待检测的图像I；S2：对图像I分别进行多尺度对比、中央周围直方图和颜色空间分布处理得到特征显著图I<sub>1</sub>、I<sub>2</sub>、I<sub>3</sub>；S3：利用马尔科夫模型分别对特征显著图I<sub>1</sub>、I<sub>2</sub>、I<sub>3</sub>进行权重的学习计算,然后采用最大似然估计法获取该马尔科夫模型参数估计最优解；S4：利用S3中得到的最优参数估计解的马尔科夫模型分别对特征显著图I<sub>1</sub>、I<sub>2</sub>、I<sub>3</sub>进行检测得出概率最大的标记序列,用灰度图像表示出该概率最大的标记序列即得到最终的特征显著图。</td>   <td>G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张燕;              柯戈扬;              潘炎;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司</td>   <td>一种基于张量展开的多视图谱聚类算法</td>   <td>广东</td>   <td>CN106127218A</td>   <td>2016-11-16</td>   <td>本发明提供一种基于张量展开的多视图谱聚类算法,该发明基于张量表示所有的视图数据,利用张量的n#Mode乘法进行展开,分析多视图数据的多维约束关系(高维结构信息)并借鉴低秩矩阵表示和稀疏表示的思想来保存关键结构信息,从而建立基于张量展开的求解模型。另外,考虑到实际获取数据过程中的噪声问题,增加噪声张量进行抗噪处理。由于该优化问题存在非凸的低秩约束条件,直接求解困难,需要对优化目标进行凸松弛,再使用ADMM算法进行优化求解。一些真实数据集的实验结果表明,本发明可有效提高多视图谱聚类的效果。</td>   <td>一种基于张量展开的多视图谱聚类算法,其特征在于,包括以下步骤：S1：将每个视图通过图结构表示得到各自的概率转移矩阵；S2：用一个张量<img file="FDA0000999769730000011.TIF" wi="219" he="47" />表示所有视图的概率转移矩阵,利用数据分布规律建模求解,得到一个概率转移矩阵P；S3：将概率转移矩阵P作为基于马尔可夫链的谱聚类算法的关键输入,计算得到谱聚类输出结果；其中n表示样本总数,m表示视图总数。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘洁;                   黄金程       </td>   <td>中山大学</td>   <td>一种三维空间裂缝分离识别与表征方法</td>   <td>广东</td>   <td>CN106127777A</td>   <td>2016-11-16</td>   <td>本发明公开一种三维空间裂缝分离识别与表征方法,对采集的图像进行如下处理,以实现对三维空间裂缝进行分离识别与表征：1)图像数据预处理；2)统计分析图像数据基本信息：图像数据的基本信息包括孔隙度、各个孔隙的连通性、孔隙大小统计、每个孔隙的位置、大小、方向以及各向异性；3)过滤：去除图像数据中非裂隙结构；4)平滑：对图像数据进行平滑和修补；5)减薄：使空隙结构在三维中最窄方向上减薄到厚度d；6)分离：以断开连接的方式分离裂缝网络中互相交错的裂缝；7)合并：合并在前一步中被断开的延伸较长的裂缝,整合分离过程形成的微小结构并恢复至减薄前状态,最后给出裂缝的表征。</td>   <td>一种三维空间裂缝分离识别与表征方法,其特征在于,对采集的图像进行如下处理,以实现对三维空间裂缝进行分离识别与表征：1)图像数据预处理；2)统计分析图像数据基本信息：图像数据的基本信息包括孔隙度、各个空隙结构的连通性、位置、大小、方向以及各向异性；3)过滤：去除图像数据中非裂隙结构；4)平滑：对图像数据进行平滑和修补；5)减薄：使空隙结构在三维中最窄方向上减薄到厚度d；6)分离：以断开连接的方式分离裂缝网络中互相交错的裂缝；7)合并：合并在前一步中被断开的空隙结构,整合分离过程形成的微小结构,最后分析各个空隙结构的孔隙度、连通性、位置、大小、方向以及各向异性,完成对三维空间裂缝的分离识别与表征。</td>   <td>G06T7/00;G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              黄秋筱;              江倩殷;              李国鸣;                   卢林       </td>   <td>中山大学</td>   <td>一种基于视频监控的客运站非出入口区域的客流统计方法</td>   <td>广东</td>   <td>CN106127812A</td>   <td>2016-11-16</td>   <td>本发明提供的客流统计方法针对于客运站非出入口区域拍摄的图像容易出现遮挡的特点,提出使用行人的不易被遮挡、且形态基本不变的头肩部haar#like特征来对行人进行检测,其检测判别是否为行人的准确率较高,适用于行人图像出现遮挡的应用场景；而在完成检测后,通过Kalman滤波器和以上检测行人的方法来对行人在每帧图像的位置进行双重追踪,以保证追踪的准确率；实验证明,该方法能够针对客运站非出入口区域行人姿态多变、行为复杂、行走方向难预测的特点,达到很好的追踪效果。通过对行人的准确检测和追踪,本发明提供的方法能够有效地记录下行人的运动轨迹,保证了行人目标的匹配,减少误检和遗漏,提高人数统计精度。</td>   <td>一种基于视频监控的客运站非出入口区域的客流统计方法,该方法预先划定好人数统计区域,并对该区域内的行人目标进行检测和跟踪,从而统计进入和离开统计区域的人数,其特征在于：其中对行人目标进行检测和跟踪的具体过程如下：S1.人工提取监控图像里的行人的头肩部haar#like特征对AdBoost分类器进行训练,得到训练好的AdBoost分类器；S2.对于当前帧图像,采用背景差分法在当前帧图像的统计区域内获取运动目标；S3.提取运动目标的头肩部haar#like特征,并将其输入训练好的AdBoost分类器内,AdBoost分类器判别运动目标是否为行人,若是则执行步骤S4；S4.计算判别为行人的运动目标的头肩部中心点位置,并使用四维向量X<sub>k</sub>＝(p<sub>x</sub>,p<sub>y</sub>,v<sub>x</sub>,v<sub>y</sub>)来表示其在当前帧的系统状态,其中(p<sub>x</sub>,p<sub>y</sub>)表示头肩部中心点的位置,(v<sub>x</sub>,v<sub>y</sub>)表示中心点的速度；S5.将X<sub>k</sub>输入Kalman滤波器,并对Kalman滤波器的四个参数进行初始化：A<sub>k</sub>、H<sub>k</sub>、w<sub>k</sub>、v<sub>k</sub>；其中A<sub>k</sub>表示状态由当前帧到下一帧的转移矩阵,H<sub>k</sub>当前帧的观测矩阵,w<sub>k</sub>和v<sub>k</sub>分别表示当前帧的系统噪声向量和观测噪声向量；令A<sub>k</sub>、H<sub>k</sub>在各帧的系统状态变换过程中为已知且具有唯一值的矩阵,另外,设w<sub>k</sub>、v<sub>k</sub>的概率密度函数是均值为零的高斯函数且相互独立；S6.Kalman滤波器对运动目标的头肩部中心点在下一帧的系统状态进行预报,具体如下：<maths num="0001"><math><![CDATA[<mrow><msub><msup><mover><mi>X</mi><mo>~</mo></mover><mo>&prime;</mo></msup><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo> =</mo><msub><mi>A</mi><mi>k</mi></msub><msub><mover><mi>X</mi><mo>~</mo></mover><mi>k</mi></msub><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001033511630000011.TIF" wi="373" he="70" /></maths>其中A<sub>k</sub>表示状态转移矩阵,<img file="FDA0001033511630000012.TIF" wi="107" he="71" />表示预报的下一帧的系统状态；<img file="FDA0001033511630000013.TIF" wi="68" he="70" />表示当前帧的系统状态；由(1)式,可得系统状态协方差的预报方程：<maths num="0002"><math><![CDATA[<mrow><msub><msup><mi>P</mi><mo>&prime;</mo></msup><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo> =</mo><msub><mi>A</mi><mi>k</mi></msub><msub><mi>P</mi><mi>k</mi></msub><msubsup><mi>A</mi><mi>k</mi><mi>T</mi></msubsup><mo>+</mo><msub><mi>Q</mi><mi>k</mi></msub></mrow>]]></math><img file="FDA0001033511630000014.TIF" wi="398" he="63" /></maths>其中,P'<sub>k+1</sub>和P<sub>k</sub>分别是<img file="FDA0001033511630000015.TIF" wi="104" he="70" />和<img file="FDA0001033511630000016.TIF" wi="65" he="71" />对应的协方差,<img file="FDA0001033511630000017.TIF" wi="58" he="63" />表示A<sub>k</sub>的转置矩阵,Q<sub>k</sub>表示当前帧的系统噪声向量w<sub>k</sub>的协方差矩阵；S7.根据步骤S6求取的内容对Kalman加权矩阵进行求取：<maths num="0003"><math><![CDATA[<mrow><msub><mi>K</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo> =</mo><msub><msup><mi>P</mi><mo>&prime;</mo></msup><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><msubsup><mi>H</mi><mi>k</mi><mi>T</mi></msubsup><msup><mrow><mo>(</mo><msub><mi>H</mi><mi>k</mi></msub><msub><msup><mi>P</mi><mo>&prime;</mo></msup><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><msubsup><mi>H</mi><mi>k</mi><mi>T</mi></msubsup><mo>+</mo><msub><mi>R</mi><mi>k</mi></msub><mo>)</mo></mrow><mrow><mo>-</mo><mn>1</mn></mrow></msup></mrow>]]></math><img file="FDA0001033511630000021.TIF" wi="717" he="63" /></maths>其中K<sub>k+1</sub>表示下一帧的Kalman加权矩阵,H<sub>k</sub>、<img file="FDA0001033511630000022.TIF" wi="72" he="62" />表示观测矩阵以及其转置,R<sub>k</sub>表示观测噪声向量v<sub>k</sub>的协方差矩阵；S8.根据求取的Kalman加权矩阵对运动目标的头肩部中心点在下一帧的系统状态<img file="FDA0001033511630000023.TIF" wi="90" he="70" />和状态向量协方差P<sub>k+1</sub>进行更新：<maths num="0004"><math><![CDATA[<mrow><msub><mover><mi>X</mi><mo>~</mo></mover><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo> =</mo><msub><msup><mover><mi>X</mi><mo>~</mo></mover><mo>&prime;</mo></msup><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>+</mo><msub><mi>K</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mrow><mo>(</mo><msub><mi>Z</mi><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>-</mo><msub><mi>H</mi><mi>k</mi></msub><msub><msup><mover><mi>X</mi><mo>~</mo></mover><mo>&prime;</mo></msup><mrow><mi>k</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001033511630000024.TIF" wi="702" he="69" /></maths>P<sub>k+1</sub>＝(I#K<sub>k+1</sub>H<sub>k</sub>)P'<sub>k+1</sub>其中Z<sub>k+1</sub>为下一帧的观测值,<img file="FDA0001033511630000025.TIF" wi="363" he="71" />I表示单位矩阵；S9.对下一帧图像按照步骤S2～S4的方法获取运动目标的头肩部中心点位置的系统状态,然后将获取的系统状态与步骤S5～S9预测得到的运动目标的系统状态进行匹配关联,若两者匹配,则将匹配的结果确定为运动目标在下一帧的位置,否则利用步骤S5～S9预测得到的系统状态确定运动目标在下一帧的位置；S10.S5～S9重复执行直至完成整个的统计过程。</td>   <td>G06T7/20;G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吕中荣;              秦昌富;                   朱嘉健       </td>   <td>中山大学</td>   <td>基于BMO算法的结构损伤识别方法</td>   <td>广东</td>   <td>CN106126774A</td>   <td>2016-11-16</td>   <td>本发明主要涉及鸟群遗传优化(BMO)算法在结构损伤识别这一领域的工程应用,具体是一种基于BMO算法的结构损伤识别方法,主要步骤如下：(一)通过有限单元法建立损伤结构的有限元模型,提取结构的固有频率、振型等模态参数。(二)利用损伤结构和计算结构的固有频率残差和模态确保准则构建目标函数(MAC)构建目标函数。(三)采用BMO算法优化这一目标函数,直到满足循环结束条件为止。(四)最后得到的最优解即为损伤识别结果。该方法相较于传统的灵敏度方法而言,无需借助梯度信息,利用少量的模态参数即可得到精度较高的识别结果。</td>   <td>一种基于BMO算法的结构损伤识别方法,其特征在于,包括以下步骤：1)用有限元方法将结构进行简化建模,并把结构划分为nel个单元；2)提取损伤结构的NF阶频率和模态,构建目标函数f如下所示：<maths num="0001"><math><![CDATA[<mrow><mi>f</mi><mo> =</mo><munderover><mo>&Sigma;</mo><mrow><mi>j</mi><mo> =</mo><mn>1</mn></mrow><mrow><mi>N</mi><mi>F</mi></mrow></munderover><msubsup><mi>w</mi><mrow><mi>&omega;</mi><mi>j</mi></mrow><mn>2</mn></msubsup><msubsup><mi>&Delta;&omega;</mi><mi>j</mi><mn>2</mn></msubsup><mo>+</mo><munderover><mo>&Sigma;</mo><mrow><mi>j</mi><mo> =</mo><mn>1</mn></mrow><mrow><mi>N</mi><mi>M</mi></mrow></munderover><msubsup><mi>w</mi><mrow><mi>&phi;</mi><mi>j</mi></mrow><mn>2</mn></msubsup><mrow><mo>(</mo><mn>1</mn><mo>-</mo><msubsup><mi>MAC</mi><mi>j</mi><mi>R</mi></msubsup><mo>)</mo></mrow></mrow>]]></math><img file="FDA0001016285830000011.TIF" wi="717" he="135" /></maths><maths num="0002"><math><![CDATA[<mrow><msub><mi>&Delta;&omega;</mi><mi>j</mi></msub><mo> =</mo><mo>|</mo><mfrac><mrow><msubsup><mi>&omega;</mi><mi>j</mi><mi>C</mi></msubsup><mo>-</mo><msubsup><mi>&omega;</mi><mi>j</mi><mi>M</mi></msubsup></mrow><msubsup><mi>&omega;</mi><mi>j</mi><mi>M</mi></msubsup></mfrac><mo>|</mo></mrow>]]></math><img file="FDA0001016285830000012.TIF" wi="339" he="158" /></maths><maths num="0003"><math><![CDATA[<mrow><msubsup><mi>MAC</mi><mi>j</mi><mi>R</mi></msubsup><mo> =</mo><mfrac><msup><mrow><mo>(</mo><msup><mrow><mo>{</mo><msubsup><mi>&phi;</mi><mi>j</mi><mi>C</mi></msubsup><mo>}</mo></mrow><mi>T</mi></msup><mo>{</mo><msubsup><mi>&phi;</mi><mi>j</mi><mi>M</mi></msubsup><mo>}</mo><mo>)</mo></mrow><mn>2</mn></msup><mrow><mo>|</mo><mo>{</mo><msubsup><mi>&phi;</mi><mi>j</mi><mi>C</mi></msubsup><mo>}</mo><msup><mo>|</mo><mn>2</mn></msup><mo>|</mo><mo>{</mo><msubsup><mi>&phi;</mi><mi>j</mi><mi>M</mi></msubsup><mo>}</mo><msup><mo>|</mo><mn>2</mn></msup></mrow></mfrac></mrow>]]></math><img file="FDA0001016285830000013.TIF" wi="475" he="172" /></maths>其中<img file="FDA0001016285830000014.TIF" wi="192" he="71" />为结构第j阶计算得到的频率和振型,<img file="FDA0001016285830000015.TIF" wi="204" he="71" />为结构第j阶测量得到的频率和振型,<img file="FDA0001016285830000016.TIF" wi="150" he="63" />为权重系数；Δw<sub>j</sub>表示结构固有频率差值,<img file="FDA0001016285830000017.TIF" wi="142" he="71" />代表第j阶不完整振型对应的简化模态置信准则,NF和NM分别为选用的固有频率和振型的个数；3)利用BMO算法不断优化目标函数,直到满足设定的终止条件,得到识别结果,其具体过程为：初始化参数,包括算法的初始种群数量、最大迭代次数、算法中的鸟群不同繁殖方式所占的比例以及五种不同鸟类繁殖方式的算法；在初始化后计算种群的函数适应度值,并评价种群；选出适应度为最佳,即对应折损系数最大的后代；选择一次迭代以后符合条件的所有优秀后代,用后代替代掉原来种群中不好的后代,如此循环,不断地将解进行优化；记忆目前最好的解,直到算法结束为止。</td>   <td>G06F17/50;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卞静;              何宇行;                   田臻       </td>   <td>中山大学</td>   <td>一种基于社交网络的消息传播模型</td>   <td>广东</td>   <td>CN106096075A</td>   <td>2016-11-09</td>   <td>本发明公开一种基于社交网络的消息传播模型,是一种基于网络中人群的特殊行以及社交网络中结点的度平均值,对社交网络的消息传播进行建模分析并提出基于结点重要性的谣言免疫策略的方法。在小世界网络中建立的&lt;k&gt;#SLIR消息传播模型的动力学方程；使用本发明的方法能更真实地考虑社交网络中各种状态的结点对消息传播的影响,根据发明中提出的改进的基于结点重要性的谣言传播策略能更好地抑制谣言在社交网络中传播。</td>   <td>一种基于社交网络的消息传播模型,其特征在于,基于传染病传播SIR模型增添“潜伏结点”,构建SLIR模型；根据不同的网络特性,在社交网络中进行消息传播模型的构建,其中所述社交网络是指任意两个人接触的概率都相等的网络的均匀混合网络；具体为：将社交网络的人群分为四类,用S,L,I,R四种状态来描述易感结点,潜伏结点,感染结点以及免疫结点,其中易感结点代表了目前尚未知晓消息,但是接收到消息后会转变成为潜伏结点；潜伏结点会以不同的概率转化为感染结点以及免疫结点,其具有微弱的传播能力,能够传播消息；染结点具有很强的传播能力,且会以一定速率转化为免疫结点；免疫结点不再关心传播中的该条信息,不具有传播能力；在社交网络中,一个具有传播能力的结点把消息传播给该网络中的其他结点,做出三条合理的基本假设：1、在均匀混合网络中的结点是均匀混合的,一个具有传播能力的结点把消息传播给网络中任意一个结点的机会均等,任意处于感染态的传播结点可以把消息传递给任意处于易感态的结点；2、在社交网络中总人数不会发生变化；3、潜伏结点以及感染结点都知晓消息,都具有传播性,以[0,1]之间的数值来量化传播性,数值越大,传播性越强,其中传播态结点的传播性为1,当传播结点与易感结点接触的时候,易感结点知晓消息的概率为1；在上述3条基本假设下,设定如下的社交网络传播规则：(1)N为社交网络中结点总数,即社交网络中的总人数,一个传播性为1的传播结点,在单位时间内,平均与βN个易感结点接触并使得他们了解到在网络中传播的消息,其中β∈[0,1]；(2)在单位时间内,潜伏结点以概率κ转化为感染结点I,也会以概率δ转化为免疫结点R,其中κ+δ≤1且κ,δ∈[0,1]；(3)在单位时间内,感染结点以速率α转化为免疫结点,其中α∈[0,1]；(4)潜伏结点具有的传播能力远比感染结点弱,使用ε∈[0,1]来表示其传播性；基于上述的假设以及规则,在社交网络中建立的消息传播模型对各个状态的结点进行分析；易感结点S：易感结点与具有传播能力的结点接触时,将会以S/N的概率知晓消息；根据传播规则(1),在Δt时间内,社交网络中的所有感染结点与易感结点接触,使得βN·S/N·Δt·I个易感结点转变为潜伏结点；同时,由于潜伏结点也具有微弱的传播能力,所以在Δt时间内,易感结点与潜伏结点接触,使得ε·βN·S/N·Δt·L个易感结点转化为潜伏结点；因此,关于易感结点的变化率的微分方程如下：<maths num="0001"><math><![CDATA[<mrow><mfrac><mrow><mi>d</mi><mi>S</mi></mrow><mrow><mi>d</mi><mi>t</mi></mrow></mfrac><mo> =</mo><munder><mi>lim</mi><mrow><mi>&Delta;</mi><mi>t</mi><mo>&RightArrow;</mo><mn>0</mn></mrow></munder><mfrac><mrow><mi>S</mi><mrow><mo>(</mo><mi>t</mi><mo>+</mo><mi>&Delta;</mi><mi>t</mi><mo>)</mo></mrow><mo>-</mo><mi>S</mi><mrow><mo>(</mo><mi>&Delta;</mi><mi>t</mi><mo>)</mo></mrow></mrow><mrow><mi>&Delta;</mi><mi>t</mi></mrow></mfrac><mo> =</mo><mo>-</mo><mi>&beta;</mi><mi>S</mi><mi>I</mi><mo>-</mo><mi>&epsiv;</mi><mi>&beta;</mi><mi>S</mi><mi>L</mi><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0000999760890000021.TIF" wi="1211" he="119" /></maths>潜伏结点L：由于易感结点在接触到具有传播能力的结点时先转化为潜伏结点,所以在Δt时间内,潜伏结点增加的数量为(βSI+εβSL)·Δt；同时,根据规则(2),在Δt时间内,潜伏结点转化为感染结点的个数为κL·Δt,转化为免疫结点的个数为δL·Δt；因此,关于潜伏结点的变化率的微分方程如下：L'＝βS(I+εL)#(κ+δ)L####(2)感染结点I：根据潜伏结点的描述,在Δt时间内,有κL·Δt个潜伏结点转化为感染结点；同时,根据规则(3),有αI·Δt个感染结点转化为免疫结点；因此,关于感染结点的变化率的微分方程如下：I'＝κL#αI####(3)免疫结点R：根据潜伏结点以及感染结点的描述,在Δt时间内,有δL·Δt个潜伏结点转化为免疫结点,有αI·Δt个感染结点转化为免疫结点；因此,关于免疫结点的变化率的微分方程如下：R'＝δL+αI结合(1)～(3)式,采用(4)式对各个状态结点的变化进行描述：<maths num="0002"><math><![CDATA[<mrow><mfenced open = "{" close = ""><mtable><mtr><mtd><mrow><msup><mi>S</mi><mo>&prime;</mo></msup><mo> =</mo><mo>-</mo><mi>&beta;</mi><mi>S</mi><mi>I</mi><mo>-</mo><mi>&epsiv;</mi><mi>&beta;</mi><mi>S</mi><mi>L</mi></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>L</mi><mo>&prime;</mo></msup><mo> =</mo><mi>&beta;</mi><mi>S</mi><mrow><mo>(</mo><mi>I</mi><mo>+</mo><mi>&epsiv;</mi><mi>&beta;</mi><mi>L</mi><mo>)</mo></mrow><mo>-</mo><mrow><mo>(</mo><mi>&kappa;</mi><mo>+</mo><mi>&delta;</mi><mo>)</mo></mrow><mi>L</mi></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>I</mi><mo>&prime;</mo></msup><mo> =</mo><mi>&kappa;</mi><mi>L</mi><mo>-</mo><mi>&alpha;</mi><mi>I</mi></mrow></mtd></mtr><mtr><mtd><mrow><msup><mi>R</mi><mo>&prime;</mo></msup><mo> =</mo><mi>&delta;</mi><mi>L</mi><mo>+</mo><mi>&alpha;</mi><mi>I</mi></mrow></mtd></mtr><mtr><mtd><mrow><mi>S</mi><mrow><mo>(</mo><mn>0</mn><mo>)</mo></mrow><mo> =</mo><msub><mi>S</mi><mn>0</mn></msub><mo>,</mo><mi>L</mi><mrow><mo>(</mo><mn>0</mn><mo>)</mo></mrow><mo> =</mo><msub><mi>L</mi><mn>0</mn></msub><mo>,</mo><mi>I</mi><mrow><mo>(</mo><mn>0</mn><mo>)</mo></mrow><mo> =</mo><msub><mi>I</mi><mn>0</mn></msub><mo>,</mo><mi>R</mi><mrow><mo>(</mo><mn>0</mn><mo>)</mo></mrow><mo> =</mo><msub><mi>R</mi><mn>0</mn></msub></mrow></mtd></mtr><mtr><mtd><mrow><mi>S</mi><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>+</mo><mi>L</mi><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>+</mo><mi>I</mi><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>+</mo><mi>R</mi><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow><mo>&equiv;</mo><mi>N</mi></mrow></mtd></mtr></mtable></mfenced><mo>-</mo><mo>-</mo><mo>-</mo><mrow><mo>(</mo><mn>4</mn><mo>)</mo></mrow></mrow>]]></math><img file="FDA0000999760890000022.TIF" wi="1126" he="473" /></maths>式中S代表社交网络中的易感结点,L代表社交网络中的潜伏结点,I代表社交网络中的感染结点,R代表社交网络中的免疫结点；N代表了社交网络中的总人数,S<sub>0</sub>,L<sub>0</sub>,I<sub>0</sub>,R<sub>0</sub>表示的是消息开始传播的初始状态时,易感结点,潜伏结点以及免疫结点的初始数量；β代表了网络中易感节点与感染结点接触的概率,反映的是网络本身的性质；ε代表的是潜伏结点的微弱传播能力；κ是潜伏结点转化为感染结点的概率,δ是潜伏结点转化为其中α,β,ε,κ,δ∈(0,1)且κ+δ≤1。</td>   <td>G06F17/50;G06Q50/00;H04L12/58</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡浩;              柏杨;              刘冶;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司</td>   <td>一种对用户进行主题挖掘和应用推荐的方法</td>   <td>广东</td>   <td>CN106095776A</td>   <td>2016-11-09</td>   <td>本发明提供一种对用户进行主题挖掘和应用推荐的方法,该方法先定量计算出衡量用户所安装的某个应用对用户主题贡献的权重,根据权重来建立用户选择应用安装的模型,然后再计算出建立好的模型的参数即可模拟用户选择应用的过程并向用户推荐其意向的应用软件,实现了根据用户的安装应用列表挖掘出用户和应用的潜在特征的功能,以及对用户推荐其较感兴趣的应用的功能。</td>   <td>一种对用户进行主题挖掘和应用推荐的方法,其特征在于,包括以下步骤：S1：计算应用对用户主题贡献的权重；S2：建立用户在安装应用时选择过程的概率图模型；S3：求取概率图模型的参数,并完成主题的挖掘和应用的推荐。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王美华;              阳可欣;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司</td>   <td>一种犯罪识别与预测方法</td>   <td>广东</td>   <td>CN106096623A</td>   <td>2016-11-09</td>   <td>本发明提供一种犯罪识别与预测方法,该方法采用数据挖掘中数据预处理方法,针对犯罪信息诸如日期、街道地址、犯罪警区、星期、犯罪类别、犯罪说明、判刑处理等进行重构属性、特征提取、特征选择、挖掘出犯罪信息之间的关联性、产生最大化差异的特征因子及其与犯罪结果即犯罪类型之间的关联；然后构建融合了高斯朴素贝叶斯、神经网络、Logistic回归、正则回归、K近邻、随机森林、支持向量机、XGBoost学习算法的模型,得到基于加权投票分类器突出分类及聚类效果良好的元分类器进而对重构后数据进行分析处理识别及预测出城市未来的犯罪情况、绘制出城市个性犯罪图谱,进而达到促进和规范城市治安及管理的效果。</td>   <td>一种犯罪识别与预测方法,其特征在于,包括以下步骤：S1：对犯罪大数据进行样本平衡；S2：对进行样本平衡的样本进行数据预处理；S3：对预处理后的数据进行属性重构；S4：构建融合元分类器,并输入经属性重构后的数据得到识别和预测结果。</td>   <td>G06K9/62;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              李昊曦;              顾建权;                   胡伟鹏       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于双线性联合CNN的人脸验证方法</td>   <td>广东</td>   <td>CN106096535A</td>   <td>2016-11-09</td>   <td>本发明公开了一种基于双线性卷积神经网络的人脸验证方法。包括下述步骤：1)使用预先准备的人脸图像进行卷积神经网络(下简称CNN)的训练；2)使用训练集中的人脸图片,进行双线性CNN的微调；3)输入待验证的人脸图片,将两张图片进行切分,提取双线性CNN输出的联合特征。4)得到的向量经过一个自编码网络训练,得到最终的验证结果。本发明基于双线性的CNN的方法,并且通过将原始的双线性神经网络的两个重复输入替换成不同的人脸验证输入图像,提出了一种新的人脸验证描述子,它对光照,遮挡和姿态变化具有鲁棒性,且双线性CNN提取的特征比一般CNN全链接层特征维数更小,减少了参数量,从而使得后续的深度信念网络训练更加容易,提高人脸验证的准确率。</td>   <td>一种基于双线性联合CNN的人脸验证方法,其特征在于,包括以下步骤：(1)对输入的人脸图像,分别以多尺度矩形框截取人脸图像的多个部分的图像,作为CNN的输入,利用训练集中的人脸图像对CNN进行预训练,获得初始CNN模型；(2)将两个具有相同参数的初始CNN模型相结合形成新的双线性联合CNN；其卷积#池化层的初始化参数由上述步骤(1)给出,两个CNN模型各自的全链接层则替换为一个联合的三层全链接层,这个三层全链接层的输入是由两个初始CNN最后一层卷积#池化层输出矩阵相乘获得,最后一层的softmax多类分类器结构更换成用于判断是否为同一人脸的二分类器,然后这三层全链接层的参数均初始化为零均值方差为σ的高斯分布随机值；(3)将训练集中的人脸图像进行两两配对,然后分别输入新的双线性联合CNN的两端,根据分类训练结果对整个双线性CNN网络的所有参数进行微调(Fine#Tuning)；微调时每次先固定双线性CNN模型其中一边结构的参数,然后对另一边CNN模型的参数使用梯度下降法进行调整,经过多次迭代微调以后,获得用于人脸验证的双线性CNN模型；(4)将采用多尺度多通道多区域的方式所截取的参考人脸图像与检测人脸图像采用三层深度自编码网络进行特征二分类,最终输出人脸验证的识别准确率。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              潘瑜;              曹向前;                   胡伟鹏       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于分层网络流图的多目标跟踪方法</td>   <td>广东</td>   <td>CN106067179A</td>   <td>2016-11-02</td>   <td>本发明提供一种基于分层网络流图的多目标跟踪方法,该方法通过分层的网络流图模型,充分利用了轨迹的整体特征信息,将整个视频等分成若干个时间段作为第一层,在每个时间段建立网络流图,计算相邻目标间的关联值,用<i>K</i>条最短路径优化算法计算各时间内目标间的匹配关系,再逐步合并相邻的视频段形成新的一层,得到多目标跟踪的结果,减少了计算时间,提高了目标跟踪准确率。</td>   <td>一种基于改进网络流图的多目标跟踪方法,其特征在于,包括以下步骤：S1：采用DPM算法在视频的每帧中检测出运动目标,并保留每个运动目标的检测准确率；S2：将整个视频等分成若干个时间段作为第一层,在每个时间段建立网络流图,构建分层的网络流图模型；S3：计算第一层各时间段的网络流图中相邻目标的关联值,通过K条最短路径优化算法计算各关联值得到时间段内的匹配关系,确定当前层各目标的运动轨迹；S4：将固定数量的相邻时间段合并得到若干个较长时间段,形成新的一层,计算当前层各时间段网络流图中相邻轨迹的关联值；S5：在当前层各时间段内用K条最短路径优化算法计算各关联值,确定合并后的时间段中各目标的运动轨迹,重复S4、S5直至确定整个视频的运动轨迹。</td>   <td>G06T7/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李恺;              彭安基;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司</td>   <td>基于混合型平衡二阶可逆二维细胞自动机图像加密方法</td>   <td>广东</td>   <td>CN106056527A</td>   <td>2016-10-26</td>   <td>本发明提供一种基于混合型平衡二阶可逆二维细胞自动机图像加密方法,该方法对需加密图像I的RGB三个通道进行像素置乱得到一个N×24M的0#1矩阵I’；将N×24M的0#1矩阵I’矩阵分成若干8×16的0#1矩阵分组；构造混合型平衡二阶可逆二维细胞自动机对每个矩阵分组进行加密迭代；将加密后的分组组合成为加密后图像。</td>   <td>一种基于混合型平衡二阶可逆二维细胞自动机图像加密方法,其特征在于,包括以下步骤：S1：对需加密图像I的RGB三个通道进行像素置乱得到一个N×24M的0#1矩阵I’；S2：将N×24M的0#1矩阵I’矩阵分成若干8×16的0#1矩阵分组；S3：构造混合型平衡二阶可逆二维细胞自动机对每个矩阵分组进行加密迭代；S4：将加密后的分组组合成为加密后图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              顾建权;              李昊曦;                   杨梁       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于区域稀疏的单张训练样本人脸识别方法</td>   <td>广东</td>   <td>CN106056074A</td>   <td>2016-10-26</td>   <td>本发明公开一种基于区域稀疏表示的单张训练样本人脸识别方法,对训练样本采用重叠分块的方式进行分块,获得多个位置的人脸块；对于每一个位置相应的所有人脸块,引入外部的人脸数据,使用SVDL算法学习该位置的类间变化字典,且学习该位置的图像表示字典；对于待验证的人脸图像,将这些图像进行分块,使用每一个分块对应的位置字典求该分块的稀疏编码向量；利用稀疏编码向量求分块的权重；根据权重与编码向量,计算基于权重的最小残差,进行分类得到识别结果。本发明能够有效地获取人脸图像中的鉴别性特征,在单张训练样本情况下的人脸识别,对人脸的各种变化如：遮挡、表情、光照变化仍然保持很好的鲁棒性。</td>   <td>一种基于区域稀疏表示的单张训练样本人脸识别方法,其特征在于,包括：图像训练：(1)基于训练样本人脸图像,采用重叠的方式进行分块,每一幅图像相同位置的分块构成该位置的子集；(2)对于每一个位置的图像子集,训练该位置的图像表示字典,采集与训练图像不相关的图像作为外部数据,对这些图像做同样的分块处理,将这些互联网上的图像的每一个位置的分块结合训练样本该位置的分块利用SVDL算法训练外部字典,并结合训练样本的图像表示字典与外部字典；图像识别：(3)对于待分类的人脸图像,先进行重叠方式的分块,然后使用每一个分块对应的位置字典求该分块的稀疏编码向量；(4)利用每一个分块的稀疏编码向量求该分块的权重；(5)根据每一个分块的权重与编码向量,计算基于权重的最小残差进行分类得到正确的识别结果。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   张清柏       </td>   <td>中山大学</td>   <td>一种基于Contourlet变换的图像拼接检测方法</td>   <td>广东</td>   <td>CN106056600A</td>   <td>2016-10-26</td>   <td>本发明提供一种基于Contourlet变换的图像拼接检测方法,利用Contourlet变换能够很好的描述图像中的轮廓和方向性纹理信息的优点,首先对训练图像进行Contourlet变换后提取Markov特征,并使用基于支持向量机的回归特征消除方法SVM#RFE对特征集进行降维,提升检测效率和准确率,使用降维后的特征集训练找到最优参数并得到SVM分类模型,然后对测试图像提取相应的特征向量,使用得到的分类模型对测试图像的特征向量进行分类预测,得到测试图像是否经过拼接操作的判断结果。本发明在一种新的变换域提取特征,具有很好的检测效率和准确率。</td>   <td>一种基于Contourlet变换的图像拼接检测方法,其特征在于,包括以下步骤：S1：选取图像训练集：训练集包含没有经过任何篡改操作的原始图像和经过拼接篡改的拼接图像；S2：对训练图像进行Contourlet变换：对于图像训练集的每一张图像,分别进行相同的Contourlet变化,使用k层的Contourlet分解,相应的每层金字塔方向滤波器DFB的向量个数设为{f1,f2,…,fn},每层分解会得到对应{2<sup>f1</sup>,2<sup>f2</sup>,…,2<sup>fn</sup>}个系数子带,并且第一层分解时,会额外得到一个低通系数子带,因此一共得到K＝1+2<sup>f1</sup>+2<sup>f2</sup>+…+2<sup>fn</sup>个系数子带,每个子带为一个系数矩阵；S3：提取Markov特征：针对每张图像的每个系数子带提取Markov特征,先将系数子带矩阵的每个系数取整和取绝对值,再按照水平方向和垂直方向计算其差分矩阵,会得到两个差分矩阵,对每个差分矩阵的系数,使用阈值T进行截断操作,大于T的系数全部替换为T,小于#T的系数全部替换为#T,然后对每个差分矩阵计算其水平方向和垂直方向的Markov转移概率矩阵,将得到的4个Markov转移概率矩阵连在一起作为该系数子带的特征向量,再将每张图像的所有系数子带的特征向量连接在一起,得到该图像的Markov特征向量；S4：训练特征准备：得到训练集所有图像的特征向量后,将原始图像的特征向量标识为+1,将拼接图像的特征向量标识为#1,将两类特征集作为SVM的特征训练集,特征集每行对应一张图像的特征向量,每列对应一种特征；S5：SVM#RFE降维：使用基于支持向量机的回归特征消除方法SVM#RFE对特征训练集的每一列特征进行排序,得到特征排序列表,按照特征排序列表对每张图像的特征向量选择前n个特征值构成新的特征向量,进而组成一个新的特征向量集；S6：寻找最优的惩罚参数c和核参数g并训练得到分类器：对降维后得到的特征向量集和相应的标识集使用径向基内核的SVM训练,使用网格搜索的方法搜索最优的惩罚参数c和核参数g,得到分类器模型；S7：测试图像提取特征：对测试图像进行与上面训练图像相同的Contourlet变换,对得到的每个系数子带提取Markov特征得到特征向量,即进行类似S2和S3的操作,然后按照S5得到的特征排序列表选取前n个特征值,得到测试图像的特征向量；S8：分类预测：加载S6得到的SVM分类模型,对S7得到的测试图像的特征向量进行分类预测,得到预测结果,+1代表测试图像为原始图像,#1代表测试图像为拼接图像。</td>   <td>G06T7/00;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   李静伟       </td>   <td>中山大学</td>   <td>一种基于KAZE特征点的图像区域复制粘贴篡改检测方法</td>   <td>广东</td>   <td>CN106056122A</td>   <td>2016-10-26</td>   <td>本发明提供一种基于KAZE特征点的图像区域复制粘贴篡改检测方法。首先对彩色图像提取KAZE特征点,然后将这些特征点用64维特征向量描述。接下来计算每个特征向量和剩下特征向量之间的欧式距离,利用最近邻距离和次近邻距离之间的比值,找到相似的特征向量,作为匹配对。然后使用SLIC算法对图像进行语义分割,滤除错误的匹配对。通过匹配对在图像中的位置关系,使用迭代的思想,估计篡改区域之间的仿射变换关系,得到仿射矩阵。最后通过仿射矩阵,计算原始图像和变换后图像之间的相关系数图,并且定位篡改区域。本发明使用了一种新型的特征点提取算法,并且使用迭代的方法求仿射矩阵,具有很好的检测准确率。</td>   <td>一种基于KAZE特征点的图像区域复制粘贴篡改检测方法,其特征在于,包括以下步骤：S1：KAZE特征点提取：对于待检测的图像,采用加性算子分裂算法AOS算法和可变传导扩散方法来构造非线性尺度空间,然后检测感兴趣特征点,这些特征点在非线性尺度空间上经过尺度归一化后的Hessian矩阵行列式是局部极大值；S2：特征点描述：根据步骤S1得到的特征点,若特征点的尺度参数为σ<sub>i</sub>,则搜索半径设为6σ<sub>i</sub>；对搜索圈内所有邻点的一阶微分值L<sub>x</sub>和L<sub>y</sub>通过高斯加权,使得靠近特征点的响应贡献大,而远离特征点的响应贡献小；将这些微分值视作向量空间中的点集,在一个角度为π/3的扇形滑动窗口内对点集进行向量叠加,遍历整个圆形区域；获得最长向量的角度就是主方向；在梯度图像上以特征点为中心取24σ<sub>i</sub>×24σ<sub>i</sub>的窗口,并将窗口划分为4×4子区域,在每个子区域上进行高斯核加权,然后计算出长度为4的子区域描述向量d<sub>v</sub>＝(∑L<sub>x</sub>,∑L<sub>y</sub>,∑|L<sub>x</sub>|,∑|L<sub>y</sub>|),再通过另一个大小为4×4的高斯窗口对每个子区域的向量d<sub>v</sub>进行加权,最后进行归一化处理,得到4×4×4＝64维的描述向量；S3：特征匹配：对于步骤S2中提取出来的每个特征,计算其与其它所有特征向量之间的欧式距离,并按照从小到大排序；计算最近邻d<sub>1</sub>和次近邻d<sub>2</sub>之间的比值,如果比值小于0.5,则认为距离为d<sub>1</sub>的两个特征匹配；S4：错误匹配对滤除：使用SLIC算法对输入的彩色图像进行语义分割,得到有意义的图像块；统计每个块中匹配特征点的个数N<sub>point</sub>,如果N<sub>point</sub>小于3,则将块中的特征点连同其匹配点判断为离异点并删除；S5：仿射矩阵估计：任取三对不共线的匹配对,计算它们之间的仿射变换矩阵T<sub>i</sub>,并将剩下的匹配点根据T<sub>i</sub>进行变换,计算变换前后匹配点对之间的误差；如果误差小于β,则这个矩阵T<sub>i</sub>获得一票；将前述步骤迭代多次,每次选出得票数最多的矩阵,直到最后剩下的矩阵票数不超过5为止；S6：可疑区域定位：对于原始图像I,使用步骤S5得到的仿射矩阵进行坐标变换,得到变换后的图像M；计算原始图像与变换后图像相应位置之间的相关系数,得到代表相似度的相关系数图；相关系数的取值范围在[0,1]之间,值越大代表越相似；对于得到的相关系数图进行二值化处理,二值化阈值为0.55；如果相关系数值大于0.55,则认为本位置的点为可疑点,其二值图相应位置的值设为1,否则设为0；最后将得到的二值图进行形态学操作以滤除杂乱点,生成最终的检测结果图。</td>   <td>G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         柏杨;              胡浩;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司</td>   <td>一种基于命名实体的社交网站好友推荐方法</td>   <td>广东</td>   <td>CN106055616A</td>   <td>2016-10-26</td>   <td>本发明提供一种基于命名实体的社交网站好友推荐方法,该方法建立由用户发言中的实体和其关注者发言中的实体组成的一个实体列表ConEntity(ui),建立用户个人信息的实体列表InfEntity(ui),并根据得到的实体列表ConEntity(ui)和InfEntity(ui)对用户的偏好的实体进行排序得到偏好度排序的实体列表,通过用户间实体列表的相似程度对社交网络中的用户进行兴趣相似的好友推荐。</td>   <td>一种基于命名实体的社交网站好友推荐方法,其特征在于,包括以下步骤：S1：对候选用户集U中的用户u<sub>i</sub>及其关注者的发言文本进行预处理并进行命名实体的识别和连接,得出由用户u<sub>i</sub>发言中的实体和其关注者发言中的实体组成的一个实体列表ConEntity(u<sub>i</sub>)；S2：对用户u<sub>i</sub>进行个人信息提取并进行命名实体的识别和连接,得出关于用户u<sub>i</sub>个人信息的实体列表InfEntity(u<sub>i</sub>)；S3：根据得到的实体列表ConEntity(u<sub>i</sub>)和InfEntity(u<sub>i</sub>)对用户u<sub>i</sub>的偏好的实体进行排序,得到一个偏好度排序的实体列表UserEntity(u<sub>i</sub>)；S4：利用每个用户的UserEntity(u<sub>i</sub>)进行相似度对比,选取最高相似度的用户进行相互推荐。</td>   <td>G06F17/30;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张雨浓;              张德阳;              马景耀;              丁亚琼;                   谭洪舟       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种电力负荷预测的方法</td>   <td>广东</td>   <td>CN106056233A</td>   <td>2016-10-26</td>   <td>本发明属于电力负荷的预测、管理和控制领域,具体为一种电力负荷预测的方法,涉及数据采集模块、学习模块和预测模块。数据采集模块负责采集采集电力负荷的历史数据,并对数据进行筛选,得出负荷时间序列Y,然后对负荷时间序列Y进行归一化处理得出预处理序列O。学习模块负责对预处理序列O进行学习得出预测正弦函数模型W(t)。预测模块根据预测正弦函数模型求出预测数据序列F。本发明基于分析电力负荷的这一周期性变化趋势的特点,采用正弦函数模型作为预测数据的基础模型,与现有技术相比,具有贴合电力负荷数据实际变化的优点,为了克服采用正弦函数作为基础模型误差相对较大的缺点,本发明还采用重复学习的方法,提高预测的准确性。</td>   <td>一种电力负荷预测的方法,其特征在于：涉及数据采集模块、学习模块和预测模块,上述模块执行以下步骤：(a)数据采集模块按时间顺序采集电力负荷的历史数据,得出负荷时间序列Y,对负荷时间序列Y进行归一化处理,得出预处理序列O；(b)学习模块将预处理序列O拟合得出一个正弦函数S(t),根据正弦函数S(t)得出基础序列L<sub>1</sub>,(c)学习模块将预处理序列O和基础序列L<sub>1</sub>相减得出基础残差序列e；(d)学习模块求出基础残差序列e的均方根误差,将该均方根误差与预设的阀值对比；若小于预设阀值,则正弦函数S(t)为预测正弦函数模型W(t),预测模块根据预测正弦函数模型W(t)得出预测序列f,并对预测序列f进行反归一化处理,得出预测数据序列F；若大于预设阀值,则继续执行以下步骤(e)至(g)；(e)学习模块对基础残差序列e进行拟合,得出残差正弦函数Q(t),根据残差正弦函数Q(t)得出残差序列M；(f)学习模块求出残差序列M的均方根误差,将该均方根误差与预设的阀值对比；若小于预设阀值,则将正弦函数S(t)和残差正弦函数Q(t)叠加,得出预测正弦函数模型W(t),预测模块根据预测正弦函数模型W(t)得出预测序列f,并对预测序列f进行反归一化处理,得出预测数据序列F；若大于预设阀值,则进入重复学习步骤：根据残差序列M<sub>i</sub>(i＝1,2,3,…,n),拟合得出预测残差正弦函数P<sub>i</sub>(t)(i＝1,2,3,…,n),根据P<sub>i</sub>(t)得出预测残差序列N<sub>i</sub>,利用公式M<sub>+1</sub>＝M<sub>i</sub>#N<sub>i</sub>,求出下一个残差序列M<sub>i+1</sub>,根据M<sub>i+1</sub>拟合得出P<sub>i+1</sub>(t),根据P<sub>i+1</sub>(t)得出预测残差序列N<sub>i+1</sub>；每次运算得出的预测残差序列N<sub>i</sub>后,计算该预测残差序列N<sub>i</sub>均方根误差,将该均方根误差与预设的阀值对比,若小于预设阀值,则停止重复学习步骤,若大于预设阀值,则继续重复学习步骤；(g)停止重复学习步骤后,将正弦函数S(t)和与残差正弦函数Q(t)和所有预测残差正弦函数P<sub>i</sub>(t)叠加,得出预测正弦函数模型W(t),预测模块根据预测正弦函数模型W(t)得出预测序列f,并对预测序列f进行反归一化处理,得出预测序列F。</td>   <td>G06Q10/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈湘萍;              周凡;              林格;                   蔡驰鹏       </td>   <td>中山大学</td>   <td>一种面向数字家庭的社区网络服务系统</td>   <td>广东</td>   <td>CN106056485A</td>   <td>2016-10-26</td>   <td>本发明实施例公开了一种面向数字家庭的社区网络服务系统,所述系统包括：服务组件引擎模块,用于对社区网络中的服务资源进行文档渲染、格式转换、业务流程封装、全真还原、组件验证、组件制定；资源解析引擎模块,用于对社区网络中的服务资源进行解析；社区网络服务管理模块,用于对社区网络服务进行分类并对社区网络服务所属类别进行管理；社区网络服务发布模块,用于对所分类的各类社区网络服务资源进行信息发布；广告发布模块,用于发布社区网络服务的相关广告信息。实施本发明实施例中,可以提高数据处理能力,根据用户需求为社区用户提供各种服务资源；采用分布式存储和计算技术,实现对海量数据的分析处理,满足海量数据的实时性处理要求。</td>   <td>一种面向数字家庭的社区网络服务系统,其特征在于,所述系统包括：服务组件引擎模块,用于对社区网络中的服务资源进行文档渲染、格式转换、业务流程封装、全真还原、组件验证、组件制定；资源解析引擎模块,用于对社区网络中的服务资源进行解析；社区网络服务管理模块,用于对社区网络服务进行分类并对社区网络服务所属类别进行管理；社区网络服务发布模块,用于对所分类的各类社区网络服务资源进行信息发布；广告发布模块,用于发布社区网络服务的相关广告信息。</td>   <td>G06Q50/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              顾建权;              李昊曦;                   肖翔       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于深度学习与字典表示的跨年龄人脸验证方法</td>   <td>广东</td>   <td>CN106022287A</td>   <td>2016-10-12</td>   <td>本发明公开一种基于深度学习与字典表示的跨年龄人脸验证方法,包括：对待验证的人脸图像进行关键点标定,获得人脸关键点；提取每一个关键点对应的局部区域人脸块,获得各关键点对应的局部人脸块；将局部人脸块输入到已经训练好的深度卷积神经网络中,提取这些局部人脸块的高层次特征,每个人脸块可获得一个多维向量表示该人脸块的高层次特征；采集多幅图像,对这些外部数据做上述操作,提取每个类的每个区域的每个年龄的特征,构成外部数据参考集；求训练图像和测试图像在外部数据参考集上的编码向量；根据每一个分块在外部数据参考集上的编码向量,利用余弦相似度的最小和得到正确的识别结果。</td>   <td>一种基于深度学习与字典表示的跨年龄人脸验证方法,其特征在于,包括以下步骤：(1)对于待验证图像,采用人脸关键点定位的方法,定位出若干个关键点,提取所有关键点对应的局部人脸块；(2)对于每一个关键点的局部人脸块,训练该局部人脸块对应的深度学习框架,每个局部人脸块的深度学习框架都是独立的,提取人脸块的高层次特征向量,每个局部人脸块的高层次特征向量为一个M维向量；(3)采集跨年龄的人脸图像作为外部数据,对这些人脸图像做步骤(1)、(2)的操作,获得每个人脸图像的关键点的局部人脸块的高层次特征向量,将所有脸图像的每个关键点的局部人脸块的相同年龄段的特征构成一个字典,设定N个年龄段,即有N个年龄段的字典；(4)求待验证的人脸图像的每个关键点的局部人脸块的高层次特征向量在每一个年龄段的字典上的编码向量；(5)人脸图像的每个关键点的每个局部人脸块都获得N个编码向量,构成一个M*N的编码向量矩阵,对这个编码向量矩阵采用最大池化方式池化成一个M维向量,即对编码向量矩阵的每一行取最大的元素作为新的M维向量对应行的元素,这个新的M维向量就作为这个人脸图像的最终编码向量；(6)对人脸图像的若干个人脸块的N个编码向量采用余弦相似度计算两幅图像的相似性验证。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘威;              骆金昌;                   印鉴       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司;广州智海纵横信息科技有限公司</td>   <td>将文本和地理信息融合在局部协同排列的兴趣点推荐方法</td>   <td>广东</td>   <td>CN106021456A</td>   <td>2016-10-12</td>   <td>本发明公开一种将文本和地理信息融合在局部协同排列的兴趣点推荐方法,包括以下步骤：S1.输入训练集,随机生成锚点；S2.根据隐特征向量、空间特征和主题特征计算出用户POI与锚点的相似度；S3.每个锚点代表一个子矩阵,根据上一步得到相似度,找到与锚点之间相似度大于预设阈值的(用户#兴趣点)对作为子矩阵中的成员,为每个子矩阵随机初始化用户特征向量和POI特征向量；S4.采集用户、位置点；S5.计算梯度,更新用户特征向量和POI特征向量；S6.判断是否满足终止迭代条件,满足跳转到步骤S7；不满足终止迭代条件,跳转到步骤S4；S7.根据用户特征向量和POI特征向量,估计用户对POI的喜好值；S8.对喜好值进行排序,为用户生成推荐列表。</td>   <td>一种将文本和地理信息融合在局部协同排列的兴趣点推荐方法,其特征在于,包括以下步骤：S1.输入训练集D<sub>s</sub>,随机生成锚点,每个锚点由结构为(用户#兴趣点POI)的数据组成的对(pair)；S2.根据隐特征向量、空间特征和主题特征计算出(用户#兴趣点POI)对与锚点的相似度；S3.基于锚点选出一个子矩阵,具体是根据上一步得到相似度,找到与锚点之间相似度大于预设阈值的结构(用户#兴趣点POI)作为子矩阵中的成员,为每个子矩阵随机初始化用户特征向量和POI特征向量；S4.从训练集D<sub>s</sub>中采样用户u,用户u去过的兴趣点v<sub>i</sub>和用户u没有去过的兴趣点v<sub>j</sub>；S5.计算梯度,更新用户特征向量和POI特征向量；S6.判断是否满足终止迭代条件,如果满足,跳转到步骤S7；如果不满足终止迭代条件,则跳转到步骤S4；S7.根据每个子矩阵中的用户特征向量和POI特征向量,估计用户对POI的喜好值；S8.对喜好值进行排序,为用户生成推荐列表。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘凯;              刘洋;              朱远辉;                   柳林       </td>   <td>中山大学</td>   <td>基于梯度滤波和PCA的无人机影像与多光谱影像融合方法</td>   <td>广东</td>   <td>CN106023130A</td>   <td>2016-10-12</td>   <td>本发明公开一种基于梯度滤波和PCA的无人机影像与多光谱影像融合方法。其首先经过影像配准、重采样至相同像元尺寸,裁剪得到相同空间范围的两套独立的多波段影像,分别为波段数目大但空间分辨率低的多光谱遥感影像与三波段高空间分辨率的无人机影像；然后对两套多波段影像采用相关系数矩阵分别进行主成分变换；进一步地,对无人机影像的全部主成分选取特定的滤波算子进行梯度滤波获取其三个主成分的纹理信息,并将其以一定权重叠加至波段数目大但空间分辨率低的多光谱影像的前三个主成分中进行增强；最后对增强后的主成分进行主成分逆变换获得波段数目大同时空间分辨率高的多光谱融合结果。本方法扩展了传统融合方法的单波段全色数据与多光谱影像融合的局限性,可以使更多样的数据参与影像融合,实现融合结果更丰富的空间细节信息。</td>   <td>一种基于梯度滤波和主成分变换的三波段无人机光学影像与多光谱遥感影像融合方法,其特征在于,包括：S11.经过影像配准、重采样至相同像元尺寸,裁剪得到相同空间范围的两套独立的多波段影像,分别为波段数目大但空间分辨率低的多光谱遥感影像与三波段高空间分辨率的无人机影像；S12.对两套多波段影像采用相关系数矩阵分别进行主成分变换；S13.对无人机影像的全部主成分选取特定的滤波算子进行梯度滤波获取其三个主成分的纹理信息；S14.对无人机影像主成分的纹理信息以一定权重叠加至波段数目大但空间分辨率低的多光谱影像的前三个主成分中进行增强；S15.对增强后的主成分进行主成分逆变换获得波段数目大同时空间分辨率高的多光谱融合结果。</td>   <td>G06T5/50;G06T7/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         衣杨;              关山;              周晓聪;              龙东阳;                   陈弟虎       </td>   <td>中山大学</td>   <td>一种自然场景视频识别方法</td>   <td>广东</td>   <td>CN105989358A</td>   <td>2016-10-05</td>   <td>本发明属于计算机视觉领域,尤其是涉及一种自然场景视频识别方法,该方法具体包括以下步骤：1)生成特征点轨迹描述符；2)生成局部时空描述符；3)词袋模型表示视频序列；4)预测摄像头的状态；5)选择适应特征融合；本发明采用基于轨迹相异度度量和ROI检测的方法,有效地移除来自背景的特征点轨迹；还提出了自适应的特征融合方法,根据摄像头的动静情况,选择性地对这两类描述符加以组合,显著地提高算法的识别效果。</td>   <td>一种自然场景视频识别方法,其特征在于,包括以下步骤：A：生成特征点轨迹描述符：通过特征点跟踪产生候选的特征点轨迹,然后采用基于轨迹相异度度量和ROI检测的轨迹剪除方法,去除由特征点误匹配或者背景变化而产生的轨迹,最后针对剪除后的可靠轨迹计算和提取一系列对尺度、平移、旋转等具有不变性的轨迹描述符；B：生成局部时空描述符：采用基于帧间差分法结合多方向Gabor滤波的方法,对视频序列进行时空兴趣点检测,再通过视频立方块提取和主成分分析特征降维方法,对兴趣点提取局部时空描述符；C：词袋模型表示视频序列：采用传统的词袋模型表示方法,将视频序列表示为视觉词语直方图；D：预测摄像头的状态：采用简化的光流法对视频片段中的所有帧计算整体光流,从而预测摄像头的状态；E：选择适应特征融合：根据预测的结果,对基于轨迹的描述符和基于时空兴趣点的描述符这两者进行选择性地融合。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              谢晓华;                   雷云       </td>   <td>中山大学</td>   <td>基于光场相机的人脸活体检测方法</td>   <td>广东</td>   <td>CN105975926A</td>   <td>2016-09-28</td>   <td>本发明公开了一种基于光场相机的人脸活体检测方法,包括：(1)光场相机原始数据的提取与解码；(2)从光场数据中提取面部不同深度的重对焦图像；(3)从重对焦图像中提取聚焦特征和功率谱特征,连接两种特征作为该人脸图像的综合特征；(4)对采集到的所有光场图像提取上述综合特征,将训练集的综合特征输入支持向量机训练,得到可用于人脸活体检测的模型；然后将待检测的图像的综合特征输入训练好的模型,得到检测结果。本发明利用光场相机一次拍照后可获得不同深度重对焦图像的特点,从中提取人脸重对焦变化特征来进行人脸活体检测,对比传统的人脸活体检测方法,本发明检测结果准确,检测效率更高,更为简单便利,符合实际应用的要求。</td>   <td>一种基于光场相机的人脸活体检测方法,其特征在于,包括下述步骤：(1)光场相机原始数据的提取与解码,通过微透镜中心标定、Bayer格式解码、六边形#正交格点校正的步骤从Lytro光场相机中提取原始光场数据并进行色彩校正；(2)通过数字重对焦,从光场数据中提取出两张对焦在面部不同深度的重对焦图像；(3)综合两张不同深度的重对焦图像,分别提取聚焦特征和功率谱特征,将两种特征连接在一起作为该人脸图像的综合特征；(4)对采集到的所有光场图像提取上述综合特征,将训练集的综合特征输入支持向量机训练,支持向量机模型选择径向基函数,得到可用于人脸活体检测的模型,然后将待检测的图像的综合特征输入训练好的模型,得到检测结果。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李明;                   刘静       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>可穿戴眼动仪第一视角视频图像分析方法</td>   <td>广东</td>   <td>CN105975928A</td>   <td>2016-09-28</td>   <td>本发明涉及一种可穿戴眼动仪第一视角视频图像分析方法,包括以下部分：数据预处理：绘制出眼睛关注点坐标与第一视角视频图像帧的关系图,找出跳变点所对应的视频图像帧,并在第一视角视频图像帧原始数据中筛选掉跳变点所对应的视频图像帧；数据分析：对通过数据预处理的第一视角视频图像数据进行分析；所述数据分析的具体步骤为：S1、相机标定：对第一视角视频图像进行矫正；S2、图像分割：检测并提取出图像中被试者所关注的目标区域；S3、物体识别：对目标区域进行有效识别。本发明能有效检测并识别被试者所注视的目标区域,并对注视点位置进行自动标识。</td>   <td>一种可穿戴眼动仪第一视角视频图像分析方法,其特征在于,包括以下部分：数据预处理：绘制出眼睛关注点坐标(x,y)与第一视角视频图像帧的关系图,找出跳变点所对应的视频图像帧,并在第一视角视频图像帧原始数据中筛选掉跳变点所对应的视频图像帧；数据分析：对通过数据预处理的第一视角视频图像数据进行分析；所述数据分析的具体步骤为：S1、相机标定：对第一视角视频图像进行矫正；S2、图像分割：检测并提取出图像中被试者所注视的目标区域；S3、物体识别：对目标区域进行有效识别。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李明;                   郭利锋       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种纯光学指纹活体检测方法</td>   <td>广东</td>   <td>CN105975936A</td>   <td>2016-09-28</td>   <td>本发明涉及一种光学指纹活体检测方法,包括以下步骤：数据采集：采集手指按压过程的一组连续指纹图片；数据筛选：对连续指纹图片的副本做一系列的前景分割步骤,找到前景区域最大的两幅连续指纹图片；活体静态质量检测：对筛选出来的两幅指纹图片中的一副进行脊线强度、方向相关性、局部能量、均值方差等特性的检测,确定质量是否符合标准；动态活体检测：对满足静态质量检测的两幅图片做差图,确定指纹的活体性。本发明通过设置数据采集、数据筛选、活体静态质量检测和动态活体检测来对指纹数据进行有效采集和分析处理,有效判别指纹的活体性,大大提高了纯光学指纹识别仪的识别精度,可有效筛选掉伪指纹。</td>   <td>一种纯光学指纹活体检测方法,其特征在于,包括以下步骤：数据采集：利用光学指纹识别仪采集手指按压过程的一组连续指纹图片；数据筛选：对连续指纹图片的副本进行前景分割,找到前景区域最大的连续指纹图片f1和f2；活体静态质量检测：对筛选出来的指纹图片f1和f2的脊线强度、方向相关性、局部能量、均值方差进行检测；动态活体检测：将通过活体质量检测的两幅指纹图片做差求出差图f,对差图f的强度特性、能量特性、方向特性等进行检测,最终确定指纹活体性。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高连如;              苏远超;              孙旭;              李军;                   张兵       </td>   <td>中国科学院遥感与数字地球研究所;中山大学</td>   <td>一种高光谱图像端元提取方法及系统</td>   <td>北京</td>   <td>CN105976357A</td>   <td>2016-09-28</td>   <td>本发明公开了一种高光谱图像端元提取方法及系统,将高光谱图像端元提取问题中的优化变量对应人工蜂群算法中的蜜源位置,每个蜜源的优化由适应度函数决定。采蜜蜂搜寻最优蜜源,并在搜索完成后将蜜源信息给跟随蜂,跟随蜂第二次搜寻最优蜜源,并利用选取最优蜜源更新之前获得的最优解,当存在预设时间段内没有更新蜜源的采蜜蜂时,将该采蜜蜂转换为侦查蜂,侦查蜂通过将随机选取蜜源的适应度值与作为最优解的蜜源的适应度值比较,对作为最优解的蜜源进行校验。本发明以人工蜂群算法为基础,将端元提取问题转化为组合优化问题的求解过程,充分发挥人工蜂群算法的优点,并通过侦查蜂对最优解的蜜源进行校验,降低优化过程陷入局部最优解的风险。</td>   <td>一种高光谱图像端元提取方法,其特征在于,包括：获取高光谱图像中的候选端元,并确定适应度函数；初始化参数,包括,采蜜蜂数量m,跟随蜂数量m,最大迭代次数maxIter；在可行解空间中随机产生m个可行解,每一个所述可行解作为一只采蜜蜂对应的蜜源；采蜜蜂随机选择一个蜜源作为当前第一蜜源,根据搜寻函数在所述当前第一蜜源的邻域内搜寻第一新蜜源,利用所述适应度函数计算所述第一新蜜源的适应度值,并选择所述当前第一蜜源和所述第一新蜜源中适应度值大的替换所述当前第一蜜源；采蜜蜂分享蜜源信息给跟随蜂；跟随蜂按照跟随概率选择采蜜蜂,将该采蜜蜂最新的当前第一蜜源作为当前第二蜜源,根据所述搜寻函数在所述当前第二蜜源的邻域内二次搜寻第二新蜜源,利用所述适应度函数计算所述第二新蜜源的适应度值,并选择所述当前第二蜜源和所述第二新蜜源中适应度值大的蜜源替换所述当前第二蜜源；利用跟随蜂选取的蜜源更新之前获得的最优解；判断m个采蜜蜂中在预设时间段内是否有没有更新蜜源的采蜜蜂；如果存在没有更新蜜源的采蜜蜂,则将所述预设时间段内没有更新蜜源的采蜜蜂转换为侦查蜂；侦查蜂在搜索空间中随机选取一个蜜源作为当前第三蜜源,根据所述搜寻函数在所述当前第三蜜源的邻域内搜寻第三新蜜源,利用所述适应度函数计算所述第三新蜜源的适应度值；判断所述第三新蜜源的适应度值是否小于所述第三蜜源的适应度值；如果小于所述第三蜜源的适应度值,则将跟随蜂选取的蜜源作为当前最优解,并判断当前迭代次数是否达到所述最大迭代次数maxIter；如果不小于所述第三蜜源的适应度值,则将该侦查蜂转换为采蜜蜂,继续搜寻新蜜源；如果不存在没有更新蜜源的采蜜蜂,则判断当前迭代次数是否达到所述最大迭代次数maxIter；如果达到所述最大迭代次数maxIter,则输出端元提取结果；如果没有达到所述最大迭代次数maxIter,则采蜜蜂继续搜寻新蜜源。</td>   <td>G06T7/00;G06T7/40;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘荻;              刘冶;              王砚文;              陈宇恒;              印鉴;                   马朔       </td>   <td>中山大学;广州火烈鸟网络科技有限公司</td>   <td>一种消息过滤的方法及装置</td>   <td>广东</td>   <td>CN105955951A</td>   <td>2016-09-21</td>   <td>本发明涉及一种消息过滤的方法,利用贝叶斯分类器模型计算消息为不良消息的概率,根据所述不良消息的概率判断消息的性质,该消息的性质包括正常消息、不良消息和可疑消息,直接过滤掉不良消息,保留正常消息和可疑消息,再利用基于语义的深度学习模型进一步分类,确定消息为正常消息或者不良消息。相对于现有技能,本发明能够自动学习,定时更新训练集并且识别近义词,节省大量人工标注的成本,具有更好的准确率、健壮性和稳定性。另外,本发明还提供了一种消息过滤的实现装置。</td>   <td>一种消息过滤的方法,其特征在于：包括步骤：S1：利用贝叶斯分类器模型计算消息为不良消息的概率；S2：根据所述不良消息的概率判断消息的性质,该消息的性质包括正常消息、不良消息和可疑消息,直接过滤掉不良消息,保留正常消息和可疑消息；S3：对所述性质为正常的和可疑的消息,利用基于语义的深度学习模型进一步分类,确定消息为正常消息或者不良消息。</td>   <td>G06F17/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              曹杨宇;              粟涛;                   衣杨       </td>   <td>中山大学</td>   <td>基于二次折射投影模型的鱼眼图像校正方法、装置和系统</td>   <td>广东</td>   <td>CN105956996A</td>   <td>2016-09-21</td>   <td>本发明公开了一种基于二次折射投影模型的鱼眼图像校正方法、装置和系统,该校正方法包括：所述鱼眼图像一坐标点的光线沿第一方向进入第一球冠面；所述光线在所述第一球冠面折射后沿第一入射角进入第二球冠面,经所述第二球冠面折射后沿所述第二球冠面的半径方向投射在承接面上；根据所述发光点在所述承接面上的投影点的坐标计算发光点的坐标。本发明实施例提供的基于二次折射投影模型的鱼眼图像校正方法、装置和系统仅使用四则运算和开方运算,图像校正的运算量较少,校正速度快,便于用硬件实现,而且能实现较好的校正效果。在实际应用中,还可以采用不同的承接面来适应各种应用场合。</td>   <td>一种基于二次折射投影模型的鱼眼图像校正方法,其特征在于,包括如下步骤：所述鱼眼图像一坐标点的光线沿第一方向进入第一球冠面,其中,所述第一方向与所述第一球冠面的顶点、第二球冠面的顶点之间的连线平行,所述鱼眼图像设于投影面内,所述投影面与所述第一球冠面的底面平行并且经过所述第一球冠面的球心；所述光线在所述第一球冠面折射后沿第一入射角进入第二球冠面,经所述第二球冠面折射后沿所述第二球冠面的半径方向投射在承接面,其中,所述第一入射角为所述光线与所述第二球冠面的球心以及所述第二球冠面的顶点连线之间夹角的一半；根据所述发光点在所述承接面的投影点的坐标计算所述发光点的坐标。</td>   <td>G06T3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              肖翔;              张伟;                   顾建权       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于密集轨迹的动作识别方法</td>   <td>广东</td>   <td>CN105956517A</td>   <td>2016-09-21</td>   <td>本发明公开一种基于密集轨迹的动作识别方法,包括：1)对输入视频每一帧的用密集采样法获取密集点,并对密集点在光流域中进行跟踪,形成该视频的轨迹；2)对轨迹进行筛选,提取位于中心区域的轨迹视作前景的轨迹,将区域外的轨迹视作背景轨迹进行删除；3)提取轨迹的形状特征,梯度方向直方图特征,光流直方图特征,运动边缘直方图特征,以及运动邻域特征；4)对每一种特征分别采用增强型局部级联描述子向量方法进行特征表示,得到3)中五种特征的向量表示,将这五种特征向量级联起来,得到最终这个视频的中层表示；5)采用支持向量机进行特征分类,得到识别准确率。</td>   <td>一种基于密集轨迹的动作识别方法,其特征在于,包括以下步骤：(1)输入待识别的视频,对输入视频的每一帧,利用密集采样得到密集的抽样点,对抽样点进行跟踪形成密集轨迹；(2)筛选出视频帧中心区域的轨迹作为前景轨迹,区域以外的轨迹视作背景轨迹予以删除；(3)提取视频帧中心区域内的前景轨迹的五种描述子特征：形状特征(TS),梯度方向直方图特征(HOG),光流直方图特征(HOF),运动边缘直方图特征(MBH)以及轨迹运动邻域特征(TMNF)；(4)对步骤(3)提取的每一种描述子特征分别采用增强型局部级联描述子向量方法(IVLAD)进行特征建模,得到每一种描述子特征的向量表示,然后将这五种特征向量级联起来,形成该视频最终的向量表示；(5)采用支持向量机(SVM)进行特征分类,最终输出分类结果,获取视频的动作识别结果,在YouTube人体行为数据集上实现了91.4％的准确率。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周梓檀;              刘济科;                   吕中荣       </td>   <td>中山大学</td>   <td>基于果蝇算法的结构损伤识别方法</td>   <td>广东</td>   <td>CN105956294A</td>   <td>2016-09-21</td>   <td>本发明一种基于果蝇算法的结构损伤识别方法,涉及果蝇算法在结构损伤识别的工程应用,主要步骤：①通过有限单元法建立损伤结构的有限元模型,提取结构的固有频率、振型等模态参数,②利用损伤结构和计算结构的固有频率残差和模态确保准则构建目标函数；③采用果蝇算法优化这一目标函数,直到满足循环结束条件为止。④最后得到的最优解即为损伤识别结果。该方法相较于传统的灵敏度方法而言,无需借助梯度信息,利用少量的模态参数即可得到精度较高的识别结果。</td>   <td>一种基于果蝇算法的结构损伤识别方法,其特征在于,包括以下步骤：步骤一：将结构划分为nel个单元,利用有限单元法得到系统刚度和质量矩阵,再提取前损伤结构NF阶固有频率和模态；步骤二：构建损伤结构的目标函数,目标函数如下：<maths num="0001"><math><![CDATA[<mrow><mi>f</mi><mo> =</mo><msubsup><mi>&Sigma;</mi><mrow><mi>j</mi><mo> =</mo><mn>1</mn></mrow><mrow><mi>N</mi><mi>F</mi></mrow></msubsup><mo>&lsqb;</mo><mi>a</mi><mo>*</mo><msub><mi>&Delta;&omega;</mi><mi>j</mi></msub><mo>+</mo><mi>b</mi><mo>*</mo><mrow><mo>(</mo><mn>1</mn><mo>-</mo><msub><mi>MAC</mi><mi>j</mi></msub><mo>)</mo></mrow><mo>&rsqb;</mo></mrow>]]></math><img file="FDA0000983689600000011.TIF" wi="662" he="93" /></maths><maths num="0002"><math><![CDATA[<mrow><msub><mi>&Delta;&omega;</mi><mi>j</mi></msub><mo> =</mo><mfrac><mrow><mo>|</mo><msubsup><mi>&omega;</mi><mi>j</mi><mi>h</mi></msubsup><mo>-</mo><msubsup><mi>&omega;</mi><mi>j</mi><mi>d</mi></msubsup><mo>|</mo></mrow><mrow><mo>|</mo><msubsup><mi>&omega;</mi><mi>j</mi><mi>d</mi></msubsup><mo>|</mo></mrow></mfrac></mrow>]]></math><img file="FDA0000983689600000012.TIF" wi="365" he="149" /></maths><maths num="0003"><math><![CDATA[<mrow><msub><mi>MAC</mi><mi>j</mi></msub><mo> =</mo><mfrac><msup><mrow><mo>(</mo><msubsup><mi>&Phi;</mi><mi>j</mi><mi>C</mi></msubsup><mo>&CenterDot;</mo><msubsup><mi>&Phi;</mi><mi>j</mi><mi>M</mi></msubsup><mo>)</mo></mrow><mn>2</mn></msup><mrow><mo>|</mo><mo>|</mo><msubsup><mi>&Phi;</mi><mi>j</mi><mi>C</mi></msubsup><mo>|</mo><msup><mo>|</mo><mn>2</mn></msup><mo>|</mo><mo>|</mo><msubsup><mi>&Phi;</mi><mi>j</mi><mi>M</mi></msubsup><mo>|</mo><msup><mo>|</mo><mn>2</mn></msup></mrow></mfrac></mrow>]]></math><img file="FDA0000983689600000013.TIF" wi="459" he="182" /></maths>其中<img file="FDA0000983689600000014.TIF" wi="180" he="71" />为第j阶结构计算得到的频率和振型,<img file="FDA0000983689600000015.TIF" wi="192" he="70" />为第j阶结构测量得到的频率和振型,a,b为权重系数,Δω<sub>j</sub>为第j阶结构计算和测量得到的频率误差,MAC<sub>j</sub>为第j阶结构计算和测量得到模态误差；步骤三：利用果蝇算法不断优化上述目标函数,直到满足设定的终止条件,得到识别结果；上述利用果蝇算法不断优化目标函数具体包括如下几个阶段：1)初始化参数,包括初始果蝇种群数量和最大迭代次数maxgen；基于下式初始化果蝇种群,即果蝇位置(X<sub>i</sub>,Y<sub>i</sub>)：X<sub>i</sub>＝10*rand(0,1)Y<sub>i</sub>＝10*rand(0,1)其中X<sub>i</sub>表示搜索空间里的果蝇初始位置的横坐标,Y<sub>i</sub>表示搜索空间里的果蝇初始位置的纵坐标；则该果蝇位置与原点的距离<img file="FDA0000983689600000016.TIF" wi="359" he="82" />基于下式获取该果蝇位置对应的折损系数c；S＝1/Dc＝1#S2)在该果蝇位置周围按照设定的种群数量派出果蝇,并分别基于目标函数求取各果蝇的函数适应度值,从中选取出适应度值最小时对应的果蝇位置(X<sub>axis</sub>,Y<sub>axis</sub>),并计算该果蝇位置(X<sub>axis</sub>,Y<sub>axis</sub>)与原点的距离<img file="FDA0000983689600000021.TIF" wi="483" he="83" />同理获取新的折损系数c<sub>axis</sub>；3)果蝇位置为(X<sub>axis</sub>,Y<sub>axis</sub>)的果蝇在食物源附近进行食物探索,并利用下式对该果蝇的位置进行更新；X<sub>i</sub>′＝X<sub>axis</sub>+2*rand(0,1)#1Y<sub>i</sub>′＝Y<sub>axis</sub>+2*rand(0,1)#14)应用“贪婪原则”,重复步骤2)、3),进行maxgen次的探索,选出适应度值更好的解和折损系数,并记忆,结束。</td>   <td>G06F17/50;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              潘瑜;              曹向前;              肖翔;              顾建权;              张伟;              胡伟鹏;                   李昊曦       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于改进网络流图的多目标跟踪方法</td>   <td>广东</td>   <td>CN105957104A</td>   <td>2016-09-21</td>   <td>本发明提供一种基于改进网络流图的多目标跟踪方法,该方法通过改进了网络流图模型,充分利用了临近目标对的信息,对每条假设轨迹内部的所有关联值求和来构建秩一张量,通过张量迭代确定所有单位向量,把单位向量作为代价消耗,并用匈牙利算法进行二值化处理,得到多目标跟踪的结果,减少了计算时间,提高了目标跟踪准确率。</td>   <td>一种基于改进网络流图的多目标跟踪方法,其特征在于,包括以下步骤：S1：用DPM算法在视频的每帧中检测出运动目标,并保留每个运动目标的检测准确率；S2：构建整个视频的改进的网络流图模型,在时间域内计算视频的每帧中相邻运动目标对的关联值；S3：对每个运动目标的每条假设轨迹的所有关联值求和来构建秩一张量,秩一张量的每一元素对应一条轨迹的关联值和；S4：用若干个单位向量相乘近似秩一张量,通过张量迭代确定所有单位向量；S5：把单位向量作为代价消耗,并用匈牙利算法进行二值化处理,得到多目标跟踪的结果。</td>   <td>G06T7/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              王福川;                   印鉴       </td>   <td>中山大学;广州智海纵横信息科技有限公司;广州中大南沙科技创新产业园有限公司</td>   <td>一种基于GPU的社会力模型人群实时仿真方法</td>   <td>广东</td>   <td>CN105955797A</td>   <td>2016-09-21</td>   <td>本发明涉及一种基于GPU的社会力模型人群实时仿真方法。包括：S1.设行人的受力感知范围；S2.根据当前场景的结构信息和行人受力感知范围,采用均匀网格分割法来划分虚拟场景,得到网格化的场景；S3.根据已分割好的场景,在行人受力感知范围内对与当前行人所在网格相邻的8个近邻网格中的行人进行并行化查询获得其他行人的分布信息；S4.根据行人受力感知范围内其他行人的分布信息并行化计算行人间相互作用力；S5.根据社会力模型的思想,CPU串行化计算行人的自驱力、行人与障碍物之间的作用力,结合行人间相互作用力,计算出当前行人新的速度和位置信息,完成群体的更新工作。本发明大大降低了算法的时间复杂度。</td>   <td>一种基于GPU的社会力模型人群实时仿真方法,其特征在于,包括：S1.设行人的受力感知范围；S2.根据当前场景的结构信息和行人受力感知范围,采用均匀网格分割法来划分虚拟场景,得到网格化的场景；S3.根据已分割好的场景,在行人受力感知范围内对与当前行人所在网格相邻的8个近邻网格中的行人进行并行化查询获得其他行人的分布信息；S4.根据行人受力感知范围内其他行人的分布信息并行化计算行人间相互作用力；#S5.根据社会力模型的思想,CPU串行化计算行人的自驱力、行人与障碍物之间的作用力,结合行人间相互作用力,计算出当前行人新的速度和位置信息,完成群体的更新工作。</td>   <td>G06F9/455;G06F9/38</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡志岗;              叶伟洲;              王福娟;                   李佼洋       </td>   <td>中山大学</td>   <td>一种在线高温零件红外图像光谱抽样检测方法</td>   <td>广东</td>   <td>CN105956591A</td>   <td>2016-09-21</td>   <td>本发明提供一种在线高温零件的红外图像光谱抽样检测方法,是将红外图像识别和选择式红外图像光谱技术融合到在线高温零件的抽样检测中。利用红外图像识别技术,可对生产线上多个高温零件进行识别并自动随机选取；然后利用选择式红外光谱技术,探测所选高温零件或所选位置的发射光谱,并提取每个光谱样品的特征峰波长,对由光谱特征峰波长组成的样品集主成分建模运算,结合光谱分析技术进行高温零件夹杂分析。该方法无须等到高温零件冷却后才检测,而且在生产线上可以对多个红外图像进行识别并自动随机检测,同时利用红外光谱对零件进行夹杂分析,为高温零件的在线抽样检测提供了一种无损、高效、非接触的安全方法。</td>   <td>一种在线高温零件的红外图像光谱抽样检测方法,其特征在于,包括：S201.规划生产线零件识别区域,并平分识别区域为若干个搜索窗口；S202.零件未进入识别区域之前,采集背景光图像数据；S203.第一个零件进入识别区域R,采集第一个零件的图像数据；S204.多个零件进入识别区域,获得识别区域内所有零件的图像信息；积分计算各搜索窗口的灰度直方图,并积分计算第一个零件的图像信息和背景光的图像数据作为标准,在每个搜索窗口中匹配出和第一个零件滤去背景光后的图像数据相似度最高的区域作为零件轮廓,并对全部零件轮廓依次进行编号；S205.随机选中一个零件编号,生成该零件轮廓ROI的掩模图,由记录该零件特征发射光谱；S206.判断该零件是否超出该搜索窗口或零件的样品数是否超出采集上限；若都否,则进行下一步S207；若其中一个是,则进行步骤S208；S207.在该搜索窗口内根据该零件的图像数据再次进行匹配,找出该零件的轮廓并继续对此零件进行光谱探测,并形成该零件的特征发射光谱集,再进入S206；S208.去除该零件的编号并且放弃对该零件的采集工作；S209.提取光谱特征峰波长作为主成分样品集；S210.将特征峰波长值与波长数量进行建模分析,判断零件是否夹杂。</td>   <td>G06K9/32;G06K9/46;G06K9/62;G01N21/35</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              肖翔;              张伟;                   顾建权       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院</td>   <td>一种基于两层时空邻域特征的动作识别方法</td>   <td>广东</td>   <td>CN105956604A</td>   <td>2016-09-21</td>   <td>本发明公开一种基于两层时空邻域特征的动作识别方法,包括：对输入的视频,根据视频中连续帧的运动方向变化信息,提取运动变化模式特征作为视频的第一层原始特征。对第一层特征采用改进的词袋模型进行特征建模,得到第一层特征的向量表示。根据第一层中的每个局部兴趣点和最近邻若干兴趣点之间的时空关系,计算出第二层时空特征。对第二层特征采用改进的词袋模型进行特征建模,得到第二层特征的向量表示。将第一、二层的向量表示级联,形成视频最终的中层特征表达。采用支持向量机进行特征分类,得到识别准确率。本发明能有效地获取最近邻兴趣点的相对位置信息和类别信息,并结合了改进的词袋模型方法进行特征建模,显著提高了动作识别的准确率。</td>   <td>一种基于两层时空邻域特征的动作识别方法,其特征在于,包括以下步骤：(1)输入待识别的视频,根据视频中连续帧的运动方向变化信息,提取运动变化模式特征作为视频的第一层原始特征；(2)对第一层原始特征采用包含k#means++聚类方法的改进词袋模型进行特征建模,得到第一层原始特征的向量表示；(3)根据第一层原始特征中的每个局部兴趣点和最近邻若干兴趣点之间的时空关系,计算出第二层时空特征；(4)对第二层时空特征同样采用改进的词袋模型进行特征建模,得到第二层时空特征的向量表示；(5)将第一层原始特征和第二层时空特征的向量表示级联起来,形成该视频最终的中层特征表达；(6)采用支持向量机(SVM)进行特征分类,最终输出动作视频的识别准确率；所述改进的词袋模型的具体实现包括数据聚类和计算统计频率直方图这两个步骤,其聚类是采用k#means++方法k#means++方法的描述如下：(3#1)从输入的数据点集合中随机选择一个点作为第一个聚类中心；(3#2)对于数据集中的每一个点x,计算它与已选择的聚类中心中最近的聚类中心的距离D(x)；(3#3)选择一个新的数据点作为新的聚类中心,其选择的原则是：D(x)较大的点,被选取作为聚类中心的概率较大；(3#4)重复步骤(3#2)和(3#3)直到k个聚类中心被选出来；(3#5)利用这k个初始的聚类中心来运行标准的k#means算法。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              何炜雄;                   陈颖聪       </td>   <td>中山大学</td>   <td>一种基于不对称变换的行人再标识方法</td>   <td>广东</td>   <td>CN105956606A</td>   <td>2016-09-21</td>   <td>本发明公开了一种基于不对称变换的行人再标识方法,包括步骤：提取训练所用的行人图像集的LOMO特征构成特征矩阵,构建每一张训练所用的测试图像期望的稀疏重构向量；构建需要优化的整体的目标函数；采用交替优化的框架队所述目标函数进行优化,当目标函数收敛后,得到非对称变换矩阵T<sub>A</sub>和T<sub>B</sub>；在测试阶段,使用变换后的图像集中的图像特征来对变换后的测试集中的图像特征进行重构；使用重构系数向量的大小关系对图像集中的图像进行排序。本发明提高了稀疏重构的可靠性,提高了行人再标识的准确性和鲁棒性；解决了行人再标识问题中遮挡情况带来的困扰；且提高了行人再标识的准确性。</td>   <td>一种基于不对称变换的行人再标识方法,其特征在于,包括步骤：S1：提取训练所用的行人图像集的LOMO特征构成特征矩阵G和P,对于每一个行人的所有图像特征进行求平均操作,得到表示该行人的特征；S2：构建每一张训练所用的测试图像期望的稀疏重构向量；S3：得到所有测试图像期望的稀疏重构向量后,构建需要优化的整体的目标函数；S4：采用交替优化的框架队所述目标函数进行优化,当目标函数收敛后,得到非对称变换矩阵T<sub>A</sub>和T<sub>B</sub>；S5：在测试阶段,将图像集中的图像使用非对称变换矩阵T<sub>A</sub>进行变换,将测试集中的图像使用非对称变换矩阵T<sub>B</sub>进行变换,并使用变换后的图像集中的图像特征来对变换后的测试集中的图像特征进行重构；S6：使用重构系数向量的大小关系对图像集中的图像进行排序。</td>   <td>G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              刘丙军;              涂新军;              林凯荣;                   张强       </td>   <td>中山大学</td>   <td>水文实时预报系统</td>   <td>广东</td>   <td>CN105912770A</td>   <td>2016-08-31</td>   <td>本发明提供一种水文实时预报系统,包括数据输入模块、模型库和数据输出模块,模型库包括栅格单元的产流模块、子流域内的汇流模块、流域的河道汇流模块、实时校正模块。本系统可利用预报过程中得到的最新信息,恰当地调整下一步预报中推算采用的数值或参数,即每次进行预报时,考虑包括现时段在内的以前一系列预报误差信息,根据自动控制理论的跟踪技术,对未来预报值进行校正,提高了水文预报精度。另外,本系统采用基于栅格的分布式新安江模型为基础,相比于传统模型,可以在数据量较少的流域运行。同时,本系统具有可视化界面,操作实用性更强。</td>   <td>水文实时预报系统,其特征在于,所述系统包括：数据输入模块：用于输入数据,输入数据包括降雨和蒸发数据,输入数据还包括产流参数、河道汇流参数；模型库：模型库包括四个模块,栅格单元的产流模块、子流域内的汇流模块、流域的河道汇流模块、实时校正模块；数据输出模块：用于输出洪水预报信息,所述洪水预报信息包括但不限于洪峰流量、洪峰出现时间、洪水涨落过程、下一时段流量。</td>   <td>G06F17/50</td>  </tr> </table></body></html>