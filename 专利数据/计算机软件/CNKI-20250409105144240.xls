<html xmlns:o='urn:schemas-microsoft-com:office:office' xmlns:x='urn:schemas-microsoft-com:office:excel' xmlns='http://www.w3.org/TR/REC-html40'><head><style>table td,th{vnd.ms-excel.numberformat:@;text-align: center;} table th{color:red}</style><title></title><meta http-equiv='Content-Type' content="text/html; charset=utf-8"></head><body><table cellspacing='0' border='1'>     <tr>   <td style='vnd.ms-excel.numberformat:@'>SrcDatabase-来源库</td>   <td style='vnd.ms-excel.numberformat:@'>Author-作者</td>   <td style='vnd.ms-excel.numberformat:@'>Applicant-申请人</td>   <td style='vnd.ms-excel.numberformat:@'>Title-题名</td>   <td style='vnd.ms-excel.numberformat:@'>CountryName-国省名称</td>   <td style='vnd.ms-excel.numberformat:@'>PubNo-公开号</td>   <td style='vnd.ms-excel.numberformat:@'>PubTime-公开日期</td>   <td style='vnd.ms-excel.numberformat:@'>Summary-摘要</td>   <td style='vnd.ms-excel.numberformat:@'>Claims-主权项</td>   <td style='vnd.ms-excel.numberformat:@'>CLC-中图分类号</td>  </tr>  <tr>   <td>中国专利</td>   <td>         林倞;              邱志林;              张雨浓;              张冬雨;                   王青       </td>   <td>中山大学</td>   <td>一种区域间出行需求预测方法及装置</td>   <td>广东省</td>   <td>CN109190795B</td>   <td>2022-02-18</td>   <td>本发明公开了一种区域间出行需求预测方法及装置,所述方法包括如下步骤：步骤S1,构建多重上下文信息抽取的深度模型,利用历史多个时间段的交通出行需求矩阵序列作为输入和对应序列下一个时间段的实际交通出行需求矩阵作为目标输出,并利用神经网络的反向传播算法来训练深度模型；步骤S2,构建上下文信息丰富的交通出行需求矩阵序列；步骤S3,将步骤S1经训练得到的深度模型参数和深度模型一起作为最终的预测器,输入连续的交通出行需求矩阵序列,预测未知的下一个时间段的交通出行需求矩阵,本发明可提高区域间出行需求预测的准确性。</td>   <td>1.一种区域间出行需求预测方法,包括如下步骤：步骤S1,构建多重上下文信息抽取的深度模型,利用历史多个时间段的交通出行需求矩阵序列作为输入和对应序列下一个时间段的实际交通出行需求矩阵作为目标输出,并利用神经网络的反向传播算法来训练深度模型；步骤S2,构建上下文信息丰富的交通出行需求矩阵序列；步骤S3,将步骤S1经训练得到的深度模型参数和深度模型一起作为最终的预测器,输入连续的交通出行需求矩阵序列,预测未知的下一个时间段的交通出行需求矩阵；步骤S1进一步包括：步骤S100,构建基于多重上下文信息抽取的深度模型的时空情境需求机器CSTN；步骤S101,构建上下文信息丰富的交通出行需求矩阵序列,将历史时间上连续的多个时间段的交通出行需求矩阵及对应时间段的外部信息作为所述时空情境需求机器的输入序列；步骤S102,利用历史多个时间段的交通出行需求矩阵序列及对应时间段的外部信息作为输入和对应序列下一个时间段的实际交通出行需求矩阵作为目标输出,利用神经网络的反向传播算法来训练深度模型,更新深度模型每一层的参数；步骤S100中,所述时空情境需求机器CSTN包括局部空间关联子网络、时序演化子网络以及全局空间协同子网络,该三个子网络分别对空域,时域和全局情境上下文进行建模；步骤S102包括：步骤S102a,利用所述局部空间关联子网络对时间段内的区域间交通出行需求矩阵提取空间局部上下文信息；步骤S102b,所述时序演化子网络接受由所述局部空间关联子网络提取得到的历史时刻的空间局部上下文信息,对下一个时刻的出行需求空间局部上下文信息进行预测；步骤S102c,所述全局空间协同子网络接受所述时序演化子网络的输出作为特征输入,通过抽取全局情境特征,并计算区域间全局特征相似性作为权重,为不同区域的特征附加一个其他区域输入特征的加权和特征信息,并使用最终的特征对区域间出行需求做出预测；步骤S102d,根据预测矩阵和目标输出的误差进行反向传播,以求出深度模型网络参数梯度,并进行更新,迭代这个过程直到深度模型能准确地预测出行需求矩阵；于步骤S102a中,所述局部空间关联子网络分别对出行需求的出发区域和到达区域的空域特征进行学习,获得出发区域和到达区域的空域特征,然后将出发和到达区域的空间特征进行融合,最后再与外部信息的特征进行融合。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈武辉;              张伟焜;              蔡婷;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于区块链和反向拍卖的市场调控方法及系统</td>   <td>广东省</td>   <td>CN113095910B</td>   <td>2022-02-18</td>   <td>本发明公开了一种基于区块链和反向拍卖的市场调控方法及系统,其中方法包括：在市场生命周期的每个时间段内,根据市场监管机构输入的命令激活智能合约,以进行反向拍卖；计算并确定门槛金额；在买家向智能合约支付门槛金额后,为买家赋予进入市场的权限,以使买家成为潜在买家；在卖家通过智能合约的接口给出报价后,为报价低于门槛金额的卖家赋予进入市场的权限,以使报价低于门槛金额的卖家成为潜在卖家；通过智能合约对进入市场的潜在买家和潜在卖家进行随机匹配,以完成市场交易。本发明不仅能够支持买家和卖家双方之间的交易,并且保留了底层区块链的优势,同时为市场监管者提供了调整市场可调节因素的接口,以促进市场的金融稳定性。</td>   <td>1.一种基于区块链和反向拍卖的市场调控方法,其特征在于,所述方法包括：在市场生命周期的每个时间段内,根据市场监管机构输入的命令激活智能合约,以进行反向拍卖；计算并确定门槛金额；在买家向所述智能合约支付所述门槛金额后,为所述买家赋予进入市场的权限,以使所述买家成为潜在买家；在卖家通过所述智能合约的接口给出报价后,为报价低于所述门槛金额的卖家赋予进入市场的权限,以使报价低于所述门槛金额的卖家成为潜在卖家；通过所述智能合约对进入市场的所述潜在买家和所述潜在卖家进行随机匹配,以完成市场交易,并将匹配结果通知给所述潜在买家和所述潜在卖家。</td>   <td>G06Q30/06;G06Q30/08;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚清河;              陈珺逸;              罗语轩;                   张栏       </td>   <td>中山大学</td>   <td>一种燃料电池装置的故障诊断方法、系统及存储介质</td>   <td>广东省</td>   <td>CN114048772A</td>   <td>2022-02-15</td>   <td>本发明公开了一种燃料电池装置的故障诊断方法、系统及存储介质,涉及燃料电池技术领域,该方法包括：采集正常工况下的传感器信号和故障工况下的传感器信号,并将其原始时间序列进行离散采样,并进行预处理及归一化,获取训练样本集；将训练样本集输入构建的多层长短时记忆LSTM网络中进行神经网络训练,直至得到最优多层长短时记忆LSTM网络；重新采集传感器信号,获取测试样本集并将其输入最优多层长短时记忆LSTM网络,得到测试样本集的故障类型。本发明能够有效提取燃料电池运行数据中更丰富、更全面的深层故障特征信息,对燃料电池装置中多类型多程度的故障进行准确判断,有效提高燃料电池故障诊断的时效性、可靠性和准确度。</td>   <td>1.一种燃料电池装置的故障诊断方法,其特征在于,包括以下步骤：采集正常工况下的传感器信号；根据目标故障类型和程度分别在不同位置引入故障,采集故障工况下的传感器信号；将所述正常工况下的传感器信号和故障工况下的传感器信号的原始时间序列进行离散采样,并进行预处理及归一化,获取训练样本集；构建多层长短时记忆LSTM网络,将所述训练样本集输入所述多层长短时记忆LSTM网络中进行神经网络训练,通过反向传播算法进行神经网络参数的拟合,当决定系数R～2＞0.99时,得到最优多层长短时记忆LSTM网络；重新采集传感器信号,对所述传感器信号进行预处理及归一化,获取测试样本集,将所述测试样本集输入所述最优多层长短时记忆LSTM网络,得到所述测试样本集的故障类型。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08;H01M8/04664;H01M8/04992</td>  </tr>        <tr>   <td>中国专利</td>   <td>         潘炎;              杜劭旭;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于注意力机制和强化学习的趋势预测方法</td>   <td>广东省</td>   <td>CN114049222A</td>   <td>2022-02-15</td>   <td>本发明提供一种基于注意力机制和强化学习的趋势预测方法,该方法充分利用市场信息,更好地捕捉到市场动态,尽可能在期货价格处于低位并且有上升趋势时入场,并减少决策失误的概率。首先选择期货品种,尽可能选择成立时间较长成交量较大的品种,并根据分形理论,通过测试判断该期货是否适合做数据增强,在一定程度上解决了数据量较少的问题。接着通过数据清洗和基于注意力机制的特征提取模型,优化模型提取金融数据特征的能力,作为最终策略网络的输入,最终使用强化学习算法并引入连续动作控制,得到一个具有策略随机性和鲁棒性的智能体,该智能体能根据市场动态做出决策。</td>   <td>1.一种基于注意力机制和强化学习的趋势预测方法,其特征在于,包括以下步骤：S1：选择期货品种,获取所选品种的期货历史行情数据；S2：对数据进行数据清洗；S3：对数据进行预处理；S4：使用预处理数据,预训练特征提取模型；S5：将特征提取模型的输出与原始数据拼接,用于强化学习模型训练；S6：把训练得到的强化学习模型用于决策,导出决策序列；S7：在回测平台进行测试。</td>   <td>G06Q40/06;G06Q40/04;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         潘炎;              戴梓煜;                   印鉴       </td>   <td>中山大学</td>   <td>一种基于教师-学生模型和强化学习的做市方法</td>   <td>广东省</td>   <td>CN114049223A</td>   <td>2022-02-15</td>   <td>本发明提供一种基于教师-学生模型和强化学习的做市方法,该方法能够充分利用市场不完美信息抓住合适的做市时机,并充分考虑头寸累积带来的风险,从而获得价差盈利并促进市场流动性。该方法首先对市场的价量信息进行预处理,再利用完美的市场信息计算相应的技术指标并作为强化学习算法输入训练出一个教师智能体,接着用得到的教师智能体来指导学生智能体的训练过程,利用不完美的市场信息计算出相应的技术指标并作为强化学习算法输入,在教师智能体的指导下训练出一个学生智能体,最终得到的学生智能体可以根据市场的历史信息来做出是否做市的决策。将该智能体进行回测测试,输出结果。</td>   <td>1.一种基于教师-学生模型和强化学习的做市方法,其特征在于,包括以下步骤：S1：收集目标期货品种的历史行情价量数据；S2：进行数据清洗工作；S3：对数据计算训练教师智能体所需的各种数据；S4：用强化学习算法训练教师智能体；S5：对数据计算训练学生智能体所需的各种数据；S6：用教师智能体指导强化学习算法训练学生智能体；S7：进行回测测试。</td>   <td>G06Q40/06;G06Q40/04;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              卢梓君;              王和旭;              韦骏;              龚喜;              谢鹏;                   孙鹏楠       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种浒苔堆积量估算方法、系统及存储介质</td>   <td>广东省</td>   <td>CN114049243A</td>   <td>2022-02-15</td>   <td>本发明公开了一种浒苔堆积量估算方法、系统及存储介质,方法包括：获取浒苔观测信息,其中,所述浒苔观测信息包括浒苔爆发信息、浒苔区域位置信息、浒苔覆盖范围信息、浒苔覆盖厚度信息、浒苔图片信息以及海气背景信息；根据所述浒苔观测信息,通过BIM三维方法构建三维浒苔空间模型；根据所述三维浒苔空间模型计算近海近岸的浒苔总量以及打捞区域。本发明增强了实时性,降低了人工成本,而且有助于提高打捞效率,可广泛应用于计算机技术领域。</td>   <td>1.一种浒苔堆积量估算方法,其特征在于,包括：获取浒苔观测信息,其中,所述浒苔观测信息包括浒苔爆发信息、浒苔区域位置信息、浒苔覆盖范围信息、浒苔覆盖厚度信息、浒苔图片信息以及海气背景信息；根据所述浒苔观测信息,通过BIM三维方法构建三维浒苔空间模型；根据所述三维浒苔空间模型计算近海近岸的浒苔总量以及打捞区域。</td>   <td>G06Q50/26;G06Q10/04;G06Q10/06;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              朱泳霖;                   郭佳俊       </td>   <td>中山大学</td>   <td>基于CPU的静态场景光线追踪棋盘渲染方法、系统及存储介质</td>   <td>广东省</td>   <td>CN114049421A</td>   <td>2022-02-15</td>   <td>本发明涉及计算机图形学渲染技术领域,具体为基于CPU的静态场景光线追踪棋盘渲染方法、系统及存储介质,其方法包括：根据点光源与几何物体的坐标构建三维场景；设置历史像素值缓冲区和历史碰撞点坐标缓冲区；计算三维场景中每个几何物体的边界包围盒；使用编程方式实现奇偶棋盘采样,获得采样像素点；如果摄像机静止,在渲染阶段利用棋盘式光线追踪算法得到半分辨率的渲染帧,再结合历史像素值缓冲区的像素值,叠加得到全分辨率的目标图像；如果摄像机通过用户交互而运动,通过交互修正算法得到全分辨率的目标图像。本发明构建三维场景,将像素空间分块,使用CPU并行计算和边界包围盒实现渲染加速,取得了减少帧缓存、提高实时交互帧率的效果。</td>   <td>1.基于CPU的静态场景光线追踪棋盘渲染方法,其特征在于,包括以下步骤：步骤S1、根据点光源与几何物体的坐标构建三维场景,初始化摄像机位置；步骤S2、设置一个历史像素值缓冲区和一个历史碰撞点坐标缓冲区；步骤S3、计算三维场景中每个几何物体的边界包围盒；步骤S4、在采样阶段,使用编程方式实现奇偶棋盘采样,获得采样像素点；步骤S5、如果摄像机静止,则在渲染阶段,利用棋盘式光线追踪算法得到半分辨率的渲染帧,再结合历史像素值缓冲区的像素值,叠加得到全分辨率的目标图像；步骤S6、如果摄像机通过用户的交互而运动,则通过交互修正算法来得到全分辨率的目标图像。</td>   <td>G06T15/00;G06T15/06;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              梁宁;                   刘镇       </td>   <td>中山大学</td>   <td>一种基于随机分形的多孔介质细观结构模型生成方法</td>   <td>广东省</td>   <td>CN108734751B</td>   <td>2022-02-11</td>   <td>本发明提供一种基于随机分形的多孔介质细观结构模型生成方法,可模拟多孔介质内部细观结构的分布情况。通过编写程序语言模拟孔隙生成,实现孔隙模型的规范化处理,针对多孔介质中孔隙边界的复杂、不确定等形状,通过林顿伊尔系统仿真模式进行模拟,实行字符串序列的等价变换,将字符串序列转化为边界演变规则作为边界生成的依据。同时,基于分形几何的迭代方式,并结合随机分布概率模拟孔隙结构的生成,得出多样化复杂的多孔介质细观结构模型。本发明的仿真效果良好,可有效揭示多孔介质内部细观结构特性,在软件模型建立与三维重构方面可实现广泛应用。</td>   <td>1.一种基于随机分形的多孔介质细观结构模型生成方法,其特征在于,包括：(1)基于林顿伊尔系统仿真模式,生成字符串发展序列并自动存储,以字符串序列模式实现孔隙边界模型的随机控制,通过字符串的拓展与演变,系统识别字符串排列特征,并执行字符串的等价变换,建立起孔隙边界模型的构造规则,实现孔隙边界的复杂连续性处理,体现形态各异孔隙边界的组合方式,更好的模拟实际孔隙边界；(2)定义异形孔隙初始元模型,运用分形几何迭代方式对孔隙初始元进行有限次迭代,模拟孔隙演变过程,结合林顿伊尔系统仿真模式并加入随机因子决定初始元迭代方向,实现孔隙生成过程的多样化、吻合度高与随机性强的无规则模拟以及孔隙模型复杂变化的动态生长方式；(3)对绘图区进行全局域遍历,建立非生长相内部坐标矩阵,同时给出区域内部随机概率分布元素,形成坐标矩阵、随机概率相统一的组装矩阵,控制孔隙初始元的大小与迭代步数,实现孔隙大小的随机分布,孔隙结构模型进一步优化处理；(4)以指定色块进行孔隙结构对非生长相的实时嵌入,并跟踪该色块对全区域所占的比例,通过该比例反演孔隙率的实时大小,通过与目标孔隙率的比较,判定孔隙生成条件,自动控制循环迭代过程, 以达到循环迭代条件而终止整个模型生成,得出多孔介质细观结构模型二值图像,有效表征实际多孔介质内部结构特征。</td>   <td>G06T11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         由林麟;              刘晟;              蔡铭;              章圣律;              郭子晗;              周檬;                   贺俊姝       </td>   <td>中山大学</td>   <td>一种面向异质场景的异步联邦学习方法、装置及存储介质</td>   <td>广东省</td>   <td>CN114037089A</td>   <td>2022-02-11</td>   <td>本发明公开了一种面向异质场景的异步联邦学习方法、装置及存储介质,方法包括：从候选客户端中确定目标客户端,其中,所述目标客户端的自相关熵高于所述候选客户端中其他客户端；对所述目标客户端进行训练,得到目标参数,并将所述目标参数上传至服务器；所述服务器根据所述目标参数对模型聚合的过程进行聚合增强处理,得到第一联邦模型；对所述第一联邦模型进行策略集成处理,得到第二联邦模型；对所述第二联邦模型进行模型评估,确定目标联邦模型。本发明能够提高模型准确率并且降低通信成本,可广泛应用于人工智能技术领域。</td>   <td>1.一种面向异质场景的异步联邦学习方法,其特征在于,包括：从候选客户端中确定目标客户端,其中,所述目标客户端的自相关熵高于所述候选客户端中其他客户端；对所述目标客户端进行训练,得到目标参数,并将所述目标参数上传至服务器；所述服务器根据所述目标参数对模型聚合的过程进行聚合增强处理,得到第一联邦模型；对所述第一联邦模型进行策略集成处理,得到第二联邦模型；对所述第二联邦模型进行模型评估,确定目标联邦模型。</td>   <td>G06N20/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         项鲲;              姜善成;              吴禄彬;              韩瑜;                   古博       </td>   <td>中山大学</td>   <td>一种资源产业信息的预测模型优化方法、装置及介质</td>   <td>广东省</td>   <td>CN114037121A</td>   <td>2022-02-11</td>   <td>本发明公开了一种资源产业信息的预测模型优化方法、装置及介质,方法包括：获取目标资源的影响因素,根据目标资源的影响因素进行数据整理得到目标数据；根据预设标准选择基础模型；根据基础模型,结合目标数据进行基于标准差的剪枝训练；根据基于标准差的剪枝训练,保存基础模型训练完成的目标模型。本发明提出了一种基于标准差的剪枝训练策略,可以优化网络最终权重、提高神经网络预测准确性,并且对于简单的回归算法也可以起到明显的效果,可广泛用于数据处理模型优化技术领域。</td>   <td>1.一种资源产业信息的预测模型优化方法,其特征在于,包括：获取目标资源的影响因素,根据所述目标资源的影响因素进行数据整理得到目标数据；根据预设标准选择基础模型；根据所述基础模型,结合所述目标数据进行基于标准差的剪枝训练；根据所述基于标准差的剪枝训练,保存所述基础模型训练完成的目标模型。</td>   <td>G06Q10/04;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;              全绍军;              陈小燕;              洪伟;                   梁少玲       </td>   <td>长视科技股份有限公司;中山大学</td>   <td>多指标关联的河流水质评价方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN114037202A</td>   <td>2022-02-11</td>   <td>本发明公开了一种多指标关联的河流水质评价方法。选取河流的三种类型指标：理化特征、水文特征和生物特征,然后利用灰加权关联度综合评价模型,构建理化特征关联评价级别。接着,对水文特征和生物特征构建评价标准及设置不同的权重,以此综合考虑各因素的影响。最后,将三种类型的特征加权求和,得到最后的评价分数。本发明还公开了一种多指标关联的河流水质评价系统、计算机设备及计算机可读存储介质。本发明通过采集河流的理化特征、水文特征和生物特征进行河流水质评价,利用灰加权关联度综合评价模型构建理化特征关联评价级别从而使理化特征评价更准确,本发明综合考虑了评价河流水质的各种因素,且计算属于轻量级,不过度依赖硬件设备。</td>   <td>1.一种多指标关联的河流水质评价方法,其特征在于,所述方法包括：采集河流待评价水质样本的理化特征、水文特征和生物特征；对理化特征,利用灰加权关联度综合评价模型,构建理化特征关联评价级别,计算所述待评价水质样本的理化特征的评分值；对水文特征和生物特征构建评价标准,形成水文特征和生物特征的评价标准表,之后根据评价标准表计算所述待评价水质样本的水文特征和所述生物特征的评分值；分别为所述理化特征、水文特征和生物特征设置特征权重,为水文特征以及生物特征中的各项指标设置指标权重；根据待评价水质样本的所述理化特征的评分值与特征权重、所述水文特征和所述生物特征的评分值与特征权重、所述各项指标的指标权重,进行加权求和计算河流水质综合评价分数,并根据评价分数将河流水质分为三个级别：风险预警、中等、健康。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄华威;              李灿林;                   郑子彬       </td>   <td>中山大学</td>   <td>一种区块链分片系统的分片账户调整方法及其相关装置</td>   <td>广东省</td>   <td>CN114037531A</td>   <td>2022-02-11</td>   <td>本申请公开了一种区块链分片系统的分片账户调整方法及其相关装置,区块链分片系统包括工作分片和协调分片,协调分片收集当前各工作分片处理账户之间的交易所产生的交易信息,并根据交易信息构建账户交易网络；协调分片通过账户交易网络计算各账户集合之间的边的权重之和,并以不同账户集合之间的边的权重之和最小为优化目标对所有工作分片的账户进行重新划分,得到划分结果；协调分片将划分结果发送给工作分片,使得工作分片根据划分结果更新自身的账户信息,改善了现有的区块链分片系统存在跨分片交易过多,导致降低了分片系统的吞吐量,增加了交易的确认延迟的技术问题。</td>   <td>1.一种区块链分片系统的分片账户调整方法,其特征在于,所述区块链分片系统包括工作分片和协调分片,所述方法包括：所述协调分片收集当前各所述工作分片处理账户之间的交易所产生的交易信息,并根据所述交易信息构建账户交易网络G(V,E),其中,V为所有所述工作分片的账户集合,E为两个账户的边集合,边的权重为两个账户之间发生交易的数量；所述协调分片通过所述账户交易网络G(V,E)计算各账户集合之间的边的权重之和,并以不同账户集合之间的边的权重之和最小为优化目标对所有所述工作分片的账户进行重新划分,得到划分结果；所述协调分片将所述划分结果发送给所述工作分片,使得所述工作分片根据所述划分结果更新自身的账户信息。</td>   <td>G06Q40/04;G06F16/27;G06F16/23</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;              全绍军;              陈小燕;              洪伟;                   梁少玲       </td>   <td>长视科技股份有限公司;中山大学</td>   <td>一种基于联盟链的水环境污染溯源方法与系统</td>   <td>广东省</td>   <td>CN114037580A</td>   <td>2022-02-11</td>   <td>本发明公开了一种基于联盟链的水环境污染溯源方法与系统。包括：首先根据水环境污染过程设计节点信息,输入水环境污染过程,获取节点储存的信息,设计节点形成区块并上链,最后进行数据储存溯源,输入不同节点对应的区块和上链过程的数据,输出最终溯源信息。本发明在区块链溯源的基础上,构建基于区块链的水环境污染物溯源模型,在信息传递过程中通过区块链共识算法、智能合约等关键技术和软硬件协同配合实现各环节中溯源数据的无缝连接。采用综合加权法来对河流水污染状况进行综合评述,基于区块链的水环境污染溯源应用环节设计保证了溯源的去中心化、污染物信息的公开透明和污染物的可信溯源。</td>   <td>1.一种基于联盟链的水环境污染溯源方法,其特征在于,所述方法包括：根据水环境污染过程设计节点信息,输入为水环境污染溯源的具体事件,输出为四个节点信息；节点储存信息获取过程,输入为所述四个节点信息和所述水环境污染溯源的具体事件,输出为四个节点储存的信息,采用综合加权法来对河流水污染状况进行综合评述；节点形成初始区块并上链,输入所述四个节点信息和所述四个节点储存的信息,形成不同节点对应的区块,输出为区块链上链过程的数据信息,加入监管部门、相关企业与周边居民节点,形成闭环；数据储存溯源过程,构建整体区块链的水环境污染溯源模型,输入所述不同节点对应的区块和所述区块链上链过程的数据信息,输出最终溯源信息。</td>   <td>G06Q50/26;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈刚;              严远星;                   凌晔华       </td>   <td>中山大学</td>   <td>一种FPGA实现的神经网络光流估计方法、装置及介质</td>   <td>广东省</td>   <td>CN114037731A</td>   <td>2022-02-11</td>   <td>本发明公开了一种FPGA实现的神经网络光流估计方法、装置及介质,方法包括：获取连续两帧的图片,根据所述图片进行预处理得到图像块；根据所述图像块,采样得到三层金字塔块；根据所述三层金字塔块,利用二值神经网络进行特征提取；根据所述特征提取的结果,得到特征金字塔；根据所述特征金字塔输出光流信息。本发明基于对图像的分层处理和特征提取,简化了计算过程的同时实现了高进度的光流估计,同时,通过该方法能够便捷的实现端到端的流水线设计,提高实时性能,同时通过了仿真和综合,可以实际部署于一块ALTERA的FPGA中,满足大部分实时系统的实时性要求,可广泛应用于图像处理技术领域。</td>   <td>1.一种FPGA实现的神经网络光流估计方法,其特征在于,包括：获取连续两帧的图片,根据所述图片进行预处理得到图像块；根据所述图像块,采样得到三层金字塔块；根据所述三层金字塔块,利用二值神经网络进行特征提取；根据所述特征提取的结果,得到特征金字塔；根据所述特征金字塔输出光流信息。</td>   <td>G06T7/207</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄敏;              刘芳;                   张腾       </td>   <td>中山大学</td>   <td>一种基于BMO算法的新建过江通道指引优化方法</td>   <td>广东省</td>   <td>CN108122053B</td>   <td>2022-02-08</td>   <td>本发明涉及一种基于BMO算法的新建过江通道指引优化方法,包括以下步骤：S1.选取布设范围,在布设范围的缓冲带内选取布设起点；S2.建立针对新建过江通道情境下的基于成本最优的指引优化数学模型；S3.利用BMO算法求解上述数学模型；S4.得到指引优化方案。</td>   <td>1.一种基于BMO算法的新建过江通道指引优化方法,其特征在于：包括以下步骤：S1.选取布设范围,在布设范围的缓冲带内选取布设起点；S2.建立针对新建过江通道情境下的基于成本最优的指引优化数学模型；S3.利用BMO算法求解上述数学模型；S4.得到指引优化方案；所述步骤S1具体为：以新建过江通道为中心,根据其道路等级和交通吸引量,指定一定的布设半径r,形成宽度为l的缓冲带,在缓冲带内考虑交通流量、重要道路节点、重要城市出入口这些信息,指定多个不同方向的节点作为布设起点；定义布设起点集为{v-p}；所述步骤S2的具体执行过程如下：S11.采用弧段-节点数据模型表征交通路网：G＝(V,A)V＝{v-i|i＝1,2...N}A＝{a-(ij)＝&lt;v-i,v-j&gt;|v-i,v-j∈V}其中有向图G表示交通路网,V表示交通路网的节点集合,v-i表示交通路网中的节点,N表示交通路网中节点的数量,A表示交通路网中路段集合,a-(ij)表示起点为节点v-i、终点为节点v-j的路段；因此新建过江通道模型D表示为：D＝{a-(dd′)＝&lt;v-d,v-(d′)&gt;|a-(dd′)∈A,v-d,v-(d′)∈V}；其中&lt;v-d,v-(d′)&gt;为终点集；S12.设新建过江通道的指路标志布设方案RS由多个指路标志项rs-t组成,每个指路标志项纪录了该项的所在路段larc、所指示的路口节点innode、指引的下一路段narc和指引信息inf,具体如下所示：RS＝{rs-t|t＝1,2,…M}rs-t＝{larc,innode,narc,inf}larc,narc∈A,innode∈V其中M为指路标志布设方案RS中包含的指路标志项rs-t的数量；S13.基于交通路网和新建过江通道的指路标志布设方案RS构建基于成本最优的指引优化数学模型,所述指引优化数学模型应包以下内容：(1)决策变量决策变量决策变量y-(ikj)；其中一条布设起点到终点的指引路径可以看做一条可行流,决策变量表示可行流p是否流过路段a-(ij),代表该可行流p流过路段a-(ij),否则决策变量y-(ikj)表示是否在路段a-(ik)上布设指引路段a-(kj)的指引信息；y-(ikj)＝1表示在路段a-(ik)上布设指引路段a-(kj)的指引信息,否则y-(ikj)＝0；(2)优化目标函数所述优化目标函数为基于成本最优的的优化目标函数：                  其中,f表示优化目标函数,表示出行者在可行流p上的出行成本,C-R表示对现有指引方案进行优化的成本,表示是关于的函数、f-R(y-(ikj))表示C-R是关于y-(ikj)的函数；          表示如下：其中,a表示新建的过江通道D的人流量；V-(ot)表示单位时间成本；c-(ij)表示路段a-(ij)的长度；b表示新建的过江通道D的车流量；v-s表示指引等级为s的道路的设计时速中位数；∑C表示车辆的使用成本；M表示年平均行驶里程；表示路段等级标识,对于等级为s的路段a-(ij),为1,否则,为0；C-R表示如下：其中w-T表示新增或替换一个指引信息项的成本；w-D表示新增一个指路标志牌的成本；e-(ikj)、g-(ikj)为新增指路标志项或指路标志的标识；e-(ikj)＝1表示经过a-(ik)到a-(kj)上可新增一个指路标志项,g-(ikj)＝1表示经过a-(ik)到a-(kj)上需新增一个指路标志；(3)约束条件所述指引优化数学模型按照其约束目的分为可行解约束和指引规则约束,其中可行解约束包含4个约束,分别为节点流平衡约束、路径重合约束、决策变量间的约束和决策变量本身的约束；1)节点流平衡约束：                  除起点和终点外,其余每个节点的流出量等于其流入量,P表示可行流的个数；2)路径重合约束：                  若两条指引路径重合,则重合点后的所有路段必须相同；3)决策变量间的约束                  路段a-(ik)与路段a-(kj)同时被选中时,才能在路段a-(ik)上布设指向a-(kj)的指引信息；4)决策变量本身的约束          y-(ikj)∈{0,1}两决策变量都为0-1型变量；指引规则约束包括以下三个：转弯布设约束、布设间距约束和起讫点布设约束；5)转弯布设约束                  在指引路径发生转弯或掉头时必须布设指引信息,即当路段a-(ik)与路段a-(kj)在可行流p中,且两路段的夹角θ-(ikj)∈(45°,315°),则y-(ikj)必须为1；6)布设间距约束                  路径p上任意连续的四条路段上至少布设一个标志；即都为1时,y-(ikj),y-(kjm),y-(jmh)中至少有一个为1；7)起讫点布设约束                  路径p的第一个路段a-(si)和最后一个路段a-(jd)必须布设指引信息；即都在路径p上时,y-(sij)一定等于1；都在路径p上时,y-(ijd)一定等于1。</td>   <td>G06Q10/04;G06Q50/26;G06N3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴嘉婧;              张如筱;                   郑子彬       </td>   <td>中山大学</td>   <td>基于深度强化学习和联盟链的能量交易方法、装置及设备</td>   <td>广东省</td>   <td>CN112419064B</td>   <td>2022-02-08</td>   <td>本发明涉及一种基于深度强化学习和联盟链的能量交易方法、装置及设备,通过采集能量交易场N个影响买卖双方的状态向量构成第一状态矩阵,在神经网络模型中对状态矩阵进行处理、分析得到动作矩阵、第二状态矩阵和奖励矩阵,还采用第一状态矩阵、动作矩阵、第二状态矩阵和奖励矩阵对神经网络模型进行训练,得到神经网络训练模型,基于神经网络训练模型和联盟链的能量交易方法应用的电动汽车的P2P电量交易中,使得参与交易的电动汽车长期收益最大化,并引入了联盟链,保证电动汽车电量交易的隐私安全,解决了在基于联盟链的P2P电量交易中,如何让买方和卖方得到最大长期效益的技术问题。</td>   <td>1.一种基于深度强化学习和联盟链的能量交易方法,应用于电动汽车电量交易,其特征在于,包括以下步骤：S10.采集能量交易场的交易特征,并将交易特征组成一个状态向量,在t时刻,所述能量交易场中N个状态向量构成第一状态矩阵；其中,所述交易特征包括电动汽车剩余停在能量交易场中的时间、买卖标签、交易能量和交易标价；S20.将所述第一状态矩阵输入深度强化学习的神经网络模型,输出动作矩阵；S30.所述动作矩阵和所述第一状态矩阵经过状态转移函数和奖励函数计算,得到t+1时刻的第二状态矩阵和奖励矩阵；所述第一状态矩阵、所述动作矩阵、所述第二状态矩阵和所述奖励矩阵构成训练矩阵,并将所述训练矩阵存储至所述神经网络模型的回放池中；S40.每隔Δt时刻,从所述神经网络模型的回放池中获取m条所述训练矩阵的数据对所述神经网络模型进行训练,直至所述神经网络模型的损失函数收敛或迭代到最大次数,得到训练后的神经网络训练模型；S50.在所述能量交易场中,将买卖双方需要交易特征构成的状态矩阵输入至所述神经网络训练模型,得到买卖双方交易的能量；状态转移函数f(S-t,A-t)的表达式为：                  式中,为电动汽车i的第二状态矩阵,分别为电动汽车i在t+1时刻的剩余停靠时间、交易电量、交易标价和买卖标签；其中,电动汽车i在t+1时刻所需的交易电量的表达式为：                  式中,为电动汽车i在t时刻所需的交易电量,为电动汽车i在t时刻的买卖标签,为动作矩阵中元素在t时刻电动汽车i向电动汽车j购买的能量；电动汽车i在t+1时刻交易标价表达式为：                                    式中,μ-1,分别为变量x满足的正态分布的均值和方差；其中,当时,电动汽车i在t+1时刻的剩余停靠时间和买卖标签表达式如下：                                    式中,为电动汽车i在t时刻的剩余停靠时间；当时,电动汽车i在t+1时刻的剩余停靠时间、交易电量和买卖标签的表达式如下：                                                      式中,μ-2和分别为电动汽车在能量交易场的停靠时间所满足正态分布的均值和方差,μ-3和是电动汽车需要交易的能量所满足的正态分布的均值和方差,变量x是N个状态向量满足正态分布的随机变量。</td>   <td>G06Q40/04;G06Q50/06;G06Q20/10;G06Q20/06;G06F16/27;G06F21/64;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              唐秀雯;                   蒋子规       </td>   <td>中山大学</td>   <td>一种区块链智能合约推荐方法及装置</td>   <td>广东省</td>   <td>CN113095939B</td>   <td>2022-02-08</td>   <td>本申请提供的一种区块链智能合约推荐方法及装置,其中方法包括：建立区块链地址集,区块链地址集包括：第一区块链地址和第二区块链地址；以交易记录信息中的交易量和交易成交价格为自变量,结合皮尔森相关系数计算公式,分别计算出区块链地址集中各个区块链地址的价格敏感度系数；根据各个区块链地址的价格敏感度系数,从区块链地址集确定第三区块链地址,根据第三区块链地址的智能合约调用记录,确定待推荐智能合约,并将待推荐智能合约推荐至第一区块链地址。针对性地向该区块链地址对应的用户推荐符合其交易群体偏好及交易价格的智能合约,解决了现有的智能合约推荐方式的推荐准确度低的技术问题。</td>   <td>1.一种区块链智能合约推荐方法,其特征在于,包括：基于区块链地址的交易记录信息,确定与第一区块链地址存在交易关系的第二区块链地址,并建立区块链地址集,所述区块链地址集包括：所述第一区块链地址和所述第二区块链地址；以所述交易记录信息中的交易量和交易成交价格为自变量,结合皮尔森相关系数计算公式,分别计算出所述区块链地址集中各个区块链地址的价格敏感度系数；其中,所述区块链地址的价格敏感度系数的计算过程具体包括：当所述区块链地址的交易记录信息为一条时,以所述交易记录信息中的交易量和交易成交价格为自变量,结合皮尔森相关系数计算公式,计算出所述交易记录信息对应的皮尔森相关系数,并将皮尔森相关系数作为所述区块链地址的价格敏感度系数；当所述区块链地址的交易记录信息为多条时,以各个所述交易记录信息中的交易量和交易成交价格为自变量,结合皮尔森相关系数计算公式,分别计算出各个所述交易记录信息对应的皮尔森相关系数,并将各个皮尔森相关系数的平均值作为所述区块链地址的价格敏感度系数；根据所述各个区块链地址的价格敏感度系数,从所述区块链地址集确定第三区块链地址,其中,所述第三区块链地址为所述第二区块链地址中,价格敏感度系数最接近于第一价格敏感度系数的区块链地址,所述第一价格敏感度系数为所述第一区块链地址的价格敏感度系数；根据所述第三区块链地址的智能合约调用记录,确定待推荐智能合约,并将所述待推荐智能合约推荐至所述第一区块链地址,其中,所述待推荐智能合约为所述第三区块链地址调用过的智能合约。</td>   <td>G06Q40/04;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   马心远       </td>   <td>中山大学</td>   <td>一种基于信息论指标的水库调度模块评价方法及系统</td>   <td>广东省</td>   <td>CN114022024A</td>   <td>2022-02-08</td>   <td>本发明涉及水文水资源技术领域,提出一种基于信息论指标的水库调度模块评价方法及系统,其中包括以下步骤：获取水库中基于时间序列的入库径流Q、出库径流O和水库蓄水量V；基于信息论分别计算水库中上一时刻的入库径流与当前时刻的出库径流之间的互信息I(Q-(t-1)；O-t),上一时刻的水库蓄水量与当前时刻的出库径流之间的互信息I(V-(t-1)；O-t),以及上一时刻入库径流、水库蓄水量与当前时刻的出库径流之间的互信息I(Q-(t-1)；V-(t-1)；O-t)；运行水库调度模块,得到基于相应水库调度模型的水库径流模拟值；计算当前时刻水库的出库径流O-t与相应水库调度模型的水库径流模拟值之间的互信息,并与互信息I(Q-(t-1)；O-t)、I(V-(t-1)；O-t)和I(Q-(t-1)；V-(t-1)；O-t)进行比较,得到水库调度模块评价结果。</td>   <td>1.一种基于信息论指标的水库调度模块评价方法,其特征在于,包括以下步骤：S1、获取水库中基于时间序列的入库径流Q、出库径流O和水库蓄水量V；S2、基于信息论分别计算水库中上一时刻的入库径流与当前时刻的出库径流之间的互信息I(Q-(t-1)；O-t),上一时刻的水库蓄水量与当前时刻的出库径流之间的互信息I(V-(t-1)；O-t),以及上一时刻入库径流、水库蓄水量与当前时刻的出库径流之间的互信息I(Q-(t-1)；V-(t-1)；O-t)；S3、运行水库调度模块,所述水库调度模块中预设有若干水库调度模型,得到基于相应水库调度模型的水库径流模拟值；S4、基于信息论计算当前时刻水库的出库径流O-t与相应水库调度模型的水库径流模拟值之间的互信息,并与互信息I(Q-(t-1)；O-t)、I(V-(t-1)；O-t)和I(Q-(t-1)；V-(t-1)；O-t)进行比较,得到水库调度模块评价结果。</td>   <td>G06Q10/06;G06Q50/06;G06F30/20;G06F111/08;G06F113/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张思哲;              吴贺俊;                   韦欣典       </td>   <td>中山大学</td>   <td>一种面向农村电商物流的配送中心选址方法</td>   <td>广东省</td>   <td>CN114022069A</td>   <td>2022-02-08</td>   <td>本发明提供一种面向农村电商物流的配送中心选址方法,该方法使用了ViT和A2C作为基础的配送中心选址方法,同时建立了一个较为完整的代价计算模型来更好的评价配送中心选址的优劣,从而能够同时保证配送中心选址的高效性和准确性。</td>   <td>1.一种面向农村电商物流的配送中心选址方法,其特征在于,包括以下步骤：S1：对使用的数据集进行预处理；S2：利用步骤S1得到的数据建立代价计算模型；S3：对步骤S1得到的数据进行可视化；S4：对于步骤S3中获得的数据图,搭建深度网络模块提取其特征；S5：搭建强化学习模块,得到使代价计算模型输出最小代价的坐标的配送中心地址集合A。</td>   <td>G06Q10/08;G06Q30/06;G06F16/29;G06F16/28;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              齐志新       </td>   <td>中山大学</td>   <td>一种生产建设用地的高频次全自动遥感监测方法</td>   <td>广东省</td>   <td>CN114022413A</td>   <td>2022-02-08</td>   <td>本发明公开了一种生产建设用地的高频次全自动遥感监测方法,涉及遥感监测的技术领域,包括：按照三个不同获取时间的先后顺序将光学遥感影像依次设置为矫正影像、参考影像和检测影像；计算检测影像和参考影像、检测影像和矫正影像之间的土地平整强度,获得第一土地平整强度图像和第二土地平整强度图像；确定土地平整强度最佳阈值,利用阈值法分别提取出第一土地平整强度图像上的生产建设用地和第二土地平整强度图像上的生产建设用地,获得第一检测结果图像和第二检测结果图像,确定最终生产建设用地。本发明可以消除农作物、自然植被、山体及建筑阴影季节性变化导致的误差,实现生产建设用地高频次、全自动监测,显著提高监测精度。</td>   <td>1.一种生产建设用地的高频次全自动遥感监测方法,其特征在于,包括以下步骤：S1：获取待检测区域三个不同时间的光学遥感影像,按照三个不同获取时间的先后顺序依次设置为矫正影像、参考影像和检测影像；S2：计算检测影像和参考影像之间的土地平整强度,获得第一土地平整强度图像；计算检测影像和矫正影像之间的土地平整强度,获得第二土地平整强度图像；S3：确定土地平整强度最佳阈值；S4：根据土地平整强度最佳阈值,利用阈值法分别提取出第一土地平整强度图像上的生产建设用地和第二土地平整强度图像上的生产建设用地,获得第一检测结果图像和第二检测结果图像；S5：根据第一检测结果图像和第二检测结果图像,获得最终生产建设用地的开发情况。</td>   <td>G06T7/00;G06T7/136;G01C11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              郭韵婷;                   周凡       </td>   <td>中山大学</td>   <td>一种自动生成三分图的人像图抠图方法与系统</td>   <td>广东省</td>   <td>CN114022493A</td>   <td>2022-02-08</td>   <td>本发明公开了一种自动生成三分图的人像图抠图方法与系统。首先训练用于得到人像图语义四分类的Parsing-Net网络、用于得到初步的抠图结果的Mask-Net网络、用于得到最终的抠图结果的Trimap-Net网络；之后输入待处理的人像图到Parsing-Net中得到人像图语义四分类,对人像图语义四分类进行处理得到AOI,并结合待处理的人像图原图与对应的mask输入到Mask-Net中得到初步的抠图结果,对结果进行处理生成三分图trimap,将待处理的人像图与三分图trimap输入到Trimap-Net中得到最终的抠图结果。本发明使用人体解析的方法利用语义信息解决了自动生成trimap的问题,利用自动生成trimap实现了镂空头发的正确处理,可以更有针对性的对头发和边缘部分进行抠图,从而使人像抠图更准确。</td>   <td>1.一种自动生成三分图的人像图抠图方法,其特征在于,所述方法包括：收集包括人像图与对应alpha图在内的人像图数据集,并以此构建人像图语义四分类数据集；利用所述人像图数据集与所述人像图语义四分类数据集对改进的Self-Human-Parsing网络进行训练,得到人像图语义四分类网络Parsing-Net,Parsing-Net的输入为人像图,输出为相应的人像图语义四分类结果；对所述人像图语义四分类数据集中的每个图进行处理得到包括原图、非头发与非边缘的内部区域AOI、人像语义分割mask在内的AOI数据集,用于训练Mask-NET,之后利用所述AOI数据集输入训练完成的Mask-NET得到初步的人像抠图结果数据集；对所述初步的人像抠图结果数据集里的每个图进行处理得到包括原图、三分图trimap、alpha图在内的trimap数据集；利用所述trimap数据集,对以原图与三分图作为输入的抠图网络DIM进行重新训练,使之适用于所述trimap数据集,训练完成的网络命名为Trimap-Net；输入待处理的人像图到所述Parsing-Net中得到人像图语义四分类；对所述人像图语义四分类进行处理得到AOI,并结合待处理的人像图原图与对应的mask输入到Mask-Net中得到初步的抠图结果,对结果进行处理生成三分图trimap；将所述待处理的人像图与所述三分图trimap输入到所述Trimap-Net中得到最终的抠图结果。</td>   <td>G06T7/11;G06T7/12;G06T7/194;G06V10/764;G06V10/774;G06V10/82;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭家莉;                   谢亚娟       </td>   <td>中山大学附属口腔医院</td>   <td>单侧正锁合下颌骨功能单元的形态学测量分析系统、方法及应用</td>   <td>广东省</td>   <td>CN114022611A</td>   <td>2022-02-08</td>   <td>本发明提供了一种单侧正锁合下颌骨功能单元的形态学测量分析系统、方法及应用,所述的形态学测量分析系统包括：CBCT扫描设备,所述CBCT扫描设备用于扫描获取单侧正锁合患者的下颌骨原始模型,对原始模型进行功能单元分区；建模单元,所述建模单元用于对每一个功能单元分别进行三维建模并镜像,得到下颌骨镜像模型；拟合单元,所述拟合单元用于将原始模型与镜像模型进行拟合并匹配,获得原始模型与镜像模型的匹配度。本发明基于CBCT的三维可视化表面匹配测量分析技术实现了对下颌骨功能单元的三维形态学测量分析,可进行直观的形态学分析,使下颌骨各个功能单元左右两侧的对称性和形态差异达到可视化和量化。</td>   <td>1.一种单侧正锁合下颌骨功能单元的形态学测量分析系统,其特征在于,所述的形态学测量分析系统包括：CBCT扫描设备,所述CBCT扫描设备用于扫描获取单侧正锁合患者的下颌骨原始模型,对原始模型进行功能单元分区；建模单元,所述建模单元用于对每一个功能单元分别进行三维建模并镜像,得到下颌骨镜像模型；拟合单元,所述拟合单元用于将原始模型与镜像模型进行拟合并匹配,获得原始模型与镜像模型的匹配度。</td>   <td>G06T17/00;G06T19/20;G06F30/10;G06F30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢铮;              王若梅;              周凡;                   林格       </td>   <td>中山大学</td>   <td>基于低维图像编码与集成学习的白胚布平整度分级方法</td>   <td>广东省</td>   <td>CN108038516B</td>   <td>2022-02-01</td>   <td>本发明实施例公开了基于低维图像编码与集成学习的白胚布平整度分级方法。该方法主要通过特征提取来生成图像编码,然后通过机器学习来生成学习器,最后通过集成学习的思想来综合多个基学习器的结果得到最后结果。实施本发明实施例,使用计算机自动化的方法来对图像平整度进行客观、准确的评级,利用特征中心直方图作为图像编码,极大降低了编码维数,减少学习器计算量；使用集成学习的策略为最后结果提供可靠的保证,从而在节省人工成本的同时降低主观误差,并且在分级结果上能达到资深工程师的评级能力。</td>   <td>1.基于低维图像编码与集成学习的白胚布平整度分级方法,其特征在于,所述方法包括：图像和标签预处理；基于预处理结果提取图像的皱褶特征中心；基于特征中心对数据集中图像进行编码；评级参考系的建立与验证；其中,所述图像和标签预处理,具体为：将彩色图像变成灰度图像；对灰度图像进行自适应中值滤波,去除日常拍摄时引入的校验噪声；选取并裁剪图像皱褶的有效区域；对裁剪的有效区域进行直方图均衡化处理,降低成像误差；对数据集中图像的皱褶等级数值进行向量化处理,便于基学习器的训练；其中,所述提取图像的皱褶特征中心,具体为：生成MR8滤波器组：MR8滤波器组由38个滤波器组成,其中包括36个各向异性滤波器和2个同向滤波器,36个各向异性滤波器中包括一阶微分高斯滤波器和分割微分高斯滤波器；2个同向滤波器分别是高斯滤波器和拉普拉斯高斯滤波器；提取任一个皱褶级别的局部特征向量集：在一个皱褶级别图片中随机选取70％的图片,共14张作为生成该皱褶级别特征中心的数据集；图像有效区域设为426×426；以图像的第25行、第25列的像素为中心截取49×49区域与所述MR8滤波器组进行卷积运算,选取共38个卷积响应值中最大的8个响应值作为局部区域的特征；经过多步操作最终在单张图片上提取到256个8维的特征向量；一个皱褶级别选取了14张图像,因此最后对于一个褶皱级别共提取了14×256个8维局部特征向量；卷积计算公式为：                  其中I-(i,j)代表被截取的49×49的局部区域第i行j列的像素的灰度,F-(i,j)代表滤波器对应位置的值,卷积的实质就是对应位置相乘后,所有位置求和就是卷积的响应值；对局部特征向量集使用聚类方法进行聚类,获得m个聚类中心,并由m个聚类中心与n个皱褶级别得到m×n个特征中心；其中,所述对数据集中图像进行编码,具体为：求出m×n个特征中心出现的频率直方图,把各特征中心出现频数排成m×n维向量以作为该图像的编码,并对编码进行归一化处理；对数据集所有的图像都进行前述处理,得到所有图像的m×n维向量编码；其中,所述评级参考系的建立与验证,具体为：选取训练集和测试集；将训练集图像的编码与第一个工程师评级的结果组成训练集,使用支持向量机来训练第一个基学习器；将训练集图像的编码与第二个工程师评级的结果组成训练集,使用K近邻算法来训练第二个基学习器,计算该编码与所有训练集的欧氏距离；将训练集图像的编码与第三个工程师评级的结果组成训练集,使用K近邻算法来训练第三个基学习器,计算该编码与所有训练集的曼哈顿距离；取三个基学习器输出结果的平均值作为最后结果输出；利用测试集来验证分类器的泛化能力,验证的方法采用的是皱褶分层验证和交叉验证法。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;                   肖小粤       </td>   <td>中山大学</td>   <td>一种基于多模型堆栈融合的项目风险评级方法及装置</td>   <td>广东省</td>   <td>CN109472462B</td>   <td>2022-02-01</td>   <td>本发明公开一种基于多模型堆栈融合的项目风险评级方法及装置,本装置用实现本方法,包括：数据预处理提取训练集,将训练集拼接成项目文档的语料库；对语料库进行特征构建,构建tf-idf特征、Doc2Vec特征、Word2Vec特征及统计特征,采用两层的多模型堆栈策略,对训练集进行上述特征概率训练,输出项目风险评级结果。本发明通过挖掘项目白皮书中的关键信息,找出与风险评级有关的重要因素,构建一个基于多模型堆栈融合的风险评级模型。训练好的模型能够汇聚过去评级人员的风险评级经验,并且自主学习项目白皮书与评级之间的关联,从而为评级人员提供评级建议,以辅助评级人员,提供评级的准确性和效率。</td>   <td>1.一种基于多模型堆栈融合的项目风险评级方法,其特征在于,包括：S10数据预处理：对输入的项目文档进行预处理,以从项目文档中提取训练集,将训练集拼接成项目文档的语料库；S101多种分词处理；对输入的项目文档分别使用结巴分词JIEBA、自然语言处理与信息检索共享平台NLPIR、中文词法分析工具包THULC和语言技术平台LTP的分词方案进行分词处理,每种分词方案构建每个文档的词语数据库；S102去除无意义信息：去除分词后词语数据库中的停用词、特殊符号、标点符号和标记信息,提取训练数据；S20特征构建：对语料库进行特征构建,构建tf-idf特征、Doc2Vec特征、Word2Vec特征及统计特征,其中：tf-idf特征为将语料库输入至TF-IDF模型所提取的每个项目文档的tf-idf特征；Doc2Vec特征为采用Doc2Vec方法将预处理后的训练集输入Doc2Vec模型,获得的项目文档的固定长度的特征向量；Word2Vec特征为将语料库输入至Word2Vec模型,获得项目文档的Word2Vec特征；统计特征包括提取项目文档中关键词出现次数的次数统计和对项目文档中的金额统计；S30采用两层的多模型堆栈策略,对训练集进行上述特征概率训练；所述两层的多模型中第一层模型包括逻辑回归模型、朴素贝叶斯模型、支持向量机模型和神经网络模型；第二层模型包括XGBoost模型,所述S30包括：S301将训练集划分为训练折和验证折,训练折用于进行模型的训练学习；验证折用于模型的预测；S302分别用逻辑回归模型、朴素贝叶斯模型和支持向量机模型来训练tf-idf特征,学习项目白皮书中的用词特点；用神经网络模型来训练Doc2Vec模型生成的文档向量特征,学习项目白皮书中的词语的语义关联信息；S303训练集由训练折在第一层模型训练后再经过验证折在第一层模型验证,由逻辑回归模型、朴素贝叶斯模型、支持向量机模型和神经网络模型依次获得预测结果为概率文件1、概率文件2、概率文件3和概率文件4；S304将概率文件1、概率文件2、概率文件3和概率文件4拼接起来,输入XGBoost模型,利用Word2Vec特征、统计特征训练XGBoost模型,获得更深入的学习项目白皮书与评级目标之间的联系；S305输出项目风险评级预测结果；S40输出项目风险预测评级结果。</td>   <td>G06Q10/06;G06Q10/04;G06K9/62;G06V10/764;G06F40/30;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              云东源;              刘力学;              吴晓航;                   晏丕松       </td>   <td>中山大学中山眼科中心;云智道智慧医疗科技(广州)有限公司</td>   <td>一种基于区块链的医疗图像标注运营方法和装置</td>   <td>广东省</td>   <td>CN114004460A</td>   <td>2022-02-01</td>   <td>本发明提供了一种基于区块链的医疗图像标注运营方法和装置,所述方法包括：向平台上用户展示医疗图像标注任务并产生第一业务数据,通过区块链系统存储第一业务数据；响应第二用户完成医疗图像标注任务的确认操作,接收所述第二用户上传的、与医疗图像标注任务对应的可用数据集；当所述可用数据集满足医疗图像标注任务的要求时,生成第二业务数据,并通过所述区块链系统存储第二业务数据,以使所述区块链系统根据所述第二业务数据在第二用户对应的区块链账户上增加相应的积分。本发明将医疗图像标注数据系统化和平台化,标注人员的劳动成果可通过积分的方式记录和积累,提高人员的工作积极性和标注水平,同时提高了医疗图像的标注质量。</td>   <td>1.一种基于区块链的医疗图像标注运营方法,其特征在于,包括：向平台上所有用户展示医疗图像标注任务并产生第一业务数据,并通过区块链系统存储所述第一业务数据；其中,所述医疗图像标注任务由第一用户或运营方发布,用于供所述平台上的其他用户对若干个待标注的医疗图像进行标注处理；响应第二用户完成所述医疗图像标注任务的确认操作,接收所述第二用户上传的、与所述医疗图像标注任务对应的可用数据集；当所述可用数据集满足所述医疗图像标注任务的要求时,生成第二业务数据,并通过所述区块链系统存储所述第二业务数据,以使所述区块链系统根据所述第二业务数据在所述第二用户对应的区块链账户上增加相应的积分。</td>   <td>G06Q10/06;G06Q40/04;G06K9/62;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈鹏飞;              陈彩琳;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于知识图谱的云原生系统故障分析方法</td>   <td>广东省</td>   <td>CN112540832B</td>   <td>2022-01-28</td>   <td>本申请公开了一种基于知识图谱的云原生系统故障分析方法,包括：获取云原生系统中的原始数据,并基于原始数据构建知识图谱,得到图数据；通过异常检测模型对图数据进行异常检测,得到异常节点；计算异常节点和异常节点对应的副本节点的相似度,并基于相似度进行故障根因定位,其中,异常节点对应的副本节点为与异常节点同类型的节点。本申请解决了现有技术忽略了实体之间的交互关系,只能定位到发生故障的实体,难以快速和准确地定位云原生系统的故障根因的技术问题。</td>   <td>1.一种基于知识图谱的云原生系统故障分析方法,其特征在于,包括：获取云原生系统中的原始数据,并基于所述原始数据构建知识图谱,得到图数据,所述原始数据包括实体信息和网络连接数据,所述获取云原生系统的原始数据包括：获取云原生系统中的所述实体信息,所述实体包括容器,Process和File；通过nsenter工具进入容器的命名空间,将宿主机的netstat文件所在目录挂载到容器的文件系统上；在容器中执行nsenter命令获取所述网络连接数据；所述基于所述原始数据构建知识图谱,得到图数据包括：对所述原始数据依次进行实体抽取、实体关系抽取以及实体属性抽取,其中,所述实体属性包括静态属性和动态属性；基于抽取的所述实体、所述实体关系以及所述实体属性构建知识图谱,得到图数据；通过异常检测模型对所述图数据进行异常检测,得到异常节点；计算所述异常节点和所述异常节点对应的副本节点的相似度,并基于所述相似度进行故障根因定位,其中,所述异常节点对应的副本节点为与所述异常节点同类型的节点。</td>   <td>G06F9/455;G06F16/36;G06K9/62;G06N3/04;G06N3/08;G06V10/74;G06V10/82</td>  </tr>        <tr>   <td>中国专利</td>   <td>         殷金昌;              邵元智;              吴双双;              张金涛;                   沈漉       </td>   <td>中山大学</td>   <td>基于机器学习的金纳米棒的合成优化方法、装置及介质</td>   <td>广东省</td>   <td>CN113988354A</td>   <td>2022-01-28</td>   <td>本发明公开了一种基于机器学习的金纳米棒的合成优化方法、装置及存储介质,该方法通过种子生成法合成若干组金纳米棒；使用紫外-可见光分子吸收光谱分别表征每一组金纳米棒的纵向最佳吸收峰峰位和纵/横最佳吸收峰强度比,以构建数据集；然后将数据集输入训练好的XGBoost预测模型中进行预测,得到预测结果；再根据所述预测结果,分析金纳米棒合成工艺与吸收光谱性能之间的映射关系,和获取金纳米棒合成工艺中各项参数的重要性排序；从而能够对金纳米棒的合成进行优化,进而能够指导合成高长径比、高产率、高质量的金纳米棒,加快金纳米棒功能性材料的研发进展。本发明可广泛应用于金纳米棒的合成技术领域。</td>   <td>1.一种基于机器学习的金纳米棒的合成优化方法,其特征在于,包括：通过种子生成法合成若干组金纳米棒；使用紫外-可见光分子吸收光谱分别表征每一组金纳米棒的纵向最佳吸收峰峰位和纵/横最佳吸收峰强度比,以构建数据集；将所述数据集输入训练好的XGBoost预测模型中进行预测,得到预测结果；根据所述预测结果,分析金纳米棒合成工艺与吸收光谱性能之间的映射关系；根据所述预测结果,获取金纳米棒合成工艺中各项参数的重要性排序；根据所述金纳米棒合成工艺与吸收光谱性能之间的映射关系和金纳米棒合成工艺中各项参数的重要性排序,对金纳米棒的合成进行优化。</td>   <td>G06Q10/04;G06N20/00;G06K9/62;B82Y40/00;B22F9/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         涂新军;              庞万宁;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种旱涝急转评估方法</td>   <td>广东省</td>   <td>CN113988673A</td>   <td>2022-01-28</td>   <td>本发明公开一种旱涝急转评估方法,包括以下步骤：S1、收集某时段的气象水文系列数据；S2、基于气象水文系列数据计算得到旱涝指数；S3、利用旱涝指数,计算得到标准化旱涝急转指数；S4、根据旱涝急转等级划分标准,对得到的标准化旱涝急转指数的值进行等级划分。本发明可解决已有技术对旱涝急转的错判和漏判问题,使旱涝急转的等级分类与常规的旱涝等级分类在阈值设置和定性上保持一致,有利于旱涝评估体系的统一。</td>   <td>1.一种旱涝急转评估方法,其特征在于,包括以下步骤：S1、收集某时段的气象水文系列数据；S2、基于气象水文系列数据计算得到旱涝指数；S3、利用旱涝指数,计算得到标准化旱涝急转指数；S4、根据旱涝急转等级划分标准,对得到的标准化旱涝急转指数的值进行等级划分。</td>   <td>G06Q10/06;G06Q50/26;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨夏;              郭贵松;              覃军友;                   张小虎       </td>   <td>中山大学</td>   <td>一种物体表面高精度定位方法及系统</td>   <td>广东省</td>   <td>CN113989368A</td>   <td>2022-01-28</td>   <td>本发明公开了一种物体表面高精度定位方法及系统,该方法包括：在物体表面制作预设分布密度的标记；对带标记的物体进行拍摄,并编号图像中的标记；获取物体表面各个标记的相对位置信息并建立标记编号与标记位置信息的对应关系；获取实时待测图像并检测实时待测图像内的标记；计算得到当前实时待测图像所对应的物体表面位置。该系统包括：标记制作模块、编号模块、标记位置关系模块、待测图像模块和物理量解算模块。通过使用本发明,能够通过单台相机拍摄物体表面的自带特征或制作的纹理特征,实现物体二维平移、三维平移、二维转角等参数的高精度测量。本发明可广泛应用于测量技术领域。</td>   <td>1.一种物体表面高精度定位方法,其特征在于,包括以下步骤：在物体表面制作预设分布密度的标记,得到带标记的物体；对带标记的物体进行拍摄,并编号图像中的标记,得到带编号标记的图像；根据带编号标记的图像获取物体表面各个标记的相对位置信息并建立标记编号与标记位置信息的对应关系；获取实时待测图像并检测实时待测图像内的标记,得到待测标记；根据待测标记在实时待测图像中的位置以及该标记对应的物体表面位置信息,计算得到当前实时待测图像所对应的物体表面位置。</td>   <td>G06T7/73;G06T7/46;G06T3/40;G06K9/62;G01B11/26;G01B11/03;G01B11/02;G01B11/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张琳;              夏俊宇;                   陈建原       </td>   <td>中山大学</td>   <td>一种结合小波变换的并行降噪方法及系统</td>   <td>广东省</td>   <td>CN113971420A</td>   <td>2022-01-25</td>   <td>本发明提出了一种结合小波变换的并行降噪方法,包括获取待降噪信号,根据噪声类型将信号分为微弱噪声信号、一般噪声信号和强噪声信号；构建深度残差网络、Res-NN网络、BP-CNN网络并进行训练；利用中值滤波器对微弱噪声信号进行降噪,输出降噪后的信号,再通过Res-NN网络进行译码；结合深度残差网络与Res-NN网络对一般噪声信号进行降噪,并进行译码；利用小波变换算法结合BP-CNN网络对强噪声信号进行降噪和译码；最终得到译码完成的信号。本发明还提出一种并行降噪系统,通过将实际生产实践中容易遇到的噪声分成三种类型,结合传统降噪的方法对噪声进行额外处理的同时,与神经网络技术相配合,实现对三种不同类型噪声的降噪处理,令本方案可以更好地适应实际使用需求。</td>   <td>1.一种结合小波变换的并行降噪方法,其特征在于,包括以下步骤：S1：获取待降噪信号,根据噪声类型对信号进行分类,得到微弱噪声信号、一般噪声信号和强噪声信号；S2：构建深度残差网络和Res-NN网络并进行训练；构建BP-CNN网络并进行训练；S3：利用中值滤波器对微弱噪声信号进行降噪,输出降噪后的信号,再通过Res-NN网络进行译码；结合深度残差网络与Res-NN网络对一般噪声信号进行降噪,并进行译码,输出译码后的信号；利用小波变换算法结合BP-CNN网络对强噪声信号进行降噪,输出降噪译码后的信号；S4：最终得到译码完成的信号。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姚顺;              铁艳梅;                   王海军       </td>   <td>中山大学附属第一医院</td>   <td>一种基于功能核磁共振成像的术前语言区定位方法及系统</td>   <td>广东省</td>   <td>CN113962966A</td>   <td>2022-01-21</td>   <td>本发明公开了一种基于功能核磁共振成像的术前语言区定位方法及系统,包括：在待测人员观影时进行核磁共振扫描,获取观影模式FMRI数据；对观影模式FMRI数据进行预处理,获得预处理后的数据,并对预处理后的数据进行分析,完成大脑语言网络提取与鉴定,即语言区定位。本发明设计了较为新颖的实验范式,即基于中文语言的观影模式功能核磁共振试验范式,同时采用了稳健的神经信息提取与处理技术,可以较为理想地构建出脑损伤患者的大脑语言网络,最终建立了临床应用工作框架,具有较高的科学价值和神经外科临床应用前景。</td>   <td>1.一种基于功能核磁共振成像的术前语言区定位方法,其特征在于,包括：S1、在待测人员观影时进行功能核磁共振图像扫描,获取观影模式FMRI数据,同时扫描大脑三维高分辨率结构核磁共振图像MPRAGE；S2、对所述观影模式FMRI、MPRAGE进行预处理,得到预处理后的数据；S3、并对预处理后的数据进行分析,完成大脑语言区定位。</td>   <td>G06T7/00;G06T7/11;G06T7/30;G06T5/00;A61B5/055</td>  </tr>        <tr>   <td>中国专利</td>   <td>         侯卫生;                   刘恒光       </td>   <td>中山大学</td>   <td>一种融合深度学习和多点统计学的地质建模方法及装置</td>   <td>广东省</td>   <td>CN113963123A</td>   <td>2022-01-21</td>   <td>本发明公开了一种融合深度学习和多点统计学的地质建模方法及装置。本发明通过在三维模拟网格中将二维训练图像转换为三维训练图像,得到三维网格图像后,利用深度神经网络提取三维网格图像中的地质结构的全局空间特征来建立初始地质模型,并对初始地质模型进行序贯模拟和地层层序校验,利用多尺度EM迭代最终实现建立最优地质模型,能够融合深度学习和多点统计学进行地质建模,对具有各向异性、方向延展性、非平稳特征的地质体或地质结构进行合理的三维重构,有利于建立精细化的地质模型。</td>   <td>1.一种融合深度学习和多点统计学的地质建模方法,其特征在于,包括：将获取的二维训练图像导入三维模拟网格,得到在三维空间中表示的二维网格图像,并在所述三维模拟网格中将所述二维训练图像转换为三维训练图像,得到三维网格图像；分别从所述三维网格图像中提取空间模式数据和深度学习训练数据,建立空间模式数据库和深度学习训练数据集,并从所述二维网格图像中提取地层层序数据,建立地层层序数据库；根据所述三维网格图像构建深度神经网络,利用所述深度学习训练数据集训练所述深度神经网络,基于训练后的深度神经网络预测所述三维网格图像中待模拟网格的目标属性值的曲面网格体,并将所述曲面网格体中所有待模拟网格的属性值设置为所述目标属性值,建立初始地质模型；根据所述空间模式数据库对所述初始地质模型进行序贯模拟,得到中间地质模型,并根据所述地层层序数据库对所述中间地质模型进行地层层序校验,在校验成功时将所述中间地质模型作为地质模型,在校验失败时重新进行序贯模拟和地层层序校验直至得到所述地质模型；根据所述三维训练图像对所述地质模型进行多尺度迭代模拟,得到优化后的地质模型,并在当前尺度达到预设精度且累计迭代次数达到预设迭代次数时,将当前所述优化后的地质模型作为输出的最优地质模型。</td>   <td>G06T17/05;G06T17/20;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         姜园;              陈婵嫔;                   王斌       </td>   <td>中山大学</td>   <td>一种基于阵列信号相位差矢量的信号检测方法与系统</td>   <td>广东省</td>   <td>CN113947120A</td>   <td>2022-01-18</td>   <td>本发明提供一种基于阵列信号相位差矢量的信号检测方法与系统,方法通过求解接收阵列不同阵元间接收信号的相位差来构造相位差矢量,将时间前后多段数据的相位差矢量相关系数均值作为检测参数,减少环境干扰的影响,与现有算法相比,本发明提出的方案计算复杂度基本不变,检测效果更优,即没有增加计算复杂度的前提下,保证且提高了阵列信号处理的优势,在低信噪比的情况下检测性能好。</td>   <td>1.一种基于阵列信号相位差矢量的信号检测方法,其特征在于,包括以下步骤：S1：生成多个阵元的高斯白噪声信号；S2：根据所述高斯白噪声信号构造多个连续时间下的噪声信号相位差矢量,根据所述多个连续时间下的噪声信号相位差矢量求解噪声信号相位差矢量相关系数均值；S3：重复步骤S2计算多个噪声信号相位差矢量相关系数均值,所述噪声信号相位差矢量相关系数均值服从正态分布,获取所述噪声信号相位差矢量相关系数均值的均值和标准差；S4：根据S3获取的所述噪声信号相位差矢量相关系数均值的均值和标准差,设置判决门限；S5：输入阵元接收信号；S6：根据所述阵元接收信号构造多个连续时间下的接收信号相位差矢量,根据所述多个连续时间下的接收信号相位差矢量求解接收信号相位差矢量相关系数均值；S7：比较接收信号相位差矢量相关系数均值与步骤S4设置的判决门限；S8：输出判决结果。</td>   <td>G06K9/00;G06F17/14;G06F17/16;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   黄悦       </td>   <td>中山大学</td>   <td>一种基于可逆流网络的无监督动作风格迁移方法</td>   <td>广东省</td>   <td>CN113947525A</td>   <td>2022-01-18</td>   <td>本发明公开了一种基于可逆流网络的无监督动作风格迁移方法,包括步骤如下：S1：获取BVH格式的动作数据并进行预处理,将预处理后的动作数据作为训练样本；所述的动作数据包括内容动作、风格动作；S2：构建动作风格迁移模型,所述的动作风格迁移模型包括用于编码动作隐藏特征的投影流网络、用于隐藏特征风格迁移的自适应实例归一化层；S3：采用训练样本训练动作风格迁移模型,在每一轮训练中利用损失函数对动作风格迁移模型参数进行调整；S4：将待迁移的动作数据输入训练好的动作风格迁移模型,实现进行任意两个动作的风格迁移。本发明能在降低训练数据要求的情况下,保留内容的完整性,并且不降低风格迁移的效果。</td>   <td>1.一种基于可逆流网络的无监督动作风格迁移方法,其特征在于：所述的方法包括步骤如下：S1：获取BVH格式的动作数据并进行预处理,将预处理后的动作数据作为训练样本；所述的动作数据包括内容动作、风格动作；S2：构建动作风格迁移模型,所述的动作风格迁移模型包括用于编码动作隐藏特征的投影流网络、用于隐藏特征风格迁移的自适应实例归一化层；S3：采用训练样本训练动作风格迁移模型,在每一轮训练中利用损失函数对动作风格迁移模型参数进行调整；S4：将待迁移的动作数据输入训练好的动作风格迁移模型,实现进行任意两个动作的风格迁移。</td>   <td>G06T3/00;G06T13/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              李博洋;              李洁铃;                   陈渤林       </td>   <td>中山大学</td>   <td>一种融合强度与时空几何特征的激光雷达去雪方法和系统</td>   <td>广东省</td>   <td>CN113947552A</td>   <td>2022-01-18</td>   <td>本发明提供了一种融合强度与时空几何特征的激光雷达去雪方法和系统,涉及自动驾驶环境感知技术领域,通过结合强度邻域数量的反射强度信息和时空邻域数量的空间特征信息对点云数据进行去雪处理,提高去雪算法的准确性和适应性,在有效去除激光雷达点云数据中的雪噪点的同时,降低点云数据中非雪噪点的损失,从而降低对点云数据中环境信息的破坏。能够自适应多种密度的降雪。</td>   <td>1.一种融合强度与时空几何特征的激光雷达去雪方法,其特征在于,所述方法包括步骤：S1、获取激光雷达实际的点云数据,对实际的点云数据进行过滤,得到候选雪噪点；S2、根据雪花在实际的点云数据单帧点云帧中的雪花周围点云分布密度特性,计算候选雪噪点在当前时刻的点云帧中的强度邻域数量；S3、对具有候选雪噪点的点云帧以及其相邻点云帧通过主成分分析法进行降维,提取宽度-时间图像,所述相邻点云帧是指具有候选雪噪点的点云帧的前后若干帧；S4、基于雪花的运动规律特性,根据所述宽度-时间图像,计算候选雪噪点在宽度-时间图像上的时空邻域数量；S5、基于熵权法利用强度邻域数量和时空邻域数量计算综合评分,然后根据综合评分对候选雪噪点进行最终分类得到真雪噪点和非噪点；S6、剔除真雪噪点实现过滤,把非噪点恢复为普通点云点实现修复。</td>   <td>G06T5/00;G06V10/77;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              刘奕志       </td>   <td>中山大学中山眼科中心</td>   <td>一种捕获和分析目标的图像数据的系统</td>   <td>广东省</td>   <td>CN113947592A</td>   <td>2022-01-18</td>   <td>本发明涉及一种捕获和分析目标的图像数据的系统,包括：图像获取单元,用于获取眼底彩照；图像预处理单元,用以对所述眼底彩照进行预处理；图像分析单元,用以根分析所述眼底彩照中是否存在感兴趣区,图像分析单元在眼底彩照上建立坐标系以确定感兴趣区的位置,在感兴趣区位置确定完成时,图像分析单元将感兴趣区的位置发送至病灶扫描单元；所述病灶扫描单元,用以扫描所述眼底彩照中各感兴趣区位置以确定各感兴趣区进行扫描；储存单元,用以储存各阶段的数据；通过本发明可以更加精准的判定是否存在感兴趣区,进而精确地对标记的感兴趣区进行扫描,提高了扫描眼底的准确性和灵活性,进一步的节约了本发明系统的扫描时间。</td>   <td>1.一种捕获和分析目标的图像数据的系统,其特征在于,包括：图像获取单元,用于获取眼底彩照；图像预处理单元,其与所述图像处理单元连接,用以对所述眼底彩照进行预处理,当眼底彩照像最外侧存在黑框时,图像处理单元将去除眼底彩照像最外侧存在的黑框；图像分析单元,其与所述图像预处理单元连接,用以根据所述眼底彩照中血管边缘的清晰度D以分析所述眼底彩照中是否存在感兴趣区,图像分析单元在眼底彩照上建立坐标系以确定感兴趣区的位置,在感兴趣区位置确定完成时,图像分析单元将感兴趣区的位置发送至病灶扫描单元；所述病灶扫描单元,其与图像分析单元连接,用以扫描所述眼底彩照中各感兴趣区位置以确定各感兴趣区进行扫描；储存单元,其与所述图像获取单元、所述图像预处理单元、所述图像分析单元和所述病灶扫描单元连接,用以储存各阶段的数据。</td>   <td>G06T7/00;G06T7/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         祁金利;              孙蕾;              李铿鹏;                   钟奋发       </td>   <td>中山大学</td>   <td>一种图像的噪声估计方法、装置及存储介质</td>   <td>广东省</td>   <td>CN113947594A</td>   <td>2022-01-18</td>   <td>本发明涉及图像处理技术领域,公开了一种图像的噪声估计方法、装置及存储介质。本发明将待估计图像进行分块,并对所得的含噪图像块进行筛选以得到待估计的含噪图像块,通过向待估计的含噪图像块加入多个不同噪声标准差的高斯白噪声,得到相应数量的新含噪图像块,进而通过各新含噪图像块的尾部奇异值均值计算待估计的含噪图像块的噪声标准差估计值,对各待估计的含噪图像块的噪声标准差估计值取平均,从而得到待估计图像的噪声标准差估计值；本发明实施例通过多次加入随机噪声实现原始噪声标准差的估计,从概率上减小了估计方法的偶然性,使得估计结果更为稳定,提高了估计精度。</td>   <td>1.一种图像的噪声估计方法,其特征在于,包括：对待估计图像进行分块处理得到多个含噪图像块；从所述多个含噪图像块中筛选待估计的含噪图像块；向所述待估计的含噪图像块加入多个不同噪声标准差的高斯白噪声,得到对应的多个新含噪图像块；对每个所述新含噪图像块进行奇异值分解并计算对应的尾部奇异值均值,根据各所述尾部奇异值均值计算所述待估计的含噪图像块的噪声标准差估计值；对所有待估计的含噪图像块的噪声标准差估计值取平均,得到所述待估计图像的噪声标准差估计值。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韦艳宏;              钟霞丽;              陈俊周;                   朱启诚       </td>   <td>中山大学</td>   <td>一种利用非传统形态学指标评价化学物血管毒性的方法</td>   <td>广东省</td>   <td>CN113936024A</td>   <td>2022-01-14</td>   <td>本发明公开了一种利用非传统形态学指标评价化学物血管毒性的方法,包括：获取经过化学物处理的样本中的血管图像,并经过图像分割处理得到目标血管；对所述目标血管进行形态学分析,得到初始血管指标数据,所述初始血管指标数据包括传统形态学指标数据和非传统形态学指标数据中至少一种；根据马氏距离法对所述初始血管指标数据进行离群值剔除处理,得到目标血管指标数据；根据独立样本t检验对所述目标血管指标数据进行均值比较,筛选得到敏感靶血管。本发明能够全面以及敏感地评价化学物的血管毒性,能够广泛应用于血管毒性检测技术领域。</td>   <td>1.一种利用非传统形态学指标评价化学物血管毒性的方法,其特征在于,包括：获取经过化学物处理的样本中的血管图像,并经过图像分割处理得到目标血管；对所述目标血管进行形态学分析,得到初始血管指标数据,所述初始血管指标数据包括传统形态学指标数据和非传统形态学指标数据中至少一种；根据马氏距离法对所述初始血管指标数据进行离群值剔除处理,得到目标血管指标数据；根据独立样本t检验对所述目标血管指标数据进行均值比较,筛选得到敏感靶血管。</td>   <td>G06T7/155;G06T7/11;G01N21/64;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              庄文梓;                   黄立峰       </td>   <td>中山大学</td>   <td>一种面向集成模型的鲁棒性提升防御方法</td>   <td>广东省</td>   <td>CN113935496A</td>   <td>2022-01-14</td>   <td>本发明公开了一种面向集成模型的鲁棒性提升防御方法,包括步骤如下：S1：在每个训练样本上提取所有子模型的非鲁棒特征样本；S2：选取未训练的子模型,将其他子模型提取的非鲁棒特征样本分别输入该子模型进行训练；S3：通过结合特征层混合方法,将非鲁棒特征样本在正在训练的子模型的第t层中间特征层的输出值,以不同的比例混合为一个中间层输出feature-map；S4：将混合得到的feature-map继续输入该正在训练的子模型进行前向传播,计算交叉熵更新该子模型的参数；S5：对集成模型中的所有子模型都分别经过上述步骤S1～S5进行训练,直到所有子模型达到最大训练轮数,则得到最终的子模型。通过本发明训练得到的集成模型,不仅能有效防御白盒攻击和黑盒攻击方法,同时还基本不影响对干净样本的识别率。</td>   <td>1.一种面向集成模型的鲁棒性提升防御方法,其特征在于：所述的方法包括步骤如下：S1：在每个训练样本上提取所有子模型的非鲁棒特征样本；S2：选取未训练的子模型,将其他子模型提取的非鲁棒特征样本分别输入该子模型进行训练,子模型间通过相互训练彼此生成的非鲁棒特征样本,以学习彼此的“脆弱性”；S3：通过结合特征层混合方法,将非鲁棒特征样本在正在训练的子模型的第t层中间特征层的输出值,以不同的比例混合为一个中间层输出feature-map；S4：将混合得到的feature-map继续输入该正在训练的子模型进行前向传播,计算交叉熵更新该子模型的参数；S5：对集成模型中的所有子模型都分别经过上述步骤S1～S5进行训练,直到所有子模型达到最大训练轮数,则得到最终的子模型。</td>   <td>G06N20/20;G06N3/08;G06V10/774</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              郭珊珊;              郭佳俊;                   印鉴       </td>   <td>中山大学</td>   <td>结合场景上下文和行人社会关系的行人轨迹预测方法、系统及存储介质</td>   <td>广东省</td>   <td>CN113920170A</td>   <td>2022-01-11</td>   <td>本发明涉及行人轨迹预测技术,具体为结合场景上下文和行人社会关系的行人轨迹预测方法、系统及存储介质,其方法包括：获取行人轨迹预测的公开数据集,划分训练集和测试集；对视频数据和行人轨迹数据进行预处理,获得静态场景图像；对静态场景图像语义分割得到语义分割图像；构建行人轨迹时空图,构建每一帧的空间图,将所有时间序列的空间图组成时空图；对静态场景图像和时空图使用不同卷积网络进行特征提取,得到场景特征张量和行人特征张量,融合得到组合特征张量后输入行人轨迹预测模型,预测行人未来的轨迹。本发明能够把场景上下文中包含的语义信息、行人间关系共同建模,并保留行人与场景之间的空间关系,提高了行人轨迹预测精度。</td>   <td>1.结合场景上下文和行人社会关系的行人轨迹预测方法,其特征在于,包括以下步骤：S1、获取关于行人轨迹预测的公开数据集,其中包括在不同场景下长度不等的视频数据和视频中对应的行人坐标轨迹数据表；S2、划分训练集和测试集；S3、数据预处理,对于视频数据,获取每段不同视频中抹去运动行人后对应的静态场景图像；对于行人轨迹数据,根据时间帧进行采样,得到统一帧间隔和帧数的轨迹,并对不同数据集中行人坐标尺度进行归一化；S4、对提取出的静态场景图像进行分辨率统一调整后输入预训练好语义分割网络中,并对得到的图像进行统一调整,得到语义分割图像；S5、构建行人轨迹时空图,使用每一帧中行人的坐标点和该坐标点对应的语义标签作为顶点信息构建该帧对应的空间图,并将行人轨迹中所有时间序列的空间图组成时空图,用来表示轨迹中行人与行人之间的社会关系；S6、分别对静态场景图像和时空图使用不同的卷积神经网络进行特征提取,得到场景特征张量和行人特征张量,再使用特征融合方法得到最后的组合特征张量；S7、预测行人轨迹,先对预测网络进行训练,得到训练好的行人轨迹预测模型并保存；再把组合特征张量输入行人轨迹预测模型,预测行人未来的轨迹。</td>   <td>G06T7/246;G06V40/10;G06V10/26;G06V10/80;G06V10/82;G06V10/62;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡杜荣;                   张鹏       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于参考图像的超分辨率方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113902617A</td>   <td>2022-01-07</td>   <td>本发明公开了基于参考图像的超分辨率方法、装置、设备及介质,方法包括：对获取的原始数据集进行预处理,得到各尺度训练所需的训练集、验证集和测试集；对所述训练集进行超分辨率网络前向传播,得到SR图像；对所述SR图像进行特征融合,得到若干种尺度下的多个SR图像；对所述多个SR图像进行尺度调整,得到任意尺度下的SR图像；对原始的损失函数进行调整；根据所述验证集、所述测试集以及所述调整后的损失函数,确定目标模型,所述目标模型能够对目标图像进行超分辨率。本发明实施例实现了任意非整数尺度需求的图像超分辨率,并巧妙地避开了冗余,繁琐的多次训练过程,实用性高,可广泛应用于图像处理技术领域。</td>   <td>1.基于参考图像的超分辨率方法,其特征在于,包括：对获取的原始数据集进行预处理,得到各尺度训练所需的训练集、验证集和测试集；对所述训练集进行超分辨率网络前向传播,得到SR图像；对所述SR图像进行特征融合,得到若干种尺度下的多个SR图像；对所述多个SR图像进行尺度调整,得到任意尺度下的SR图像；对原始的损失函数进行调整；根据所述验证集、所述测试集以及所述调整后的损失函数,确定目标模型,所述目标模型能够对目标图像进行超分辨率。</td>   <td>G06T3/40;G06T7/11;G06V10/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              夏文君;              郑炎辉;              宋超;                   金浩宇       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种基于智能合约的水资源决策管理系统</td>   <td>广东省</td>   <td>CN113177731B</td>   <td>2022-01-07</td>   <td>本发明公开了一种基于智能合约的水资源决策管理系统,包括：水资源情报管理模块,用于将水资源数据上链至区块链平台,并通过区块链平台对所述水资源数据进行管理；水资源评价管理模块,用于根据水资源数据,通过智能合约对水资源指标进行评价及管理；水资源预测管理模块,用于根据水资源数据,对水量、水质进行预测及管理；以及水资源决策管理模块,用于根据水资源数据,通过智能合约对水量分配、水质调节和水源调度进行决策及管理。本发明通过区块链平台对大量分布式水资源数据进行管理,构造有效、不可篡改的水资源数据,基于该数据,通过智能合约对水资源情况进行评价、预测,并制定动态的水资源调配决策,实现公平的多尺度水资源管理。</td>   <td>1.一种基于智能合约的水资源决策管理系统,其特征在于,包括：水资源情报管理模块、水资源评价管理模块、水资源预测管理模块、水权交易模块和水资源决策管理模块；所述水资源情报管理模块用于,将水资源数据上链至区块链平台,并通过区块链平台对所述水资源数据进行管理；所述水资源评价管理模块用于,根据所述区块链平台上的水资源数据,通过智能合约对水资源指标进行评价及管理,并得到水资源评价结果；所述水资源预测管理模块用于,根据所述区块链平台上的水资源数据,对水量、水质进行预测及管理,并得到水资源预测结果；所述水权交易模块用于,构建基于Hyperledger Fabric的水权交易平台,并基于所述水权交易平台,通过智能合约实现水资源的交易、结算及监管；所述水资源决策管理模块用于,根据所述区块链平台上的水资源数据、所述水资源评价结果、所述水资源预测结果和所述水权交易平台的交易数据,通过智能合约对水量分配、水质调节、水源调度进行决策及管理；所述水资源决策管理模块通过智能合约对水量分配、水质调节、水源调度进行决策及管理的过程,包括：通过智能合约对来水信息和用水信息自动进行分析计算,按照区域、用水时段、行业性质和/或用水户对水量进行分配；通过智能合约对水质不达标的节点进行定位及整改,以及对上报水质问题的节点用户进行奖励；通过智能合约对区域之内的水库调度、跨区域的水库调度以及引进江河水的调度方案进行计算。</td>   <td>G06Q10/06;G06Q10/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              尹森堂;              张冬雨;                   王青       </td>   <td>中山大学</td>   <td>一种快速行人检测方法及装置</td>   <td>广东省</td>   <td>CN108399362B</td>   <td>2022-01-07</td>   <td>本发明公开了一种快速行人检测方法及装置,所述方法包括如下步骤：步骤S1,构建可配置的基于卷积神经网络的深度模型,利用训练样本学习出构建的网络参数,获得用于测试过程的模型；步骤S2,输入测试样本,通过训练好的模型利用神经网络感知域的变化规律使用不同的中间层对不同尺度范围内的目标物体进行检测,预测出图像中目标物体的框图,本发明通过利用神经网络感知域的变化规律,使用不同的中间层对特定尺度范围内的目标物体进行检测,更好的适应了感知域与物体大小的关系,有效提高了检测结果。</td>   <td>1.一种快速行人检测方法,包括如下步骤：步骤S1,构建可配置的基于卷积神经网络的深度模型,利用训练样本学习出构建的网络参数,获得用于测试过程的模型；步骤S2,输入测试样本,通过训练好的模型利用神经网络感知域的变化规律使用不同的中间层对不同尺度范围内的目标物体进行检测,预测出图像中目标物体的框图；步骤S1进一步包括：构建可配置的基于卷积神经网络的深度模型；输入训练样本；初始化卷积神经网络及其参数,包括网络层中每层连接的权重和偏置；采用前向传播算法和后向传播算法,利用训练样本学习出构建的网络参数,即用于测试过程的模型；所述深度模型包括多尺度的目标候选网络与目标检测网络,所述目标候选网络基于卷积神经网络不同层提出特征的差异性,在中间层分别生成对不同尺度目标物体的候选框图；所述目标检测网络在所述目标候选网络输出的候选框图的基础上进行精细化的分类和检测；所述卷积神经网络由卷积层、降采样层、上采样层堆叠而成,所述卷积层是指对输入的图像或者特征图在二维空间上进行卷积运算,提取层次化特征；所述降采样层使用没有重叠的max-pooling操作,该操作用于提取形状和偏移不变的特征,同时减少特征图大小,提高计算效率；所述上采样层,是指对输入的特征图在二维空间上进行去卷积的操作,用以增大特征图的像素。</td>   <td>G06K9/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              张黎明;                   肖尧       </td>   <td>中山大学</td>   <td>一种自主式交通系统演化模型的构建方法、装置及介质</td>   <td>广东省</td>   <td>CN113902124A</td>   <td>2022-01-07</td>   <td>本发明公开了一种自主式交通系统演化模型的构建方法、装置及介质,方法包括：根据自主式交通系统架构,确定系统要素及要素属性；根据要素属性,确定系统要素的关联关系；根据关联关系,搭建多层复杂网络结构,并向多层复杂网络结构输入配置包；根据多层复杂网络结构,结合第一预设标准,建立面向目标层的自主式交通系统复杂网络的演化模型,并确定演化模型的演化状态值属性；根据第二预设标准,确定演化模型的初始状态值和属性值,并根据初始状态值和属性值驱动演化模型进行演化；输出演化模型的演化数据,并根据演化数据进行特征分析。本发明的有益效果为：能够科学的描述和预测自主式交通系统演化特征及发展规律,有利于交通系统的可持续发展。</td>   <td>1.一种自主式交通系统演化模型的构建方法,其特征在于,包括：根据自主式交通系统架构,确定系统要素及要素属性；根据所述要素属性,确定所述系统要素的关联关系；根据所述关联关系,搭建多层复杂网络结构,并向所述多层复杂网络结构输入配置包；根据所述多层复杂网络结构,结合第一预设标准,建立面向目标层的自主式交通系统复杂网络的演化模型,并确定所述演化模型的演化状态值属性；根据第二预设标准,确定所述演化模型的初始状态值和属性值,并根据所述初始状态值和所述属性值驱动所述演化模型进行演化；输出所述演化模型的演化数据,并根据所述演化数据进行特征分析。</td>   <td>G06N20/00;G06Q10/04;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              李凝;                   马天俊       </td>   <td>中山大学</td>   <td>一种基于卷积神经网络的特征提取与目标跟踪方法</td>   <td>广东省</td>   <td>CN108038435B</td>   <td>2022-01-04</td>   <td>本发明公开一种基于卷积神经网络的特征提取与目标跟踪方法,首先通过线下预训练的方法,提高网络在特征提取与前景分割时的性能；之后将标定有的视频序列第一帧放入到网络中进行线上训练,对网络模型的参数进行微调,从而提升卷积神经网络在具体问题中的处理能力。通过增加随机二维掩膜和多次迭代的方法,既提高了网络预测的准确率,同时也避免了过拟合的问题。多尺度的可选性也使得本方法在目标跟踪过程中能够自适应地选择目标的尺度大小。在网络参数更新方面,通过设置阈值的方式实时进行更新,提升了目标跟踪方法的精度和鲁棒性。</td>   <td>1.一种基于卷积神经网络的特征提取与目标跟踪方法,其特征在于,包括以下步骤：S1：构建并预训练网络模型；S2：根据视频序列,线上训练网络模型；S3：输入视频序列,计算跟踪结果；S4：对视频序列中上一帧的跟踪结果进行评估,选取正样本结果放入网络中迭代以更新网络参数；步骤S1所述的预训练为线下预训练,分为以下三个步骤执行：S11：获取训练前景分割网络的数据集以及目标跟踪所用视频序列；S12：构建前景分割所需的网络模型,对网络模型参数进行初始化,所述的初始化为随机初始化；步骤S12中构建前景分割所需的网络模型为一个包含有11个卷积层的特征提取网络,卷积层采用3x3的小卷积；S13：利用前景分割网络数据集中的数据对网络模型进行训练,直至结果收敛；步骤S2分为以下两个步骤执行：S21：将视频序列中的第一帧放入至网络中,利用groundtruth提供的跟踪对象位置对网络模型进行微调；S22：提取训练网络中的特征提取部分及参数,重构目标定位网络,将视频序列第一帧放入至重构后的网络中反复迭代,训练网络模型；根据步骤S1的训练结果,提取训练网络中的特征提取部分及参数时,保留特征提取部分中Conv4及其前的8层卷积层及模型参数,重构目标定位网络；步骤S3分为以下两个步骤执行：S31：依次选取视频序列中的图像,以上一帧中目标位置为基准,确定跟踪目标所在的大致范围,按照顺序放入至目标跟踪网络中,根据处理后所得到的概率分布矩阵,确定当前跟踪目标的中心位置,步骤S3在选取目标所在的范围时,按照以下范围进行挑选：                                    其中(x-(0),y-(0))为groudtruth所标定位置的左上角坐标,w为bounding box的宽度,h为bounding box的高度；S32：以当前确定的目标中心位置为中心,计算多尺度空间中各尺度所对应的信心值,选取响应最大值所对应的尺度作为跟踪目标的尺度,并对多尺度空间进行更新；在确定目标尺度时,按照以下方式计算信心值：                  其中,f()函数表示二维高斯分布的概率密度函数；s为尺度所标定的范围,ε表示通道数量,X-(i)第i个通道的分布输出,γ-(i)为本通道参量。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              程高升;              陈荣军;              谢舜道;              朱雄泳;              王灿昆;                   曾衍瀚       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学花都产业科技研究院</td>   <td>一种基于大数据关联度分析的溯源防伪方法</td>   <td>广东省</td>   <td>CN108734475B</td>   <td>2022-01-04</td>   <td>本发明公开一种基于大数据关联度分析的溯源防伪方法,通过消费者使用溯源终端扫描一次商品上的溯源标签,同时获得溯源序列号和关联度数据项；查询溯源序列号和关联度数据项是否存在以及满足商品实际预设条件,从而确保查询数据是否有效；根据查询结果,将溯源序列号和关联度数据项集合进行大数据关联度分析；根据分析结果,对比本次查询的溯源序列号和关联度数据项是否满足关联度分析结果,从而确保商品信息的真伪,即达到商品信息溯源防伪的效果。</td>   <td>1.一种基于大数据关联度分析的溯源防伪方法,其特征在于,包括以下步骤：S1：获取溯源码,根据溯源码得到溯源序列号；S2：溯源终端应用获取商品流通或售卖时具有关联度的数据项；S3：溯源终端发送获取的溯源序列号以及相关联度的数据项到溯源系统平台；S4：溯源系统平台中溯源防伪功能接口接受溯源终端发送的溯源序列号和相关联度数据,进行匹配查询；S5：对溯源序列号和商品关联度数据项进行关联度分析；S6：溯源终端显示结果；在步骤S1中,所述的溯源序列号由溯源编码规则和随机序列生成的溯源码经过加密、位运算生成,步骤如下：S11：溯源码经过加密运算转化为字节序列；S12：针对该字节序列进行位运算,转化为字符；S13：将每次转化的字符拼接在一起,生成溯源序列号；在步骤S5中,查询数据库溯源序列号与之对应加密、位运算前的溯源码,得到该溯源码的批次号；根据溯源批次号,把溯源序列号和关联度数据项写入已扫描的溯源序列号和关联度数据项集合中并进行大数据关联度度分析,步骤如下：S51：读取溯源序列号和关联度数据项集合,根据溯源批次号把溯源序列号和关联度数据项集合分发至大数据平台各计算节点中；S52：大数据平台各计算节点统计各批次溯源码关联度数据项的出现频次,并转化为关联度指标；S53：比较本次查询溯源序列号和关联度数据项是否满足大数据关联度分析的关联度指标,若不满足,则返回“溯源序列号和关联度数据项不满足大数据关联度分析的关联度指标”,提示消费者该溯源序列号和关联度数据项应满足的关联度关系,查询结束；反之,若满足,则返回溯源序列号的溯源相关信息。</td>   <td>G06Q30/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              徐枫;              杨雅涵;              汪瑞昕;                   吕军锋       </td>   <td>中山大学中山眼科中心;清华大学</td>   <td>一种保护眼科患者隐私的方法、装置及存储介质</td>   <td>广东省</td>   <td>CN113887311A</td>   <td>2022-01-04</td>   <td>本发明公开了一种保护眼科患者隐私的方法、装置及存储介质,其中方法包括：采集眼科患者的检查视频；提取检查视频中每一帧图像的图像特征,根据图像特征中的器官位置信息对每一帧图像进行区域划分,并根据区域划分结果得到待精密重建区域和待弱化重建区域；对待精密重建区域和待弱化重建区域进行三维重建,得到每一帧图像对应的三维重建数据；将所有三维重建数据渲染成三维重建视频。本发明根据该位置信息将每一帧图像都划分为多个图像区域,在图像区域中得到待精密重建区域和待弱化重建区域已进行三维重建,能够在保留眼科患者大部分病例特征的同时,掩盖眼科患者的大部分身份特征,从而能够在不影响医生诊断的前提下保护眼科患者的隐私。</td>   <td>1.一种保护眼科患者隐私的方法,其特征在于,包括：采集眼科患者的检查视频；提取所述检查视频中每一帧图像的图像特征,根据所述图像特征中的器官位置信息对每一帧所述图像进行区域划分,并根据区域划分结果得到待精密重建区域和待弱化重建区域；对所述待精密重建区域和所述待弱化重建区域进行三维重建,得到每一帧所述图像对应的三维重建数据；将所有所述三维重建数据渲染成三维重建视频。</td>   <td>G06K9/00;G06T7/11;G06T15/00;G06T17/00;G06N3/04;G06N3/08;G16H10/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁进;              马可;                   肖鹏       </td>   <td>中山大学中山眼科中心</td>   <td>基于海洋捕食者算法的电生理信号的分类方法及分类系统</td>   <td>广东省</td>   <td>CN113887397A</td>   <td>2022-01-04</td>   <td>本公开描述了一种基于海洋捕食者算法的电生理信号的分类方法,是融合海洋捕食者算法和基于机器学习的分类模型以在特征选择的同时优化分类模型的分类方法,包括获取电生理信号；基于目标特征集提取电生理信号的目标特征数据；并且将目标特征数据输入已训练的分类模型以获取分类结果,其中,在海洋捕食者算法中,基于超参数项和训练特征项初始化猎物矩阵和精英矩阵,基于分类模型计算猎物矩阵中每一个个体的适应度,并基于适应度迭代更新猎物矩阵和精英矩阵直至满足停止迭代的条件以获得优化后的猎物矩阵和精英矩阵并同时获取已训练的分类模型,基于优化后的猎物矩阵获取最优的特征子集作为目标特征集、以及已训练的分类模型对应的超参数。</td>   <td>1.一种基于海洋捕食者算法的电生理信号的分类方法,其特征在于,是融合海洋捕食者算法和基于机器学习的分类模型以在特征选择的同时优化所述分类模型的分类方法,包括：获取电生理信号；基于包括多个特征项的目标特征集提取所述电生理信号与所述目标特征集中的特征项对应的多个特征数据作为所述电生理信号的目标特征数据；并且将所述目标特征数据输入已训练的分类模型以获取分类结果,其中,所述目标特征集和所述已训练的分类模型通过如下训练方法获得：构建训练样本,所述训练样本的输入数据包括多个待训练信号；提取各个待训练信号与训练特征项对应的多个特征数据作为训练特征数据,所述训练特征项包括多个特征项；基于所述分类模型的超参数的超参数项、所述训练特征项和所述训练特征数据并利用海洋捕食者算法获取所述目标特征集和所述已训练的分类模型,其中,在海洋捕食者算法中,基于所述超参数项和所述训练特征项初始化猎物矩阵和精英矩阵,基于所述分类模型计算所述猎物矩阵中每一个个体的适应度,并基于所述适应度迭代更新所述猎物矩阵和所述精英矩阵直至满足停止迭代的条件以获得优化后的猎物矩阵和精英矩阵并同时获取所述已训练的分类模型,基于所述优化后的猎物矩阵获取所述目标特征集、以及所述已训练的分类模型对应的超参数。</td>   <td>G06K9/00;G06K9/62;G06N20/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈亮;              谢涛;              许杨俊;              刘阳;                   郑子彬       </td>   <td>中山大学</td>   <td>一种物品推荐模型的训练方法、物品推荐方法和装置</td>   <td>广东省</td>   <td>CN113888282A</td>   <td>2022-01-04</td>   <td>本申请公开了一种物品推荐模型的训练方法、物品推荐方法和装置,根据用户对不同物品的历史行为记录构建训练样本,历史行为记录包括用户对物品的多种类型交互信息；用户记忆网络从训练样本中提取物品潜在特征和用户潜在特征,用户潜在特征包括用户固有喜好特征和用户动态喜好特征,用户固有喜好特征通过用户记忆网络提取训练样本中的用户喜好信息得到,用户动态喜好特征基于记忆矩阵和双层注意力机制提取得到；用户记忆网络通过用户潜在特征和物品潜在特征计算训练样本的预测得分,通过训练样本的预测得分和标签计算得到的损失值更新网络参数,从而得到物品推荐模型,改善了现有的推荐系统存在的推荐效果不理想的技术问题。</td>   <td>1.一种物品推荐模型的训练方法,其特征在于,包括：根据用户对不同物品的历史行为记录构建训练样本,所述历史行为记录包括用户对物品的多种类型交互信息；通过用户记忆网络从所述训练样本中提取物品潜在特征和用户潜在特征,所述用户潜在特征包括用户固有喜好特征和用户动态喜好特征,所述用户固有喜好特征通过所述用户记忆网络提取所述训练样本中的用户喜好信息得到；根据所述用户潜在特征和所述物品潜在特征计算所述训练样本的预测得分；根据所述训练样本的预测得分和标签计算得到的损失值更新所述用户记忆网络的网络参数,直至所述用户记忆网络收敛,得到物品推荐模型；其中,用户记忆网络提取用户潜在特征的过程为：用户记忆网络基于所述物品潜在特征对当前的用户记忆矩阵进行读操作,获取第一用户记忆特征；所述用户记忆网络基于所述用户固有喜好特征和所述物品潜在特征对所述用户记忆矩阵中的记忆特征进行双层注意力处理,获取第二用户记忆特征；所述用户记忆网络融合所述第一用户记忆特征和所述第二用户记忆特征,得到用户动态喜好特征；所述用户记忆网络融合所述用户固有喜好特征和所述用户动态喜好特征,得到用户潜在特征。</td>   <td>G06Q30/06;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         雷文斌;              李芸;              赵章宗;                   雷国庆       </td>   <td>重庆南鹏人工智能科技研究院有限公司;中山大学附属第一医院;重庆鹏康大数据有限公司;广州天鹏计算机科技有限公司</td>   <td>一种基于深度学习分割、分类多任务的喉咽内镜肿瘤检测及良恶性分类方法</td>   <td>重庆市</td>   <td>CN113888518A</td>   <td>2022-01-04</td>   <td>本发明涉及图像识别技术领域,具体涉及一种基于深度学习分割、分类多任务的喉咽内镜肿瘤检测及良恶性分类方法；包括以下步骤：S1、系统研发；S10、采集训练数据并对病灶的区域、良恶性进行标注；S11、训练一个图像分割、分类多任务模型,并实现图像的病灶区域分割和图像分类。本发明利用基于深度学习的图像分割、图像分类多任务方法对待检测图像进行预测,并综合两者的预测结果,得到图像属于正常、良性或恶性的概率,同时根据分割结果输出病灶区域,供内镜操作医生参考,并且视频最近若干帧取平均概率的方法可以平滑逐帧预测到的概率,降低图像噪声、运动模糊、某些罕见图像形态的影响,降低输出概率的波动,提高检测准确率。</td>   <td>1.一种基于深度学习分割、分类多任务的喉咽内镜肿瘤检测及良恶性分类方法,其特征在于,包括以下步骤：S1、系统研发；S10、采集训练数据并对病灶的区域、良恶性进行标注；S11、训练一个图像分割、分类多任务模型,并实现图像的病灶区域分割和图像分类；S2、实际应用；S20、将喉咽内镜采集到的视频传输到预设程序中,当镜头进入喉咽待查部位后,开启多任务模型,综合分割、分类的输出结果,得到当前帧的正常、良性或恶性预测概率,并在画面中显示分割出的病灶位置和轮廓；S21、综合分类的方法：,                  其中,          输入图像；          ,预测输入图像是类别r的得分；          ,预测输入图像是类别r的概率,由预测得分归一化得到；          ,分类模块测输入图像是类别r的概率；          ,当r为良性或者恶性时,表示分割模块预测图像 (h,w)像素是病灶的概率,当r为正常时,表示分割模块预测该像素是正常的概率；          ,分割模块的输出像素总数；          ,分割输出加权面积占比的非线性系数,一般取1/4          ,缩放系数,一般取2；S22、对于输入视频,通过所述步骤S4可以获得每一帧正常、良性或恶性的概率。</td>   <td>G06T7/00;G06T7/11;G06T7/13;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林海城;              陈翔;                   龚杰       </td>   <td>中山大学</td>   <td>一种用于同时检测家具板材边界、圆孔、槽的方法及系统</td>   <td>广东省</td>   <td>CN113888527A</td>   <td>2022-01-04</td>   <td>本发明公开了一种用于同时检测家具板材边界、圆孔、槽的方法及系统,该方法包括：构建边界、圆孔、槽的数据集,并对数据集进行预处理,得到修改后的数据集；基于修改后的数据集对预构建的改进VGG19网络模型进行训练,得到检测模型；将待测样本输入到检测模型,得到检测结果；将检测结果标注在原图上。该系统包括：数据集预处理模块、训练模块、检测模块和标注模块。通过使用本发明,能够兼顾板材的多种花色并在受到纹理、破损以及槽深的影响下同时完成样本的分类,及其边界,圆孔,槽轮廓的提取。本发明可广泛应用于计算机视觉目标检测领域。</td>   <td>1.一种用于同时检测家具板材边界、圆孔、槽的方法,其特征在于,包括以下步骤：构建边界、圆孔、槽的数据集,并对数据集进行预处理,得到修改后的数据集；基于修改后的数据集对预构建的改进VGG19网络模型进行训练,得到检测模型；将待测样本输入到检测模型,得到检测结果；将检测结果标注在原图上。</td>   <td>G06T7/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;                   徐光       </td>   <td>中山大学</td>   <td>一种基于自然特征的跟踪注册方法及装置</td>   <td>广东省</td>   <td>CN108694348B</td>   <td>2021-12-31</td>   <td>本发明公开了一种基于自然特征的跟踪注册方法及装置,所述跟踪注册方法包括以下步骤：图像序列划分,获取图像序列后,对图像序列进行人脸检测,并将所述图像序列划分为人脸区域和背景区域；相机位姿估计,对所述背景区域提取特征,并通过帧间匹配估算相机位姿,计算投影矩阵；人脸视觉检测,将所述人脸区域进行人脸特征点定位和人脸姿态估计；跟踪注册,根据所述上述步骤所得参数计算注册矩阵,完成跟踪注册；所述装置包括图像序列划分模块、相机位姿估计模块、人脸视觉检测模块和跟踪注册模块。本技术方案能够有效实现运动相机和运动目标区域之间的估计,完成增强现实的跟踪注册。</td>   <td>1.一种基于自然特征的跟踪注册方法,其特征在于,适用于对均在运动的人和相机进行跟踪注册,所述方法包括以下步骤：图像序列划分：获取图像序列后,对图像序列进行人脸检测,并将所述图像序列划分为人脸区域和背景区域；相机位姿估计：对所述背景区域提取特征,并通过帧间匹配估算相机位姿,计算投影矩阵,并得到三维空间不变点；人脸视觉检测：将所述人脸区域进行人脸特征点定位,得到人脸特征点位置信息,再进行人脸姿态估计；跟踪注册：根据所述投影矩阵、人脸特征点位置信息和三维空间不变点计算注册矩阵,完成跟踪注册。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              宋日辉;              李洋灏;                   江志华       </td>   <td>中山大学</td>   <td>一种基于事件触发相机与三维激光雷达融合系统下的物体识别与配准方法</td>   <td>广东省</td>   <td>CN109146929B</td>   <td>2021-12-31</td>   <td>本发明涉及深度学习、图象处理以及三维点云处理的技术领域,更具体地,涉及一种基于事件触发相机与三维激光雷达融合系统下的物体识别与配准方法。本发明提出的基于事件触发相机数据和激光雷达数据融合的系统。通过YOLO3深度学习神经网络对图像进行通用物体检测。对被检测出物体的图像使用极小值滤波器融合激光雷达的深度信息,实现实时准确地检测图像中的物体及其深度信息的目的。</td>   <td>1.一种基于事件触发相机与三维激光雷达融合系统下的物体识别与配准方法,其特征在于,包括以下步骤：步骤1、搭建和配准事件触发相机与三维激光雷达构成的融合系统；得到事件触发相机的内参矩阵以及事件触发相机与三维激光雷达之间的外参矩阵,利用这两个矩阵配准事件触发相机与三维激光雷达这两个传感器得到的数据,使这两种数据融合；步骤2、针对事件触发相机得到的数据,对YOLO3深度学习神经网络进行微调；因为原YOLO3是对普通RGB相机得到的图片进行物体分类识别,而事件触发相机得到的图片为黑白二值图；黑白二值图相对+于彩色照片来说更容易被处理,因此能够相应地对YOLO3深度学习网络进行微调,减少系统的运行负担；另外,用事件触发相机得到的数据对微调过后的YOLO3深度学习神经网络进行训练；步骤3、实现极小值滤波器；在使用微调过的YOLO3对事件触发相机得到的图片进行物体分类检测之后,每一个被识别到的物体都会有一个对应的数据结构,包括被检测到物体的可能种类的置信度以及物体在图像中的位置和大小；根据步骤1,图像中的某些像素点会被赋予深度信息；通过使用极小值滤波器,对被识别到的物体范围内的带有深度信息的像素点进行筛选,以其中深度的最小值作为该物体的深度；步骤4、启动事件触发相机与三维激光传感器的融合系统,并运行算法,能够实时分类识别物体及对物体进行定位。</td>   <td>G06T7/30;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              高健豪;              陈然;              陈颖薇;              戴晨睿;              黄颖瑜;              刘李哲;              韦骏;              黄硕;              龚喜;                   陈顺华       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>基于空间特征差异的海流预测方法以及系统</td>   <td>广东省</td>   <td>CN113869350A</td>   <td>2021-12-31</td>   <td>本发明公开了基于空间特征差异的海流预测方法以及系统,方法包括:确定研究区域和研究时间；获取待预测海域的在一段时间内的表现因子和影响因子；根据所述表现因子和所述影响因子之间的相关性,建立相关性模型,并从空间上将所述待预测海域划分为多个分区；根据所述表现因子和所述影响因子,建立所述多个分区流场与影响因子之间的机器学习模型,得到各个分区的流场模型；整合各个分区的流场模型,建立全区域流场模型,以确定全区域流场对影响因子的非线性响应；根据所述全区域流场模型获取预测流场数据。本发明可以在考虑各类相关影响因素的同时,进行长周期的海表流场预测,可广泛应用于海流数据处理技术领域。</td>   <td>1.基于空间特征差异的海流预测方法,其特征在于,包括：确定研究区域和研究时间；获取待预测海域的在一段时间内的表现因子和影响因子；其中,所述表现因子包括实测流场数据；所述影响因子包括所述待预测海域的地形数据、同一时段内的潮流数据、水深数据和风场数据；根据所述表现因子和所述影响因子之间的相关性,建立相关性模型,并从空间上将所述待预测海域划分为多个分区；根据所述表现因子和所述影响因子,建立所述多个分区流场与影响因子之间的机器学习模型,得到各个分区的流场模型；整合各个分区的流场模型,建立全区域流场模型,以确定全区域流场对影响因子的非线性响应；根据所述全区域流场模型获取预测流场数据,所述预测流场数据包括风场数据、潮流数据和水深数据。</td>   <td>G06K9/62;G06N3/08;G06Q10/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              谢晨曦;                   王国倩       </td>   <td>中山大学</td>   <td>基于深度学习的低频UWB SAR图像目标变化检测方法</td>   <td>广东省</td>   <td>CN113870193A</td>   <td>2021-12-31</td>   <td>本发明提供一种基于深度学习的低频UWB SAR图像目标变化检测方法,该方法采用深度学习方法,能够有效解决低频UWB SAR图像目标检测中检测难、虚警高等问题。利用深度神经网络对低频UWB SAR图像进行目标检测,避免了人工设计特征进行低频UWB SAR图像目标检测中识别的难度大等问题。通过卷积神经网络对图像特征进行自主学习与分类,能够有效降低低频UWB SAR图像目标检测中的虚警率。</td>   <td>1.一种基于深度学习的低频UWB SAR图像目标变化检测方法,其特征在于,包括以下步骤：S1：构建深度神经网络所需数据集；S2：构建深度神经网络；S3：网络训练与测试。</td>   <td>G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         辜祥宏;                   杨然       </td>   <td>中山大学</td>   <td>基于深度学习算法的细菌性与病毒性儿童肺炎的分类方法</td>   <td>广东省</td>   <td>CN108171232B</td>   <td>2021-12-28</td>   <td>本发明提供一种基于深度学习算法的细菌性与病毒性儿童肺炎的分类方法,该方法首先对源数据集进行人工标注,再在全卷积网络语义分割与卷积神经网络算法的基础上,先采用全卷积网络语义分割算法对图像进行前景分割肺部区域得到感兴趣区域,将提取到的感兴趣区域输入到卷积神经网络模型中训练分类器,从而预测未知胸部X线图像所属类别提取感兴趣区域的高维特征,同时采用传统的图像处理方法提取感兴趣区域的低维特征,分别将高、低维特征用于训练非线性分类器,并预测未知X线图像的类别,从而判断患者所患肺炎的类型。采用主成成分分析算法对特征降维,减少计算量,然后将混合降维后的特征输入到非线性分类器中,对未知X线图像预测类别。</td>   <td>1.一种基于深度学习算法的细菌性与病毒性儿童肺炎的分类方法,其特征在于,包括以下步骤：S1：分割胸部X图像的肺部区域作为ROI区域；S2：将ROI输入卷积神经网络分类器；S3：抽取高、低维特征放入非线性分类器；S4：混合高、低维特征放入非线性分类器得到分类结果；准备若干张胸部X影像以及对应的图像格式和肺部掩模图像,将胸部X影像对应的图像格式的图像及肺部掩模图像按照4:1比例划分成训练集和验证集,采用已公开数据作为测试集,用8层网络结构训练PSCAL VOC2012数据集得到全卷积网络模型,对上述数据进行迁移学习,将训练所得模型用于测试集,生成测试集对应的肺部掩模图像,依据肺部掩模图像得到感兴趣区域；用8层网络结构训练PSCAL VOC2012数据集得到FCN模型的具体过程是：1)、8层网络结构都是卷积层,神经网络的结构特点就是将上一层的输出作为下一层的输入,即第n-1层的第k个特征图,经过卷积核g和偏置项b的运算,得到第n层的输入公式如下：                  其中,f()代表激活函数,这里采用修正线性单元激活函数,对于输入值x,激活函数表示：f(x)＝max(0,x)；2)、为了减少参数便于计算,在第1、2层卷积层后面加上了采样层,假设n-1层为卷积层,第n层的计算公式如下：                  其中down(·)为下采样函数；3)、在后3层卷积层加上了反卷积层,也称为上采样层,可理解为卷积的逆操作过程,在网络中,g-(ij)是连接n-1层的某个神经元i与第n层某个神经元j的权重,0表示i和j不相连,那么权重矩阵C可由公式表示为：                  由步骤1)可知,卷积过程由输入x得到输出o的公式可以简化为：          反卷积过程由输入x’得到输出o’的公式为：得到与原图一样大小的预测图像,并且该预测图像每一个像素都会有对应分类；4)、定义损失函数Loss Function,公式如下：                  其中,b表示batch size大小,y-(i)表示第i个样本的真实label,表示预测label,p-(i)是一个[0,1]概率值,取值依据公式：                  其中,γ属于惩罚项,o-(i)是第i个神经元的输出；5)、在训练网络的过程中,前向传播和后向传播是交替进行的,直到最终误差在可接受范围以内便可训练完成。</td>   <td>G06K9/32;G06K9/62;G06N3/04;G06T7/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高燕;              武志毅;              李文龙;                   周羿彬       </td>   <td>中山大学</td>   <td>基于Revit软件的地质环境载体断层模型的构建方法及装置</td>   <td>广东省</td>   <td>CN110910499B</td>   <td>2021-12-28</td>   <td>本发明涉及一种基于Revit软件的地质环境载体断层模型的构建方法及装置,其中方法包括：依据断层发育情况将区域分为多个单位,并对各单位分别进行钻孔族及地层建模；基于Kriging插值法得到每个地层的内插点；基于Delaunay三角插值法进行地质环境载体地层的建模；载体断层平面模型构建：基于边界虚拟钻孔法和三维空间平面拟合构建地质环境载体断层平面模型构建；载体断层曲面模型构建：基于边界虚拟钻孔法、Kriging插值法和Delaunay三角插值法构建地质环境载体断层曲面模型。与现有技术相比,本发明解决了Revit软件中没有三维地质环境载体建模模块的问题。</td>   <td>1.一种基于Revit软件的地质环境载体断层模型的构建方法,其特征在于,包括：依据断层发育情况将区域分为多个单位,并对各单位分别进行钻孔族及地层建模,基于Kriging插值法得到每个地层的内插点,基于Delaunay三角插值法进行地质环境载体地层的建模,载体断层平面模型构建：基于边界虚拟钻孔法和三维空间平面拟合构建地质环境载体断层平面模型构建,载体断层曲面模型构建：基于边界虚拟钻孔法、Kriging插值法和Delaunay三角插值法构建地质环境载体断层曲面模型；所述内插点的获取过程为：通过Kriging算法由已知的钻孔点的地层标高数据得到未知点的地层标高数据；所述内插点的获取过程具体包括：步骤S21：输入原始数据,其中,所述原始数据为随机选取的已知的钻孔点的位置坐标数据及地层标高数据,步骤S22：计算由任意两个已知的钻孔点构成的点对的距离和半方差,步骤S23：基于步骤S22的计算结果,每隔n个单位区间计算一个均值点,得到多个均值点,选定拟合模型拟合均值点得到拟合模型曲线,步骤S24：根据拟合得到的模型曲线,求得拟合模型的主变程和偏基台值,通过已知点的高程计算未知点的高程,得到内插点。</td>   <td>G06T17/05</td>  </tr>        <tr>   <td>中国专利</td>   <td>         钟鸣;              林凯荣;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种基于中介效应的洪水灾害韧性分析方法及系统</td>   <td>广东省</td>   <td>CN113850435A</td>   <td>2021-12-28</td>   <td>本发明提出一种基于中介效应的洪水灾害韧性分析方法及系统,包括：收集数据,建立洪水灾害韧性交互系统,对洪水灾害韧性的影响因素进行指标状态的阈值划分,得到不同维度的洪水灾害韧性的指标；利用中介效应进行数据预处理,对洪水灾害韧性的指标进行关联度分析,构建各指标的传递关系；利用解释结构模型,在各指标的传递关系基础上构造洪水灾害韧性多维网络层级结构,分析洪水灾害韧性。利用中介效应,对洪水灾害韧性的指标采用量化的关联度计算方法,获得不同指标间定量和定向的传递关系,确定洪水灾害韧性指标的多级递阶关系,构建洪水灾害韧性多维网络层级结构,能对洪水灾害韧性进行准确的分析。</td>   <td>1.一种基于中介效应的洪水灾害韧性分析方法,其特征在于,包括以下步骤：Step1：根据洪水灾害韧性的影响因素,采集相应的影响因素数据；Step2：根据预设的指标状态划分阈值,对所述影响因素数据进行指标状态的阈值划分,得到不同维度的洪水灾害韧性的指标；Step：3：利用中介效应进行数据预处理,对洪水灾害韧性的指标进行关联度分析,构建各指标的传递关系；Step4：利用解释结构模型,在各指标的传递关系基础上构造洪水灾害韧性多维网络层级结构,分析洪水灾害韧性。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈俊周;              陈文权;              苟超;                   徐勇志       </td>   <td>中山大学</td>   <td>一种驾驶员分心行为的识别方法、装置、终端及存储介质</td>   <td>广东省</td>   <td>CN113850151A</td>   <td>2021-12-28</td>   <td>本发明公开了一种驾驶员分心行为的识别方法、装置、终端及存储介质,通过深度学习的方法,使用卷积、激活函数以及注意力机制对驾驶分心数据集进行图像增强,通过学习通道间信息交互,增加图像感兴趣区域特征表达,使其作为神经网络的输入,减少通道冗余,增强特征表达能力。经过图像增强网络的图片提取了人体特征,加强了重要特征的表达,使得Transformer模型特征提取更加容易,识别结果更加准确,最后通过置信学习筛选样本中的错误标签图片,提升识别准确率,可以兼容各种自动驾驶系统实现端到端的驾驶分心行为识别。</td>   <td>1.一种驾驶员分心行为的识别方法,其特征在于,包括：获取待识别的驾驶行为图像；对所述驾驶行为图像进行人体区域提取,获得待识别的人体区域图像；将所述待识别的人体区域图像输入至经过置信度学习优化后的可伸缩视觉Transformer模型,以使可伸缩视觉Transformer模型输出分心行为识别结果；其中,可伸缩视觉Transformer模型共有M+N层模型,前N层模型用于对输入的人体区域图像进行图像特征提取,后M层模型用于对输入的人体区域图像进行图片块的划分筛选,并通过设置的损失函数输出分心行为识别结果,M和N为正整数。</td>   <td>G06K9/00;G06K9/32;G06K9/34;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈海斌;              胡漫;              吴书裕;              李焱;                   陆遥       </td>   <td>中山大学</td>   <td>一种跨模态医学影像精准转换方法</td>   <td>广东省</td>   <td>CN113850710A</td>   <td>2021-12-28</td>   <td>本发明属于医学图像技术领域,更具体地,涉及一种跨模态医学影像精准转换方法,通过配对影像模态转换模型对降采样图像进行第一次转换,得到的图像经像插值后,与待转换图像一起输入非配对影像模态转换模型中进行转换,输出最终的目标模态影像；本发明中先通过配对影像转换模型对降采样影像进行转换,此时,降采样图像能够减少图像高频噪声对图像模态转换的干扰,从而保证影像中主要的信息可以准确转换,之后再将输出的第一目标模态影像进行像素插值,插值影像可以提供丰富稳定的灰度信息,从而在非配对影像转换模型中引导高频的待转换影像保留更多的细节,避免丢失影像中的信息,从而实现精准稳定的医学影像模态转换。</td>   <td>1.一种跨模态医学影像精准转换方法,其特征在于,包括以下步骤：S1：获取多组不同患者的多模态影像数据集,并将所述多模态影像数据集分成训练集以及验证集；S2：对多组所述多模态影像数据集中的影像数据分别进行预处理,得到降采样影像；S3：以所述降采样影像作为输出,构建配对影像模态转换模型；S4：将待转换影像输入所述配对影像模态转换模型,得到第一目标模态影像；S5：对所述第一目标模态影像进行像素插值,得到插值影像；S6：以所述插值影像及待转换模态影像作为双输入,以第二目标模态影像作为输出,构建非配对影像模态转换模型；S7：设定最大迭代次数以及迭代结束条件,将所述训练集中的多模态影像数据集分组输入所述配对影像模态转换模型中,循环执行步骤S4至步骤S6,以对所述配对影像模态转换模型及非配对影像模态转换模型进行训练,并计算转换损失以实时更新所述配对影像模态转换模型及非配对影像模态转换模型；S8：将验证集中的多模态影像数据输入步骤S7中更新的所述配对影像模态转换模型及非配对影像模态转换模型中,输出最终目标模态影像。</td>   <td>G06T3/00;G06T7/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏培强;              徐彩霞;              袁浩东;              张宝林;                   廖智恒       </td>   <td>中山大学附属第一医院</td>   <td>一种脊柱Cobb角测量方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113850763A</td>   <td>2021-12-28</td>   <td>本发明公开了一种脊柱Cobb角测量方法、装置、设备及介质,其中,所述测量方法包括：将所获取的脊柱医学影像输入预设第一神经网络模型,以使所述第一神经网络模型对所述医学影像进行脊椎关键点检测,得到椎体关键点位置信息；根据所述椎体关键点位置信息确定椎体的上缘和下缘,基于所述上缘和下缘计算脊柱Cobb角。上述测量方法流程更快速、高效,且得到的Cobb角误差更小,可为脊柱畸形的严重程度提供更准确的参考信息。</td>   <td>1.一种脊柱Cobb角测量方法,其特征在于,包括：将所获取的脊柱医学影像输入预设第一神经网络模型,以使所述第一神经网络模型对所述医学影像进行脊椎关键点检测,得到椎体关键点位置信息；根据所述椎体关键点位置信息确定椎体的上缘和下缘,基于所述上缘和下缘计算脊柱Cobb角。</td>   <td>G06T7/00;G06T7/11;G06T7/73;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈俊周;              赵楠;                   韦艳宏       </td>   <td>中山大学</td>   <td>一种血管精细化分割方法、装置、终端及存储介质</td>   <td>广东省</td>   <td>CN113850819A</td>   <td>2021-12-28</td>   <td>本发明公开了一种血管精细化分割方法、装置、终端及存储介质,通过对斑马鱼的血管功能区进行标注处理,生成粗标注图对应的粗分割数据集和细标注图对应的细分割数据集；构建第一级网络模型和第二级网络模型,将粗分割数据集输入到第一级网络模型中进行训练,生成粗分割模型,再将细分割数据集输入到第二级网络模型中进行训练,生成细分割模型；将待分割的斑马鱼高内涵荧光图输入到粗分割模型中,生成斑马鱼高内涵荧光图对应的血管功能区的粗分割结果,将粗分割结果输入到细分割模型中,获取斑马鱼高内涵荧光图对应的血管精细化分割结果。本发明采用二级级联架构的方式,分割出斑马鱼血管功能区精细化血管结构,实现对斑马鱼血管的精细化分割。</td>   <td>1.一种血管精细化分割方法,其特征在于,包括：获取斑马鱼高内涵荧光图,对所述斑马鱼高内涵荧光图中对应的斑马鱼的血管功能区进行标注处理,生成粗标注图对应的粗分割数据集和细标注图对应的细分割数据集；构建第一级网络模型和第二级网络模型,对所述第一级网络模型和所述第二级网络模型进行优化,将所述粗分割数据集输入到所述第一级网络模型中进行训练,生成粗分割模型,再将所述细分割数据集输入到所述第二级网络模型中进行训练,生成细分割模型；将待分割的斑马鱼高内涵荧光图输入到所述粗分割模型中,生成所述斑马鱼高内涵荧光图对应的血管功能区的粗分割结果,将所述粗分割结果输入到所述细分割模型中,获取所述斑马鱼高内涵荧光图对应的血管精细化分割结果。</td>   <td>G06T7/11;G06T7/00;G06N3/04;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         伊永菊;              王文辉;              佘广南;              李银;                   梅甜       </td>   <td>中山大学附属第六医院</td>   <td>一种模态交互的图注意融合的教育视频问答方法及系统</td>   <td>广东省</td>   <td>CN113837259A</td>   <td>2021-12-24</td>   <td>本申请提供了一种模态交互的图注意融合的教育视频问答方法及系统,本申请通过对原始教育视频素材进行预处理得到训练数据集；提取训练数据集中各个模态的特征,将视频静态帧特征、视频动态特征和字幕特征分别输入至模态内交互模块中得到模态内交互特征；将各模态内交互特征输入至模态间交互模块得到模态间交互特征；将输入视频静态交互特征、输入视频文本交互特征与模态间交互特征输入至图注意融合模块进行融合得到最终的图注意融合的特征；将最终的图注意融合的特征输入至分类器进行训练得到教育视频问答模型模型,并应用到实际场景中。本申请能够提取视频中更加精确的信息,提高用户和视频的交互效果以及用户理解视频的效率。</td>   <td>1.一种模态交互的图注意融合的教育视频问答方法,其特征在于,所述方法包括如下步骤：获取原始教育视频素材；对所述原始教育视频素材进行预处理得到训练数据集；提取所述训练数据集中各个模态的特征,包括视频静态帧特征、视频动态特征、问题特征和字幕特征；将所述视频静态帧特征、视频动态特征和字幕特征分别输入至各自对应的模态内交互模块中与所述问题特征进行第一注意力计算得到输入视频静态交互特征、输入视频动态交互特征和输入视频文本交互特征；将输入视频静态交互特征、输入视频动态交互特征和输入视频文本交互特征输入至模态间交互模块进行第二注意力计算得到模态间交互特征；将所述输入视频静态交互特征、输入视频文本交互特征与所述模态间交互特征输入至图注意融合模块进行融合得到最终的图注意融合的特征；将所述最终的图注意融合的特征输入至分类器进行训练得到教育视频问答模型模型,并应用到实际场景中。</td>   <td>G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国玉;              周永坤;              饶彬;              王伟;              王涛;              周颖;              邹小海;                   徐峰       </td>   <td>中山大学</td>   <td>多无人机协同的干扰资源优化分配方法</td>   <td>广东省</td>   <td>CN113822534A</td>   <td>2021-12-21</td>   <td>本发明公开了多无人机协同的干扰资源优化分配方法,包括：分析干扰机干扰信号与辐射源接收目标信号之间的映射关系；将系统的干信比作为指标,根据所述映射关系建立干扰机对辐射源进行干扰的目标结群模型；根据贪心算法对所述目标结群模型进行计算,确定干扰机对各辐射源的第一干扰资源分配结果。本发明能够在干扰资源有限的情况下,合理分配干扰资源,以取得对多个辐射源的最佳干扰效果,可广泛应用于数据处理技术领域。</td>   <td>1.多无人机协同的干扰资源优化分配方法,其特征在于,包括：分析干扰机干扰信号与辐射源接收目标信号之间的映射关系；将系统的干信比作为指标,根据所述映射关系建立干扰机对辐射源进行干扰的目标结群模型；根据贪心算法对所述目标结群模型进行计算,确定干扰机对各辐射源的第一干扰资源分配结果。</td>   <td>G06Q10/06;G06Q10/04;G06F17/15;G06F17/11</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张新玲;              王艾俊;              林穆清;              邹耀贤;                   何绪金       </td>   <td>深圳迈瑞生物医疗电子股份有限公司;中山大学附属第三医院</td>   <td>输卵管超声造影成像方法、超声成像装置和存储介质</td>   <td>广东省</td>   <td>CN113822837A</td>   <td>2021-12-21</td>   <td>本发明提供了一种输卵管超声造影成像方法、超声成像装置和存储介质,该方法包括：获取目标对象的输卵管区域的四维造影数据和四维组织数据；从所述四维造影数据和所述四维组织数据中分别获取至少一个时刻的三维造影数据和三维组织数据；对获取的每一时刻的三维造影数据和三维组织数据各自进行渲染,并将同一时刻的三维造影数据和三维组织数据各自渲染后得到的渲染结果进行融合,以得到混合渲染图像；对所述混合渲染图像进行特征提取,并基于所述特征提取的结果输出对所述输卵管区域的分析结果；显示混合渲染图像和分析结果。本申请的输卵管超声造影成像方法和装置能够帮助用户更为直观地理解、观察造影剂在组织内的空间位置关系以及流动情况。</td>   <td>1.一种输卵管超声造影成像方法,其特征在于,所述方法包括：获取目标对象的输卵管区域的四维造影数据和四维组织数据；从所述四维造影数据和所述四维组织数据中分别获取至少一个时刻的三维造影数据和三维组织数据；对获取的每一时刻的三维造影数据和三维组织数据各自进行渲染,并将同一时刻的三维造影数据和三维组织数据各自渲染后得到的渲染结果进行融合,以得到混合渲染图像；对所述混合渲染图像进行特征提取,并基于所述特征提取的结果输出对所述输卵管区域的分析结果；显示所述混合渲染图像和所述分析结果。</td>   <td>G06T7/00;G06T5/50;G06T15/08;G06T15/50;G06T15/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              汪瑞昕;              杨华胜;              毕少炜;              陈荣新;              李明远;                   林桢哲       </td>   <td>中山大学中山眼科中心</td>   <td>一种眼表肿物的判断方法及装置</td>   <td>广东省</td>   <td>CN113822861A</td>   <td>2021-12-21</td>   <td>本发明公开了一种眼表肿物的判断方法及装置,所述方法包括：先获取眼表肿物图；再将眼表肿物图输入至眼表肿物判断模型中,以使眼表肿物判断模型进行眼表肿物良恶性判断,得到判断结果；其中,眼表肿物判断模型用于根据眼表肿物图获取第一特征图和候选区域,继而根据第一特征图和候选区域得到多个第二特征图,将多个第二特征图的维度设置为第一维度后进行眼表肿物良恶性判断；其中,所述候选区域为疑似病灶区域。采用本发明实施例能提高判断眼表肿物良恶性的准确度。</td>   <td>1.一种眼表肿物的判断方法,其特征在于,包括：获取眼表肿物图；将所述眼表肿物图输入至眼表肿物判断模型中,以使所述眼表肿物判断模型进行眼表肿物良恶性判断,得到判断结果；其中,所述眼表肿物判断模型用于根据所述眼表肿物图获取第一特征图和候选区域,继而根据所述第一特征图和所述候选区域得到多个第二特征图,将多个所述第二特征图的维度设置为第一维度后进行眼表肿物良恶性判断；其中,所述候选区域为疑似病灶区域。</td>   <td>G06T7/00;G06K9/32;G06K9/62;G16H50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈洪波;              刘立志;              黎浩江;              龚琼;              黄文捷;                   阮广英       </td>   <td>桂林电子科技大学;中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种鼻咽癌概率图谱获取及定量分析方法</td>   <td>广西壮族自治区</td>   <td>CN113822863A</td>   <td>2021-12-21</td>   <td>本发明公开了一种鼻咽癌概率图谱获取及定量分析方法,该方法通过建立头颈部标准三维坐标系,尽量消除个体间头颅大小和形状的差异,可以更好地描述肿瘤位置和浸润深度。同时在标准三维坐标系中获取鼻咽癌概率图谱,并提供一种概率图谱特征描述与定量分析方法,同时可以为大样本的头颈部肿瘤定量分析提供新的技术手段,生成鼻咽癌概率图像并研究概率图谱特征描述方法,形成标准空间下的影像学特征,完善现有鼻咽癌影像组学特征体系,并通过大数据医学影像分析,提高鼻咽癌预后模型的准确度,为制订鼻咽癌精准个性化治疗方案提供技术支持。</td>   <td>1.一种鼻咽癌概率图谱获取及定量分析方法,其特征在于,包括如下步骤：1)分别获取鼻咽癌患者和健康者的头部MRI图像,从鼻咽癌患者的头部MRI图像中获取T1W、T2W、DCE-MRI和DWI扫描图像,并从扫描图像中获取常用参数,将获取的参数采用DICOM格式存储；采用相同的参数,从健康者的头部MRI图像中获取健康者的T1W、T2W、DCE-MRI和DWI扫描图像,作为标准参考图像；2)对鼻咽癌患者头部MRI图像进行归一化显示,对MRI图像中的鼻咽癌ROI区域和四个稳定解剖结构点进行勾画,获取到头部四个稳定解剖结构点；3)根据步骤2)获得的四个稳定解剖结构点构建头部医学影像标准三维坐标系,并将鼻咽癌患者的医学图像和肿瘤ROI配准到标准三维坐标系的空间中进行图像配准,利用叠加的方法获取鼻咽癌概率图谱；4)对步骤3)获得的鼻咽癌概率图谱进行定量分析和特征描述,获得肿瘤的位置信息、肿瘤体积,以及肿瘤区域的平均概率、肿瘤边界的概率分布、概率的梯度方向。</td>   <td>G06T7/00;G06T7/33;G06K9/32</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张志权;              林淑金;                   周凡       </td>   <td>中山大学</td>   <td>一种基于教育视频自动提取不重复的幻灯片方法</td>   <td>广东省</td>   <td>CN108182391B</td>   <td>2021-12-17</td>   <td>本发明实施例公开了一种基于教育视频自动提取不重复的幻灯片方法,所述方法包括：获取视频,按照一定时间间隔,截取图像；将截取图像灰度化生成二值图,找出边缘点的所有连通区域,进行检测,获得二值图中所有线段,并延长成直线,进行迭代合并相等的直线,获取任意两条不相等直线,计算两直线之间的交叉点,获取4个交叉点组成四边形,进行判断识别,获得合法四边形,进行透视变换,提取5张候选幻灯片图像并进行过滤提取冗余幻灯片图像,获得所需要的幻灯片。实施本发明实施例,在没有明显降低提取幻灯片的召回率的同时,很大程度减少了处理时间,提高了准确率。为用户提供了方便。</td>   <td>1.一种基于教育视频自动提取不重复的幻灯片方法,其特征在于,所述方法包括：获取视频,按照一定时间间隔,截取图像；将截取图像灰度化生成二值图,找出边缘点的所有连通区域,进行检测,获得二值图中所有线段,并延长成直线；获取所述直线,进行迭代合并相等的直线,获得不相等直线；获取任意两条不相等直线,计算两直线之间的交叉点,取其一；获取4个交叉点组成四边形,进行判断识别,循环迭代直至获得合法四边形；获取周长最大的5个四边形进行透视变换,提取5张候选幻灯片图像；获取候选幻灯片图像进行过滤提取冗余幻灯片图像,获得不重复的幻灯片；其中,所述提取5张候选幻灯片图像是基于幻灯片区域在教育视频里宽高比不变的特点,统计所有候选幻灯片区域宽高比的众数,选择宽高比最接近该众数的区域,获取所述候选幻灯片图像；其中,所述获取任意两条不相等直线,计算两直线之间的交叉点,取其一的同时,把每一个交叉点和产生这个交叉点的线段关联在一起；其中,所述进行迭代合并相等的直线的依据为如果两条直线存在一个交点且夹角少于3°,则认为这两条直线相同,就剔除其中任意一条直线；其中,所述获取候选幻灯片图像进行过滤提取冗余幻灯片图像包括：从幻灯片图像I-(i)中得到的特征点集合为从幻灯片图像I-(i+1)中得到的特征点集合为其中N-(i)、N-(i+1)为I-(i)、I-(i+1)的特征点个数,每一个特征点都是128维向量；设分别是幻灯片图像I-(i)、I-(i+1)中的一个特征点,对于中任意的特征点来说,总能在中找到一个与其欧氏距离最近的特征点如果其欧式距离小于D-(c),则认为和是一组匹配点对；如果和之间存在的匹配点对超过预先设定的阈值T-(d),则认为幻灯片图像I-(i)、I-(i+1)相似,可从幻灯片图像序列中删除幻灯片图像I-(i+1),然后接着比较幻灯片图像I-(i)、I-(i+2)的相似性；否则,认为幻灯片图像I-(i)、I-(i+1)不相似,然后接着比较幻灯片图像I-(i+1)、I-(i+2)的相似性；最终得到的不相似幻灯片图像序列,就是提取出不重复的幻灯片。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈佩;              卢德辉;                   谢晓明       </td>   <td>中山大学</td>   <td>一种基于Census变换和局部图优化的RGB-D视觉里程计方法</td>   <td>广东省</td>   <td>CN108010081B</td>   <td>2021-12-17</td>   <td>本发明涉及一种基于Census变换和局部图优化的RGB-D视觉里程计方法,包括以下步骤：通过RGB-D传感器获取环境的彩色和深度图像信息,使用彩色图像计算Census描述图；基于Census描述图,使用直接法对当前帧进行运动估计,计算当前帧与局部图中最新关键帧的相对位姿；对于局部图中梯度信息显著但缺少深度信息的点,在当前帧中进行深度跟踪估计；根据当前帧的位姿估计结果,生成新的关键帧,并插入到局部图中,对局部图进行图优化和关键帧管理操作。本发明使用Census描述图进行直接法运动估计,并结合局部图的优化和管理,提高了视觉里程计在彩色图像亮度发生变化和深度图像深度信息不足时的实时鲁棒性。</td>   <td>1.一种基于Census变换和局部图优化的视觉里程计方法,其特征在于,包括以下步骤：S1.通过RGB-D传感器获取环境的彩色和深度图像信息,使用彩色图像信息计算Census描述图；S2.基于Census描述图,使用直接法对当前帧进行运动估计,计算当前帧与局部图中最新关键帧的相对位姿；梯度信息显著点为满足梯度信息大于阈值t-(g)的点；S3.对于局部图中梯度信息显著但缺少深度图像信息的点,在当前帧中进行深度跟踪估计；S4.根据当前帧的位姿估计结果,生成新的关键帧,并插入到局部图中,对局部图进行图优化和关键帧管理操作；所述基于Census描述图,使用直接法对当前帧进行运动估计,计算当前帧与局部图中最新关键帧的相对位姿包括：对当前帧使用直接法进行运动估计,选出局部图中的最新关键帧,基于Census描述图使用直接法估计最新关键帧到当前帧的位姿变换,迭代优化方法为基于金字塔的LK反向相乘算法：记当前帧为I,局部图中的最新关键帧为K,定义直接法运动估计为：E＝∑-(x∈Ω)w-(x)×||D(W(x,T),I)-D(x,K)||～(2)T～(*)＝argmin-(T)(E)其中,E为直接法优化目标函数,T为关键帧K到当前帧I的位姿变换,T*为使得目标函数E最小的位姿变换；D()表示根据输入的灰度图片I计算得到8通道的描述图D(I)；W(x,T)为将从K中选出的像素点投影到当前帧的变换：W(x,T)＝π(T*π～(-1)(x,dx)),其中π(·)为相机投影函数,将像素点从相机坐标系投影到图像平面中；π～(-1)(·,·)为相机反投影函数,将给定深度值的像素点从图像平面反投影到相机坐标系,w-(x)为通过迭代重赋权最小二乘方法计算的权重值,Ω为从关键帧K中选出的满足梯度信息阈值t-(g)且有有效深度值的像素点；直接法迭代估计结束后,如果像素点x的权重w-(x)大于权重阈值t-(w),则认为x在估计中属于良好点,良好点个数占运动估计所用的总像素个数的比例是生成关键帧的判据之一。</td>   <td>G06T7/73;G06T7/207;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              宋日辉;              江志华;                   李洋灏       </td>   <td>中山大学</td>   <td>一种事件触发相机与三维激光雷达的配准方法</td>   <td>广东省</td>   <td>CN109215063B</td>   <td>2021-12-17</td>   <td>本发明涉及图像处理、点云处理以及传感器数据配准的技术领域,更具体地,涉及一种事件触发相机与三维激光雷达的配准方法。设计一种适用于事件触发相机与三维激光雷达配准的标定物；将带有若干圆孔的板放到电视屏幕前,成为本发明使用的标定物；使用电视屏幕显示用于内参标定的棋盘图得到的内参矩阵；同时启动事件触发相机以及三维激光雷达,得到两种传感器在同一个时刻的数据；使用边缘提取、特定图案识别等图象处理方法,在图象中定位到标定物的一个点；使用基于RANSAC的点云分割等方法,在点云中也定位到标定物的同一个点；通过得到的结果推算出空间中六个自由度上的变换矩阵；通过本发明提出的配准误差和基于边缘的价值函数对配准结果进行评价。</td>   <td>1.一种事件触发相机与三维激光雷达的配准方法,其特征在于,包括以下步骤：步骤1：设计一种适用于事件触发相机与三维激光雷达配准的标定物；步骤2：将带有若干圆孔的板放到电视屏幕前,作为标定物；步骤3：使用电视屏幕显示用于内参标定的棋盘图得到的内参矩阵；步骤4：同时启动事件触发相机以及三维激光雷达,得到两种传感器在同一个时刻的数据；步骤5：使用边缘提取、特定图案识别图像处理方法,在图像中定位到标定物的一个点；步骤6：使用基于RANSAC的点云分割方法,在点云中也定位到标定物的同一个点；步骤7：通过步骤5和步骤6得到的结果推算出空间中六个自由度上的变换矩阵；步骤8：通过配准误差和基于边缘的价值函数对配准结果进行评价；步骤9：配准的过程分为粗校准和细校准,使用基于深度点云切割和融合染色的方法衡量粗配准的质量,基于两图间边缘信息重合度的价值函数S来评价细校准的质量。</td>   <td>G06T7/33;G06T7/80;G06T7/155</td>  </tr>        <tr>   <td>中国专利</td>   <td>         瞿毅力;              苏琬棋;              邓楚富;              王莹;              卢宇彤;                   陈志广       </td>   <td>中山大学</td>   <td>基于条件生成对抗网络的多模态MRI转换方法、系统及介质</td>   <td>广东省</td>   <td>CN110544239B</td>   <td>2021-12-17</td>   <td>本发明公开了一种基于条件生成对抗网络的多模态MRI转换方法、系统及介质,本发明方法包括输入原始MRI图像,将原始MRI图像输入条件生成对抗网络的编码器得到语义特征图,并通过条件生成对抗网络的鉴别器识别原始MRI图像的模态类别；针对每一种原始MRI图像的模态类别以外的其他模态：生成该模态的条件向量,将语义特征图与该模态的条件向量连接,将连接后的结果输入条件生成对抗网络的解码器得到该模态的MRI转换图,从而最终得到所有其他模态的MRI转换图。本发明是无监督的,无需配准的多模态影像即可训练,同时能保证转换生成的多模态MRI是配准的,最后还能保证转换生成的MRI完好的保留了关键的病灶信息,还可以进一步根据需要加以进行检验。</td>   <td>1.一种基于条件生成对抗网络的多模态MRI转换方法,其特征在于实施步骤包括：1)输入原始MRI图像,将原始MRI图像输入条件生成对抗网络的编码器得到语义特征图,并通过条件生成对抗网络的鉴别器识别原始MRI图像的模态类别；2)针对每一种原始MRI图像的模态类别以外的其他模态：生成该模态的条件向量,将语义特征图与该模态的条件向量连接,将连接后的结果输入条件生成对抗网络的解码器得到该模态的MRI转换图,从而最终得到所有其他模态的MRI转换图；步骤1)之前还包括针对条件生成对抗网络进行模块组合训练的步骤,详细步骤包括：S1)输入的i模态的MRI图像x-(i)经过病灶处理器得到生成的病灶标签label-(g,i),原始输入模态i的MRI图像x-(i)对应的真实病灶标签label-(i)作为其监督标签,通过监督标签与生成的病灶标签label-(g,i)求得的均方差损失指导该病灶处理器的训练,病灶处理器预先完成独立训练,且在训练完成后采用该训练好的病灶处理器为后续的生成器提供损失,所述生成器由生成对抗网络的编码器和解码器组成；S2)针对模态数量为C的所有模态中的任意一个模态i,通过条件生成对抗网络的编码器将i模态的MRI编码得到语义特征图code-(i),然后将语义特征图code-(i)与不同模态的条件向量连接,通过条件生成对抗网络的解码器解码出全部的模态,当解码还原到i模态本身时,即是该模态的模态重建,从而完成C-1次模态转换、一次模态重建；对所有通过模态转换得到的转换图,全部采用条件生成对抗网络的编码器进行再编码,将全部再编码得到的语义特征图均与i模态的条件向量进行连接,最后再用条件生成对抗网络的解码器全部解码得到循环重建的i模态的MRI图像；S3)将真实模态图与模态转换得到的转换图分别作为鉴别器的正样本和负样本,通过条件生成对抗网络的鉴别器提供的对抗性损失实现无监督训练；在上述过程中,原始输入的i模态的MRI图像x-(i)经过病灶处理器得到生成的病灶标签label-(g,i),模态i转换成的模态j的MRI图像x-(t,j,i)经过病灶处理器得到生成的病灶标签label-(t,j,i),两个生成标签求得的均方差损失的约束使得MRI图像x-(t,j,i)中病灶信息与x-(i)中病灶信息尽可能一致,从而指导转换过程中生成器的病灶还原训练；S4)根据各个训练步骤的输出结果和指定的损失函数计算损失,再调用优化器对损失函数求导得到上述生成器的各个组件中模型参数的梯度,然后将各个参数与对应梯度求差,完成网络参数的更新,所述生成器的各个组件包括编码器和解码器；S5)判断是否满足预设的迭代结束条件,所述迭代结束条件为损失函数值低于设定阈值或迭代次数达到设定步数,如果不满足则跳转执行步骤S2)；否则退出。</td>   <td>G06T7/00;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;              张星;                   牛群       </td>   <td>中山大学</td>   <td>一种基于室内地标文本与轮廓的室内定位方法</td>   <td>广东省</td>   <td>CN113807357A</td>   <td>2021-12-17</td>   <td>本发明公开了一种基于室内地标文本与轮廓的室内定位方法,包括步骤如下：S1：获取某一室内地标图像,图像包括地标的文本信息、轮廓信息；同时采用GPS定位获取用户当前所在的场景信息；S2：采用光学字符识别算法提取所述的图像中的文本信息,并与第三方平台的室内平面图信息进行匹配,确定用户在室内的初步定位结果,并获取该地标的尺度信息渲染模型,得到不同位置的渲染图像；S3：使用训练好的神经网络提取所述的图像的轮廓信息；S4：使用渲染图像与轮廓信息进行匹配,选择与轮廓信息最为相似的一张渲染图像,将渲染图像的渲染位置作为用户相对地标的拍摄位置,从而产生相对定位结果；S5：将初步定位结果、相对定位结果结合,得到用户的绝对位置信息。</td>   <td>1.一种基于室内地标文本与轮廓的室内定位方法,其特征在于：所述的方法包括步骤如下：S1：获取某一室内地标图像,所述的图像包括地标的文本信息、轮廓信息；同时采用GPS定位获取用户当前所在的场景信息；S2：采用光学字符识别算法提取所述的图像中的文本信息,采用字符串匹配方法将提取的文本信息与第三方平台的室内平面图信息进行匹配,从而确定用户在室内的初步定位结果,并获取该地标的尺度信息渲染模型,得到不同位置的渲染图像；S3：使用训练好的神经网络提取所述的图像的轮廓信息；S4：使用渲染图像与步骤S3提取的轮廓信息进行匹配,选择与轮廓信息最为相似的一张渲染图像,将渲染图像的渲染位置作为用户相对地标的拍摄位置,从而产生相对定位结果；S5：将步骤S2的初步定位结果、步骤S3的相对定位结果结合,得到用户的绝对位置信息。</td>   <td>G06K9/34;G06K9/46;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄晓;              马争鸣;                   袁雪敬       </td>   <td>中山大学</td>   <td>一种基于SPD流形切空间和局部LDA的SPD数据降维算法</td>   <td>广东省</td>   <td>CN113807423A</td>   <td>2021-12-17</td>   <td>本发明提出一种基于基于SPD流形切空间和局部LDA的SPD数据降维算法,实现数据降维算法的构建需要了解数据间的关系,数据降维算法的构建都是基于数据集并非针SPD数据。所以与常见的大数应用不同,本发明采用一个SPD数据表示一个多维数据集。在此数据集表示中,半对称SPD数据是SPD最小线性扩集,(1)本文采用仿射不变的黎曼度量、单位矩阵的切空间以及log变换,把SPD数据从黎曼流形变换到单位矩阵切空间,从而使得SPD与单位矩阵的测地距离与变换后切向量与切空间原点的欧式距离变换保持不变；(2)所谓SPD的局部判别差异就是先把SPD数据分解成一个一个局部,然后根据SPD数据的所属类别(标签)计算SPD数据的局部判别差异。</td>   <td>1.一种基于SPD流形切空间和局部LDA的SPD数据降维算法,其特征在于：A.给出一组有标签(已分类)的SPD数据：(这里X-(ci)表示第c类中的第j个SPD矩阵,N-(c)表示第c类包含SPD矩阵的个数),采用log变换,把这些有标签的SPD数据投影到高维SPD流形单位矩阵的切空间中：由于SPD矩阵的切空间都是对称矩阵空间,也是其SPD矩阵集合的最小线性扩集,这样就减小了变换误差,最大限度的保持了SPD流形的几何结构。B.SPD数据的双线性变换降维是目前常用的SPD数据降维方式。设W∈R～(D×d),且W～(T)W＝I-(d),定义对于任意因为W～(T)W＝I-(d),定义对于任意本文采用仿射不变的黎曼度量、选择单位矩阵的切空间和log变换：对于任意的C.这样做的好处是SPD矩阵X与单位矩阵I-(D)的测地距离和它的切向量log(X)与切空间的原点的欧式距离相同。通过双线性变换矩阵W∈R～(D×d)变换到降维SPD流形单位矩阵的切空间实现高维SPD数据的双线性降维。D.我们在低维SPD流形切空间中计算有标签的数据集的类内散度和类间散度,利用局部LDA准则,得到目标函数。利用黎曼共轭卷积梯度方法优化求解目标函数,该求解方法最适合保留原始SPD切空间结构,简化了计算量,容易求得双线性变换矩阵W∈R～(D×d)。</td>   <td>G06K9/62;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭键清;              樊金飞;                   李蔚东       </td>   <td>中山大学</td>   <td>一种基于深度学习的物流包裹自主检测方法</td>   <td>广东省</td>   <td>CN113807466A</td>   <td>2021-12-17</td>   <td>发明提出了一种基于深度学习的物流包裹自主检测方法,其中,根据深度学习技术要求建立物流包裹图片数据集,数据集从多个场景采集,并且具备不同的角度、光线,也包含一些密集包裹和小包裹；再对数据集中的所有图片进行手动标注。同时,考虑到物流包裹传送过程中包裹堆积导致的包裹和包裹间存在遮挡,包裹错误分类问题,引入Deep-SORT算法,改善包裹堆积情况下的检测效果,引入Deep-SORT算法造成计算量加大,模型效率降低,使用剪枝的方法对模型进行简化,提高模型效率。</td>   <td>1.一种基于深度学习的物流包裹自主检测方法,其特征在于,所述方法包括：S1物流包裹数据采集：基于深度学习模型建立物流包裹图片数据集,数据集从多个场景采集,并且具备不同的角度、光线,也包含一些密集包裹和小包裹；S2建立物流包裹数据集：根据监督学习要求,使用数据标注工具对数据集中的所有图片进行手动标注；S3使用改进后的基于深度学习的目标检测模型进行训练：获得包裹位置异常识别模型；S4使用包裹位置异常识别模型对物流包裹数据进行识别：对识别结果进行评价。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈舒雅;              王青松;                   焦润之       </td>   <td>中山大学</td>   <td>一种异源图像配准方法、系统及装置</td>   <td>广东省</td>   <td>CN113808180A</td>   <td>2021-12-17</td>   <td>本发明公开了一种异源图像配准方法、系统及装置,该方法包括：对SAR图像进行滤波并与对应的光学图像组成图像块对；将图像块对样本本输入深度卷积生成对抗网络进行训练；对训练样本进行数据增强并进行划分；基于训练集训练深度孪生匹配网络；基于训练完成的匹配网络生成匹配点对；根据匹配点对计算变换矩阵并配准图像。该系统包括：图像对样本模块、训练样本模块、划分模块、训练模块、匹配模块和配准模块。该装置包括存储器以及用于执行上述异源图像配准方法的处理器。通过使用本发明,能够提高异源配准精度。本发明作为一种异源图像配准方法、系统及装置,可广泛应用于图像配准领域。</td>   <td>1.一种异源图像配准方法,其特征在于,包括以下步骤：对SAR图像进行滤波并与对应的光学图像组成图像块对,得到图像块对样本；将图像块对样本本输入深度卷积生成对抗网络进行训练,得到训练样本；对训练样本进行数据增强并进行划分,得到训练集和测试集；基于训练集训练深度孪生匹配网络,得到训练完成的匹配网络；提取测试集中图片的图像块并输入至训练完成的匹配网络,得到匹配点对；根据匹配点对计算变换矩阵并配准图像。</td>   <td>G06T7/33;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              欧锐植;                   周凡       </td>   <td>中山大学</td>   <td>基于稀疏采样进行端到端训练的视频问答方法与系统</td>   <td>广东省</td>   <td>CN113807222A</td>   <td>2021-12-17</td>   <td>本发明公开了一种基于稀疏采样进行端到端训练的视频问答方法。包括：对输入的视频进行稀疏采样得到相同时长的N个视频片段；将采样得到的每一个视频片段进行视觉编码、时间融合、位置嵌入,生成该视频片段的视频特征序列；对文本信息编码得到词向量序列,并对其进行位置嵌入；将N个视频片段特征序列和词向量序列进行交叉模型融合和预测,得到N个预测结果,最后再将N个预测结果融合得到最终答案；输入视频和问题到模型中预测问题答案。本发明也公开了一种基于稀疏采样进行端到端训练的视频问答的系统、设备及存储介质。本发明通过稀疏采样解决视频问答任务的方法,相对于基于注意力模型视频问答方法,本发明模型收敛更快,预测准确性更高。</td>   <td>1.一种基于稀疏采样进行端到端训练的视频问答方法与系统,其特征在于,所述方法包括：收集视频片段数据集,将完整视频进行稀疏采样,选取其中注意力权重高的N个视频片段；利用所述采样得到的每一个视频片段进行预处理,对其视觉编码、时间融合、位置嵌入等,生成该视频片段的视频特征序列；利用可训练的词嵌入网络对问题文本信息进行编码,进行位置嵌入操作,得到文本词向量序列；将所述N个视频片段得到的N个视频特征序列分别与所述文本词向量序列进行交叉模型融合和预测,得到N个预测结果,再将N个预测结果进行融合得到最终预测答案；初始化神经网络模型结构中的权重参数,进行端到端训练,至损失函数的结果收敛到合适阈值,训练完成后得到视频问答模型；输入待处理问题和对应的视频到所述训练后的视频问答模型中,利用其生成预测答案。</td>   <td>G06K9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈思航;                   骆伟祺       </td>   <td>中山大学</td>   <td>一种结合日内量价信息的股指趋势预测方法及系统</td>   <td>广东省</td>   <td>CN113807970A</td>   <td>2021-12-17</td>   <td>本发明提出一种结合日内量价信息的股指趋势预测方法及系统,涉及量化交易与计算机科学的技术领域,在每个交易日收盘后,获取股票指数当前交易日及之前若干个交易日的量价信息数据,并从数据中提取粗粒度因子及细粒度因子,以充分考虑可能影响股票市场的市场内部因素以及市场外部因素,然后通过因子评价方法对细粒度因子进行评价筛选,确定训练集数据和测试集数据,将该股票指数在之前若干个交易日的涨跌作为标签,对股指趋势预测模型进行训练,然后测试股指趋势预测模型,在下一个交易日开盘时,根据股指趋势预测模型输出的涨跌信号进行交易,最后,基于历史回测,对股指趋势预测模型进行评价,具有很强的实践意义。</td>   <td>1.一种结合日内量价信息的股指趋势预测方法,其特征在于,所述方法包括以下步骤：S1.选定作为预测对象的股票指数,在每个交易日收盘后,获取该股票指数当前交易日及之前若干个交易日的量价信息数据；S2.从步骤S1的数据中获取粗粒度因子及细粒度因子；S3.通过因子评价法对细粒度因子进行评价筛选；确定股指趋势预测模型；S4.将该股票指数在之前若干个交易日数据中提取的粗粒度因子和步骤S3评价筛选后的细粒度因子作为训练集数据,将该股票指数在之前若干个交易日的涨跌信号作为标签,对股指趋势预测模型进行训练；S5.将该股票指数当前交易日中提取的粗粒度因子和步骤S3评价筛选后的细粒度因子作为测试集数据输入至训练好的股指趋势预测模型,在下一个交易日开盘时,根据股指趋势预测模型输出的涨跌信号进行交易；S6.基于历史回测,对股指趋势预测模型进行评价。</td>   <td>G06Q40/04;G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              孟小哲;              林格;                   苏卓       </td>   <td>中山大学</td>   <td>基于高斯过程映射的迁移学习去雾方法与系统</td>   <td>广东省</td>   <td>CN113808039A</td>   <td>2021-12-17</td>   <td>本发明公开了基于高斯过程映射的迁移学习去雾方法与系统。包括：数据集收集和处理,搭建去雾网络包括编码器模块和解码器模块,通过将有雾图和无雾图输入,获得相应的编码器、解码器参数,进行高斯迁移计算,得到预测值,最终得到去雾图。本发明提供一种能够通过基于高斯过程的迁移学习进行去雾的框架,解决数据域漂移带来的在合成数据上训练模型存在偏差的问题,同时通过迁移学习以及在隐空间中建立函数关系来实现有雾图和无雾图在神经网络上的重建,神经网络的参数可以视为将两个数据域参数化,同时将隐空间中的特征以向量形式储存。在隐空间中建立映射,解决卷积的特征空间难以建立函数关系的问题。</td>   <td>1.基于高斯过程映射的迁移学习去雾方法,其特征在于,所述方法包括：数据收集和预处理,将数据集统一裁剪尺寸,得到的每个有雾图对应一张无雾图；搭建重建网络包括编码器和解码器,解码器与编码器对称,各包含五个模块；将所述有雾图和所述有雾图对应的无雾图输入所述重建网络,所述编码器将输入图像压缩至固定维度,所述解码器负责重建图像,获得有雾图矩阵和无雾图矩阵,保存训练结束后重建损失最小时的有雾图数据集对应的模型参数和无雾图数据集对应的模型参数；迁移所述编码器,记为新编码器,添加一个滤除模块,加载所述有雾图数据集对应的模型参数中编码器部分,保持该参数固定不更新；从真实有雾图数据集中选取新的有雾图,输入所述新编码器中,得到一个新编码器输出结果,变换维度后得到一维向量；迁移所述有雾图矩阵和所述无雾图矩阵,进行降维操作,得到降维后的有雾图矩阵和降维后的无雾图矩阵；将所述新编码器输出结果、所述降维后的有雾图矩阵和所述降维后的无雾图矩阵,进行矩阵变换,输入高斯过程GPM模块,计算得到最终预测值；迁移所述解码器,加载所述无雾图数据集对应的模型参数中解码器部分,保持该参数固定不更新,将所述预测值输入到解码器中,输出所述新的有雾图对应的去雾图。</td>   <td>G06T5/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈刚;              周兆恒;                   何晨宇       </td>   <td>中山大学</td>   <td>一种轻量化的语音去噪方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113808613A</td>   <td>2021-12-17</td>   <td>本发明公开了一种轻量化的语音去噪方法、系统、设备及存储介质,方法包括：获取混合音源数据；通过VoiceBit计算框架对所述混合音源数据进行分类处理,确定所述混合音源数据中不同类型的音源数据；将所述分类处理的结果传输至目标终端,由所述目标终端播放相应类型的音源数据。本发明能够实现在移动端的低延时以及低功耗的音源分离,可广泛应用于音频数据处理技术领域。</td>   <td>1.一种轻量化的语音去噪方法,其特征在于,包括：获取混合音源数据；通过VoiceBit计算框架对所述混合音源数据进行分类处理,确定所述混合音源数据中不同类型的音源数据；将所述分类处理的结果传输至目标终端,由所述目标终端播放相应类型的音源数据。</td>   <td>G10L21/028;G10L25/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国玉;              周永坤;              王伟;              饶彬;              王涛;              周颖;              邹小海;                   徐峰       </td>   <td>中山大学</td>   <td>基于电磁频谱数据挖掘的社会性群体行为识别方法、计算机装置和存储介质</td>   <td>广东省</td>   <td>CN113792763A</td>   <td>2021-12-14</td>   <td>本发明公开了一种基于电磁频谱数据挖掘的社会性群体行为识别方法、计算机装置和存储介质,社会性群体行为识别方法包括：获取频段占用度和社会性群体行为的特征数据,从特征数据中提取出最优特征子集,确定频段占用度与最优特征子集之间的相关关系,对最优特征子集进行时变行为分析,获得第一时间序列,根据相关关系以及第一时间序列,构建社会性群体行为预测模型进行社会性群体行为识别等步骤。本发明只需进行物理层面的分析即可完成识别,并且监测过程不会对通信过程以及无线电环境造成干扰,在合法进行的前提下无需经过通信运营商或者用户,不会有侵犯隐私的风险,实施难度小。本发明广泛应用于数据挖掘技术领域。</td>   <td>1.一种基于电磁频谱数据挖掘的社会性群体行为识别方法,其特征在于,包括：获取第一区域中进行的无线电通信的频段占用度；获取所述第一区域中社会性群体行为的特征数据；从所述特征数据中提取出最优特征子集；通过地理加权回归模型确定所述频段占用度与所述最优特征子集之间的相关关系；通过时间序列模型对所述最优特征子集进行时变行为分析,获得第一时间序列；根据所述频段占用度与所述最优特征子集之间的相关关系以及所述第一时间序列,使用深度学习模型构建社会性群体行为预测模型；使用所述社会性群体行为预测模型进行社会性群体行为识别。</td>   <td>G06K9/62;G06N3/08;G06F17/18;H04W4/029</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李德芳;              陈伟福;                   冯国灿       </td>   <td>中山大学</td>   <td>人脸图像属性编辑方法、系统、计算机设备及存储介质</td>   <td>广东省</td>   <td>CN113793254A</td>   <td>2021-12-14</td>   <td>本发明公开了人脸图像属性编辑方法、系统、计算机设备及存储介质,该方法通过由编码器获取待编辑图像,将待编辑人脸图像解耦表征为隐表示,该隐表示中包含若干个表示人脸属性的隐单元；提取待编辑隐单元后,根据预设条件调整该待编辑隐单元为目标单元,更新该隐表示；将更新后的隐表示与根据目标单元与待编辑隐单元计算得到的残差属性向量一同输入解码器,生成目标图像。本发明通过解决了当前人脸图像属性编辑算法在基于语义层面的属性编辑,因受制于属性类标所提供的有限信息导致转换属性结果缺乏多样性,也无法实现实例层面的特定属性风格转换,以及图像准确性与保真度低下的问题。</td>   <td>1.人脸图像属性编辑方法,所述方法应用于服务器上,其特征在于,所述方法包括：接收待编辑人脸图像；将待编辑人脸图像通过编码器进行映射处理,生成隐表示,所述隐表示包括若干个表示图像属性的隐单元；从所述隐表示中提取待编辑隐单元,根据预设条件调整所述待编辑隐单元为目标单元,再根据目标单元更新隐表示；根据目标单元与待编辑隐单元计算残差属性向量,所述残差属性向量用于指示人脸属性变化；将所述残差属性向量与更新后隐表示输入解码器,生成目标人脸图像。</td>   <td>G06T3/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴维刚;                   杨晨罡       </td>   <td>中山大学</td>   <td>一种基于层次聚类的联邦学习方法及系统</td>   <td>广东省</td>   <td>CN113780344A</td>   <td>2021-12-10</td>   <td>本发明为克服在联邦学习数据非独立同分布下,抵抗恶意攻击效果不理想的缺陷,提出一种基于层次聚类的联邦学习方法及系统包括以下步骤：根据服务器收到客户端上传的局部模型,对客户端进行聚类处理,将客户端分成k类；在每个类中,采用传统分布式机器学习的聚合算法,分别选出k个客户端类的代表；对选择的代表重新计算权重,减弱可能存在的恶意代表影响,对选择的代表进行加权平均,得到更新的全局模型。最终在联邦学习数据非独立同分布的情况下,有效地抵抗恶意客户端的攻击。</td>   <td>1.一种基于层次聚类的联邦学习方法,其特征在于,包括以下步骤：S1：对客户端聚类：根据服务器收到客户端上传的局部模型,对客户端进行聚类处理,将客户端分成k类；S2：选择代表：在每个类中,采用传统分布式机器学习的聚合算法,分别选出k个客户端类的代表；S3：更新全局模型：对S2步骤中选择的代表重新计算权重,对选择的代表进行加权平均,得到更新的全局模型。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;              许圣钧;              彭渝泽;              陈清坤;                   黄文津       </td>   <td>中山大学</td>   <td>基于使用物品流行度辅助用户兴趣建模的推荐方法</td>   <td>广东省</td>   <td>CN113781181A</td>   <td>2021-12-10</td>   <td>本发明公开了一种基于使用物品流行度辅助用户兴趣建模的推荐方法,包括如下：S1：将会话中物品序列分成多个样本点输入到图神经网络,每一个样本点构成一张图,每一个物品为一个节点,根据物品点击的先后顺序连接,形成若干条边；通过相邻节点的信息流动不断更新节点的向量表示；S2：将一张图中所有节点的向量表示输入感知网络得到采用向量表示的长期兴趣；把会话中最后一项物品的向量表示当作不充分的短期兴趣；通过会话物品交互信息提取物品流行度；S3：最后将得到的长期兴趣、短期兴趣和物品流行度输入自关注层,通过SoftMax层得到会话的最终表示,即用户兴趣；S4：将用户兴趣与各个物品分别相乘,得到得分,然后通过softmax得到最终推荐概率向量。</td>   <td>1.一种基于使用物品流行度辅助用户兴趣建模的推荐方法,其特征在于：所述的推荐方法包括如下：S1：将会话中物品序列分成多个样本点输入到图神经网络,每一个样本点构成一张图G-(s)＝(V-(s),ξ-(s)),每一个物品为一个节点v-(s,i)∈V,根据物品点击的先后顺序连接,形成若干条边,每一条边(v-(s,i-1),v-(s,i))∈ξ-(s)表示一个用户在会话s中先点击物品v-(s,i-1),再点击物品v-(s,i)；通过相邻节点的信息流动不断更新节点的向量表示；S2：将一张图中所有节点的向量表示输入感知网络得到采用向量表示的长期兴趣；把会话中最后一项物品的向量表示当作不充分的短期兴趣；通过会话物品交互信息提取物品流行度；S3：最后将得到的长期兴趣、短期兴趣和物品流行度输入自关注层,通过SoftMax层得到会话的最终表示,即用户兴趣；S4：将用户兴趣与各个物品分别相乘,得到得分,然后通过softmax得到最终推荐概率向量。</td>   <td>G06Q30/06;G06N3/08;G06N3/04;G06F16/9535</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张荣辉;                   苟万婷       </td>   <td>中山大学</td>   <td>一种低光照场景下车道线检测增强方法、装置及终端设备</td>   <td>广东省</td>   <td>CN113781374A</td>   <td>2021-12-10</td>   <td>本发明公开了一种低光照场景下车道线检测增强方法、装置及终端设备,该方法对原始图像和经过增强后的图像沿着通道数的维度进行拼接获得六通道图像,并将六通道图像输入车道检测网络中。该方法帮助车道检测线提取更多有效的车道特征,提高了低光照场景下的数据识别精度,且没有产生额外的数据标注工作量及网络推理开销。</td>   <td>1.一种低光照场景下车道线检测增强方法,其特征在于,包括：通过车道线图像增强网络对设备采集的车道线图像进行图像增强处理,得到第一图像；将所述车道线图像与所述第一图像进行拼接处理,获得六通道图像；将所述六通道图像输入到训练好的车道线模型中进行检测,获得含有车道线预测位置的第二图像；其中,将车道线样本图像输入LaneNet网络中训练得到所述车道线模型。</td>   <td>G06T5/50;G06T3/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              张夏茵;              肖辉;              邱伟;                   刘春新       </td>   <td>中山大学中山眼科中心</td>   <td>一种鉴别视神经脊髓炎和原发性开角型青光眼的系统</td>   <td>广东省</td>   <td>CN113781380A</td>   <td>2021-12-10</td>   <td>本发明涉及一种鉴别视神经脊髓炎和原发性开角型青光眼的系统,包括：图像采集模块；参数获取模块,用于根据患有视神经脊髓炎和患有原发性开角型青光眼的眼底光学相干断层扫描血管图像获得诊断参数；函数生成模块,用于利用所述诊断参数计算Fisher判别的分类函数系数,并根据所述分类函数系数分别生成视神经脊髓炎和原发性开角型青光眼的Fisher判别函数；比较判定模块,用于将待鉴别的眼底光学相干断层扫描血管图像的诊断参数分别代入Fisher判别函数中,比较两个函数值大小,若视神经脊髓炎的函数值大于原发性开角型青光眼的函数值,则判定为视神经脊髓炎,否则判定为原发性开角型青光眼。本发明提高两种疾病的准确率,同时有助于患者减少检查项目和检查时间。</td>   <td>1.一种鉴别视神经脊髓炎和原发性开角型青光眼的系统,其特征在于,包括：图像采集模块,用于采集患有视神经脊髓炎和患有原发性开角型青光眼的眼底光学相干断层扫描血管图像；参数获取模块,用于根据患有视神经脊髓炎和患有原发性开角型青光眼的眼底光学相干断层扫描血管图像,获得诊断参数,所述诊断参数包括眼底结构参数、血流参数和黄斑中心无血管区面积FAZ,所述眼底结构参数包括视乳头旁神经纤维层颞侧及下方的平均厚度TIpRNFL、黄斑神经节细胞层-内丛状层鼻侧厚度N GC-IPL和垂直杯盘比verticalC/D；函数生成模块,用于利用所述诊断参数计算Fisher判别的分类函数系数,并根据所述分类函数系数分别生成视神经脊髓炎和原发性开角型青光眼的Fisher判别函数；比较判定模块,用于将待鉴别的眼底光学相干断层扫描血管图像的诊断参数分别代入所述视神经脊髓炎和原发性开角型青光眼的Fisher判别函数中,得到两个函数值,并比较两个函数值大小,若视神经脊髓炎的函数值大于原发性开角型青光眼的函数值,则判定所述待鉴别的眼底光学相干断层扫描血管图像为患有视神经脊髓炎,否则判定为所述待鉴别的眼底相干断层扫描血管图像为患有原发性开角型青光眼。</td>   <td>G06T7/00;G06K9/62;A61B3/12;A61B3/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              彭晖;              张夏茵;                   肖辉       </td>   <td>中山大学中山眼科中心</td>   <td>一种识别慢性肾病图像的系统</td>   <td>广东省</td>   <td>CN113781381A</td>   <td>2021-12-10</td>   <td>本发明涉及一种识别慢性肾病图像的系统,包括：图像采集模块,采集患有慢性肾病患者和健康人群的眼底光学相干断层扫描血管图像；参数获取模块,根据采集的眼底光学相干断层扫描血管图像获得诊断参数；函数生成模块,利用所述诊断参数计算Fisher判别的分类函数系数,并根据所述分类函数系数分别生成慢性肾病和健康人群的Fisher判别函数；比较判定函数模块,将待识别患者的诊断参数分别代入所述慢性肾病和健康人群的Fisher判别函数中,得到两个函数值,并比较两个函数值大小,若慢性肾病的Fisher判别函数的函数值大于健康人群的Fisher判别函数的函数值,则判定为患有慢性肾病的图像,否则判定为健康状态的图像。本发明识别准确率高,有助于患者减少检查项目和时间。</td>   <td>1.一种识别慢性肾病图像的系统,其特征在于,包括：图像采集模块,用于采集患有慢性肾病患者和健康人群的眼底光学相干断层扫描血管图像；参数获取模块,用于根据采集的眼底光学相干断层扫描血管图像获得诊断参数,所述诊断参数包括眼底结构参数和血流参数,所述眼底结构参数包括视乳头旁神经纤维层鼻侧厚度NpRNFL、黄斑神经节细胞层-内丛状层鼻侧上方厚度NS GC-IPL和垂直杯盘比verticalC/D；函数生成模块,用于利用所述诊断参数计算Fisher判别的分类函数系数,并根据所述分类函数系数分别生成慢性肾病和健康人群的Fisher判别函数；比较判定模块,用于将根据待识别患者的眼底光学相干断层扫描血管图像获得的诊断参数分别代入所述慢性肾病和健康人群的Fisher判别函数中,得到两个函数值,并比较两个函数值大小,若慢性肾病的Fisher判别函数的函数值大于健康人群的Fisher判别函数的函数值,则判定所述待识别患者的眼底光学相干断层扫描血管图像为患有慢性肾病的图像,否则判定为所述待识别的眼底相干断层扫描血管图像为健康状态的图像。</td>   <td>G06T7/00;A61B3/10;A61B3/12;A61B3/13</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄佳博;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于生成式对抗网络的多图像人脸对齐的方法及装置</td>   <td>广东省</td>   <td>CN108319932B</td>   <td>2021-12-07</td>   <td>本发明公开一种基于生成式对抗网络的多图像人脸对齐方法,包括输入多张真实人脸图像至生成器,生成器处理该图像,以生成拟合真实图像分布的合成图像；将真实人脸图像与合成图像输入判别器,以获得真实人脸图像的真实概率及合成图像的真实概率,迭代更新生成器和判别器的参数直至其收敛以确定由生成器和判别器构建的模型；将待对齐多人脸图像输入到所确定的模型中,通过一次前向传递运算得到对齐后人脸图像。本发明能够根据多张人脸图像生成一张清晰且对齐后的人脸图像,多人脸图像矩阵与对齐图像相减得到的噪声矩阵的稀疏程度反应了生成人脸图像与输入人脸图像对齐的程度,而生成式对抗网络记录了人脸的整体与细节特征。</td>   <td>1.一种基于生成式对抗网络的多图像人脸对齐方法,其特征在于,包括如下步骤：S10输入多张经过预处理的真实人脸图像至生成器,生成器对所输入的真实人脸图像进行编码、转码及解码处理,生成拟合真实图像分布的合成图像,将多张预处理后真实人脸图像与合成图像输入判别器,以获得真实人脸图像的真实概率及合成图像的真实概率,迭代更新生成器和判别器的参数直至其收敛以确定由生成器和判别器构建的模型；包括：S101图像预处理：对人脸图像数据库中每一张待处理人脸图像,使用人脸检测算法得到图像中人脸所处的方形区域,将图像输入到MTCNN模型中,MTCNN将输出图像中人脸方形区域的坐标及长宽,用变量s表示输入图像的长与宽,用c表示图像的通道数,利用python程序的numpy程序库中的矩阵操作接口,根据人脸方形区域的坐标将每张图像中的人脸区域裁剪出来并进行缩放,使得数据库中每张图像都有一致的尺寸,裁剪并缩放后得到的图像作为数据预处理的结果,供后续步骤使用；S102划分图像段：将预处理后的数据中将每个对象的所有图像随机划分成由n张图像组成的图像段(clip),如果所有图像的整数无法整除n,抛弃余数图像或者随机从前面的视频段中抽取图像填到最后一个clip中,将每个clip中的n张图像在通道维度上拼接,让每张图像在通道维度上首尾相连,以得到一个尺寸为(s,s,c*n)的多图像矩阵,将处理得到的所有多图像矩阵作为队列元素依次储存于python程序的一个列表对象中,并使用python程序的random程序库的shuffle方法随机打算队列元素的顺序；S103构建模型：根据生成器和判别器的结构及参数,采用深度学习框架构建生成式对抗网络模型；S104模型训练：模型训练的过程是通过不断调用自适应矩估计梯度下降算法,更新模型参数以最小化估计分布与真实分布之间的偏差造成的损失,根据目标函数,通过一次前向传递运算计算得到当前模型的损失,然后根据当前模型的损失计算模型中各参数的更新梯度,并通过一次后向传递运算进行参数更新,使得更新后模型拟合的数据分布趋近真实的数据分布；S20将待对齐多人脸图像输入到所确定的模型中,通过一次前向传递得到对齐后人脸图像。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴维刚;                   亓文康       </td>   <td>中山大学</td>   <td>基于聚类和注意力机制的集群负载预测方法及系统</td>   <td>广东省</td>   <td>CN113762356A</td>   <td>2021-12-07</td>   <td>本发明提出一种基于聚类和注意力机制的集群负载预测方法及系统,包括获取计算机集群的离散时间序列,将离散时间序列分为训练集和测试集；通过聚类算法,将计算机集群的离散时间序列分成k类；基于注意力机制,设置k个成对的本类编码器和本类解码器,以及全局编码器,并对k个成对的本类编码器和本类解码器,以及全局编码器进行训练；将聚类后的测试集的离散时间序列输入到训练好的本类编码器和全局编码器中得到相应的注意力序列表示,再将本类编码器和全局编码器分别输出的注意力序列拼接后,输入本类解码器中,得到集群负载预测结果。本发明提高了模型预测的精度,避免了计算资源损耗较高的缺陷,有助于集群更好的调度任务以提升资源利用率。</td>   <td>1.基于聚类和注意力机制的集群负载预测方法,其特征在于,包括以下步骤：S1：获取计算机集群的离散时间序列,将离散时间序列分为训练集和测试集；S2：通过聚类算法,将计算机集群的离散时间序列分成k类；S3：基于注意力机制,设置k个成对的本类编码器和本类解码器,以及全局编码器；将k类离散时间序列全部输入全局编码器中进行训练,每个类的本类编码器采用本类内的离散时间序列进行训练；全局编码器和本类编码器训练完成后,将全局编码器和本类编码器的输出拼接起来,再输入到相应的本类解码器中进行训练；S4：将聚类后的测试集的离散时间序列输入到训练好的本类编码器和全局编码器中得到相应的注意力序列表示,再将本类编码器和全局编码器分别输出的注意力序列拼接后,输入相应的本类解码器中,得到集群负载预测结果。</td>   <td>G06K9/62;G06F9/50;G06F9/48</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴维刚;                   肖汕斌       </td>   <td>中山大学</td>   <td>一种区块链支付通道网络交易手续费分配方法及系统</td>   <td>广东省</td>   <td>CN113763163A</td>   <td>2021-12-07</td>   <td>本发明提出一种区块链支付通道网络交易手续费分配方法及系统,解决了当前区块链链下支付通道交易中手续费分配方式不合理,不利于区块链网络交易效能提升的问题,首先确定交易的双方、交易路径及发送方需支付的手续费,在区块链链下建立支付通道,考虑支付通道路径节点的倾斜程度,基于HTLC合约,将资金按照对路径节点倾斜程度的利害进行分配,在给定支付通道交易的交易路径和手续费的情况下,合理地分配各个中间路径节点的手续费,从而吸引更多的路径节点加入,使整体网络更加健壮,达到提升区块链网络交易效能的目的。</td>   <td>1.一种区块链支付通道网络交易手续费分配方法,其特征在于,所述方法至少包括：S1.确定交易的发送方与接收方、发送方与接收方之间的交易路径节点、支付通道资金参数及原HTLC合约中路径节点之间的资金交易额度；S2.从发送方至接收方的方向,依次获取路径节点的倾斜程度；S3.根据路径节点的倾斜程度,由发送方计算每个中间路径节点的临时权重,根据临时权重计算总权重；S4.根据总权重,由发送方计算每个路径节点应获得的手续费；S5.在原HTLC合约中路径节点之间的资金交易额度上增加每个路径节点应获得的手续费,并按照HTLC交易流程完成交易,由接收方发送原像y至发送方；S6.以发送方至接收方的方向,依次发送以y为原像的HTLC合约至下一个路径节点,并设置资金交易额度；S7.从接收方至接收方的方向,依次接收HTLC合约,使用原像y完成HTLC合约交易。</td>   <td>G06Q40/04;G06Q20/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              吴晓航;              郭翀;                   刘力学       </td>   <td>中山大学中山眼科中心</td>   <td>一种眼底图像分析方法、系统、存储介质和计算机设备</td>   <td>广东省</td>   <td>CN113744254A</td>   <td>2021-12-03</td>   <td>本发明涉及医学图像分析领域,更具体地,涉及一种眼底图像分析方法、系统、存储介质和计算机设备。一种眼底图像分析方法,包括以下步骤：获取所拍摄的眼底图像；分析眼底图像的整体质量是否合格,如果整体质量合格,则输出眼底图像,如果整体质量不合格,则分析眼底图像的结构完整度和亮度是否合格；如果结构完整度或者亮度不合格,则重新拍摄眼底图像,如果结构完整度和亮度合格,则分析眼底图像的清晰度是否合格；如果清晰度合格,则输出眼底图像,如果清晰度不合格,则分析眼底图像是否屈光间质浑浊；如果屈光间质浑浊,则输出眼底图像并发送就诊建议,如果没有屈光间质浑浊,则重新拍摄眼底图像。</td>   <td>1.一种眼底图像分析方法,其特征在于,包括以下步骤：获取所拍摄的眼底图像；分析所述眼底图像的整体质量是否合格,如果所述整体质量合格,则输出所述眼底图像,如果所述整体质量不合格,则分析所述眼底图像的结构完整度和亮度是否合格；如果所述结构完整度或者所述亮度不合格,则重新拍摄所述眼底图像,如果所述结构完整度和亮度合格,则分析所述眼底图像的清晰度是否合格；如果所述清晰度合格,则输出所述眼底图像,如果所述清晰度不合格,则分析所述眼底图像是否屈光间质浑浊；如果屈光间质浑浊,则输出所述眼底图像并发送就诊建议,如果没有屈光间质浑浊,则重新拍摄所述眼底图像。</td>   <td>G06T7/00;G06N3/04;A61B3/12;A61B3/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         江颖;              刘曌焕;              刘伟锋;                   吴锐帆       </td>   <td>中山大学</td>   <td>一种低剂量SPECT弦图恢复和散射校正的方法</td>   <td>广东省</td>   <td>CN113744356A</td>   <td>2021-12-03</td>   <td>本发明涉及一种低剂量SPECT弦图恢复和散射校正的方法,步骤一：生成投影数据并进行标准化处理；步骤二：将生成的投影数据输入至SCASC-Net模型中进行模型训练；步骤三：将低剂量SPECT弦图数据输入至步骤二的训练好的模型中,对弦图进行恢复和散射校正。对于低剂量SPECT投影数据的特点和在角度方向的连续性,本发明的网络模型在进行低剂量弦图恢复和散射校正的同时,通过空间注意力模块和通道注意力模块能够发现投影数据角度之间的联系,同时也能关联到相邻断层图像之间在投影数据域的关系,使得恢复后的弦图尽可能地保留细节。经过上述方法对弦图进行预处理后,弦图的细节能够保留,再通过使用预处理后的弦图进行图像的重建,最终能够获得高质量的SPECT断层图像。</td>   <td>1.一种低剂量SPECT弦图恢复和散射校正的方法,其特征在于,包括如下步骤：步骤一：生成投影数据并进行标准化处理；步骤二：将生成的投影数据输入至SCASC-Net模型中进行模型训练；所述SCASC-Net模型通过编码器提取投影数据的特征后同时输入至通道注意力模块和空间注意力模块中；通道注意力模块和空间注意力模块中输出特征在通道维度上进行拼接,作为解码器的初始输入；解码器对所输入的特征进行逐步上采样至原图大小,最终输出V通道的预测图；将预测图与真实的弦图作对比并计算误差,使用梯度下降法反向传导更新模型参数,从而完成模型的训练；步骤三：将低剂量SPECT弦图数据输入至步骤二的训练好的模型中,对弦图进行恢复和散射校正。</td>   <td>G06T11/00;G06N3/04;G06N3/08;A61B6/03</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴维刚;                   曹博凯       </td>   <td>中山大学</td>   <td>一种基于联邦学习的在线学习方法、系统、计算机设备及介质</td>   <td>广东省</td>   <td>CN113743616A</td>   <td>2021-12-03</td>   <td>本发明提出一种基于联邦学习的在线学习方法、系统、计算机设备及介质,解决了因当前用户终端采集数据的质量和数量参差不齐,导致联邦学习得到的模型泛化能力差的问题,本申请基于联邦学习,将采集的数据保存在在用户终端本身,防止了数据泄露的问题,每个用户终端利用持续采集的数据对接收到的全局模型进行在线学习训练,将持续采集的数据加入到训练之中,新数据整合成一个数据训练批后即加入全局模型进行训练,提高了数据量,提升了联邦学习的模型泛化能力。</td>   <td>1.一种基于联邦学习的在线学习方法,其特征在于,所述方法包括以下步骤：S1.服务器初始化全局模型的参数,统一将全局模型派发给每个用户终端；S2.每个用户终端接收全局模型；S3.每个用户终端持续采集用户行为产生的数据,并保存于用户终端本地；S4.每个用户终端利用持续采集的数据对接收到的全局模型进行在线学习训练；S5.每个用户终端将训练好的全局模型参数上传至服务器；S6.服务器进行参数聚合,生成新的全局模型,执行步骤S7；S7.判断是否达到在线学习终止条件,若是,则在线学习训练结束；否则,返回步骤S3。</td>   <td>G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              张雪婷;              徐锐;                   李丽       </td>   <td>中山大学</td>   <td>一种基于机器学习的船舶关键技术参数预测方法及系统</td>   <td>广东省</td>   <td>CN113743662A</td>   <td>2021-12-03</td>   <td>本发明提出了一种基于机器学习的船舶关键技术参数预测方法,包括构建关键技术参数预测模型和船舶技术参数数据库；根据船舶技术参数数据库中的数据建立关键技术参数的特征样本集并从中获取关键技术参数预测模型的输入特征；利用输入特征和对应关键技术参数对关键技术参数预测模型进行训练测试,直至关键技术参数预测模型符合训练要求；将待预测的船舶关键技术参数作为验证集输入训练好的关键技术参数预测模型中,完成船舶关键技术参数的预测。本发明通过训练完成的关键技术参数预测模型有效解决船舶关键技术参数缺失的问题,过程简单、精度高,可以快速预测得到多种类型船舶关键技术参数,提高了船舶关键技术参数补充的精度和效率。</td>   <td>1.一种基于机器学习的船舶关键技术参数预测方法,其特征在于,包括以下步骤：S1：基于机器学习算法构建关键技术参数预测模型；S2：获取船舶的技术参数信息数据,构建船舶技术参数数据库；S3：对船舶技术参数数据库中的数据进行预处理,建立关键技术参数的特征样本集；S4：根据海军部系数法获取关键技术参数的影响因素,从特征样本集中获取关键技术参数预测模型的输入特征；S5：将输入特征和对应关键技术参数进行数据结构转换和归一化处理,划分出训练集和测试集；S6：使用训练集对关键技术参数预测模型进行训练,测试集测试关键技术参数预测模型的预测效果,直至关键技术参数预测模型符合训练要求；S7：将待预测的船舶关键技术参数作为验证集输入训练好的关键技术参数预测模型中,完成船舶关键技术参数的预测；其中,关键技术参数为主机额定功率和设计最大航速两个连续性数据。</td>   <td>G06Q10/04;G06Q10/06;G06K9/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐晓颖;              邓丽洁;              袁进;                   黄海香       </td>   <td>佛山市顺德区中山大学研究院;中山大学;中山大学中山眼科中心</td>   <td>荧光染色图像反光点识别与重定义的方法及系统</td>   <td>广东省</td>   <td>CN109410236B</td>   <td>2021-11-30</td>   <td>本发明为荧光染色图像反光点识别与重定义的方法及系统,提供的方法及系统根据反光区域的RGB颜色特征,设置特定阈值范围识别图片中的反光点、反光区域,根据反光点周围像素点的颜色信息进行迭代填充,最后根据反光点特定范围像素点的颜色信息对其进行颜色的重新定义。该方法精准地识别出荧光染色图像的反光区域,对于溃烂区域和非溃烂区域的反光点都能很好地区分以及重新定义,解决了染色图像中反光区域影响精准分割的问题,为后续的角膜溃烂区域分割减少冗余信息与干扰因素。</td>   <td>1.一种荧光染色图像反光点识别与重定义的方法,其特征在于：包括以下步骤：S1.定义具体的RGB颜色空间三个通道的阈值范围作为发光点的判断阈值范围H,并以此阈值范围来识别提取荧光染色图像中角膜的反光点及对应的反光区域；S2.以反光区域的每一个反光点为中心,在半径为m个像素点的圆形区域上随机抽取一个像素点,并把该像素点的RGB值赋值给对应的反光点,m为大于1的整数；以上过程由反光区域边缘向内部中心的方向依次进行,赋值后反光点的RGB颜色空间三个通道的值不在判断阈值范围H内；S3.在步骤S2的基础上,以反光点为中心,在半径为n个像素点的圆形区域上随机抽取k个像素点,其中n为大于1的整数,k为大于2的整数；k个像素点中,若某个像素点的RGB值满足阈值范围：0＜R＜200,100＜G＜255,0＜B＜200,则该像素点判定反光点原来的颜色为绿色；否则判定为蓝色；统计k个像素点中分别判定反光点原来的颜色为绿色、蓝色的像素点的数量,若判定反光点原来的颜色为绿色的像素点较多,则重定义反光点的RGB值为绿色[0,255,0],否则重定义反光点的RGB值为蓝色[0,0,255]。</td>   <td>G06T7/136;G06T7/11;G06T7/90;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         莫颖倩;              戴冽;              欧阳志明;              李谦华;                   柳叶青       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种唇腺病理智能分析系统及方法</td>   <td>广东省</td>   <td>CN113723441A</td>   <td>2021-11-30</td>   <td>本发明公开了一种唇腺病理智能分析系统及方法。所述系统包括唇腺组织面积测定模块、淋巴细胞灶测定模块、分析处理模块、结果显示模块。该系统通过构建第一深度神经网络,逐一测量唇腺数字病理切片中各唇腺组织面积(mm～(2)),并将各唇腺组织面积相加,得唇腺组织总面积；同时构建第二深度神经网络和第三深度神经网络,用于识别统计超过50个淋巴细胞聚集的淋巴细胞灶数量,得淋巴细胞灶数量；进而计算出评估患者是否符合诊断干燥综合征的“金标准”,即灶性指数≥1,为临床医生提供诊断建议。该系统实现了唇腺病理智能分析评估,可直接输出判断结果,简单准确,不但解决了人工唇腺病理报告不规范的临床问题,而且可促进我国干燥综合征规范化诊断的进程。</td>   <td>1.一种唇腺病理智能分析方法,其特征在于,包括如下步骤：S1.构建第一深度神经网络,用于逐一测量唇腺数字病理切片中各唇腺组织面积(mm～(2)),并将各唇腺组织面积相加,得唇腺组织总面积；S2.构建第二深度神经网络和第三深度神经网络,用于识别淋巴细胞密集区域,并统计测量唇腺组织中淋巴细胞灶数量,得淋巴细胞灶数量；所述淋巴细胞灶的定义为：超过50个淋巴细胞的聚集定义为淋巴细胞灶；S3.利用唇腺组织总面积和淋巴细胞灶数量的数据,计算出灶性指数；灶性指数计算公式为：灶性指数＝淋巴细胞灶数量÷唇腺组织总面积(mm～(2))×4；S4.根据灶性指数判断唇腺数字病理切片是否为干燥综合征灶性淋巴细胞性唾液腺炎；判断标准为：灶性指数≥1为符合干燥综合征灶性淋巴细胞性唾液腺炎,灶性指数&lt;1则不符合干燥综合征灶性淋巴细胞性唾液腺炎。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         涂新军;              唐榆森;              吴海鸥;                   陈晓宏       </td>   <td>中山大学</td>   <td>一种基于避咸蓄淡的城市供水分析方法及装置</td>   <td>广东省</td>   <td>CN113723791A</td>   <td>2021-11-30</td>   <td>本发明公开了一种基于避咸蓄淡的城市供水分析方法及装置,其方法包括：获取目标区域的组合数据、取水口的日均含氯度和取水口的含氯度日超标时数；其中,组合数据包括典型风、潮汐和上游来水过程数据；建立日均含氯度与组合数据的重要影响因子的第一映射关系,并根据第一映射关系得到取水口的含氯度预测数据；建立日均含氯度与含氯度日超标时数的第二映射关系,根据第二映射关系以及含氯度预测数据得到取水口的含氯度超标时数预测数据；基于含氯度超标时数预测数据,结合当地取水口取水能力和水库调蓄能力及供蓄过程,计算得到城市水资源供需平衡情况,以及供水分析结果。本实施例能够有效提高供水分析结果的可靠性和准确性。</td>   <td>1.一种基于避咸蓄淡的城市供水分析方法,其特征在于,包括：获取目标区域的组合数据、取水口的日均含氯度以及取水口的含氯度日超标时数；其中,所述组合数据包括典型风、潮汐和上游来水过程数据；建立所述日均含氯度与所述组合数据的重要影响因子的第一映射关系,并根据所述第一映射关系得到所述取水口的含氯度预测数据,其中,所述重要影响因子包括风力因子、潮汐因子和径流因子；建立所述日均含氯度与所述含氯度日超标时数的第二映射关系,根据所述第二映射关系以及所述含氯度预测数据得到所述取水口的含氯度超标时数预测数据；基于所述含氯度超标时数预测数据、取水口取水能力、当地水库兴利库容计算得到城市水资源供需平衡情况,并基于所述城市水资源供需平衡情况对目标区域进行避咸蓄淡供水,在城市取水规模满足城市每日需水量时,将多余水量存储至水库中,在所述城市取水规模不满足城市每日需求量,通过水库补给供水,并根据所述城市水资源供需平衡情况以及供水情况计算得到供水分析结果。</td>   <td>G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   黄日聪       </td>   <td>中山大学</td>   <td>用于自监督单目深度估计的自提升学习方法、装置及设备</td>   <td>广东省</td>   <td>CN113724155A</td>   <td>2021-11-30</td>   <td>本发明公开了用于自监督单目深度估计的自提升学习方法、装置及设备,本发明通过不断地迭代使得用于监督网络训练的伪标签中的噪声数据得到有效剔除,从而训练得到一个收敛的深度网络,进一步利用了深度网络对噪声数据的去噪能力,使得深度网络可以在其本身通过自监督方法产生的带有噪声的伪标签中进一步提升自我的性能,且与现有的自监督训练方法相结合构成用于自监督单目深度估计的自提升学习方法,从而能够进一步提升网络的输出性能。</td>   <td>1.一种用于自监督单目深度估计的自提升学习方法,其特征在于,包括：S1：将训练数据集输入到已训练好的深度网络中,输出相应的第一深度结果,根据所述第一深度结果生成伪标签；S2：使用当前的伪标签对目标深度网络进行监督训练,并将所述训练数据集输入到训练好的目标深度网络中,输出相应的第二深度结果；S3：根据当前输出的第二深度结果作为新的伪标签,重复步骤S2,直至所述目标深度网络收敛。</td>   <td>G06T5/00;G06T7/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张亚慧;              伍贵富;              宋代远;              杨迪朗;              张晓东;              陈怡锡;              麦周明;              陈子奇;                   魏文斌       </td>   <td>中山大学附属第八医院(深圳福田)</td>   <td>一种血流频谱信号分类方法及系统</td>   <td>广东省</td>   <td>CN113724208A</td>   <td>2021-11-30</td>   <td>本发明公开了一种血流频谱信号分类方法及系统,该方法包括：S1、采集动脉血管超声图像并提取动脉血流频谱变化曲线；S2、根据动脉血流频谱变化曲线建立血流速度频谱的ARX传递函数；S3、对血流速度频谱的ARX传递函数进行拟合分析,得到传递函数特征；S4、采用SVM分类器对传递函数特征进行处理,完成血流频谱信号分类。该系统包括：频谱曲线提取模块、传递函数构建模块、特征计算模块和分类模块。通过使用本发明,实现对信号的准确分类。本发明作为一种血流频谱信号分类方法及系统,可广泛应用于信号分类领域。</td>   <td>1.一种血流频谱信号分类方法,其特征在于,包括以下步骤：S1、采集动脉血管超声图像并提取动脉血流频谱变化曲线；S2、根据动脉血流频谱变化曲线建立血流速度频谱的ARX传递函数；S3、对血流速度频谱的ARX传递函数进行拟合分析,得到传递函数特征；S4、采用SVM分类器对传递函数特征进行处理,完成血流频谱信号分类。</td>   <td>G06T7/00;G06T7/13;G06T5/30;G06K9/62;A61B8/08;A61B8/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金舒原;                   肖睿智       </td>   <td>中山大学</td>   <td>面向异常检测的云虚拟机生命周期状态依赖关系提取方法</td>   <td>广东省</td>   <td>CN113703916A</td>   <td>2021-11-26</td>   <td>本发明公开了一种面向异常检测的云虚拟机生命周期状态依赖关系提取方法,包括获取云虚拟机实例日志；基于每种改变云虚拟机实例生命周期状态的操作产生的对应日志,构造操作自动机；将云虚拟机实例日志输入操作自动机进行匹配,识别云虚拟机实例的运行状态变化；根据云虚拟机实例的运行状态提取云虚拟机实例生命周期状态依赖关系序列；基于云虚拟机实例生命周期状态依赖关系序列实时检测云虚拟机实例的运行状态。本发明能够提取出生命周期状态依赖关系并用于后续的异常检测。本发明可广泛应用于云计算安全领域。</td>   <td>1.面向异常检测的云虚拟机生命周期状态依赖关系提取方法,其特征在于,包括以下步骤：获取云虚拟机实例日志；基于每种改变云虚拟机实例生命周期状态的操作产生的对应日志,构造操作自动机；将云虚拟机实例日志输入操作自动机进行匹配,识别云虚拟机实例的运行状态变化；根据云虚拟机实例的运行状态提取云虚拟机实例生命周期状态依赖关系序列；基于云虚拟机实例生命周期状态依赖关系序列实时检测云虚拟机实例的运行状态。</td>   <td>G06F9/455;G06F9/48</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   张权       </td>   <td>中山大学</td>   <td>一种基于多模态人脸训练的单模态人脸活体检测方法</td>   <td>广东省</td>   <td>CN113705400A</td>   <td>2021-11-26</td>   <td>本发明公开了一种基于多模态人脸训练的单模态人脸活体检测方法,包括：获取输入数据并基于输入数据训练预构建的生成对抗网络,得到训练完成的生成对抗网络,所述预构建的生成对抗网络包括生成器和判别器；基于训练完成的生成对抗网络合成数据集并训练类多模态人脸活体检测模型,得到训练完成的类多模态人脸活体检测模型；获取单模态待测图像；基于生成对抗网络将单模态待测图像扩展为多模态人脸图像,并输入至练完成的多模态人脸活体检测模型进行判别。本发明提高传统单模态人脸活体检测模型性能的同时,还降低了实际场景下的硬件成本。本发明作为一种基于多模态人脸训练的单模态人脸活体检测方法,可广泛应用于计算机视觉领域。</td>   <td>1.一种基于多模态人脸训练的单模态人脸活体检测方法,其特征在于,包括以下步骤：S1、获取输入数据并基于输入数据训练预构建的生成对抗网络,得到训练完成的生成对抗网络,所述预构建的生成对抗网络包括生成器和判别器；S2、基于训练完成的生成对抗网络合成数据集并训练类多模态人脸活体检测模型,得到训练完成的类多模态人脸活体检测模型；S3、获取单模态待测图像；S4、基于生成对抗网络将单模态待测图像扩展为多模态人脸图像,并输入至练完成的多模态人脸活体检测模型进行判别,得到检测结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢晓华;              彭其阳;              杨凌霄;              赖剑煌;                   冯展祥       </td>   <td>中山大学</td>   <td>基于弱监督和度量学习的行人属性识别方法</td>   <td>广东省</td>   <td>CN113705439A</td>   <td>2021-11-26</td>   <td>本发明公开了一种基于弱监督和度量学习的行人属性识别方法,包括：获取原始数据集；基于原始数据集中的属性标签信息训练属性感兴趣区域定位网络,得到训练完成的属性感兴趣区域定位网络；以训练完成的属性感兴趣区域定位网络的参数作为行人属性识别网络预训练参数,基于原始数据集对行人属性识别网络进行训练,得到训练完成的属性识别网络；输入待测图像并基于训练完成的属性识别网络进行属性识别,得到属性识别结果。本发明在行人属性识别上具备较好的性能。本发明可广泛应用于图像属性识别领域。</td>   <td>1.基于弱监督和度量学习的行人属性识别方法,其特征在于,包括以下步骤：获取原始数据集；基于原始数据集中的属性标签信息训练属性感兴趣区域定位网络,得到训练完成的属性感兴趣区域定位网络；以训练完成的属性感兴趣区域定位网络的参数作为行人属性识别网络预训练参数,基于原始数据集对行人属性识别网络进行训练,得到训练完成的属性识别网络；输入待测图像并基于训练完成的属性识别网络进行属性识别,得到属性识别结果。</td>   <td>G06K9/00;G06K9/32;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              陈凯鹏;                   王国倩       </td>   <td>中山大学</td>   <td>一种基于深度学习的车牌识别方法</td>   <td>广东省</td>   <td>CN113705577A</td>   <td>2021-11-26</td>   <td>本发明提供一种基于深度学习的车牌识别方法,该方法引入了车牌跟踪算法,确保车辆不会重复进行车牌识别,并在特定区域进行车牌图像采集,提高了获取车牌图像的清晰度,同时能实现对车流量的统计以及车辆信息记录等功能；在进行车牌识别的过程中,如发现车牌运动模糊或者拍摄角度不好的情况下,可反馈至车辆跟踪和检测模块,进行重复检测,提高了车牌识别的准确率；同时,采用了WPOD-NET车牌定位和校正网络,融合了车牌定位和校正处理,采用了端到端的车牌识别方法,融合了字符分割和字符识别处理,提高了车牌识别程序的速度。</td>   <td>1.一种基于深度学习的车牌识别方法,其特征在于,包括以下步骤：S1：车牌图像采集以及图像预处理；S2：车辆检测与车辆跟踪；S3：车牌检测与车牌校正；S4：车牌识别。</td>   <td>G06K9/36;G06K9/32;G06K9/34;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡浚楠;                   陶钧       </td>   <td>中山大学</td>   <td>一种基于属性的文物层次分类方法、系统及装置</td>   <td>广东省</td>   <td>CN113705642A</td>   <td>2021-11-26</td>   <td>本发明公开了一种基于属性的文物层次分类方法、系统及装置,该方法包括：根据指定特征对预设节点内的文物进行划分,得到细节图；根据文物图片计算文物相似性,得到相似性矩阵；根据相似性矩阵对细节图内的文物进行排序,得到排序后细节图；基于重要性度量方法对排序后细节图进行处理,确定文物布局,得到分类图。该系统包括：特征划分模块、相似性矩阵模块、排序模块和布局模块。通过使用本发明,可清晰呈现大规模文物的数据,有助于研究和比较文物的不同特征。本发明作为一种基于属性的文物层次分类方法、系统及装置,可广泛应用于分类领域。</td>   <td>1.一种基于属性的文物层次分类方法,其特征在于,包括以下步骤：S1、根据指定特征对预设节点内的文物进行划分,得到细节图；S2、根据文物图片计算文物相似性,得到相似性矩阵；S3、根据相似性矩阵对细节图内的文物进行排序,得到排序后细节图；S4、基于重要性度量方法对排序后细节图进行处理,确定文物布局,得到分类图。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈俊周;              赵楠;                   韦艳宏       </td>   <td>中山大学</td>   <td>一种斑马鱼荧光图像的分割方法及装置</td>   <td>广东省</td>   <td>CN113706570A</td>   <td>2021-11-26</td>   <td>本发明公开了一种斑马鱼荧光图像的分割方法及装置,所述方法包括：先获取多通道的斑马鱼荧光图像；再将多通道斑马鱼荧光图像输入至斑马鱼血管分割模型中,以使斑马鱼血管分割模型进行分割最终输出分割结果。其中,斑马鱼血管分割模型用于根据ECA注意力机制对多通道斑马鱼荧光图像进行图像增强处理后,进行降维处理并生成单通道的斑马鱼荧光图像,继而根据单通道的斑马鱼荧光图像进行分割。采用本发明实施例能提高对斑马鱼荧光图像的分割精度。</td>   <td>1.一种斑马鱼荧光图像的分割方法,其特征在于,包括：获取多通道的斑马鱼荧光图像；将所述多通道斑马鱼荧光图像输入至斑马鱼血管分割模型中,以使所述斑马鱼血管分割模型进行分割最终输出分割结果；其中,所述斑马鱼血管分割模型用于根据ECA注意力机制对所述多通道斑马鱼荧光图像进行图像增强处理后,进行降维处理并生成单通道的斑马鱼荧光图像,继而根据所述单通道的斑马鱼荧光图像进行分割。</td>   <td>G06T7/174;G06N3/08;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴维刚;                   占聪聪       </td>   <td>中山大学</td>   <td>一种用于联邦学习的优化聚类方法</td>   <td>广东省</td>   <td>CN113673572A</td>   <td>2021-11-19</td>   <td>本发明提供一种用于联邦学习的优化聚类方法,该方法通过计算各个节点的样本类分数向量,并且按样本类别求平均得到一个向量矩阵；该向量矩阵的维度只取决于样本类别的大小,不依赖于模型大小或者样本数量,然后把该向量矩阵作为k-means聚类的参数进行聚类；通过使用每个节点的所有样本类分数向量求得样本的平均类分数向量矩阵作为k-means聚类的参数,不仅聚类效果不会变差,而且聚类时间复杂度很小,节省计算开销。</td>   <td>1.一种用于联邦学习的优化聚类方法,其特征在于,包括以下步骤：S1：服务器随机初始化一个全局模型w,并下发到各个节点c(i)；S2：各个节点使用本地数据集迭代n轮得到更新后的本地模型w(i)；S3：每个节点各自使用本地数据集在本地模型w(i)上面进行一次预测得到样本的类分数向量；S4：然后按照样本类别0-9,对上面的样本类分数按类别进行平均；S5：将步骤S4中得到的平均类分数向量组成一个向量矩阵,并上传服务器；S6：服务器对所有节点上传的向量矩阵使用k-means聚成10类,并从每个类中随机挑选1个节点作为代表参与本次聚合；S7：选中的节点上传本地训练的模型w(i),服务器使用聚合算法得到一个更新的全局模型w’,并下发至各个节点c(i)；S8：返回步骤S2,直到训练k轮。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周达敏;              陈荣军;              嵇志辉;              谢舜道;              李小敏;                   朱雄泳       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>一种圆形寻像图形二维码及其生成和解译方法</td>   <td>广东省</td>   <td>CN108256609B</td>   <td>2021-11-16</td>   <td>本发明公开了一种圆形寻像图形二维码及其生成和解译方法,该二维码包括由三个黑色大圆组成的寻像图形和由黑色小圆组成的矩阵,所述三个黑色大圆圆心组成一个等腰直角三角形。其生成方法步骤为：将数据流转化为字节流,进行编码,确定二维码大小,布置寻像图形,转化为矩阵,布置矩阵,生成二维码图像。其解译方法步骤为：扫描二维码图片,进行处理,寻找寻像图形,对二维码进行校正,转化为0/1矩阵,将矩阵解码,译为数据信息,完成解译。寻像图形和矩阵都采用圆形,结构简单,抗模糊性好,易识别,可以使用霍夫变换算法进行检测,提高其解码速度。采用中短码长的LDPC码编码,其纠错性能比RS算法更高。</td>   <td>1.一种圆形寻像图形二维码的生成方法,其特征在于：所述生成方法包括：S1:将数据流转化为一个字节流,然后采用中短码长的LDPC码编码的方法进行编码；S2:根据编码后数据的位数、版本信息确定二维码的大小；S3:布置寻像图形,寻像图形为三个黑色大圆,所述三个黑色大圆圆心组成一个等腰直角三角形；S4:将字节流编码转化为0/1矩阵,采用黑色小圆布置二维码矩阵；S5:生成圆形寻像图形二维码图像,所述圆形寻像图形二维码包括由所述三个黑色大圆组成的寻像图形和由所述黑色小圆组成的矩阵,所述黑色大圆和黑色小圆直径比为4:1,所述矩阵是二维码的信息点,有黑色小圆的位置代表1,无黑色小圆位置代表0,信息点相邻间距为1：1,所述黑色大圆内嵌任意形状的商标。</td>   <td>G06K19/06;G06K7/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   黄信朝       </td>   <td>中山大学</td>   <td>一种基于LIOP特征与块匹配的图像区域复制篡改检测方法</td>   <td>广东省</td>   <td>CN108335290B</td>   <td>2021-11-12</td>   <td>本发明主要针对数字图像的取证领域,更具体地,涉及一种基于LIOP特征与块匹配的图像区域复制篡改检测方法。本发明将基于特征点及基于分块两类方法相结合,融合两类方法的优势；首先选取LIOP特征作为图像特征提取算法,相比其他特征,能够更好地应对旋转、缩放、JPEG压缩、添加噪声等情况；特征匹配之后,使用新的匹配对表达模型对匹配对进行表达并筛选,去除冗余的匹配对,使得精确度提高,计算复杂度降低。根据匹配对进行图像切割并分块提取特征后,使用了块匹配算法对篡改进行匹配,最后进行精确定位；本算法检测精度高,同时对各种类型图像复制粘贴篡改如旋转、缩放、加噪声、压缩等,都有着很好的效果。</td>   <td>1.一种基于LIOP特征与块匹配的图像区域复制篡改检测方法,其特征在于,包括以下步骤：S1.检测DoG关键点：对于待检测的图像,构造DoG尺度空间,在DoG尺度空间中找寻极值点作为关键点,并把关键点定位于图像上；S2.提取LIOP特征向量：把步骤S1获取的每个关键点区域规范化成圆形区域,根据像素值将区域分割为B个子区间,每个子区间的所有像素的像素值都在相应区间段之内,区域内每个像素的描述子通过该像素周围采样点的灰度信息来计算得到,通过将局部顺序区间内所有像素点的描述子串联起来构成LIOP特征向量；S3.匹配特征：对于步骤S2中提取出来的每个特征向量,计算其与其它所有特征向量之间的欧式距离,并按照从小到大排序；计算最近邻d-(1)和次近邻d-(2)之间的比值,如果比值小于ε,其中∈的取值可根据实际情况设定为0.5至0.7之间的数值,则认为距离为d-(1)的两个特征匹配,构成匹配对；S4.转换匹配对模型并过滤：在匹配对的两个特征点中,确定其中的一个特征点为起始点(x-(1),y-(1)),对应特征点为终点(x-(2),y-(2)),将匹配对表达为四维空间M∈{x-(1),y-(1),x-(2)-x-(1),y-(2)-y-(1)|x-(1),x-(2),y-(1),y-(2)∈R}中的点,并确保相邻的匹配对使用相同一侧的特征点作为起始点,将四维空间M的每一维都划分为相同大小的区间,大小取为μ,则各维度上不同区间的组合将四维空间M划分为相同大小的矩形四维子空间集,对于落在同一子空间的点的数量σ,若σ&gt;1,则随机选择其中的一个点进行保留,去除掉其他的点；S5.切割图像并分块提取Zernike特征：若存在有效的匹配对,则对于每一个匹配对,以匹配对的两个特征点坐标为中心点,切割出两个α×α大小的矩形图像,以b×b为窗口,其中b小于α,以1为步进,遍历图像并将分割出的图像有重叠的进行分块,对每个分块,计算其5阶Zernike矩系数,生成一个12维特征向量作为该分块的特征；S6.进行块匹配：以Zernike矩系数为准,对切割出的两个对应的图像块A和B进行匹配,首先随机初始化匹配,A中的点随机匹配到B中的点,然后通过迭代的传播以及随机搜索对匹配进行不断优化,每一次迭代方向为从左上到右下以及从右下到左上交替进行,最后获得A到B的匹配结果,通过相同的方式获得B到A的匹配,最终获得两个不同方向的块匹配结果；S7.定位复制区域：以每个像素为中心,m×m为大小,计算矩阵方差D-(e),对于矩阵方差D-(e)小于Δ的像素,则认为是属于待选篡改区域；对两个块匹配结果,可分别获得A中的待选篡改区域Γ-(A)以及B中的区域Γ-(B),然后根据块匹配算法的结果,将待选篡改区域的点一一映射到对应区域,得到B中的Γ′-(A)以及A中的Γ′-(B),最后定位区域为Γ-(A)∩Γ′-(B)以及Γ-(B)∩Γ′-(A),将所有匹配对的结果进行整合,并应用形态学操作以滤除杂乱点,生成最终的检测结果图。</td>   <td>G06T7/00;G06T7/11;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小丹;              龙衍鑫;                   林冰倩       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于对抗对比学习的导航系统训练方法、装置及导航系统</td>   <td>广东省</td>   <td>CN113627249A</td>   <td>2021-11-09</td>   <td>本发明公开了一种基于对抗对比学习的导航系统训练方法、装置及导航系统,所述方法包括：在智能体移动时采集智能体处于不同模态下的模态信息,将所述模态信息编码成特征向量；当确定智能体停止移动时,根据所述特征向量获取隐藏状态向量；对所述隐藏状态向量进行轨迹编码得到轨迹编码数据；调用预设的障碍场景轨迹数据和预设的无障碍场景轨迹数据对所述轨迹编码数据进行对抗对比学习的训练模型,得到导航训练系统。本发明可以通过对抗对比学习和训练,优化智能体长期计划能力,可以大大提高导航器在障碍条件下的鲁棒性,并提高导航的准确性。</td>   <td>1.一种基于对抗对比学习的导航系统训练方法,其特征在于,所述方法包括：在智能体移动时采集智能体处于不同模态下的模态信息,将所述模态信息编码成特征向量；当确定智能体停止移动时,根据所述特征向量获取隐藏状态向量；对所述隐藏状态向量进行轨迹编码得到轨迹编码数据；调用预设的障碍场景轨迹数据和预设的无障碍场景轨迹数据对所述轨迹编码数据进行对抗对比学习的训练模型,得到导航训练系统,其中,所述预设的障碍场景轨迹数据为智能体在障碍条件的导航轨迹数据,所述预设的无障碍场景轨迹数据为智能体在无障碍条件的导航轨迹数据。</td>   <td>G06K9/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张海;              张俊;                   朱荣       </td>   <td>中山大学新华学院</td>   <td>一种人工智能用人脸识别系统</td>   <td>广东省</td>   <td>CN214670662U</td>   <td>2021-11-09</td>   <td>本实用新型提供一种人工智能用人脸识别系统,涉及人脸识别技术领域。所述人工智能用人脸识别系统包括：立柱,所述立柱固定连接有开口向下的防护罩；人脸识别用摄像头,所述人脸识别用摄像头通过弹性连接机构弹性连接在防护罩内；地面驱动机构,所述地面驱动机构与立柱连接,且地面驱动机构用于驱动人脸识别用摄像头运动。本实用新型提供的人工智能用人脸识别系统具有使用寿命长的优点。</td>   <td>1.一种人工智能用人脸识别系统,其特征在于,包括：立柱(3),所述立柱(3)固定连接有开口向下的防护罩(1)；人脸识别用摄像头(6),所述人脸识别用摄像头(6)通过弹性连接机构(7)弹性连接在防护罩(1)内；地面驱动机构(5),所述地面驱动机构(5)与立柱(3)连接,且地面驱动机构(5)用于驱动人脸识别用摄像头(6)运动。</td>   <td>G06K9/00;G03B17/56;A61L2/18;F16M11/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;              陈家亮;                   方艳梅       </td>   <td>中山大学</td>   <td>一种基于局部纹理模式的二值图像隐写分析方法</td>   <td>广东省</td>   <td>CN108460715B</td>   <td>2021-11-05</td>   <td>本发明涉及多媒体信息安全以及图像信息隐写技术领域,更具体地,涉及一种基于局部纹理模式的二值图像隐写分析方法。包括以下步骤：S1.构建十三宫格像素点块模板；S2.利用块模板扫描图像得到二值图像局部纹理模式；S3.统计每个二值图像局部纹理模式出现的频率；S4.将局部纹理模式出现的频率级联形成特征向量,利用集成分类器进行学习分类。本发明利用集成分类器进行学习分类,所提取的二值图像分析特征具有较高的特征维度,并且能够很好地描述图像的纹理,集成分类器能够很好地利用所提取的高维特征进行学习分类,能够很好地检测出待检测图像是否包含隐秘信息,具有较强可靠性。</td>   <td>1.一种基于局部纹理模式的二值图像隐写分析方法,其特征在于,包括以下步骤：S1.构建十三宫格像素点块模板；具体包括：构造一个5×5大小的十三宫格像素点块模板,其中每一宫格是一个小的正方形,表示一个像素,十三个宫格构成一个二值图像扫描窗口,其中包含3×3大小的九宫格,其余四个宫格分别位于九宫格的正上方,正下方,正左方和正右方；对扫描窗口中的十三宫格按照一定的顺序进行编号：0,1,2……12,其中标号为0的宫格位于扫描窗口的中心位置S2.利用块模板扫描图像得到二值图像局部纹理模式；S3.统计每个二值图像局部纹理模式出现的频率；S4.将局部纹理模式出现的频率级联形成特征向量,利用集成分类器进行学习分类。</td>   <td>G06T1/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑培嘉;              郭剑艇;                   黄继武       </td>   <td>中山大学</td>   <td>基于H.264/AVC加密视频的运动异常检测方法</td>   <td>广东省</td>   <td>CN108629237B</td>   <td>2021-11-05</td>   <td>本发明提供一种基于H.264/AVC加密视频的运动异常检测方法,本发明通过对加密视频进行信息提取,对提取的信息进行特征计算,再利用训练集提取的特征,训练模型,最后,利用训练好的模型,进行异常检测。该方法采用直接在压缩码流上处理的方法使得算法效率更高,更适应于实际应用场景,同时根据加密码流结构的特性进行信息提取,为应对加密视频下异常运动的特点,重新设计了特征提取方法,使得异常检测能够在加密视频上实现,利用物理世界物体运动的特性,减少加密视频检测结果的离散问题,进一步提高了检测的准确率,从而可以为云监控系统、云存储系统等应用提供帮助。</td>   <td>1.一种基于H.264/AVC加密视频的运动异常检测方法,其特征在于,包括以下步骤：S1：对加密视频进行信息提取；S2：对提取的信息进行特征计算；S3：利用训练集提取的特征,训练模型；S4：利用训练好的模型,进行异常检测；所述步骤S1的具体过程如下：S11：根据码流结构中的宏块划分,获取每个宏块比特量的大小,记为s-(ij)；S12：根据码流结构中的子块划分,获取每个宏块划分为子宏块的方式,将对应的分块级别记为p-(ij)；S13：对携带运动向量残差的宏块,根据码字长度估计其大小,公式为：                  其中,L为运动向量残差的码字长度,当L＝1时,所述步骤S2的具体过程如下：S21：对提取出的信息,进行时域上的中值滤波,令γ为视频编码的帧率,那么滤波的窗口大小为γ/5；S22：对每一类信息,按帧进行整合,得到其在每一帧的大小,其公式为                                                      其中,S-(i)表示第i帧比特量,P-(i)表示第i帧分块级别,M-(i)表示第i帧运动向量能量,f-(i)表示第i帧中所有宏块的地址；S23：对每一类信息,计算其在时域窗口内的方差,其公式为Sv-(i)＝var{[S-(i-5),S-(i-4),…,S-(i+5)]}Pv-(i)＝var{[P-(i-5),P-(i-4),…,P-(i+5)]}Mv-(i)＝var{[M-(i-5),M-(i-4),…,M-(i+5)]}其中,var{}表示计算方差,Sv-(i)表示第i帧比特量在当前时域窗口内的方差,Pv-(i)表示第i帧分块级别在当前时域窗口内的方差,Mv-(i)表示第i帧运动向量能量在当前时域窗口内的方差；S24：对每一类信息,计算其在每一帧中,最大的前10％的值之和,其公式为：                                                      其中,fst-(i),fpt-(i),fmt-(i)分别为第i帧最大的前10％的s,p,v的地址,Ss-(i)表示i帧最大的前10％宏块比特量之和,Ps-(i)最大的前10％宏块分块级别之和,Ms-(i)最大的前10％宏块运动向量能量之和；S25：得到用于训练的特征集合[S,P,M],其中S＝[S-(i),Sv-(i),Ss-(i)]-(i∈v)P＝[P-(i),Pv-(i),Ps-(i)]-(i∈v)M＝[M-(i),Mv-(i),Ms-(i)]-(i∈v)S表示比特量相关特征集合,P表示分块级别相关特征集合,M表示运动向量能量相关特征集合,v表示视频中所有的帧的集合。</td>   <td>G06K9/00;G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         古博;              束嘉乐;                   姜善成       </td>   <td>中山大学</td>   <td>基于时空注意力机制的电力负荷预测方法、装置及介质</td>   <td>广东省</td>   <td>CN113610277A</td>   <td>2021-11-05</td>   <td>本发明公开了一种基于时空注意力机制的电力负荷预测方法、装置及存储介质,该方法包括获取电力负荷数据；然后利用训练好的图时空注意力网络模型接收电力负荷数据并进行处理；最后获取训练好的图时空注意力网络模型输出的预测结果；本发明通过训练好的图时空注意力网络模型进行预测,不仅可以捕捉时间相关性,同时还可以捕捉动态空间相关性,从而能够显著提高电力负荷的预测精度。本发明可广泛应用于电力负荷预测技术领域。</td>   <td>1.一种基于时空注意力机制的电力负荷预测方法,其特征在于,包括：获取电力负荷数据；利用训练好的图时空注意力网络模型接收所述电力负荷数据并进行处理；获取所述训练好的图时空注意力网络模型输出的预测结果。</td>   <td>G06Q10/04;G06Q50/06;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐伟嘉;              郭月;              刘永红;                   丁卉       </td>   <td>中山大学;广东旭诚科技有限公司</td>   <td>大气复合污染观测数据的质量及共享效果评价方法与系统</td>   <td>广东省</td>   <td>CN113610383A</td>   <td>2021-11-05</td>   <td>本发明涉及数据评价与共享效果或质量领域,具体涉及一种大气复合污染观测数据的质量及共享效果评价方法,通过提取大气复合污染观测数据质量和共享效果评估指标,在明确观测数据质量评估指标体系之间的相互依存及影响的基础上,根据大气复合污染观测数据的特点和实际应用,经过对专家进行调研,确定大气复合污染观测数据质量指标的评标标准；共建设4个一级指标以及监测组分种类、闭合实验、项目类型、访问量等13项二级指标。本发明方法能够基于现有数据共享平台定性、定量地评估大气复合观测数据的质量水平和共享效果,并实现在线更新指标体系及指标权重,供用户根据实际情况选用,以实现评价体系和综合得分函数按照实际需要在线更新。</td>   <td>1.一种大气复合污染观测数据的质量及共享效果评价方法,其特征在于,包括如下步骤：S1.建立大气复合污染观测数据质量和共享效果评估体系,自上而下包括由被评估的大气复合污染观测数据质量形成的目标层、由大气复合污染观测数据质量评估一级指标形成的准则层、由大气复合污染观测数据质量评估二级指标形成的指标层；S2.通过所述目标层、所述准则层、所述指标层两两比较下层元素对于上层元素的相对重要性建立判断矩阵；S3.计算所述判断矩阵的各层次单排序数值,获得所述指标层针对所述准则层的相对权重、所述准则层针对所述目标层的相对权重,即获得所述判断矩阵的权重向量；S4.根据所述权重向量计算所述判断矩阵的最大特征值,根据所述最大特征值判定所述判断矩阵的一致性,若所述一致性不好,则重复执行S2,修改所述判断矩阵；若所述一致性良好或较好,则执行S5；S5.根据所述相对权重计算所述目标层评分,判断所述被评估的大气复合污染观测数据质量。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>              蒋弥       </td>   <td>中山大学</td>   <td>一种时序SAR图形的变化检测方法及装置</td>   <td>广东省</td>   <td>CN113610781A</td>   <td>2021-11-05</td>   <td>本发明公开了一种时序SAR图形的变化检测方法及装置,所述方法包括：获取SAR数据集,对所述SAR数据集进行取模与估计操作得到序列数据；对所述强度序列进行假设检验得到变化类样本,以及对所述相干性序列进行干涉对筛选得到稳定类样本；分别拟合所述变化类样本的变化特征与所述稳定类样本的稳定特征,得到条件分布参数；获取预设的滤波系数图,以所述条件分布参数为似然项并利用预设的图割算法将预设的滤波系数图进行阈值化,得到变化检测结果。本发明可以将时序SAR决策阈值转变为二分类并利用二分类进行变化检测,不但顾及变化的空间关联性,也避免了复杂的统计建模和聚类过程,缩短处理时间,区分数据中的微弱变化和噪声,以提高决策阈值的准确率。</td>   <td>1.一种时序SAR图形的变化检测方法,其特征在于,所述方法包括：获取SAR数据集,对所述SAR数据集进行取模与估计操作得到序列数据,其中,所述序列数据包括强度序列与相干性序列；对所述强度序列进行假设检验得到变化类样本,以及对所述相干性序列进行干涉对筛选得到稳定类样本；分别拟合所述变化类样本的变化特征与所述稳定类样本的稳定特征,得到条件分布参数；获取预设的滤波系数图,以所述条件分布参数为似然项并利用预设的图割算法将预设的滤波系数图进行阈值化,得到变化检测结果。</td>   <td>G06T7/00;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>              蒋弥       </td>   <td>中山大学</td>   <td>基于时序SAR强度图像变异系数的变化检测方法及装置</td>   <td>广东省</td>   <td>CN113610783A</td>   <td>2021-11-05</td>   <td>本发明公开了一种基于时序SAR强度图像变异系数的变化检测方法及装置,所述方法包括：获取待检测区域在预设时长内的若干个时间节点的SAR强度图像,得到时序SAR强度图像序列；根据时序SAR强度图像序列中每一空间像素点的强度时序样本,计算每一空间像素点的变异系数,继而根据每一空间像素点的变异系数,生成变异系数图；根据时序SAR强度图像序列,提取每一空间像素点所对应的统计同分布像素样本；根据每一空间像素点的统计同分布像素样本对变异系数图进行空间滤波,获得已滤波变异系数图；对已滤波变异系数图进行阈值分割,获得待检测区域的变化检测结果。通过实施本发明实施例能够提高变化检测的准确性。</td>   <td>1.一种基于时序SAR强度图像变异系数的变化检测方法,其特征在于,包括：获取待检测区域在预设时长内的若干个时间节点的SAR强度图像,得到时序SAR强度图像序列；根据所述时序SAR强度图像序列中每一空间像素点的强度时序样本,计算每一空间像素点的变异系数,继而根据每一所述空间像素点的变异系数,生成变异系数图；根据所述时序SAR强度图像序列,提取每一所述空间像素点所对应的统计同分布像素样本；根据每一所述空间像素点的统计同分布像素样本对所述变异系数图进行空间滤波,获得已滤波变异系数图；对所述已滤波变异系数图进行阈值分割,获得所述待检测区域的变化检测结果。</td>   <td>G06T7/00;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄凯;              宋日辉;              谭志东;                   凌晔华       </td>   <td>中山大学</td>   <td>一种用于单目内窥镜手术中的多基线融合的深度估计方法</td>   <td>广东省</td>   <td>CN113610908A</td>   <td>2021-11-05</td>   <td>本发明属于深度估计领域和医学图像处理技术领域,更具体地,涉及一种用于单目内窥镜手术中的多基线融合的深度估计方法。能够应用到临床中,起到在术中辅助手术的作用。通过水平移动小段距离对当前手术画面获取两张不同视角的照片,可以对组织纹理较少的手术画面估计出较为准确的深度信息。本发明还提出了一种多基线深度图融合的方法,针对不同的深度范围在合适的基线附近选择多个基线,将不同基线得到的深度图进行融合,保证在不同深度范围时都能生成准确的深度图。</td>   <td>1.一种用于单目内窥镜手术中的多基线融合的深度估计方法,其特征在于,包括以下步骤：S1.采集内窥镜拍摄的照片；S2.根据内窥镜的内参矩阵和畸变系数对照片进行校正；S3.对校正后的照片进行深度估计；S4.用基线选取方法选出当前内窥镜画面中物体所处的深度范围下的最优基线；S5.将最优基线附近的几个基线对应的深度图进行融合,得到最终的深度图；S6.根据融合后的深度图在照片中标注出每个物体的深度值；S7.将标注深度后的照片显示在屏幕上,根据照片中的深度信息判断画面中物体的位置。</td>   <td>G06T7/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑华滨;                   潘嵘       </td>   <td>中山大学</td>   <td>一种基于计数聚焦模型的新型文本识别方法</td>   <td>广东省</td>   <td>CN108009539B</td>   <td>2021-11-02</td>   <td>本发明涉及一种基于计数聚焦模型的新型文本识别方法,所述计数聚焦模型包括编码器和解码器,所述识别方法包括以下步骤：S1.采用基于卷积神经网络的编码器对输入图像的高层特征进行抽取,得到高层特征图；S2.基于长短期记忆网络和聚焦机制的解码器从高层特征图中按序解码出从左到右的字符。</td>   <td>1.一种基于计数聚焦模型的文本识别方法,所述计数聚焦模型包括编码器和解码器,其特征在于：所述识别方法包括以下步骤：S1.采用基于卷积神经网络的编码器对输入图像的高层特征进行抽取,得到高层特征图；S2.基于长短期记忆网络和聚焦机制的解码器从高层特征图中按序解码出从左到右的字符,具体如步骤S21～S30所示：S21.将高层特征图沿着横向维度从左到右进行切分,得到W个内容向量v-1,v-2,…,v-W,其中W为高层特征图的宽度；S22.将内容向量序列分别输入至长LSTM模块中,得到对应的W个状态向量s-1,s-2,…,s-W；S23.将状态向量序列输入至全连接层中,并用线性整流函数保证其数值非负,得到W个计数累加标量c-1,c-2,…,c-W；S24.设置一个初始计数标量k-0；S25.按照从左到右的方向,在计数标量上不断叠加步骤S23获得的累加标量,得到W个计数标量,即k-w＝k-{w–1}+c-k,其中1≤w≤W；S26.设置最大解码长度L,代表解码器需要从高层特征图里解码出的字符数目；S27.解码第q个字符,q≤L,将索引q与所有计数标量分别进行比对操作,计算它们的差值的绝对值的反,得到聚焦分数score-w,即：score-w＝-|k-w–q|,1≤w≤W；S28.使用softmax函数对W个聚焦分数进行归一化,得到聚焦权重a-w：a-w＝e～((score-w))/[e～((s-1))+e～((s-2))+…+e～((s-W))]；S29.使用聚焦权重对内容向量进行加权求和,得到第q个字符对应的特征向量o-q：o-q＝a-1*v-1+a-2*v-2+…+a-W*v-W；S30.利用全连接层从o-q预测出第q个字符的概率分布。</td>   <td>G06K9/20;G06K9/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄家明;              吴维刚;              尹烨;                   常红立       </td>   <td>中山大学;腾讯科技(深圳)有限公司</td>   <td>基于双层注意力机制和对抗学习的深度学习时序聚类方法</td>   <td>广东省</td>   <td>CN113591905A</td>   <td>2021-11-02</td>   <td>本发明为克服深度学习模型中存在学习能力不平衡、训练效率低的缺陷,提出一种基于双层注意力机制和对抗学习的深度学习时序聚类方法,包括以下步骤：采集集群中所有容器的时序数据并进行预处理,得到时序数据集；将所述时序数据集输入基于双层注意力机制的自编码器中对时间序列进行降维和重构学习,将所述自编码器输出的隐层低维特征传输至聚类层中进行时序聚类,生成各个类的簇心以及记录样本的分配情况,得到时序聚类结果；所述自编码器将经过重构的低维特征输入基于对抗学习的辅助判别器中,所述辅助判别器通过计算损失函数对所述自编码器进行优化训练。本发明能够加强自编码器学习样本的差异特征的能力,能够有效提高训练效率。</td>   <td>1.基于双层注意力机制和对抗学习的深度学习时序聚类方法,其特征在于,包括以下步骤：采集集群中所有容器的时序数据并进行预处理,得到时序数据集；将所述时序数据集输入基于双层注意力机制的自编码器中对时间序列进行降维和重构学习,将所述自编码器输出的隐层低维特征传输至聚类层中进行时序聚类,生成各个类的簇心以及记录样本的分配情况,得到时序聚类结果；所述自编码器将经过重构的低维特征输入基于对抗学习的辅助判别器中,所述辅助判别器通过计算损失函数对所述自编码器进行优化训练。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨伟志;              衣杨;              赵小蕾;              张海;              曾青青;              刘少江;              黎丹雨;                   王玉娟       </td>   <td>中山大学新华学院</td>   <td>一种网络诈骗号码检测方法、系统、存储介质及终端设备</td>   <td>广东省</td>   <td>CN113591924A</td>   <td>2021-11-02</td>   <td>本申请涉及一种网络诈骗号码检测方法,所述方法包括：首先针对信息诈骗行为设计相应特征并对用户行为日志进行特征提取,以构建原始特征矩阵并进行数据预处理；然后根据数据预处理后原始特征矩阵中正常用户与风险用户比例的不平衡度,采用自调节过采样算法进行少数类样本过采样,重构训练集；接着通过XGBoost模型进行预训练及特征重要性评估和特征筛选；然后对重构后的特征矩阵使用XGBoost和LightGBM模型进行模型训练；最后通过Stacking多模型融合方式提高模型性能,得到二层模型Logistic,完成移动网络风险用户识别模型。本发明能够提高对网络通信中诈骗号码识别的准确度及鲁棒性,满足了实际应用需求。</td>   <td>1.一种网络诈骗号码检测方法,其特征在于,所述方法包括以下步骤：通过自调节过采样算法进行少数类样本的过采样,并将过采样得到的过采样矩阵与特征工程矩阵融合后得到训练特征矩阵；通过所述训练特征矩阵分别对XGBoost模型和LightGBM模型进行训练；将所述XGBoost模型和LightGBM模型的预测结果通过Stacking的方式进行模型融合,以得到Logistic模型；通过所述Logistic模型对通信过程中的网络风险用户进行识别。</td>   <td>G06K9/62;H04M3/22</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              周周艺;              周凡;                   苏卓       </td>   <td>中山大学</td>   <td>一种利用时间因素的个性化服饰搭配推荐方法与系统</td>   <td>广东省</td>   <td>CN113592609A</td>   <td>2021-11-02</td>   <td>本发明公开了一种利用时间因素的个性化服饰搭配推荐方法与系统。包括：收集数据集,构建异构图,学习服饰和用户的特征表示和服饰搭配的一般规则,学习用户对套装的偏好规则,计算个性化搭配评分,对异构图网络进行训练,得到综合服饰搭配匹配度与用户个人偏好的评分模型,最后用户根据该模型获取个性化服饰搭配推荐。本发明构建异构图神经网络,考虑用户的不同交互行为所包含的对服饰的不同的偏好程度,通过融入用户交互行为时间与服饰节点时间,学习时间因素对用户偏好的影响规律,最后通过用户历史记录与服饰信息、用户对单品的偏好学习用户对套装的偏好,建模服饰与用户的特征表示及内在联系,实现个性化服饰搭配推荐方法。</td>   <td>1.一种利用时间因素的个性化服饰搭配推荐方法,其特征在于,所述方法包括：收集数据集,包括服饰数据、用户与服饰单品的历史交互数据和套装数据；通过服饰与用户两种类型的节点及其不同的边联系,组成异构图网络,将所述数据集中的服饰数据与用户数据进行编码,作为异构图网络的节点初始输入,构建元路径,编码交互时间特征,融合时间特征,通过异构图神经网络的节点聚合,学习节点间的潜在联系,得到最终的异构图网络输出结果；学习服饰搭配的一般规则,计算套装搭配分数；学习用户对套装的偏好规则,计算某用户对某套装评价分数；由所述套装搭配分数与所述套装评价分数,计算个性化搭配评分,综合用户对套装的喜爱与套装的通用搭配规律,由所述套装数据和所述服饰数据组成正负训练样本,定义损失函数对所述异构图网络进行训练,得到综合服饰搭配匹配度与用户个人偏好的评分模型；用户利用所述评分模型最终获取个性化服饰搭配推荐。</td>   <td>G06Q30/06;G06Q10/06;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              殷业熙;                   林淑金       </td>   <td>中山大学</td>   <td>点云数据不均匀的三维重建方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113592711A</td>   <td>2021-11-02</td>   <td>本发明公开了一种点云数据不均匀的三维重建方法。包括：对物体扫描得到一个完整的点集数据,并进行法向量归一化等预处理；对于缺失数据人为增加简要的轮廓线条,得到稀疏点集；利用稀疏点集构造埃米特矩阵并求得法向量；法向量和点集数据计算得到插值函数,之后上采样得到最终点云；进行三角形化的操作,得到最终的三维重建模型。本发明还公开了一种点云数据不均匀的三维重建系统、计算机设备及计算机可读存储介质。本发明使用插值法解决了缺失部分的物体表面重建问题,结合人工草图的形状信息补全,可以自由地在模型缺失部分修改,能够很好地结合实际物体的样本点的几何特征与人工添加草图的特征,得到一个较为完整的重建模型。</td>   <td>1.一种点云数据不均匀的三维重建方法,其特征在于,所述方法包括：使用扫描设备对物体做尽可能全视角的扫描,得到空间中一个完整的点集数据；对所述点集数据进行预处理,并保存为PLY数据格式,并对数据格式中的每个点的法向量进行归一化；对于没有扫描到的缺失数据部分人为增加简要的轮廓线条,得到缺失数据的稀疏点集；利用所述缺失数据的稀疏点集构造埃米特矩阵,再利用该矩阵通过最优化的方法求得所述缺失数据的稀疏点集的法向量；通过所述稀疏点集的法向量和所述稀疏点集的数据来计算得到插值函数,再根据该插值函数上采样增加点云的密度使得与完整数据部分的采样点密度一致,得到缺失数据的最终点云；结合扫描得到的点云以及所述缺失数据的最终点云,进行三角形化的操作,得到最终的三维重建模型。</td>   <td>G06T3/40;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              卢林鹏;              周凡;              林淑金;                   林格       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的点云三维重建方法与系统</td>   <td>广东省</td>   <td>CN113593043A</td>   <td>2021-11-02</td>   <td>本发明公开了一种基于生成对抗网络的点云三维重建方法与系统。包括：首先处理等待重建的点云数据,其次搭建生成器模块和判别器模块,然后对生成器和判别器进行多次对抗训练得到训练完成后的生成器,最终训练完成的生成器生成的就是等待重建的点云数据对应的三维模型。本发明以已经拥有的点云数据为基准最终得到相对应的三维模型,能够应用于多种多样的单个物体,并且在多个模型的不同部分的拼接任务中能够生成较为光滑的过度区域,而不会很出现非常突兀的变化,其次损失函数的设计更好地加快网络模型的收敛速度,体现点云数据的三维特性,最终生成的对应三维模型精确度更高。</td>   <td>1.一种基于生成对抗网络的点云三维重建方法,其特征在于,所述方法包括：处理等待重建的点云数据,得到一个包围该等待重建的点云数据的三维网格模型；搭建生成器模块,输入是所述三维网格模型,得到该模型中各个顶点的位移,该位移与所述三维网格模型的顶点坐标相加,得到一个新的三维网格模型,从该新模型中均匀采样一些点,得到生成器生成的点云数据；搭建判别器模块,输入是所述等待重建的点云数据和从所述生成器中生成的点云数据,输出是一个小于1的概率值；对所述判别器和所述生成器进行多次训练优化,得到训练完成的判别器和训练完成的生成器；最终所述训练完成的生成器所生成的就是所述等待重建的点云数据对应的三维模型。</td>   <td>G06T17/20;G06T19/20;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              程露莹       </td>   <td>中山大学南方学院</td>   <td>一种带有预警装置的投资管理风险评估系统</td>   <td>广东省</td>   <td>CN214587002U</td>   <td>2021-11-02</td>   <td>本实用新型公开了一种带有预警装置的投资管理风险评估系统,包括预警箱,所述预警箱内腔底部的中心处固定连接有管体,所述管体的内腔滑动连接有滑板,所述滑板的顶部固定连接有活动柱,所述活动柱的顶部固定连接有承载板,所述滑板的底部均匀固定连接有压簧。本实用新型通过设置预警箱、管体、滑板、活动柱、承载板、压簧、横板、触发板、金属接触板和电池组,能够使风险评估设备移动时,蜂鸣器蜂鸣,从而达到预警的效果,通过设置以上结构,具备风险评估设备在使用时,具有预警装置的优点,解决了原有风险评估设备在使用时,不具有预警装置的问题,从而避免不法分子对风险评估设备进行盗窃,从中牟利。</td>   <td>1.一种带有预警装置的投资管理风险评估系统,包括预警箱(1),其特征在于：所述预警箱(1)内腔底部的中心处固定连接有管体(2),所述管体(2)的内腔滑动连接有滑板(3),所述滑板(3)的顶部固定连接有活动柱(4),所述活动柱(4)的顶部固定连接有承载板(5),所述滑板(3)的底部均匀固定连接有压簧(6),所述压簧(6)的底部与管体(2)的连接处固定连接,所述预警箱(1)的顶部放置有风险评估设备(7),所述承载板(5)的顶部贯穿预警箱(1)且与风险评估设备(7)的连接处紧密贴合,所述活动柱(4)的左侧并位于管体(2)的上方固定连接有横板(8),所述横板(8)顶部的左侧固定安装有触发板(9),所述预警箱(1)内腔的顶部固定安装有与触发板(9)配合使用的金属接触板(10),所述预警箱(1)内腔底部的右侧固定安装有蜂鸣器(11),所述预警箱(1)内腔底部的左侧通过螺丝固定安装有电池组(12)。</td>   <td>G06Q40/06;G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马锦华;              吴发明;                   胡彦旭       </td>   <td>中山大学</td>   <td>一种基于知识迁移和概率校正的少样本目标检测方法</td>   <td>广东省</td>   <td>CN113569940A</td>   <td>2021-10-29</td>   <td>本发明公开了一种基于知识迁移和概率校正的少样本目标检测方法,该方法包括：获取Base类数据集,构建只有少量样本的Novel类数据集并计算概率校正因子；构建目标检测模型并将Base类的数据输入到目标检测模型中训练分类器模块和回归器模块,得到基础检测器；按批次使用Base类和Novel类的混合数据进一步训练基础检测器。重复上一步骤,直到新的目标检测模型在混合数据集上充分收敛,得到新的目标检测器；利用训练得到的目标检测器对测试图像进行检测,然后得到测试图像目标检测结果。该发明可以适用只有少量标记样本的目标检测场景,能够有效解决计算机视觉中少样本目标检测任务。本发明作为少样本目标检测模型,可广泛应用于少样本目标检测领域及应用场景。</td>   <td>1.一种基于知识迁移和概率校正的少样本目标检测方法,其特征在于,所述方法包括以下步骤：S1获取Base类数据集,构建只有少量样本的Novel类数据集,统计两个数据集里每个类的样本数目并计算概率校正因子；S2构建目标检测模型并将Base类的数据输入到目标检测模型中训练分类器模块和回归器模块,得到基础检测器；S3按批次使用Base类和Novel类的混合数据进一步训练基础检测器；训练过程中,保持回归器模块不变,分类器模块根据概率校正因子对Base类和Novel类的分类概率进行校正,然后再计算损失函数并使用SGD优化器进行模型优化；S4重复步骤S3,直到新的目标检测模型在混合数据集上充分收敛,得到新的目标检测器；S5利用步骤S4中训练得到的目标检测器对测试图像进行检测,然后得到测试图像目标检测结果。</td>   <td>G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李秋萍;                   吴飒莎       </td>   <td>中山大学</td>   <td>一种复杂环境下的行人移动轨迹在线预测方法及系统</td>   <td>广东省</td>   <td>CN113569980A</td>   <td>2021-10-29</td>   <td>本发明公开了一种复杂环境下的行人移动轨迹在线预测方法及系统,该方法包括：基于智能移动设备探测一定时间内的行人位置数据,得到行人历史轨迹；根据行人历史轨迹提取行人多维度移动特征；基于行人多维度移动特征和行人历史轨迹训练支持向量回归模型,得到轨迹预测模型；动态更新轨迹预测模型的参数并基于轨迹预测模型预测行人未来时刻的轨迹。该系统包括：数据获取模块、特征提取模块、模型训练模块和预测模块。通过使用本发明,能够提高轨迹预测的准确率,降低智能移动设备与周围行人碰撞的风险。本发明作为一种复杂环境下的行人移动轨迹在线预测方法及系统,可广泛应用于智能交通领域。</td>   <td>1.一种复杂环境下的行人移动轨迹在线预测方法,其特征在于,包括以下步骤：基于智能移动设备探测一定时间内的行人位置数据,得到行人历史轨迹；根据行人历史轨迹提取行人多维度移动特征；基于行人多维度移动特征和行人历史轨迹训练支持向量回归模型,得到轨迹预测模型；动态更新轨迹预测模型的参数并基于轨迹预测模型预测行人未来时刻的轨迹；所述行人多维度移动特征包括位置特征、速度特征、加速度特征和阻力特征。</td>   <td>G06K9/62;G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丘昌镇;              黄宇荣;              张志勇;                   陈少龙       </td>   <td>中山大学</td>   <td>一种多目标跟踪方法、装置、设备和存储介质</td>   <td>广东省</td>   <td>CN113570637A</td>   <td>2021-10-29</td>   <td>本申请公开了一种多目标跟踪方法、装置、设备和存储介质,方法包括：对第一帧图片中的目标进行检测,得到若干第一目标；在第二帧图片中,对各所述第一目标进行跟踪,得到各所述第一目标对应的第一跟踪结果；对第二帧图片中的目标进行检测,得到目标检测结果；根据所述第一跟踪结果和所述目标检测结果,确定所述第二帧图片中的若干第二目标；根据所述第一目标和所述第二目标之间的第一欧式距离,确定所述第二帧图片对应的目标跟踪结果。解决了现有基于神经网络的多目标跟踪方法,在小型化、低功耗的嵌入式平台难以实时运行的技术问题。</td>   <td>1.一种多目标跟踪方法,其特征在于,包括：对第一帧图片中的目标进行检测,得到若干第一目标；在第二帧图片中,对各所述第一目标进行跟踪,得到各所述第一目标对应的第一跟踪结果；对第二帧图片中的目标进行检测,得到目标检测结果；根据所述第一跟踪结果和所述目标检测结果,确定所述第二帧图片中的若干第二目标；根据所述第一目标和所述第二目标之间的第一欧式距离,确定所述第二帧图片对应的目标跟踪结果。</td>   <td>G06T7/246;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡燕嫦;                   倪江群       </td>   <td>中山大学</td>   <td>一种基于特征融合的数字图像相机源模型分类方法</td>   <td>广东省</td>   <td>CN108710893B</td>   <td>2021-10-29</td>   <td>本发明提供一种基于特征融合的数字图像相机源模型分类方法,该方法基于深度卷积神经网络CNN,设计了一种针对相机源模型的定制化神经网络结构,主要包括：采用图像隐写分析人工特征集中的30个基本滤波器初始化CNN网络第一层,以生成具有显著表征能力的残差特征图；在训练样本图像较少的情况下,通过将样本图像随机分块来扩充数据量,并训练CNN作为分块图像的特征表达；对待分类图像对应分块图像的CNN特征按位置、亮度、纹理复杂度进行特征融合,并以支持向量机进行分类判决。本专利基于深度卷积网络和多位置特征融合,通过对样本图像全局、位置、亮度和纹理信息的综合利用,有效提升了相机模型分类准确度。</td>   <td>1.一种基于特征融合的数字图像相机源模型分类方法,其特征在于：包括以下步骤：S1：对训练集和验证集中的大图进行随机分块,生成的小块标签与大图标签一致；S2：用训练集小块训练CNN作为分块图像的特征表达,选取在验证集上平均分类准确度最高的模型作为CNN特征提取器；S3：再次对训练集和验证集的大图进行切块,每个小块按照其亮度、纹理复杂度计算其可信度,形成可信度矩阵并且记录每个小块在大图中的位置；S4：将训练集和验证集中每张大图的小块输入到CNN特征提取器中得到分类图像对应分块图像的CNN特征,按照小块在大图中的位置以及小块的可信度进行特征融合,得到训练集和验证集融合后的特征；S5：用训练集和验证集融合后的特征训练SVM,即支持向量机作为分类器,判断分类器在验证集的平均分类准确度是否不再上升,如果分类器的准确度持续提高,则继续训练；如果分类器的准确度不再提高,则结束训练,得到分类器；S6：将目标图像通过CNN特征提取器提取特征,特征融合后导入分类器中,进行分类；其中,步骤S3中所述的可信度矩阵,其构建方式如下：S31：根据图像小块的亮度、纹理复杂度,通过亮度函数和纹理复杂度函数分别计算,得到亮度系数和纹理复杂度；S32：将得到的亮度系数和纹理复杂度按照一定比例相加得到该小块的可信度；S33：将得到的小块可信度按照其在大图中的位置组成可信度矩阵。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              马天俊;                   朱婷       </td>   <td>中山大学</td>   <td>一种端到端的基于深度决策森林的人群计数方法</td>   <td>广东省</td>   <td>CN108491766B</td>   <td>2021-10-26</td>   <td>本发明提供一种端到端的基于深度决策森林的人群计数方法,将视频帧图像与人数标签分布联系起来,标签分布反映了不同标签对该视频帧的贡献程度。采用深度回归森林来学习人数标签分布模型,输入测试数据便可得到对应的分布预测,其中描述程度最大的标记便是该图像数据对应的人数。本发明定义了一个基于分布的森林损失函数,使所有的树能够共同学习,并且通过变分边界可以导出叶节点预测的更新函数,从而保证了损失函数的严格下降。</td>   <td>1.一种端到端的基于深度决策森林的人群计数方法,其特征在于,包括以下步骤：S1：利用深度学习框架caffe建立卷积神经网络,对视频帧图像进行深度特征提取；S2：利用卷积神经网络全连接层输出,将决策森林替代卷积神经网络的softmax层训练深度回归森林；步骤S2中,利用决策森林来代替卷积神经网络的softmax层包括以下步骤：S21:决策森林由5棵决策树组成,记为森林中所有树都共享卷积神经网络的网络参数θ,对于第i颗树而言：(1)深度为7层,包括分裂节点和预测节点；(2)索引函数将S1的输出单元映射到决策树的分裂节点上；S22:分裂节点即决策树的非叶子节点,分裂节点集合记为每个分裂节点都定义了一个分裂函数γ是sigmod函数,使分裂函数的输出映射到[0,1],表示分裂节点n通过该决策树的索引函数对应的神经网络的输出单元值,通过分裂函数结果得出一个样本x分类为该节点左子树的概率t-(n)(x；θ)；以及分类为右子树的概率：1-t-(n)(x；θ)；S23:预测节点是决策树的叶子节点,预测节点集合记为每个叶子节点都定义了一个概率分布函数作为预测结果输出,为了计算简便,初始设定是一个高斯分布,据上,一个样本x落入某个预测节点l的概率为：                  其中和分别表示S22中定义的分裂节点n的左子树和右子树；Ι(·)是指示函数；t-(n)(x；θ)为该叶子节点与决策树根节点之间路径上的分裂节点上的分裂函数,所以一个样本x在一棵决策树下最终预测对应的标记分布y的概率为：                  所以对于训练集定义森林的loss函数是所有树的loss函数和的均值,记为定义如下：                  其中N为森林中决策树的数量,其余变量如前文所示,预测节点的概率分布q和网络参数θ为训练目标；S3：对视频帧图像按角度旋转、图像的多尺度缩放、图像的镜像以及图像金字塔缩放的操作实现图像数据增强；S4：将视频人群图片输入给卷积神经网络训练,通过反向传播不断地优化最终得到训练好的卷积神经网络模型；S5：输入测试图像得到的分布预测,其中描述程度最大的标记便是该图像对应的人数,最终预测结果是森林中所有决策树的均值。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              任创杰;              成慧;              王青;                   王可泽       </td>   <td>中山大学</td>   <td>一种用于卷积神经网络的特征图增强系统及方法</td>   <td>广东省</td>   <td>CN108596865B</td>   <td>2021-10-26</td>   <td>本发明公开了一种用于卷积神经网络的特征图增强系统及方法,该系统包括：内置特征图单元,用于存储训练样本之间的本质共性特征；输入控制器,基于原输入特征图及以往的内置特征图,整合两者的特征信息,进行一系列卷积操作,得到一个与内置特征图大小一致的输入控制器的中间特征图；特征图控制器,以原输入特征图以及以往内置特征图作为输入,进行一系列卷积操作,得到一个与内置特征图大小一致的特征图控制器的中间特征图,结合所述输入控制器的中间特征图,并以β参数来控制两者的表达能力,得到最新的内置特征图表达；输出控制器,以最新内置特征图以及原输入特征图作为输入,通过卷积操作以及对最新内置特征图的特征提取,得到辅助特征图输出。</td>   <td>1.一种用于卷积神经网络的特征图增强系统,用于深度图像处理,包括：内置特征图单元,用于存储训练样本之间的本质共性特征；输入控制器,基于原输入特征图x以及以往的内置特征图M-(t-1),整合两者的特征信息,进行一系列卷积操作,得到一个与内置特征图大小一致的输入控制器的中间特征图；特征图控制器,以原输入特征图x以及以往内置特征图M-(t-1)作为输入,进行一系列卷积操作,得到两个高度抽象的特征图表达,以γ-(m)参数控制两者的表达能力,经过sigmoid函数σ进行非线性数值转换,并与以往内置特征图M-(t-1)进行点乘,得到一个与内置特征图大小一致的特征图控制器的中间特征图表达,并结合所述输入控制器的中间特征图,以β参数来控制两者的表达能力,得到最新的内置特征图M-(t)表达；输出控制器,在得到最新内置特征图表达M-(t)的情况下,以最新内置特征图M-(t)以及原输入特征图x作为输入,通过卷积操作得到两个高度抽象的特征表达,并用参数γ-(o)控制两个高度抽象的特征表达的表达能力,经过sigmoid函数得到特征图,将该特征图与最新内置特征图M-(t)进行点乘,从最新内置特征图M-(t)中提取出辅助信息作为最终的辅助特征图输出,所述输入控制器、特征图控制器以及输出控制器为卷积控制器,对于给定输入特征图以及内置特征图,各卷积控制器首先使用两个一层二维卷积层来分别提取两者的特征,然后将它们相加,依次再接BN层、矫正线性单元层、二维卷积层、BN层,其中：二维卷积层,用于对输入特征图与内置特征图在二维空间进行卷积,以提取特征,假设输入图像的宽度和高度分别为w和h,三维卷积核的大小为w'×h'×m',其中w',h',m'分别表示宽度,高度和通道数,卷积后获得一个特征图,其中位于特征图(x,y)位置处的值表示成：                  其中p-((x+i)(y+j)(s+k))表示输入的第(s+k)帧中(x+i,y+j)位置的像素值,ω-(ijk)表示卷积核的参数,b表示跟与该特征图相关的偏置；BN层,对一批次的输入数据中每个通道,计算其均值μ和方差δ,以对神经元进行归一化操作,得到中间结果y；矫正线性单元层,连接BN层,采用简单的非线性阈值函数,对输入进行只允许非负信号通过的变换。</td>   <td>G06T5/50;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              陆瑞智;                   谢晓华       </td>   <td>中山大学</td>   <td>基于双流卷积神经网络的双目图像快速目标检测方法</td>   <td>广东省</td>   <td>CN110110793B</td>   <td>2021-10-26</td>   <td>本发明公开了一种基于双流卷积神经网络的双目图像快速目标检测方法,包括步骤：对双目摄像头进行标定,得到标定参数；根据标定参数对训练图像进行校正,训练隐式深度语义挖掘网络用于在双目图像上隐式地学习深度语义信息,训练多模态特征混合检测网络；将隐式深度语义挖掘网络输出的特征与多模态特征混合检测网络的特征通过通道串联的方式结合在一起,便组成双流卷积神经网络,利用训练图像训练双流卷积神经网络；通过双目摄像头获取测试图像,并对其进行校正,将校正后的图像输入到上述双流卷积神经网络中进行目标检测,得到目标检测结果。本发明可以综合利用RGB和深度语义信息的互补性,具有效率高、目标检测结果更准确的优点。</td>   <td>1.基于双流卷积神经网络的双目图像快速目标检测方法,其特征在于,包括步骤：(1)对双目摄像头进行标定,得到标定参数；(2)根据标定参数对训练图像进行校正,训练隐式深度语义挖掘网络用于在双目图像上隐式地学习深度语义信息,训练多模态特征混合检测网络；将隐式深度语义挖掘网络输出的特征与多模态特征混合检测网络的特征通过通道串联的方式结合在一起,便组成双流卷积神经网络,利用训练图像训练双流卷积神经网络；(3)通过双目摄像头获取测试图像,并对其进行校正,将校正后的图像输入到上述双流卷积神经网络中进行目标检测,得到目标检测结果；具体为：(3-1)将校正后的图像输入至双流卷积神经网络中,其中网络参数采用步骤(2)训练得出的参数；在双流卷积神经网络中,将双目图像均输入至隐式深度语义挖掘网络,将其中左目图像输入至多模态特征混合检测网络,经过双流卷积神经网络的目标识别从而得出目标检测结果,检测结果包括检测得出的目标数量,每个目标的位置信息以及置信度；步骤(2)中,训练隐式深度语义挖掘网络,步骤是：(2-1-1)建立隐式深度语义挖掘网络结构,并初始化网络结构中的参数；(2-1-2)对于标定后的训练图像,人为标注出其中左目摄像头的图像中的目标位置；(2-1-3)利用隐式深度语义挖掘网络进行目标检测,对于每一对双目图像,经训练后得到对应的目标位置信息与类别置信度,将其与步骤(2-1-2)中人为标注信息比对,利用损失函数与梯度下降法对隐式深度语义挖掘网络进行训练；训练后,只保留隐式深度语义挖掘网络的前7个层级,得到训练后的模型参数；步骤(2)中,训练多模态特征混合检测网络,步骤是：(2-2-1)建立多模态特征混合检测网络,并初始化网络结构中的参数；(2-2-2)对于标定后的训练图像,人为标注出其中左目摄像头的图像中的目标位置；(2-2-3)屏蔽隐式深度语义挖掘网络的特征来源,输入上述标注过目标的原始图像,让多模态特征混合检测网络进行目标检测；对于每一个训练图像,得到对应的目标位置信息与类别置信度,将其与步骤(2-2-2)中人为标注信息比对,利用损失函数与梯度下降法对多模态特征混合检测网络进行训练,得到训练后的模型参数；步骤(2)中,对双流卷积神经网络进行训练,步骤是：(2-3-1)对于标定后的训练图像,人为标注出图像中的目标位置；(2-3-2)让双流卷积神经网络进行目标检测,对于每一个训练图像,得到对应的目标位置信息与类别置信度,将其与步骤(2-3-1)中人为标注信息比对,利用损失函数与梯度下降法对网络进行训练,得到训练后的模型参数；所述步骤(2-1-1)中,隐式深度语义挖掘网络结构采用基于DispNet的网络结构,主干设置17个层级,其中conv代表卷积层、corr代表相关层,在网络的conv4b、conv6b、conv7b和conv8b上分别设置了一条检测分支；每个检测分支上分别设置了四对卷积层,负责四个不同大小范围的目标检测；所述步骤(2-2-1)中,多模态特征混合检测网络的主干采用VGG16的神经网络结构,其中conv代表卷积层、pool代表池化层,在多模态特征混合检测网络的conv4-3、conv-fc7、conv6-2、conv7-2、conv8-2和conv9-2上分别设置了一条检测分支；每个检测分支上分别设置了四对卷积层,负责四个不同大小范围的目标检测。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周素红;              周淑丽;              郑重;                   卢俊文       </td>   <td>中山大学</td>   <td>一种基于疫情传播风险的疫苗分配方法、系统及装置</td>   <td>广东省</td>   <td>CN112633681B</td>   <td>2021-10-26</td>   <td>本发明公开了一种基于疫情传播风险的疫苗分配方法、系统及装置,该方法包括：获取用户移动轨迹并对用户移动轨迹进行标准化处理,得到用户轨迹数据；根据预设参数和用户轨迹数据确定疫情流行病参数；构建基于Agent和SEIR的疫情传播模型,并模拟自然传播过程,得到疫情风险地图；根据疫情风险地图确定疫苗投放策略,并模拟疫苗投放后的疫情结果。该系统包括：用户轨迹模块,参数模块、传播模型模块、风险地图模块和策略模块。该装置包括存储器以及用于执行上述基于疫情传播风险的疫苗分配方法的处理器。通过使用本发明,可提高疫苗分配效率。本发明作为一种基于疫情传播风险的疫苗分配方法、系统及装置,可广泛应用于资源分配领域。</td>   <td>1.一种基于疫情传播风险的疫苗分配方法,其特征在于,包括以下步骤：获取用户移动轨迹并对用户移动轨迹进行标准化处理,得到用户轨迹数据；根据疫情数据确定潜伏期、感染期和基本繁殖数；根据用户轨迹数据统计时间单元内相遇人次并将时间单元的相遇人次相加,得到对应时间段内的总相遇人次；根据对应时间段内的总相遇人次和用户总数,得到平均相遇人次；根据平均相遇人次、感染期和基本繁殖数得到接触感染率,确定疫情流行病参数；根据用户轨迹数据和疫情流行病参数构建基于Agent和SEIR的疫情传播模型,并模拟自然传播过程,得到疫情风险地图；根据疫情风险地图确定疫苗投放策略,并基于Agent和SEIR的疫情传播模型模拟疫苗投放后的疫情结果。</td>   <td>G06Q10/06;G06F16/29;G16H50/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡凇源;              周晓聪;                   衣杨       </td>   <td>中山大学</td>   <td>空指针检测方法</td>   <td>广东省</td>   <td>CN109522232B</td>   <td>2021-10-22</td>   <td>本发明提供一种空指针检测方法,涉及静态分析技术领域。具体包括：获取待分析程序的控制流图；获取所述控制流图中的所有节点；沿着所有可能的路径,遍历所述控制流图中的所有节点,获取每个所述节点内待检测的变量值与到达条件；遍历至所述控制流图出口节点时,结合所述出口节点的变量的值与到达条件,确定返回的变量值是否为空。相对于现有技术,通过与定值到达条件的结合,可以有效去除掉定值不可能到达的情况,提高了到达定值分析给出的结论准确度不高的问题。</td>   <td>1.一种空指针检测方法,其特征在于,包括：获取待分析程序的控制流图；获取所述控制流图中的所有节点；沿着所有可能的路径,遍历所述控制流图中的所有节点,获取每个所述节点内待检测的变量值与到达条件；遍历至所述控制流图出口节点时,结合所述出口节点的变量的值与到达条件,确定返回的变量值是否为空；所述沿着所有可能的路径,遍历所述控制流图中的所有节点,获取每个所述节点内待检测的变量值与到达条件,包括：计算所述节点n的入函数In(n),其中n为大于零的整数,且小于或等于待分析程序的控制流图中所有节点的数量；扩展所述节点n的生成条件定值,并获取扩展后的生成条件定值,所述扩展为：当控制流图里的入口节点的条件取值为ture时,到了下一个节点,若下个节点为if语句,则将入口节点的条件值ture与if语句里条件表达式的条件值进行合取,所得到的合取后的值为扩展后的生成条件定值；筛选所述扩展后的生成条件定值,并删除未通过筛选的条件定值；分析剩余的条件定值,确定所述节点n的变量值与对应的条件定值。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         董春雨;              颜宇;              郭杰;              陈晓宏;              林凯荣;                   刘智勇       </td>   <td>中山大学;广东省科学院广州地理研究所</td>   <td>一种衡量植被健康极化程度的方法</td>   <td>广东省</td>   <td>CN113537705A</td>   <td>2021-10-22</td>   <td>本发明公开了一种衡量植被健康极化程度的方法,包括：根据预设的月尺度植被健康数据通过植被极化指数算法确定植被健康基尼指数、Wolfson指数和植被极化指数,用于衡量植被健康极化程度。本发明根据获取的数据通过植被极化指数算法确定植被健康基尼指数、Wolfson指数和植被极化指数,用于分析植被极化程度,同时通过植被健康基尼指数和Wolfson指数构建的算法,进一步验证植被极化程度,降低计算的难度并提高衡量植被健康极化程度的准确度。</td>   <td>1.一种衡量植被健康极化程度的方法,其特征在于,包括：根据预设的月尺度数据通过植被极化指数算法确定植被健康基尼指数、Wolfson指数和植被极化指数,用于衡量植被健康极化程度。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韦艳宏;              钟霞丽;              柯炜健;                   王璨       </td>   <td>中山大学</td>   <td>基于高内涵成像系统的芳基磷酸酯类阻燃剂血管毒性的评价方法</td>   <td>广东省</td>   <td>CN110956625B</td>   <td>2021-10-19</td>   <td>本发明公开了基于高内涵成像系统的芳基磷酸酯类阻燃剂血管毒性的评价方法,包括以下步骤：1)获取芳基磷酸酯类阻燃剂处理的斑马鱼胚胎/幼鱼血管荧光图像；2)血管图像分割识别与分析；3)获得评价和筛选结果。通过采集特异性血管荧光标记的转基因斑马鱼胚胎/幼鱼的血管图像,分析多血管参数实现对芳基磷酸酯类阻燃剂血管发育毒性评价和筛选。该方法配置包括：硬件系统负责血管图像数据的获取,由高内涵成像系统及配套琼脂糖包被的96孔玻底板组成；软件系统用于目标血管的半自动识别以及多参数输出分析,涉及Photoshop、Matlab以及GraphPad Prism等软件。本发明具有高通量的特征,结果稳定,能快速准确对芳基磷酸酯类阻燃剂进行多参数指标的血管发育毒性评价与筛选。</td>   <td>1.基于高内涵成像系统的芳基磷酸酯类阻燃剂血管毒性的评价方法,其特征在于,包括以下步骤：1)获取芳基磷酸酯类阻燃剂处理的斑马鱼胚胎/幼鱼血管荧光图像；步骤1)中包括以下步骤：1.1)上机：运行高内涵成像系统,载入装有芳基磷酸酯类阻燃剂处理的斑马鱼胚胎/幼鱼的96孔板；1.2)设置预扫图像分析程序：识别488nm通道区域面积大于或等于100000像素并且荧光强度高于400,保存命名为“Findingfish”；1.3)设置成像程序参数：①选择5X物镜非共聚焦模式,488nm通道的参数设置：曝光时20ms、激光功率50％、拍摄高度500um,选中所有孔以及镜头,分析程序设置为“Findingfish”,保存好程序命名为“Pre”；②选择10X物镜共聚焦模式,488nm的参数设置：曝光时间300ms、激光功率100％,以及明场的参数设置：曝光时间20ms、激光功率50％、拍摄高度500um双通道,层扫模式的参数：起始处为300um,20um/层,20层,选中所有孔以及镜头,保存好程序命名为“Re”；1.4)成像与图像保存：使用预扫模式,分别载入“Pre”以及“Re”两个程序,命名实验名称,运行程序进行高内涵全自动成像,选择荧光增强模式,以bmp格式保存斑马鱼胚胎或幼鱼血管荧光图并按编号命名；2)血管图像分割识别与分析；所述血管图像分割识别与分析运用Photoshop及Matlab两款软件,通过录制宏与编写算法对目标血管进行批量半自动识别、输出与分析形态学的参数改变；3)获得评价和筛选结果。</td>   <td>G06T7/00;G06T7/11;G06T7/62;G01N21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曹孟莹;                   辛秦川       </td>   <td>中山大学</td>   <td>一种植物生长时间的识别方法及装置</td>   <td>广东省</td>   <td>CN113516067A</td>   <td>2021-10-19</td>   <td>本发明涉及植物物候识别技术领域,公开了一种植被生长时间的识别方法及装置,所述方法包括：获取包括第一植物的第一图片；将所述第一图片输入到图像分割网络,获取所述第一图片的感兴趣区域；将所述感兴趣区域输入到预设的神经网络模型中,通过神经网络模型提取感兴趣区域的绿度信息,并将所述绿度信息和所述神经网络模型生成的植物不同生长时间的绿度信息曲线进行比较,得到所述第一图片中第一植物所处的生长时间。有益效果：通过提取第一图片的绿度信息并将所述绿度信息和预设的神经网络所生成的绿度信息曲线进行比较,可以更加准确的判断第一图片中第一植物所处的生长时间。</td>   <td>1.一种植物生长时间的识别方法,其特征在于,包括：获取包括第一植物的第一图片；将所述第一图片输入到图像分割网络,获取所述第一图片的感兴趣区域；将所述感兴趣区域输入到预设的神经网络模型中,通过神经网络模型提取感兴趣区域的绿度信息,并将所述绿度信息和所述神经网络模型生成的植物不同生长时间的绿度信息曲线进行比较,得到所述第一图片中第一植物所处的生长时间。</td>   <td>G06K9/00;G06K9/34;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         秦宗;              万权震;              邱钰清;              戴睿佳;              杨文超;                   杨柏儒       </td>   <td>中山大学</td>   <td>一种集成成像光场显示的实时渲染方法及装置</td>   <td>广东省</td>   <td>CN113516748A</td>   <td>2021-10-19</td>   <td>本申请公开了一种集成成像光场显示的实时渲染方法及装置,包括：根据预设的目标重建空间和待渲染的目标图像,确定目标重建平面及其重建范围；针对各个目标重建平面,获取目标图像在目标重建平面的纹理图；根据各个目标重建平面的纹理图的体像素信息以及第一索引矩阵,获取包含各目标重建平面的纹理图中的每个体像素与显示面板上的二维像素的对应关系的第二索引矩阵；其中,第一索引矩阵为预先计算得到的；最后根据各个目标重建平面的纹理图的体像素信息以及第二索引矩阵,获取显示面板的单元图像阵列。整个计算过程简单、快捷,不需要依赖于强大的硬件算力,压缩了计算量并节约了渲染单个图片的时间,使得图像渲染的速度达到视频级的水平。</td>   <td>1.一种用于集成成像光场显示的实时渲染方法,其特征在于,包括：根据预设的目标重建空间和待渲染的目标图像,确定至少两个目标重建平面以及目标重建平面的重建范围；针对每个目标重建平面,根据显示面板的参数和目标重建平面的重建范围,以及显示面板、微透镜阵列与目标重建平面三者之间的几何关系,获取待渲染的目标图像在目标重建平面的纹理图；根据各个目标重建平面的纹理图的体像素信息以及预设的第一索引矩阵,获取第二索引矩阵；其中,所述第一索引矩阵包含了各个可能的重建平面在其重建范围内的每一个体像素与显示面板上的二维像素的对应关系；所述第二索引矩阵包含各个目标重建平面的纹理图中的每一个体像素与显示面板上的二维像素的对应关系；根据各个目标重建平面的纹理图的体像素信息以及所述第二索引矩阵,获取显示面板的单元图像阵列。</td>   <td>G06T15/00;G06T15/04;G06F16/51</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              杨猛;              王可泽;                   王青       </td>   <td>中山大学</td>   <td>基于深度网络的人体三维关节点估计框架及其定位方法</td>   <td>广东省</td>   <td>CN109087329B</td>   <td>2021-10-15</td>   <td>本发明公开了一种基于深度网络的人体三维关节点估计框架及其定位方法,该框架包括：二维姿势子网络,用于在二维姿势数据集上进行预训练,以提取二维姿势特征传入二维-三维转换模块,并生成精确的二维预测姿势；二维-三维转换模块,用于接收所述二维姿势子网络提取的二维姿势特征转换到三维姿势特征空间中,并生成时序一致的三维姿势粗估计；三维-二维投影模块,用于将所述二维-三维转换模块估计的中间级三维姿势粗估计投影回二维空间,生成二维投影姿势,并通过优化二维投影姿势和二维预测姿势之间的一致性,修正估计的三维姿势,最终输出具有时空一致性、二维三维几何一致性的精确三维姿势估计,本发明可提高人体三维关节点预测定位的精度。</td>   <td>1.一种基于深度网络的人体三维关节点估计框架,包括：二维姿势子网络,用于在二维姿势数据集上进行预训练,以提取二维姿势特征传入二维-三维转换模块,并生成精确的二维预测姿势；二维-三维转换模块,用于接收所述二维姿势子网络提取的二维姿势特征转换到三维姿势特征空间中,并生成时序一致的三维姿势粗估计；三维-二维投影模块,用于将所述二维-三维转换模块估计的中间级三维姿势粗估计投影回二维空间,生成二维投影姿势,并通过优化二维投影姿势和二维预测姿势之间的一致性,修正估计的三维姿势,最终输出具有时空一致性、二维三维几何一致性的精确三维姿势估计；所述框架引入两个对偶学习任务,所述两个对偶学习任务分别是根据预测二维姿势的二维空间特征转换到三维空间预测三维姿势坐标,以及三维姿势坐标投影生成二维姿势坐标,最小化三维姿势投影生成的二维投影姿势和预测的二维姿势之间的误差,以在不需要更多三维姿势标注的基础上修正预测的三维姿势,并引入更多二维姿势标注数据提高三维姿势预测的准确率,最终通过自监督修正机制生成具有空间几何一致性的三维姿势估计。</td>   <td>G06T7/207</td>  </tr>        <tr>   <td>中国专利</td>   <td>              周宇       </td>   <td>中山大学</td>   <td>断层几何结构获取方法、装置和计算机设备</td>   <td>广东省</td>   <td>CN110766794B</td>   <td>2021-10-15</td>   <td>本发明涉及一种断层几何结构获取方法、装置、计算机设备和计算机可读存储介质,该方法包括步骤：生成目标区域的数字高程模型；确定数字高程模型中的断层迹线,断层迹线用于表示数字高程模型中断层在地表的迹线；根据断层迹线,对目标区域的数字高程模型进行采样；生成基于采样的多个平面；获取多个平面的收敛平面；根据收敛平面确定目标区域的断层面结构。可以提高获取断层面结构的效率。</td>   <td>1.一种断层几何结构获取方法,其特征在于,包括步骤：生成目标区域的数字高程模型；确定所述数字高程模型中的断层迹线,所述断层迹线用于表示所述数字高程模型中断层面与地面相交的曲线；根据所述断层迹线,对所述目标区域的数字高程模型进行采样；包括：生成以所述断层迹线为中心线的多个多边形；对所述目标区域的数字高程模型中的在所述多个多边形内的点进行采样；所述多个多边形包括多个基于所述断层迹线随机生成的多边形；所述采样包括对所述多边形范围内的数字高程模型中坐标进行采样；生成基于所述采样的多个平面；所述平面基于所述采样中的一个或多个坐标点生成；获取所述多个平面的收敛平面；根据所述收敛平面确定所述目标区域的断层面结构。</td>   <td>G06T17/05</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;                   张睿       </td>   <td>中山大学</td>   <td>语音唇形拟合方法、系统及存储介质</td>   <td>广东省</td>   <td>CN110942502B</td>   <td>2021-10-15</td>   <td>本发明涉及一种语音唇形拟合方法,包括以下内容：采集目标人物视频数据集的图像数据和语音数据；提取所述图像数据中目标人物的唇形特征向量；提取所述语音数据中目标人物的语音特征向量；以语音特征向量为输入,唇形特征向量为输出,训练多尺度融合卷积神经网络；向多尺度融合卷积神经网络输入目标人物待拟合的语音特征向量,多尺度融合卷积神经网络生成拟合的唇形特征向量并进行输出,基于所述唇形特征向量对唇形进行拟合。</td>   <td>1.语音唇形拟合方法,其特征在于：包括以下内容：采集目标人物视频数据集的图像数据和语音数据；提取所述图像数据中目标人物的唇形特征向量；提取所述语音数据中目标人物的语音特征向量；以语音特征向量为输入,唇形特征向量为输出,训练多尺度融合卷积神经网络；向多尺度融合卷积神经网络输入目标人物待拟合的语音特征向量,多尺度融合卷积神经网络生成拟合的唇形特征向量并进行输出,基于所述唇形特征向量对唇形进行拟合；所述目标人物的唇形特征向量由采集的图像数据逐帧画面中嘴唇、下巴和脸颊部位的30维BlendShape系数向量组成；所述提取语音数据中目标人物的语音特征向量的具体过程如下：对采集的目标人物的语音数据逐帧进行梅尔频率倒谱系数的特征向量提取；获取一个经过语音识别训练的深度神经网络,并去除掉最后的CTC分类损失层；将提取的梅尔频率倒谱系数特征向量逐帧输入所述深度神经网络,深度神经网络输出语音数据经过二次提取后的特征向量,即为所需语音特征向量；所述训练多尺度融合卷积神经网络的具体过程如下：A、设采集的语音数据长度共为a帧,帧序号为从1到a,则按照[1:m][2:(m+1)]...[(a-m+1):a]的形式进行滑动帧序分组,将提取的语音特征向量构造成大小为m×n的二维矩阵形式；B、将所述提取的唇形特征向量构造成大小为m×30的二维矩阵形式；C、构造多尺度融合卷积神经网络；D、将所述唇形特征向量展平成一维向量作为所述多尺度融合卷积神经网络训练的标签向量；E、向所述多尺度融合卷积神经网络输入提取的语音特征向量；F、根据多尺度融合卷积神经网络的输出计算损失函数,并基于所述损失函数根据反向传播和梯度下降原理调整多尺度融合卷积神经网络的各层权重；G、重复步骤E、F直至损失函数值符合要求。</td>   <td>G06T13/20;G06T13/40;G10L15/16;G10L15/25</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              孙亚;                   曾莹       </td>   <td>中山大学</td>   <td>一种基于多尺度特征融合的活体检测方法、系统及装置</td>   <td>广东省</td>   <td>CN113505722A</td>   <td>2021-10-15</td>   <td>本发明公开了一种基于多尺度特征融合的活体检测方法、系统及装置,包括：获取训练图像并对训练图像进行人脸关键点检测并进行裁剪,得到裁剪后的训练图像；基于特征提取网络对裁剪后的训练图像进行特征提取,得到真实人脸图像特征和攻击人脸图像特征；基于生成对抗网络对真实人脸图像特征进行重构,得到重构真实人脸图像特征；基于三元组损失函数对重构真实人脸图像特征和攻击人脸图像特征进行约束,得到分类边界；采用全连接层作为分类器并根据分类边界对待测图像进行检测,得到检测结果。本发明方法提高人脸活体检测性能。本发明作为一种基于多尺度特征融合的活体检测方法、系统及装置,可广泛应用于计算机视觉领域。</td>   <td>1.一种基于多尺度特征融合的活体检测方法,其特征在于,包括以下步骤：S1、获取训练图像并对训练图像进行人脸关键点检测并进行裁剪,得到裁剪后的训练图像；S2、基于特征提取网络对裁剪后的训练图像进行特征提取,得到真实人脸图像特征和攻击人脸图像特征；S3、基于生成对抗网络对真实人脸图像特征进行重构,得到重构真实人脸图像特征；S4、基于三元组损失函数对重构真实人脸图像特征和攻击人脸图像特征进行约束,得到分类边界；S5、采用全连接层作为分类器并根据分类边界对待测图像进行检测,得到检测结果。</td>   <td>G06K9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;              刘凯;                   阳建华       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的空域图像隐写方法及系统</td>   <td>广东省</td>   <td>CN108346125B</td>   <td>2021-10-08</td>   <td>本发明公开了一种基于生成对抗网络的空域图像隐写方法,通过利用U型结构的生成网络将载体图像转换为概率图,然后利用双曲正切编码模块对概率图进行编码,生成篡改点图,并将载体图像与篡改点图相加,生成载密图像；再利用隐写分析网络对载体图像和载密图像进行区分,并将分类结果以误差的形式反馈回生成网络；最后将训练好的生成网络和编码模块组合在一起,作为最终的空域图像隐写模型,对整个模型输入载体图像,输出载密图像。本发明还公开了一种基于生成对抗网络的空域图像隐写系统,包括生成网络模块、编码模块和图像隐写模块。本发明所提出的基于生成对抗网络的空域图像隐写方法在安全性方面有明显提升,并且设计简单。</td>   <td>1.一种基于生成对抗网络的空域图像隐写方法,其特征在于,包括以下步骤：S1：将载体图像输入到生成网络中,经过生成网络处理后得到与载体图像尺寸相同的概率图；其中,采用U型网络作为生成网络,将原图x输入到U型生成网络,得到概率图：p＝Ugen(x)；其中p表示嵌入概率,与失真不同的是,嵌入概率越高的像素点,表示嵌入的可能性越大；S2：将步骤S1中得到的概率图和相同尺寸的随机噪声图像输入到编码模块中,输出一张与载体图像尺寸相同的篡改点图,将篡改点图与载体图像相加,得到载密图像；S3：用载体图像和步骤S2中生成的载密图像对隐写分析网络进行训练,训练的误差以损失的形式反馈回生成网络,也对生成网络进行训练,此步骤即生成对抗训练；S4：将训练好的生成网络和编码模块组合在一起,作为最终的空域图像隐写模型,对整个模型输入载体图像,输出载密图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              黄凯;              王东妮;              汪瑞昕;                   康德开       </td>   <td>中山大学中山眼科中心;中山大学</td>   <td>一种基于深度学习的细胞种类鉴定方法</td>   <td>广东省</td>   <td>CN109063547B</td>   <td>2021-10-08</td>   <td>本发明具体涉及一种基于深度学习的细胞种类鉴定方法,该方法基于深度学习来预设神经网络模型,通过滑动窗口得到多个局部图像输入神经网络模型后,再将得出来的结果进行整合,而不是直接将细胞图像输入到神经网络模型中,提高了得到细胞种类热图的精度。上述过程均为计算机的图像处理过程,相比于现有常用的细胞鉴定方法,不需要人工操作,也不需要对细胞进行侵入性的检测,具有快速、方便、非侵入、全局检测等优点。</td>   <td>1.一种基于深度学习的细胞种类鉴定方法,其特征在于,包括如下步骤：预先建立神经网络模型；采集细胞图像；得出细胞种类热图：S11、对细胞图像进行初步处理；S12、采用滑动窗口的方式使细胞图像分为多个局部图像；S13、多个局部图像输入神经网络模型中,得到局部图像的细胞种类标签；S14、将所有细胞种类标签整合为细胞种类热图；得出二值化图像及细胞密度热图：S21、对经步骤S11处理后的细胞图像进行阈值化处理,得到二值化图像；S22、采用滑动窗口的方式使二值化图像分为多个局部二值化图像,计算每个局部二值化图像中细胞区域所占总区域的比例,整合计算得到的所有比例,得到细胞密度热图；得出细胞种类鉴定结果：S31、整合细胞种类热图和二值化图像,得到二值化细胞种类热图,二值化图像将图像分为细胞区域和背景区域；S32、结合二值化细胞种类热图和细胞密度热图,得到细胞图像的细胞种类鉴定结果,具体为：对二值化细胞种类热图逐个像素点进行遍历,若该像素点在背景区域则跳过,若该像素点在细胞区域,则判断该像素点在对应的细胞密度热度中的灰度值,如果灰度值小于阈值T,则去除该像素点的细胞种类标签,如果灰度值大于阈值T,则保留该像素点的细胞种类标签。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林冠豪;                   吴贺俊       </td>   <td>中山大学</td>   <td>一种基于双层LSTM神经网络的动作识别方法</td>   <td>广东省</td>   <td>CN109271889B</td>   <td>2021-10-08</td>   <td>本发明涉及传感器领域,提出一种基于双层LSTM神经网络的动作识别方法,包括以下步骤：收集原始数据,对原始数据进行去噪处理；对数据进行分片；计算分片数据的频谱图,将两两相邻的频谱图进行减法运算,得出频谱图差值；对分片数据打标签；将打好标签的数据划分为训练集、交叉验证集和测试集；将频谱图差值导入双层单向LSTM神经网络模型对数据进行训练；在交叉验证集上不断调整学习率参数,选择准确度最高的模型对应的学习率作为最终参数值；将最终参数值导入测试集中,将模型运行在测试集数据上,其运行结果即为本算法模型的最终结果。本发明能够记忆所有输入数据,准确划分不同的人体动作的运动数据,提取不同动作在时间上的依赖性。</td>   <td>1.一种基于双层LSTM神经网络的动作识别方法,其特征在于,包括以下步骤：S1：收集原始数据,对原始数据进行去噪处理；S2：根据分片标准对经去噪处理的数据进行分片；S3：计算分片数据的频谱图,将两两相邻的频谱图进行减法运算,得出频谱图差值；其中,所述步骤S3中的频谱图计算公式为短时傅里叶变换公式：                  式中,t为时间,f为频率值,z(t)为源数据,g(t)为窗函数；所述窗函数为矩形窗函数,其公式为：                  式中,M为数据样本的数量；S4：对分片数据打标签；S5：将打好标签的数据划分为训练集、交叉验证集和测试集；S6：设计双层单向LSTM神经网络模型,并将频谱图差值输入双层单向LSTM神经网络模型中对数据进行训练；S7：在交叉验证集上不断调整学习率参数,选择准确度最高的模型对应的学习率作为最终参数值；S8：确定双层单向LSTM神经网络模型的最终参数值之后,将模型运行在测试集数据上,其运行结果即为动作识别的结果。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁陶希;              郑慧诚;                   吕怡静       </td>   <td>中山大学</td>   <td>基于时域分段及特征差分的动作识别方法</td>   <td>广东省</td>   <td>CN110032942B</td>   <td>2021-10-08</td>   <td>本发明公开了一种基于时域分段及特征差分的动作识别方法,包括：S1.将训练集中的动作视频等间隔分成多个片段,并在每个片段中随机提取一帧RGB图像以及光流图像；S2.构建双流网络；S3.将所有RGB图像以及光流图像分别对应输入双流网络进行训练；S4.将目标动作视频输入训练好的双流网络进行动作识别,并将其中所有网络流得到的结果进行融合从而得到动作视频的识别结果。通过将动作视频在时域上进行分段,整合动作视频中不同时段的特征,并进行特征差分融合得到动作视频的差分融合特征,从而有效提取长时动态信息；同时对双流网络中的空间流特征以及时间流特征进行时空相关融合,在保留原有时空信息的同时,进一步提取具有时空一致性的重要局部信息。</td>   <td>1.基于时域分段及特征差分的动作识别方法,其特征在于,包括以下步骤：S1.将训练集中的动作视频等间隔分成多个片段,并在每个片段中随机提取一帧RGB图像以及光流图像；S2.构建双流网络,其包括空间流网络和时间流网络,空间流网络的输入为RGB图像；时间流网络的输入为光流图像；S3.将所有RGB图像以及光流图像分别对应输入双流网络进行训练,具体步骤如下：S31.分别利用所述双流网络中的空间流网络和时间流网络对所有RGB图像以及光流图像进行特征提取,得到训练集中动作视频的空间流特征及时间流特征；S32.对动作视频的空间流特征进行差分融合操作,得到差分融合特征；将得到的差分融合特征与原始的空间流特征进行串联操作得到空间流融合特征；S33.利用空间流融合特征及时间流特征对双流网络进行训练,并将双流网络中所有网络流得到的结果进行融合从而得到动作视频的识别结果；S4.将目标动作视频输入训练好的双流网络进行动作识别,并将其中所有网络流得到的结果进行融合从而得到动作视频的识别结果；定义训练集中的动作视频分段数为K,则双流网络每次输入包含有K个RGB图像,输入的K个RGB图像经过双流网络后得到的空间流特征X为：X＝(x-1,x-2,...,x-K)；其中x-k表示第k个输入RGB图像对应的空间流特征,即为第k个时段的空间流特征；则步骤S32中所述的差分融合操作的定义如下：通过特征差分的方式得到相邻帧间的差异从而得到差分融合特征Y～(diff)：所述步骤S33还包括以下步骤：将同一时刻的空间流特征及时间流特征通过双线性融合法进行融合得到时空融合特征,然后将时空融合特征与空间流融合特征及时间流特征进行串联操作后对所述双流网络进行训练；所述双线性融合法为Compact Bilinear的双线性融合方法；双线性融合方法是指对同样大小的两张特征图作外积运算,可以表示为：                  其中表示的是外积操作,特征图和转置后的特征图进行矩阵乘法运算,得到了双线性融合特征双线性融合特征用乘积的形式捕捉了时间流特征图和空间流特征图在所有通道和所有空间位置的相关性。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪涛;              张宇思;              张文;              张佳敏;                   刘彦志       </td>   <td>中山大学</td>   <td>一种快速灵活全纯嵌入式经济策略调整方法及装置</td>   <td>广东省</td>   <td>CN113487196A</td>   <td>2021-10-08</td>   <td>本发明公开了一种快速灵活全纯嵌入式经济策略调整方法及装置,该方法包括：获取产品数据并基于伯特兰德模型建立均衡状态多项式方程组；将均衡状态多项式方程组描述为多项式系统并构建多项式同伦函数；对均衡状态多项式方程组进行求解,得到方程解；基于方程解分析均衡状态并进行经济策略选择。该装置包括存储器以及用于执行上述快速灵活全纯嵌入式经济策略调整方法的处理器。通过使用本发明,能够高效地求解均衡状态多项式方程组并以此调整经济策略,提高企业效益。本发明作为一种快速灵活全纯嵌入式经济策略调整方法及装置,可广泛应用于策略调整领域。</td>   <td>1.一种快速灵活全纯嵌入式经济策略调整方法,其特征在于,包括以下步骤：S1、获取产品数据并基于伯特兰德模型建立均衡状态多项式方程组；S2、将均衡状态多项式方程组描述为多项式系统并构建多项式同伦函数；S3、对均衡状态多项式方程组进行求解,得到方程解；S4、基于方程解分析均衡状态并进行经济策略选择。</td>   <td>G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         招继恩;              朱勇杰;              王国良;              张海;              谭大伦;                   周明       </td>   <td>广州智慧城市发展研究院;中山大学</td>   <td>一种基于注意力机制的行为识别系统</td>   <td>广东省</td>   <td>CN109871777B</td>   <td>2021-10-01</td>   <td>本发明公开了一种基于注意力机制的行为识别系统,由输入、中间Block、输出构成；所述系统整个网络结构基于Inception V3,选择在其中一个Block加入提出的两个Attention Module；其中使用Channel Attention模块来提取通道间依赖,通过使用Spatial Attention来获取空间的依赖。本发明为了克服错误标签和背景信息的影响。使用残差学习将通道注意力和空间注意力结合起来。并使用自我注意作为网络的一部分来获取更长期的时间信息。在模型中,利用了空间和通道的注意力,并且在模块设计中只使用二维通道的注意力。</td>   <td>1.一种基于注意力机制的行为识别系统,其特征在于,由输入、中间Block、输出构成；输入端为RGB图像,其中的注意力模块能任意嵌入在其中一个Block；注意力模块主要分为通道间注意力模块和空间注意力模块；视频中的一帧图像输入后,经过前馈运算后,卷积神经网络输出对应行为的类别；所述系统整个网络结构基于Inception V3,选择在其中一个Block加入两个注意力模块注意力模块；其中使用通道间注意力模块模块提取通道间依赖,通过使用空间注意力模块获取空间的依赖；整体系统通过输入的视频数据切分为图像数据后进行行为识别；所述系统根据通道间注意力模块的设计,关注信息部分或无关信息,与通道间注意力分支对称；空间注意模块的设计有两种方式；第一种形式是计算2D描述符,该描述符对通道上每个像素的信道信息进行编码,命名为第一空间注意力模块；使用通道最大池化和通道平均池化,生成两个2D特征图和然后在它们之间进行逐元素加法并通过标准卷积层进行卷积以产生2D空间注意力图,在最后添加sigmoid激活函数；具体公式表达如下所示：                                                      其中F为输入特征,c表示通道数,δ为表示Relu函数,σ表示Sigmoid激活函数；W-0以及W-1分别表示两个全连接层对应的参数；在第二种形式中,对于每个通道,将每个通道划分为N×N的网格,N选择为3或4；首先对每个网格执行最大池化,然后使用2层MLP和一个softmax激活函数来产生这些网格的系数；记为第二空间注意力模块；在设计完这些模块之后,神经网络,对数据集进行采样,数据增强并进行训练,测试时在测试集进行验证。</td>   <td>G06K9/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   祝恺蔓       </td>   <td>中山大学</td>   <td>基于关键帧人脸特征的人脸交换篡改视频检测方法、系统及介质</td>   <td>广东省</td>   <td>CN113469062A</td>   <td>2021-10-01</td>   <td>本发明公开了一种基于关键帧人脸特征的人脸交换篡改视频检测方法、系统及介质,方法包括：将视频数据集划分为训练集和测试集,对每个视频流提取一定的关键帧；对关键帧进行人脸定位,提取保留脸部边缘背景的人脸区域图像；再次检测与定位,获取紧密人脸区域图像；输入到神经网络模型中获取人脸图像的特征表示；使用训练集视频的多个关键帧上的人脸图像特征表示对长短期记忆网络和线性判别器进行训练；将测试集视频的多个关键帧上的人脸图像特征表示作为一组输入,输入到长短期记忆网络中,将最后一个图像对应的输出经过线性判别器,得到检测结果。本发明提供了与设备中现存人脸识别模块接入的可能性,检测用时短,对硬件要求低,可实时高效检测。</td>   <td>1.基于关键帧人脸特征的人脸交换篡改视频检测方法,其特征在于,包括下述步骤：将视频数据集划分为训练集和测试集,对每个视频流提取设定数量的关键帧；对提取的关键帧进行人脸定位,提取所有人脸区域图像并保留脸部边缘背景；对保留脸部边缘背景的人脸区域图像再次检测与定位,获取紧密人脸区域图像；将紧密人脸区域图像输入到人脸识别任务中训练好的神经网络中,获取人脸图像特征表示；将训练集视频的多个关键帧上的人脸图像特征表示作为一组输入,对长短期记忆网络和线性判别器进行训练；将测试集视频的多个关键帧上的人脸图像特征表示作为一组输入,输入到长短期记忆网络中,将最后一个图像对应的输出经过线性判别器,得到检测结果并评估检测性能。</td>   <td>G06K9/00;G06K9/32;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;                   全绍军       </td>   <td>长视科技股份有限公司;中山大学</td>   <td>基于目标检测的物体遮挡比例计算方法与系统</td>   <td>广东省</td>   <td>CN113469187A</td>   <td>2021-10-01</td>   <td>本发明公开了一种基于目标检测的物体遮挡比例计算方法。包括：输入待处理图像,利用目标检测器进行目标检测分割出目标物体图像,之后利用遮挡物检测器进行遮挡物检测,对遮挡物进行边缘检测计算出遮挡物所占的像素,再结合用于估计被遮挡物体在未被遮挡时占有的像素的基准值得到的被遮挡物所占像素个数从而计算出遮挡物的遮挡比例。本发明还公开了一种基于目标检测的物体遮挡比例计算系统、计算机设备及计算机可读存储介质。本发明在计算遮挡比例时,采用拉普拉斯算子进行边缘信息的提取,能够更为精确的计算出原始物体所占像素以及遮挡物所占像素,从而使得本发明计算出的物体被遮挡比例更加精确。</td>   <td>1.一种基于目标检测的物体遮挡比例计算方法,其特征在于,所述方法包括：采集目标检测数据集,并为目标检测数据集添加遮挡物,形成遮挡物数据集；基于MaskRCNN网络模型,利用所述遮挡物数据集进行训练,形成目标检测器,该检测器的输出为目标物体的类别及其检测框；利用所述目标检测器处理所述目标检测数据集,针对检测出的各个类别的物体分别计算出一个基准值,用于估计被遮挡物体在经过目标检测分割出来后,该类别的物体在未被遮挡时占有的像素个数；利用所述目标检测器处理所述遮挡物数据集,分割所有被遮挡物体的检测框形成被遮挡物图像集,再基于MaskRCNN网络模型,利用所述被遮挡物图像集进行训练,形成遮挡物检测器,该检测器的输出为遮挡物的检测框；输入待处理图像,利用所述目标检测器对该图像进行目标检测,从而分割出含有目标物体的图像,之后利用所述遮挡物检测器对含有目标物体的图像进行遮挡物检测,如果没有遮挡物则输出0％,否则对遮挡物进行边缘检测计算出遮挡物所占的像素个数,再结合所述各类物体的基准值得到的被遮挡物所占像素个数从而计算出遮挡物的遮挡比例。</td>   <td>G06K9/34;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵慧英;              林斯颖;              杨跃东;              吴卓;                   刘海晴       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种基于深度学习的乳腺癌病灶自动标注方法及装置</td>   <td>广东省</td>   <td>CN113469229A</td>   <td>2021-10-01</td>   <td>本发明提供了一种基于深度学习的乳腺癌病灶自动标注方法及装置,方法包括：采集乳腺癌患者的MR图像；对从MR图像中提取出的增强图像进行勾画得到病灶区域,根据病灶区域提取出待处理训练图像数据和待处理测试图像数据；根据待处理训练图像数据对预设的深度学习模型进行模型训练；将待处理测试数据输入至训练完成后的深度学习模型中进行预测,得到乳腺癌病灶的自动标注结果；采用交叉验证方法对深度学习模型进行验证并优化。本发明通过结合二维卷积和CLSTM处理三维乳腺MR影像,从而提高对乳腺癌病灶标注的准确性,同时采用交叉验证方法对深度学习模型进行验证以提高预测的真实性,进而能够为乳腺癌新辅助治疗患者的临床个体化精准诊疗提供理论依据。</td>   <td>1.一种基于深度学习的乳腺癌病灶自动标注方法,其特征在于,包括：采集乳腺癌患者的MR图像；提取所述MR图像中的增强图像,并对所述增强图像中的肿物边缘进行勾画得到病灶区域,根据所述病灶区域提取出待处理训练图像数据和待处理测试图像数据；对所述待处理训练图像数据进行图像预处理后输入至预设的深度学习模型中进行模型训练,得到模型参数；对所述待处理测试数据进行图像预处理后输入至训练完成后的深度学习模型中进行预测,得到乳腺癌病灶的自动标注结果；基于所述自动标注结果,采用交叉验证方法对所述深度学习模型进行验证,并根据验证结果对所述深度学习模型进行优化。</td>   <td>G06K9/62;G06K9/00;G06N3/04;G06N3/08;G16H30/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林炯良;                   戴宪华       </td>   <td>中山大学</td>   <td>一种基于CRNN解决拼图任务的自监督学习方法</td>   <td>广东省</td>   <td>CN113469238A</td>   <td>2021-10-01</td>   <td>本发明提出了一种基于CRNN解决拼图任务的自监督学习方法,该方法包括：数据构建步骤,将图片统一放缩大小后划分为互不重叠的9块,重新排序后生成拼图任务的样本；拼图任务网络模型设计与训练步骤,使用拼图任务样本数据训练AlexNet与Bi-LSTM结合的网络,得到拼图任务网络模型权重；图像分类、目标检测与语义分割任务网络设计与训练步骤,使用ImageNet和PASCAL VOC数据集训练AlexNet、Fast-RCNN与FCN,得到其在图像分类、目标检测与语义分割任务上的性能表现。本发明涉及计算机视觉技术领域,设计了一种基于CRNN解决拼图任务的自监督学习方法,与现有的方法相比,本方法能够解决所有拼图类别,捕捉拼图块之间的位置关系,使得模型能够学习到更加通用的视觉特征。</td>   <td>1.一种基于CRNN解决拼图任务的自监督学习方法,其特征在于,所述方法包括下列步骤：S1、数据构建,使用全排列随机排序的方法,计算机生成数字1-9的全排列,对于ImageNet数据集中的图片,统一放缩大小为225×225,并分割成互不重叠的3×3块,拼图块的编号自上而下、自左向右对应为1-9,随机挑选9!排列方式中的一种作为标签,并依此重新排序拼图块作为样本；S2、拼图任务网络模型设计与训练,使用AlexNet作为基础结构,将其全连接层改为3层Bi-LSTM,得到拼图任务网络,将拼图任务训练样本输入网络,通过优化预测的拼图块位置标签与真实的拼图块位置标签之间的相似度,更新网络权重,实现拼图任务网络模型的收敛；S3、图像分类、目标检测与语义分割任务网络设计与训练,图像分类任务的网络模型为AlexNet,目标检测与语义分割任务的网络模型为以AlexNet作为基础结构的Fast-RCNN和FCN,使用从拼图任务中学习得到的模型参数进行初始化,在ImageNet和PASCAL VOC数据集上进行训练,得到收敛的图像分类、目标检测与语义分割网络模型,及它们的性能表现。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;                   全绍军       </td>   <td>长视科技股份有限公司;中山大学</td>   <td>基于数据仿真的视频超分辨方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113469884A</td>   <td>2021-10-01</td>   <td>本发明公开了一种基于数据仿真的视频超分辨方法。包括：采集高分辨率视频与低分辨率目标视频；对低分辨率目标视频的模糊核、噪声进行采样；利用模糊核对高分辨率视频进行模糊并添加噪声,构建出仿真视频数据集；构建超分辨率网络模型,并利用仿真视频数据集进行训练；利用训练好的超分辨率网络模型对低分辨率目标视频进行超分辨重建,生成需要的超分辨率视频。本发明还公开了一种基于数据仿真的视频超分辨系统、计算机设备及计算机可读存储介质。本发明通过数据仿真的方法,采用对抗生成网络以及统计的方式对目标低分辨率数据集的特征进行采样和估计,能生成更加符合实际条件的低分辨率视频的训练数据,提高了超分辨率的效果。</td>   <td>1.一种基于数据仿真的视频超分辨方法,其特征在于,所述方法包括：采集高分辨率视频数据集以及待进行超分辨处理的低分辨率目标视频数据集；采用生成对抗网络对所述低分辨率目标视频数据集的模糊核进行采样,采用统计的方法对所述低分辨率目标视频数据集的噪声进行采样；利用所述采样得到的模糊核对所述高分辨率视频数据集进行模糊,并利用所述采样得到的噪声对所述高分辨率视频数据集添加噪声,构建出仿真视频数据集；构建视频超分辨率网络模型,并利用所述仿真视频数据集对该视频超分辨率网络模型进行训练；利用训练好的视频超分辨率网络模型对所述低分辨率目标视频数据集进行超分辨重建,生成需要的超分辨率视频。</td>   <td>G06T3/40;G06T5/50;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         麦庆云;              李冠彬;              高峰;              周灿权;              颜鹏翔;              陈方莹;              谢翔;              丁晨晖;                   徐艳文       </td>   <td>中山大学附属第一医院</td>   <td>一种胚胎发育潜能预测方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113469958A</td>   <td>2021-10-01</td>   <td>本发明涉及医疗人工智能技术领域,尤其涉及一种胚胎发育潜能预测方法、系统、设备及存储介质,包括：将所述胚胎初始图像输入囊胚预测模型,得到胚胎特征向量；将所述胚胎特征向量输入双向长短期记忆网络,得到胚胎发育特征；基于跨模态特征融合机制,根据临床数据及所述胚胎发育特征,得到融合特征；将所述融合特征输入第一多层感知器,预测得到胚胎妊娠率。本发明通过分析早期拍摄的多焦段胚胎视频,利用多焦段选择模型以及时间转移模型得到具有时空特性的融合特征,从而实时预测体外培养的胚胎妊娠率,提高了预测的准确度；同时本发明通过预测囊胚形成概率以及整倍体概率,辅助医生进行早期胚胎筛选,从而减少人力成本。</td>   <td>1.一种胚胎发育潜能预测方法,其特征在于,包括以下步骤：对同一胚胎的多焦段的胚胎图像进行预处理,得到胚胎初始图像；将所述胚胎初始图像输入囊胚预测模型,得到胚胎特征向量；将所述胚胎特征向量输入双向长短期记忆网络,得到胚胎发育特征；基于跨模态特征融合机制,根据临床数据及所述胚胎发育特征,得到融合特征；将所述融合特征输入第一多层感知器,预测得到胚胎妊娠率；所述囊胚预测模型的网络结构包括依次连接的卷积层、第一残差块、多焦段特征选择模型、第二残差块、第三残差块、第四残差块、第一全连接层和第二全连接层；其中,所述第一至第四残差块均嵌入了时间转移模块,所述多焦段特征选择模型包括通道注意力模块、深度非局部模块。</td>   <td>G06T7/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张燕;              柯戈扬;              潘炎;                   印鉴       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种基于张量奇异值分解的多视图谱聚类算法</td>   <td>广东省</td>   <td>CN108734187B</td>   <td>2021-09-28</td>   <td>本发明提供一种基于张量奇异值分解的多视图谱聚类算法,该算法用三阶张量表示所有视图数据的概率转移矩阵。由于张量具有横向、纵向、竖向三个方向的低秩性,本发明采用基于张量奇异值分解(Tensor-SVD)的多重秩(multi-rank)来表征该张量在各个维度上的低秩性。因为Tensor-SVD分解基于tube卷积产生的,不仅能比其他张量分解方式和基于二维结构关系建模的方法更能充分表达在空间结构上的相关性,而且可通过傅里叶变换进行快速计算,提高计算效率。因此,基于Tensor-SVD张量分解进行建模,会更加科学、快速、高效,并且实验结果表明可有效地提高多视图聚类的效果。</td>   <td>1.一种基于张量奇异值分解的多视图谱聚类算法,其特征在于,包括以下步骤：S1：将每个视图通过高斯核表示得到各自的概率转移矩阵；S2：用一个张量表示所有视图的概率转移矩阵,每个张量的前片表示一个视图的概率转移矩阵,利用数据分布规律建模求解,得到一个概率转移矩阵L,其中其中n表示样本总数,m表示视图总数；S3：将概率转移矩阵L作为基于马尔可夫链的谱聚类算法的关键输入,计算得到谱聚类输出结果；所述步骤S2的具体过程是：S21：分析张量的数据分布规律,由于各个视图的数据在实际获取过程中都会受到噪声的干扰,必然包含了噪声,假设其中表示接近真实的概率转移矩阵组成的张量,ε表示噪声张量；S22：张量的3个维度都体现了低秩性,主要表现以下两方面：1)、如果一组对象可以聚成多个簇,那么属于同一个簇内的对象都是相似的,不同簇之间的对象差别比较大,由所有视图的概率转移矩阵组成的张量的各个前片表征了这一组对象之间的相似度,则的每个前片中属于同一簇内的行或列向量有相关性,进而行或列向量组的秩相对维度而言就会比较小,因此在横向和纵向上都是低秩的；2)、从不同角度对同一组对象进行观测获取的数据描述即特征集合会有一定的差异,但它们都表征了这一组对象之间的内部关系,即它们所呈现的内部关系都是相似的,由所有视图的概率转移矩阵组成的张量的各个前片表征了这一组对象之间的相似度,正是体现对象内部关系的数据,因此的各个前片都是相似的,表现了竖向低秩性；S23：张量每个前片是概率转移矩阵,则每个元素要必须大于等于零,并且前片的每行是一个概率分布,概率和为1,于是张量需要满足：                  其中,e为元素值全为1的列向量；S24：假设噪声的干扰是随机少量的,于是噪声张量ε是稀疏的,用L1-norm来表征；S25：利用S21-S24的分析结果可建立模型,得到优化目标：                                    其中,λ是一个折中因子,n-i表示张量ε各个维度的大小；S26：对S25中优化目标求解后得到低秩张量的各个前片求和平均,得到概率转移矩阵L,即步骤S25中得到的优化目标还需进行IALM优化求解,具体过程如下：S251：对优化目标进行凸松弛处理,由于张量多重秩的凸包络是张量核范数得到：                                    S252：引入一个辅助变量将优化目标转化为：                                    S253：输入张量参数S254：初始化以下变量：                  S256：进行迭代过程,在每一次迭代中,更新变量并计算S252中优化目标的值,如果S252中优化目标的值小于阈值η,则停止迭代；S257：输出变量ε的值,即为S25优化目标的解。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李浚时;              李文军;                   陈龙       </td>   <td>中山大学</td>   <td>一种基于颜色特征和词袋特征的票据图像分类方法</td>   <td>广东省</td>   <td>CN108764302B</td>   <td>2021-09-28</td>   <td>本发明涉及图像的技术领域,更具体地,涉及一种基于颜色特征和词袋特征的票据图像分类方法。本发明利用了计算机视觉中经典的Bag of Words的思路,即先对训练样本中提取每张票据的SIFT特征点并生成128维特征描述符,然后进行K均值聚类获得K个视觉单词,并对每一类票据统计其视觉单词出现次数形成该类的视觉单词直方图作为特征,最后融入颜色特征形成总的特征向量,送入SVM分类器进行训练,得到票据分类器模型。因为词袋模型并没有用到票据图像的颜色特征,故本方法加入了图像的全局主颜色特征,进一步提升票据分类器的性能。本发明仅需极少量训练样本且无需人工设计额外特征就能训练出票据分类器模型,而且分类器分类速度快,准确率高。</td>   <td>1.一种基于颜色特征和词袋特征的票据图像分类方法,其特征在于,包括线下票据分类器训练和线上票据快速分类两大部分,线下票据分类器训练部分分为颜色特征提取和词袋模型训练两大部分：颜色特征提取包括：首先将训练集中的图像转换到HSV色彩空间,并对H分量进行量化生成颜色直方图,记录每类票据的主颜色并存入硬盘保存；词袋模型训练包括：对训练集的票据进行SIFT特征提取并进行K均值聚类得到K个聚类中心,并对每一类的票据进行特征量化生成词袋,并对每一类的票据训练样本进行视觉单词频数统计,生成该类的视觉单词直方图,并以此直方图生成相应的特征向量,以此特征向量为SVM分类器的输入进行训练,最后将训练好的模型参数文件存入硬盘保存；线上票据快速分类部分首先载入已经训练好的票据分类器模型和颜色分类参数文件,首先将待分类图像转换到HSV色彩空间,生成其颜色直方图并提取主颜色特征,用该特征判定该待分类图像的主颜色在已有票据类别是否存在且唯一,若是则直接输出分类结果,若不是则进入词袋模型分类过程；词袋模型分类过程首先提取待分类图像的SIFT特征并生成视觉单词,对视觉单词进行统计,得到视觉单词特征向量,并将此特征向量送入SVM进行分类,得到分类结果,然后对此分类结果根据颜色特征做二次判断,即根据该分类结果查询该结果对应的主颜色特征是否与获得的待分类图像的主颜色特征相同,若是则输出分类结果,若不同则表示分类结果错误,分类失败。</td>   <td>G06K9/62;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   刘凌毅       </td>   <td>中山大学</td>   <td>一种基于人脸关键点的深度伪造人脸视频检测方法、系统及介质</td>   <td>广东省</td>   <td>CN113449657A</td>   <td>2021-09-28</td>   <td>本发明公开了一种基于人脸关键点的深度伪造人脸视频检测方法、系统及介质,方法包括：从视频数据集构造训练集和测试集,对视频进行分帧并根据人脸标记对视频帧图像提取人脸图像；对训练集和测试集的人脸图像提取人脸关键点的坐标；利用训练集的连续帧人脸关键点坐标作为特征,使用梯度下降法训练一个全连接神经网络,用于预测下一帧人脸关键点坐标；将预测得到的人脸关键点坐标和实际人脸关键点坐标构成特征向量输入SVM中训练得到一个分类模型；将测试集的特征向量输入到训练得到的分类模型中,实现对深度伪造人脸视频的检测。本发明结合深度学习和传统机器学习方法,所需计算资源少,对硬件要求低,具有较强的鲁棒性和准确率。</td>   <td>1.一种基于人脸关键点的深度伪造人脸视频检测方法,其特征在于,包括下述步骤：将含有真实和深度伪造人脸视频的数据集划分为训练集和测试集,对所述数据集分帧并根据人脸标记点获取人脸图像；提取训练集和测试集人脸图像中人脸关键点的坐标,得到人脸关键点坐标向量；利用训练集连续帧中人脸关键点坐标作为特征,输入到全连接神经网络中预测下一帧人脸关键点坐标,用梯度下降算法训练网络参数,并保存最优网络参数的全连接神经网络；将预测的下一帧人脸关键点坐标和实际的下一帧人脸关键点坐标构成特征向量,输入SVM中进行训练,得到一个二分类模型；将测试集连续帧中的人脸关键点坐标和全连接神经网络输出的预测坐标组成特征向量,输入到所述二分类模型中,判定视频真假。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         韩广云;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于深度学习的本征图像分解方法及装置</td>   <td>广东省</td>   <td>CN108416805B</td>   <td>2021-09-24</td>   <td>本发明公开一种基于深度学习的本征图像分解方法及装置,其中该方法包括在若干3D模型中选取3D模型加载入基于物理的渲染器,随机设置光照,任取视角渲染图片,并通过渲染器获取对应的反射成分和光照成分,以此重复操作,生成大批量的有标注本征图分解的数据集；利用所生成的数据集将全卷积神经网络训练成本征图分解网络；对本征图分解网络进行应用,由预测输出的分解结果,得到期望输出的分解目标。本发明提出的本征图分解方法允许通过图形渲染的方式获取大批量有标注数据集,通过训练深度神经网络,获取鲁棒性良好的分解模型；通过应用损失网络,进一步提高泛化性能并且避免了损失函数的设计困难。</td>   <td>1.一种基于深度学习的本征图像分解方法,其特征在于,包括如下步骤：S10在若干3D模型中选取3D模型加载入基于物理的渲染器,随机设置光照,任取视角渲染图片,并通过渲染器获取对应的反射成分和光照成分,以此重复操作,生成大批量的有标注本征图分解的数据集；S20利用所生成的数据集将全卷积神经网络训练成本征图分解网络,包括：S201计算像素误差：采用以衡量预测值和真实值之间像素误差,其中表示像素误差,是预测输出的分解结果,y是期望输出的分解目标,即生成的数据集对应的真实值,n是有效像素数,i是任意一个有效像素,λ∈(0,1),为权重,可调；S202计算特征误差：采用以用损失网络φ的第l层对应的特征图φ-l来衡量特征误差,其中表示特征的相似度,l是选取的网络层,φ-l为其对应的特征图,C-l为对应这个特征图的通道数,H-l为对应这个特征图的高度,W-l为对应这个特征图的宽度；S203计算风格相似度对应的误差：采用以通过Gram矩阵来衡量风格相似度,其中表示损失网络的第l层对应的Gram矩阵的第i行第j列上的元素,φ′-(l,i)表示特征图φ-l中的第i个通道对应的特征,并将这个矩阵φ-(l,i)按任意固定方式拉伸为向量,则风格相似度对应的误差如公式6所示：其中,表示风格相似度对应的误差,‖·‖-F表示求F-范数；S204结合特征误差和风格相似度对应的误差计算感知误差：采用其中,表示感知误差,L-f和L-s表示选用的用于衡量感知误差的激活层,w-1∈(0,1),为权重,可调；S205通过梯度对应的Frobenius范数的比值对误差进行加权,以平衡各误差所带来的梯度大小不平衡所造成的训练不稳定,采用训练全卷积神经网络ψ；S30对本征图分解网络进行应用,由预测输出的分解结果,得到期望输出的分解目标。</td>   <td>G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张志勇;              丘昌镇;              荣易成;              王鲁平;                   王亮       </td>   <td>中山大学</td>   <td>基于三色四灯标记识别的无人机姿态估计方法及系统</td>   <td>广东省</td>   <td>CN111784768B</td>   <td>2021-09-24</td>   <td>本发明实施例涉及一种基于三色四灯标记识别的无人机姿态估计方法及系统,通过在目标无人机的机翼和尾翼的尖端设置有四个信号灯作为信号标记,减少了目标无人机姿态变动过程中标志被遮挡的几率；四个信号灯使用三种颜色,提高了无人机飞行姿态估计的鲁棒性,通过对采集的目标无人机的图像进行处理,检测得到图像特征,在识别图像特征与信号灯对应关系后,得到信号灯的二维图像坐标,将信号灯的三维坐标和二维图像坐标输入姿态估计模型中得到目标无人机的位置以及姿态,实现无人机自动实时姿态估计。该方法易挑选避开背景的色调,降低了图像特征的识别难度,解决了现有对无人机飞行姿态估计方法稳定性低的问题。</td>   <td>1.一种基于三色四灯标记识别的无人机姿态估计方法,其特征在于,在目标无人机的机翼和尾翼的尖端设置有四个用于标记的信号灯,四个所述信号灯具有三种颜色,基于三色四灯标记识别的无人机姿态估计方法包括以下步骤：步骤S1.获取采集设备采集具有四个信号灯标志的目标无人机飞行状态的图像,在HSV颜色空间对所述图像进行处理,得到具有高亮度高饱和度的图像特征；步骤S2.根据四个所述信号灯三种颜色的色调从所述图像特征中提取与四个所述信号灯对应的连通域,识别所述连通域与四个所述信号灯一一对应关系,建立四个所述信号灯的二维图像坐标；步骤S3.基于目标无人机建立四个所述信号灯的三维坐标,将所述三维坐标和所述二维图像坐标输入姿态估计模型中,输出目标无人机的位置以及姿态；其中,所述姿态估计模型中设置有采集设备的参数。</td>   <td>G06T7/70;G06T7/187;G06T7/136;G06T7/90</td>  </tr>        <tr>   <td>中国专利</td>   <td>              郑永江       </td>   <td>中山大学附属第三医院(中山大学肝脏病医院);中山大学</td>   <td>一种血液肿瘤染色体核型自动分析方法及系统</td>   <td>广东省</td>   <td>CN113435285A</td>   <td>2021-09-24</td>   <td>本发明提供一种血液肿瘤染色体核型自动分析方法,包括以下步骤：S1：采集染色体图像；S2：对采集的染色体图像进行预处理；S3：根据预处理得到的染色体图像对染色体进行分割；S4：对分割完成的染色体进行特征参数的提取；S5：根据特征参数的提取结果,对染色体进行分类,完成染色体核型自动分析。本发明还提供一种血液肿瘤染色体核型自动分析系统,实现染色体核型分析的智能化,将细胞遗传学实验技术与先进的图像处理、图像分析等技术相结合,大大提高了诊断准确率及减少检测时间,大大增加了检测效率,有效克服现有技术存在的智能化程度不高且检测效率低的技术缺陷。</td>   <td>1.一种血液肿瘤染色体核型自动分析方法,其特征在于,包括以下步骤：S1：采集染色体图像；S2：对采集的染色体图像进行预处理；S3：根据预处理得到的染色体图像对染色体进行分割；S4：对分割完成的染色体进行特征参数的提取；S5：根据特征参数的提取结果,对染色体进行分类,完成染色体核型自动分析。</td>   <td>G06K9/00;G06K9/62;G06T7/12;G06T7/13;G06T7/136;G06T7/194</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              岳九涛;              魏朋旭;                   林倞       </td>   <td>中山大学</td>   <td>一种基于频域的真实图像超分辨鲁棒方法及装置</td>   <td>广东省</td>   <td>CN113436073A</td>   <td>2021-09-24</td>   <td>本申请实施例提供了一种基于频域的真实图像超分辨鲁棒方法及装置,所述方法包括：接收总图像数据,判断所述总图像数据是否为对抗样本的图像数据,在所述图像数据为对抗样本的图像数据时,将所述总图像数据发送至随机频域掩盖模块；将所述总图像数据转换为频域的第一图像数据,掩盖掉所述第一图像数据中的多个高频分量,并得到第二图像数据,将所述第二图像数据转换为时域中的第三图像数据,并将所述第三图像数据发送至真实超分辨模型；基于所述第三图像数据生成对应于所述总图像数据的具有更清晰的细节和更好的保真度的图像。</td>   <td>1.一种基于频域的真实图像超分辨鲁棒方法,其特征在于,所述方法包括：接收总图像数据,判断所述总图像数据是否为对抗样本的图像数据,在所述图像数据为对抗样本的图像数据时,将所述总图像数据或者图像特征数据发送至随机频域掩盖模块；将所述总图像数据或者图像特征数据转换为频域的第一图像数据,掩盖掉所述第一图像数据中的多个高频分量,并得到第二图像数据,将所述第二图像数据转换为时域中的第三图像数据,并将所述第三图像数据发送至真实超分辨模型,且频域掩盖模块嵌入到超分辨模型中；基于所述第三图像数据生成对应于所述总图像数据的具有更清晰的细节和更好的保真度的图像。</td>   <td>G06T3/40;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              李伟宏;                   李本超       </td>   <td>中山大学</td>   <td>基于全局-局部RGB-D多模态的手势识别方法</td>   <td>广东省</td>   <td>CN108388882B</td>   <td>2021-09-21</td>   <td>本发明公开了一种基于全局-局部RGB-D多模态的手势识别方法,本发明主要通过包括骨骼位置、RGB图像、深度图像和光流图像等数据模态对输入的手势视频进行表示,得到多模态的手势数据表示后,利用卷积神经网络和递归神经网络的方法把不同模态的手势数据分别进行特征表达,并且利用不同模态下得到的特征进行手势的分类。最终将不同模态下得到的不同类别的手势得分进行融合,得到最终基于多模态的手势分类结果。本发明可以应用于客户端或云端对用户输入的手势视频进行识别,通过手势的输入使计算机或手机软硬件做出对应的响应。</td>   <td>1.基于全局-局部RGB-D多模态的手势识别方法,其特征在于,包括下述步骤：S1、骨骼序列生成及基于骨骼数据的全局-局部手势识别：给定输入的RGB-D视频图片, 利用多人姿态估计方法估计出每帧图片中人体骨骼的坐标位置,并根据整个视频获得的上半身的骨骼点,利用长短时记忆网络对上半身的骨骼点特征进行时序建模和分类,得到基于全局骨骼的手势分类得分；S2、基于全局-局部的RGB-D模态手势识别：对于RGB数据和深度数据的全局手势表示,首先分别将T帧的RGB和T帧深度图在通道沿时间进行堆叠,分别得到堆叠后的RGB图和T帧深度图,并且对VGG16卷积神经网络的输入通道进行改进,使其能够接受对应通道数目的数据输入；通过卷积神经网络的特征提取处理,分别在堆叠的RGB数据和堆叠的深度图获得对应的全局RGB特征和全局深度特征；最后,利用神经网络的非线性分类方法分别获得基于全局的RGB手势分类得分和全局的深度手势分类得分；S3、基于全局-局部的RGB光流和深度光流模态手势识别；分别在RGB视频数据和深度视频数据中提取光流信号,从而分别获得RGB光流和深度光流图片数据,光流是一种记录像素运动的方式,其主要记录了每个像素沿时间帧之间的运动方向和强度；步骤S3中,利用TV-L1光流算法对光流图片进行计算,通过对RGB光流和深度光流的提取,分别获得全局和局部的RGB光流图片和全局和局部的深度光流图片,并且利用VGG16卷积神经网络对其进行分类,最终获得基于全局和局部的RGB光流的手势分类得分和,和基于全局和局部的深度光流的手势分类得分和；S4、多模态的手势分类得分融合；在获得骨骼、RGB图、深度图、RGB光流图和深度光流图5种不同的数据模态的全局和局部手势分类得分,,,,,,,,和后,其中,为局部骨骼的手势分类得分,为局部RGB图的手势分类得分,为局部深度图的手势分类得分；基于以上的手势分类得分进行平均,并且利用归一化函数进行类别得分的归一化,最终获得不同手势类别的概率。</td>   <td>G06K9/00;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗燕;              王学钦;                   吕林       </td>   <td>中山大学中山眼科中心;中山大学</td>   <td>眼底彩照视盘与黄斑定位识别方法</td>   <td>广东省</td>   <td>CN108416344B</td>   <td>2021-09-21</td>   <td>本发明公开了一种眼底彩照视盘与黄斑定位识别方法,通过对眼底彩照中各部位的自动定位以及测量,达到疾病预筛选的效果,将有病变嫌疑的图片自动筛选出,以供医生复查准确判断是否患病,减少医生工作量；并且其结果不依赖于医生经验,更加客观,能够快速有效地对眼底彩照中的视盘、视杯与黄斑进行定位识别,从而可以辅助诊断正常眼底、青光眼及异常发育的眼底等疾病,实现远程会诊的目的。</td>   <td>1.一种眼底彩照视盘与黄斑定位识别方法,其特征在于包括以下步骤：图片质量检测,输入原始图像,进行图像特征的提取,并对以决策树为基分类器的随机森林模型进行训练,使用随机森林模型对图片质量进行预测,检测出图片质量过关的眼底图像进行后续处理；图像预处理,在所有的图像中选择一张图片质量最好的,并提取其RGB三个轨道的灰度分布,将其作为标准图；视盘识别,包括以下步骤：初定位,首先将整张图片更亮的区域用阈值分割的方法提取出来,其余较暗区域利用均值填补,修改后的图片再次进行阈值切分,通过多次迭代,将高亮区域面积一步步减小,当感兴趣区域面积小于确定的阈值后,停止迭代,再对提取出的高亮区域进行筛选,提取出该感兴趣区域的中心并截取以供下一步分析；精确定位与平滑拟合：利用形态学处理方法先去掉噪音影响,然后对于图像进行阈值分割以得到相对不光滑的边界位置,然后对于边界位置进行椭圆拟合,最后将边界方程绘制在原图上；其中,所述图像特征的提取包括以下步骤：首先使用canny算子对图像进行边缘检测,再用中值滤波进行去噪处理,之后用去噪处理后的图,计算边缘总像素点的个数、边缘的总周长、边缘区域的最大长度、最大宽度、奇数链的链码数目、目标面积、矩形度、伸长度,然后提取图像的七个不变矩特征；每个图层提取5个判断清晰度的特征：灰度熵、Brenner梯度函数、方差函数、能量梯度函数、梯度函数；利用灰度直方图提取256个频率特征；将原本的RGB空间转换为HSV空间,计算色彩直方图,得到256个色彩与纹理特征。</td>   <td>G06K9/20;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         成慧;              申静怡;                   周佺       </td>   <td>中山大学</td>   <td>一种基于深度学习的智能物流仓库引导线视觉检测方法</td>   <td>广东省</td>   <td>CN108830171B</td>   <td>2021-09-21</td>   <td>本发明涉及检测方法的技术领域,更具体地,涉及一种基于深度学习的智能物流仓库引导线视觉检测方法。一种基于深度学习的智能物流仓库引导线视觉检测方法,包括训练阶段和测试阶段,所述的训练阶段包括：训练数据获取与标记、构建模型、模型训练、模型验证与对比、模型选取、模型转换；所述的测试阶段包括：输入数据、引导线检测、检测结果拟合。本发明提出的方法灵活性较高,而且可以根据不同的性能要求,修改用于检测的神经网络的卷积核大小以及深度,满足不同的精度要求和运行时间要求。</td>   <td>1.一种基于深度学习的智能物流仓库引导线视觉检测方法,其特征在于,包括训练阶段和测试阶段,所述的训练阶段包括：训练数据获取与标记、构建模型、模型训练、模型验证与对比、模型选取、模型转换；所述的测试阶段包括：输入数据、引导线检测、检测结果拟合；所述的训练阶段具体实施步骤为：S1.首先需要获取训练数据并对训练数据进行标记获取标记图；先利用树莓派进行实验场地实地数据采集,通过树莓派上自带Picamera进行视频捕捉,得到足够多的视频数据后,对视频数据进行分帧后即得到用于训练FCN的训练图片；S2.使用matlab实现数据标注脚本,脚本能自动获取目标图片所在文件夹下所有图片并显示,在显示出的图片上用描点的方式点出引导线区域的边缘轮廓,然后使用inpolygon函数对图片进行逐像素判断是否属于引导线区域轮廓多边形中,通过该方式对获取到的训练图片进行标记,标出训练图片中引导线所属区域,得到与训练图片等大小的标记图,作为训练数据的一部分,用于指明训练图片中引导线所在区域,使得FCN能在训练过程中提取学习该区域的特征；S3.通过计算明确构建出的全卷积网络的各层卷积层所使用的卷积核大小k及步长s、补零区域大小p的具体值,使用Pytorch框架完成FCN的整体构建；本方法中采用的卷积核大小均为5*5,卷积层后使用ReLU层进行激活,一个卷积层与一个ReLU层组合成一个卷积结构,两个卷积结构之后连接一个池化尺寸为2*2的最大池化层构成一个卷积块；本方法中共有3个卷积块,故经过卷积层和池化层的逐步提取特征后最终得到的特征图尺寸为原来的1/8；输入大小为h*w的数据,经过卷积：h-(new)＝(h-5+2*2)/1+1＝hw-(new)＝(w-5+2*2)/1+1＝w卷积层和激活层在设置合适的padding参数的情况下不会改变数据维度,特征图的尺寸仅通过之后的池化层缩小为输入的1/2；多层卷积和池化之后有dropout率为0.5的Dropout层,以0.5的概率丢弃部分神经元,增强模型表达能力,防止过拟合；然后分类器通过1*1的卷积核进行降维,将多通道信息整合,128通道转为2通道；由转置卷积恢复图像大小；使用的卷积核大小为10*10,步长为8,padding为1：                  Up-(out)＝Up-(in)*8通过转置卷积,将当前图像扩大8倍,恢复到240*320大小；为了获得概率分布,Sigmoid函数在最后一个输出层之后使用,输出2通道概率图；使用交叉熵作为损失函数,与标签图的ground truth比较,计算损失后反向传播,更新网络权重；S4.上一步骤中描述的构建及训练过程仅针对一组固定的超参数,实际上在实验过程中还需要调整超参数来获得更好的检测效果；超参数包含训练次数epoch,训练批大小batch-size,损失函数loss function和梯度更新方式；通过选取不同的超参数并进行组合,然后进行实验,之后使用验证数据对模型和超参数进行验证,选取检测效果最好的一组超参数作为最终使用的模型；S5.经上述步骤得到的模型仅为Pytorch模型,而本方法目的在于在嵌入式开发平台上实现基于深度学习的视觉检测模块,因此为适应树莓派的环境,需要将Pytorch模型转换为可部署在树莓派上的Caffe2框架可用的模型；本方法中采用ONNX工具,将pytorch模型pth文件转为onnx文件格式的ONNX模型,并将ONNX模型导入到Caffe2框架中,使得Caffe2框架能使用ONNX模型的结构和参数,并通过Caffe2完成对引导线的检测。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08;G06Q10/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              王健;              陈荣军;              谢舜道;              朱雄泳;                   曾衍瀚       </td>   <td>中山大学;广东顺德中山大学卡内基梅隆大学国际联合研究院;佛山市顺德区中山大学研究院</td>   <td>一种基于区块链技术的数字版权保护方法</td>   <td>广东省</td>   <td>CN108846776B</td>   <td>2021-09-21</td>   <td>本发明公开一种基于区块链技术的数字版权保护方法,包括：构建P2P网络；设计加密验证模块；构建用户地址模块；交易模块设计；设计节点之间共识机制；区块链数据存储设计。本发明通过采用区块链技术使得版权作品登记实现自我监管,去中心化极大的降低了管理成本,提高登记数据库的安全性。</td>   <td>1.一种基于区块链技术的数字版权保护方法,其特征在于,包括如下步骤：S10建立基于区块链技术的版权保护系统总体功能框架,该框架包括核心层、扩展层和应用层,其中核心层包括P2P网络模块、加密验证模块、用户地址模块、交易模块、区块链数据存储模块、共识机制模块；S20生成基于区块链技术的版权保护系统的网络模块,建立去中心的P2P网络,形成一个互联互通的网络；S30生成基于区块链技术的版权保护系统的加密验证模块,构建一个无需人工验证、高度可信的底层网络；S40生成基于区块链技术的版权保护系统的交易模块,并基于S20和S30生成交易信息,实现电子书版权登记和版权交易；S50生成基于区块链技术的版权保护系统的用户地址模块,利用S30的加密验证模块为用户生成加密的Hash地址,通过S40的交易模块拓展和关联其他功能；S60生成基于区块链技术的版权保护系统的区块链数据存储模块,记录每一个区块,区块包含交易信息,并通过当前区块记录着前一条记录的信息,通过加密信息字段,使区块中的交易信息具有签名认证作用；具体包括：S601建立基于区块链技术的版权保护方法的区块链存储模块；S602记录每一个区块,区块包含交易信息；S603通过当前区块记录着前一条记录的信息,通过加密的信息字段进行签名认证；S604通过自引用的数据库表,每条记录代表一个区块,这条区块记录着它前面一条记录的信息,由此任何一条记录可往前顺序追溯查询到第一条记录；具体包括：S6041保存创世区块,运行时直接写入数据库,保证每一个客户端有一个可信、安全的根区块；S6042加载本地区块,每个节点都需要首先加载验证本地区块链,确保其没有被篡改,在软件初始化的过程中进行；S6043验证本地区块,逐个加载区块并验证,首先追溯前一区块；然后验证块签名,防止块内容被篡改,如果验证失败,就要终止整个验证过程,删除该块及其后面的块；再验证块时段,防止块位置被篡改；最后验证交易；S6044创建新区块,获取未确认的交易,并再次验证,并通过获取块时段数据为区块提供密钥对、时间戳受托人列表；S6045产生区块链分叉；S6046同步区块链,并解决分叉；S70生成基于区块链技术的版权保护系统的共识机制模块,使得区块链网络对具有记账权节点的选择达成共识,产生的区块写入节点区块链存储模块中；具体包括：S701用户注册为受托人,并接受投票；S702维持循环,调整受托人；根据设定不同的块周期来调整区块的循环周期,每个循环周期调整一次受托人名单；奖励周期：根据区块链高度,设置里程碑时间,在某个时间点调整区块奖励；S703循环产生新区块,广播至网络各节点。</td>   <td>G06Q50/18;G06Q40/04;G06F21/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任江涛;                   赖超杰       </td>   <td>中山大学</td>   <td>基于时空的警情预测模型的建立方法、装置和存储介质</td>   <td>广东省</td>   <td>CN109472419B</td>   <td>2021-09-21</td>   <td>本发明公开了一种基于时空的警情预测模型的建立方法,所述基于时空的警情预测模型的建立方法包括以下步骤：获取多个目标警情文本,并确定各个所述目标警情文本中警情对应的目标犯罪地点；根据各个所述目标犯罪地点确定犯罪风险区域；根据所述犯罪风险区域对应的各个警情、所述警情的犯罪类型以及所述警情的犯罪时间点,建立所述犯罪风险区域对应的警情预测模型。本发明还公开一种基于时空的警情预测模型的建立装置和存储介质。本发明建立的警情预测模型的警情预测准确性较高。</td>   <td>1.一种基于时空的警情预测模型的建立方法,其特征在于,所述基于时空的警情预测模型的建立方法包括以下步骤：获取多个目标警情文本,并确定各个所述目标警情文本中警情对应的目标犯罪地点；根据各个所述目标犯罪地点确定犯罪风险区域；根据所述犯罪风险区域对应的各个警情、所述警情的犯罪类型以及所述警情的犯罪时间点,建立所述犯罪风险区域对应的警情预测模型；所述确定各个所述目标警情文本中警情对应的目标犯罪地点的步骤包括：采用第一地点提取算法以及第二地点提取算法,分别在各个所述目标警情文本提取犯罪地点,以得到所述第一地点提取算法对应的第一集合以及所述第二地点提取算法对应的第二集合；根据所述第一集合以及所述第二集合中的各个犯罪地点,确定各个所述目标犯罪地点；所述第一地点提取算法为正则匹配算法,所述第二地点提取算法为命名实体识别算法。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         原尉峰;              郭佳明;              杨红杰;                   苏卓       </td>   <td>中山大学</td>   <td>一种基于着装解析及人体检测的多人服装检索方法</td>   <td>广东省</td>   <td>CN107818489B</td>   <td>2021-09-17</td>   <td>本发明实施例公开了一种基于着装解析及人体检测的多人服装检索方法,其中,该方法包括：对街拍图像进行多人着装解析处理；对图像中的人脸进行识别、计算,获取人脸位置的数据；结合多人着装解析数据集通过双通道人体检测神经网络,转化出对应的人体分布热度检测图；将其进行离散化处理；用户可以通过前端展示中选择衣物,后端进行数据检索,得出检索结果。对实施本发明实施例,能够满足用户便捷地利用街拍的图像去检索网上商城相似服装的需求。</td>   <td>1.一种基于着装解析及人体检测的多人服装检索方法,其特征在于,所述方法包括：对街拍图像进行多人着装解析处理,分割图像中的衣物,获取多人着装解析数据集；对图像中的人脸进行识别,计算得出图像中人脸的数据；获取人脸数据及所述街拍图像,逐个输入双通道人体检测神经网络当中,得出每个人脸对应人体的分布热度检测图；对人体分布热度检测图设定一定阈值,进行离散化处理,将离散化处理后的人体分布热度检测图点乘多人着装解析数据集,获得所有服装区域；将服装区域在前端展示给用户,用户根据需求选择需要检索的衣物；后端接收前端传输过来的需检索衣物的数据,逐个输入到检索系统中,获得检索衣物；其中,所述得出每个人脸对应人体的分布热度检测图的具体步骤,包括：获取识别计算后的人脸数据,选出一条作为此次人体检测的目标；构建一个长宽与所述街拍图像的二维矩阵为人脸数据热度检测图,默认值为0,对应人脸区域设置为1；获取人脸数据热度检测图与所述街拍图像,输入到双通道人体检测神经网络当中,由双通道人体检测神经网络输出与人脸数据对应的人体分布热度检测图,该热度检测图为一个二维矩阵,其大小与街拍图像一致,每个元素代表对应位置输入该人物身体的概率；根据人体分布热度检测图以及对应的人脸数据,进行记录并检查是否存在未使用的人脸数据,如果有则返回重新识别计算；否则结束此步骤；其中,所述对人体分布热度检测图设定一定阈值,进行离散化处理,将离散化处理后的人体分布热度检测图点乘多人着装解析数据集,获得所有服装区域,包括：设定阈值为a,判断人体分布热度检测图的每一个元素是否大于此阈值,若大于a,则重新赋值为1,否则赋值为0；将离散化后的所有人体分布热度检测图分别点乘多人着装解析数据集,表达式为：C-(ij)＝H-i·L(I＝c-j)其中C-(ij)表示第i个人体的第j件服装的分布检测图,H-i表示第i个人体分布热度检测图；I为所述街拍图像；L(I＝c-j)为指示函数,作用是将街拍图像I中属于服装c-j的区域设置为1,否则为0。</td>   <td>G06Q30/06;G06K9/34;G06F16/583</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              黄培根;              王广聪;                   谢晓华       </td>   <td>中山大学</td>   <td>一种结合表观特征和时空分布的双流网络行人重识别方法</td>   <td>广东省</td>   <td>CN109325471B</td>   <td>2021-09-17</td>   <td>本发明公开了一种结合表观特征和时空分布的双流网络行人重识别方法,方法主要包括下述步骤：使用深度神经网络提取行人图像的表观特征并计算图像对的表观相似度；通过基于高斯平滑的统计方法学习训练数据集的时空分布模型；通过基于逻辑平滑的联合度量方法对表观相似度和时空概率进行联合计算得出最终相似度；将最终相似度进行排序得到行人重识别结果。主要贡献包括：(1)提出一种结合表观特征和时空分布的双流网络行人重识别框架；(2)提出新的基于高斯平滑的时空分布学习方法。(3)提出新的基于逻辑平滑的相似性联合度量方法。实验结果表明,本方法在DukeMTMC-reID和Market1501数据集上的Rank1准确率分别从83.8％和91.2％提高到94.4％和98.0％,较其他方法有非常大的性能提升。</td>   <td>1.一种结合表观特征和时空分布的双流网络行人重识别方法,其特征在于,包括步骤：表观特征上,使用深度神经网络算法提取每个行人图像的表观特征向量,计算出所有行人图像对之间的表观相似度,所述图像对是指检索图像和数据库图像；时空分布上,对于训练数据集,以一时间差单位区间统计每组摄像头对的原始时间差概率分布模型,得到n*n个时间差概率统计直方图,n为摄像头个数,然后对每个时间差概率统计直方图进行高斯平滑,得到时空分布模型；由时空分布模型求出检索图像和数据库图像之间的时空概率；时空分布模型的构建步骤是：步骤2.1,假设训练数据集中一共有n个摄像头,对于摄像头对C-i和C-j,i＝1,2,...,n,j＝1,2,...,n,以Δt为一个单位区间,统计训练数据集中同一行人先后出现在摄像头C-i和C-j的时间差概率分布,从而得到n*n个原始时间差概率分布直方图步骤2.2,对于摄像头对C-i和C-j的原始时间差概率分布直方图在直方图中的每一个单位区间叠加一个以该单位为对称中心的高斯函数,在所有单位区间将原始概率与所有高斯函数在此区间的函数值相加,再除以归一化值得到高斯平滑后的时空分布模型；原始时间差概率分布直方图的计算方法是：                                    其中：k代表统计直方图中第k个单位区间,记Δt为统计直方图的时间差单位区间,则t-j-t-i∈((k-1)Δt,kΔt)；          代表摄像头C-i到摄像头C-j中第k个单位区间的频数；y＝1代表统计的行人对频数是指同一行人；          代表摄像头C-i到摄像头C-j的时间差概率分布直方图；高斯平滑后的时空分布模型获取方法如下：                  z＝∑-kP(y＝1|k,c-i,c-j)                  其中：          代表关于摄像头对C-i和C-j的原始时间差概率分布模型在第k个时间差单位区间的时空概率；K为高斯核函数,用于平滑原始时间差概率分布模型；Z为归一化参数；P(y＝1|k,c-i,c-j)代表关于摄像头对C-i和C-j的原始时间差概率分布模型经过高斯平滑后,在第k个单位区间的时空概率；对表观相似度和时空概率进行逻辑平滑,得到平滑后的表观相似度和时空概率；将平滑后的表观相似度和时空概率进行联合计算得到最终的行人图像对相似度,对行人图像对相似度排序得到行人重识别结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢晓华;              许伟鸿;                   赖剑煌       </td>   <td>中山大学</td>   <td>基于生成对抗网络的人脸光照迁移方法</td>   <td>广东省</td>   <td>CN110706152B</td>   <td>2021-09-17</td>   <td>本发明公开了一种基于生成对抗网络的人脸光照迁移方法,包括步骤：(1)获取正面人脸图像的样本数据；(2)从样本数据中选择两张图像分别作为目标人脸图像和参考光照图像,作为生成器的输入,生成器输出重光照图像,判别器将真实图像和重光照图像的误差反馈给生成器,分类器将目标人脸图像和重光照图像的身份信息的误差反馈给生成器。生成器、判别器和分类器进行反复对抗训练,得到最优人脸光照迁移模型；(3)人脸光照迁移。本发明采用生成对抗网络架构及损失函数,利用注意力机制使得模型能够有效地处理对局部光照细节。网络训练中不需要使用人脸的3D信息,也不需要对齐人脸,进行端到端训练,具有很好的重光照结果。</td>   <td>1.基于生成对抗网络的人脸光照迁移方法,其特征在于,(1)获取正面人脸图像的样本数据；(2)生成对抗网络的对抗训练：从样本数据中选择两张图像分别作为目标人脸图像和参考光照图像,将上述两张图像作为生成器的输入,生成器输出重光照图像；判别器将目标人脸图像和当前生成的重光照图像的误差反馈给生成器,分类器将目标人脸图像和当前生成的重光照图像的身份信息的误差反馈给生成器；将当前生成的重光照图像作为新的当前目标人脸图像,将与原目标人脸具有相同光照效果的图像作为新的参考光照图像,重新输入到生成器中,生成器输出重构图像,将原目标人脸图像和重构图像的误差反馈给生成器,这个误差称之为循环一致性损失；循环一致性损失的计算方式为：(2-3-1)PSNR损失：                  其中,x,y为给定的两张图像,PSNR(x,y)表示x和y之间的相似度,MAX表示x,y中最大的像素值；(2-3-2)SSIM损失：                  其中,x,y分别表示两张图像,μ-x,μ-y分别表示图像x,y的均值,σ-x,σ-y分别表示图像x,y的方差,σ-(xy)表示图像x,y之间的协方差；C-1,C-2为两个常数,以避免除零的情况出现；每次计算的时候都从图像上取一个子窗口,然后不断滑动子窗口,最后取子窗口的平均值作为全局的SSIM；(2-3-3)attention-SSIM损失：                  其中,M是子窗口的总数,SSIM-i是第i个子窗口SSIM值,att-i表示第i个子窗口的权值,权值越高表示越重要；生成器、判别器和分类器进行反复对抗训练,得到最优人脸光照迁移模型；(3)人脸光照迁移：利用训练好的最优人脸光照迁移模型进行人脸光照迁移,输入目标人脸图像和参考光照图像,即可输出光照迁移后带有参考光照的目标人脸图像。</td>   <td>G06T3/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              吴至斌;                   王国倩       </td>   <td>中山大学</td>   <td>一种低频超宽带合成孔径雷达图像叶簇覆盖目标检测方法</td>   <td>广东省</td>   <td>CN113408366A</td>   <td>2021-09-17</td>   <td>本发明提供一种低频超宽带合成孔径雷达图像叶簇覆盖目标检测方法,该方法通过随机切割和数据增广技术生成具有一定代表性的低频超宽带合成孔径雷达叶簇覆盖目标的数据集以及相应标注；接着设计卷积神经网络用于预测叶簇覆盖目标,输出为与输入图像相同尺寸的预测图像；然后利用生成的数据集对设计的神经网络进行训练,网络收敛时停止训练；最后基于网络输出结果的特点,设计针对网络输出图像的后处理流程,包括方差滤波与二值化操作,得到最终的预测结果。本发明方案适用于低频超宽带合成孔径雷达图像叶簇覆盖目标的检测,能够保证一定精度下快速检测多个目标。</td>   <td>1.一种低频超宽带合成孔径雷达图像叶簇覆盖目标检测方法,包括以下步骤：S1：根据应用场景生成对应数据集；S2：构建神经网络；S3：利用步骤S1中的数据集训练步骤S2中的神经网络；S4：利用训练好的神经网络初步预测目标位置；S5：对步骤S4的输出结果进行处理得到最终预测结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         秦宗;              邹国伟;              罗青云;              杨文超;              邱志光;              吴梓毅;                   杨柏儒       </td>   <td>中山大学</td>   <td>一种基于深度学习的色序型显示器控制方法及装置</td>   <td>广东省</td>   <td>CN113408655A</td>   <td>2021-09-17</td>   <td>本申请公开了一种基于深度学习的色序型显示器控制方法及装置,包括：对输入的单帧图像,基于所述单帧图像的图像特征以及色序型显示器的刷新率,确定与其匹配的驱动算法；采用所述驱动算法计算得到所述单帧图像在各个场中的理想背光分布；根据所述理想背光分布,结合所述色序型显示器的光扩散特性,计算出所述单帧图像在各个场中的模拟背光分布和透射率；根据所述模拟背光分布和透射率,计算出各个场的图像。本申请针对每一帧图像,根据图像内容中所包含的具体图像特征,一一为其确定相匹配的驱动算法,以抑制图像在色序型显示器中所产生的色分离现象,降低了图像的色分离程度,使得每一帧图像在色序型显示器中均能获得较好的色分离抑制效果。</td>   <td>1.一种基于深度学习的色序型显示器控制方法,其特征在于,包括：对输入的单帧图像,基于所述单帧图像的图像特征以及色序型显示器的刷新率,采用深度学习的方法确定与所述单帧图像匹配的驱动算法；采用所述驱动算法计算得到所述单帧图像在各个场中的理想背光分布；根据所述理想背光分布,结合所述色序型显示器的光扩散特性,计算出所述单帧图像在各个场中的模拟背光分布和透射率；根据所述模拟背光分布和透射率,计算出各个场的图像。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G09G3/34;G09G3/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李占潮;              邹小勇;                   戴宗       </td>   <td>广东药科大学;中山大学</td>   <td>一种药物-疾病关系识别方法、系统和装置</td>   <td>广东省</td>   <td>CN108062556B</td>   <td>2021-09-14</td>   <td>本发明公开了一种药物-疾病关系识别方法、系统及装置。所述方法包括获取待识别药物-疾病关系对对应的疾病关系二维矩阵和/或灰度图,将其输入到卷积神经网络中进行处理,得到识别结果。所述系统包括用于获取药物-疾病关系二维矩阵和/或灰度图的获取模块,以及用于将药物-疾病关系二维矩阵和/或灰度图输入到卷积神经网络中进行处理,从而输出识别结果的处理模块。所述装置包括存储至少一个程序的存储器和执行至少一个程序的处理器。本发明利用卷积神经网络的处理功能,快速高效地识别药物-疾病治疗关系,识别潜在的药物-疾病相互作用,开展先导化合物识别和药物重定位研究。本发明广泛用于计算机辅助药物设计领域。</td>   <td>1.一种药物-疾病关系识别方法,其特征在于,包括以下步骤：获取待识别药物-疾病关系对所对应的药物-疾病关系二维矩阵和/或灰度图；将获得的药物-疾病关系二维矩阵和/或灰度图输入到卷积神经网络中进行处理,从而输出药物-疾病关系识别结果；所述将获得的药物-疾病关系二维矩阵和/或灰度图输入到卷积神经网络中进行处理这一步骤之前,设有建立卷积神经网络的步骤,所述建立卷积神经网络的步骤具体包括：获取药物-疾病数据库中的药物-疾病关系对所对应的药物-疾病关系二维矩阵、灰度图和药物-疾病关系值,利用所得的药物-疾病关系二维矩阵和灰度图构建输入数据正样本,利用所得药物-疾病关系值构建输出数据正样本；获取药物-疾病数据库外的药物-疾病关系对所对应的药物-疾病关系二维矩阵、灰度图和药物-疾病关系值,利用所得药物-疾病关系二维矩阵和灰度图构建输入数据负样本,利用所得药物-疾病关系值构建输出数据负样本；抽选输入数据正样本和输入数据负样本从而分别构建训练输入数据集和测试输入数据集；抽选输出数据正样本和输出数据负样本从而分别构建训练输出数据集和测试输出数据集；用训练输入数据集以及训练输出数据集训练卷积神经网络,用测试输入数据集以及测试输出数据集测试卷积神经网络；将训练和测试结束后得到的卷积神经网络作为所需建立的卷积神经网络。</td>   <td>G06K9/62;G06N3/04;G06N3/08;G16H20/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁北辰;              陈皓;              代泽瑞;              黄庆庆;              刘德斌;              金蕾;                   李锦钊       </td>   <td>中山大学</td>   <td>一种基于共享单车调配优化的目标检测方法</td>   <td>广东省</td>   <td>CN113392799A</td>   <td>2021-09-14</td>   <td>本发明公开了基于摄像头的共享单车检测管理系统与方法,通过数据收集单元从道路监控系统中采集共享单车停放的现场信息,以及将采集到的共享单车停放的现场信息传递给图像处理模块；图像处理单元根据所述数据收集模块采集的共享单车停放的现场信息,识别单车停放信息；再将所述图像处理单元识别的单车停放信息输出至政府单位和/或单车公司以进行辅助决策单车的调度策略。通过本发明解决了共享单车造成的交通隐患和共享单车违规造成的财产损失,提高了利用率；以及通过合理管制,减少了共享单车浪费造成的环境污染。</td>   <td>1.一种基于摄像头的共享单车检测管理系统,其特征在于包括：数据收集单元,用于从道路监控系统中采集共享单车停放的现场信息,以及将采集到的共享单车停放的现场信息传递给图像处理模块；图像处理单元,用于根据所述数据收集模块采集的共享单车停放的现场信息,识别单车停放信息；输出单元,用于将所述图像处理单元识别的单车停放信息输出至政府单位和/或单车公司以进行辅助决策单车的调度策略。</td>   <td>G06K9/00;G06Q10/04;G06Q10/06;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈深进;                   欧勇辉       </td>   <td>中山大学南方学院</td>   <td>一种基于云平台的短时公交客流预测系统及预测方法</td>   <td>广东省</td>   <td>CN113393012A</td>   <td>2021-09-14</td>   <td>本发明公开了一种基于云平台的短时公交客流预测系统及预测方法,包括短时公交客流预测系统、公交客流OD推导、智能公交客流统计终端,智能公交客流统计终端与短时公交客流预测系统采用无线方式连接；本发明利用无监督特征学习理论的公交站点客流预测,分析站点客流分布,挖掘公共交通出行特征,为市民提供实时、准确、有效的公交出行服务,既能够解决大量的客流转移对城市交通造成的压力,减少全社会的能源消耗,同时也能增加公交公司的营运收入。</td>   <td>1.一种基于云平台的短时公交客流预测系统,其特征在于,包括短时公交客流预测系统、公交客流OD推导和智能公交客流统计终端,所述智能公交客流统计终端与短时公交客流预测系统采用无线方式连接；所述短时公交客流预测系统包括云端控制主机、公交基础信息数据库、公交车辆动态信息数据库、公交客流信息数据库、公交客流OD推导、公交客流预测数据库。</td>   <td>G06Q10/04;G06Q10/06;G06N3/04;G06N3/08;G06F16/25;G06F16/27</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              杨明健;                   周凡       </td>   <td>中山大学</td>   <td>一种基于图注意力网络的服装属性识别方法与系统</td>   <td>广东省</td>   <td>CN113378962A</td>   <td>2021-09-10</td>   <td>本发明公开了一种基于图注意力网络的服装属性识别方法与系统。包括：对服装数据集的属性关系进行分析,构建属性关系邻接矩阵,从数据集中筛选出输入图像和对应的服装属性标签,进行数据增强处理,其次提取特征,包括提取服装图像的整体视觉特征、属性值视觉特征和属性的关系特征,最后将属性值视觉特征与属性的关系特征进行特征融合,输入至全接网络,输出属性类别预测得分,即属性识别分类结果,计算属性关系图注意力网络最终的输出结果与服装属性标签交叉熵损失函数,利用梯度下降的方法训练整个属性关系图注意力网络。本发明基于计算机视觉的服装属性识别技术,使用图注意力网络充分挖掘属性的内在联系,提高网络识别准确率。</td>   <td>1.一种基于图注意力网络的服装属性识别方法,其特征在于,所述方法包括：对服装数据集的属性关系进行分析,为每个不同的属性组构建属性关系邻接矩阵；从所述服装数据集中筛选出输入图像与其对应的服装属性标签,并将输入图像进行统一尺寸和数据增强处理；将所述输入图像输入到在图像分类数据集ImageNet上预训练好的ResNet模型中,提取服装图像的整体视觉特征；将所述整体视觉特征再分别经过M个全连接层,为M个所述属性组提取对应的属性视觉特征,分出的每一个分支就是一个属性识别网络；将所述属性视觉特征进行转化、切片分割,得到属性值视觉特征；将所述属性值视觉特征输入至属性关系图注意力网络中,得到属性的关系特征；将所述属性值视觉特征与所述属性的关系特征进行特征融合后,输入至属性分类器中,输出最终的属性识别分类结果；计算所述属性关系图注意力网络最终的输出结果与所述服装属性标签交叉熵损失函数,利用梯度下降的方法训练整个所述属性关系图注意力网络,得到训练好的属性关系图注意力网络；输入待处理的服装图像到所述训练好的属性关系图注意力网络,获得需要的服装属性识别结果。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王文标;                   林瀚       </td>   <td>中山大学</td>   <td>基于iDistance算法的不确定数据序列K近邻方法及系统</td>   <td>广东省</td>   <td>CN113378995A</td>   <td>2021-09-10</td>   <td>本发明提出基于iDistance算法的不确定数据序列K近邻方法及系统,结合了iDistance索引为样本扫描算法所需读取的不确定序列数据建立索引；索引后,本方案可以按需对样本数据进行读取,有效提升了现有样本扫描算法在大规模不确定序列数据库上进行K近邻查询的外存性能和速度。</td>   <td>1.基于iDistance算法的不确定数据序列K近邻方法,其特征在于,包括以下步骤：S1：获取待计算的数据集,包括所有不确定序列和查询序列；S2：基于iDistance算法选取一组参考点,为数据集建立索引；S3：计算查询序列与每个参考点的距离；S4：初始化当前距离d和选取距离增量deld；S5：新建以距离distance为键值的小顶堆heap1和heap2,heap1用于维护查询序列的距离d范围内的样本的信息,heap2用于维护已从索引中读取并计算与查询序列间距离但不在距离d范围内的样本的信息；S6：构建第一数组、第二数组和控制变量,并对第一数组、第二数组和控制变量进行初始化；S7：构建数据结构并进行初始化；S8：对heap1、heap2、第一数组、第二数组、数据结构、控制变量进行循环计算更新,最终获取数据结构中维护的答案。</td>   <td>G06K9/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   韦舒心       </td>   <td>中山大学</td>   <td>基于递进学习策略的图像修复方法、系统、介质及设备</td>   <td>广东省</td>   <td>CN113379637A</td>   <td>2021-09-10</td>   <td>本发明公开了一种基于递进学习策略的图像修复方法、系统、存储介质及终端设备,包括：将待修复图像输入粗生成模型,以得到粗生成结果；提取所述粗生成结果的特征图,以得到前景特征图；将所述前景特征图与背景特征图进行匹配,并将得到的与所述前景特征图匹配度最高的背景样本块对所述前景特征图进行重构。本发明能够在对图像中大面积破损区域进行生成时,保持图像语义完整并生成较为清晰的细节,对结构性强的图片有较好的修复效果,从而提升了用户图像修复体验。</td>   <td>1.一种基于递进学习策略的图像修复方法,其特征在于,所述方法包括：将待修复图像输入粗生成模型,以得到粗生成结果；提取所述粗生成结果的特征图,以得到前景特征图；将所述前景特征图与背景特征图进行匹配,并将得到的与所述前景特征图匹配度最高的背景样本块对所述前景特征图进行重构。</td>   <td>G06T5/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              刘洋旗;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种CT结肠影像内容物的标注方法及系统</td>   <td>广东省</td>   <td>CN113379735A</td>   <td>2021-09-10</td>   <td>本发明公开了一种CT结肠影像内容物的标注方法及系统,该方法包括：获取CT结肠影像数据集并进行标注；对带标注的CT结肠影像数据集进行预处理；基于预处理后的CT影像数据集训练预构建的3D Inception网络和改进的U-net网络；获取待测图像并基于训练完成的DM-UNet网络进行预测,得到结肠内容物标注。该系统包括：标注模块、预处理模块、网络训练模块和应用模块。通过使用本发明,能够标注并去除CT结肠影像内容物。本发明作为一种CT结肠影像内容物的标注方法及系统,可广泛应用于医学图像处理领域。</td>   <td>1.一种CT结肠影像内容物的标注方法,其特征在于,包括以下步骤：获取CT结肠影像数据集并进行标注,得到带标注的CT影像数据集；对带标注的CT结肠影像数据集进行预处理,得到预处理后的CT影像数据集；基于预处理后的CT影像数据集训练预构建的3D Inception网络和改进的U-net网络,并以训练好的3D Inception网络辅助训练改进的U-net网络,得到训练完成的DM-UNet网络；获取待测图像并基于训练完成的DM-UNet网络进行预测,得到结肠内容物标注。</td>   <td>G06T7/00;G06T7/13;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈跃东;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于生成式对抗网络进行图像去运动模糊的方法</td>   <td>广东省</td>   <td>CN108416752B</td>   <td>2021-09-07</td>   <td>本发明公开一种基于生成式对抗网络进行图像去运动模糊的方法及用于该方法的去运动模糊的生成式对抗网络模型,该方法包括设计生成式对抗网络模型；模型训练；应用阶段,该生成式对抗网络模型包括生成器和判别器,生成器用于不断优化参数以使其生成的图像趋近清晰图像的分布,判别器用于不断优化参数以使其能更好地判别图像来自于去模糊图像分布或清晰图像分布,其中生成器包括降采样器和上采样器,降采样器用于对图像进行卷积操作,提取图像的语义信息,上采样器用于根据获取到的语义信息,结合图像的结构信息,对图像进行解卷积操作。本发明有效地去除图像的运动模糊,获得符合人类感知的清晰图像。</td>   <td>1.一种基于生成式对抗网络进行图像去运动模糊的方法,其特征在于,包括如下步骤：S10设计去运动模糊的生成式 对抗网络模型结构,其中该网络模型由生成器和判别器组成,其中生成器包括降采样器和上采样器,降采样器用于对图像进行卷积操作,提取图像的语义信息,上采样器用于根据获取到的语义信息,结合图像的结构信息,对图像进行解卷积操作；S20将一个包含模糊图像和清晰图像的图像对数据集中模糊图像作为队列元素存储至模糊图像队列,清晰图像作为队列元素存储至清晰图像队列,且以清晰图像队列中的元素顺序调整模糊图像队列的元素顺序,以使清晰图像与模糊图像一一对应；S30输入一组包含有m个从S20步骤中的两个队列获取的清晰-模糊图像对至网络模型,分别将该图像对中的清晰图像和模糊图像缩放成Sh×Sw的尺寸,再剪成出尺寸为Ch×Cw的图像块；S40将由S30得到的图像块输入该网络模型,通过迭代应用后向传播算法,逐步更新该网络模型的训练参数,每代队列中的所有元素训练结束之后,重新打乱队列元素的排序,开始新一代的训练,循环多代训练,直至该网络模型收敛,保存并导入该网络模型收敛时的训练参数,以使得该网络模型拟合成一个从模糊图像分布到清晰图像分布的映射,包括：S401将由S30得到的图像块输入该网络模型,模糊图像的图像块在生成式对抗网络的生成器中,经过一次前向传播计算,生成一张去模糊图像,其中模糊图像先经过降采样器,得到一个尺寸为(Ch/128)×(Cw/128)×512的带有图像高层语义信息的矩阵,然后,再经过一个上采样器,最终生成一个尺寸为Ch×Cw×3的去模糊图像；S402所生成的去模糊图像和与其对应的模糊图像构成一个“模糊—去模糊”图像对,输入到判别器中,经过一次前向传播计算,得到一个该映射为真实映射的概率D(x,G(x)),及将其对应的“模糊—清晰”图像输入到判别器中,经过一次前向传播计算,得到一个该映射为真实映射的概率D(x,y)；S403生成式对抗网络的损失函数通过生成器的生成损失和判别器的判别损失优化参数,其中,生成器的优化方程：                  判别器的优化方程：                  其中,G为生成器,G(x)为生成器输出的去模糊图像；D为判别器,D(·)为判别器的输出结果,与S402中同义,为目标函数的数学期望,x～pdata(x)指的是图像x取自一个特定的分布pdata(x),在本方法中,这个特定的分布指的就是一个图像队列；同理,y～pdata(y)指的是图像y取自一个特定的分布pdata(y),指的是在更新模型参数时,只更新生成器网络G的参数,并使得损失函数L(G,D)的值最小化,同理,指的是在更新模型参数时,只更新判别器网络D的参数,并使得损失函数L(G,D)的值最小化,公式(7)表示生成器的目标函数,是最大化判别器判定“模糊—去模糊”图像对为真实映射的概率D(x,G(x)),使其趋向于1,公式(8)表示判别器的目标函数,是最大化判别器判定“模糊—清晰”图像对为真实映射的概率D(x,G(x)),使其趋向于1,同时最小化概率D(x,G(x)),使其趋向于0；S404生成器通过S402中的生成损失、L1范数损失、感知损失及总变分损失的约束优化模型参数,最终得到生成器的损失函数,其中：图像x和图像y之间的L1范数函数：                  其中x指的是输入的清晰图像,y指的是模型生成的去模糊图像；W指的是图像的宽度,H指的是图像的高度,图像x和图像y的尺寸完全相同,都是(W,H),i指的是宽度维度上的坐标,j指的是高度维度上的坐标,y-(i,j)指的是图像y在坐标[i,j]上的像素的灰度值,同理,x-(i,j)指的是图像x在坐标[i,j]上的像素的灰度值；图像x和图像y之间的感知距离函数：                  其中x指的是输入的清晰图像,y指的是模型生成的去模糊图像,[α,β]为一个整体,是一个坐标信息,指的是VGG网络中,第α个卷积层后,第β个池化层前的那一层语义特征的坐标,而W-(α,β),H-(α,β)则是语义特征层的宽度和高度,i指的是宽度维度上的坐标,j指的是高度维度上的坐标,指的是在网络第α个最大池化层之前,第β个卷积层之后的特征矩阵,指的是图像y的第[α,β]语义特征层,而指的是图像y的第[α,β]语义特征层上的坐标[i,j]上的元素的数值,同理,指的是图像x的第[α,β]语义特征层上的坐标[i,j]上的元素的数值；图像x的总变分损失函数：                  其中x指的是模型生成的去模糊图像,W指的是图像的宽度,H指的是图像的高度,i指的是宽度维度上的坐标,j指的是高度维度上的坐标,x-(i,j)指的是图像x在坐标[i,j]上的像素的灰度值；由公式(4)、(5)、(6)得到生成器的损失函数：                  其中lL1与公式(4)同指,lperceptual与公式(5)同指,ltv与公式(6)同指,α-1,α-2和α-3分别为L1范数损失、感知损失以及总变分损失对应的权重；S405模型在后向传播阶段,分别根据公式(8)和公式(9)计算出生成器和判别器的损失,并依次单独更新生成器和判别器中的模型参数,应用后向传播算法更新优化模型；S406重复S401-405,直至模型收敛,则停止训练,当输入队列被取空之后,如果模型还没有收敛,则按照S402中提及的方法,重新对清晰图像队列和清晰图像队列进行随机乱序排序；S50输入模糊图像,通过一次前向传播计算,生成去模糊图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         沈鸿;                   卜凡       </td>   <td>中山大学</td>   <td>一种基于Lyapunov优化的数据中心电能开销优化控制方法及系统</td>   <td>广东省</td>   <td>CN108629448B</td>   <td>2021-09-07</td>   <td>一种基于Lyapunov优化的数据中心电能开销优化控制方法,包括以下步骤：获得当前时刻的电网批发电价Pr,电网向数据中心输出的最大功率PB-(max)以及电网当前的碳排放率C-b,当前时刻的最大可用风电输出功率PW-(avail)和风电的碳排放量C-w；基于电网能源和风电能源建立数据中心电能能耗模型；建立数据中心电能开销模型：基于Lyapunov优化得到数据中心电能开销的优化函数F(t)；取数据中心电能开销的优化函数F(t)的最小值,并结合能耗模型和开销模型,求得此时数据中心的电网能源负载PB、风电能源负载PW、延时敏感服务器数量m-u及延时容忍服务器数量m-d。本发明将电网电力与风电绿色能源两种电力输入,统筹考虑绿色清洁能源的使用,合理分配电力负载,最终有效降低数据中心能耗开销。</td>   <td>1.一种基于Lyapunov优化的数据中心电能开销优化控制方法,其特征在于包括以下步骤：获得当前时刻的电网批发电价Pr,电网向数据中心输出的最大功率PB-(max)以及电网当前的碳排放率C-b,当前时刻的最大可用风电输出功率PW-(avail)和风电的碳排放量C-w；基于电网能源和风电能源建立数据中心电能能耗模型,能耗模型为：PB+PW＝[m-u·PO-u+m-d·PO-d]·PUE其中,0≤PB≤PB-(max),0≤PW≤PW-(avail),0＜m-d≤M-d,PB为数据中心的电网能源负载,PW为数据中心的风电能源负载,PO-u为数据中心单个延迟敏感服务器物理机的能耗,PO-d为数据中心单个延迟容忍服务器物理机的能耗,m-u为延时敏感服务器数量,m-d为延时容忍服务器数量,PUE为系数常数,M-d为延时容忍服务器数量的最大值；建立数据中心电能开销模型,开销模型为：COST＝CT[PB·C-b+PW·C-w]+PB·Pr其中CT为碳税价格；基于Lyapunov优化得到数据中心电能开销的优化函数F(t),F(t)＝V·COST-Q-d(t)·m-d·sr-d其中V为Lyapunov惩罚系数,Q-d(t)为t时刻延迟容忍任务的虚拟队列值,sr-d为延时容忍作业处理速率；取数据中心电能开销的优化函数F(t)的最小值,并结合能耗模型和开销模型,求得此时数据中心的电网能源负载PB、风电能源负载PW、延时敏感服务器数量m-u及延时容忍服务器数量m-d。</td>   <td>G06Q10/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>              齐志新       </td>   <td>中山大学</td>   <td>一种基于多源光学遥感图像的违法建设用地开发自动检测方法</td>   <td>广东省</td>   <td>CN112270291B</td>   <td>2021-09-07</td>   <td>本发明公开了一种基于多源光学遥感图像的违法建设用地开发自动检测方法,包括：分别获取待检测区域两个不同时间的光学遥感影像；计算两个不同时间的光学遥感影像间的土地平整强度,得到土地平整强度图像；利用最大期望算法对土地平整强度图像进行聚类分析,提取待检测区域的建设用地开发对应区域；将提取的建设用地开发对应区域与待检测区域的土地规划进行对比,土地规划严禁开发区域内的建设用地开发即为违法建设用地开发。本发明能够对违法建设用地开发进行短周期、全自动监测,计算简单、易于理解,执行效率高,且无需任何训练样本,能够及时发现并预防违法建设用地导致的各种社会及环境问题,并且显著降低监测成本、提高监测效率。</td>   <td>1.一种基于多源光学遥感图像的违法建设用地开发自动检测方法,其特征在于,包括以下步骤：S1：分别获取待检测区域两个不同时间的光学遥感影像；S2：计算两个不同时间的光学遥感影像间的土地平整强度,得到土地平整强度图像；S3：利用最大期望(Expectation Maximum,EM)算法对土地平整强度图像进行聚类分析,提取待检测区域的建设用地开发对应区域,步骤S3具体过程为：利用最大期望算法对土地平整强度图像进行聚类分析,得到最大期望依赖样本的分布类型；根据分布模型的参数,确定土地平整强度图像中建设用地开发区域与非建设用地开发区域的阈值,根据阈值提取建设用地开发区域,所述最大期望依赖样本的分布类型为正态分布；S4：将提取的建设用地开发对应区域与待检测区域的土地规划进行对比,土地规划范围外的建设用地开发区域即为违法建设用地开发区域。</td>   <td>G06K9/00;G06K9/32;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张志勇;              业泽政;              丘昌镇;              王鲁平;                   王亮       </td>   <td>中山大学</td>   <td>一种红外小目标检测方法及装置</td>   <td>广东省</td>   <td>CN113361321A</td>   <td>2021-09-07</td>   <td>本申请公开了一种红外小目标检测方法及装置,本申请包括粗检和精检两个阶段。在粗检阶段只针对像素子块进行操作,而像素级的操作只在精检阶段才进行使用,这样大大降低了算法的计算量,提升了实时性。采用新的对比度公式,能够准确识别并标记出亮目标、暗目标可能存在的区域,与此同时能够削弱单点噪声、背景边缘的影响；在精检阶段采用多个方向的QDoG滤波器在可疑区域中进行逐像素点滤波,进一步减少背景边缘、单点噪声的影响,从而有效减少虚警率。</td>   <td>1.一种红外小目标检测方法,其特征在于,包括：采用滑窗获取原始红外图像的多个子块；将所述子块作为中心子块,在所述原始红外图像中查找与所述中心子块相邻的多个相邻子块；分别计算所述中心子块和多个所述相邻子块的灰度值均值；将所述灰度值均值代入预设第一公式中计算出所述中心子块对应的第一对比度；将所述第一对比度大于预设第一阈值的所述中心子块定义为可疑亮目标子块,将所述第一对比度小于预设第二阈值的所述中心子块定义为可疑暗目标子块；将所述可疑亮目标子块和所述可疑暗目标子块分别进行扩展；对所述可疑亮目标子块和所述可疑暗目标子块进行滤波,得到所述可疑亮目标子块和所述可疑暗目标子块中每个像素点的第二对比度,得到由所述第二对比度构成的所述可疑亮目标子块的第一显著度矩阵和所述可疑暗目标子块的第二显著度矩阵；分别计算所述第一显著度矩阵和所述第二显著度矩阵的均值和方差,并由预置阈值公式分别求解所述第一显著度矩阵的第三阈值和所述第二显著度矩阵的第四阈值；获取所述第一显著度矩阵中大于所述第三阈值的所述第二对比度对应的亮像素点,将所述亮像素点及所述亮像素点周围预设范围内的像素点构成的块作为所需的亮小目标；获取所述第二显著度矩阵中小于所述第四阈值的所述第二对比度对应的暗像素点,将所述暗像素点及所述暗像素点周围预设范围内的像素点构成的块作为所需的暗小目标。</td>   <td>G06K9/00;G06K9/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>              姚军艇       </td>   <td>中山大学</td>   <td>一种基于多任务学习模型的AI换脸视频检测方法</td>   <td>广东省</td>   <td>CN113361395A</td>   <td>2021-09-07</td>   <td>本发明公开了一种基于多任务学习模型的AI换脸视频检测方法,属于计算机视觉与深度学习领域,该检测方法具体步骤如下：(1)用户上传待检测视频；(2)构建人脸图像伪造检测器；(3)对视频进行逐帧取图；(4)对提取出的图片进行图片筛选；(5)对剩余图片进行换脸检测；(6)将检测结果反馈给用户；本发明能够避免计算机感染病毒,降低用户信息被窃取的风险,保护用户财产安全,同时人脸图像伪造检测器可以不断进行更新学习,不断提高其工作效率,方便工作人员查看,防止工作人员手动记录出现误差,提高工作人员的工作效率。</td>   <td>1.一种基于多任务学习模型的AI换脸视频检测方法,其特征在于,该检测方法具体步骤如下：(1)用户上传待检测视频：用户通过外部输入设备向计算机上传待检测视频,其中,外部输入设备具体为键盘、鼠标或触控屏中的一种,视频上传成功,用户将其放入检测软件；(2)构建人脸图像伪造检测器：检测软件接收到视频,并开始与互联网进行数据交互,并对其中换脸检测数据进行数据抓取,同时对抓取的数据进行安全检测,并开始构建人脸图像伪造检测器；(3)对视频进行逐帧取图：人脸图像伪造检测器开始自行扫描待检测视频,并对视频数量进行计算,同时进行检测排序,视频排序完成,人脸图像伪造检测器对视频进行逐帧取图；(4)对提取出的图片进行图片筛选：图片提取完成,开始构建图片筛选器,构建完成,图片筛选器开始与特征信息库进行数据交互,并开始对提取出的图片进行对比筛选；(5)对剩余图片进行换脸检测：对筛选后的图片进行伪造检测,并将检测结果分别录入XLSX工作表中,并在该XLSX工作表中标注检测时间；(6)将检测结果反馈给用户：将检测结果通过显示设备反馈给用户,同时用户可通过输入设备对XLSX工作表进行检索查看,并通过打印设备对其进行打印处理,其中,显示设备具体为CRT显示屏、LCD显示屏或LED显示屏,其中,打印设备具体为激光打印机、喷墨打印机或针式打印机。</td>   <td>G06K9/00;G06K9/34;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑伟诗;              陈泽林;                   吴岸聪       </td>   <td>中山大学</td>   <td>基于字母层次上的字迹鉴别方法、系统及存储介质</td>   <td>广东省</td>   <td>CN113361406A</td>   <td>2021-09-07</td>   <td>本发明公开了一种基于字母层次上的字迹鉴别方法、系统及存储介质,所述方法具体为：将采集到的字母的字迹信息经过多支路编码器、字母与样式适配器与多层次的带注意力机制的池化策略,并经用户身份分类器得到用户的身份信息。本发明目的在于克服现有的字迹鉴别技术中大多需在长文本层次上进行字迹识别的缺陷和不足之处,通过构建包括多支路编码器、字母与样式适配器和多层次的带注意力机制的池化策略的字迹鉴别模型,能够在字母层次上达到快速、准确的用户身份识别。</td>   <td>1.基于字母层次上的字迹鉴别方法,其特征在于,包括下述步骤：将采集到的字母的字迹信息输入多支路编码器,使用不同的编码器建模不同样式减轻书写多样式带来的类内差距,所述多支路编码器中每条支路包括网络结构相同、初始化参数不同的编码器,即一维的卷积网络和双向长短期记忆网络；将经过多支路编码器处理后的字迹信息输入字母与样式适配器,进一步减轻用户书写多样式带来的类内差距和缩小不同字母的特征表达的差距,所述字母与样式适配器包括分布归一化过程与字母特定特征选择过程；所述一维的卷积网络和双向长短期记忆网络后均设置有字母与样式适配器；将经过字母与样式适配器处理后的字迹信息采用多层次的带注意力机制的池化策略进行处理,所述多层次的带注意力机制的池化策略包括关注于书写样式的注意力池化层、关注于书写时序的注意力池化层和关注于字母的注意力池化层；利用所述关注于书写样式的注意力池化层,判断出用户输入的字母对应的书写样式,并提取每条支路对应书写样式的编码；利用所述关注于书写时序的注意力池化层提取字母中具有区分性的特征,并增强所述具有区分性的特征；利用所述关注于字母的注意力池化层识别出可靠的字母并增强该字母的特征；将经过带注意力机制的池化策略处理后的信息输入到用户身份分类器得到用户的身份信息。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丁培荣;              姜武;              李立;              张惠忠;              凌逸虹;                   梅伟健       </td>   <td>中山大学肿瘤防治中心(中山大学附属肿瘤医院、中山大学肿瘤研究所)</td>   <td>一种结直肠癌错配修复功能的预测方法及装置</td>   <td>广东省</td>   <td>CN113361580A</td>   <td>2021-09-07</td>   <td>本发明公开了一种结直肠癌错配修复功能的预测方法及装置,通过获取结直肠组织的HE染色病理切片,生成所述HE染色病理切片的数字病理图像,将所述数字病理图像划分为多个子区域,提取所述多个子区域中的组织区域,通过组织分类器分类出所述组织区域中的肿瘤区域,再通过MSI/MSS分类模型将所述所有肿瘤区域划分为MSI区域和MSS区域,计算所述MSI区域的数量占所述肿瘤区域的数量的比率,并根据所述比率,输出所述HE染色病理切片的预测结果。本发明提供一种结直肠癌错配修复功能的预测方法及装置,相对于现有技术减少了对人工的依赖性,提高了效率。</td>   <td>1.一种结直肠癌错配修复功能的预测方法,其特征在于,包括：获取结直肠组织的HE染色病理切片,生成所述HE染色病理切片的数字病理图像；将所述数字病理图像划分为多个子区域,提取所述多个子区域中的组织区域；通过组织分类器分类出所述组织区域中的肿瘤区域,再通过MSI/MSS分类模型将所述所有肿瘤区域划分为MSI区域和MSS区域；计算所述MSI区域的数量占所述肿瘤区域的数量的比率,并根据所述比率,输出所述HE染色病理切片的预测结果。</td>   <td>G06K9/62;G06T7/11;G06T7/136;G06T7/194</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张小虎;              杨明坤;              王杰;              林彬;                   钟立军       </td>   <td>中山大学</td>   <td>一种基于深度学习的封装芯片缺陷检测方法</td>   <td>广东省</td>   <td>CN113362306A</td>   <td>2021-09-07</td>   <td>本发明公开了一种基于深度学习的封装芯片缺陷检测方法,包括：对封装芯片的X射线图像进行降噪处理；对X射线图像进行图像分割,提取具有封装芯片的测试图像；基于模板匹配得到测试图像中芯片的密封圈内外边缘；建立训练数据集与目标检测模型,对目标检测网络进行训练；基于训练后的目标检测模型对测试图像进行检测,得到测试图像中缺陷区域对应的检测框；基于区域生长对检测框进行精定位修正；基于密封圈内外边缘与检测框的最短路径对芯片进行合格性判定。深入研究了以深度学习视觉检测技术为代表的计算机视觉技术,研制出电子元器件X射线检查气泡缺陷自动识别方法,解决了军工电子元器件质量检测的迫切需求。</td>   <td>1.一种基于深度学习的封装芯片缺陷检测方法,其特征在于,包括如下步骤：步骤1,获取封装芯片的X射线图像,并对其进行降噪处理；步骤2,对降噪处理后的X射线图像进行图像分割,提取具有封装芯片的测试图像；步骤3,基于模板匹配得到测试图像中芯片的密封圈内外边缘；步骤4,建立训练数据集与目标检测模型,并基于训练数据集对目标检测网络进行训练；步骤5,基于训练后的目标检测模型对测试图像进行检测,得到测试图像中缺陷区域对应的检测框；步骤6,基于区域生长对检测框进行精定位修正；步骤7,基于密封圈内外边缘与检测框的最短路径对芯片进行合格性判定。</td>   <td>G06T7/00;G06N3/04;G06N3/08;G06T5/00;G06T7/11;G06T7/12;G06T7/181</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈纪凯;              潘炎;              赖韩江;              印鉴;                   高静       </td>   <td>中山大学;广东恒电信息科技股份有限公司</td>   <td>一种基于关键点检测的衣服种类和属性分类方法</td>   <td>广东省</td>   <td>CN107918780B</td>   <td>2021-09-03</td>   <td>本发明提供一种基于关键点检测的衣服种类和属性分类方法,该方法先采集训练样本的数据；然后构建可配置的检测衣服关键点的深度模型,并将训练样本的数据输入深度模型,以对深度模型进行训练；接着利用训练后的检测关键点的深度模型对衣服图像进行分析,预测衣服图像中每个关键点的位置；最后根据S3中预测关键点的结果,以此提取相关局部信息,再融合全局的图片信息,再通过深度模型对衣服种类和属性进行训练、预测。该方法实现了能够更好融合衣服局部和全局特征。</td>   <td>1.一种基于关键点检测的衣服种类和属性分类方法,其特征在于,包括以下步骤：S1：采集训练样本的数据；S2：构建可配置的检测衣服关键点的深度模型,并将训练样本的数据输入深度模型,以对深度模型进行训练；S3：利用训练后的检测关键点的深度模型对衣服图像进行分析,预测衣服图像中每个关键点的位置；S4：根据S3中预测关键点的结果,以此提取相关局部信息,再融合全局的图片信息,再通过深度模型对衣服种类和属性进行训练、预测；所述步骤S2中深度模型包括两个卷积神经网络；第一个深度卷积神经网络对衣服关键点位置进行学习,运用卷积神经网络的卷积层提取图像的数据的基础表达,再利用反卷积层得到与原图同样尺寸的特征图来预测各个关键点的位置；第二个深度卷积神经网络用于融合衣服图像的局部特征和全局特征,其中,局部特征根据第一个深度卷积神经网络预测得到的关键点位置提取；衣服图像经过第一个卷积神经网络,预测出衣服关键点的位置；再根据这些关键点,确定出与识别目标有关的局部区域,再经过第二个卷积神经网络融合局部和全局特征对衣服种类和属性进行预测,输出最终的结果；所述的第一个深度卷积神经网络由三种主要的层实现,分别是卷积层、降采样层和反卷积层；该卷积层的输入特征和输出特征的长宽一致,可保持尺度不变；最后一层输出的特征为256×256×L,其中L是关键点的个数,让输出的feature map的第k个通道预测第k个关键点的位置,对于该通道上的每个点的响应值F(x,y,k),令它为预测点(x,y)是第k个关键点的概率值：采用交叉熵来训练该卷积神经网络,定义损失函数如下：                  其中batch-(size)是输入神经网络图像的数目,H为输入图像和输出特征的高,将手工标注的点坐标记为(x-g,y-g),而对于一个二维平面,在标注点邻近的点也可作为目标点,即(x-g-1,y-g),(x-g,y-g-1),(x-g+1,y-g),(x-g,y-g+1),(x-g-1,y-g-1),(x-g+1,y-g+1)坐标也可以作为标注坐标；因此定义标注点(x-g,y-g)处的值为最大概率值1,其邻近的坐标按照一定比例线性下降,即如下公式所示,其中α为衰减因子；Q(x,y,k)＝max(0,1-αmax(|x-x-g|,|y-y-g|))再将Q(x,y,k)标准化之后,得到真实坐标的期望概率分布G(x,y,k)                  这样通过神经网络的反向传播算法更新及参数值,从而学习到一个健壮的模型。</td>   <td>G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭卫文;              欧阳孔雷;              黄承赓;              韩瑜;                   古博       </td>   <td>中山大学</td>   <td>一种基于迁移学习的设备集群跨域故障预测方法及系统</td>   <td>广东省</td>   <td>CN113342476A</td>   <td>2021-09-03</td>   <td>本发明公开了一种基于迁移学习的设备集群跨域故障预测方法及系统,该方法包括：采集源域和目标域中设备的信号,得到原始监测数据；基于连续异常点检测方法对原始监测数据进行初识别,得到早期故障节点；进行信号校准和特征提取处理,得到故障特征集；基于故障特征集对预构建的域自适应迁移学习MLP-DCNN双神经网络进行训练,得到预测模型；实时采集目标域设备的时频域数据并输入到预测模型,实现故障检测。该系统包括：数据获取模块、初识别模块、故障特征提取模块、训练模块和故障检测模块。通过使用本发明,解决了跨域的制造设备之间的迁移故障预测。本发明作为一种基于迁移学习的设备集群跨域故障预测方法及系统,可广泛应用于设备运维管理领域。</td>   <td>1.一种基于迁移学习的设备集群跨域故障预测方法,其特征在于,包括以下步骤：基于传感器采集源域和目标域中设备的信号,得到原始监测数据；基于连续异常点检测方法对原始监测数据进行初识别,得到早期故障节点；对原始监测数据中早期故障节点后的数据进行信号校准和特征提取处理,得到故障特征集；基于故障特征集对预构建的域自适应迁移学习MLP-DCNN双神经网络进行训练,得到预测模型；实时采集目标域设备的时频域数据并输入到预测模型,实现故障检测。</td>   <td>G06F9/455;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              姚军艇       </td>   <td>中山大学</td>   <td>一种自适应人脸识别方法</td>   <td>广东省</td>   <td>CN113343842A</td>   <td>2021-09-03</td>   <td>本发明公开了一种自适应人脸识别方法,属于安全监测领域,该识别方法具体步骤如下：(1)检测采集范围内是否出现行人；(2)采集摄像头开始智能调整采集角度；(3)采集相关环境信息闭并进行采集优化；(4)开始对行人人脸信息进行采集；(5)对采集到的人脸图像进行对比分析；(6)对比结果反馈并方便工作人员检索查看；本发明能够提前检测障碍物类型,降低采集摄像头误触概率,减少其使用功耗,延长使用寿命,有效的去除噪音对采集图像产生的影响,降低识别错误的发生次数,方便用户使用,提高识别准确率。</td>   <td>1.一种自适应人脸识别方法,其特征在于,该识别方法具体步骤如下：(1)检测采集范围内是否出现行人：感应元件开始对一定范围进行检测,同时对该区域是否存在行人进行分析判断,其中,感应元件具体为激光雷达或声波雷达；(2)采集摄像头开始智能调整采集角度：当需要对人脸进行采集时,采集摄像头开始工作,并开始自行调整采集角度,当采集角度调整完成,开始进行检测判断；(3)采集相关环境信息闭并进行采集优化：光感应器以及监测摄像头开始对周围环境进行数据采集,并构建相应范围的环境模型,同时对环境进行分析判断,依据分析结果对采集过程进行数据优化；(4)开始对行人人脸信息进行采集：优化完成,采集摄像头开始对行人人脸信息进行数据采集,并对采集到的图像通过图像优化处理生成分析数据；(5)对采集到的人脸图像进行对比分析：从特征数据库中提取特征信息,并将其分别与分析数据进行对比判断；(6)对比结果反馈并方便工作人员检索查看：将对比结果通过显示设备反馈给行人,同时通过语音播报将结果反馈给用户,且将数据上传至云端数据库,工作人员可以对云端数据库中的数据进行检索查看；其中,显示设备具体为CRT显示屏、LCD显示屏或LED显示屏中的一种。</td>   <td>G06K9/00;G06K9/62;G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;              黄梓轩;                   陈蔓薇       </td>   <td>中山大学</td>   <td>一种基于前景选择域自适应的目标检测方法及系统</td>   <td>广东省</td>   <td>CN113343989A</td>   <td>2021-09-03</td>   <td>本发明公开了一种基于前景选择域自适应的目标检测方法及系统,该方法包括：获取源域图像数据集和目标域图像数据集；对源域图像数据集和目标域图像数据集进行图像特征提取；提取感兴趣区域；对感兴趣区域进行前景选择；对不同层次的前景特征和全局特征进行域自适应,得到域自适应的检测网络；根据域自适应的检测网络对待测目标集进行目标检测。该系统包括：数据获取模块、语义特征提取模块、感兴趣区域提取模块、前景选择模块、域自适应模块和检测模块。通过使用本发明,避免了在对齐前景时背景的干扰,从而有效提高检测网络在目标域上的检测性能。本发明作为一种基于前景选择域自适应的目标检测方法及系统,可广泛应用于目标检测领域。</td>   <td>1.一种基于前景选择域自适应的目标检测方法,其特征在于,包括以下步骤：获取源域图像数据集和目标域图像数据集,并输入至检测网络；分别对源域图像数据集和目标域图像数据集进行图像特征提取,得到对应的多层次语义特征；根据多层语义特征中的全局特征提取图像的感兴趣区域；对感兴趣区域进行前景选择,得到不同层次的前景特征；对不同层次的前景特征和全局特征进行域自适应,得到域自适应的检测网络；根据域自适应的检测网络对待测目标集进行目标检测。</td>   <td>G06K9/32;G06K9/34;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈川;                   郑子彬       </td>   <td>中山大学</td>   <td>一种不完整数据的子空间聚类方法及装置</td>   <td>广东省</td>   <td>CN113344126A</td>   <td>2021-09-03</td>   <td>本申请公开了一种不完整数据的子空间聚类方法及装置,包括：将获取的不完整数据按照预置规则进行排列,不完整数据包括多媒体数据；采用基于转换的张量核范数的张量优化问题将排列后的不完整数据投影到低维的子空间；采用交替迭代算法求解张量优化问题,得到子空间表示张量的相似矩阵；采用谱聚类算法基于求得的相似矩阵,得到不完整数据的聚类结果。本申请能够在保存不完整数据的空间结构下进行聚类,并能寻找较低秩的表示张量以充分的探索数据的全局相关性。</td>   <td>1.一种不完整数据的子空间聚类方法,其特征在于,包括：将获取的不完整数据按照预置规则进行排列,所述不完整数据包括多媒体数据；采用基于转换的张量核范数的张量优化问题将排列后的所述不完整数据投影到低维的子空间；采用交替迭代算法求解所述张量优化问题,得到子空间表示张量的相似矩阵；采用谱聚类算法基于求得的所述相似矩阵,得到所述不完整数据的聚类结果。</td>   <td>G06K9/62;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王文标;                   林瀚       </td>   <td>中山大学</td>   <td>一种基于剪枝条件的不确定数据序列扫描方法及系统</td>   <td>广东省</td>   <td>CN113344140A</td>   <td>2021-09-03</td>   <td>本发明提出一种基于剪枝条件的不确定数据序列扫描方法和系统,充分利用概率计算过程中概率变化所满足的条件,以及K近邻问题只需找出前k大而无需求出具体值的特点,为传统的样本扫描算法设置剪枝条件,大大减少了算法需要扫描的样本数量,有效提高扫描效率。</td>   <td>1.一种基于剪枝条件的不确定数据序列扫描方法,设数据集D中有N个不确定数据序列,每个序列包含m个样本,给定查询序列Q和结果集大小k,其特征在于,包括以下步骤：S1：计算数据集D中所有不确定序列X-i的所有样本与查询序列Q的距离将距离与样本所属不确定序列编号保存在samples数组中,使samples[(i-1)*m+j]·i＝i,S2：以distance为键值,对samples数组的元素建立小顶堆heap；S3：初始化长度为N的scanned数组和res数组,使其所有元素为0,初始化变量logp＝N*lnm；S4：初始化大小为k的数据结构answer；S5：循环从小顶堆heap的堆顶取元素直到堆空,每步执行如下过程：S51：令当前元素为sample,i＝sample.i,dis＝sample.distance；S52：计算当前样本对所属的不确定序列X-i的最邻近概率P-(NN)(Q,X-i)的贡献e～(logp)～(-ln(m-scanned[i])-N*lnm),将其更新累加到res数组的对应元素res[i]中；S53：以(i,res[i])更新数据结构answer；S54：更新scanned数组的对应元素,使scanned[i]+＝1；S55：判断scanned[i]是否与m相等,若是,则跳出循环结束扫描过程；S56：更新变量logp+＝ln(m-scanned[i])-ln(m-scanned[i]+1)；S57：在扫描的每步中,当前任意不确定序列X-i的已累加概率res[i]与它最邻近概率满足不等式：0≤P-(NN)(Q,X-i)-res[i]≤e～(logp-N*lnm)因此,对于任意两个不确定序列X-(i1)和X-(i2),若存在：res[i1]-res[i2]＞e～(logp-N*lnm)则有：P-(NN)(Q,X-(i1))≥res[i1]＞res[i2]+e～(logp-N*lnm)≥P-(NN)(Q,X-(i2))即只要res数组中第k大和第k+1大的元素之间的差超过e～(logp-N*lnm),那么最邻近概率前k大和第k+1大之间的差值diff,判断diff＞e～(logp-N*lnm)是否成立,则跳出循环结束扫描过程；S6：获取数据结构answer中维护的答案。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王文标;                   林瀚       </td>   <td>中山大学</td>   <td>基于样本扫描的不确定数据序列K近邻方法及系统</td>   <td>广东省</td>   <td>CN113344141A</td>   <td>2021-09-03</td>   <td>本发明提出一种基于样本扫描的不确定数据序列K近邻方法,包括通过计算所有不确定序列的所有样本与查询序列的距离,将距离与样本所属不确定序列编号一同进行保存和排序；构建并初始化第一数组、第二数组和控制变量；对排序后的样本数组从第一个样本开始扫描；根据控制变量计算当前样本对其所属的不确定序列的概率贡献后更新累加到第二数组对应的元素中并根据当前样本所属的不确定序列更新第一数组对应的元素；判断待测不确定序列在第一数组中对应的元素是否不小于每个不确定序列的样本数,若是,则待测不确定序列的所有样本已经完成扫描,找出其中最大的K个元素；否则,扫描下一个样本；本方法高效解决了不确定序列的K近邻问题。</td>   <td>1.基于样本扫描的不确定数据序列K近邻方法,其特征在于,包括以下步骤：S1：获取待计算的数据集,包括所有不确定序列和查询序列；S2：计算所有不确定序列的所有样本与查询序列的距离,将距离与样本所属不确定序列编号一同保存在样本数组中；S3：根据距离从小到大对样本数组进行排序；S4：构建第一数组、第二数组和控制变量,并对第一数组、第二数组和控制变量进行初始化；其中：所述第一数组用于记录每个不确定序列已被扫描的样本数；所述第二数组用于记录当前扫描到的样本为每个不确定序列累加的概率贡献；控制变量用于计算当前样本对其所属的不确定序列的概率贡献；S5：对排序后的样本数组从第一个样本开始扫描；根据控制变量计算当前样本对其所属的不确定序列的概率贡献后更新累加到第二数组对应的元素中,同时,根据当前样本所属的不确定序列更新第一数组对应的元素；S6：判断待测不确定序列在第一数组中对应的元素是否不小于每个不确定序列的样本数,若是,则待测不确定序列的所有样本已经完成扫描,执行步骤S7；否则,返回步骤S5,扫描下一个样本；S7：扫描第二数组,找出其中最大的K个元素,其在数组的位置即是带计算数据集中查询序列的K近邻的编号。</td>   <td>G06K9/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   罗俊伟       </td>   <td>中山大学</td>   <td>基于空洞卷积和特征融合的双目超分辨率图像检测方法、系统及介质</td>   <td>广东省</td>   <td>CN113344791A</td>   <td>2021-09-03</td>   <td>本发明公开了一种基于空洞卷积和特征融合的双目超分辨率图像检测方法、系统及介质,包括下述步骤：将双目图像组输入经典双目图像超分辨率网络中,生成双目超分辨率图像作为负样本集,原双目图像组作为正样本集；将正负样本数据集切成图像块并随机划分训练集图像块和测试集图像块；对图像块进行预处理,转换为灰度图像,使用高通滤波器进行滤波得到滤波图像；构建双目超分辨率图像检测网络,将训练集滤波图像输入进行训练,得到训练好的网络；将测试集滤波图像输入训练好的网络中,输出概率最大的分类对应类别,得到图像检测结果。本发明直接对输入图像进行检测,适用于各种尺寸的图像检测,具有良好的检测性能,检测用时短,可实现实时检测。</td>   <td>1.基于空洞卷积和特征融合的双目超分辨率图像检测方法,其特征在于,包括下述步骤：将双目图像组输入到经典的双目图像超分辨率网络中,生成对应的双目超分辨率图像,所述双目超分辨率图像作为负样本数据集,所述双目图像组作为正样本数据集；将正负样本数据集切成不重叠的大小一致的图像块,并随机划分为训练集图像块和测试集图像块；对训练集图像块和测试集图像块进行预处理,将RGB图像转换为灰度图像,使用高通滤波器对所述灰度图像进行滤波得到滤波图像块；构建基于空洞卷积和特征融合的双目超分辨率图像检测网络,将训练集滤波图像块输入到双目超分辨率图像检测网络中进行训练,得到训练好的网络；将测试集滤波图像块输入到所述训练好的网络中,输出概率最大的分类对应类别,得到图像检测结果。</td>   <td>G06T3/40;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              刘芮致;                   周凡       </td>   <td>中山大学</td>   <td>一种基于全局特征融合注意力网络的图像去雾方法与系统</td>   <td>广东省</td>   <td>CN113344806A</td>   <td>2021-09-03</td>   <td>本发明公开了一种基于全局特征融合注意力网络的图像去雾方法。包括：首先,输入有雾图像,利用特征融合注意力网络提取图像特征,将各个群架构提取的特征输入层次注意力模块处理,生成无雾的图像；其次,以有雾图和无雾图作为训练集,用损失函数计算真实无雾图像和生成的无雾图像损失,更新网络模型中的参数,得到训练完毕的模型；最后,输入要进行去雾的有雾图像,训练好的模型计算输出无雾图像。本发明还公开了基于全局特征融合注意力网络的图像去雾系统、计算机设备及计算机可读存储介质。本发明探讨了特征注意力模块与层次注意力模块融合的方法,提出了全局特征融合注意力模块,专注于训练图像的重要信息,从而恢复有雾图像更多的纹理细节。</td>   <td>1.一种基于全局特征融合注意力网络的图像去雾方法,其特征在于,所述方法包括：搭建特征注意力网络结构,结构第一层卷积用于提取浅层初始特征,后续包括N个群架构,每个群架构包含M个基础块结构,基础块结构由局部残差学习和特征注意力模块组成,特征注意力模块由通道注意力模块和像素注意力模块组成；将特征图进行全局平均池化操作后输入所述通道注意力模块的两个卷积层和激活函数中,输出特征图不同通道的权重,将权重与特征图按元素相乘,对所有通道操作得到通道加权后的特征图；将所述通道加权后的特征图输入所述像素注意力模块的两个卷积层和激活函数中得到像素权重,将像素权重与所述通道加权后的特征图按元素相乘,输出所述特征注意力模块的特征图,输入下一个基础块,经过所述N个群架构和一层卷积后输出最终特征图；添加层次注意力模块与所述特征注意力模块组合,构建全局特征融合注意力网络模型,以所述N个群架构提取的中间特征组合而成的中间特征组FG输入层次注意力模块,计算不同层之间的相关性,输出层次注意力模块特征图；将所述最终特征图、所述层次注意力模块特征图和所述浅层初始特征进行整合得到无雾图像的特征图,再经过一层卷积操作恢复出无雾图像；构建数据集,数据集中包含室内和室外两种由无雾图像合成的有雾图像,将有雾图像和对应的无雾图像组成图像对,作为所述全局特征融合注意力网络模型的训练集；对所述训练集进行数据增强,每次取有雾图像块输入所述全局特征融合注意力网络模型中,得到去雾后的图像,利用损失函数计算生成的无雾图像和真实无雾图像的损失,然后反向更新所述全局特征融合注意力网络模型的权重,重复该步骤得到训练好的全局特征融合注意力网络模型；将有雾图像输入所述训练好全局特征融合注意力网络模型中,输出的图像就是去雾后的图像。</td>   <td>G06T5/00;G06T5/50;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         聂琳;              吴文熙;              陈添水;                   王青       </td>   <td>中山大学</td>   <td>一种用于物体精细识别的层次语义嵌入模型及其实现方法</td>   <td>广东省</td>   <td>CN109102024B</td>   <td>2021-08-31</td>   <td>本发明公开了一种用于物体精细识别的层次语义嵌入模型及其实现方法,所述层次语义嵌入模型包括：主干网络,用于对输入图像的浅层特征进行提取,以特征图的形式输出至各分支网络；若干分支网络,用于对主干网络输出的图像浅层特征图进行进一步的深层特征提取,使其输出的特征图适用于分支网络所对应层级的识别任务,并通过引入语义知识嵌入机制,实现上层语义知识对下层分支网络特征学习的指导,本发明解决依赖额外信息引导学习的物体精细化识别技术方案中的额外信息标注成本高的问题。</td>   <td>1.一种用于物体精细识别的层次语义嵌入模型,包括：主干网络,用于对输入图像的浅层特征进行提取,以特征图的形式输出至各分支网络；若干分支网络,用于对主干网络输出的图像浅层特征图进行进一步的深层特征提取,使其输出的特征图适用于分支网络所对应层级的识别任务,并通过引入语义知识嵌入机制,实现上层语义知识对下层分支网络特征学习的指导；所述分支网络包括：深层特征提取子模块,用于对所述主干网络输出的特征图进行深层特征提取,并输出上级语义知识引导下的特征表达以及无引导的特征表达；上级语义知识嵌入子模块,将上级预测的得分向量s-(i-1)经过一全连接层,映射成语义知识表达向量,并将该向量将与所述深层特征提取子模块输出的特征图的W×H平面上的每个位点拼接,将拼接之后的特征图,通过一注意力模型学习到一个注意力系数向量,将该注意力系数向量作用到所述深层特征提取子模块输出的特征图,得到加权的特征图,其中,W和H分别指宽和高；分值融合子模块,用于将所述上级语义知识嵌入子模块和深层特征提取子模块输出的特征图通过分值融合操作,输出相应的分值向量。</td>   <td>G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;                   李佳铭       </td>   <td>中山大学</td>   <td>半监督领域自适应方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113326848A</td>   <td>2021-08-31</td>   <td>本发明公开了一种半监督领域自适应方法,包括获取有标签源域图像、有标签目标域图像及无标签目标域图像；将有标签目标域图像、无标签目标域图像分别转换为具有源域图像风格的第一图像、第二图像；将第二图像输入至源域分割模型,得到第一概率置信图；将无标签目标域图像输入至目标域分割模型,得到第二概率置信图；根据第一概率置信图推断出的类别结果图合成第一伪标签,根据第二概率置信图推断出的类别结果图合成第二伪标签；利用第一伪标签及第一概率置信图监督目标域分割模型,得到其损失函数；利用第二伪标签及第二概率置信图监督源域分割模型,得到其损失函数。本发明能更好地缩减域间差及更好地利用目标域图片,进而提高语义分割效果。</td>   <td>1.一种半监督领域自适应方法,其特征在于,包括：获取有标签源域图像、有标签目标域图像及无标签目标域图像；将所述有标签目标域图像、所述无标签目标域图像分别转换为具有源域图像风格的第一图像、第二图像；将所述第二图像输入至源域分割模型,得到第一概率置信图；及将所述无标签目标域图像输入至目标域分割模型,得到第二概率置信图；根据所述第一概率置信图推断出的类别结果图合成第一伪标签,及根据所述第二概率置信图推断出的类别结果图合成第二伪标签；利用所述第一伪标签及所述第一概率置信图监督目标域分割模型,得到目标域分割模型的损失函数；及利用所述第二伪标签及所述第二概率置信图监督源域分割模型,得到源域分割模型的损失函数。</td>   <td>G06K9/34;G06N3/04;G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              吴梓溢;              颜鹏翔;              刘梦梦;                   林倞       </td>   <td>中山大学</td>   <td>基于无监督学习的显著性物体检测方法及系统</td>   <td>广东省</td>   <td>CN113326886A</td>   <td>2021-08-31</td>   <td>本发明公开了一种基于无监督学习的显著性物体检测方法及系统,所述方法包括：获取目标域样本,所述目标域样本的标签为使用上一轮迭代得到的模型在目标域图像进行预测得到的伪标签；对所述伪标签进行不确定性评估,并进行不确定性排序；根据排序结果,对所述伪标签进行图片级筛选,得到伪标签不确定性低于预设阈值的目标域样本；对所述目标域样本进行像素级伪标签重加权处理,得到用于下一个迭代训练的目标域样本。本发明提供的基于无监督学习的显著性物体检测方法,可以在不依赖人工标签的情况下,在多个显著性物体检测数据集上取得优异的性能,并达到与全监督显著性检测方法相匹敌的能力,大大减轻了显著性物体检测方法对像素级人工标签的依赖性。</td>   <td>1.一种基于无监督学习的显著性物体检测方法,其特征在于,包括：获取目标域样本,所述目标域样本的标签为使用上一轮迭代得到的模型在目标域图像进行预测得到的伪标签；对所述伪标签进行不确定性评估,并进行不确定性排序；根据排序结果,对所述伪标签进行图片级筛选,得到伪标签不确定性低于预设阈值的目标域样本；对所述目标域样本进行像素级伪标签重加权处理,得到用于下一个迭代训练的目标域样本。</td>   <td>G06K9/62;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄小红;                   郭伟健       </td>   <td>中山大学·深圳;中山大学</td>   <td>基于高分辨率网络的SAR图像目标识别方法、装置和存储介质</td>   <td>广东省</td>   <td>CN113312998A</td>   <td>2021-08-27</td>   <td>本发明公开了一种基于高分辨率网络的SAR图像目标识别方法、计算机装置和存储介质,包括依次执行多个处理阶段,在各处理阶段内使用高分辨率网络的子网并行进行卷积处理以及分辨率特征变换,对最后一次处理阶段中各子网输出的卷积结果进行融合处理,根据融合处理的结果进行目标分类识别等步骤。本发明通过在每个处理阶段最后对各子网的卷积处理结果进行分辨率特征变换,能够充分利用多个分辨率的信息,使每一个子网都能重复接受其他并行子网的信息,可以学习到更强的语义信息和获得更大的感受野以及高分辨率的特征,能够掌握全局信息和局部细节,能够准确地识别出SAR图像中的目标。本发明广泛应用于图像识别技术领域。</td>   <td>1.一种基于高分辨率网络的SAR图像目标识别方法,其特征在于,包括：获取SAR图像；获取高分辨率网络,所述高分辨率网络包括多个子网,各所述子网具有不同的分辨率；依次执行多个处理阶段,每个所述处理阶段内均有若干个所述子网并行进行卷积处理；在第一个所述处理阶段内,所述子网对所述SAR图像进行卷积处理；在除了第一个所述处理阶段的其他所述处理阶段内,所述子网对分辨率特征变换结果进行卷积处理,所述分辨率特征变换结果是通过获取上一个所述处理阶段各所述子网的卷积处理结果,将各所述卷积处理结果的分辨率特征变换至与本次所述处理阶段内所述子网相适应后获得的；对最后一次所述处理阶段中各所述子网输出的卷积结果进行融合处理；根据所述融合处理的结果进行目标分类识别。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏卓;              陈敏诗;                   周凡       </td>   <td>中山大学</td>   <td>基于图表示和改进Transformer的人体解析方法</td>   <td>广东省</td>   <td>CN113313173A</td>   <td>2021-08-27</td>   <td>本发明公开了一种基于图表示和改进Transformer的人体解析方法。本发明从高维的特征表示嵌入为低维的图特征,并以改进的Transformer来进行推理计算,捕捉上下文特征关系,生成新的图特征重新解码为精解析图,从而以高效的方式迭代训练整个模型得到最终的解析结果。本发明仅根据人体层次结构的先验知识,更高效率地进行推理计算；对图表示的人体部位特征进行推理,能够在后续的迭代推理中节约更多的计算成本；改进了Transformer的结构,对人体各个部位特征的上下文信息进行全局性提取和整合,从而全面地感知不同人体部位的关联度,使得解析结果的精度更高。</td>   <td>1.一种基于图表示和改进Transformer的人体解析方法,其特征在于,所述方法包括：第一步,从服装数据集输入原始人体图像和分割真值图,并做预处理；第二步,对所述预处理后的原始人体图像,使用DeeplabV3+网络生成粗解析图,并计算得到各个部位的分割掩码；第三步,根据人体层次结构的先验知识,定义出语义类别数目和标签层次结构信息,从而定义三种邻接矩阵,作为输入图-Transformer结构的掩膜；第四步,利用所述各个部位的分割掩码,以及利用所述语义类别数目和标签层次结构信息,将高维的所述粗解析图嵌入表示为图特征；第五步,利用所述图特征和所述三种邻接矩阵,通过图-Transformer结构对全局信息推理传播,计算出新的图特征；第六步,使用所述新的图特征和所述各个部位的分割掩码,计算出中间解析图,将其与所述粗解析图进行融合得到精解析图；第七步,利用所述预处理后的原始人体图像,在神经网络的编码解码结构中重复上述第二、四、五、六步进行训练,形成最终人体解析模型；第八步,输入待处理人体图像到所述最终人体解析模型中,得到需要的精解析图。</td>   <td>G06K9/62;G06K9/36;G06K9/42;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘立林;                   罗志宇       </td>   <td>中山大学</td>   <td>一种三维语义地图构建方法</td>   <td>广东省</td>   <td>CN113313824A</td>   <td>2021-08-27</td>   <td>本发明属于地图构建技术领域,更具体地,涉及一种三维语义地图构建方法,包括可基于GPU并行处理的配准图像线程、局部地图与全局地图线程、语义地图线程、融合线程、全局线程；同时对场景图像进行位姿求解、语义分割、图像融合及匹配等计算处理,使得SLAM系统实时性更强、地图构建速度更快,同时,在三维图像上融合语义信息,丰富地图的表现形式,以使无人机、机器人等无人移动平台设备可通过更多的维度理解场景地图,进而更加精准地控制运动轨迹,提高无人移动平台的性能。</td>   <td>1.一种三维语义地图构建方法,其特征在于,包括：可基于GPU并行处理的配准图像线程、局部地图与全局地图线程、语义地图线程、融合线程、全局线程；所述配准图像线程用于获取场景的彩色图像及深度图像,并对所述彩色图像及深度图像进行预处理,得到配准图像；所述局部地图与全局地图线程用于根据所述配准图像及深度图像求解图像之间的位姿,利用所述位姿、彩色图像、深度图像进行三维重建得到局部地图与全局地图；所述语义地图线程用于利用PSP Net对多个配准图像进行语义分割,得到二维语义图像；所述融合线程用于将所述二维语义图像分别与所述局部地图、全局地图融合,得到局部语义地图、全局语义地图；所述全局线程用于对所述局部语义地图、全局语义地图进行匹配,得到全局一致性稠密语义地图。</td>   <td>G06T17/05;G06T7/33;G06T7/10;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王凯;                   吴洁伟       </td>   <td>中山大学</td>   <td>一种基于T1加权磁共振图像的脑结构分割系统</td>   <td>广东省</td>   <td>CN113298813A</td>   <td>2021-08-24</td>   <td>本发明公开了一种基于T1加权磁共振图像的脑结构分割系统,其系统包括：图像预处理模块、脑结构分割模块、后处理模块和分割结果展示模块。在深度学习模型的基础上,结合提出的洋葱式后处理算法,有效解决了头骨和侧脑室难以精准分割的问题。提出的后处理方法可以识别误分为灰质或白质的头骨部分和识别误分为背景的侧脑室部分,并修正分割结果。此外,本发明基于现代的软件技术设计并构建一个具有良好用户体验的图形界面。本发明的方法及系统可以为临床实践提供一个方便对大脑结构进行量化分析的工具,辅助医生诊断,减轻负担并提高诊断效率。</td>   <td>1.一种基于T1加权磁共振图像的脑结构分割系统,其特征在于：具体包括以下模块：图像预处理模块,脑结构分割模块,后处理模块和分割结果展示模块,图像预处理模块：对采集的T1加权图像进行预处理,判断图像是否在MNI空间,如不在MNI空间则先进行刚性变换对齐到MNI空间；脑结构分割模块：基于nnUNet框架训练分割模型对图像预处理模块的输出图像进行分割；后处理模块：采用洋葱式后处理方法,利用脑结构空间分布位置的先验知识对分割结果进行修正；分割结果展示模块：对分割修正图像进行展示,此模块采用前后端分离设计,后端使用Flask服务器框架和Celery异步任务框架搭建,前端与后端两者通过Socket协议进行通信；在获得最终分割结果后,此模块将分割结果重叠在原图像上,并进行可视化显示。</td>   <td>G06T7/10;G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余阳;                   赖威       </td>   <td>中山大学</td>   <td>一种实现云工作流系统流程实例均衡调度的方法</td>   <td>广东省</td>   <td>CN108665157B</td>   <td>2021-08-20</td>   <td>本发明提供一种实现云工作流系统流程实例负载均衡的方法,包括：(1)使用日志分析的方法估计当前到达的流程实例在运行时期内每个监控周期内的计算资源需求；(2)使用带有缓冲队列的首次适应降序策略为当前启动的流程实例选取调度域内合适的工作流引擎。本发明所述方法能够解决传统流程实例负载均衡算法需要迁移流程实例,影响用户体验的问题。</td>   <td>1.一种实现云工作流系统流程实例均衡调度的方法,其特征在于包括工作流引擎空闲资源监控和流程实例调度两个部分；其中所述工作流引擎空闲资源监控部分为调度域内每一个工作流引擎维护一个空闲资源向量,并通过向量更新机制保证向量能实时体现工作流引擎在给定时间范围内的空闲资源；流程实例调度部分用于分析当前启动流程实例的资源需求、选取空闲资源大于流程实例需求的工作流引擎和调度流程实例至选定的工作流引擎；工作流引擎空闲资源监控部分维护一个向量列表E＝[e-1,e-2,...,e-N],其中e-i是调度域内编号为i的工作流引擎的空闲资源向量,e-i＝[e-(i,1),e-(i,2),...,e-(i,K)]；e-(i,j)表示工作流引擎e-i在从当前时刻开始的第j个监控周期内能够处理的请求；其中,N为集群中工作流引擎的数量,K为监控周期的数量,监控周期的时间长度和监控周期的数量通过配置参数设置；工作流引擎空闲资源监控包括以下步骤：i.通过压力测试程序预先测得集群中每个工作流引擎的请求处理饱和值C,将每个引擎的空闲资源向量的元素值都初始化为C；ii.每个监控周期结束时,将每个引擎的空闲资源向量的第一个元素删除,并将C插入到每个工作流引擎的空闲资源向量的末尾；当用户启动流程实例时,云工作流需要将流程实例调度到集群中的工作流引擎；流程实例调度部分包括以下步骤：i.查询和当前启动流程实例具有相同流程定义和启动用户的历史流程实例；ii.将查询结果中的流程实例按照与当前时刻的相近度大小排序,选取与当前时刻最接近的J个流程实例,J通过配置参数设置；iii.查询这J个流程实例的日志,统计这些流程实例在执行时间内的每个监控周期发送给云工作流的请求数量,得出向量集合P＝[p-1,p-2,...,p-J],p-j＝[p-(j,1),p-(j,2),...,p-(j,M)],向量中的元素p-(j,m)表示编号为j的流程实例在启动后的第m个监控周期内发送给云工作流的请求数量；计算当前启动流程实例资源需求估计向量                  iv.将当前启动流程实例插入缓冲队列的末尾；v.如果缓冲队列已满,执行步骤vi,缓冲队列的容量通过配置参数设置；否则,等待下一个到达的流程实例；vi.将流程实例资源需求估计向量中的最大元素记为流程实例的兼容度,将缓冲队列中的流程实例按照兼容度从小到大排序；vii.依次遍历缓冲队列中的流程实例,寻找集群中第一个空闲资源向量大于流程实例资源需求估计向量的工作流引擎；viii.将流程实例调度至选择的工作流引擎；ix.被选工作流引擎的空闲资源向量减去当前启动向量的资源需求估计向量。</td>   <td>G06Q10/06;G06Q10/10;H04L29/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         檀祖冰;              张彧;                   陈龙       </td>   <td>中山大学</td>   <td>一种视觉机器人的地图表示系统及其构建方法</td>   <td>广东省</td>   <td>CN110807782B</td>   <td>2021-08-20</td>   <td>本发明属于移动机器人环境表示、规划和定位领域,更具体地,涉及一种视觉机器人的地图表示系统及其构建方法。该地图表示系统由多信息体素层、地图元素层以及拓扑层的数据结构组成,分别涵盖了空间信息、场景实例、连通性三方面特征。该地图由语义信息提取模块、几何信息提取模块、场景语义提取模块、多信息体素整合模块、提取空间拓扑模块和拓扑整合模块六个模块共同完成构建。本发明仅基于视觉传感器,具有构建流程清晰,信息全面,层次关系紧密、易于可视化的优点,适用于移动机器人室内外场景的规划、定位与导航等工作。</td>   <td>1.一种视觉机器人的地图表示系统,其特征在于,包括语义信息提取模块、几何信息提取模块、场景语义提取模块、多信息体素整合模块、提取空间拓扑模块、拓扑整合模块、以及地图元素层、多信息体素层和拓扑层；其中,所述的语义信息提取模块用于利用视觉传感器在需要构造地图的环境中采集图像,并进行图像语义信息提取,得到图像分割结果；接着进行其余特定语义提取,得到特定的语义信息,特定的语义信息部分的结果最终会存储在地图元素层中；所述的几何信息提取模块用于使用视觉传感器在需要构造地图的环境中采集图像,经过计算得到深度图、顶点集合和顶点对应的法向量,接着基于深度图由几种关于距离与法线的几何特征分割深度图；所述的场景语义提取模块用于利用视觉传感器在需要构造地图的环境中采集图像,并进行场景语义提取,得到场景的分类信息,场景的分类信息是人为定义的、具有一定的标识度的场景称号；所述的多信息体素整合模块,用于将语义信息提取模块得到的图像分割结果和几何信息提取模块得到的深度分割结果进行融合,得到三维语义部件,该部件描述了场景中某一个由人类预定的有一定标识度和对规划、定位来说意义的物体；接着,结合视觉SLAM方法得到的相机位姿,将使用三维语义部件与几何信息提取模块得到的顶点集合计算得到的多信息体素,更新到地图的多信息体素层中；所述的提取空间拓扑模块用于基于所述的多信息体素整合模块得到的多信息体素层,提取出包含场景语义的三维空间凸包及表达其连接关系的拓扑信息；所述拓扑整合模块用于基于空间的相邻关系,关联所述的多信息体素整合模块中三维语义部件和所述的提取空间拓扑模块得到的三维空间凸包,计算空间节点到部件节点的拓扑信息,并将空间节点到部件节点的拓扑信息与空间节点到空间节点的拓扑信息合并,得到完整的拓扑层；所述的地图元素层、多信息体素层和拓扑层共同构成地图,拓扑层将地图元素层中的三维空间凸包和三维语义部件联系起来。</td>   <td>G06T7/11;G06T7/50;G06T7/70;G06T7/80;G06T11/60;G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄志康;                   黄方军       </td>   <td>中山大学</td>   <td>一种基于分段的自适应直方图平移可逆信息隐藏方法</td>   <td>广东省</td>   <td>CN108447492B</td>   <td>2021-08-20</td>   <td>本发明公开了一种基于分段的自适应直方图平移可逆信息隐藏方法,首先将音频分为辅助段和嵌入段,对嵌入段进行分段；然后,构造辅助信息和包括秘密信息的待嵌信息,辅助信息先嵌入音频中；对嵌入段中的每个子段进行基值计算,构造子段直方图,将子段的每个元素与基值进行比对,进行平方图平移,进而将待嵌信息嵌入音频中,得到带有秘密信息的音频。本发明方案的优点在于,在保证信息被完全嵌入的情况下,每子段选取一对用于比较的基值提高了在音频上信息被嵌入的容量；音频的数值变化最多为一个单位,实现较好的听觉效果；嵌入秘密信息后的音频依然具有高信噪比。</td>   <td>1.一种基于分段的自适应直方图平移可逆信息隐藏方法,其特征在于,包括以下步骤：S1.获取原始音频、密钥、秘密信息S和嵌入量EC；其中,所述密钥的内容为十进制数或者任意字符串,用于指定一段音频中为辅助段的音频元素；所述秘密信息S的内容为被转换为二进制流的文本或者图片；S2.通过所述密钥从原始音频中随机选取一定长度的辅助段,剩余的均为嵌入段；S3.设定分段阈值L的初始值,将所述嵌入段均分为N个长度为L的子段；S4.将所述分段阈值L和嵌入量EC的信息组合为与辅助段的长度一致的辅助信息,并转换为二进制格式的辅助信息流X,将辅助段的最低有效位LSB的值与秘密信息S组合为待嵌信息M,将辅助信息流X的值依次替换辅助段的最低有效位LSB处的值；S5.对所述嵌入段的每个子段均进行基值计算,从子段中选择第一元素数值p1和第二元素数值p2,从两者中比较出较大值和较小值,作为两个用于后续比较的基值,其中,较大值为max-p,较小值为min-p,比较的计算过程如下列公式所示：max-p＝max(p1,p2)；min-p＝min(p1,p2)；S6.对所述嵌入段的每个子段均构造以max-p和min-p为嵌入点的子段直方图,顺序扫描子段中其他元素的数值p,判断p与max-p和min-p之间的关系并做出相应的变动,具体过程用以下公式表示：                  对p进行判断和处理,如果p大于max-p,则加1,子段直方图实现右移；如果p小于min-p,则减1,子段直方图实现左移；如果p同时小于max-p、大于min-p,则子段直方图保持不变；如果p等于max-p,则判断此时秘密信息中待嵌入的比特数是否为1,如果是,则将此元素数值加1,否则保持不变；如果p等于min-p,判断此时待嵌入的比特数是否为1,如果是,则将此元素数值减1,否则保持不变,完成将待嵌信息M嵌入音频,得到携带秘密信息的音频。</td>   <td>G10L19/018</td>  </tr>        <tr>   <td>中国专利</td>   <td>         戎利民;              刘斌;              余海阳;              庞卯;              刘珍珍;              骆秋霞;              陈宇勇;              武文斌;              刘仲宇;              陈子豪;              杨阳;              陈东亮;              温会泉;              谢沛根;                   吴亮       </td>   <td>中山大学附属第三医院(中山大学肝脏病医院)</td>   <td>基于MRI多模态神经成像评估脊髓损伤程度的方法</td>   <td>广东省</td>   <td>CN113284105A</td>   <td>2021-08-20</td>   <td>本发明公开了一种基于MRI多模态神经成像评估脊髓损伤程度的方法,基于MRI扫描损伤部位、高位颈脊髓和腰膨大以获得多模态神经成像,使用医学影像处理软件对神经成像中的靶区进行勾画,根据医学影像处理软件逐层计算整体脊髓面积、脊髓灰质、脊髓白质、后索高信号以及后索的以定量评估神经退变,能够从多角度多方面特别是神经微观结构反映病变组织的综合信息,让研究者和医生可以进行系统性的客观定量评估中枢神经系统继发性损伤的严重程度,还能对患者远期的预后进行预测。</td>   <td>1.一种基于MRI多模态神经成像评估脊髓损伤程度的方法,其特征在于：首先,基于MRI扫描损伤部位、高位颈脊髓和腰膨大以获得多模态神经成像；其次,使用医学影像处理软件对神经成像中的靶区进行勾画；最后,根据医学影像处理软件逐层计算脊髓面积、灰质面积、后索高信号区域,以定量评估神经退变程度。</td>   <td>G06T7/00;G06T7/13;G06T5/30;A61B5/00;A61B5/372</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄健;              林天歆;              吴少旭;              欧阳能太;              沈泽锋;              陈雄;              陈泽仕;              陈浩;                   万欢       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种图像分类方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN113269257A</td>   <td>2021-08-17</td>   <td>本发明公开了一种图像分类方法、装置、终端设备及存储介质,包括：获取图像样本,所述图像样本标注有感兴趣区域及其中目标区域的标注框坐标和类别标签；根据所述图像样本对预先建立的深度卷积神经网络进行训练,得到图像识别模型,所述图像识别模型包括特征提取模型、区域选取模型和分类模型；获取待识别图像；将所述待识别图像输入到所述图像识别模型,获得所述待识别图像中各目标区域的类别概率和相对位置坐标；根据所述目标区域的类别概率,确定所述待识别图像的分类结果。本发明提高了图像获取的准确性,适用于不同制片方式的图像,减少了工作量。</td>   <td>1.一种图像分类方法,其特征在于,包括：获取图像样本,所述图像样本标注有感兴趣区域及其中目标区域的标注框坐标和类别标签；根据所述图像样本对预先建立的深度卷积神经网络进行训练,得到图像识别模型,所述图像识别模型包括特征提取模型、区域选取模型和分类模型；获取待识别图像；将所述待识别图像输入到所述图像识别模型,获得所述待识别图像中各目标区域的类别概率和相对位置坐标；根据所述目标区域的类别概率,确定所述待识别图像的分类结果。</td>   <td>G06K9/62;G06K9/32;G06T7/00;G06T7/11;G06T3/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;                   袁雪敬       </td>   <td>中山大学</td>   <td>一种基于全局模积和局部判别差异的张量降维</td>   <td>广东省</td>   <td>CN113269328A</td>   <td>2021-08-17</td>   <td>本发明提出一种基于张量空间全局模式积下结合局部判别差异的LDA数据降维算法,实现数据降维算法的构建需要了解数据间的关系,由于此原因,数据降维算法的构建都是基于数据集并非针对单个数据。所以与常见的大数应用不同,本发明采用一个张量表示一个多维数据集。在此数据集表示中,前N-1位代表张量数据的各个维度,最后一维M表示数据集包含数据的个数。张量具有与一个矩阵的模式积可以改变张量某个维度的大小,我们选择一个低维张量和一系列低维矩阵,使得这个低维张量与这些矩阵的模式积尽量逼近给定的高维张量。相比全局或模式LDA解法,迭代解法得到的结果虽然不是问题的最优数学解,但却是保持张量数据各个维度的差异和联系的最优近似解。</td>   <td>1.一种基于全局模积和局部判别差异的张量降维算法,其特征在于：A.给出一个张量表示一个张量数据集,这里L-1,…,L-(N-1)表示张量数据各个维度的大小,而M则表示这个张量数据集所包含的张量数据的个数。张量的降维,以为例,就是要确定另一个张量这里L-n＞＞J-n,n＝1,…,N-1,这个张量就是的降维张量数据集。B.对于每一个降维张量数据记是它的K＝K-1+K-2个最近邻,并且不失一般性,我们设定前K-1个数据是与同标签的数据,而后K-2个数据是与不同标签的数据。C.我们求出局部同类数据关于的方差(局部同类方差),上式只是考虑一个降维张量数据如果考虑所有的降维张量数据,则同样地,Φ也是对称半正定矩阵。D.同理得到局部一类数据关于的方差(局部异类方差),只是考虑一个降维张量数据如果考虑所有的降维张量数据,则有Ψ也是对称半正定矩阵。E.为了便于判别分析,我们希望局部异类方差越大越好,局部同类方差越小越好,典型的广义瑞利商问题,根据广义瑞利商问题的解,矩阵与J-1 … J-(N-1)个最大的特征值所对应的J-1 … J-(N-1)个标准正交的特征向量构成矩阵W的列向量。</td>   <td>G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林天歆;              黄健;              吴少旭;              曾弘;              潘杰鑫;              陈雄;                   陈浩       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种图像检测方法、装置终端设备及存储介质</td>   <td>广东省</td>   <td>CN113269752A</td>   <td>2021-08-17</td>   <td>本发明公开了一种图像检测方法、装置终端设备及存储介质,包括：获取图像样本,并将所述图像样本切割成多个图像样本块,所述图像样本标注有感兴趣区域及图像类别；根据所述图像样本块对预先建立的深度卷积神经网络进行训练和测试,得到图像检测模型；获取待检测图像,并将所述待检测图像切割成多个待检测图像块；将所述待检测图像块输入到所述图像检测模型,得到所述待检测图像块的概率图；将所述待检测图像块的概率图拼接成所述待检测图像的概率图,以获得所述待检测图像的感兴趣区域定位结果和分类结果,这样实现了面对复杂图像时能够精确、有效的进行主体区域的检测、分离,提高了病理图像检测的准确性,减少了工作量。</td>   <td>1.一种图像检测方法,其特征在于,包括：获取图像样本,并将所述图像样本切割成多个图像样本块,所述图像样本标注有感兴趣区域及图像类别；根据所述图像样本块对预先建立的深度卷积神经网络进行训练和测试,得到图像检测模型；获取待检测图像,并将所述待检测图像切割成多个待检测图像块；将所述待检测图像块输入到所述图像检测模型,得到所述待检测图像块的概率图；将所述待检测图像块的概率图拼接成所述待检测图像的概率图,以获得所述待检测图像的感兴趣区域定位结果和分类结果。</td>   <td>G06T7/00;G06T7/11;G06T3/40;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林天歆;              黄健;              吴少旭;              董文;              陈雄;              沈泽锋;                   陈浩       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>一种图像区域分割方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN113269794A</td>   <td>2021-08-17</td>   <td>本发明公开了一种图像区域分割方法、装置、终端设备及存储介质,包括：获取待分割图像；将所述待分割图像输入到预先建立的深度残差模型,得到所述待分割图像的特征图像；将所述待分割图像的特征图像作为一预先建立的金字塔场景分割模型的输入,通过所述金字塔场景分割模型将局部和全局的语境信息进行融合,以输出区域分割预测结果。本发明提高了图像区域分割的准确度,大大降低了现有技术中依赖人工经验带来的出错率。</td>   <td>1.一种图像区域分割方法,其特征在于,包括：获取待分割图像；将所述待分割图像输入到预先建立的深度残差模型,得到所述待分割图像的特征图像；将所述待分割图像的特征图像作为一预先建立的金字塔场景分割模型的输入,通过所述金字塔场景分割模型将局部和全局的语境信息进行融合,以输出区域分割预测结果。</td>   <td>G06T7/11;G06T5/50;G06T3/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈利;              邓小武;              彭应林;              孙文钊;                   高兴旺       </td>   <td>中山大学肿瘤防治中心</td>   <td>一种基于深度学习的医学图像配准方法及终端</td>   <td>广东省</td>   <td>CN113269815A</td>   <td>2021-08-17</td>   <td>本发明公开了一种基于深度学习的医学图像配准方法及终端,对待配准移动图像和待配准固定图像进行预处理和拼接；使用U型网络在拼接图像的基础上预测得到待配准移动图像与待配准固定图像间的流场,通过得到的流场对待配准移动图像进行重采样,从而通过无监督的学习方法避免了配准过程中对大量数据标签的依赖,提高配准的计算速度；对重采样后的待配准移动图像和待配准固定图像进行配准,并使用损失函数对配准图像进行调整,能够通过损失函数衡量配准过程中预测值与样本值的距离,进一步提高配准图像的精度；因此本发明使用U型网络进行流场预测,基于流场进行图像配准,使用损失函数进行配准图像的调整,快速准确地实现医学图像的配准。</td>   <td>1.一种基于深度学习的医学图像配准方法,其特征在于,包括步骤：获取待配准移动图像和待配准固定图像,对所述待配准移动图像和待配准固定图像进行预处理；将预处理后的所述待配准移动图像和待配准固定图像进行拼接得到拼接图像；使用U型网络对所述拼接图像进行预测得到所述待配准移动图像与待配准固定图像间的流场,根据所述流场对所述待配准移动图像进行重采样；对重采样后的待配准移动图像和待配准固定图像进行配准得到配准图像,使用多个损失函数对所述配准图像进行调整并验证调整后的配准图像。</td>   <td>G06T7/33;G06T7/38;G06T7/269;G06T7/246;G06T7/00;G06N3/08;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         文永明;              方译权;                   成慧       </td>   <td>中山大学</td>   <td>基于几何约束协同注意力网络的6D位姿估计方法和装置</td>   <td>广东省</td>   <td>CN113269830A</td>   <td>2021-08-17</td>   <td>本发明公开了基于几何约束协同注意力网络的6D位姿估计方法和装置,方法包括：从场景图像中提取第一图像块和第二图像块；从第一图像块中提取第一稠密特征,以及从第二图像块中提取第二稠密特征；对第一稠密特征进行采样处理得到第一采样特征,并对第二稠密特征进行采样处理得到第二采样特征；将第一采样特征和第二采样特征进行连接,得到场景全局特征；确定模型几何特征；根据场景全局特征和模型几何特征,确定协同注意力响应图；根据协同注意力响应图确定总体多模态特征；将总体多模态特征输入位姿估计网络中,预测得到对象的6D位姿。本发明能够提高位姿估计的性能,可广泛应用于机器人视觉技术领域。</td>   <td>1.基于几何约束协同注意力网络的6D位姿估计方法,其特征在于,包括：从场景图像中提取第一图像块和第二图像块；从所述第一图像块中提取第一稠密特征,以及从所述第二图像块中提取第二稠密特征；对所述第一稠密特征进行采样处理得到第一采样特征,并对所述第二稠密特征进行采样处理得到第二采样特征；将所述第一采样特征和所述第二采样特征进行连接,得到场景全局特征；确定模型几何特征；根据所述场景全局特征和所述模型几何特征,确定协同注意力响应图；根据所述协同注意力响应图确定总体多模态特征；将所述总体多模态特征输入位姿估计网络中,预测得到对象的6D位姿。</td>   <td>G06T7/73;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘坤华;              陈龙;              张亚琛;                   袁湛楠       </td>   <td>中山大学</td>   <td>一种基于GAN的三维地图修复方法</td>   <td>广东省</td>   <td>CN110766797B</td>   <td>2021-08-13</td>   <td>本发明涉及深度学习技术领域,更具体地,涉及一种基于GAN的三维地图修复方法。首先,对输入的原始待修复色彩图像和其对应的待修复伪色彩视差图进行缩放和归一化处理,使其大小为H*W；其次,把待修复色彩图像和待修复伪色彩视差图输入到生成模型；再次,生成模型完成对待修复色彩图像和待修复伪色彩视差图的修复,得到修复后的色彩图像和修复后的伪彩色视差图。本发明提供的基于GAN的三维地图修复方法中生成模型和判别模型均有卷积神经网络构成,卷积神经网络可以很好地提取图像特征,解决传统方法难处理无纹理或弱纹理的图像的问题。</td>   <td>1.一种基于GAN的三维地图修复方法,其特征在于,首先,对输入的三维地图中原始待修复色彩图像和其对应的待修复伪色彩视差图进行缩放和归一化处理,使其大小为H*W；其次,把待修复色彩图像和待修复伪色彩视差图同时传入生成模型,生成模型同时对其进行修复；再次,生成模型完成对待修复色彩图像和待修复伪色彩视差图的修复,得到修复后的色彩图像和修复后的伪彩色视差图；所述的生成模型的训练过程包括以下步骤：S21.把待修复色彩图像和其对应的待修复伪色彩视差图输入到生成模型,其中,色彩图像或伪彩色视差图的生成器损失函数L-(gen),L-(gen)为真色彩图像与待修复的色彩图像判别结果L1距离的期望,或者真伪色彩图与待修复的伪彩色视差图判别结果L1距离的期望：                  式中,x为真色彩图像或真伪色彩图；          为待修复的色彩图像或伪彩色视差图；          为待修复的色彩图像或伪彩色视差图经过生成器的预测结果；D(x)为真色彩图像或真伪色彩图的真值；S22.生成模型完成对待修复色彩图像和待修复伪色彩视差图的修复,得到修复后的色彩图像和修复后的伪彩色视差图。</td>   <td>G06T17/05;G06T5/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡天江;              朱劭豪;              朱波;              王勇;              张清瑞;                   潘亮       </td>   <td>中山大学</td>   <td>一种狼群围猎行为状态智能识别方法及系统</td>   <td>广东省</td>   <td>CN113255549A</td>   <td>2021-08-13</td>   <td>本发明公开了一种狼群围猎行为状态智能识别方法及系统,所述方法包括以下步骤:动物个体检测,其中,包括输入：狼群围猎视频,输出：视频每一帧图片动物所在的区域及动物种类；动物个体追踪,其中,包括输入：个体检测部分输出的每一帧的动物所在区域,输出：视频每一帧里成功追踪的动物编号；动物个体运动状态识别,其中,包括输入：视频每一帧每一个动物的区域及编号,输出：视频每一帧每一个动物的运动状态。本发明的系统的鲁棒性较强；本发明系统将目标外观空域流特征与运动时域流特征结合,共同判断种群里每一个个体的物种信息和运动状态,即针对群体的状态识别。本发明系统能直接运用于自然环境下的行为观测,使利用无人机实时观测和监督动物群落状况成为可能。</td>   <td>1.一种狼群围猎行为状态智能识别方法及系统,所述系统包括至少一个处理器、分别与所述处理器通信连接的存储器与摄像设备；其中,所述处理器通过调用所述存储器中存储的计算机程序,用于对所述摄像设备获取的视频执行所述方法,其特征在于,所述方法包括以下步骤:S1动物个体检测,其中,包括输入：狼群围猎视频,输出：视频每一帧图片动物所在的区域及动物种类；S2动物个体追踪,其中,包括输入：个体检测部分输出的每一帧的动物所在区域,输出：视频每一帧里成功追踪的动物编号；S3动物个体运动状态识别,其中,包括输入：视频每一帧每一个动物的区域及编号,输出：每一个动物的运动状态和结果可视化视频。</td>   <td>G06K9/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              严文俊;                   曾莹       </td>   <td>中山大学</td>   <td>一种基于光照差异消除的人脸活体检测方法及系统</td>   <td>广东省</td>   <td>CN113255562A</td>   <td>2021-08-13</td>   <td>本发明公开了一种基于光照差异消除的人脸活体检测方法及系统,该方法包括：获取人脸图像并输入到欺骗信息生成支路,得到欺骗信息；将人脸图像输入到光照生成模块模拟不同光照条件并分别提取对应的人脸特征；将不同光照条件下对应的人脸特征进行相似度约束,得到共同特征；将欺骗信息与共同特征结合判断,得到判断结果。该系统包括：欺骗信息单元、特征提取单元、特征约束单元和识别单元。通过使用本发明,能够消除光照对活体检测的影响,提高人脸活体检测的准确度。本发明作为一种基于光照差异消除的人脸活体检测方法及系统,可广泛应用于人脸图像处理领域。</td>   <td>1.一种基于光照差异消除的人脸活体检测方法,其特征在于,包括以下步骤：获取人脸图像并输入到欺骗信息生成支路,得到欺骗信息；将人脸图像输入到光照生成模块模拟不同光照条件并分别提取对应的人脸特征；将不同光照条件下对应的人脸特征进行相似度约束,得到共同特征；将欺骗信息与共同特征结合判断,得到判断结果。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>              姚军艇       </td>   <td>中山大学</td>   <td>一种建筑物的虚拟三维重建及场景创建方法</td>   <td>广东省</td>   <td>CN113256802A</td>   <td>2021-08-13</td>   <td>本发明公开了一种建筑物的虚拟三维重建及场景创建方法,属于三维图形设计领域,该创建方法具体步骤如下：(1)采集建筑物基本信息以及环境信息；(2)建模软件开始构建建筑物模型以及环境模型；(3)接收场景信息并开始进行虚拟场景构建；(4)对构建完成的场景进行细节优化；(5)对虚拟模型上进行数据标注并生成相关设计文档；本发明能够自行对建筑物、场景设计以及环境进行协调性判断与优化,提高建筑以及场景设计时与周围环境的环境协调性,符合人与自然和谐发展的需求,保护自然环境,节省资源,无需工作人员手动对建筑各部分进行标注,同时节省工作人员撰写设计文档的时间,提高工作人员的工作效率。</td>   <td>1.一种建筑物的虚拟三维重建及场景创建方法,其特征在于,该创建方法具体步骤如下：(1)采集建筑物基本信息以及环境信息：通过人工采集或智能采集设备采集建筑物数据以及环境数据,同时将采集到的数据进行数据分类,并将分类完成的数据上传至云端数据库中进行存储,智能采集设备具体为智能机器人或无人机中的一种；(2)建模软件开始构建建筑物模型以及环境模型：工作人员启动建模软件,建模软件开始与云端数据库通信连接,并开始对云端数据库中存储的数据进行检索调用,相关数据调用完成,建模数据开始构建建筑物三维模型以及环境三维模型；(3)接收场景信息并开始进行虚拟场景构建：用户发送场景信息,建模软件接收到场景信息,并开始进行场景模型构建,并对其进行数据标注；(4)对构建完成的场景进行细节优化：场景模型构建完成,开始对建筑模型、环境模型以及场景模型进行智能检测,并开始对场景模型各细节处进行数据优化；(5)对虚拟模型上进行数据标注并生成相关设计文档：模型优化完成,开始对建筑模型、环境模型以及场景模型更改处进行数据标注,同时智能生成相关设计文档,并将其上传至信息数据库进行分类存储。</td>   <td>G06T17/00;G06F30/13;G06F30/27;G06F111/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              庞志勇;                   黄铚聪       </td>   <td>中山大学</td>   <td>一种多视点图像合成方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN113256544A</td>   <td>2021-08-13</td>   <td>本发明公开了一种多视点图像合成方法、系统、装置及存储介质。该方法包括以下步骤：获取原始图像,根据原始图像获取深度特征图；根据缩放因子对深度特征图的深度维度进行插值处理得到第一深度特征图,缩放因子用于调节深度特征图的视点；根据第一深度特征图和原始图像,得到视点图像,若干张视点图像组成多视点图像。本发明利用缩放因子在原始图像的深度特征图的深度维度上进行插值处理,得到包含新的深度信息的第一深度特征图,再将第一深度特征图与原始图像进行融合,即可得到包含有新视点的视点图像,多张包含不同视点的视点图像即可组成多视点图像,具有价格低廉、应用范围广的特点。本发明可广泛应用于视点图像合成方法技术领域内。</td>   <td>1.一种多视点图像合成方法,其特征在于,包括以下步骤：获取原始图像,根据所述原始图像获取深度特征图；根据缩放因子对所述深度特征图的深度维度进行插值处理得到第一深度特征图,所述缩放因子用于调节所述深度特征图的视点；根据所述第一深度特征图和所述原始图像,得到视点图像,若干张所述视点图像组成多视点图像。</td>   <td>G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>              孙雪冬       </td>   <td>中山大学</td>   <td>一种基于知识拓扑关系的群体教学内容量化优化方法</td>   <td>广东省</td>   <td>CN109345047B</td>   <td>2021-08-10</td>   <td>本发明公开了一种基于知识拓扑关系的群体教学内容量化优化方法,首先,对研究对象进行限定,再给出研究对象群体的折中优化模型；然后,创建相关知识图谱描述,并由此图谱获得学习个体的个性化知识图谱；试设定群体的知识目标和知识背景,并进行个体知识目标及知识背景划分；最后,进行群体补充知识及冗余知识求解,并计算相应的补充量及冗余量,并根据优化目标、重复前面步骤进行群体教学内容优化,给出此时个体的补充知识及冗余知识。本发明可以根据群体中个体的知识目标和知识背景,给出优化的群体知识目标、知识背景及教学内容,并给出每个个体需要补充的知识元及冗余知识元,解决了传统教学计划制定中教学内容无法进行量化优化的难题。</td>   <td>1.一种基于知识拓扑关系的群体教学内容量化优化方法,其特征在于：该方法包括以下步骤：步骤1,限定研究对象,所述研究对象包括由知识目标和知识背景相近的多个学习个体构成的学习群体；通过分析所述学习群体与所述学习个体的关系,给出所述学习群体教学内容优化模型,所述模型为基于学习群体冗余知识量和补充知识量的折中优化模型；根据知识特点及学习群体与学习个体的学习实际情况给出进行优化求解的基本前提；步骤2,根据所述学习群体中所述学习个体的知识目标进行相关知识图谱选择或创建,并基于有向超图对所述相关知识图谱进行描述,用有向超图的节点描述某一领域所包含的知识元,用有向超图的超边描述所述知识元之间的关系；所述知识元是指不可再分割的、具有完备知识表达的知识单位；在所述相关知识图谱上进行学习个体原知识目标和原知识背景描述,获得个性化知识图谱；步骤3,根据所述学习群体中包含的所述学习个体的知识目标和知识背景试设定所述学习群体的知识目标和知识背景；所述学习群体的知识目标和知识背景的设定为基于个体的群体知识目标与知识背景设定,该步骤分为如下两方面：1)根据个体知识目标设定群体知识目标选择个体知识目标中出现频率较高的知识元作为学习群体知识目标,具体选择过程为：假设学习群体中个体i的知识目标集为：PObjKESet-i,PObjKESet-i＝{ke-(ij)|j＝1,…,in},i＝1,2,……,n,n表示学习个体数量,ke-(ij)为知识元；in为个体i目标中的知识元数；我们可以应用如下算法生成群体知识目标GObjKESet；群体知识目标生成算法,该算法分两步：步骤一,进行群体中个体知识目标中知识元及其出现次数统计,并找出出现次数最大值maxon；设定可能的目标知识集初始值PPObjKESet＝{Ф}及最高频率的初始值maxon＝0；针对每个学习者的目标集PObjKESet-i,选择其中的每个知识元ke-(ij),把知识元ke-(ij)与PPObjKESet中的知识元相比较,判断是否存在于PPObjKESet；如果不存在于PPObjKESet,则把该知识元加入到该集合,并设置该知识元出现频率sn-(ij)＝1；如果存在于PPObjKESet,则sn-(ij)++；把sn-(ij)与maxon相比较,如果sn-(ij)&gt;maxon,则maxon＝sn-(ij)；重复上述操作,直到所有个体的所有目标知识元都遍历；步骤二,生成群体知识目标；设定x值,x＝0.0～1.0,计算x*maxon；对于其出现次数为sn-i,将sn-i与x*maxon相比较；如果sn-i≥x*maxon,则ke-i∈GObjKESet；当x＝0.0时,表示取其中个体知识目标的并集作为群体知识目标；当x＝1.0时,并且每个个体中知识元只出现一次时,表示取其中个体目标知识的交集作为群体知识目标；当每个个体的目标知识元出现不止一次时,x*maxon表示以出现频率最高的知识元作为学习群体的目标知识元；2)根据个体知识背景设定群体知识背景选择个体学习中出现频率较高的背景知识元作为群体背景知识,具体选择过程为：假设学习群体中个体的知识背景为：PBGKESet-i,i＝1,2,……,n,共n个学习者；假设学习群体中出现频率最高的知识元出现次数为：maxbn,我们选择出现频率≥y*maxbn,y＝0.0～1.0的知识作为学习群体的背景知识；当y＝0.0时,表示取个体背景知识的并集作为群体知识背景；当y＝1.0时,表示取个体背景知识的交集作为群体知识目标；群体知识背景生成算法与群体知识目标生成算法相似,这里省略；步骤4,根据试设定的所述学习群体知识目标和知识背景,进行所述学习个体知识目标及知识背景划分,其中,所述学习个体目标知识划分为：公共目标知识集、多余目标知识集、补充目标知识集；所述学习个体知识背景划分为：公共背景知识集、重复背景知识集、补充背景知识集；并给出所述学习个体知识目标和知识背景的形式化描述；步骤4的个体知识目标及知识背景的划分,都划分为三部分：假设群体知识目标为：GObjKESet,原个体知识目标分别为PObjKESet-i,i＝1,2,……,n,共n个学习者；则在群体教学环境下的个体知识目标为：GPObjKESet-i＝GObjKESet∪PObjKESet-i；则个体目标知识可分为：部分1,既属于群体知识目标,又属于个体知识目标,我们称之为公共目标知识,可形式化描述为：CPObjKESet-i＝GObjKESet∩PObjKESet-i；部分2,属于群体知识目标,但不属于个体知识目标,此部分相对于个体为多余,我们称之为多余目标知识,可形式化描述为：RPObjKESet-i＝GObjKESet-i-GObjKESet∩PObjKESet-i；部分3,属于个体知识目标,但不属于群体知识目标,此部分需要个体补充学习,我们称之为补充目标知识,可形式化描述为：SPObjKESet-i＝PObjKESet-i-GObjKESet∩PObjKESet-i；同理,假设群体知识背景为：GBKGKESet,原个体知识背景分别为：PBGKESet-i,i＝1,2,……,n,共n个学习者；则在群体教学环境下个体知识背景为：GPBGKESet-i＝GBKGKESet∩PBGKESet-i；则个体背景知识可分为：部分1,既属于群体背景,又属于个体背景,我们称之为公共背景知识,可形式化描述为：CPBKGKESet-i＝GBKGKESet∩PBGKESet-i；部分2,属于群体背景,但不属于个体背景,此部分相对于个体为需要补充知识,我们称之为补充背景知识,可形式化描述为：SPBGKESet-i＝GBKGKESet-i-GBKGKESet∩PBGKESet-i；部分3,属于个体背景,但不属于群体背景,此部分相对个体为重复学习知识,我们称之为重复背景知识,可形式化描述为：RPBGKESet-i＝PBGKESet-i-GBKGKESetet于群体背景；步骤5,进行所述学习个体的公共知识、补充知识及冗余知识求解,在此基础上,给出群体教学内容、个体学习内容的求解公式,进而进行相应的学习群体的补充知识量、冗余知识量计算；根据优化目标,重复前面步骤,进行群体教学内容优选,并给出此时学习个体的补充知识集、冗余知识集。</td>   <td>G06Q10/04;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>              毛锦庚       </td>   <td>中山大学南方学院</td>   <td>一种抗摔型计算机键盘</td>   <td>广东省</td>   <td>CN213934826U</td>   <td>2021-08-10</td>   <td>本实用新型公开了一种抗摔型计算机键盘,包括键盘本体、限位槽和键盘连接线,所述键盘本体的外侧安装有橡胶软垫,且键盘本体的后表面对称连接有连接板,所述限位槽开设在键盘本体的后侧中心位置,且限位槽的外侧安装有连接杆,所述键盘连接线连接在键盘本体的后侧位置,所述连接杆的末端安装有连接块,且连接块与橡胶软垫之间安装有紧固板,所述紧固板的内部固定对称安装有弹簧,且弹簧的末端连接有紧固块,所述紧固块的外侧连接有连接带,所述键盘本体的左右两端均贯穿安装有固定板。该抗摔型计算机键盘,不仅对键盘进行保护,使得键盘抗摔,而且方便进行收纳,实用性强。</td>   <td>1.一种抗摔型计算机键盘,包括键盘本体(1)、限位槽(4)和键盘连接线(6),其特征在于：所述键盘本体(1)的外侧安装有橡胶软垫(2),且键盘本体(1)的后表面对称连接有连接板(3),所述限位槽(4)开设在键盘本体(1)的后侧中心位置,且限位槽(4)的外侧安装有连接杆(5),所述键盘连接线(6)连接在键盘本体(1)的后侧位置,所述连接杆(5)的末端安装有连接块(7),且连接块(7)与橡胶软垫(2)之间安装有紧固板(8),所述紧固板(8)的内部固定对称安装有弹簧(9),且弹簧(9)的末端连接有紧固块(10),所述紧固块(10)的外侧连接有连接带(11),所述键盘本体(1)的左右两端均贯穿安装有固定板(12),且固定板(12)的内部贯穿安装有承载杆(13),所述承载杆(13)的上下两端均连接有承载块(14)。</td>   <td>G06F3/02;B42F7/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              郭浩翀;                   林谋广       </td>   <td>中山大学</td>   <td>一种基于生成对抗网络的图像去雨滴方法</td>   <td>广东省</td>   <td>CN108230278B</td>   <td>2021-08-06</td>   <td>本发明实施例公开了一种基于生成对抗网络的图像去雨滴方法。该方法主要通过构建生成对抗网络,利用深度去雨算法,提供一种更加高效显著的图像去雨方法,在实际使用中只需要把图片输入生成式网络中,通过一次前向传播即可得到结果图片,相比起传统的图像处理方法会有更高效的效果,此外,在模型中引入特征空间上的感知相关性,可以调整部分去雨效果的细节,使得生成的图像更加清晰直观,在图像增强方面可以提供更好的效果。</td>   <td>1.一种基于生成对抗网络的图像去雨滴方法,其特征在于,所述方法包括：从数据库中获取外景图片集；图像预处理,为所获取到的外景图片集加入下雨效果,构建训练集和测试集；构建生成式网络,其输入为带雨场景图像,输出为清晰场景图像；根据像素空间上的误差训练生成式网络；加入特征空间上的误差再次训练生成式网络；构建判别式网络,其输入为真实样本或者由生成器生成的样本,输出为真或假的单个标识；把判别式网络加入到模型之中,采用误差反向传播算法训练所述的生成式网络；将测试集中的带雨场景图输入训练好的生成式网络中,输出为对应的清晰场景图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;              薛飞;                   刘红梅       </td>   <td>中山大学</td>   <td>一种JPEG重压缩图像篡改定位方法</td>   <td>广东省</td>   <td>CN108269221B</td>   <td>2021-08-06</td>   <td>本发明涉及数字图像取证技术领域,更具体地,涉及一种JPEG重压缩图像篡改定位方法。包括以下步骤：S1.估计DCT系数值,计算出篡改区域的DCT系数C-1和未篡改区域的DCT系数C-2的值；S2.用归一化灰度梯度共生矩阵对DCT系数分布的混合模型进行建模；S3.计算出带未知参数的DCT系数条件概率；S4.对未知参数进行估计,将估计得到的参数代入至S3步骤中,得到不含未知参数的DCT系数条件概率；S5.计算某一频率f上的篡改概率图S6.得到DCT系数块的篡改概率图；S7.利用连通性和高斯权值滤波对篡改概率图后处理；S8.对篡改区域进行定位。本发明首次使用二阶的灰度梯度共生矩阵对DCT的混合分布进行了建模,得到了更为准确的混合分布模型,使得对JPEG重压缩篡改定位更加的准确。</td>   <td>1.一种JPEG重压缩图像篡改定位方法,其特征在于,包括以下步骤：S1.估计DCT系数值,计算出篡改区域的DCT系数C-1和未篡改区域的DCT系数C-2的值；S2.用归一化灰度梯度共生矩阵对DCT系数分布的混合模型进行建模；S3.计算出带未知参数的DCT系数条件概率；S4.对未知参数进行估计,将估计得到的参数代入至S3步骤中,得到不含未知参数的DCT系数条件概率；S5.计算某一频率f上的篡改概率图：提取测试图片某一频率f上的DCT系数值组成一个矩阵,计算矩阵中所有点的篡改概率,这些概率值按矩阵中点的顺序就可以得到某一频率f上的篡改概率图,篡改概率图中的每一个点代表的是每个8*8块的篡改概率；S6.按zig-zag的排列顺序求出前21个AC系数的篡改概率图,21个频率上的篡改概率求平均后,得到DCT系数块的篡改概率图；S7.利用连通性和高斯权值滤波对篡改概率图后处理；S8.对篡改区域进行定位。</td>   <td>G06T1/00;G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   李纪先       </td>   <td>中山大学</td>   <td>一种基于频域差分统计特征的JPEG图像重压缩检测方法</td>   <td>广东省</td>   <td>CN108376413B</td>   <td>2021-08-06</td>   <td>本发明涉及数字图像取证技术领域,更具体地,涉及一种基于频域差分统计特征的JPEG图像重压缩检测方法,针对JPEG压缩原理,利用了DCT变换后,DCT块内的DCT系数的相关性在频域方向增强的现象,对图像的DCT系数矩阵进行了重排列,使得相邻频域的DCT系数在重排矩阵中水平相邻,然后提取重排矩阵水平差分的Markov特征,并结合图像的DCT系数矩阵的斜对角差分矩阵的水平和垂直的Markov特征作为分类特征,该特征很好地利用了块内频率域的差分信息,能够得到有效的分类器,本发明能够有效地检测图像是否经过JPEG重压缩操作,结合JPEG压缩原理,利用图像频率域的块内差分统计特征作为分类特征,具有较好的检测效果,有效提高了检测的准确率。</td>   <td>1.一种基于频域差分统计特征的JPEG图像重压缩检测方法,其特征在于,包括以下步骤：S1.选取图像训练集：训练集由各种质量因子QF1压缩的单次JPEG压缩图像和由质量因子QF1、QF2压缩得到的JPEG重压缩图像构成,其中,QF1∈{50,55,60,65,70,75,80,85,90,95},QF2∈{50,55,60,65,70,75,80,85,90,95},且QF1≠QF2；S2.对训练图像Y通道的DCT系数矩阵进行重排列；S3.提取Markov特征：先对S2中得到的重排矩阵计算水平方向的二阶差分矩阵,得到原图像频域方向的块内二阶差分矩阵,然后对该差分矩阵使用阈值T进行截断处理,大于T的数值全部用T来替换,小于-T的数值全部用-T来替换,最后对处理后的差分矩阵提取水平方向的三阶Markov转移概率矩阵,并结合原图像的DCT系数矩阵的斜对角方向的二阶差分矩阵的水平、垂直的三阶Markov转移概率矩阵,得到该图像块内的Markov特征向量；S4.训练特征准备：对所有训练集中的图像进行S3操作后,可以得到训练集中所有图像的特征向量,再将单次JPEG压缩图像的特征向量标识为1,将重压缩图像的特征向量标识为-1,并将标识好的特征集作为SVM的特征训练集,输入SVM分类模型中进行学习；S5：SVM-RFE降维：使用基于支持向量机的回归特征消除方法SVM-RFE对特征训练集进行排序,使有效的特征排在特征训练集前面,得到重排后的特征列表后,选择特征列表的前n个特征值构成新的特征向量,所有图像的n个特征组成一个新的特征向量集；S6.寻找最优的c,g参数：对S5得到的特征向量集和对应的标识集使用径向基内核的SVM进行训练,使用网格搜索的方法搜索最优的惩罚参数c和核参数g,得到分类器模型；S7.测试图像提取特征：先对测试图像进行S2中的重排列,然后提取重排矩阵的水平差分矩阵的水平方向的Markov特征向量,并提取DCT系数矩阵的斜对角差分矩阵的水平、垂直的Markov特征,即进行S3的操作,然后按照S5操作,取重排后的特征排序列表的前n个特征值,组成测试图像的特征向量；S8.分类预测：将S7得到的测试图像的特征向量输入到S6得到的SVM分类模型中,得到测试图像的预测结果；其中,1代表测试图像为单次JPEG压缩图像,-1代表测试图像为JPEG重压缩图像。</td>   <td>G06T9/00;G06K9/62;H04N19/625</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈川;              赖俞静;                   郑子彬       </td>   <td>中山大学</td>   <td>一种交叉图匹配不完整多视图聚类方法及装置</td>   <td>广东省</td>   <td>CN113221974A</td>   <td>2021-08-06</td>   <td>本申请公开了一种交叉图匹配不完整多视图聚类方法及装置,方法包括：建立不完整多模态数据的缺失值填充模型,多模态数据包括网页数据或者多媒体数据；建立不完整多模态数据的交叉图匹配模型；结合缺失值填充模型和交叉图匹配模型的目标函数,建立交叉图匹配不完整多视图聚类模型；将交叉图匹配不完整多视图聚类模型分解为三个子问题,包括优化缺失矩阵E,求解映射空间U以及更新连接矩阵S；采用迭代算法求解三个子问题直到三个子问题收敛,求得最优解。本申请在减少缺失数据的影响的同时,利用模态间一致和互补的信息来使得聚类效果得到提升。</td>   <td>1.一种交叉图匹配不完整多视图聚类方法,其特征在于,包括：建立不完整多模态数据的缺失值填充模型,所述多模态数据包括网页数据或者多媒体数据；建立不完整多模态数据的交叉图匹配模型；结合所述缺失值填充模型和所述交叉图匹配模型的目标函数,建立交叉图匹配不完整多视图聚类模型；将所述交叉图匹配不完整多视图聚类模型分解为三个子问题,包括优化缺失矩阵E,求解映射空间U以及更新连接矩阵S；采用迭代算法求解所述三个子问题直到三个子问题收敛,求得最优解。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘小平;              赵林峰;                   曾莉       </td>   <td>中山大学</td>   <td>一种基于FLUS模型和生物多样性模型的变化情景模拟方法</td>   <td>广东省</td>   <td>CN113222316A</td>   <td>2021-08-06</td>   <td>本发明公开了一种基于FLUS模型和生物多样性模型的变化情景模拟方法,本发明集成了旧土地利用模拟模型的优势,消除了误差传递、改良了模型的内部的现实意义不明确的参数；FLUS模型中引入的神经网络算法计算各类用地的分布概率,再使用轮盘赌机制引入土地利用类型的竞争,实现了智能算法和不确定性机制的结合并同时应用于未来土地利用情景预测中；最终用更少的数据、更少的参数、更快的速度获取了精确度比旧土地利用模拟模型更高的模拟结果；生物多样性模型中的生态系统服务模型、物种分布模型和生物多样性指数模型计算各指标,能定量评估未来情景下的土地利用对生物多样性的影响；设置不同情景下的目标要求,能模拟获得符合情景目标的土地利用。</td>   <td>1.一种基于FLUS模型和生物多样性模型的变化情景模拟方法,其特征在于,所述方法包括两个阶段：使用土地利用模拟模块模拟土地利用阶段；通过生物多样性变化定量评估模块评估土地利用对生物多样性影响阶段；具体步骤为：使用土地利用模拟模块模拟土地利用阶段：S1：获取初始土地高分影像并进行预处理,对预处理后的高分影像解译得到分类后的影像,从分类后的影像获取初始土地利用数据；之后选取若干影响土地利用变化的驱动力因子组成驱动力数据；S2：对初始土地利用数据规定好模拟区域的范围与标准栅格影像大小,用欧式距离公式计算模拟区域内栅格到土地利用变化驱动因子的距离,生成与标准栅格影像图幅大小一致的栅格距离数据；S3：在驱动力数据与初始土地利用数据上进行随机点采样,获得采样数据；S4：使用采样数据对参数自适应神经网络算法进行训练；S5：将全部的驱动力数据数据输入训练好的神经网络,通过神经网络计算获得每种土地利用类型在模拟区域内的分布概率；S6：将S5输出的分布概率与S1中的初始土地利用数据在土地利用模拟模块中进行迭代；迭代前设定好邻域大小、转换限制矩阵和每种用地类型的像元个数；S7：迭代扫描初始土地利用数据的像元,计算每个像元在邻域内包含的土地利用类型和在邻域内所占的比例,与S5输出的分布概率、转换限制矩阵共同合成每个像元上各类土地利用类型的总分布概率；S8：将每个像元上的各类土地利用类型的总分布概率构成轮盘,通过轮盘赌的方法,使区域内各种土地利用类型在像元上竞争,竞争获胜的土地利用类型占据该像元；S9：转到步骤S7,直至迭代完一幅影像的全部有效像元,所述有效像元即土地利用数据中像元值不为空值的像元,然后返回S6刷新初始影像进入下一次迭代,计算到目标像元数目的差值；到达迭代次数R或者达到目标像元数目后,停止迭代输出模拟的土地利用结果；通过生物多样性变化定量评估模块评估土地利用对生物多样性影响阶段：S10：对模拟的土地利用和初始土地利用数据进行计算,获得土地利用转换矩阵；S11.将模拟的土地利用和生态系统服务数据输入生态系统服务模型,计算获得固碳释氧和水源涵养价值；S12.将模拟的土地利用和物种分布数据输入物种分布模型,计算获得生境适宜性和生境破碎化指数；S13.将模拟的土地利用和生物多样性指数数据输入生物多样性指数模型,计算获得生物丰度和平均物种丰度指数；S14.将S10中的土地利用转换矩阵、S11中的固碳释氧和水源涵养价值、S12中的生境适宜性和生境破碎化指数、S13中的生物丰度和平均物种丰度指数组成生物多样性指标定量评估结果,在评估前设定好情景方案,根据不同情景输出对于的情景模拟结果：若为驱动力情景,不受其他条件约束,评估结果直接输出作为生物多样性情景模拟结果；若为保护目标情景,受生物多样性保护目标的约束,未达到目标要求则转到S6重新进行土地利用迭代模拟,满足目标要求后则输出情景模拟结果；若为多目标情景,受城市发展目标和生物多样性保护目标的共同约束,未达到目标要求则转到S6重新进行土地利用迭代模拟,满足目标要求后则输出情景模拟结果。</td>   <td>G06Q10/06;G06Q50/26;G06N3/04;G06N3/08;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              夏文君;              郑炎辉;              宋超;                   金浩宇       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种水资源证照化管理系统</td>   <td>广东省</td>   <td>CN113222430A</td>   <td>2021-08-06</td>   <td>本发明公开了一种水资源证照化管理系统,包括：电子证照化管理子系统,包括节点管理单元、智能合约管理单元、账本查看单元、元数据管理单元和证照上传及更新单元,用于部署一区块链平台,并基于所述区块链平台实现对水资源电子证照的存储与管理；用水量指标监控子系统,包括信息采集单元、信息验证及存储单元、超额预警单元和用水量监控单元,用于根据采集的用水信息执行超额预警操作,以及通过对各用户的用水量的实时监督,对违规用水的用户执行停止供水的操作。本系统通过区块链实现了水资源证照不可篡改、全程留痕、公开透明、集体维护的存储与管理,同时,为水管理部门对各用户的用水管控策略提供了数据支撑。</td>   <td>1.一种水资源证照化管理系统,其特征在于,包括：电子证照化管理子系统和用水量指标监控子系统；所述电子证照化管理子系统包括节点管理单元、智能合约管理单元、账本查看单元、元数据管理单元和证照上传及更新单元；所述用水量指标监控子系统包括信息采集单元、信息验证及存储单元、超额预警单元和用水量监控单元；其中,所述电子证照化管理子系统用于部署一区块链平台,并基于所述区块链平台实现对水资源电子证照的存储与管理；所述水量指标监控子系统用于根据采集的用水信息执行超额预警操作,以及通过对各用户的用水量的实时监控,对违规用水的用户执行停止供水操作。</td>   <td>G06Q10/06;G06Q50/06;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王嘉辉;              杨上玄;              郭祥;              劳子健;              蔡志岗;              江灏;                   张佰君       </td>   <td>中山大学</td>   <td>一种基于特殊复合平面镜虚像成像的三维重建装置和方法</td>   <td>广东省</td>   <td>CN113223135A</td>   <td>2021-08-06</td>   <td>本发明提供一种基于特殊复合平面镜虚像成像的三维重建装置和方法,装置包括相机设备和标定-成像联合器件,其中：所述相机设备获取视场深度图；所述标定-成像联合器件其表面设置有镀银的镜面区域、漫反射区域和定位标识图像,所述镜面区域与漫反射区域位于同一平面上；所述相机设备通过标定-成像联合器件的反射,获取不在所述相机设备视场范围内的目标物的深度图。方法包括点云重建,镜面区域框定,镜面点云分离,平面拟合以及镜面对称。相比于光路几何解算,本方法无需得知相机设备,镜面,目标物之间的相对位置关系,也不要额外的标准尺寸参考物,可实现快速动态得到非直接视场的目标在相机坐标系中的空间位置,从而得到方位和距离等信息。</td>   <td>1.一种基于特殊复合平面镜虚像成像的三维重建装置,其特征在于,包括相机设备和标定-成像联合器件,其中：所述相机设备获取视场深度图；所述标定-成像联合器件其表面设置有镀银的镜面区域、漫反射区域和定位标识图像,所述镜面区域与漫反射区域位于同一平面上；所述相机设备通过标定-成像联合器件的反射,获取不在所述相机设备视场范围内的目标物的深度图。</td>   <td>G06T15/04;G06T15/00;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈刚;              凌晔华;              何涛;              何晟宇;              张余;              孟海涛;                   黄凯       </td>   <td>中山大学</td>   <td>一种基于FPGA实现的二值神经网络立体视觉匹配方法</td>   <td>广东省</td>   <td>CN111553296B</td>   <td>2021-08-03</td>   <td>本发明涉及一种基于FPGA实现的二值神经网络立体视觉匹配方法,包括以下步骤：步骤一：获取双目匹配灰度图像中的像素的周期性输入流；步骤二：从像素中获取图像块；步骤三：将步骤二中的图像块输入预设权值与参数的二值神经网络获取二值的特征向量；步骤四：将特征向量在最大搜索视差内进行代价计算,获得匹配代价；步骤五：将代价输入半全局代价聚合进行代价聚合,得到聚合后的代价；步骤六：在聚合后的代价中选择代价最小的位置作为视差；步骤七：对选择的视差进行一致性检测和视差细致化计算,得到视差图,并且按周期逐个输出像素的视差值。通过二值化的方法可以有效的降低网络的计算和存储资源,从而可以将高精度的立体匹配网络部署到FPGA中。</td>   <td>1.一种基于FPGA实现的二值神经网络立体视觉匹配方法,其特征在于,包括以下步骤：步骤一：获取双目匹配灰度图像中的像素的周期性输入流；输入图片并进行双目左右标定,标定后的图片经过矫正后按照相同的时钟周期逐个像素输入系统；步骤二：从像素中获取用于计算代价的图像块；将输入的像素按照匹配时钟输入移位寄存器中,经过预定的延时后,并行多行数据后得到一个由预设像素大小的图像块；步骤三：使用二值化策略将卷积神经网络进行二值化处理得到二值神经网络；将步骤二中的图像块输入预设权值与参数的二值神经网络获取二值的特征向量；所述二值神经网络一共四层,前一层网络的输出为下一层网络的输入,直至得到最后的特征向量；所述二值神经网络第一层有四个子层：8位量化卷积层、缩放比例层单元、归一化层单元、激活层单元；其余三层共具有四个子层：二值卷积层网络单元、缩放比例层单元、归一化层单元、激活层单元；前一个单元的输出为下一个单元的输入,最后一个单元的输出即为整层的输出；步骤四：将特征向量在最大搜索视差内进行代价计算,获得匹配代价；步骤五：将代价输入半全局代价聚合进行代价聚合,得到聚合后的代价；步骤六：在聚合后的代价中选择代价最小的位置作为视差；步骤七：对选择的视差进行一致性检测和视差细致化计算,得到视差图,并且按周期逐个输出像素的视差值。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08;G06T1/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何兆成;                   钟嘉明       </td>   <td>中山大学</td>   <td>基于公交APP用户数据的公交乘客候车时间计算方法</td>   <td>广东省</td>   <td>CN107944700B</td>   <td>2021-08-03</td>   <td>本发明利用实时公交App中海量的用户数据,通过时间关联的方法,构建公交信息查询链,并结合数据挖掘的方法,从中发现用户在公交出行中的节点时刻,如规划公交出行时刻、到站时刻和离站时刻,依此计算该用户候车时间。对于无法计算候车时间的不完整公交信息查询链,如无法识别或缺失到站行为或离站行为等记录,则利用与其相似的完整公交信息查询链,采取随机森林算法对缺失的行为记录进行修补,最终实现候车时间的计算。</td>   <td>1.基于公交APP用户数据的公交乘客候车时间计算方法,其特征在于：包括有以下步骤：S1.记录用户使用公交APP时留下的对应服务的请求数据和用户进行位置类服务请求留下的定位数据,若请求数据的请求时间与定位数据的请求时间相差在k秒以内,则将定位数据及请求数据进行时间关联,形成一个公交信息查询节点；所述请求数据包括用户ID、设备类型、请求时间、请求类型和请求内容；所述定位数据包括用户ID、定位时间、经纬度和速度；将同一用户ID的定位数据及请求数据进行时间关联；所述k为10；S2.记录用户使用公交APP出行留下的对应服务的请求数据和用户进行位置类服务请求留下的定位数据,然后按照步骤S1的方法进行处理,得到多个公交信息查询节点；S3.得到的多个公交信息查询节点按发生时间顺序进行排序,形成一条公交信息查询链；S4.根据公交信息查询链上的公交信息查询节点的定位数据分别计算各个节点与目标公交车站间的距离,以及根据定位数据确定用户在各个节点的移动速度,然后根据计算的各个节点与目标公交车站间的距离、用户在各个节点的移动速度确定公交信息查询链上的到站节点、离站节点,从而确定用户出行的到站时刻T-2和离站时刻T-3,从而计算得到候车时间：T-(候车时间)＝T-3—T-2。</td>   <td>G06Q10/06;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              李深林;              何艳虎;                   王浩       </td>   <td>中山大学;中国水利水电科学研究院</td>   <td>基于反馈机制的水资源优化配置方法</td>   <td>广东省</td>   <td>CN109034485B</td>   <td>2021-07-30</td>   <td>本发明涉及水资源管理领域,更具体地,涉及一种基于反馈机制的水资源优化配置方法。包括以下步骤：S1.构建水资源配置基础模型,运用常规水资源配置方法得到水资源初始配置方案；S2.将初始配置方案应用于实际水文情境中,由于需水不可准确预测,初始配置水量与实际需水量存在偏差,得到配置偏差序列；S3.构建反馈增益函数,利用偏差序列得到增益量；S4.利用增益量对未来时段的初始配置方案进行调整,得到反馈配置方案。本方法可以节约高效利用水资源,有效减少水资源管理的工程量,对于水资源管理具有十分重要的意义。</td>   <td>1.一种基于反馈机制的水资源优化配置方法,其特征在于,包括以下步骤：S1.构建水资源配置基础模型,运用常规水资源配置方法得到水资源初始配置方案；S2.将初始配置方案应用于实际水文资源情境中,由于需水不可准确预测,初始配置水量与实际需水量存在偏差,得到配置偏差序列；所述配置偏差序列为初始配置方案与实际需水所存在的偏差在时间推进中产生的序列,其公式为：dif(t)＝IAS(t)-RTD(t)式中,t为时刻,dif(t)为偏差序列,IAS(t)为t时刻的初始配置方案,RTD(t)为t时刻实际水资源需求；S3.构建反馈增益函数,利用偏差序列得到增益量；所述的反馈增益函数为：gain(t)＝Kr*dif(t)+Kd*∈其中,gain(t)为增益量,Kr为误差系数,∈为噪声扰动,Kd为噪声扰动系数；S4.利用增益量对未来时段的初始配置方案进行调整,得到反馈配置方案；所述的S4步骤具体包括：S41.反馈配置初始调整方案为：FAS-0(t+1)＝IAS(t+1)+gain(t)式中,FAS-0(t+1)为t+1时刻的反馈配置初始调整方案；S42.根据资源配置约束条件,对反馈配置初始调整方案做进一步调整,得到最终反馈配置方案,调整方程为：FAS(t+1)＝mid{Min(d),FAS-0(t+1),Max(d)}式中,mid是取中间值函数,Min(d)和Max(d)是已定义的可配水量的最小值和最大值；S43.将初始配置方案进行逐时刻反馈调整,得到反馈配置方案。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              朱婷;                   马天俊       </td>   <td>中山大学</td>   <td>一种基于尺度自适应的头部检测和密度图的人群计数方法</td>   <td>广东省</td>   <td>CN108154089B</td>   <td>2021-07-30</td>   <td>本发明公开一种基于尺度自适应的头部检测和密度图的人群计数方法,对图像进行特征训练和预测；首先提取图像的梯度信息和图像的前景；生成与图像对应的尺度和参数；然后分割前景图像,筛选样例；用样例进行训练得到头部的训练模型；利用训练模型进行预测,得到预测结果；根据预测结果生成多尺度密度图,将密度图加和得到预测总人数。用尺度自适应的方法结合头部检测对图片中的行人进行计数,弥补了普通的检测方法对于透视变换问题上的不足；自适应的尺度筛选方法和密度图的应用,使得本发明有更好的鲁棒性,可以适用于不同的场景。对于patch的筛选以及分类使得训练出来的模型分类能力更强,保障了人群计数的准确性。</td>   <td>1.一种基于尺度自适应的头部检测和密度图的人群计数方法,对图像进行特征训练和预测,其特征在于,包括以下步骤：S1：提取图像的梯度信息和图像的前景；S2：生成与图像对应的尺度和参数；步骤S2中利用检测模型来自动生成与图像对应的尺度和参数,包括以下步骤：S21：利用检测模型来对输入图片进行检测,得到不同尺度对于图片的匹配率,筛选出匹配率高的尺度；S22：根据尺度的大小以及图像透视矩阵权值的比例来生成每个尺度对应的参数,参数用来在之后密度图加和的时候调整该尺度下密度图的权重；S3：分割前景图像,筛选样例；S4：用样例进行训练得到头部的训练模型；S5：利用训练模型进行预测,得到预测结果；S6：根据预测结果生成多尺度密度图,将密度图加和得到预测总人数。</td>   <td>G06K9/00;G06K9/62;G06T7/194;G06T7/269</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杜川;              刘志博;              张磊;                   徐世友       </td>   <td>中山大学</td>   <td>基于深度编码网络的SAR目标识别对抗样本生成方法</td>   <td>广东省</td>   <td>CN113191268A</td>   <td>2021-07-30</td>   <td>本发明公开了一种SAR目标识别对抗样本生成方法,针对某个特定的SAR目标识别模型能够实施靶向性攻击和非靶向性攻击,包括使用靶向性攻击的损失函数以及非靶向性攻击的损失函数训练编码器网络等步骤,使编码器网络可以快速地生成输入图片的对抗样本。本发明广泛应用于雷达目标识别技术领域。</td>   <td>1.基于深度编码网络的SAR目标识别对抗样本生成方法,其特征在于,包括：获取待处理图像；所述待处理图像用于供合成孔径雷达目标识别模型进行识别处理；将所述待处理图像输入至编码器网络；获取所述编码器网络的输出结果作为对抗样本；所述对抗样本用于对所述合成孔径雷达目标识别模型进行靶向性攻击；所述编码器网络为输入输出等大的全卷积神经网络,所述编码器网络经过训练样本的训练,在训练过程中所使用的损失函数为其中x表示输入至所述编码器网络的所述训练样本,表示所述编码器网络的输出结果,f(·)表示合成孔径雷达目标识别模型对应的映射,λ表示可设定的正则项系数,k表示可设定的参数。</td>   <td>G06K9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   徐贵       </td>   <td>中山大学</td>   <td>基于调色盘的属性预测方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113192148A</td>   <td>2021-07-30</td>   <td>本发明公开了基于调色盘的属性预测方法、装置、设备及介质,方法包括：采用基于几何位置的预测值方法对待测点进行属性编码,得到初始属性预测值；对所述初始属性预测值的残差值进行统计,得到残差值统计结果；根据所述残差值统计结果采用基于调色盘的属性预测方法确定目标属性预测值。本发明的适用范围广且计算复杂度较低,可广泛应用于数据处理技术领域。</td>   <td>1.基于调色盘的属性预测方法,其特征在于,包括：采用基于几何位置的预测值方法对待测点进行属性编码,得到初始属性预测值；对所述初始属性预测值的残差值进行统计,得到残差值统计结果；根据所述残差值统计结果采用基于调色盘的属性预测方法确定目标属性预测值。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         程思锦;                   黄方军       </td>   <td>中山大学</td>   <td>基于二维直方图修改的JPEG图像可逆信息隐藏方法</td>   <td>广东省</td>   <td>CN108009975B</td>   <td>2021-07-27</td>   <td>本发明提供一种基于二维直方图修改的JPEG图像可逆信息隐藏方法,通过解码产生DCT系数；将量化的系数分成对,构建二维直方图；根据嵌入信息长度计算阈值Th,根据自适应选择JPEG图像嵌入信息的最佳频段计算阈值Tp；通过二维直方图映射方式,将可逆信息嵌入在阈值范围内的系数。本发明方法隐藏了嵌入信息,维持原始JPEG图像的文件大小,保证在嵌入信息后无损恢复原始JPEG图像。</td>   <td>1.一种基于二维直方图修改的JPEG图像可逆信息隐藏方法,其特征在于,包括以下步骤：S1：将原始JPEG图像进行熵解码得到量化的DCT系数,对于每一个8*8块,将量化的DCT系数分为32对,舍弃第一对,构造基于DCT系数的二维直方图；量化的DCT系数按照zig-zag顺序排列,一共有64个系数,其中第一个系数是DC系数,其他63个系数是AC系数,第一对系数是指(DC,AC1)；S2：计算每个8*8块中零系数个数,根据所嵌入秘密信息的长度确定阈值Th,自适应选择JPEG图像嵌入信息的最佳频段,具体方法为：计算每个8*8块中的零系数个数,并记为N,根据N的大小来选择是否利用这个8*8块来嵌入信息,如果该块被选来嵌入信息,会舍弃(DC,AC1)这个系数对,从AC2系数开始至AC63系数中依次选择相应的系数对用来嵌入信息；S3：当该块中零系数个数不小于阈值Th,所处频段小于阈值Tp的DCT系数对用来嵌入信息,将辅助信息与秘密信息通过构造的二维直方图映射方式一起嵌入到JPEG图像中；辅助信息包含L1,L2,L3,Tp,Th,其中L1表示待嵌入的秘密信息的总比特数L的位数,L3表示最佳频段阈值Tp的位数,L2表示包含零系数个数N不小于阈值Th的位数,Tp是指最佳频段阈值,其范围在1-31之间,Th是指零系数个数阈值,其范围在0-62之间；S4：在所有信息被嵌入后,将DCT系数进行熵编码得到含秘JPEG图像。</td>   <td>G06T1/00;G06T5/40;G06F21/16;G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何俊奇;                   黄方军       </td>   <td>中山大学</td>   <td>一种基于消除块效应的非对称JPEG隐写方法</td>   <td>广东省</td>   <td>CN108416725B</td>   <td>2021-07-27</td>   <td>本发明公开了一种基于消除块效应的非对称JPEG隐写方法,将图像由DCT域解压至空域,在保证图像尺寸不变的情况下,对解压后的图像进行一定的改动,得到经过改动的图像,然后将原图像的量化表转换至经过改动的图像的DCT域中；通过计算原始图像的代价值并对原图像和经过改动的图像均进行切割,调整标记系数对应的代价值,得到经过改动的图像的代价值；以经过原始图像作为载体,通过经过改动的图像的代价值和编码算法将秘密信息嵌入至经过改动的图像中,作为最终完成隐写的图像。本发明提供的隐写方法可在不影响现有隐写方法嵌入量和算法效率的基础上提高隐写方法的安全性,规避了常规DCT变换可能引起的块效应。</td>   <td>1.一种基于消除块效应的非对称JPEG隐写方法,其特征在于,包括以下步骤：S1.提取载体图像的DCT系数C和量化表q-tab,获取秘密信息；S2.根据所述DCT系数将DCT域解压到空域中,得到各子块对应的空域像素值；S3.将解压到空域的图像裁剪i行、j列,其中0≤i≤2,0≤j≤2且i+j＞0；在保证行数为i、列数为j的条件下,将经过裁剪的图像进行一定修改,得到经过修改的空域图像组C'-(i,j)；步骤S3中具体修改过程如下：先裁剪出图像的前m行补到图像下方,再裁剪出图像的前n列补到图像右侧,其中,0&lt;m&lt;i,0&lt;n&lt;j；S4.将所述空域图像组C'-(i,j)的像素值相加求均值,并利用步骤S1中的量化表q-tab将其转换到DCT域内,得到与原载体图像对应的、经过块效应消除的图像C-s,具体公式如下：                  其中,x表示图像的行,y表示图像的列；S5.计算原始的代价值ρ；S6.将所述C和C-s分成8×8的不重叠块,并将各块的边界进行标记,调整标记的系数所对应的代价值,得到新的代价值ρ'；S7.通过最终的代价值ρ'和编码算法将秘密信息嵌入到载体图像中,得到最终的隐写图像。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              龚海帆;              谢一凡;                   陈冠锜       </td>   <td>中山大学</td>   <td>甲状腺结节识别与分割方法、系统、存储介质及设备</td>   <td>广东省</td>   <td>CN113177554A</td>   <td>2021-07-27</td>   <td>本发明公开了一种甲状腺结节识别与分割方法,包括：获取预处理样本,并输入至骨架网络进行样本特征提取；将提取到的特征样本分别输入至第一分支及第二分支进行训练；分别计算训练后的第一分支的分类损失及第二分支的分割损失；通过分类损失及分割损失的线性加权得到总损失训练模型；其中,总损失训练模型能够对输入图像的甲状腺结节的良恶性类别和病变区域进行判断。本发明能够减轻对医生等人力资源的依赖,降低人为错误的可能性,实现智能化检测。同时充分考虑了甲状腺结节的影像学特点,以缓解深度学习模型由于影像类别和病理类别不一致带来的干扰问题,从而让分类器更好的学习到合适的影像学特征,实现在分类器上对病变区域的精确分割。</td>   <td>1.一种甲状腺结节识别与分割方法,其特征在于,所述方法包括：获取预处理样本,并输入至骨架网络进行样本特征提取；将提取到的特征样本分别输入至第一分支及第二分支进行训练；分别计算训练后的所述第一分支的分类损失及所述第二分支的分割损失；通过所述分类损失及所述分割损失的线性加权得到总损失训练模型。</td>   <td>G06K9/34;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              夏文君;              郑炎辉;              宋超;                   金浩宇       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种水资源溯源管理系统</td>   <td>广东省</td>   <td>CN113177730A</td>   <td>2021-07-27</td>   <td>本发明公开了一种水资源溯源管理系统,包括：水资源数据管理模块,用于对供水、用水、耗水和排水环节的水资源数据进行采集,并通过区块链平台实现水资源数据的存储与管理；水资源溯源应用模块：用于通过智能合约对上链后的各环节的水资源数据进行分析,确定水质污染和水量漏损等水资源问题,并对其进行识别与诊断,以及用于对水资源数据进行溯源,通过对水资源数据的溯源,确定水资源问题的责任方。本系统以分布式账本的形式对各环节的水资源数据进行存储与管理,数据记录过程公开透明,通过智能合约对水量、水质问题进行识别与诊断,发现问题后通过溯源直接明确产生问题的节点,无需考虑数据真伪,降低了追责成本并提高了追责效率。</td>   <td>1.一种水资源溯源管理系统,其特征在于,包括：水资源数据管理模块和水资源溯源应用模块；所述水资源数据管理模块用于对供水、用水、耗水和排水环节上的水资源数据进行采集,并通过区块链平台实现水资源数据的存储与管理；所述水资源溯源应用模块包括水资源问题检测模块和水资源数据溯源模块；所述水资源问题检测模块用于通过智能合约对上链后的各环节的水资源数据进行分析,识别出水资源问题,并对水资源问题进行诊断与分析；所述水资源数据溯源模块用于对水资源数据进行溯源,当存在水资源问题时,还用于通过对各环节的水资源数据的溯源,确定所述水资源问题产生的根源节点和相应的责任方。</td>   <td>G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              夏文君;              郑炎辉;              宋超;                   金浩宇       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种基于智能合约的水资源决策管理系统</td>   <td>广东省</td>   <td>CN113177731A</td>   <td>2021-07-27</td>   <td>本发明公开了一种基于智能合约的水资源决策管理系统,包括：水资源情报管理模块,用于将水资源数据上链至区块链平台,并通过区块链平台对所述水资源数据进行管理；水资源评价管理模块,用于根据水资源数据,通过智能合约对水资源指标进行评价及管理；水资源预测管理模块,用于根据水资源数据,对水量、水质进行预测及管理；以及水资源决策管理模块,用于根据水资源数据,通过智能合约对水量分配、水质调节和水源调度进行决策及管理。本发明通过区块链平台对大量分布式水资源数据进行管理,构造有效、不可篡改的水资源数据,基于该数据,通过智能合约对水资源情况进行评价、预测,并制定动态的水资源调配决策,实现公平的多尺度水资源管理。</td>   <td>1.一种基于智能合约的水资源决策管理系统,其特征在于,包括：水资源情报管理模块、水资源评价管理模块、水资源预测管理模块和水资源决策管理模块；所述水资源情报管理模块用于,将水资源数据上链至区块链平台,并通过区块链平台对所述水资源数据进行管理；所述水资源评价管理模块用于,根据所述区块链平台上的水资源数据,通过智能合约对水资源指标进行评价及管理,并得到水资源评价结果；所述水资源预测管理模块用于,根据所述区块链平台上的水资源数据,对水量、水质进行预测及管理,并得到水资源预测结果；所述水资源决策管理模块用于,根据所述区块链平台上的水资源数据、所述水资源评价结果和所述水资源预测结果,通过智能合约对水量分配、水质调节、水源调度进行决策及管理。</td>   <td>G06Q10/06;G06Q10/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张晓娜;              江明;              李正鹏;              区志行;                   张朝婷       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;广州极汇信息科技有限公司;中山大学</td>   <td>一种用于可见光成像定位的条纹识别和信息检测方法</td>   <td>广东省</td>   <td>CN107169952B</td>   <td>2021-07-23</td>   <td>本发明提供一种用于可见光成像定位的条纹识别和信息检测方法,该方法在接收机CMOS传感器前面放置一层减光材料来产生清晰的明暗条纹图像；从得到的明暗条纹图片中,获取有效的条纹区域；将得到的条纹区域转换为灰度图像,对灰度图像进行处理得到明暗条纹所对应的总像素行数；根据S3中得到的明暗条纹所对应的总像素行数计算得到灰度图像的估计行数值,利用该估计行数值计算出估计的FSOOK信号频率。提高了经FSOOK调制的可见光信号所产生的明暗条纹的清晰度,避免了明暗条纹图片中的高光干扰问题,具有较好的信息检测性能,从而可增加正确解调可见光信号的距离,同时还具有很低的实现复杂度。</td>   <td>1.一种用于可见光成像定位的条纹识别和信息检测方法,该方法用于采用FSOOK调制的LED发射机,且LED灯具安装有灯罩和基于CMOS图像传感器的接收机所组成的可见光通信系统,其特征在于,包括以下步骤：S1：在接收机CMOS图像传感器前面放置一层减光材料来产生清晰的明暗条纹图片；S2：从得到的明暗条纹图片中,获取有效的条纹区域；S3：将得到的条纹区域转换为灰度图像,对灰度图像进行处理得到明暗条纹所对应的总像素行数；S4：根据S3中得到的明暗条纹所对应的总像素行数计算得到灰度图像的估计行数值,利用该估计行数值计算出估计的FSOOK信号调制频率；所述步骤S3的具体过程如下：S31：求灰度图像每行像素的灰度值的平均值M-i,即每行像素灰度值总和除以该行的列数,将N个灰度平均值存储在数组G-(average)(n),n＝1,2…,N；S32：计算相邻两行像素的差值,即当前行像素值减去上一行的像素值,然后将差值与预设的灰度阈值α进行比较,如差值大于α,将此行值赋为“1”,否则将此行值赋为“0”,得到数组D；S33：将D中值为“1”的所有元素的索引号取出,保存到数组E中,根据数组E计算得到数组H(l),根据数组H(l)的元素取值得到总像素的行数；所述步骤S4中计算灰度图像的估计行数值的过程如下：由步骤S1-S3得到目标图片所包含全部L对明暗条纹所对应的行数H(l),l＝1,2,...,L,由于每个合法的FSOOK信号调制频率是已知的,它们所对应的真实行数可根据公式计算,其中,f-(LED)为FSOOK信号调制频率,f-S为摄像头的行扫描频率,L-(LED)为一对明暗条纹的像素行数,表示向下取整的操作；故每个真实行数对应的有效行数可由公式得到,其中,有效行数定义为行数的真值R-T的浮动范围,W为可见光通信系统合法频率值的总数；将前述L个行数值H(l),l＝1,2,...,L中的每一个数值与进行比较,并统计H(l)匹配的次数,得到下表：                                    由该表找出S-(wl),l＝1,2,...,L；w＝1,2,...,W的最大值：                  则其所对应的关联的真实行数值R-(T,max),即可视为最终的估计行数值</td>   <td>G06T7/00;H04B10/116</td>  </tr>        <tr>   <td>中国专利</td>   <td>         涂雨龙;              林淑金;                   林格       </td>   <td>中山大学</td>   <td>一种实现血管动态仿真的三维可视化方法</td>   <td>广东省</td>   <td>CN108198239B</td>   <td>2021-07-23</td>   <td>本发明实施例公开了一种实现血管动态仿真的三维可视化方法。其中,该方法包括：获取医学影像,进行提取处理,获得图像序列信息；获取图像序列信息通过三维空间区域生长法进行提取血管轮廓的像素信息；对血管轮廓的像素信息进行统一化处理,建立血管表面模型；根据血管轮廓点的物理特性及血管结构的还原进行对血管动态仿真在本发明实施例中,能够简便地、快捷地以三维方式展示出人体血管动态,不仅大大提高还原精度,也真实还原血管表面受到力的作用时的实时变化情况,增强用户体验感。</td>   <td>1.一种实现血管动态仿真的三维可视化方法,其特征在于,所述方法包括：获取医学影像,进行提取处理,获得图像序列信息；获取图像序列信息通过三维空间区域生长法进行提取血管轮廓的像素信息；对血管轮廓的像素信息进行统一化处理,建立血管表面模型；根据血管轮廓点的物理特性及血管结构的还原进行对血管动态仿真；其中,所述对血管轮廓的像素信息进行统一化处理,建立血管表面模型包括：根据血管轮廓的像素信息进行累加弦长曲线构建处理获得血管轮廓的控制顶点；根据血管轮廓的控制顶点进行角度采样处理,获得统一化后新的血管断层轮廓点；根据新的血管轮廓点重新进行累加弦长曲线构建处理,获得新的血管断层轮廓控制点；获取新的血管断层轮廓控制点进行血管建模,获得血管表面模型,该血管表面模型表达公式为：                  其中,C(u)为单层血管轮廓,d-i为血管轮廓控制点,w-i为血管数据点权重,N-(i,k)(u)为k次规范B样条基函数,n为从每层血管轮廓中提取出n个新的血管轮廓点q-i,i取0到n的整数。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              汪丽娜;                   张建云       </td>   <td>中山大学;水利部交通运输部国家能源局南京水利科学研究院</td>   <td>洪水全要素异变的诊断方法</td>   <td>广东省</td>   <td>CN109145967B</td>   <td>2021-07-23</td>   <td>本发明涉及水文水资源领域,更具体地,涉及一种洪水全要素异变的诊断方法。包括以下步骤：S1.获取洪水全要素的指标数据；S2.对各个指标进行归一化处理；S3.从分类的角度对洪水全要素的异变诊断进行界定,利用AFS-FCM模型确定分类数；S4.确定各个要素的权重值大小；S5.依据归一化的指标、分类数、各要素的权重值大小,依据云模型的计算方式,计算得到洪水全要素异变的诊断结果；S6.根据分类结果解读洪水全要素的异变性。本发明利用AFS-FCM模型中的平均目标函数值,为分类数的划分寻找到了科学的依据,能够用于比较不同分类数分类方案的优劣,在确定权重时,依据量化结果为各洪水要素提供权重值,为洪水全要素的异变性分析提供了有益的支撑。</td>   <td>1.一种洪水全要素异变的诊断方法,其特征在于,包括以下步骤：S1.获取洪水全要素的指标数据,包括洪峰流量值、洪峰水位、最大3天洪量值、最大7天洪量值和洪水历时；S2.对各个指标进行归一化处理：包括：假设第i场洪水第j个指标为则进行归一化计算的公式为：                  式中,和分别为第j个指标的最大值和最小值；S3.从分类的角度对洪水全要素的异变诊断进行界定,利用AFS-FCM模型确定分类数；所述的S3步骤中利用AFS-FCM模型确定分类数的核心为利用平均目标函数值来确定最佳分类数,平均目标函数越小的分类数越好,其中,平均目标函数的计算公式为：                  式中X＝{x-i,i＝1,2…,n}为训练样本集,c是预设的类别数目,v-i(i＝1,2,…,c)为各类别的聚类中心,其中：                                    且即各个聚类的隶属度值和为1；式中,b为模糊指数,b∈[1,∞)；d-(ik)是样本点X-k到第i类中心V-i的欧氏距离；d-(lk)是样本点X-k到第l类中心V-l的欧氏距离；S4.确定各个要素的权重值大小；所述的S4步骤具体包括：S41.计算多维样本数据的一维投影：                  式中x-(ij)(j＝1,2,…,n)是一个n维样本值,a＝(a-1,a-2,…,a-n),a-j∈[-1,1],为一个投影向量；S42.构造投影指标函数：Q-a＝S-a·D-a式中的S-a为类间距离函数,D-a为类内密度函数,其中：                                    式中,为投影值Z-i的平均值；r-(ij)为样本之间的距离,即r-(ij)＝Z-i-Z-j；R为局部密度的窗口半径,u(t)为单位阶跃函数,当t≥0时其值为1,当t＜0时其值为0；S43.构建投影追踪模型：                  S44.根据投影值(Z-i)和归一化的各要素值(x-(ij))得到各指标在各场洪水中的投影值：Z-(ij)＝a-j×x-(ij)；S45.计算各要素在各场洪水中的权重C-(ij)：                  S46.计算各要素的平均权重值C-j：                  为了使得到的权重均为正值,即C-j&gt;0,在此将投影向量a＝(a-1,a-2,…,a-n)的范围进行调整为：a∈(0,1]；S5.依据归一化的指标、分类数、各要素的权重值大小,依据云模型的计算方式,计算得到洪水全要素异变的诊断结果,所述的S5步骤具体包括：S51.依据步骤S3中确定最佳分类数,划定各要素的类别标准集；S52.依据标准集,计算云模型的数字特征,并生成云模型；S53.结合各要素的平均权重,计算综合确定度；S54.利用综合确定度,判定样本级别；S6.根据分类结果解读洪水全要素的异变性。</td>   <td>G06K9/62;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              黄思恩;                   冯展祥       </td>   <td>中山大学</td>   <td>基于注意力机制的孪生网络解决换装行人重识别的方法</td>   <td>广东省</td>   <td>CN113158739A</td>   <td>2021-07-23</td>   <td>本发明公开了一种基于注意力机制的孪生网络解决换装行人重识别的方法,包括由视觉流和轮廓流组成的双流孪生网络结构,所述方法包括以下步骤：分别输入原始图和轮廓图；分别对原始图和轮廓图采用ResNet-50作为骨干网络提取特征；将提取到的特征分别送入注意力分支和全局分支进行处理；将两个经过处理后的流的总输出进行特征融合,获得最后的输出。其中,整个过程受损失函数模块引导和约束。本发明优势在于整个网络架构是一个双流体系结构,同时利用视觉特征和轮廓特征,并利用视觉特征和轮廓特征相结合,去学习既具有区别性又鲁棒稳定的特征,在换装行人重识别领域中非常有价值。</td>   <td>1.基于注意力机制的孪生网络解决换装行人重识别的方法,其特征在于,包括由视觉流和轮廓流组成的双流孪生网络结构,所述方法包括以下步骤：S1分别输入原始图和轮廓图；S2分别对原始图和轮廓图采用ResNet-50作为骨干网络提取特征；S3将提取到的特征分别送入注意力分支和全局分支进行处理；S4将两个经过处理后的流的总输出进行特征融合,获得最后的输出。其中,整个过程受损失函数模块引导和约束。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张荣辉;                   吴月颖       </td>   <td>中山大学</td>   <td>基于ResNeSt和自注意力蒸馏的智能车辆车道线检测方法</td>   <td>广东省</td>   <td>CN113158768A</td>   <td>2021-07-23</td>   <td>本发明公开ResNeSt和自注意力蒸馏的智能车辆车道线检测方法,该方法基于深度学习,以卷积神经网络和编码-解码框架为核心,设计了一个车道线检测网络；使用ResNeSt作为主干网络,并采用自注意力蒸馏技术,以增强网络的特征提取能力；利用传感器获取的图像作为输入,对输入图像进行预处理,以提高网络的速度和精度；网络设计了两个分支,利用二进制分支实现车道线的语义分割,利用嵌入分支实现车道线的实例分割,获取每一条车道线的实例。本发明的方法可在不同的因素影响下,提高车道线检测的准确性和鲁棒性,为驾驶员辅助系统和智能车辆系统提供更准确的感知信息。</td>   <td>1.基于ResNeSt和自注意力蒸馏的智能车辆车道线检测方法,其特征在于,包括以下步骤：S1、对训练图像进行预处理；S2、制作训练集：对每一张图像制作两个标签作为训练集的数据,其中一个作为训练二进制分支的真实标签,另一个作为训练嵌入分支的真实标签；S3、将训练集的图像输入多分支卷积神经网络进行训练：卷积神经网络设有编码-解码结构；编码器对训练数据进行编码,编码器中使用ResNeSt作为主干网络,并设有自注意力蒸馏路径；解码器对编码器输出的特征图进行反卷积,实现上采样和分类；解码器的最后一层,设有两个分支,分别为二进制分支和嵌入分支,利用二进制分支进行语义分割、嵌入分支进行实例分割,两个分支均使用卷积核为1×1的卷积层降低特征映射的维数,作为二进制分支和嵌入分支的输出；计算输出的特征图像与输入的真实标签之间的损失,然后使用梯度下降算法更新神经网络模型的参数,训练直至网络收敛；S4、训练完毕后,将实际的道路图片输入多分支卷积神经网络,得到两个输出,一个是通过二进制分支进行语义分割后的输出,另一个是通过嵌入分支进行实例分割后的输出,之后进行后处理,如下：得到语义分割的结果后,用语义分割的结果制作mask过滤掉嵌入分支输出中属于背景的部分,然后对其进行Meanshift聚类即得到属于不同车道线像素的聚类,获得真正的实例分割的结果；得到实例分割的结果后,在拟合车道过程中,采用如下算法：假设第i条车道的点集为A-i,而A-i中的点坐标为(x,y),则有一系列的x(x-1,x-2,x-3,......,x-n)对应于相同的y值,然后对这些x计算平均值得到：                  由此得到点的坐标为根据这一算法,得到每个车道的点集,最后通过三次样条插值得到最终的车道线检测结果输出。</td>   <td>G06K9/00;G06K9/34;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张秀兰;              乔宇;              宋迪屏;              熊健;              李飞;                   何军军       </td>   <td>中国科学院深圳先进技术研究院;中山大学中山眼科中心</td>   <td>基于多模态的眼部检测数据的处理方法、装置及终端设备</td>   <td>广东省</td>   <td>CN113158821A</td>   <td>2021-07-23</td>   <td>本申请适用于人工智能技术领域,提供了基于多模态的眼部检测数据的处理方法、装置及终端设备,包括：获取待处理至少两种不同的眼部检测数据；采用与至少两种不同的所述眼部检测数据一一对应的特征提取网络,提取每一种所述眼部检测数据对应的数据特征；将至少两种不同的所述眼部检测数据对应的数据特征进行特征融合,得到融合特征；利用分类器对所述融合特征进行分类,得到至少两种不同的所述眼部检测数据的分类结果。通过上述方法,能够得到更准确的分类结果。</td>   <td>1.一种基于多模态眼部检测数据的处理方法,其特征在于,包括：获取待处理至少两种不同的眼部检测数据；采用与至少两种不同的所述眼部检测数据一一对应的特征提取网络,提取每一种所述眼部检测数据对应的数据特征；将至少两种不同的所述眼部检测数据对应的数据特征进行特征融合,得到融合特征；利用分类器对所述融合特征进行分类,得到至少两种不同的所述眼部检测数据的分类结果。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         乔宇;              张秀兰;              宋迪屏;              李飞;              熊健;              何军军;                   付彬       </td>   <td>中国科学院深圳先进技术研究院;中山大学中山眼科中心</td>   <td>基于跨模态关系推理的眼部检测数据的分类方法及装置</td>   <td>广东省</td>   <td>CN113158822A</td>   <td>2021-07-23</td>   <td>本申请适用于人工智能技术领域,提供了基于跨模态关系推理的眼部检测数据的分类方法及装置,包括：获取视野VF数据和视盘数据；将VF数据和视盘数据输入已训练的卷积神经网络模型,得到VF数据和视盘数据对应的分类结果,其中,卷积神经网络模型对VF数据和视频数据的处理过程包括：分别提取VF数据和视盘数据的数据特征,得到VF数据特征和视盘数据特征,对VF数据特征和视盘数据特征进行联合处理,得到VF数据的增强特征和视盘数据的增强特征,将VF数据的增强特征和视盘数据的增强特征进行特征融合,得到融合特征,将融合特征进行分类,得到分类结果。通过上述方法,能够得到更准确的分类结果。</td>   <td>1.一种基于跨模态关系推理的眼部检测数据的分类方法,其特征在于,包括：获取视野VF数据和视盘数据；将所述VF数据和所述视盘数据输入已训练的卷积神经网络模型,得到所述VF数据和所述视盘数据对应的分类结果,其中,所述卷积神经网络模型对所述VF数据和所述视频数据的处理过程包括：分别提取所述VF数据和所述视盘数据的数据特征,得到VF数据特征和视盘数据特征,对所述VF数据特征和所述视盘数据特征进行联合处理,得到所述VF数据的增强特征和所述视盘数据的增强特征,将所述VF数据的增强特征和所述视盘数据的增强特征进行特征融合,得到融合特征,将所述融合特征进行分类,得到所述分类结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              陈凯鹏;                   王国倩       </td>   <td>中山大学</td>   <td>改进的低频UWB SAR叶簇隐蔽目标融合变化检测方法</td>   <td>广东省</td>   <td>CN113159157A</td>   <td>2021-07-23</td>   <td>本发明提供一种改进的低频UWB SAR叶簇隐蔽目标融合变化检测方法,该方法首先对检测图像和参考图像进行预处理,进行双方向的相对辐射校正处理；其次,求解基于改进杂波分布模型的图像分割差值法的检验量图像和检测阈值；将检测图像和参考图像相减得到差值检验量图像,并对差值检验量图像的杂波分布进行估计,设定虚警概率后得到检测阈值,即得到第一个子算法的检验量图像和检测阈值；然后,求解一维Edgeworth法以及广义Laguerre多项式法的检验量图像和检测阈值；最后,将三个检验量图像以及对应阈值输入到LE-SVDD空间中进行分类器的设计,从而实现低频UWB SAR图像的变化检测。</td>   <td>1.一种改进的低频UWB SAR叶簇隐蔽目标融合变化检测方法,其特征在于,包括以下步骤：S1：对检测图像和参考图像进行预处理；S2：求出基于改进杂波分布模型的图像分割差值法的检验量图像和检测阈值；S3：求出一维Edgeworth法和广义Laguerre多项式法的检验量图像和检测阈值；S4：将三个检验量图像和检测阈值都输入到LE-SVDD分类器中进行训练,并对测试样本进行目标与非目标判别,即为最终变化检测结果。</td>   <td>G06K9/62;G06K9/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈旭;              马惠荣;                   周知       </td>   <td>中山大学</td>   <td>多层边缘计算系统中联合绿色能源调度和动态任务分配方法</td>   <td>广东省</td>   <td>CN113159539A</td>   <td>2021-07-23</td>   <td>本发明公开了多层边缘计算系统中联合绿色能源调度和动态任务分配方法,所述方法包括模型建立并初始化；收集系统信息并建立问题成本模型；Lyapunov技术优化；策略实施；更新电池能量队列及策略。本发明优势在于,利用变量依赖性来求解最优解的方法,所指定的随机策略具有高度依赖性,其核心思想是一个向下舍入的变量将被另一个向上舍入的变量来补偿,从而确保即使在舍入后,系统的物理资源约束也能满足。并且本发明方法所得系统成本及计算耗时两方面明显优于现有技术中的方法。</td>   <td>1.多层边缘计算系统中联合绿色能源调度和动态任务分配方法,其特征在于,所述方法包括：S1模型建立并初始化：任务模型建模、前后端边缘服务器模型建模、前端边缘服务器电池模型建模,中心控制器设定绿色能源电池最大容量Q-(max),设定长期服务运行时间为T,并根据每个离散时间片段内中心控制器所收集到的信息为任务卸载执行进行长期成本建模；S2收集系统信息并建立问题成本模型：基站收集当前的设备任务卸载请求及前后端边缘服务器资源信息,并将其发送至中心控制器；S3 Lyapunov技术优化：中心控制器根据任务卸载模型及约束进行Lyapunov优化,联合优化当前卸载成本和电池电量；S4策略实施：中心控制器将制定的任务卸载策略和绿色能源调度策略广播至网络中的所有服务器,处理相应的卸载请求；S5更新电池能量队列及策略：更新绿色能源电池容量,历史任务卸载策略、绿色能源调度策略,及时间t＝t+1,判断时间片段t是否小于总时间片段数T,如果是,则继续步骤S2,反之结束。</td>   <td>G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         章影;              程晓;                   陈卓奇       </td>   <td>北京师范大学;中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>卫星影像自动化几何纠正方法、系统、介质及终端设备</td>   <td>北京市</td>   <td>CN113160071A</td>   <td>2021-07-23</td>   <td>本发明公开了一种适用于国产极地小卫星影像自动化几何纠正方法、装置、存储介质及终端设备,自动化择优筛选用于目标卫星影像自动化几何纠正的同源传感器参考影像；整景影像、影像分四部分及九部分进行图像增强处理后提取目标卫星影像与参考影像的同名点对,以得到用于几何纠正的地理坐标文件；对目标卫星采用不同方法校正后的影像进行校正精度评估,以筛选出最优校正方案,并根据所述最优校正方案对所述目标卫星的影像进行校正。本发明能够实现自动化择优筛选同源传感器配准参考影像,且通过影像增强法突出极地影像的细节特征来增加同名点的选择,并根据影像校正精度筛选出最优的几何校正方案,以克服我国极地小卫星几何定位精度不高的缺陷。</td>   <td>1.一种卫星影像自动化几何纠正方法,应用于极地小卫星,其特征在于,所述方法包括：从影像获取时间远近、空间覆盖程度以及同名点对数量三个方面择优筛选用于目标卫星影像自动化几何纠正的参考影像,以获得用于目标卫星影像几何校正的最优参考影像；采用预设方案提取目标卫星影像与MODIS影像的同名点,以得到各方案用于几何校正的地理坐标文件；其中,所述预设方案包括通过整景影像提取同名点、影像分四部分和九部分进行影像增强处理后提取同名点；对目标卫星影像采用预设方案校正后的影像进行校正精度评估,以筛选出最优校正方案,并根据所述最优校正方案对所述目标卫星影像进行校正。</td>   <td>G06T5/00;G06T7/33</td>  </tr>        <tr>   <td>中国专利</td>   <td>         金枝;              张欢荣;              齐银鹤;                   庞雨贤       </td>   <td>中山大学</td>   <td>一种合成高仿真图像的方法</td>   <td>广东省</td>   <td>CN113160101A</td>   <td>2021-07-23</td>   <td>本发明提供的一种合成高仿真图像的方法,步骤包括：构建原始图像数据集和目标数据集,通过原始图像数据集和目标数据集训练得到非成对无监督风格转换网络模型；获取原始图像数据集中待处理图像,通过非成对无监督风格转换网络模型,生成具有目标数据集风格的目标图像；其中,模型训练步骤包括：获取原始图像数据集中的第一原图,将第一原图转换为目标数据集风格下的第一中间图像；将第一中间图像通过信息增长恢复或信息逆向更改得到第二原图；方法节省大量的时间成本及人力成本,并使得图像数据可用性更高,可广泛应用于图像处理技术领域。</td>   <td>1.一种合成高仿真图像的方法,其特征在于,包括以下步骤：构建原始图像数据集和目标数据集,通过所述原始图像数据集和所述目标数据集训练得到非成对无监督风格转换网络模型；获取原始图像数据集中待处理图像,通过所述非成对无监督风格转换网络模型,生成具有所述目标数据集风格的目标图像；所述通过所述原始图像数据集和所述目标数据集训练得到非成对无监督风格转换网络模型这一步骤,其包括：获取所述原始图像数据集中的第一原图,将所述第一原图转换为目标数据集风格下的第一中间图像；将所述第一中间图像通过信息增长恢复或信息逆向更改得到第二原图。</td>   <td>G06T5/50;G06T3/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>              富明慧       </td>   <td>中山大学</td>   <td>一种基于半方盲文数字编码的手写汉字输入法</td>   <td>广东省</td>   <td>CN107831918B</td>   <td>2021-07-20</td>   <td>本发明提供了一种基于半方盲文数字编码的手写汉字输入法,包括以下步骤：S1、将盲文拆分成左右半方,并根据半方盲文图案进行数字编码；S2、在手写输入设备上设置一手写输入区域；S3、用户在手写输入区域内通过手写手势输入代表一方盲文的两位数字编码；S4、通过手写输入设备识别用户的手写手势,获取用户输入的两位数字编码；S5、将两位数字编码分别还原为对应的半方盲文图案,并按照左右顺序将左右半方盲文图案拼合成一方盲文；S6、将盲文转换为汉字。本发明中,将半方盲文中可能出现的8种不同图案分别映射到8个不同的数字上；用户只需记住映射关系,省去了记忆大量手写图形的麻烦,大大降低了盲文手写输入法的记忆及书写难度。</td>   <td>1.一种基于半方盲文数字编码的手写汉字输入法,其特征在于,包括以下步骤：S1、将盲文拆分成左右半方,并根据半方盲文图案进行数字编码：将一方盲文拆分成左右两个半方,则每个半方有3个点位、8种变化图案；将半方盲文的8种变化图案分别映射到1～9之间的任意8个数字上,则一方盲文可以用两位数的数字编码表示；S2、在手写输入设备上设置一手写输入区域；S3、用户在手写输入区域内通过手写手势输入代表一方盲文的两位数字编码；S4、通过手写输入设备识别用户的手写手势,获取用户输入的两位数字编码；S5、将两位数字编码分别还原为对应的半方盲文图案,并按照左右顺序将左右半方盲文图案拼合成一方盲文；S6、将盲文转换为汉字；其中,S3具体包括：S301、在输入一方盲文的过程中,当用户起手点中手写输入区域的任一位置时,将该位置作为初始位置,以初始位置为中心,按照九宫格数字键盘中各数字按键的方位分布,在手写输入区域中生成数字1～9的虚拟按键区域；其中,初始位置所在的区域为数字“5”的虚拟按键区域；S302、用户通过继续在数字1～9的虚拟按键区域内滑动或点击,输入分别代表左右两个半方盲文图案的两位数字编码；在S3中,在手写输入区域内通过手写手势输入代表一方盲文的两位数字编码的方法为：当左半方的数字编码为5时,一方盲文的输入手势为：用手指在手写区域轻点一下,以确认初始位置并输入数字“5”,然后抬手向右半方的数字编码所在虚拟按键区域点一下；当左半方的数字编码不为5,且左右半方的数字编码相同时,一方盲文的输入手势为：用手指点中手写区域,以确认初始位置,然后划向左右半方的数字编码所在虚拟按键区域后立即松开；当左半方的数字编码不为5,且左右半方的数字编码位置连线呈水平、竖直或45度角方向时,一方盲文的输入手势为：用手指点中手写区域,以确认初始位置,然后划向左半方的数字编码所在虚拟按键区域,接着再折向右半方的数字编码所在虚拟按键区域；当左半方的数字编码不为5,且左右半方的数字编码位置连线不水平、不竖直、也不呈45度角方向时,一方盲文的输入手势为：用手指点中手写区域,并划向左半方的数字编码所在虚拟按键区域,然后松开手指并点在右半方的数字编码所在虚拟按键区域。</td>   <td>G06F3/023</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              李冠彬;              张雨浓;              何翔;                   王青       </td>   <td>中山大学</td>   <td>一种基于深度学习的图像去雨方法及装置</td>   <td>广东省</td>   <td>CN109087258B</td>   <td>2021-07-20</td>   <td>本发明公开了一种基于深度学习的图像去雨方法及装置,所述方法包括：步骤S1,利用浅层卷积神经网络产生所有有雨图像的浅层特征图；步骤S2,将获得的浅层特征图输入至一个逐级下采样的多层编码器以进行编码；步骤S3,通过一个与上游的编码器结构对称、逐级上采样的多层解码器对编码后的特征图进行解码操作；步骤S4,对解码后的特征图进行细化处理,并预测有雨图像的雨条负残差信息；步骤S5,对所述有雨图像与雨条负残差信息求和,最终获得高质量无雨图像,本发明在有效地去除雨条信息的同时,能良好地保留场景细节信息。</td>   <td>1.一种基于深度学习的图像去雨方法,包括如下步骤：步骤S1,利用浅层卷积神经网络产生所有有雨图像的浅层特征图；步骤S2,将获得的浅层特征图输入至一个逐级下采样的多层编码器以进行编码；步骤S3,通过一个与上游的编码器结构对称、逐级上采样的多层解码器对编码后的特征图进行解码操作；步骤S4,对解码后的特征图进行细化处理,并预测有雨图像的雨条负残差信息；步骤S5,对所述有雨图像与雨条负残差信息求和,最终获得高质量无雨图像。</td>   <td>G06T5/00;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李定林;              华丕龙;              彭鹏;              陈满;              江淑文;              刘广立;              韩正洋;              石江健;                   张昊英       </td>   <td>南方电网调峰调频发电有限公司;中山大学</td>   <td>海岛环境下的植被调查方法、装置、系统、设备和介质</td>   <td>广东省</td>   <td>CN110084120B</td>   <td>2021-07-20</td>   <td>发明公开了海岛环境下的植被调查方法、装置、系统、设备和介质、针对于需要进行植被调查的海岛,首先获取无人机航拍的多张二维地形图像,对海岛植被地形进行三维重建,得到海岛的三维地形图；然后根据无人机拍摄指定区域的植物图像时的位置坐标,确定出无人机拍摄的植物图像所属指定区域位于三维地形图中的位置；针对无人机拍摄到的指定区域的多张植物图像,选取存在植物叶片的图像,并且将其中的植物叶片分割出来,得到植物叶片目标；将上述获取到的植物叶片目标与植物叶片图像数据库进行对比,根据对比结果识别到物种信息。本发明能够快速以及准确的实现海岛环境植被调查的优点,为海岛上的植被资源勘察提供了一种快速安全的方法。</td>   <td>1.一种海岛环境下的植被调查方法,其特征在于,步骤如下：针对于需要进行植被调查的海岛,获取无人机航拍的多张二维地形图像,根据无人机每次航拍到的二维地形图像以及无人机每次航拍二维地形图像时的位置坐标对海岛植被地形进行三维重建,得到海岛的三维地形图；获取无人机拍摄到的指定区域的多张植物图像,根据无人机拍摄指定区域的植物图像时的位置坐标,确定出无人机拍摄的植物图像所属指定区域位于三维地形图中的位置；针对于无人机拍摄到的指定区域的每张植物图像,首先对其进行切分处理,将其中的各棵植物提取出来,得到仅包括一棵植物的一张或多张植物图；针对于上述获取到的仅包括一棵植物的植物图像,将其中的植物叶片分割出来,得到植物叶片目标图像；将上述获取到的植物叶片目标图像与植物叶片图像数据库进行对比,根据对比结果识别到物种信息；设定无人机航拍参数,包括设定无人机在航拍过程中航向重叠度为80％～100％,旁向重叠度为70％～90％,飞行高度为20米～60米；设置无人机拍摄到植物图像的分辨率为0.5厘米～2厘米；将植物叶片目标图像与植物叶片图像数据库进行对比的操作过程如下：针对于需要进行植被调查的海岛,首先根据当地的气候条件建立一个可能存在的第一物种数据库；将待识别的各张植物叶片目标图像存储为一个CSV文件,并且获取所有待识别的植物叶片目标图像的路径；将CSV文件上传到云端服务器,由云端服务器将CSV文件中待识别的各张植物叶片目标图像分别与植物叶片图像数据库中的各植物叶片图像进行对比,得到对比结果,即得到各张植物叶片目标图像的物种信息判定结果；其中,将对比结果中准确率低于一定值的对比结果删除；将上述获取到的物种信息判定结果分别与第一物种数据库进行对比,若上述获取到的物种信息判定结果不存在于第一物种数据库中,则对该物种信息判定结果进行标记；统计每种被标记的物种信息判定结果,若个数超过所有物种信息判定结果的b‰,则将该物种信息判定结果进行剔除,其中b为一定值；针对于无人机拍摄到的各张植物图像,通过以下方式进行切分处理得到仅包括一棵植物的一张或多张植物图：对于无人机拍摄到的各张植物图像,首先转换成灰度图像；针对于转换得到的灰度图像进行降噪滤波处理后,提取其中各个像素点的灰度值；针对于降噪滤波处理后的灰度图像,利用K近邻算法比较一定范围内的各像素点的灰度相似度,从而区分出灰度图像中的背景部分和植物部分；将降噪滤波处理后的灰度图像转换成RGB图像,将RGB图像中是各棵植物的像素点切分出来,以提取到仅包括一棵植物的一张或多张植物图像；针对于上述切分得到的仅包括一棵植物的植物图像,计算其图像面积,若其图像面积小于无人机拍摄到的植物图像面积的a％,则剔除该切分得到的仅包括一棵植物的植物图像,其中a为一定值。</td>   <td>G06K9/00;G06K9/40;G06K9/62;G06T7/155</td>  </tr>        <tr>   <td>中国专利</td>   <td>         付青;              朱坤;                   乔宇德       </td>   <td>中山大学</td>   <td>一种操作票自动生成方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN112116308B</td>   <td>2021-07-20</td>   <td>本发明公开了一种操作票自动生成方法、系统、装置及存储介质,其中方法包括以下步骤：获取输入的操作目标任务后,获取多个实现所述操作目标任务的操作路径；根据预设策略和设备管理系统中记录的设备信息从所述多个操作路径中获取最佳路径,根据所述最佳路径生成操作票,以及更新所述设备信息；所述预设策略包括均匀使用策略或风险最低策略的至少之一。本发明在操作票的生成过程中,考虑操作票涉及的所有变电站设备充分的使用情况和运行情况,从而获得更加优化的操作路径,同时将使用情况反馈至设备管理系统,使设备管理系统中记录的信息更加完善,可广泛应用于电力系统自动化领域。</td>   <td>1.一种操作票自动生成方法,其特征在于,所述操作票自动生成方法应用于融合设备信息的操作票自动生成系统,所述操作票自动生成系统包括信息处理单元,所述信息处理单元从设备管理系统获得设备信息,分析判断设备的使用寿命及使用程度,通过使用风险评估后,确定其在本次操作中的使用优先权,并对变电站关键设备进行实时监控,结合设备实际运行情况更新各设备的使用优先权；所述操作票自动生成方法包括以下步骤：获取输入的操作目标任务后,获取多个实现所述操作目标任务的操作路径；根据预设策略和设备管理系统中记录的设备信息从所述多个操作路径中获取最佳路径；根据所述最佳路径生成操作票以及更新设备管理系统的所述设备信息；所述预设策略包括均匀使用策略或风险最低策略的至少之一；若所述预设策略为风险最低策略,所述根据预设策略和设备管理系统中记录的设备信息从所述多个操作路径中获取最佳路径,根据所述最佳路径生成操作票,以及更新所述设备信息,包括：根据所述设备信息获取每个所述操作路径中使用到的设备的出厂参数和使用情况；根据所述出厂参数和所述使用情况获取使用风险最低的设备,选择所述使用风险最低的设备对应的所述操作路径作为最佳路径；根据所述最佳路径生成操作票,以及在所述设备管理系统中更新所述最佳路径对应的设备的使用情况；所述使用情况为使用次数或使用累计时长；所述操作票为倒闸操作票,所述设备包括一次设备和二次设备。</td>   <td>G06Q10/10;G06Q10/04;G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         石茜;              李学章;                   刘小平       </td>   <td>中山大学</td>   <td>一种基于深度学习和多目遥感影像的地物深度预测方法</td>   <td>广东省</td>   <td>CN113139661A</td>   <td>2021-07-20</td>   <td>本发明公开了一种基于深度学习和多目遥感影像的地物深度预测方法,包括以下步骤：S1：利用无人机实际拍摄获取待预测数据,利用仿真扩充方法获取训练数据,将待预测数据和训练数据进行预处理；S2：将预处理后的训练数据和待预测数据进行单应性变换；S3：将变换后的训练数据输入至深度学习模型中对模型进行训练；S4：将变换后的待预测数据输入至训练好的深度学习模型中,输出地物深度。本发明利用深度学习模型和多目遥感影像技术结合,充分利用深度学习的特征提取与模型泛化优势,提高了地物深度预测的效率和精度。</td>   <td>1.一种基于深度学习和多目遥感影像的地物深度预测方法,其特征在于,包括以下步骤：S1：利用无人机实际拍摄获取待预测数据,利用仿真扩充方法获取训练数据,将待预测数据和训练数据进行预处理；S2：将预处理后的训练数据和待预测数据进行单应性变换；S3：将变换后的训练数据输入至深度学习模型中对模型进行训练；S4：将变换后的待预测数据输入至训练好的深度学习模型中,输出地物深度。</td>   <td>G06N20/00;G06N3/08;G01C11/04;G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              许剑锋;              王德明;              吴劲;              丁颜玉;                   段志奎       </td>   <td>广州智慧城市发展研究院;中山大学</td>   <td>一种低功耗检卡控制系统及方法</td>   <td>广东省</td>   <td>CN112800795B</td>   <td>2021-07-16</td>   <td>本发明提供一种低功耗检卡控制系统及方法,包括主机控制模块和从机控制模块；从机控制模块用于在电子标签在场时,发送主机唤醒指令,以及在接收到从机唤醒指令后,从低功耗状态切换至正常状态；主机控制模块用于在处于正常状态时,发送从机唤醒指令,以及在接收到主机唤醒指令后,从低功耗状态切换至正常状态,本发明通过配置低功耗检卡机制,以超低的功耗完成对外部电子标签是否在场的检测,实现RFID读写器从低功耗状态至正常状态的切换,主机控制模块和从机控制均可在低功耗状态下运行,整个RFID读写器功耗更低,获取电子标签信息时更稳定。</td>   <td>1.一种低功耗检卡控制系统,其特征在于,包括：主机控制模块和从机控制模块；所述从机控制模块用于在电子标签在场时,向所述主机控制模块发送主机唤醒指令,以及在从机控制模块接收到从机唤醒指令后,从机控制模块从低功耗状态切换至正常状态；所述主机控制模块用于在处于正常状态时,向从机控制模块发送所述从机唤醒指令,以及在主机控制模块接收到所述主机唤醒指令后,主机控制模块从低功耗状态切换至正常状态；所述从机控制模块包括：从机控制单元、从机门控时钟单元、参数基准单元和射频检测单元,所述从机门控时钟单元、所述参数基准单元和所述射频检测单元均与所述从机控制单元电性连接；参数基准单元用于提供天线载波的参考电平阈值；射频检测单元用于以检卡周期对电子标签进行检测,获取天线载波信号,根据所述参考电平阈值,得到天线载波幅度的变化值,并根据所述天线载波幅度的变化值,判断是否有电子标签在场,以及当电子标签在场时,向从机控制单元发送在场指令；从机控制单元用于根据所述在场指令,向主机控制模块中的主机控制单元发送主机唤醒指令,以及在从机控制单元接收从机唤醒指令后,令从机控制模块从低功耗状态切换至正常状态；主机控制模块和从机控制模块重新回到低功耗状态时,从机控制模块先回到低功耗状态,主机控制模块再回到低功耗状态,且,从机控制模块循环工作在所述检卡周期内。</td>   <td>G06K7/10;G07C9/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              黄凯;              夏俊;                   王婷       </td>   <td>中山大学中山眼科中心;中山大学</td>   <td>一种洗手质量检测方法及装置</td>   <td>广东省</td>   <td>CN113128354A</td>   <td>2021-07-16</td>   <td>本发明公开了一种洗手质量检测方法及装置,对洗手视频进行预处理后得到若干视频帧集,用视频流深度学习模型对若干视频帧集进行特征提取,并对所述特征进行分类处理,得到多个第一分类概率结果；对每个第一分类概率结果进行概率平滑处理得到多个第二分类概率结果；对多个第二分类概率结果进行结果匹配和数值转换,得到不同洗手步骤的洗手步骤质量评价结果,即洗手视频的质量评价结果。采用本发明技术方案能够客观评价用户的洗手步骤和流程,有利于洗手质量评价的推广,提高用户的洗手质量。</td>   <td>1.一种洗手质量检测方法,其特征在于,包括：获取洗手视频；根据预设的视频流深度学习模型,对所述洗手视频进行数据预处理,得到若干个视频帧集,其中,每个视频帧集包括多个处理后的洗手视频连续帧；根据所述视频流深度学习模型,依次对所述视频帧集进行特征提取,并对提取的特征进行分类处理,分别获得每个所述视频帧集对应的第一分类概率结果；其中,所述视频流深度学习模型是根据已设置标签的洗手样本视频训练而生成的,每个洗手样本视频设置有多个标签,且一个标签对应配置一个洗手步骤；分别对每个所述第一分类概率结果进行概率平滑处理,获得每个所述视频帧集对应的第二分类概率结果；分别将每个所述第二分类概率结果与多个预设标签进行结果匹配,输出每个所述第二分类概率结果对应的洗手步骤；对所有的第二分类概率结果进行数值转换,并将数值转换的结果和第二分类概率结果对应的洗手步骤进行匹配,得到洗手步骤和数值转换的结果的对应关系,即洗手视频的质量评价结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         曾坤;              林俊杰;                   林格       </td>   <td>中山大学</td>   <td>基于自监督学习的旋转鲁棒的点云分类方法</td>   <td>广东省</td>   <td>CN113128591A</td>   <td>2021-07-16</td>   <td>本发明提供一种基于自监督学习的旋转鲁棒的点云分类方法,所述的方法包括如下：S1：获取三维点云数据,对三维点云数据进行预处理,得到三维点云的三维坐标序列；S2：将三维点云的三维坐标序列输入预设的自监督学习网络进行训练,训练好的自监督学习网络中的骨干网络输出为对应三维点云模型的高维表征；S3：将三维点云进行多次空间变换,得到多个模型并输入S2训练好的骨干网络,每个模型得到对应的三维点云的高维表征；S4：结合通过步骤S3得到的多个高维表征得到最终表征,并用最终表征和对应的类别标注信息有监督学习得到网络参数,根据网络参数生成目标分类器；S5：在预测阶段,将待分类的三维点云模型预处理后,输入目标分类器完成点云分类。</td>   <td>1.一种基于自监督学习的旋转鲁棒的点云分类方法,其特征在于：所述的方法步骤包括如下：S1：获取三维点云数据,并对三维点云数据进行预处理,得到三维点云的三维坐标序列；S2：将步骤S1得到的三维点云的三维坐标序列输入预设的自监督学习网络进行训练,训练好的自监督学习网络中的骨干网络输出为对应三维点云模型的高维表征；S3：将步骤S1得到的三维点云的三维坐标序列进行多次空间变换,得到多个模型并输入S2训练好的骨干网络,每个模型得到对应的三维点云的高维表征；S4：结合通过步骤S3得到的多个高维表征得到最终表征,并用最终表征和对应的类别标注信息有监督学习得到网络参数,根据网络参数生成目标分类器；S5：在预测阶段,将待分类的三维点云数据进行预处理后,输入目标分类器完成点云分类。</td>   <td>G06K9/62;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         孙兴华;              马嘉华;              黄晓霞;              詹文;              王玺钧;                   陈翔       </td>   <td>中山大学</td>   <td>一种基于标签量信息的联邦学习节点选择方法及系统</td>   <td>广东省</td>   <td>CN113128706A</td>   <td>2021-07-16</td>   <td>本发明公开了一种基于标签量信息的联邦学习节点选择方法及系统,该方法包括：根据本地数据生成标签向量并通过加密矩阵对标签向量进行加密,得到加密后标签向量；根据计算资源估计单轮训练耗时,得到训练耗时估计；上传加密后标签向量与训练耗时估计并进行数据整合,得到整合后数据；基于整合后数据,在预设的最大通信耗时限制下,搜索标签组合分布最优的节点序列作为最终的被选客户节点序列。该系统包括：计算节点、加密中心和计算服务器。通过使用本发明,保证联邦学习的通信效率的同时,提高新节点选择方法的泛用性。本发明作为一种基于标签量信息的联邦学习节点选择方法及系统,可广泛应用于人工智能机器学习领域。</td>   <td>1.一种基于标签量信息的联邦学习节点选择方法,其特征在于,包括以下步骤：根据本地数据生成标签向量并通过加密矩阵对标签向量进行加密,得到加密后标签向量；根据计算资源估计单轮训练耗时,得到训练耗时估计；上传加密后标签向量与训练耗时估计并进行数据整合,得到整合后数据；基于整合后数据,在预设的最大通信耗时限制下,搜索标签组合分布最优的节点序列作为最终的被选客户节点序列。</td>   <td>G06N20/20;G06F21/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李军;              赵子燕;              叶威;                   郑培庆       </td>   <td>中山大学</td>   <td>一种基于IC卡数据的公交通勤识别方法</td>   <td>广东省</td>   <td>CN113128970A</td>   <td>2021-07-16</td>   <td>本发明提供一种基于IC卡数据的公交通勤识别方法,所述的方法包括步骤如下：S1：对公交IC卡数据依次进行数据清洗、下车站点匹配,得到具有完整OD信息的数据；S2：对步骤S1得到的数据中交通出行量的时间分布进行统计,对早晚高峰时间段进行扩展,确定通勤时间范围；S3：分别对早晚通勤时间段内的数据进行统计筛选,得到具有通勤可能性的通勤者和通勤起讫点；S4：对早晚通勤时间范围内的可能通勤者进行匹配,确定通勤者和通勤OD。本发明提供的基于IC卡数据的公交通勤识别方法能够简单高效的识别出公交通勤数据。</td>   <td>1.一种基于IC卡数据的公交通勤识别方法,其特征在于：所述的方法包括步骤如下：S1：对公交IC卡数据依次进行数据清洗、下车站点匹配,得到具有完整OD信息的数据；S2：对步骤S1得到的数据中交通出行量的时间分布进行统计,对早晚高峰时间段进行扩展,确定通勤时间范围；S3：分别对早晚通勤时间段内的数据进行统计筛选,得到具有通勤可能性的通勤者和通勤起讫点；S4：对早晚通勤时间范围内的可能通勤者进行匹配,确定通勤者和通勤OD。</td>   <td>G06Q10/10;G06F16/2458</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王嘉辉;              李文湧;              考塞尔·库热西;              麦麦提艾力·麦麦提;              陈泽鹏;              蔡志岗;              张佰君;                   江灏       </td>   <td>中山大学</td>   <td>一种基于深度卷积生成对抗网络的弱光散斑成像恢复方法</td>   <td>广东省</td>   <td>CN113129232A</td>   <td>2021-07-16</td>   <td>本发明提供一种基于深度卷积生成对抗网络的弱光散斑成像恢复方法,包括以下步骤：S1：获取点光源的散斑PSF；S2：获取未知物的散斑I；S3：对未知物的散斑I和点光源的散斑PSF实施图像灰阶自适应非线性归一化得到S4：根据散射体成像系统的最近似噪信比和所述归一化后的点光源散斑对所述归一化后的未知物散斑实施解卷积操作得到未知物恢复图像O-(tem)；S5：将所述未知物恢复图像O-(tem)输入至预训练好的深度卷积生成对抗网络模型,得到未知物最终重建图像O。本发明能够从信息光学、自适应优化以及深度学习出发构建完整闭环的散斑恢复成像方法,不仅增强了解卷积散斑成像的能力,还大大提高了深度学习在散斑成像恢复中的泛化性。</td>   <td>1.一种基于深度卷积生成对抗网络的弱光散斑成像恢复方法,其特征在于,包括以下步骤：S1：获取点光源的散斑PSF；S2：获取未知物的散斑I；S3：对未知物的散斑I和点光源的散斑PSF实施图像灰阶自适应非线性归一化得到S4：根据散射体成像系统的最近似噪信比和所述归一化后的点光源散斑对所述归一化后的未知物散斑实施解卷积操作得到未知物恢复图像O-(tem)；S5：将所述未知物恢复图像O-(tem)输入至预训练好的深度卷积生成对抗网络模型,得到未知物最终重建图像O。</td>   <td>G06T5/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              姬进财;              杨凌娜;              苗建明;              罗向欣;                   牛丽霞       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种海岛遥感影像集获得方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113129248A</td>   <td>2021-07-16</td>   <td>本发明公开了一种海岛遥感影像集获得方法、装置、设备及介质,方法包括：本发明获取初始海岛遥感影像集；对所述初始海岛遥感影像集进行筛选处理,确定第一海岛遥感影像集；对所述第一海岛遥感影像集进行预处理,确定第二海岛遥感影像集；将所述第二海岛遥感影像集输入到深度残差网络中,确定第三海岛遥感影像集；获取初始无人机-艇海岛遥感影像集；对所述初始无人机-艇海岛遥感影像集进行编辑处理,确定目标无人机-艇海岛遥感影像集；将所述第三海岛遥感影像集以及所述目标无人机-艇海岛遥感影像集输入到所述深度残差网络中,确定目标海岛遥感影像集；能够获得更加完备的、准确的、实时的海岛遥感影像集,能广泛应用于影像融合技术领域。</td>   <td>1.一种海岛遥感影像集获得方法,其特征在于,包括：获取初始海岛遥感影像集；对所述初始海岛遥感影像集进行筛选处理,确定第一海岛遥感影像集；对所述第一海岛遥感影像集进行预处理,确定第二海岛遥感影像集；将所述第二海岛遥感影像集输入到深度残差网络中,确定第三海岛遥感影像集；获取初始无人机-艇海岛遥感影像集；对所述初始无人机-艇海岛遥感影像集进行编辑处理,确定目标无人机-艇海岛遥感影像集；将所述第三海岛遥感影像集以及所述目标无人机-艇海岛遥感影像集输入到所述深度残差网络中,确定目标海岛遥感影像集。</td>   <td>G06T5/50;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;                   苏程佳       </td>   <td>中山大学</td>   <td>一种水文水资源特征空间变异性识别的方法</td>   <td>广东省</td>   <td>CN108009562B</td>   <td>2021-07-13</td>   <td>本发明涉及水文水资源领域,更具体地,涉及一种水文水资源特征空间变异性识别的方法。包括以下步骤：S1.采集河网区水文站点的同步实测水位数据并对网河区进行网格布设；S2.结合所采集的数据及网格布设,计算各方向的水位半变异函数,研究水位在各方向的变异性；S3.运用模型叠加的方法,将不同变程的半变异函数进行叠加构成一个新的套合结构半变异函数模型,根据该套合结构半变异函数模型可方便获得区域内任意两点间的半变异函数值,并对研究区域待估点的水位进行估算。本发明计算复杂度较低、计算效率高、预测准确度高,操作简单,可对河网区水位特征进行空间变异性分析,并对水位在网河区进行空间点估计模拟。</td>   <td>1.一种水文水资源特征空间变异性识别的方法,其特征在于,包括以下步骤：S1.采集河网区水文站点的同步实测水位数据并对网河区进行网格布设；S2.结合所采集的数据及网格布设,计算各方向的水位半变异函数,研究水位在各方向的变异性；所述的S2步骤包括：S21.计算试验半变异函数γ～*(h)：利用求[Z(x-i)-Z(x-i+h)]～2的算术平均值的方法来计算γ～*(h)；其中,h为距离向量,N(h)是被向量h相隔的实验数据对的个数,Z(x-i)和Z(x-i+h)是x方向上相隔为h的点x-i和(x-i+h)处的观测值；S22.计算得出诸对h、γ～*(h)值,做出h-γ～*(h)实验半变异图；S23.在实验半变异函数的基础上,利用合适的理论半变异函数模型对其进行拟合,利用拟合的模型进行水位特征空间变异性分析；所述的S23步骤包括：S231.选用球状模型,球状模型的一般公式为：                  其中,C-0为块金常数；(C-0+C)为基台值；C称为拱高；a为变程；S232.当0&lt;h≤a时,选用加权多项式回归法拟合球状模型半变异函数图；S3.运用模型叠加的方法,将不同变程的半变异函数进行叠加构成一个新的套合结构半变异函数模型,根据该套合结构半变异函数模型可方便获得区域内任意两点间的半变异函数值,并对研究区域待估点的水位进行估算；所述的S3步骤包括：S31.构建x方向和y方向的理论半变异函数,其中,x方向理论半变异函数为：y方向理论半变异函数为：其中,(C-0+C-1)为x方向的基台值；C-1称为x方向的拱高；α-1为x方向的变程；(C-0+C-2)为y方向的基台值；C-2称为y方向的拱高；α-2为y方向的变程；S32.对h-y坐标进行线性变换,使之变为h'-y,于是,γ-y(h-y)可变为保持原有基台值,但变程与γ-y(h-y)的变程相同的一个中间半变异函数γ'-y(h'-y)；S33.把γ'-y(h'-y)看成是在各方向同性结构γ-x(h-x)的基础上再在h'-y方向叠加上另一个球状模型半变异函数的套合结构,即可得到套合结果模型：γ(h')＝γ-0(h'-0)+γ-1(h'-x)+γ-2(h'-y)；根据套合结构半变异函数模型可获得区域内任意两点间的半变异函数值,以此模型为依据可扩展为研究区域待估点的系统估值。</td>   <td>G06K9/62;G06F17/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              朱志华;                   谢璐       </td>   <td>中山大学</td>   <td>一种海绵城市水文计算方法</td>   <td>广东省</td>   <td>CN108022047B</td>   <td>2021-07-13</td>   <td>本发明涉及水文计算领域,更具体地,涉及一种海绵城市水文计算方法。包括以下步骤：S1.采集研究区设定时限内的与降雨相关的基础数据；S2.结合所采集的数据,构建适于研究区域的SWMM模型；S3.构建不同降雨情景,结合SWMM排水模型分析不同降雨情景下LID措施调控前后区域排水系统响应特征,对比LID措施的调控效果；S4.建立区域雨洪特征评估体系,探讨不同降雨情景下LID措施调控前后雨洪的空间变化特征。本发明提供的一种海绵城市水文计算方法,构建区域排水模型,模拟多种极端降水情景下区域经LID措施调控前后的子汇水区域高峰径流、排水管网排泄压力、积水时间和积水量,有助于把握LID措施对区域雨洪的调控效果,方便海绵城市建设中的LID措施设置。</td>   <td>1.一种海绵城市水文计算方法,其特征在于,包括以下步骤：S1.采集研究区域设定时限内的与降雨相关的基础数据；S2. 结合所采集的数据,构建适于研究区域的SWMM模型；所述的S2步骤包括：S21. 对S1步骤采集的基础数据进行处理,形成符合实际和SWMM模型计算要求的形式；对基础数据进行模型化,确定区域的排水区界及产汇流出口,概化排水管网,建立排水系统较为封闭的SWMM模型；S22. 对S21构建的模型进行参数率定,评价模型精度；具体包括：S221. 根据基础数据对不确定性参数进行调整,运用PEST模型对主要参数进行初步调试,得到一组模拟效果较好的参数,在此基础之上再通过人工试错法对参数进行微调,提高SWMM模型的精度；S222. 采用Nash-Sutcliffe效率系数NSE、相关性系数和相对误差对所构建的SWMM模型模拟结果精度进行定量评价；S23.选取若干场次的实测降雨数据和流量数据验证所率定的模型参数,验证所构建的SWMM模型在其它降雨情景下的适用性,验证所构建的区域排水模型以及所率定的参数模拟结果；S3.构建不同降雨情景,结合SWMM模型分析不同降雨情景下LID措施调控前后区域排水系统响应特征,对比LID措施的调控效果；所述的S3步骤包括：S31. 设置极端降雨情形,利用符合该区域暴雨特性的暴雨强度公式,求得该区域不同重现期及不同降雨历时的雨强,与芝加哥雨型合成能同时反映降雨强度、降雨历时和雨峰系数的降雨数据；S32. 根据各重现期降雨情景下SWMM模型模拟的结果,分析区域排水系统各汇水区域的水力特征,分析排水管网系统在不同降雨情景下的响应特征,通过大量数据的处理识别不同降雨情景下最容易发生积水的节点、和出现满管流的管段；S33. 选用步骤S32同样的降雨情景,并对所构建的模型响应参数根据LID设计情况,对研究区域在不同降雨情景下的子汇水区域径流峰值、节点积水情况、管道超载情况、节点积水以及区域积水分布情况进行模拟,以确定不同降雨情景下LID措施在不同降雨情景下的响应,掌握LID措施的调控效果；S4. 建立区域雨洪特征评估体系,探讨不同降雨情景下LID措施调控前后雨洪的空间变化特征；所述的S4步骤包括：S41. 选取研究区域内雨洪致灾因子,建立相应的评估体系,基于粒子群算法的投影寻踪模型对选取的评价指标各投影方向分量进行计算,选择最佳投影方向；构建投影指标函数,将最佳投影方向代入投影指标函数得到各排水节点的投影值,根据得到的各排水节点的投影值对各节点的积水影响进行评估；S42. 根据基于粒子群算法的投影寻踪模型分析不同降水频率下区域雨洪灾害变化特征,通过定性分析区域雨洪灾害的主要驱动因素,通过定量分析指出排涝黑点,并以对数模型拟合模型归纳不同暴雨重现期下的雨洪变化规律,评价区域排水系统能力及其区域雨洪的空间演变特征；S43. 采用步骤S41的方法,对比实施LID措施之后排水节点在不同降雨情景下的雨洪特征,揭示区域在不同降雨情景下应用LID后的积水变化。</td>   <td>G06Q10/06;G06Q50/26;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         袁宝煜;                   郑伟诗       </td>   <td>中山大学</td>   <td>基于多层特征学习的行人属性识别系统及方法</td>   <td>广东省</td>   <td>CN110046550B</td>   <td>2021-07-13</td>   <td>本发明公开了一种基于多层特征学习的行人属性识别系统及方法,该系统包括自下到上特征提取模块、自上到下特征融合模块、特征预测模块、多层预测融合模块和测试模块,该方法具体步骤为：自下到上逐层处理图片得到多层特征；自上到下逐层融合相邻层的特征,较高一层得到的特征图压缩通道,并与上一层上采样后的特征图进行特征融合和通道降维,输出当前层特征；融合后特征和提取的最上层特征,经最大池化层、全连接层后得到不同层级的初步预测结果；将不同层级的初步预测结果叠加,并对每层预测的每个属性对应赋予权重值,得到最终的预测结果；提取图片对应预测结果,计算各个指标的结果。本发明针对融合后的特征得到的预测值,对每个属性学习一组特定的权重,让每个属性各自更好地利用多层特征来得到更好的识别效果。</td>   <td>1.一种基于多层特征学习的行人属性识别方法,其特征在于,包括下述步骤：S1：采用卷积神经网络自下到上逐层提取图片特征得到多层特征；S2：自上到下逐层融合相邻层的特征,在较高一层得到的特征图通过第一卷积层压缩通道,保持通道数不变,并与上一层进行上采样后得到特征图通过相加的操作进行特征融合,融合后的特征通过第二卷积层进行通道降维,在进行上采样到下一层的特征融合的同时,输出当前层特征；S3：自上到下逐层融合相邻层得到的融合特征,以及自下到上提取到的最上层的特征,经过对应的最大池化层后,得到图片大小一致的特征图,并再经过全连接层,通过Sigmoid函数进行激活后得到一个每个点的值为0～1之间的向量,为每个属性对应的分类预测概率,得到不同层级的初步预测结果；S4：将不同层级的初步预测结果向量叠加,得到多层预测矩阵,通过组卷积层对多层预测矩阵进行卷积操作,对应每组初步预测结果,每个属性都设置一组自动学习的权重,每个属性对初步预测结果进行加权求和结合得到最终的预测结果；S5：根据训练好的行人属性识别网络,提取图片对应最终的预测结果,计算各个指标的结果,所述的指标,包括：基于标签的指标和基于样本的指标,所述基于标签的指标从标签维度上计算平均准确率mA,所述基于样本的指标从样本维度上计算准确率accuracy,精确率precision,召回率recall和F1值,基于标签维度的平均准确率mA的计算公式如下：                  其中,L表示属性的个数,i是第i个属性维度,TP-i是ground truth为1且预测为1的样本数,样本数是指每一个具体的标签的数量,TN-i是ground truth为0且预测为0的样本数,P-i和N-i是第i个属性的正样本和负样本个数,基于样本维度的指标计算公式如下：                                                                        其中,FP-i是标签为0而预测为1的样本数,FN-i是标签为1而预测为0的样本数,N是总样本数,在样本维度上是属性的总个数,i指的是第i张图片。</td>   <td>G06K9/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李中华;                   肖玉梅       </td>   <td>中山大学</td>   <td>考虑邻居探测的RFID阅读器防碰撞方法</td>   <td>广东省</td>   <td>CN111401091B</td>   <td>2021-07-13</td>   <td>本发明公开了一种考虑邻居探测的RFID阅读器防碰撞方法,其包括每轮依次执行的邻居探测、资源竞争、碰撞协调三个阶段。本发明从提高阅读器利用率的角度,阅读器根据邻居数量来选择竞争时序序号,使相对稀疏的邻居阅读器优先参与竞争,减少资源竞争阶段阅读器之间的碰撞。同时设计碰撞后的协调机制,使竞争阶段发生碰撞的阅读器通过交换和比较彼此的邻居数量,来决定胜出的阅读器。邻居数量较少的阅读器竞争成功,使更多的阅读器有机会被利用。本发明方法通过在邻居阅读器之间共享邻居阅读器数量信息,使更多的阅读器得到利用,从而提高RFID系统的标签识别效率。</td>   <td>1.一种考虑邻居探测的RFID阅读器防碰撞方法,其特征在于：所述的方法包括每轮依次执行的邻居探测、资源竞争、碰撞协调三个阶段；其中邻居探测阶段：每一个RFID移动阅读器发送信标信号来探测邻居阅读器,并对邻居阅读器数量进行估计；资源竞争阶段：所述RFID阅读器根据邻居阅读器的数量来选择竞争时序序号,并在自身的竞争时序序号与服务器发送的同步竞争命令的时序序号相等时,竞争通信资源；竞争成功的RFID阅读器开始识别标签,竞争失败且在资源竞争阶段所有邻居阅读器都竞争失败的RFID阅读器退避至碰撞协调阶段；碰撞协调阶段：进入碰撞协调阶段的RFID阅读器向邻居阅读器发送包含邻居阅读器数量的协调信号,等待一段时间后,若所述RFID阅读器未接收到其邻居阅读器发送的协调信号,则获取通信资源并进入识别状态；若所述RFID阅读器接收到其邻居阅读器发送的协调信号,则根据约定的协调规则决定胜出的阅读器,胜出的阅读器进入识别状态,被淘汰的阅读器进入休眠状态；在资源竞争阶段,所述RFID阅读器根据邻居阅读器的数量来选择竞争时序序号,其具体选择规则如下：邻居阅读器数量为1且是其邻居阅读器唯一邻居的RFID阅读器随机地选择竞争时序序号；其余邻居阅读器数量小于或者等于1的RFID阅读器的竞争时序序号为1；而邻居阅读器数量大于或者等于2的RFID阅读器从给定区间中随机地选择竞争时序序号。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李中华;                   何冠男       </td>   <td>中山大学</td>   <td>基于分簇竞争的防碰撞方法、移动阅读器、可读存储介质</td>   <td>广东省</td>   <td>CN111444736B</td>   <td>2021-07-13</td>   <td>本发明公开了一种基于分簇竞争的防碰撞方法、移动阅读器、可读存储介质,所述防撞方法是每一轮执行包括以下阶段：竞争簇首RFID移动阅读器阶段、簇间通信资源竞争阶段、簇内通信资源竞争阶段、RFID移动阅读器换簇阶段。本发明从RFID系统通信资源最优化分配的角度出发,先确定簇首阅读器,簇首阅读器代表本簇竞争簇通信资源,簇内的阅读器竞争再对本簇的通信资源进行再竞争。从而实现对通信资源的分层竞争,提高了竞争通信资源的效率,也提升了通信资源的利用效率,最大化RFID系统的标签询问效率。</td>   <td>1.一种基于分簇竞争的防碰撞方法,其特征在于：所述防撞方法是每一轮执行包括以下阶段：竞争簇首RFID移动阅读器阶段、簇间通信资源竞争阶段、簇内通信资源竞争阶段、RFID移动阅读器换簇阶段；其中所述竞争簇首RFID移动阅读器阶段：RFID移动阅读器在服务器广播簇首竞争信号的同步下通过相互随机发送竞争信号的形式对簇首RFID移动阅读器进行竞争,成为簇首的RFID移动阅读器向通信范围内的阅读器广播簇信息,接收到簇信息的RFID移动阅读器加入到簇中；所述簇间通信资源竞争阶段：簇首RFID移动阅读器代表本簇竞争通信资源,各个簇首RFID移动阅读器根据竞争规则对各类通信资源信息进行竞争,竞争结束后,簇首RFID移动阅读器向本簇的阅读器广播簇间竞争获得的通信资源信息；所述簇内通信资源竞争阶段：簇内的RFID移动阅读器通过竞争规则对在簇间获得的通信资源进行竞争,竞争成功并获得通信资源的阅读器开始询问标签；RFID移动阅读器换簇阶段：在簇内竞争通信资源失败或由于移动性远离本簇簇首通信范围的RFID移动阅读器在本簇和相邻簇首阅读器的辅助下,进行换簇操作；换簇成功之后,根据新簇通信资源的利用情况对通信资源展开再竞争,以实现对通信资源的高效利用；如果一个阅读器发送簇首竞争信号并且簇首信号没有产生碰撞,那么这个阅读器就为簇首RFID移动阅读器。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              李金膛;              王国倩;                   陈曾平       </td>   <td>中山大学</td>   <td>一种基于脉冲神经网络的SAR图像舰船目标识别方法</td>   <td>广东省</td>   <td>CN113111758A</td>   <td>2021-07-13</td>   <td>本发明提供一种基于脉冲神经网络的SAR图像舰船目标识别方法,该方法采用了基于视觉注意力机制的视觉显著图提取方法,可以增强图像特征、去除相干斑等噪声影响,提高模型泛化能力和鲁棒性；然后,利用泊松编码器对视觉显著图进行步长为T的脉冲编码,得到离散的脉冲时间序列,以便后续的网络进行信息传递；接着,利用卷积神经网络和LIF脉冲神经元构建脉冲神经网络模型,赋予神经网络更好的生物特性,从而能够更准确地模拟大脑的信息传递过程；最后,利用替代梯度训练方法,解决了脉冲神经网络模型难以利用梯度下降和反向传播进行优化的问题；该方法能够准确识别舰船目标,同时兼具有高效节能的优势。</td>   <td>1.一种基于脉冲神经网络的SAR图像舰船目标识别方法,其特征在于,包括以下步骤：S1：进行SAR图像视觉显著图提取和脉冲编码；S2：进行脉冲神经网络模型构建；S3：进行脉冲神经网络模型训练。</td>   <td>G06K9/00;G06K9/46;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              陈小燕;                   陈丽娜       </td>   <td>中山大学</td>   <td>语义分割的人脸完整度度量方法、系统、设备及存储介质</td>   <td>广东省</td>   <td>CN113111817A</td>   <td>2021-07-13</td>   <td>本发明公开了语义分割的人脸完整度度量方法。包括：训练人脸检测深度神经网络模型与人脸语义分割深度神经网络模型,之后把待检测图像输入到人脸检测深度神经网络模型,得到待检测图像人脸区域；将人脸区域输入到人脸语义分割深度神经网络模型,得到人脸区域中每个像素的语义分类结果,并进行统计,用未遮挡人脸的像素点总数和遮挡物的像素点总数计算出人脸完整度。本发明还公开了语义分割的人脸完整度度量系统、计算机设备及计算机可读存储介质。本发明使用深度学习和图像语义分割技术,能够得到人脸部分图像精确的、像素级别的分类结果,使人脸遮挡检测结果更加准确,计算得到的遮挡比例能够很好地度量人脸完整度。</td>   <td>1.一种语义分割的人脸完整度度量方法,其特征在于,所述方法包括：组织人脸检测数据集,并利用人脸检测数据集训练得到人脸检测深度神经网络模型,该模型的输出为图像中人脸区域的外接矩形坐标；利用所述图像中人脸区域的外接矩形坐标组织人脸语义分割数据集,并利用人脸语义分割数据集训练得到人脸语义分割深度神经网络模型,该模型的输出为将图像的人脸区域中每个像素分类为背景、未遮挡的人脸和遮挡物的结果；将待检测图像进行预处理,输入到所述人脸检测深度神经网络模型,得到待检测图像中人脸区域的外接矩形坐标；将所述待检测图像中人脸区域的外接矩形坐标输入到所述人脸语义分割深度神经网络模型,得到待检测图像的人脸区域中每个像素的语义分类结果,即把每个像素分类为背景、未遮挡人脸和遮挡物；对所述每个像素的语义分类结果进行统计,得到分类为所述未遮挡人脸类别的像素点总数和所述遮挡物类别的像素点总数,从而得到人脸遮挡比例,若遮挡比例为0,则表示无遮挡,否则为有遮挡,遮挡比例用于衡量遮挡的严重程度,即人脸完整度。</td>   <td>G06K9/00;G06K9/34;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;                   袁雪敬       </td>   <td>中山大学</td>   <td>一种基于正则的RKHS子空间学习的BCI脑肌电信号识别</td>   <td>广东省</td>   <td>CN113111845A</td>   <td>2021-07-13</td>   <td>本发明提出一种基于正则的RKHS子空间学习的BCI脑肌电信号识别算法,结合源域数据LDA的辅助准则确定新的数据空间,也就是根据标签优化子空间的源域数据几何分布,具体方法是将子空间中同一类的源域数据尽可能靠近,不同类的数据尽可能远离,使得RKHS子空间上的源域与目标域数据分布合理,提高目标域数据的正确识别率。与KNN识别算法相匹配,因为本文提出的算法是将数据投影到其低维的子空间中,通过学习子空间添加源域LDA正则项,将同一类别数据尽可能靠近,不同类数据尽可能远离,使得子空间中源域数据分布更加匹配KNN分类器,同时使投影矩阵行稀疏,选出最有利于构造子空间的元素；用2范数来约束投影矩阵,这使得行稀疏正则化来选择最有用的特征。</td>   <td>1.一种基于正则的RKHS子空间学习的BCI脑肌电信号识别算法,其特征在于：A.基于RKHS子空间学习和MMD的领域自适应：给定原始数据空间Ω中的一组源域数据和一组目标域数据：其中源域数据X-s是有标签的,而目标域数据X-t是无标签的,需要利用X-s的标签识别X-t的标签。结合MMD域自适应框架,令N＝N-s+N-t利用上文节所提出的RKHS子空间学习框架；有i＝1,…,N-si＝1,…,N-t。Y-s和Y-t的表达式中,矩阵W是未知的,代表RKHS的子空间,通过W的学习,使得Y-s和Y-t在欧式空间R～d的中达到我们想要的分布。B.源域数据有C个类别,每类有数据样本数N-c个,求出c～(th)类中心样本矩阵为了提高源域数据的不同类判别效率,我们将不同类数据之间的距离尽可能增大,定义类间散度尽可能大。C.同理,我们让相同类别信息的源域数据之间的距离尽可能减小,这样提高子空间的相同类别数据的判别效率,类内散度尽可能的小。D.我们用l-(2,1)范数来限定W矩阵,让其行稀疏,帮助我们选择构成子空间的元素。代入后得到基于源LDA正规化RKHS子空间学习的领域自适应目标函数((L+γ(Φ-Ψ)+μI)+λG)W＝KWΛ,结合梯度下降发对该算法进行求解得到W。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         水冰雪;              何兆成;                   陈金邕       </td>   <td>中山大学</td>   <td>一种基于通勤场景下的私家车拼车匹配方法</td>   <td>广东省</td>   <td>CN113112331A</td>   <td>2021-07-13</td>   <td>本发明公开了一种基于通勤场景下的私家车拼车匹配方法,包括以下步骤：S1：获取早高峰时段的通勤车辆的出行数据并进行预处理；S2：根据用户的行驶路径起点划分所属小区；S3：构建拼车匹配模型；S4：利用遗传算法求解拼车匹配模型的输出最佳拼车匹配方案。本发明针对同一小区的用户以小区为起点通过获取用户出行数据并进行预处理,进行用户所属小区划分,构建拼车匹配模型并求解最佳拼车匹配方案,适用性强,匹配效果好。</td>   <td>1.一种基于通勤场景下的私家车拼车匹配方法,其特征在于,包括以下步骤：S1：获取早高峰时段的通勤车辆的出行数据并进行预处理；S2：根据用户的行驶路径起点划分所属小区；S3：构建拼车匹配模型；S4：利用遗传算法求解拼车匹配模型的最佳拼车匹配方案。</td>   <td>G06Q30/06;G06Q50/30;G06N3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              夏文君;              郑炎辉;              宋超;                   金浩宇       </td>   <td>中山大学;广州丰泽源水利科技有限公司</td>   <td>一种水资源去中心化管理系统</td>   <td>广东省</td>   <td>CN113112375A</td>   <td>2021-07-13</td>   <td>本发明公开了一种水资源去中心化管理系统,包括水资源管理区块链平台、水源地管理子系统、供水管理子系统、用水管理子系统和排水管理子系统；所述水资源管理区块链平台用于构建一区块链平台,并基于所述区块链平台实现水资源数据的存储与管理；所述水源地管理子系统、供水管理子系统、用水管理子系统和排水管理子系统从“供用耗排”各环节实现数据的上链、监测数据的评价、水资源问题的溯源分析以及水资源调度方案的制定。本发明基于区块链技术去构建去中心化的“供用耗排”全过程水资源管理,构建各环节主体之间的信任机制,实现各环节水资源问题的自检自查；针对水资源问题,基于水资源数据结合制定相应的对策,提高了水资源系统的管理效率。</td>   <td>1.一种水资源去中心化管理系统,其特征在于,包括：水资源管理区块链平台、水源地管理子系统、供水管理子系统、用水管理子系统和排水管理子系统；所述水资源管理区块链平台用于,构建一区块链平台,并基于所述区块链平台实现水资源数据的存储与管理；所述水源地管理子系统用于,对水源地的水信息进行管理,对水源地的监测项目进行评价和管理,和/或对水源地的突发事件进行管理；所述供水管理子系统用于,对供水厂和/或供水管网的供水信息进行管理,对供水厂、供水管网的监测项目进行评价和管理,和/或对供水突发事件进行管理；所述用水管理子系统用于,对用水户的用水信息进行管理,对用水户的用水量进行评价和管理,和/或对超额用水进行预警管理；所述排水管理子系统用于,对污水处理厂和/或排水户的污水信息进行管理,对污水处理厂和/或排水户的监测项目进行评价和管理,和/或对污水问题进行确认及处理。</td>   <td>G06Q50/06;G06F16/27;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈泽涛;              林义雄;              施梦汝;              王小双;              曾培生;              龚卓弘;              刘海雯;                   陈卓凡       </td>   <td>中山大学附属口腔医院</td>   <td>一种基于人工智能的前牙即刻种植测量分析方法</td>   <td>广东省</td>   <td>CN113112477A</td>   <td>2021-07-13</td>   <td>为了解决即刻种植术前各项软硬组织指标测量时存在的精度不足及耗时问题,本发明提供了一种基于人工智能前牙即刻种植测量分析方法,其通过先行构建标准化前牙即刻种植相关软硬组织数据库,并依托该数据库对Resnet神经网络算法进行训练优化,搭建具备前牙即刻种植相关软硬组织测量的高精度、高可行性AI算法,临床通过输入患者的口腔硬组织数据及口腔表面数据,即可得到前牙即刻种植术前各项软硬组织及角度指标,本发明基于人工智能神经网络,旨在通过卷积神经网络算法获得前牙美学区即刻种植相关的软硬组织指标测量数据,提高测量精度及速度,减轻临床口腔医生负担,提高工作效率,促进完善的即刻种植方案的决策与制定。</td>   <td>1.一种基于人工智能的前牙即刻种植测量分析方法,其特征在于,包含以下步骤：S1、构建标准化前牙即刻种植相关软硬组织数据库S1.1构建口腔软硬组织图像数据影像学资料库批量收集患者口腔硬组织数据及口腔表面数据,通过种植分析软件导入同一患者的口腔硬组织数据DICOM文件及口腔表面数据STL文件,分别在两组数据上标记3组或3组以上的对应点,将口腔硬组织数据及口腔表面数据进行标准化拟合处理,构建具有口腔软硬组织图像数据的影像学资料库；S1.2选定测量截面分别以颌平面、人体正中线为水平参考平面和垂直参考平面,绘制标准牙弓曲线,并在横断面上选取拟测量牙位,截取牙髓腔最大矢状面作为测量平面,标记,保存；S1.3构建标准化前牙即刻种植相关软硬组织数据库由受过系统性训练的人员对资料库图像,按照规范化测量标准进行前牙即刻种植相关软硬组织指标测量,构建包含硬组织指标、软组织指标及角度指标在内的标准化测量数据库,与步骤S1.1构建的口腔软硬组织图像数据影像学资料库对应匹配,构建标准化前牙即刻种植相关软硬组织数据库；S2、构建以Resnet卷积神经网络为基础的软硬组织测量模型S2.1搭建具备模型拟合及截面选取能力的Resnet神经网络构建包含多层卷积层的Resnet神经网络,输入原始口腔硬组织数据DICOM文件、口腔表面数据STL文件及对应的模型拟合数据、标准牙弓曲线及矢状测量截面,通过对原始数据三维拟合及归一化处理,搭建具备模型拟合及截面选取能力的Resnet神经网络；S2.2搭建具备图像识别与测量分析能力的Resnet神经网络构建包含多层卷积层的Resnet神经网络,输入步骤S1建立的标准化前牙即刻种植相关软硬组织数据库及步骤S2.1输出的矢状测量截面,并通过数据扩增及超参数的调整对包含多层卷积层的Resnet神经网络进行训练和优化,最终构建具备即刻种植相关软硬组织测量的高精度、高可行性AI算法；S3、构建上前牙即刻种植相关软硬组织指标AI测量系统S3.1输入患者信息在步骤S2中搭建的Resnet神经网络内输入包含患者口腔硬组织数据的DICOM文件及口腔表面数据的STL文件；S3.2Resnet神经网络输出通过Resnet卷积神经网络,输出具有口腔软硬组织图像的影像学数据、标准牙弓曲线、上前牙矢状测量截面以及相应硬组织指标、软组织指标和角度指标的测量结果；S3.3临床医生根据人工智能测量系统得到的前牙即刻种植相关软硬组织及角度数据后,对患者进行前牙美学区即刻种植治疗方案的制定。</td>   <td>G06T7/00;G06T7/60;G06N3/04;G16H30/00;G16H50/80;A61C8/00;A61C19/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘立林;                   胡泽天       </td>   <td>中山大学</td>   <td>一种多ToF相机系统实时配准方法</td>   <td>广东省</td>   <td>CN113112532A</td>   <td>2021-07-13</td>   <td>本发明属于计算机视觉技术领域,更具体地,涉及一种多ToF相机系统实时配准方法,包括多个相机分别实时获取相位与振幅信息,多个相机之间具有重合视野；将相位与振幅信息分别转换为深度图像与红外图像；根据红外图像与深度图像计算得到多个相机的实时位姿关系；根据深度图像得到在相机坐标系下的三维点云信息；根据实时相对位姿与三维点云信息,完成多个相机的三维信息实时配准。本发明中通过特征点匹配求解相机间位姿关系,不需要对多个相机进行标定,适用于多个相机间具有相对运动的情况,且不需要保证多个相机的时序严格同步,降低系统成本,具有较高的实用性。</td>   <td>1.一种多ToF相机系统实时配准方法,其特征在于,包括：S1：多个相机分别实时获取相位与振幅信息,所述多个相机之间具有重合视野；S2：将所述相位与振幅信息分别转换为深度图像与红外图像；S3：根据所述红外图像与深度图像计算得到多个相机的实时位姿关系；S4：根据所述深度图像得到在相机坐标系下的三维点云信息；S5：根据所述实时相对位姿与三维点云信息,完成多个相机的三维信息实时配准。</td>   <td>G06T7/33;G06T19/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓楚富;              肖侬;              卢宇彤;              陈志广;              瞿毅力;              苏婉琪;                   王莹       </td>   <td>中山大学</td>   <td>基于条件生成对抗网络的多域图像转换方法、系统及介质</td>   <td>广东省</td>   <td>CN110675316B</td>   <td>2021-07-09</td>   <td>本发明涉及深度学习图像生成领域,具体涉及一种基于条件生成对抗网络的多域图像转换方法、系统及介质,本发明实施步骤包括输入待转换的x模态的原图x、y模态的原图y；采用预先训练好的条件提取器来生产x模态条件C-x和y模态条件C-y；将原图x、原图y、x模态条件C-x、y模态输入预先训练好的条件生成对抗网络得到对应的图像转换结果。本发明利用特征提取器提取原图的特征,通过上采样及与零矩阵在通道上的拼接得到条件矩阵,在具有较高的独立性情况下,又保有每个模态输入自身的语义信息；本发明训练灵活,且对要转换的域的数量没有限制,所需参数少。</td>   <td>1.一种基于条件生成对抗网络的多域图像转换方法,其特征在于,实施步骤包括：1)输入待转换的x模态的原图x、y模态的原图y；2)针对原图x采用预先训练好的条件提取器来生产x模态条件C-x,针对原图y采用预先训练好的条件提取器来生产y模态条件C-y；3)将原图x、原图y、x模态条件C-x、y模态条件C-y输入预先训练好的条件生成对抗网络得到对应的图像转换结果；步骤2)的详细步骤包括：针对原图x采用预先训练好的条件提取器提取图像特征,再对图像特征进行上采样放大成原图大小然后再与零矩阵进行通道上的拼接得到x模态条件C-x；针对原图y采用预先训练好的条件提取器提取图像特征,再对图像特征进行上采样放大成原图大小然后再与零矩阵进行通道上的拼接得到y模态条件C-y；所述条件生成对抗网络包括几何信息编码器Encoder-(same)、细节信息编码器Encoder-(diff)以及解码器Decoder,步骤3)中条件生成对抗网络得到对应的图像转换结果的详细步骤包括：3.1)针对原图x,通过几何信息编码器Encoder-(same)编码得到x模态几何空间特征x-(same),将x模态几何空间特征x-(same)与零矩阵进行通道上的拼接后输入解码器Decoder得到x模态掩膜图x-(mask)；针对原图y,通过几何信息编码器Encoder-(same)编码得到y模态几何空间特征y-(same),将y模态几何空间特征y-(same)与零矩阵进行通道上的拼接后输入解码器Decoder得到x模态掩膜图y-(mask)；将原图x与y模态条件C-y进行通道上的拼接,然后通过细节信息编码器Encoder-(diff)编码得到y模态细节语义特征y-(diff),将y模态细节语义特征y-(diff)与零矩阵进行通道上的拼接后输入解码器Decoder得到y模态细节特点图y-(dic)；将图像y与x模态条件C-x进行通道上的拼接,然后通过细节信息编码器Encoder-(diff)编码得到x模态几何空间特征x-(diff),将x模态几何空间特征x-(diff)与零矩阵进行通道上的拼接后输入解码器Decoder得到x模态细节特点图x-(dic)；3.2)重用x模态几何空间特征x-(same)、y模态细节语义特征y-(diff)进行通道上的拼接后输入解码器Decoder得到y模态生成图y-(fake)；重用y模态几何空间特征y-(same)、x模态细节语义特征x-(diff)进行通道上的拼接后输入解码器Decoder得到x模态生成图x-(fake)。</td>   <td>G06T3/40;G06T7/33;G06T9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁姗姗;                   张航       </td>   <td>中山大学</td>   <td>一种视线估计方法、系统、装置及存储介质</td>   <td>广东省</td>   <td>CN113095274A</td>   <td>2021-07-09</td>   <td>本发明公开了一种视线估计方法、系统、装置及存储介质,该方法包括：获取人脸图像并进行关键点检测和3D模型拟合处理,得到人眼图像和3D头部旋转向量；对人眼图像和3D头部旋转向量进行数据正则化,得到正则化人眼图像和头部姿态估计向量；将正则化人眼图像和头部姿态估计向量输入到预训练的CNN网络,并将网络输出转换为3D视线方向向量。该系统包括：图像预处理模块、数据正则化模块和结果输出模块。该装置包括存储器以及用于执行上述视线估计方法的处理器。通过使用本发明,能够得到高精度的视线估计结果。本发明作为一种视线估计方法、系统、装置及存储介质,可广泛应用于视线估计领域。</td>   <td>1.一种视线估计方法,其特征在于,包括以下步骤：获取人脸图像并进行关键点检测和3D模型拟合处理,得到人眼图像和3D头部旋转向量；对人眼图像和3D头部旋转向量进行数据正则化,得到正则化人眼图像和头部姿态估计向量；将正则化人眼图像和头部姿态估计向量输入到预训练的CNN网络,并将网络输出转换为3D视线方向向量。</td>   <td>G06K9/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         任磊;              姬进财;              杨凌娜;              苗建明;              罗向欣;                   牛丽霞       </td>   <td>中山大学;南方海洋科学与工程广东省实验室(珠海)</td>   <td>一种海岛分区火势等级划分方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113095282A</td>   <td>2021-07-09</td>   <td>本发明公开了一种海岛分区火势等级划分方法、装置、设备及介质,方法包括：根据海岛遥感影像集确定海岛基本地物特征以及海岛基本几何特征；根据海岛基本几何特征对海岛几何图形进行几何解析,确定海岛分区；通过海岛分区火势面积,确定第一海岛分区火势等级排序；通过海岛平均风速,确定第二海岛分区火势等级排序；通过海岛日平均温度以及海岛日平均湿度,确定第三海岛分区火势等级排序；对第一海岛分区火势等级排序、第二海岛分区火势等级排序以及第三海岛分区火势等级排序进行计算,确定海岛分区火势等级划分；本发明能够综合多种因素对海岛火灾进行分析,实现了对海岛分区火势等级的划分,能广泛应用于海岛火灾监测技术领域。</td>   <td>1.一种海岛分区火势等级划分方法,其特征在于,包括：通过无人机-艇系统获取海岛遥感影像集,对所述海岛遥感影像集进行特征信息提取,确定海岛基本地物特征以及海岛基本几何特征；根据所述海岛基本几何特征对海岛几何图形进行几何解析,确定海岛分区；通过所述无人机-艇系统获取海岛分区火势面积,根据所述海岛分区火势面积占海岛分区面积的百分比,确定第一海岛分区火势等级排序；通过所述无人机-艇系统检测海岛平均风速,根据所述海岛平均风速在所述海岛分区的分区轴线上的分量,估算火势在所述分区轴线上的蔓延时间,确定第二海岛分区火势等级排序；通过所述无人机-艇系统获取海岛日平均温度以及海岛日平均湿度,结合所述海岛基本地物特征,确定海岛特征数据集；对所述海岛特征数据集进行数据转换,确定第三海岛分区火势等级排序；对所述第一海岛分区火势等级排序、所述第二海岛分区火势等级排序以及所述第三海岛分区火势等级排序进行计算,确定海岛分区火势等级划分。</td>   <td>G06K9/00;G06K9/46;G01D21/02;G06N3/00;G06N3/08;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张智伦;                   惠凤鸣       </td>   <td>中山大学</td>   <td>基于中法海洋卫星散射计的北极海冰分类方法</td>   <td>广东省</td>   <td>CN113095375A</td>   <td>2021-07-09</td>   <td>本发明提供的基于中法海洋卫星散射计的北极海冰分类方法,方法步骤包括：获取中法海洋卫星同极化的全球条带数据,根据全球条带数据生成散射计影像；散射计影像中包括第一冰区像元；获取亮温数据,通过阈值分割,从亮温数据中提取得到第二冰区像元；联合第一冰区像元和第二冰区像元得到海冰像元,根据海冰像元的后向散射系数以及亮温数据,将海冰像元进行分类；分类结果包括一年冰和多年冰；方法能够实现对源数据的自适应,提高了分类结果的精度及稳定,增强分类算法跨的普适性,可广泛应用于北极海冰遥感技术领域。</td>   <td>1.基于中法海洋卫星散射计的北极海冰分类方法,其特征在于,包括以下步骤：获取中法海洋卫星散射计同极化的全球条带数据,根据所述全球条带数据生成散射计影像；所述散射计影像中包括第一冰区像元；获取亮温数据,通过阈值分割,从所述亮温数据中提取得到第二冰区像元；联合所述第一冰区像元和所述第二冰区像元得到海冰像元,根据所述海冰像元的后向散射系数以及亮温数据,将所述海冰像元进行分类,所述分类的结果包括一年冰和多年冰。</td>   <td>G06K9/62;G06K9/34</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡海峰;              夏志武;                   吴永波       </td>   <td>中山大学</td>   <td>一种基于注意力机制的图像描述方法、系统及装置</td>   <td>广东省</td>   <td>CN113095431A</td>   <td>2021-07-09</td>   <td>本发明公开了一种基于注意力机制的图像描述方法、系统及装置,该方法包括：基于编码器模块对图像特征进行处理,得到编码信息；基于解码器模块获取序列向量信息并对编码信息进行解码,得到单词概率分布；重复编码解码步骤直至达到预设次数,输出图像描述。该系统包括：编码器模块、解码器模块和循环模块。该装置包括存储器以及用于执行上述基于注意力机制的图像描述方法的处理器。通过使用本发明,能够充分挖掘出图像中对象之间隐藏的内在语义联系和空间位置关系,生成全面准确的图像描述。本发明作为一种基于注意力机制的图像描述方法、系统及装置,可广泛应用于图像描述生成检测。</td>   <td>1.一种基于注意力机制的图像描述方法,其特征在于,包括以下步骤：获取输入图像的图像特征X并对图像特征X进行线性变换,得到向量集Q、K-1和V-1；对向量集K-1和V-1中分别插入语义关联向量S-k、S-v,得到向量集K-2和V-2；将向量集Q、K-2和V-2输入自注意力模块S,得到特征信息S(X)；将特征表示S(X)经过前向传播和残差连接正则化,得到编码信息获取前一时间步的序列向量信息Y并经过掩码自注意力模块处理得到问询向量Yq；将编码信息经过线性变换得到向量集K-2和V-2；将问询向量Yq、向量集K-2和V-2输入交叉注意力模块得到解码结果C并进一步残差连接和正则化更新解码结果C；将解码结果C经过Sigmoid算子和前向传播,得到单词概率分布以编码信息作为新的图像特征、单词概率分布作为新的序列向量表示并返回步骤S1直至循环次数达到四次,输出图像描述。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李晓丽;              陈川;                   郑子彬       </td>   <td>中山大学</td>   <td>双层公平联邦学习方法、装置和存储介质</td>   <td>广东省</td>   <td>CN113095513A</td>   <td>2021-07-09</td>   <td>本发明公开了一种双层公平联邦学习方法,其包括如下步骤：获取多个客户端的局部模型；中央服务端对所有局部模型进行聚合处理,得到全局模型；每一所述客户端分别依据所述全局模型对对应的局部模型进行约束处理,使对应的局部模型的模型参数接近所述全局模型的模型参数,以得到对应的新的局部模型；所述中央服务端依据所有新的局部模型更新所述全局模型；本发明能够在不泄露个体客户端的内部数据的情况下,依据各个客户端的非独立同分布数据生成具有较高泛化能力的全局模型,且各个客户端的局部模型依据全局模型进行调整实现所有客户端的模型训练共享。</td>   <td>1.一种双层公平联邦学习方法,其特征在于,包括如下步骤：获取多个客户端的局部模型；中央服务端对所有局部模型进行聚合处理,得到全局模型；每一所述客户端分别依据所述全局模型对对应的局部模型进行约束处理,使对应的局部模型的模型参数接近所述全局模型的模型参数,以得到对应的新的局部模型；所述中央服务端依据所有新的局部模型更新所述全局模型。</td>   <td>G06N20/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   黄泽青       </td>   <td>中山大学</td>   <td>一种耦合伯努利-伽马-高斯分布的日尺度降水预报校正方法</td>   <td>广东省</td>   <td>CN113095579A</td>   <td>2021-07-09</td>   <td>本发明为克服日尺度降水数据呈现的偏态与离散-连续混合分布导致难以对日尺度降水预报进行分析及校正的缺陷,提出一种耦合伯努利-伽马-高斯分布的日尺度降水预报校正方法,包括以下步骤：采集日尺度的原始预报数据和观测数据；采用伯努利分布进行降水发生分析；采用伽马分布对发生降水的数据进行降水量分析；根据伯努利分布和伽马分布的分析结果,采用高斯分布将原始预报数据和观测数据进行正态转化,得到相应的正态化变量；构建双变量联合正态分布；构建预报变量的条件概率分布；判断待校正预报是否为发生降水事件,根据预报变量的条件概率分布,确定预报变量的条件概率分布参数后对其进行随机采样,再根据正态分位逆变换得到校正预报。</td>   <td>1.一种耦合伯努利-伽马-高斯分布的日尺度降水预报校正方法,其特征在于,包括以下步骤：S1：采集日尺度的流域面平均降水的原始预报数据和相应流域面的平均降水的观测数据；S2：采用伯努利分布对所述原始预报数据和观测数据进行降水发生分析；S3：采用伽马分布对发生降水的原始预报数据和观测数据进行降水量分析；S4：根据伯努利分布和伽马分布的分析结果,将所述原始预报数据和观测数据进行正态转化,得到所述原始预报数据和观测数据相应的正态化变量和S5：根据所述正态化变量和构建双变量联合正态分布；S6：将所述原始预报数据的正态化变量作为预报因子,将所述观测数据的正态化变量作为预报变量,构建所述预报变量的条件概率分布；S7：判断待校正的预报数据是否发生降水事件,确定预报变量的条件概率分布,进一步对预报变量的条件概率分布进行随机采样,再根据正态分位逆变换得到校正预报。</td>   <td>G06Q10/04;G06F16/2458;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余志;              黎炜驰;              曾雪兰;                   刘永红       </td>   <td>中山大学</td>   <td>一种碳排放配额分配技术的数据质量评价方法</td>   <td>广东省</td>   <td>CN113095678A</td>   <td>2021-07-09</td>   <td>本发明提供一种碳排放配额分配技术的数据质量评价方法,包括如下步骤：步骤一,建立包括数据类型需求和数据层级需求的碳排放配额分配技术的数据需求模型；步骤二,建立以准确性、可靠性和可比性为基础的碳排放配额分配技术的数据质量评价指标体系；步骤三,基于数据质量评价指标体系对碳排放配额分配技术的数据质量进行评价。本发明通过开发了一个面向配额分配技术的数据质量评价指标体系,填补了本领域中碳排放配额分配技术的数据层级需求和数据质量评价指标体系的空白。且该评价指标体系的结果为政府及相关支撑机构的碳市场机制设计提供支持,以及对碳市场的启动及改进具有指导意义。</td>   <td>1.一种碳排放配额分配技术的数据质量评价方法,其特征在于：包括以下步骤：步骤一,建立碳排放配额分配技术的数据需求模型；步骤二,建立碳排放配额分配技术的数据质量评价指标体系；步骤三,通过所述数据质量评价指标体系对碳排放配额分配技术的数据质量进行评价；所述碳排放配额分配技术的配额方案采用了历史排放法或历史强度法或基准法。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈武辉;              张伟焜;              蔡婷;                   郑子彬       </td>   <td>中山大学</td>   <td>一种基于区块链和反向拍卖的市场调控方法及系统</td>   <td>广东省</td>   <td>CN113095910A</td>   <td>2021-07-09</td>   <td>本发明公开了一种基于区块链和反向拍卖的市场调控方法及系统,其中方法包括：在市场生命周期的每个时间段内,根据市场监管机构输入的命令激活智能合约,以进行反向拍卖；计算并确定门槛金额；在买家向智能合约支付门槛金额后,为买家赋予进入市场的权限,以使买家成为潜在买家；在卖家通过智能合约的接口给出报价后,为报价低于门槛金额的卖家赋予进入市场的权限,以使报价低于门槛金额的卖家成为潜在卖家；通过智能合约对进入市场的潜在买家和潜在卖家进行随机匹配,以完成市场交易。本发明不仅能够支持买家和卖家双方之间的交易,并且保留了底层区块链的优势,同时为市场监管者提供了调整市场可调节因素的接口,以促进市场的金融稳定性。</td>   <td>1.一种基于区块链和反向拍卖的市场调控方法,其特征在于,所述方法包括：在市场生命周期的每个时间段内,根据市场监管机构输入的命令激活智能合约,以进行反向拍卖；计算并确定门槛金额；在买家向所述智能合约支付所述门槛金额后,为所述买家赋予进入市场的权限,以使所述买家成为潜在买家；在卖家通过所述智能合约的接口给出报价后,为报价低于所述门槛金额的卖家赋予进入市场的权限,以使报价低于所述门槛金额的卖家成为潜在卖家；通过所述智能合约对进入市场的所述潜在买家和所述潜在卖家进行随机匹配,以完成市场交易,并将匹配结果通知给所述潜在买家和所述潜在卖家。</td>   <td>G06Q30/06;G06Q30/08;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑子彬;              唐秀雯;                   蒋子规       </td>   <td>中山大学</td>   <td>一种区块链智能合约推荐方法及装置</td>   <td>广东省</td>   <td>CN113095939A</td>   <td>2021-07-09</td>   <td>本申请提供的一种区块链智能合约推荐方法及装置,其中方法包括：建立区块链地址集,区块链地址集包括：第一区块链地址和第二区块链地址；以交易记录信息中的交易量和交易成交价格为自变量,结合皮尔森相关系数计算公式,分别计算出区块链地址集中各个区块链地址的价格敏感度系数；根据各个区块链地址的价格敏感度系数,从区块链地址集确定第三区块链地址,根据第三区块链地址的智能合约调用记录,确定待推荐智能合约,并将待推荐智能合约推荐至第一区块链地址。针对性地向该区块链地址对应的用户推荐符合其交易群体偏好及交易价格的智能合约,解决了现有的智能合约推荐方式的推荐准确度低的技术问题。</td>   <td>1.一种区块链智能合约推荐方法,其特征在于,包括：基于区块链地址的交易记录信息,确定与第一区块链地址存在交易关系的第二区块链地址,并建立区块链地址集,所述区块链地址集包括：所述第一区块链地址和所述第二区块链地址；以所述交易记录信息中的交易量和交易成交价格为自变量,结合皮尔森相关系数计算公式,分别计算出所述区块链地址集中各个区块链地址的价格敏感度系数；根据所述各个区块链地址的价格敏感度系数,从所述区块链地址集确定第三区块链地址,其中,所述第三区块链地址为所述第二区块链地址中,价格敏感度系数最接近于所述第一价格敏感度系数的区块链地址,所述第一价格敏感度系数为所述第一区块链地址的价格敏感度系数；根据所述第三区块链地址的智能合约调用记录,确定待推荐智能合约,并将所述待推荐智能合约推荐至所述第一区块链地址,其中,所述待推荐智能合约为所述第三区块链地址调用过的智能合约。</td>   <td>G06Q40/04;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周毅;              毛钤镶;                   承垠林       </td>   <td>中山大学</td>   <td>一种CT图像结石数量和体积的计算方法、系统及装置</td>   <td>广东省</td>   <td>CN113096093A</td>   <td>2021-07-09</td>   <td>本发明公开了一种CT图像结石数量和体积的计算方法、系统及装置,该方法包括：对CT图像进行标注处理,得到标注后图像；对标注后图像进行结石分割处理,得到结石切片信息和轮廓信息；根据结石切片信息和预设规则判断不同帧CT图像的结石切片是否属于同一结石,得到切片归属信息；基于轮廓信息和切片归属信息计算结石数量和结石体积。该系统为应用于上述CT图像结石数量和体积的计算方法的模块。通过使用本发明,实现了CT图像中结石的分割及结石数目和体积的测算。本发明作为一种CT图像结石数量和体积的计算方法、系统及装置,可广泛应用于医学图像处理领域。</td>   <td>1.一种CT图像结石数量和体积的计算方法,其特征在于,包括以下步骤：获取多帧CT图像,并对CT图像进行标注处理,得到标注后图像；对标注后图像进行结石分割处理,得到结石切片信息和轮廓信息；根据结石切片信息和预设规则判断不同帧CT图像的结石切片是否属于同一结石,得到切片归属信息；基于轮廓信息和切片归属信息计算结石数量和结石体积。</td>   <td>G06T7/00;G06T7/136;G06T7/62;G16H30/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   刘一晴       </td>   <td>中山大学</td>   <td>一种双向点云属性预测压缩方法,装置,设备及介质</td>   <td>广东省</td>   <td>CN113096198A</td>   <td>2021-07-09</td>   <td>本发明公开了一种双向点云属性预测压缩方法、装置、设备及介质,方法包括：分别计算点云数据在几何坐标轴上的标准差；根据所述标准差,确定空间偏倚系数；对所述点云数据的几何信息进行莫顿编码排序或者希尔伯特编码排序,确定莫顿序或希尔伯特序；根据所述莫顿序或希尔伯特序结合序号进行属性预测,确定属性预测值；根据所述属性预测值,对所述点云数据进行属性预测压缩。本发明实现了减少以往根据个人经验设定空间偏倚系数所带来的不确定性,能更精确地找到真实几何空间中距离最近的点,减少了在点云数据的属性压缩中的损失,可广泛应用于点云数据处理技术领域。</td>   <td>1.一种双向点云属性预测压缩方法,其特征在于,包括：分别计算点云数据在几何坐标轴上的标准差；根据所述标准差,确定空间偏倚系数；对所述点云数据的几何信息进行莫顿编码排序或者希尔伯特编码排序,确定莫顿序或希尔伯特序；根据所述莫顿序或希尔伯特序结合序号进行属性预测,确定属性预测值；根据所述属性预测值,对所述点云数据进行属性预测压缩。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   刘一晴       </td>   <td>中山大学</td>   <td>一种基于莫顿码的点云属性预测方法、装置和介质</td>   <td>广东省</td>   <td>CN113096199A</td>   <td>2021-07-09</td>   <td>本发明公开了一种基于莫顿码的点云属性预测方法、装置和介质,方法包括：获取点云数据的几何坐标,并对所述几何坐标进行莫顿排序；根据所述莫顿排序的结果,通过预设的搜索范围搜索共面共线点；计算所述共面共线点的权重值和；根据所述权重值和的数值大小,采用第一预测方法和第二预测方法预测目标点的目标属性值；其中,所述第二预测方法基于莫顿码来实现。本发明能够提高属性预测的准确度,可广泛应用于点云数据处理技术领域。</td>   <td>1.一种基于莫顿码的点云属性预测方法,其特征在于,包括：获取点云数据的几何坐标,并对所述几何坐标进行莫顿排序；根据所述莫顿排序的结果,通过预设的搜索范围搜索共面共线点；计算所述共面共线点的权重值和；根据所述权重值和的数值大小,采用第一预测方法和第二预测方法预测目标点的目标属性值；其中,所述第二预测方法基于莫顿码来实现。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁凡;                   刘一晴       </td>   <td>中山大学</td>   <td>一种基于法向量的点云属性压缩方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113096200A</td>   <td>2021-07-09</td>   <td>本发明公开了一种基于法向量的点云属性压缩方法、装置、设备及介质,方法包括：计算待压缩点云数据的几何信息；根据所述点云数据的几何信息进行莫顿码排序,得到莫顿序；根据所述莫顿序遍历得到当前编码点的目标预测点,并确定所述目标预测点的预测权值；构建k-d树；根据所述k-d树搜索所述当前编码点和所述目标预测点的最邻近点；根据所述最邻近点进行平面拟合,得到所述平面的法向量；根据所述法向量对所述预测权值进行修正,得到目标权值；根据所述目标权值确定所述点云数据的编码结果。本发明能够降低点云属性压缩结果的误差,可广泛应用于点云数据处理技术领域。</td>   <td>1.一种基于法向量的点云属性压缩方法,其特征在于,包括：计算待压缩点云数据的几何信息；根据所述点云数据的几何信息进行莫顿码排序,得到莫顿序；根据所述莫顿序遍历得到当前编码点的目标预测点,并确定所述目标预测点的预测权值；构建k-d树；根据所述k-d树搜索所述当前编码点和所述目标预测点的最邻近点；根据所述最邻近点进行平面拟合,得到所述平面的法向量；根据所述法向量对所述预测权值进行修正,得到目标权值；根据所述目标权值确定所述点云数据的编码结果。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         文永明;              黄绮恒;                   成慧       </td>   <td>中山大学</td>   <td>基于注意力机制网络的人脸生成方法、装置、设备及介质</td>   <td>广东省</td>   <td>CN113096206A</td>   <td>2021-07-09</td>   <td>本发明公开了一种基于注意力机制网络的人脸生成方法、装置、设备及介质,方法包括：获取训练图像以及训练表情目标域；根据表情基本类别与激活向量的关系,确定映射关系表；根据所述映射关系表,确定所述表情基本类别的概率向量到所述激活向量的映射规则；将所述训练图像以及所述训练表情目标域输入双向对抗性网络训练得到双向对抗性模型；根据所述映射规则,将待生成的初始人脸表情图像以及待生成的表情基本类别概率向量输入所述双向对抗性模型,确定连续的目标人脸表情图像。本发明能够处理连续的表情分布,生成连续的人脸表情图像,还能够提高模型对背景和光照条件变化的鲁棒性。</td>   <td>1.一种基于注意力机制网络的人脸生成方法,其特征在于,包括：获取训练图像以及训练表情目标域；根据表情基本类别与激活向量的关系,确定映射关系表；根据所述映射关系表,确定所述表情基本类别的概率向量到所述激活向量的映射规则；将所述训练图像以及所述训练表情目标域输入双向对抗性网络训练得到双向对抗性模型,其中,所述双向对抗性模型,用于消除注意力和颜色遮罩,以及用于评估生成图像；根据所述映射规则,将待生成的初始人脸表情图像以及待生成的表情基本类别概率向量输入所述双向对抗性模型,确定连续的目标人脸表情图像。</td>   <td>G06T11/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈宇恒;              马朔;              刘冶;              李浩跃;              李锦芬;              彭楠;              徐振涛;                   印鉴       </td>   <td>火烈鸟网络(广州)股份有限公司;中山大学</td>   <td>一种游戏智能评级方法与系统</td>   <td>广东省</td>   <td>CN108389082B</td>   <td>2021-07-06</td>   <td>本发明涉及一种游戏智能评级方法及系统,所述方法包括以下步骤：采集已上线游戏在上线前的数值数据和文本数据；提取已上线游戏在上线前的数值特征和文本特征并进行特征处理；根据特征处理后已上线游戏在上线前的数值特征、文本特征和已上线游戏的级别标签,建立并训练最优随机森林算法模型；采集未上线游戏的数值数据和文本数据；提取未上线游戏的数值特征和文本特征并进行特征处理；根据最优随机森林算法模型,输入特征处理后未上线游戏的数值特征和文本特征,预测未上线游戏的游戏级别。本发明的游戏智能评级方法及系统具有评级准确,且不受人为主观因素影响的优点。</td>   <td>1.一种游戏智能评级方法,其特征在于,包括以下步骤：采集已上线游戏在上线前的数值数据和文本数据,其中,所述数值数据为该已上线游戏自身参数,所述文本数据包括短文本数据和长文本数据；提取已上线游戏在上线前的数值特征和文本特征并进行特征处理,其中,所述文本特征包括短文本特征和长文本特征；根据特征处理后已上线游戏在上线前的数值特征、文本特征和已上线游戏的游戏级别标签,建立并训练最优随机森林算法模型,其中,所述游戏级别标签为：根据已上线游戏上线后一段时间内的受欢迎程度和盈利能力设立的游戏级别；采集未上线游戏的数值数据和文本数据；提取未上线游戏的数值特征和文本特征并进行特征处理；根据所述的最优随机森林算法模型,输入特征处理后未上线游戏的数值特征和文本特征,预测未上线游戏的游戏级别；其中,所述提取已上线游戏在上线前的数值特征和文本特征的步骤中,包括提取已上线游戏在上线前的短文本特征,具体包括以下步骤,对每种短文本数据,将每个已上线游戏在上线前的短文本数据转换成用TF-IDF权重向量空间来表示的形式,并记录该短文本数据对应的文本语料库；通过LDA聚类对每个转换成TF-IDF权重向量空间形式的已上线游戏进行分类,将所有已上线游戏划分为N类具有相同隐含主题的游戏,将每个已上线游戏所属的隐含主题作为该已上线游戏的短文本特征,并记录该短文本数据对应的N个聚簇中心,其中,N为一常数；所述提取未上线游戏的数值特征和文本特征的步骤中,包括提取未上线游戏的短文本特征,具体包括以下步骤,对每种短文本数据,根据所述记录的对应短文本数据的文本语料库,将每个未上线游戏的短文本数据转换成用TF-IDF权重向量空间来表示的形式；根据所述记录的对应短文本数据的N个聚簇中心,对每个转换成TF-IDF权重向量空间形式的未上线游戏进行分类,将所有未上线游戏划分为N类具有相同隐含主题的游戏,将每个未上线游戏所属的隐含主题作为该游戏的短文本特征。</td>   <td>G06Q30/02;G06F16/35;G06F40/289;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         范述治;              杜云飞;                   卢宇彤       </td>   <td>中山大学</td>   <td>一种容器环境下的MPI应用性能优化方法及系统</td>   <td>广东省</td>   <td>CN113076176A</td>   <td>2021-07-06</td>   <td>本发明公开了一种容器环境下的MPI应用性能优化方法及系统,该方法包括：接收来自用户端的描述参数并进行参数检查,申请对应的物理资源和请求启动相应的容器；记录并接管容器的启动过程,为每个位于同一物理主机上的容器子集申请共享的PID namespace、IPC namespace和共享内存；确认容器就绪,判断通信对端是否为共居进程,并按照预设规则进行MPI进程间通信。该系统包括：面向MPI的容器编排模块、面向Docker容器的组管理插件和面向MPI进程的局部性检测插件。通过使用本发明,实现提高容器环境下的MPI应用运行效率。本发明作为一种容器环境下的MPI应用性能优化方法及系统,可广泛应用于容器和高性能计算领域。</td>   <td>1.一种容器环境下的MPI应用性能优化方法,其特征在于,包括以下步骤：接收来自用户端的描述参数并进行参数检查,申请对应的物理资源和请求启动相应的容器；记录并接管容器的启动过程,为每个位于同一物理主机上的容器子集申请共享的PIDnamespace、IPC namespace和共享内存；确认容器就绪,判断通信对端是否为共居进程,并按照预设规则进行MPI进程间通信。</td>   <td>G06F9/455</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李子明;                   辛秦川       </td>   <td>中山大学</td>   <td>一种基于高分辨率遥感影像的建筑物矢量提取方法及系统</td>   <td>广东省</td>   <td>CN113076803A</td>   <td>2021-07-06</td>   <td>本发明公开了一种基于高分辨率遥感影像的建筑物矢量提取方法及系统,其方法包括：获取目标区域的三波段遥感影像；将三波段遥感影像分别导入训练好的U-Net网络模型和训练好的Cascade CNN网络模型,对应输出建筑物语义分割图和建筑物角点热力图；对建筑物语义分割图和建筑物角点热力图进行要素提取,构成建筑物矢量顶点集；将三波段遥感影像导入训练好的Cascade R-CNN网络模型,并利用模型输出的建筑物预测边界框对建筑物矢量顶点集进行更新；基于更新后的建筑物矢量顶点集生成建筑物基本骨架,结合建筑物语义分割图从建筑物基本骨架中筛选出所有相关骨架数据；对所有相关骨架数据进行矢量融合,得到建筑物矢量结果。</td>   <td>1.一种基于高分辨率遥感影像的建筑物矢量提取方法,其特征在于,所述方法包括：获取目标区域的三波段遥感影像；将所述三波段遥感影像分别导入训练好的U-Net网络模型和训练好的Cascade CNN网络模型,对应输出建筑物语义分割图和建筑物角点热力图；对所述建筑物语义分割图和所述建筑物角点热力图进行要素提取,构成建筑物矢量顶点集；将所述三波段遥感影像导入训练好的Cascade R-CNN网络模型,输出建筑物预测边界框,并利用所述建筑物预测边界框对所述建筑物矢量顶点集进行更新；基于更新后的建筑物矢量顶点集生成建筑物基本骨架,结合所述建筑物语义分割图从所述建筑物基本骨架中筛选出所有相关骨架数据；对所述所有相关骨架数据进行矢量融合,得到建筑物矢量结果。</td>   <td>G06K9/00;G06K9/46;G06K9/62;G06N3/04;G06N3/08;G06T7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              王阔;              刘凌波;                   林倞       </td>   <td>中山大学</td>   <td>一种航空图像道路提取方法及设备</td>   <td>广东省</td>   <td>CN113076811A</td>   <td>2021-07-06</td>   <td>本发明公开了一种航空图像道路提取方法及设备,本发明通过在道路提取模型中对原始航空图像以及GPS热度图进行局部信息提取,将提取到的航空图像局部信息和所述GPS热度图局部信息进行融合,得到航空图像特征图以及GPS热度特征图,基于航空图像特征图以及GPS热度特征图,得到所述航空图像的道路提取结果。本发明通过将航空图像局部信息和GPS热度图局部信息进行融合,从而极大地提高了道路提取效果；航空图像中的遮挡问题以及铁路和道路的混淆问题,可以通过GPS轨迹很好地解决,而GPS轨迹数据中的偏移问题,噪声问题又能够通过航空图像信息来得到缓解,从而使得道路的提取结果准确率高,鲁棒性强。</td>   <td>1.一种航空图像道路提取方法,其特征在于,包括以下步骤：获取原始航空图像以及与所述原始航空图像相对应的GPS热度图；将所述原始航空图像以及所述GPS热度图输入到预先设置好的道路提取模型中,以使所述道路提取模型从所述原始航空图像中提取出航空图像局部信息,从所述GPS热度图中提取出GPS热度图局部信息,并对所述航空图像局部信息和所述GPS热度图局部信息进行融合,得到航空图像特征图以及GPS热度特征图,基于所述航空图像特征图以及所述GPS热度特征图,得到所述航空图像的道路提取结果。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张东;              王梦瑶;              余萌;              陈伟聪;                   何坚       </td>   <td>中山大学</td>   <td>一种基于人眼动作特征的专注度分级方法及系统</td>   <td>广东省</td>   <td>CN113076885A</td>   <td>2021-07-06</td>   <td>本发明公开了一种基于人眼动作特征的专注度分级方法及系统,该方法包括：录制待测视频数据；根据待测视频数据提取用户的左眼视频数据、右眼视频数据、眨眼时长和眨眼频次,得到用户眼部动作特征；将用户眼部动作特征输入到预训练的分类网络,得到用户专注状态的眨眼次数和用户非专注状态的眨眼次数；根据用户专注状态的眨眼次数与用户非专注状态的眨眼次数的比值,判断用户的专注度等级。该系统包括：数据采集模块、特征提取模块、分类模块和分级模块。通过使用本发明,能够分析出该学生在上网课时的专注程度,从而提高学生学习的质量。本发明作为一种基于人眼动作特征的专注度分级方法及系统,可广泛应用于视频处理领域。</td>   <td>1.一种基于人眼动作特征的专注度分级方法,其特征在于,包括以下步骤：录制用户在观看网课时的视频,得到待测视频数据；根据待测视频数据提取用户的左眼视频数据、右眼视频数据、眨眼时长和眨眼频次,得到用户眼部动作特征；将用户眼部动作特征输入到预训练的分类网络,得到用户专注状态的眨眼次数和用户非专注状态的眨眼次数；根据用户专注状态的眨眼次数与用户非专注状态的眨眼次数的比值,判断用户的专注度等级。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余德亮;                   谭光       </td>   <td>中山大学</td>   <td>一种连续帧目标检测去重方法及装置</td>   <td>广东省</td>   <td>CN113076894A</td>   <td>2021-07-06</td>   <td>本申请公开了一种连续帧目标检测去重方法及装置,包括：获取连续视频帧；将图像进行分块；在上一帧图像中搜索与当前帧图像块误差值最小的匹配块,并获取匹配块到当前帧图像块的位移向量；将位移向量进行分类,并计算每一类中的平均位移向量；根据平均位移向量搜索当前帧图像块对应的匹配块；将PSNR值大于预设阈值对应的当前帧图像块标记为可重复使用区域；将上一帧图像的目标检测结果作为待搜索图像区域,搜索当前帧中与待搜索图像块误差值最小的匹配区域；将匹配区域与可重复使用区域作为当前帧在上一帧图像中的重复区域,使得对当前帧进行目标检测时不对重复区域进行计算。本申请解决了现有技术在目标检测时计算区域多,计算量增大的技术问题。</td>   <td>1.一种连续帧目标检测去重方法,其特征在于,包括：获取连续的视频帧；将当前帧图像和上一帧图像进行分块；在上一帧图像中搜索与当前帧图像中图像块误差值最小的第一匹配块,并获取所述第一匹配块到当前帧图像中对应的图像块的位移向量；按方向将所述位移向量进行分类,并计算每一类中所述位移向量的平均值作为平均位移向量,根据所述位移向量所在类别获取当前帧图像中图像块对应的所述平均位移向量；根据所述平均位移向量在上一帧图像中搜索当前帧图像中图像块对应的第二匹配块；计算所述第二匹配块对应的PSNR,将PSNR值大于第一预设阈值的所述第二匹配块对应的当前帧图像块标记为可重复使用区域；将上一帧图像的目标检测结果对应的图像区域作为待搜索图像区域,在当前帧图像中搜索与所述待搜索图像块误差值最小的匹配区域；将所述匹配区域与所述可重复使用区域作为当前帧图像在上一帧图像中的重复区域,使得后续对当前帧进行目标检测时,不对所述重复区域进行计算。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘永红;              王敏亦;              徐锐;                   杨鹏史       </td>   <td>中山大学</td>   <td>一种多因素对空气质量影响的评价方法和装置</td>   <td>广东省</td>   <td>CN113077089A</td>   <td>2021-07-06</td>   <td>本发明提供一种多因素对空气质量影响的评价方法和装置,所述方法包括：获取路网地理信息数据、路网交通流量数据、风向数据和空气质量数据；根据路网地理信息数据,获取路网道路组成、风向数据和空气质量监测站的位置关系；根据位置关系,对数据进行预处理,构建数据集；利用关联规则算法,设定最小支持度和最小置信度,迭代计算支持度和置信度,获得强关联规则；选择合适的强关联规则,输出对应的置信度作为不同路网道路组成、不同交通流量在不同风向环境下,对空气质量影响的评价结果。本发明对影响空气质量的多因素进行定量分析,获得不同路网道路组成、不同交通流量在不同风向环境下对空气质量影响的评价结果,为改善空气质量提供理论基础。</td>   <td>1.一种多因素对空气质量影响的评价方法,其特征在于,所述方法包括以下步骤：S1：获取试验区域内路网地理信息数据、路网交通流量数据、风向数据和空气质量监测站监测的空气质量数据；S2：根据所述路网地理信息数据,获取路网道路组成、风向数据和空气质量监测站的位置关系；S3：根据所述位置关系,对路网交通流量数据、路网道路组成、风向数据和的空气质量数据进行预处理,将预处理后的数据作为数据集的元素,构建数据集；S4：设定最小支持度和最小置信度,利用关联规则算法迭代计算数据集中元素的支持度和置信度,保留所有置信度大于最小置信度的元素,获得强关联规则；所述强关联规则包括规则前项和规则后项；S5：确定强关联规则,所述强关联规则的规则前项为不同路网道路组成、不同交通流量和不同风向,规则后项为空气质量,输出该项强关联规则对应的置信度作为不同路网道路组成、不同交通流量在不同风向环境下,对空气质量影响的评价结果。</td>   <td>G06Q10/04;G06F16/29;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赵铜铁钢;                   陈泽鑫       </td>   <td>中山大学</td>   <td>一种面向出入库径流的水文情势变化分析方法</td>   <td>广东省</td>   <td>CN113077167A</td>   <td>2021-07-06</td>   <td>本发明为克服由于水库出入库流量的差异造成的水库上游和下游的水文情势变化影响河流实际水文情势变化研究的缺陷,提出一种面向出入库径流的水文情势变化分析方法,包括以下步骤：采集入库流量数据序列和出库流量数据序列,确定入库径流和出库径流的水文年；计算入库流量数据的IHA低流量与高流量所需的划分参数,以及入库流量数据的EFC划分参数；将所述IHA低流量与高流量所需的划分参数以及EFC划分参数应用于出库流量数据,分别计算入库径流和出库径流的IHA参数和EFC参数；根据所述入库径流和出库径流的IHA参数和EFC参数,采用IHA的变化范围法RVA对出入库径流的水文情势变化进行分析。</td>   <td>1.一种面向出入库径流的水文情势变化分析方法,其特征在于,包括以下步骤：采集入库流量数据序列和出库流量数据序列,确定入库径流和出库径流的水文年；计算入库流量数据的IHA低流量与高流量所需的划分参数,以及入库流量数据的EFC划分参数；将所述IHA低流量与高流量所需的划分参数以及EFC划分参数应用于出库流量数据,分别计算入库径流和出库径流的IHA参数和EFC参数；根据所述入库径流和出库径流的IHA参数和EFC参数,采用IHA的变化范围法RVA对出入库径流的水文情势变化进行分析。</td>   <td>G06Q10/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李冠彬;              朱聿莹;              刘凌波;                   林倞       </td>   <td>中山大学</td>   <td>一种地铁客流量分布预测方法以及设备</td>   <td>广东省</td>   <td>CN113077281A</td>   <td>2021-07-06</td>   <td>本发明公开了一种地铁客流量分布预测方法以及设备,本发明通过将OD客流量分布中未完成的订单信息作为输入的一部分,与已完成的订单信息一起输入OD客流量分布预测子模型进行预测,从而在对未来的客流量分布预测中考虑了未完成的订单信息。并且,本发明实施例通过将OD第一分布特征隐藏状态和DO第一分布特征隐藏状态进行融合后获得融合特征,从而充分发掘了OD客流量分布与DO客流量分布在预测中相互之间的指导作用,使得地铁客流量分布预测模型输出的预测结果能够准确完整地反映客流量的真实分布情况。</td>   <td>1.一种地铁客流量分布预测方法,其特征在于,包括以下步骤：获取地铁系统在Z个历史时刻的OD客流量分布以及Z个历史时刻的DO客流量分布；其中,所述OD客流量分布中包括已完成的订单信息以及未完成的订单信息,其中,Z∈N+；将所述Z个历史时刻的OD客流量分布以及所述Z个历史时刻的DO客流量分布输入到预先设置的地铁客流量分布预测模型中,以使所述地铁客流量分布预测模型根据所述Z个历史时刻的OD客流量分布以及所述Z个历史时刻的DO客流量分布,获得OD第一分布特征隐藏状态以及DO第一分布特征隐藏状态,并基于由所述OD第一分布特征隐藏状态和所述DO第一分布特征隐藏状态融合后获得的融合特征,获得OD第二分布特征隐藏状态和DO第二分布特征隐藏状态,基于所述OD第一分布特征隐藏状态、所述DO第一分布特征隐藏状态、所述OD第二分布特征隐藏状态以及所述DO第二分布特征隐藏状态,输出未来Z个时刻的OD客流量分布预测和未来Z个时刻的DO客流量分布预测。</td>   <td>G06Q30/02;G06Q50/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         田海博;              罗玉琴;                   叶婉       </td>   <td>中山大学</td>   <td>一种基于有向无环图的区块链共识系统</td>   <td>广东省</td>   <td>CN113077343A</td>   <td>2021-07-06</td>   <td>本发明涉及一种基于有向无环图的区块链共识系统。包括委员会模块、链增长模块、排序模块以及网络模块,网络模块用于完成系统中各个模块之间的网络通信；委员会模块、链增长模块和排序模块共同完成区块链共识；委员会模块用于确认下一世代的活跃节点,第零世代的活跃链节点形成初始委员会,每个世代的委员会成员数量均为L；链增长模块用于根据当前委员会成员生成的链交易CTs更新有向无环图；排序模块首先完成普通交易NNTs的确认,形成共识,然后采用所确定的算法对确认的NNTs进行排序,形成一致的顺序。本发明将权益证明和有向无环图结合,不需要在一个委员会中运行拜占庭容错算法,也避免了需要见证节点或协调服务器的情况。</td>   <td>1.一种基于有向无环图的区块链共识系统,其特征在于,包括委员会模块、链增长模块、排序模块以及网络模块,所述的网络模块用于完成系统中各个模块之间的网络通信；所述的委员会模块、链增长模块和排序模块共同完成区块链共识；所述的委员会模块用于确认下一世代的活跃节点,第零世代的活跃链节点形成初始委员会,每个世代的委员会成员数量均为L；所述的链增长模块用于根据当前委员会成员生成的链交易CTs更新有向无环图；所述的排序模块首先完成普通交易NNTs的确认,形成共识,然后采用所确定的算法对确认的NNTs进行排序,形成一致的顺序。</td>   <td>G06Q40/04;G06F21/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         董春雨;              马至敏;              郭杰;              陈晓宏;              林凯荣;                   刘智勇       </td>   <td>中山大学;广东省科学院广州地理研究所</td>   <td>一种数据空间分辨率提高方法、装置、介质及终端设备</td>   <td>广东省</td>   <td>CN113077384A</td>   <td>2021-07-06</td>   <td>本发明公开了一种数据空间分辨率提高方法、装置、存储介质及终端设备,包括：将获取的预设时间段内的AVHRR NDVI数据及MODSI NDVI数据进行数据预处理,以得到月尺度数据；将所述月尺度数据输入尺度变换模型进行降尺度处理；对降尺度处理后的尺度数据进行误差分析,并根据分析结果对所述尺度变换模型进行优化。本发明能够将某一地区的AVHRR NDVI低分辨率的空间尺度转变为MODIS NDVI数据高分辨率的空间尺度,提高数据的精度,增加其可用性。</td>   <td>1.一种数据空间分辨率提高方法,其特征在于,所述方法包括：将获取的预设时间段内的AVHRR NDVI数据及MODSI NDVI数据进行数据预处理,以得到月尺度数据；将所述月尺度数据输入尺度变换模型进行降尺度处理；对降尺度处理后的尺度数据进行误差分析,并根据分析结果对所述尺度变换模型进行优化。</td>   <td>G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         匡铭;              翁宗鹏;              许丽霞;              彭穗;              陈淑玲;              肖晗;                   陈峭峰       </td>   <td>中山大学附属第一医院</td>   <td>一种基于图像分析的肿瘤微血管侵犯检测装置</td>   <td>广东省</td>   <td>CN113077415A</td>   <td>2021-07-06</td>   <td>本发明公开了一种基于图像分析的肿瘤微血管侵犯检测装置,包括：输入模块,用于将病理图像分割成若干个预设尺寸大小的区域图像,并将若干个区域图像输入至血管侵犯模型中；标记模块,用于利用血管侵犯模型对区域图像进行图像检测得到肿瘤微血管侵犯结构,并采用矩形框标记每一肿瘤微血管侵犯结构；去重模块,用于根据矩形框的覆盖面积和置信度,对重叠的两个矩形框进行去重得到去重后的矩形框；分类模块,用于将每一矩形框裁剪成以每一矩形框的重心作为重心、以每一矩形框的长作为边长的正方形图像,采用分类模型对正方形图像进行分类,判断正方形图像是否为肿瘤微血管侵犯。本发明实施例能够有效提高肿瘤微血管侵犯检测的准确性和可靠性。</td>   <td>1.一种基于图像分析的肿瘤微血管侵犯检测装置,其特征在于,包括：输入模块,用于将病理图像分割成若干个预设尺寸大小的区域图像,并将若干个所述区域图像输入至血管侵犯模型中；标记模块,用于利用所述血管侵犯模型对所述区域图像进行图像检测得到肿瘤微血管侵犯结构,并采用矩形框标记每一所述肿瘤微血管侵犯结构,其中每一所述矩形框所标记的肿瘤微血管侵犯结构均对应一个置信度；去重模块,用于根据所述矩形框的覆盖面积和置信度,对重叠的两个所述矩形框进行目标去重处理,得到去重后的矩形框；分类模块,用于将每一矩形框裁剪成以每一所述矩形框的重心作为重心、以每一所述矩形框的长作为边长的正方形图像,采用分类模型对所述正方形图像进行分类,判断所述正方形图像是否为肿瘤微血管侵犯。</td>   <td>G06T7/00;G06T7/11;G06T7/66</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周锦;              张青;              孙伟;              郑伟诗;                   席杨       </td>   <td>中山大学</td>   <td>基于无监督学习的单张图片本征图像分解方法、系统及介质</td>   <td>广东省</td>   <td>CN113077451A</td>   <td>2021-07-06</td>   <td>本发明公开了一种基于无监督学习的单张图片本征图像分解方法、系统及介质,方法包括下述步骤：构建本征图像分解模型,所述本征图像分解模型包括两个分支,一支为反射率生成网络,另一支为光照生成网络；设置随机噪声参数并经过训练后得到两个与原图尺度相同的随机噪声；将生成的两个随机噪声分别作为反射率网络和光照网络的输入,在损失函数的约束下,不断利用反向传播算法更新反射率网络和光照网络的参数；当更新反射率网络和光照网络的参数多次后,在历史输出中选取重构图与原图峰值信噪比PSNR值最小的那组结果作为本征图像分解的最终结果。通过两个结构相同的反射率生成网络和光照网络,分别输出反射率和光照,实现无监督的本征图像分解。</td>   <td>1.基于无监督学习的单张图片本征图像分解方法,其特征在于,包括下述步骤：构建本征图像分解模型,所述本征图像分解模型包括两个分支,一支为反射率生成网络,另一支为光照生成网络；设置随机噪声参数并经过训练后得到两个与原图尺度相同的随机噪声；将生成的两个随机噪声分别作为反射率网络和光照网络的输入,在损失函数的约束下,不断利用反向传播算法更新反射率网络和光照网络的参数；当更新反射率网络和光照网络的参数多次后,在历史输出中选取重构图与原图峰值信噪比PSNR值最小的那组结果作为本征图像分解的最终结果。</td>   <td>G06T7/00;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;              凌鹏;                   莫浩然       </td>   <td>中山大学</td>   <td>草图图像语义分割方法、装置、终端设备及存储介质</td>   <td>广东省</td>   <td>CN113077469A</td>   <td>2021-07-06</td>   <td>本发明公开了一种草图图像语义分割方法、装置、终端设备及存储介质,包括：获取一草图图像；将所述草图图像输入到预先建立的交汇点识别模型,获得仅包含所述草图图像中交汇点的第一图像；对所述草图图像和所述第一图像作差,得到去除所述草图图像中交汇点的第二图像；将所述草图图像和所述第二图像组织成训练样本,并基于所述训练样本对预设的神经网络模型进行训练,得到语义分割模型；将待分割草图图像输入到所述语义分割模型,得到草图语义分割结果,能有效解决使用现有模型将位于一条连续线条上的像素被划分为多个类导致错误分割的问题,大大提高了图像语义分割的准确度。</td>   <td>1.一种草图图像语义分割方法,其特征在于,包括：获取一草图图像；将所述草图图像输入到预先建立的交汇点识别模型,获得仅包含所述草图图像中交汇点的第一图像；对所述草图图像和所述第一图像作差,得到去除所述草图图像中交汇点的第二图像；将所述草图图像和所述第二图像组织成训练样本,并基于所述训练样本对预设的神经网络模型进行训练,得到语义分割模型；将待分割草图图像输入到所述语义分割模型,得到草图语义分割结果。</td>   <td>G06T7/10;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   莫浩然       </td>   <td>中山大学</td>   <td>图像矢量化方法、装置及终端设备</td>   <td>广东省</td>   <td>CN113077477A</td>   <td>2021-07-06</td>   <td>本发明公开了一种图像矢量化方法、装置及终端设备,包括：获取像素级图像,并构造与像素级图像大小相同的画布,初始化裁剪窗口的信息,根据裁剪窗口,对像素级图像和画布进行对齐裁剪,得到区域小块,将区域小块输入到笔划生成器进行计算,获得相应的笔划信息,并根据笔划信息绘制笔划,基于裁剪窗口对笔划进行可微拼贴,得到与像素级图像相适配的笔划帧,将裁剪窗口移动到笔划绘制的末端位置,并更新裁剪窗口的窗口位置,当检测到当前绘制长度达到绘制最大长度时,停止绘制,获得矢量图。本发明可适用于不同风格、不同分辨率的图像,且无需调整大量参数以适配不同的图像,降低了计算复杂度,并能有效提高矢量化技术速度。</td>   <td>1.一种图像矢量化方法,其特征在于,包括：获取像素级图像,并构造与所述像素级图像大小相同的画布；初始化裁剪窗口的信息,所述信息包括窗口大小和窗口位置；根据所述裁剪窗口,对所述像素级图像和所述画布进行对齐裁剪,得到区域小块；将所述区域小块输入到预先建立的笔划生成器进行计算,获得相应的笔划信息,并根据所述笔划信息绘制笔划；基于所述裁剪窗口对所述笔划进行可微拼贴,得到与所述像素级图像相适配的笔划帧；将所述裁剪窗口移动到所述笔划绘制的末端位置,并更新所述裁剪窗口的窗口位置；当检测到当前绘制长度达到预设的绘制最大长度时,停止绘制,获得矢量图。</td>   <td>G06T7/11;G06T11/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   陈佳星       </td>   <td>中山大学</td>   <td>一种基于局部特征关系探究的小样本图像分类方法</td>   <td>广东省</td>   <td>CN113076976A</td>   <td>2021-07-06</td>   <td>本发明提供一种基于局部特征关系探究的小样本图像分类方法,该方法采用了多层次的图神经网络,首先通过局部级图神经网络挖掘每个图像中局部特征之间的关系,提取出图像的更具代表性的局部语义特征；然后通过任务级图神经网络探究每个任务中所有样本的局部语义特征之间的关系,去学习更具区分性的任务级局部语义特征。相比之前的基于图神经网络的小样本学习方法,本发明方法通过多层次的局部关系挖掘,使得学习到的样本间的相似性更细粒度、更准确,从而提升了小样本图像分类的性能。</td>   <td>1.一种基于局部特征关系探究的小样本图像分类方法,其特征在于,包括以下步骤：S1:使用卷积神经网络提取图像的初始局部特征；S2：用S1得到的初始局部特征构造一个局部级图,通过局部级图神经网络提取图像的局部语义特征；S3：用S2得到的所有图像的局部语义特征构造一个任务级图,通过任务级图神经网络探究局部语义特征间的关系,并运用于小样本图像分类。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苏勤亮;                   高月       </td>   <td>中山大学</td>   <td>一种基于注意力增强以及输入扰动的分布外图像检测方法</td>   <td>广东省</td>   <td>CN113076980A</td>   <td>2021-07-06</td>   <td>本发明提供一种基于注意力增强以及输入扰动的分布外图像检测方法,该方法采用了输入扰动的技巧,对分布内的样本影响大于分布外样本,使得分布内样本的自信分数更高,同时使用了温度缩放的技巧,使得分布内样本的预测概率分布更加尖锐,分布外样本的预测概率更加平滑,进一步加大分布内外样本的自信分数差距；相较于直接使用生成模型进行分布外样本检测任务,本方法不需要引入额外的超参,并且模型相对简单,可以节省训练时间；相较于使用生成对抗的方法做分布外样本检测任务,本方法不会过度局限于训练数据,对于边缘样本不容易产生误判,可以得到更好的检测效果。</td>   <td>1.一种基于注意力增强以及输入扰动的分布外图像检测方法,其特征在于,包括以下步骤：S1：给输入图像添加扰动,并计算扰动后图像分类以及判别是否为分布内样本的两种不确定性；S2：利用S1不确定性进行注意力图计算,给特征进行加权；S3：将S2得到的加权后的特征作为分类器的输入进行温度缩放后得到数据分类的概率分布。</td>   <td>G06K9/62;G06K9/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              郑炎辉;              何艳虎;              张建云;                   王高旭       </td>   <td>中山大学;水利部交通运输部国家能源局南京水利科学研究院</td>   <td>基于报童模型的考虑供需不确定的水资源优化配置方法</td>   <td>广东省</td>   <td>CN109190902B</td>   <td>2021-07-02</td>   <td>本发明涉及一种基于报童模型的考虑供需不确定的水资源优化配置方法。包括：S1.利用实测水文资料分析寻求径流变化规律,通过统计分析得到径流的概率分布；S2.按照经典报童理论,根据农业、工业、生活用水特点,把这三个类型需水量均假设为均匀分布,以前三年的数据作为历史数据分析进行需水滚动预报；S3.利用来水、需水的概率分布函数,引入经济学报童模型,构建考虑供需水不确定性的水资源优化配置报童模型,求解得到初步配置方案；判断初步配置方案总配置水量是否超过最大可供水量,若没有,则初步配置方案就是最优方案,若超过,采用两阶段启发式算法重新进行求解,得到最优方案。本发明提供的方法能够获得更接近来需水实际情况的水资源配置方案。</td>   <td>1.一种基于报童模型的考虑供需不确定的水资源优化配置方法,其特征在于,包括以下步骤：S1.来水不确定性分析：利用实测水文资料分析寻求径流变化规律,通过统计分析得到径流的概率分布函数；S2.需水不确定性分析：按照经典报童理论,根据农业、工业、生活用水特点,把农业、工业、生活三个类型需水量均假设为均匀分布,以预测年份前三年的数据作为历史数据分析进行需水滚动预报；S3.利用S1、S2步骤分析得到的来水、需水的概率分布函数,引入经济学报童模型,构建考虑供水需水不确定性的水资源优化配置报童模型,求解得到初步配置方案；判断初步配置方案总配置水量是否超过最大可供水量,若无超过则初步配置方案就是最优方案,若超过则采用两阶段启发式算法重新进行求解,得到最优方案；其中：所述的考虑供需不确定的水资源优化配置报童模型考虑了来水、需水的不确定性,其目标函数的来水与需水变量皆为随机变量,考虑来水、需水的概率分布函数：某地区某类型配水成本函数为                  期望成本如下：                                                      式中,为i单元、j部门、t时段需水量,为随机变量；为累积分布函数为；为密度函数,最小为最大为R～t为t时段径流流量,为随机变量；G(R～t)为累积分布函数为,g(R～t)为密度函数,最大为最小为为i单元,j部门,t时段配水量； 为t时段配水过多成本；为t时段配水不足成本；为购水成本；r～t＝t时段,实际流量；h为配水过多的单位罚款,c为单位水价,v为配水不足的单位机会损失；所述的采用两阶段启发式算法进行求解,是通过拉格朗日参数将目标费用函数与可利用水量约束联系起来,构成一个全新的拉格朗日函数,其函数为：                  式中,t为时刻,为t时刻水库下泄最大流量,λ为表示约束条件的拉格朗日参数。</td>   <td>G06Q10/06;G06Q10/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         熊会元;              王志军;              刘羽;              潘跃龙;              马健;              李同同;                   尹文成       </td>   <td>中山大学;中广核工程有限公司</td>   <td>基于物联网的放射性废物贮运控制系统</td>   <td>广东省</td>   <td>CN113065818A</td>   <td>2021-07-02</td>   <td>针对贮运对象的特殊性以及现有技术的局限性,本发明提出了一种基于物联网的放射性废物贮运控制系统,通过智能化运输车辆将放射性废物从废物暂存库到废物处置洞实现无人智能化运输,通过智能堆码装置实现放射性废物的处置工作,通过工艺流程状态看板实时了解贮运处置作业流程状态,通过数据中心对放射性废物实现决策分析和协同控制；实现了放射性废物的全流程智能化贮运,避免了工作人员近距离接触放射性废物,便于工作人员对贮运过程的管控,同时也提高了贮运处置作业操作效率,保证安全、可靠地实现废物货包的贮运操作。</td>   <td>1.一种基于物联网的放射性废物贮运控制系统,其用于将包括放射性废物的废物包从暂存库转移至处置库,其特征在于,包括运用物联网技术实现连接的放射性废物贮运数据中心、放射性废物贮运智能化装备、主控中心以及贮运处置作业流程状态看板；其中：所述放射性废物贮运数据中心用于采集、存储、管控贮运处置作业流程的实时数据,根据实时数据分析进行决策,生成最优控制指令；所述主控中心用于根据所述最优控制指令控制所述放射性废物贮运智能化装备对所述废物包进行贮运处置作业；所述贮运处置作业流程状态看板用于实时呈现所述放射性废物贮运智能化装备的运行状态和贮运处置作业流程。</td>   <td>G06Q10/08;G06Q50/30;G21F5/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴万庆;              韦程琳;              蒋明哲;                   张献斌       </td>   <td>中山大学</td>   <td>一种基于紧凑型卷积神经网络的抑郁症识别方法及系统</td>   <td>广东省</td>   <td>CN113052113A</td>   <td>2021-06-29</td>   <td>本发明提供了一种基于紧凑型卷积神经网络的抑郁症识别方法及系统,所述方法包括：获取若干个受测者的脑电信号数据；其中,所述受测者包括抑郁症受测者和正常受测者；对所述脑电信号数据进行数据预处理,并按照预设的比例将预处理后的脑电信号数据划分为训练数据集和测试数据集；将所述训练数据集输入至预先构建的紧凑型卷积神经网络,以对所述紧凑型卷积神经网络进行训练,在所述紧凑型卷积神经网络达到预设的收敛状态时,生成抑郁症识别模型；将所述测试数据集输入至所述抑郁症识别模型进行识别并分别输出抑郁症识别结果以及正常识别结果。通过实施本发明能够有效降低识别模型对数据质量的依赖性,并提高识别的准确性。</td>   <td>1.一种基于紧凑型卷积神经网络的抑郁症识别方法,其特征在于,包括：获取若干个受测者的脑电信号数据；其中,所述受测者包括抑郁症受测者和正常受测者；对所述脑电信号数据进行数据预处理,并按照预设的比例将预处理后的脑电信号数据划分为训练数据集和测试数据集；将所述训练数据集输入至预先构建的紧凑型卷积神经网络,以对所述紧凑型卷积神经网络进行训练,在所述紧凑型卷积神经网络达到预设的收敛状态时,生成抑郁症识别模型；其中,所述紧凑型卷积神经网络包含常规卷积层、Depthwise卷积层、Separable卷积层和softmax层；将所述测试数据集输入至所述抑郁症识别模型进行识别并分别输出抑郁症识别结果以及正常识别结果。</td>   <td>G06K9/00;G06N3/04;G06N3/08;G16H20/70</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;                   谭骏朗       </td>   <td>中山大学</td>   <td>一种基于对数映射函数分块处理融合的色调映射方法</td>   <td>广东省</td>   <td>CN108022223B</td>   <td>2021-06-25</td>   <td>本发明涉及一种基于对数映射函数分块处理融合的色调映射方法,包括以下步骤：步骤100：获得一幅高动态图像；步骤200：将所述高动态图像划分为多个大小相等的局部块；步骤300：将划分的局部块分别使用对数压缩函数进行亮度压缩处理；步骤400：将所述经过亮度压缩处理的局部块使用高斯融合函数进行图像融合；步骤500：将所述图像融合得到的图像使用双边滤波进行细节增强；步骤600：将所述经过细节增强的图像进行伽马校正后输出低动态图像。</td>   <td>1.一种基于对数映射函数分块处理融合的色调映射方法,其特征在于：包括以下步骤：步骤100：获得一幅高动态图像；步骤200：将所述高动态图像划分为多个大小相等的局部块；所述步骤200对高动态图像进行划分后,对各个局部块的最大亮度值和亮度进行调整,具体如下：1)计算局部块的对数均值：                  其中L-w(x,y)表示局部块上坐标为(x,y)的像素点的亮度值,δ表示一个非常小的常数,b表示对数压缩系数,N表示局部块上像素点的数量；2)利用对数均值计算键值：L-(wa)＝L-a/((1.0+b-0.85)～5)；3)利用键值对局部块的最大亮度值和亮度进行调整：L-(amax)＝L-(max)/L-(wa)L-w'＝L-w/L-(wa)其中L-(amax)、L-w'分别表示调整后的局部块的最大亮度值和亮度,L-(max)、L-w分别表示调整前的局部块的最大亮度值和亮度；步骤300：将划分的局部块分别使用对数压缩函数进行亮度压缩处理；步骤400：将经过亮度压缩处理的局部块使用高斯融合函数进行图像融合；步骤500：将所述图像融合得到的图像使用双边滤波进行细节增强；步骤600：将经过细节增强的图像进行伽马校正后输出低动态图像。</td>   <td>G06T5/00;G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              刘德地;              张建云;              叶海霞;                   王高旭       </td>   <td>中山大学;水利部交通运输部国家能源局南京水利科学研究院</td>   <td>一种多智能体配置方法</td>   <td>广东省</td>   <td>CN109117998B</td>   <td>2021-06-25</td>   <td>本发明涉及一种多智能体配置方法。包括：S1.根据人类用水的特点,确立水资源配置系统的层次结构；S2.建立基于多智能体系统的水资源优化配置模型框架：确立水资源配置系统中智能体的组成与系统结构,在智能体组成与层次结构的基础上构建水资源优化配置模型框架结构,其次确定智能体之间的协作关系、协商机制；S3.分析水资源优化配置模型中各智能体Agent的模型行为,确定各智能体的约束和边界条件；S4.利用优化算法对模型进行求解。本发明将智能体系统的理论与方法应用于水资源配置领域,确立了一套比较完整的多智能体模型,有助于分析水资源配置系统中各层次的相互关系,描述各主体行为与整体演化的有机联系,模拟水资源分配过程,进行水资源的优化配置。</td>   <td>1.一种多智能体配置方法,其特征在于,包括以下步骤：S1.根据研究区人类用水的特点,确立水资源配置系统的层次结构；S2.建立基于多智能体系统MAS的水资源优化配置模型框架：首先确立水资源配置系统中智能体的组成与系统结构,并在智能体组成与层次结构的基础上构建水资源优化配置模型框架结构,其次确定智能体之间的协作关系、协商机制；S3.分析水资源优化配置模型中各智能体Agent的模型行为,确定各智能体的约束和边界条件；S4.利用优化算法对模型进行求解；其中,多智能体的组成包括：水源Agent、需水Agent、供水Agent、水资源调配Agent；所述的水源Agent用于分析水文气象变化特点,给出不同时空水资源量的大小、水质情况,与供水Agent协商,实现任务委派,监测水质变化,执行调配计划；所述的需水Agent用于分析社会经济发展状况,预测水资源需求量,将水资源需求的统计信息传递给水资源配置Agent；所述的供水Agent用于考虑不同区域工程特点和规模,形成供水任务分配联盟,与水源Agent协商,形成任务委派,向水资源调配Agent传递任务执行情况,与水资源调配Agent协商,完成供水Agent系统优化,确定水资源配置目标；所述的水资源调配Agent用于接受需水Agent、水源Agent、供水Agent的约束,指导整个水资源系统的优化配置,将分配结果传递给供水Agent和用水Agent,指导水资源的应急调度。</td>   <td>G06Q10/04;G06Q10/06;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              欧阳柳;              吴卓亮;                   谢晓华       </td>   <td>中山大学</td>   <td>一种融合手工设计描述子和深度特征的人脸姿态估计方法</td>   <td>广东省</td>   <td>CN109858342B</td>   <td>2021-06-25</td>   <td>本发明公开了一种融合手工设计描述子和深度特征的人脸姿态估计方法,常应用于针对安全防范和人脸识别应用的人脸图像质量评测。该方法使用SIFT描述子提取人脸图像的轮廓和局部信息,使用DeepID深度网络提取人脸图像的表观和结构信息,主要包括以下步骤：训练一个提取深度特征的深度神经网络模型,输入一张检测得到的人脸图像,利用该深度网络模型提取所述人脸图像深度特征；提取具有尺度空间不变特性的SIFT特征向量,将该人脸图像的SIFT特征以及深度特征串联,输入到训练好的SVM分类器进行分类,确定该待分类的人脸的姿态类别。本发明能够有效地进行人脸姿态估计,提高姿态估计的准确率。</td>   <td>1.一种融合手工设计描述子和深度特征的人脸姿态估计方法,其特征在于,包括步骤：S1：对图像进行人脸检测；S2：对检测到的人脸图像进行滤波以去除噪声；S3：提取人脸图像的SIFT特征,作为手工设计描述子；提取描述人脸的深度特征；S4：对手工设计描述子和深度特征进行有效融合；S5：对融合特征进行训练,生成人脸姿态分类器；S6：利用人脸姿态分类器对图像或视频帧中的人脸姿态进行有效估计。</td>   <td>G06K9/00;G06K9/46;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄伟浩;              郑伟诗;                   庞景龙       </td>   <td>中山大学</td>   <td>基于自动数据增强的域泛化行人重识别方法、系统及介质</td>   <td>广东省</td>   <td>CN113033410A</td>   <td>2021-06-25</td>   <td>本发明公开了一种基于自动数据增强的域泛化行人重识别方法、系统及介质,该方法包括：定义数据增强策略,并构建数据增强策略算法以得到最终输出的数据增强策略在源域训练集上应用重新训练行人重识别模型；应用训练好的行人重识别模型进行行人匹配。本发明采用了一种针对域泛化行人重识别问题的数据增强策略搜索算法搜索出一组复杂的数据增强策略,多样性强,可提升行人重识别模型在未知场景下的稳定性和鲁棒性,有利于推进行人重识别技术落地。另外,本发明在数据增强策略搜索过程中采用了TPE算法调优数据增强策略,相比普通数据增强操作进一步提升模型的泛化能力,策略搜索时不需要重复训练行人重识别模型,提升了搜索效率。</td>   <td>1.基于自动数据增强的域泛化行人重识别方法,其特征在于,包括下述步骤：定义数据增强策略,并构建数据增强策略算法以得到最终输出的数据增强策略具体为：采样子数据集；令最终输出的数据增强策略为空；在每个子数据集内通过数据增强策略算法搜索数据增强策略,并将搜索到的数据增强策略补充至在源域训练集上应用重新训练行人重识别模型,具体为：对源域训练集进行采样；应用生成输入数据并输入行人重识别模型；使用损失函数优化行人重识别模型；所述行人重识别模型以残差网络ResNet50为主干网络,主干网络输出一个高维向量作为判别特征,训练网络时,判别特征输入到分类器以计算损失函数和通过反向传播更新参数,实际应用时,判别特征用于计算行人图片间的相似度；应用训练好的行人重识别模型,以行人图像判别特征间的欧氏距离作为相似度进行行人匹配。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建芳;                   侯智聪       </td>   <td>中山大学</td>   <td>基于双线性的多模态信息处理的人工智能方法、系统及介质</td>   <td>广东省</td>   <td>CN113033430A</td>   <td>2021-06-25</td>   <td>本发明公开了一种基于双线性的多模态信息处理的人工智能方法、系统及介质,该方法包括：将视频流转化为图像帧；划分动作序列；构建骨架时序特征、RGB和深度时序特征；构建三维特征立方体并输入双线性特征学习模块；输出分类识别结果。本发明通过双线性的处理方式构造深度网络融合RGBD视频中多模态信息,克服了现有的多模态模型中简单地拼接或加权不同模态输出的特征或激活向量,并没有深入挖掘模态间信息的缺陷,进行准确的动作行为识别。本发明的双线性操作为平面级计算,计算代价小,适于在实时性要求高的工业领域进行应用。</td>   <td>1.基于双线性的多模态信息处理的人工智能方法,其特征在于,包括下述步骤：将视频流转化为图像帧,并划分为动作序列；根据所述动作序列构建骨架时序特征、RGB和深度时序特征,并构建三维特征立方体；将所述三维特征立方体输至双线性特征学习模块中,得到激活向量；所述双线性特征学习模块为若干模态池化层和时序池化层的堆叠；取所述激活向量中的最大值对应的类别作为动作识别的分类结果。</td>   <td>G06K9/00;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄方军;                   万晨       </td>   <td>中山大学</td>   <td>基于预测校正和随机步长优化的对抗性攻击与防御方法及系统</td>   <td>广东省</td>   <td>CN113033822A</td>   <td>2021-06-25</td>   <td>本发明为基于预测校正和随机步长优化的对抗性攻击与防御方法及系统,其方法包括步骤：输入训练数据集和机器学习模型；根据输入的训练数据集训练机器学习模型；判断损失函数是否收敛；若损失函数不收敛则采用基于预测校正和随机步长优化的对抗攻击生成对抗样本,并和原始数据作为训练数据集对机器学习模型进行训练,直至损失函数收敛,得到训练好的机器学习模型；若损失函数收敛,则直接输出结果。本发明通过对抗攻击生成对抗样本,能够在相同扰动约束限制下实现更高的攻击成功率,可用于评估机器学习模型的性能以及对抗防御方法的有效性；所产生的对抗样本对机器学习模型实施对抗训练能有效地抵御各种对抗性攻击,提升模型的鲁棒性。</td>   <td>1.基于预测校正和随机步长优化的对抗性攻击与防御方法,其特征在于,包括以下步骤：S1、输入训练数据集和机器学习模型f；S2、根据输入的训练数据集训练机器学习模型f；S3、判断损失函数J是否收敛,如果损失函数J不收敛,则采用基于预测校正和随机步长优化的对抗性攻击生成对抗样本x～(adv),并将所生成的对抗样本和原始数据x组成训练数据集对机器学习模型f进行训练,直至损失函数J收敛,得到训练后的机器学习模型f。</td>   <td>G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴卓;              林斯颖;              刘海晴;              赵慧英;              宋益东;              杨跃东;                   麦思瑶       </td>   <td>中山大学孙逸仙纪念医院</td>   <td>基于乳腺MR影像组学的乳腺癌分子分型变化预测装置</td>   <td>广东省</td>   <td>CN113034436A</td>   <td>2021-06-25</td>   <td>本发明公开了一种基于乳腺MR影像组学的乳腺癌分子分型变化预测装置,包括：采集模块,用于采集乳腺癌患者的MR图像；分割模块,用于提取MR图像中的增强图像,并对增强图像中的肿物边缘进行勾画,得到标注的病灶区域；第一预测模块,用于提取病灶区域得到待处理图像,并对待处理图像进行图像预处理后输入到深度学习模型中,得到乳腺癌分子分型的第一预测结果；第二预测模块,用于提取增强图像中的特征数据,基于特征数据进行分析得到乳腺癌分子分型的第二预测结果；验证模块,用于对第一预测结果和第二预测结果进行鲁棒性的验证。本发明实施例通过第一预测结果和第二结果进行鲁棒性验证,能够有效提高对乳腺癌分子分型预测的准确性。</td>   <td>1.一种基于乳腺MR影像组学的乳腺癌分子分型变化预测装置,其特征在于,包括：采集模块,用于采集乳腺癌患者的MR图像；分割模块,用于提取所述MR图像中的增强图像,并对所述增强图像中的肿物边缘进行勾画,得到标注的病灶区域；第一预测模块,用于提取所述病灶区域得到待处理图像,并对所述待处理图像进行图像预处理后输入到深度学习模型中,得到乳腺癌分子分型的第一预测结果；第二预测模块,用于提取所述增强图像中的特征数据,基于所述特征数据进行分析得到乳腺癌分子分型的第二预测结果；验证模块,用于对所述第一预测结果和所述第二预测结果进行鲁棒性的验证。</td>   <td>G06T7/00;G06K9/34;G06K9/62;G06N3/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓晓晴;                   骆伟祺       </td>   <td>中山大学</td>   <td>一种基于梯度网络架构搜索的空域隐写分析方法及系统</td>   <td>广东省</td>   <td>CN113034472A</td>   <td>2021-06-25</td>   <td>本发明提出一种基于梯度网络架构搜索的空域隐写分析方法及系统,解决了现有人工设计网络性能表现欠佳以及搜索网络耗时长的问题,首先定义一个隐写分析网络搜索架构,确定隐写分析网络搜索架构中每部分待搜索模块的搜索架构及候选操作,并使用Softmax函数融合搜索空间中的所有候选操作以构建一个超参数网络,然后利用梯度下降法对所构建的超参数网络进行训练优化,根据训练好的超参数网络中的架构参数选定相应的操作,完成隐写分析网络的搜索构建,本方案所提方法减少了网络设计中的人工干预,避免所构建隐写分析网络的性能受限的弊端,并且基于梯度更新的网络架构搜索方式使搜索耗时减少。</td>   <td>1.一种基于梯度网络架构搜索的空域隐写分析方法,其特征在于,至少包括：S1.构建包括若干部分的隐写分析网络搜索框架,确定每部分对应的搜索架构及搜索空间中的候选操作；S2.利用Softmax函数将搜索空间中的所有候选操作进行结合,构建包含候选操作的超参数网络；S3.利用梯度下降法对构建出的超参数网络进行训练优化；S4.根据训练好的超参数网络,完成隐写分析网络的搜索构建,确定搜索得到的隐写分析网络,用于隐写分析。</td>   <td>G06T7/00;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈思航;              骆伟祺;                   余超       </td>   <td>中山大学</td>   <td>一种基于专家轨迹的量化投资方法及装置</td>   <td>广东省</td>   <td>CN113034290A</td>   <td>2021-06-25</td>   <td>本发明提出一种基于专家轨迹的量化投资方法及装置,解决了现有利用机器学习实现量化投资的方法忽略真实交易因素且考虑较局限的问题,首先收集历史数据,引入马尔可夫决策过程,降低量化投资交易的复杂度,基于强化学习中的Q学习方法,引入Q网络,实现状态到值函数的映射并输出每一个动作的值函数,然后设计专家轨迹,考虑上一个时间点与下一个时间点的情况,避免传统方法忽略真实交易因素且考虑较局限的问题,平衡强化学习中不确定策略的探索和开发的过程,使强化学习中的智能体更适应金融市场中不可避免的噪音,进一步训练Q网络,保证量化投资方法的有效性。</td>   <td>1.一种基于专家轨迹的量化投资方法,其特征在于,至少包括：S1.根据预设的投资标的,获取历史交易数据,并根据预设的交易周期将历史交易数据划分为训练数据和测试数据；S2.引入马尔可夫决策过程,确认智能体观测到的状态集合、智能体动作集合及智能体与环境交互获得的奖励函数；S3.基于强化学习中的Q学习方法,引入Q网络,实现状态到值函数的映射并输出每一个动作的值函数；S4.根据训练数据设计专家,基于下一时刻和当前收盘价做出正确的交易动作以获得最大累计奖励,并形成专家轨迹；S5.根据马尔可夫决策过程及专家轨迹训练Q网络；S6.利用测试数据在训练好的Q网络中进行投资收益测试。</td>   <td>G06Q40/06;G06Q40/04;G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈金坤;              蔡丹蔚;              蔡炜城;                   李明       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于重排序超向量和残差网络的说话人识别方法及其装置</td>   <td>广东省</td>   <td>CN108694949B</td>   <td>2021-06-22</td>   <td>本发明公开了基于重排序超向量和残差网络的说话人识别方法及其装置,方法包括：对语音样本进行信号检测,提取及优化MFCC特征；基于TDNN声学模型处理MFCC特征,得到均值中心化超向量；根据senone状态的相似性对均值中心化超向量进行重排序；以重排序后的均值中心化超向量作为外部神经网络的输入,对外部神经网络进行训练,其中输入端为残差网络,从其输出端获取说话人的深度编码特征；对说话人的深度编码特征进行PLDA建模,得到PLDA模型；计算语音样本的深度编码特征在PLDA模型上的似然得分,判断说话人是否为同一个人。本发明能够更好地学习超向量内部的连续性信息和局部相关性信息,有利于提升说话人识别性能。</td>   <td>1.基于重排序超向量和残差网络的说话人识别方法,其特征在于,包括以下步骤：S1、对语音样本进行语音信号检测,提取及优化MFCC特征；S2、基于TDNN声学模型处理MFCC特征,从而得到均值中心化超向量；S3、根据senone状态的相似性对均值中心化超向量进行重排序；S4、以重排序后的均值中心化超向量作为外部神经网络的输入,对外部神经网络进行训练,其中外部神经网络的输入端为残差网络；从外部神经网络的输出端获取说话人信息的深度编码特征；S5、对说话人信息的深度编码特征进行PLDA建模,从而得到PLDA模型；S6、计算多个语音样本的深度编码特征在PLDA模型上的似然得分,并比较对应的似然得分是否相同,若相同,则判定对应的说话人为同一个人,否则不为同一个人；其中,所述步骤S2中,基于TDNN声学模型处理MFCC特征,从而得到均值中心化超向量,包括：S21、基于TDNN声学模型提取MFCC特征中每一帧在音素层单元上的后验概率,得到：                  其中,MFCC特征为{y-1,y-2,...,y-L},L为帧数,c-i是TDNN声学模型中的第i个senone状态,μ-i是对应第i个senone状态的均值向量,P(c-i|y-t)是第t帧特征y-t在音素层单元上的后验概率,N-i和F-i分别是MFCC特征在第t帧下的零阶和一阶的Baum-Welch统计量。S22、利用N-i对F-i的均值中心化向量进行权重估计,得到F-i的归一化均值中心化向量                  S23、将所有帧的拼接,得到均值中心化超向量</td>   <td>G10L17/04;G10L17/02;G10L17/18;G10L17/06;G10L25/24</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林浩添;              杨雅涵;              林桢哲;              陈文贲;              赵兰琴;              郭翀;              云东源;              李睿扬;                   东野枚枚       </td>   <td>中山大学中山眼科中心;中山大学</td>   <td>一种多功能的医学影像数据标注系统</td>   <td>广东省</td>   <td>CN113012134A</td>   <td>2021-06-22</td>   <td>本发明提供了一种多功能的医学影像数据标注系统,包括图像读取模块、数据标注模块和标注数据导出模块；所述图像读取模块用于对多种医学影像进行读取；所述数据标注模块用于对医学影像进行分类信息标注以及对感兴趣区域以及语义信息区域进行标注；所述标注数据导出模块用于将添加标注信息后形成的标注文件进行导出。本发明系统能够对读取的医学影像进行多功能的信息标注,包括影像分类标注和影像感兴趣区域标注等,从而有效提高了系统对医学影像数据的整理能力。</td>   <td>1.一种多功能的医学影像数据标注系统,其特征在于,包括图像读取模块、数据标注模块和标注数据导出模块；所述数据标注模块包括影像分类标签模块和影像感兴趣区域标注模块；所述图像读取模块,用于对医学影像进行读取；其中,所述医学影像包括MRI图像、CT图像、超声图像、RGB图像中的一种或多种；所述影像分类标签模块,用于对所述医学影像添加影像所属的属性类别信息；所述影像感兴趣区域标注模块,其用于对所述医学影像中的感兴趣区域进行圈定,并对该圈定区域添加区域所属的属性类别信息；所述标注数据导出模块,用于将添加标注信息后形成的标注文件进行导出。</td>   <td>G06T7/00;G06K9/32;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              李金膛;                   王国倩       </td>   <td>中山大学</td>   <td>一种面向大规模图结构的简化攻击方法</td>   <td>广东省</td>   <td>CN112990285A</td>   <td>2021-06-18</td>   <td>本发明提供一种面向大规模图结构的简化攻击方法,该方法首先使用简化的图卷积神经网络作为一个具有更好扩展性和灵活性的替代模型,该替代模型相较于以往研究使用的GCN具有更快的训练速度和推理速度以及更少的内存要求；然后选取目标攻击结点的一个k阶子图作为输入数据,输入该k阶子图得到的目标结点预测结果等效于输入整个图后得到的结果。最后,利用该替代模型在k阶子图上的推理结果,反向传播求出备选边集合的梯度,并根据梯度选取绝对值最大的一条边进行翻转,以此迭代地进行梯度攻击直至达到终止条件。该攻击模型能够显著地提升攻击算法的运行速度和降低内存使用,同时还具有较好的攻击表现,因而能够适用于大规模的图网络攻击。</td>   <td>1.一种面向大规模图结构的简化攻击方法,其特征在于,包括以下步骤：S1：构建简化的图卷积神经网络替代模型；S2：利用步骤S1中的替代模型提取目标结点的k阶子图；S3：利用步骤S2得到的子图进行快速梯度计算；S4：迭代利用梯度选取攻击边及更新子图。</td>   <td>G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗婷予;                   龙乐思       </td>   <td>中山大学</td>   <td>一种城市记忆资源分类标注方法及系统</td>   <td>广东省</td>   <td>CN112966704A</td>   <td>2021-06-15</td>   <td>本发明公开了一种城市记忆资源分类标注方法及系统,所述方法包括：根据资源分类原则定义分类标准和分类编码规范,获取并分析城市记忆资源特征,依据所述城市记忆资源特征定义元数据规范；依据所述分类标准和分类编码规范,对所述城市记忆资源进行规范化处理；依据所述元数据规范对所述城市记忆资源进行标注,形成城市记忆资源数据文档。所述方法结合城市记忆资源特征,提出一种城市记忆资源分类标准与元数据规范,实现资源的规范化描述,同时通过建立城市记忆资源分类标注系统,数字化存储资源,进而更高效地进行资源整合和研究。</td>   <td>1.一种城市记忆资源分类标注方法,其特征在于,所述方法包括：根据资源分类原则定义分类标准和分类编码规范,所述资源分类原则包括排他性和完整性；获取并分析城市记忆资源特征,依据所述城市记忆资源特征定义元数据规范,所述城市记忆资源特征包括外部特征、关联关系特征和内容特征；依据所述分类标准和分类编码规范,对所述城市记忆资源进行规范化处理；依据所述元数据规范对所述城市记忆资源进行标注,形成城市记忆资源数据文档。</td>   <td>G06K9/62;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈晓宏;              刘丙军;              涂新军;              刘德地;                   王高旭       </td>   <td>中山大学</td>   <td>南方湿润地区的水资源优化配置系统</td>   <td>广东省</td>   <td>CN105913146B</td>   <td>2021-06-11</td>   <td>本发明涉及一种南方湿润地区的水资源优化配置系统,包括：水资源智能分析子系统,用于导入和存储研究对象区域包括基础工程数据和水文数据的水资源数据,检查数据的合理性,对数据进行分析,根据分析结果,将数据进行规范化处理与智能整编,生成数据列表,同时计算研究对象子区域和节点的雨量和来水量；水资源优化配置子系统,用于根据水资源智能分析子系统生成的数据列表和研究对象子区域和节点的雨量和来水量数据对水资源进行配置,并对南方湿润地区水资源供需平衡进行计算。这种前后继承关系的双子系统实现了系统的有机结合,确保对水资源数据的精确高效计算,同时也确保了系统的高效运行及稳定性。</td>   <td>1.一种南方湿润地区的水资源优化配置系统,其特征在于,包括：水资源智能分析子系统,用于导入和存储研究对象区域包括基础工程数据和水文数据的水资源数据,检查数据的合理性,对数据进行分析,根据分析结果,将数据进行规范化处理与智能整编,生成数据列表,并计算研究对象子区域和节点的雨量和来水量；水资源优化配置子系统,用于根据水资源智能分析子系统生成的数据列表和研究对象子区域和节点的雨量和来水量数据对水资源进行配置,并对南方湿润地区水资源供需平衡进行计算；所述水资源智能分析子系统包括：数据库设置模块,用于为水资源优化配置子系统的运行提供数据库连接机制；数据处理模块,包括数据导入模块和数据完整性分析模块,用于为水资源优化配置子系统提供所需的基础工程数据和水文数据,并分析数据的完整性及合理性,生成数据列表；雨量计算模块,包括区间雨量计算模块和水库雨量计算模块,用于计算研究对象子区域和节点的雨量；来水量计算模块,包括区间来水计算模块和水库来水计算模块,用于计算研究对象子区域和节点的来水量；所述水资源优化配置子系统包括：配置属性设置模块,用于对配置计算的研究对象节点关系及配置参数进行设置,根据水资源智能分析子系统生成的数据列表中的数据同节点关系进行结合匹配；优化配置计算模块,用于对配置属性设置模块匹配的数据进行计算并保存,完成系统运行；所述水资源优化配置子系统的工作过程如下：(1)确定水资源合理分配的工作目标；(2)确定配水传输模型,流域水资源调配传输系统主要由水库流域水系输水河道组成,水量在河道传播过程中以区间径流的方式加入和取出,以节点控制水量平衡,将节点输水方案反馈至协调级进行配水协调；(3)平衡协调级,采用加大权重的方式对各子系统间的供水保证率或缺水率不均衡情况进行调整；(4)规划协调级,确定水资源的各项指标,选出水资源调配运行方案。</td>   <td>G06Q10/04;G06Q50/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘梦曦;                   石茜       </td>   <td>中山大学</td>   <td>一种基于超分辨率的多分辨率遥感影像的变化检测方法</td>   <td>广东省</td>   <td>CN112949549A</td>   <td>2021-06-11</td>   <td>本发明提出一种基于超分辨率的多分辨率遥感影像的变化检测方法,解决了如何更准确的对遥感影像进行变化检测的问题,构建基于高分辨率遥感影像的双时相变化检测数据集,进行多分辨率预处理,得到低分辨率影像,利用超分辨率模块学习恢复低分辨率影像中的语义信息特征,恢复得到更真实的具有语义信息的样本,可以减少不确定性映射带来的误差累积,有助于提高后续高分辨率变化检测的精度,设计基于多层次注意力机制模块的深度学习变化检测网络模型并训练,多层次注意力模块增强多层次特征的有效信息,获取更具有可区分性的特征对,帮助深度学习变化检测网络模型学习到更准确的变化检测图,实现对多分辨率遥感影像土地覆盖的变化检测。</td>   <td>1.一种基于超分辨率的多分辨率遥感影像的变化检测方法,用于土地覆盖变化的检测识别,其特征在于,至少包括：S1.构建基于高分辨率遥感影像的双时相变化检测数据集；S2.将单一分辨率的双时相变化检测数据集进行多分辨率预处理,得到低分辨率影像；S3.利用超分辨率模块学习恢复低分辨率影像中的语义信息特征,将低分辨率影像的尺寸扩大,输出超分辨率影像,与原双时相变化检测数据集共同组成输入数据集；S4.设计基于多层次注意力机制模块的深度学习变化检测网络模型；S5.将输入数据集输入深度学习变化检测网络模型,对深度学习变化检测网络模型进行训练；S6.将待检测变化区域的多分辨率的双时相遥感影像输入至训练好的深度学习变化检测网络模型,得到变化检测结果。</td>   <td>G06K9/00;G06K9/32;G06K9/46;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              吴迪邦;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种基于深度学习的大肠空腔区及肠内容物标注方法</td>   <td>广东省</td>   <td>CN112950599A</td>   <td>2021-06-11</td>   <td>本发明公开了一种基于深度学习的大肠空腔区及肠内容物标注方法,该方法包括：获取CT腹腔图像并对图像中的相关区域进行区域合并,得到区域合并后图像；将区域合并后图像进行图像拆分,得到拆分后图像；基于预训练的分割网络对拆分后图像进行分割,得到大肠区域图；根据大肠区域图对大肠区域进行标注,得到标注图；将标注图与输入的CT腹腔图像进行图像拼接,得到带标注的CT腹腔图像。本发明方法能够自动对输入的CT腹腔图像的大肠空腔区及肠内容物区域进行标注。本发明作为一种基于深度学习的大肠空腔区及肠内容物标注方法,可广泛应用于图像处理领域。</td>   <td>1.一种基于深度学习的大肠空腔区及肠内容物标注方法,其特征在于,包括以下步骤：获取CT腹腔图像并对图像中的相关区域进行区域合并,得到区域合并后图像；将区域合并后图像进行图像拆分,得到拆分后图像；基于预训练的分割网络对拆分后图像进行分割,得到大肠区域图；根据大肠区域图和输入的CT腹腔图,分别对大肠空腔区及肠内容物进行标注,得到标注图；将标注图与输入的CT腹腔图像进行图像拼接,得到带标注的CT腹腔图像。</td>   <td>G06T7/00;G06T7/11;G06T7/187;G06T3/40;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         熊会元;              钱沛聪;              马健;              潘跃龙;              刘羽;              李同同;                   尹文成       </td>   <td>中山大学;中广核工程有限公司</td>   <td>特种场景的多传感器动态加权融合的点云地图构建方法</td>   <td>广东省</td>   <td>CN112950781A</td>   <td>2021-06-11</td>   <td>本发明提出了一种对最大后验概率目标函数中各传感器约束项进行动态加权以提高轨迹精度的方法,用于构建包含室外环境、室内环境和信号屏蔽区域的特种场景点云地图。在GNSS覆盖下,以载体位置与卫星定位的欧氏距离最小化为目标构造卫星定位约束,并根据激光里程计与GNSS精度因子调整其权重来减小卫星定位误差对点云地图的影响；在GNSS盲区下,以载体姿态与惯性测量数据构成的预期重力方向与实际重力方向的夹角最小化为目标构造姿态约束,并根据载体加速度大小调整其权重,解决由于缺乏全局位置观测导致点云地图高程累积误差大的问题。以激光里程计为基础,使用位姿图优化方法整合所述约束并求解载体位姿,拼接关键帧点云以准确生成所述特种场景点云地图。</td>   <td>1.一种特种场景的多传感器动态加权融合的点云地图构建方法,其特征在于,其通过设有激光雷达、卫星定位设备以及惯性测量单元的载体在预定的室内外环境中进行数据采集和激光扫描,根据激光扫描得到的点云构建所述载体移动轨迹范围内的点云地图；包括以下步骤：S1,所述载体从室外启动,将起点处的载体位姿以固定顶点的方式加入位姿图中,并以起点为坐标原点,以“东向-北向-天向”为基准方向,构建笛卡尔直角坐标系作为全局坐标系,后续卫星定位数据均转换到所述全局坐标系下；S2,在所述载体运动距离大于设定阈值时,将激光雷达的扫描结果记为关键帧,将该关键帧对应的载体位姿作为待求解顶点加入位姿图；根据激光雷达的帧间扫描配准结果来构造激光里程约束,并根据点云配准重合度来调整所述激光里程约束的动态权重；当载体位于室外环境时,根据卫星定位结果与所述载体位置的欧氏距离来构造卫星定位约束,并根据水平精度因子与激光里程信息来调整所述卫星定位约束的动态权重；当所述载体位于室内环境时,根据惯性测量单元的数据并结合载体姿态计算预期重力方向与实际重力方向的夹角来构造姿态约束,并根据所述载体处于静止或匀速状态的置信度来调整所述姿态约束的动态权重；当所述载体从室内返回室外环境时,利用卫星定位结果对历史关键帧进行检索得到闭环候选关键帧,利用当前关键帧与以闭环候选关键帧为中心的局部子地图进行点云配准,根据配准结果来构造激光闭环约束,并根据点云配准重合度来调整所述激光闭环约束的动态权重；S3,根据包括所述激光里程约束、卫星定位约束、姿态约束、激光闭环约束在内的约束项以及各约束项对应的动态权重,对各项约束相关的变量顶点进行连接,构建位姿图,对位姿图中的所有约束项进行求和得到关于载体轨迹的最大后验概率目标函数,使用非线性优化方法进行求解即对所述位姿图进行求解；S4,根据所述位姿图的求解结果对所述历史关键帧点云进行拼接,生成点云地图。</td>   <td>G06T17/05;G06T17/20;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              孙黎波;              黎丹;                   黄凯       </td>   <td>中山大学</td>   <td>基于色彩图像和红外图像融合的即时定位与建图系统</td>   <td>广东省</td>   <td>CN107204015B</td>   <td>2021-06-08</td>   <td>本发明公开了一种基于色彩图像和红外图像融合的即时定位与建图算法,该算法可以适用于在光照充足环境以及低光照环境下的即时定位与建图。在具体实现过程中该算法主要通过提取色彩图像和红外图像中的特征点来创建同时包含色彩图像地图点和红外图像地图点的地图,并且在达到新的位置时通过获取到的新的信息来不断地更新已经创建好的地图,同时利用现有的地图定位出当前的位置。该算法由于同时使用了色彩图像和红外图像,因此综合考虑了周围环境的色彩信息和红外信息,从而使得该算法与传统的基于色彩图像的算法相比具有更高的光照鲁棒性、更好的适用范围,能够适用于使用色彩图像定位失败的低光照环境。</td>   <td>1.基于色彩图像和红外图像融合的即时定位与建图系统,其特征在于,包括定位模块、建图模块、优化模块三大部分,定位模块基于已经被创建出来的包含红外特征地图点和色彩特征地图点的地图来进行,并且通过获取的色彩图像和红外图像来不断更新已经被创建的地图用于后续定位；建图模块创建同时包含色彩图像特征和红外图像特征的地图点,并在定位完成时根据新的数据源不断的更新现有地图,以及对地图点中错误的坏点进行剔除；回环优化模块通过回环探测的方式对创建好的全局地图进行优化,在进行回环探测时同时使用色彩图像和红外图像进行回环探测；色彩信息和红外信息的融合被放在图像的前端进行,即在色彩图像和红外图像之间寻找图像像素之间的相关性,并且通过图像像素之间的相关性完成信息融合后再执行之后的定位、建图、优化；初始化模块,用于实现对系统的初始化,即构建已知的初始化地图,所述的初始化模块中,基于缓冲区的初始化方法,该方法不是仅使用一个先前帧作为参考帧,而是在现有图像的缓存队列中查找并尝试初始化或更新缓存,直到初始化成功。</td>   <td>G06T7/73;G06T11/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         毛莉;                   李中华       </td>   <td>佛山市顺德区中山大学研究院;广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>WSN充电服务站点设定方法及充电设备行驶路径规划方法</td>   <td>广东省</td>   <td>CN110059848B</td>   <td>2021-06-08</td>   <td>本发明公开了一种WSN充电服务站点设定方法及充电设备行驶路径规划方法,通过若干个大小相等的图形将WSN划分成若干个区域,将每个传感器节点分别对应到所属的区域中,并在每个区域中根据传感器节点的位置选取锚节点,利用锚节点作为充电服务站点的设定基准,可以简单、合理地确定充电服务站点的最优位置；而通过人工免疫模型,筛选出移动无线充电设备完成能量补充任务所需总耗能最小的行驶路径,有效地节约了能量资源；另一方面,由于人工免疫模型的多样性和快速的收敛速度,有利于提高行驶路径的优化准确性以及获取效率。</td>   <td>1.一种移动无线充电设备行驶路径规划方法,其特征在于,包括：将传感器节点、锚节点和WSN充电服务站点的位置输入到人工免疫模型,筛选出移动无线充电设备完成能量补充任务所需总耗能最小的行驶路径；所述WSN充电服务站点的设定方法包括：步骤S100：利用若干个大小相等的图形将WSN划分成若干个区域；步骤S200：将每个传感器节点分别对应到所属的区域中；步骤S300：在每个区域中根据传感器节点的位置选取锚节点,包括：若某个区域中不存在传感器节点,则不在该区域内选取锚节点；若某个区域中仅存在一个传感器节点,则锚节点的位置即为该传感器节点的位置；若某个区域中存在两个传感器节点,则锚节点的位置为两个传感器节点的位置的中心点；若某个区域内的传感器节点数量大于两个,则锚节点的位置为该区域的中心点；对每个锚节点进行编号；步骤S400：将WSN充电服务站点设定在与各个锚节点的距离之和最小的位置；所述筛选出移动无线充电设备完成能量补充任务所需总耗能最小的行驶路径,包括：步骤S500：以移动无线充电设备遍历锚节点的路径作为抗体,构建抗体种群,具体为：根据锚节点的数量生成一组随机序列,作为一个抗体；生成若干个抗体,将抗体和抗体数量利用矩阵形式表示；步骤S600：根据移动无线充电设备的剩余能量对抗体种群中的抗体进行检验；步骤S700：利用适应度函数获取抗体的适应度,所述适应度为移动无线充电设备总消耗能量,所述适应度函数为：fit＝E-(tra)+E-(ch)                                                                                          e-(sn,j)＝E-(sn)-p-j×t其中,fit为总耗能,E-(tra)为移动无线充电设备的行驶耗能,E-(ch)为移动无线充电设备为WSN中所有传感器节点充电所消耗的能量；P-(tra)为移动无线充电设备的行驶功率,V为移动无线充电设备的行驶速度,Len为移动无线充电设备完成充电任务所行驶的路程；D-l为一个充电回路移动无线充电设备的行驶路程；d-(i,i+1)为锚节点i到锚节点i+1的距离,d-(m,0)为锚节点m到WSN充电服务站点的距离；ech-i为第i个锚节点所在区域内,移动无线充电设备对该区域内传感器节点充电所消耗的能量；E-(sn)为传感器节点的初始能量,e-(sn,j)为该区域内第j个传感器节点的剩余能量；P-j为传感器节点的能耗功率,t为移动无线充电设备到达该传感器节点所在区域的时刻；步骤S800：对抗体种群进行克隆操作；步骤S900：通过变异算子对克隆后的抗体种群进行变异操作；步骤S1000：在变异后的抗体种群中筛选出适应度较小的抗体；若未达到迭代终止条件,则更新抗体种群,迭代执行以上步骤S600到步骤S1000,若达到迭代终止条件,则输出该适应度较小的抗体。</td>   <td>G06Q10/04;G06Q50/06;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈龙;              谢玉婷;                   张亚琛       </td>   <td>中山大学</td>   <td>面向动态环境的语义分割与视觉SLAM紧耦合方法</td>   <td>广东省</td>   <td>CN110827305B</td>   <td>2021-06-08</td>   <td>本发明属于机器人、计算机视觉、人工智能技术领域,更具体地,涉及一种面向动态环境的语义分割与视觉SLAM紧耦合方法。包括：S1.经过语义分割模块输出图像的像素级语义分割结果和深度恢复结果；然后原图像和每个像素点的语义标签以及对应深度图传递给视觉SLAM模块；S2.视觉SLAM模块利用这些信息获知新图像与序列中历史图像的数据关联状况,并将这个信息反馈回语义分割模块；S3.语义分割模块利用历史图像的分割结果及历史图像与新图像帧之间的数据关联状况,优化新图像帧的语义分割结果；S4.优化后的语义分割结果再一次传送回视觉SLAM模块,得到最终精细化的三维重建结果。本发明有效提升了语义分割的效果,从而进一步提高依赖于语义分割结果的SLAM性能。</td>   <td>1.一种面向动态环境的语义分割与视觉SLAM紧耦合方法,其特征在于,包括以下步骤：S1.由单目相机捕捉的原图像,经过语义分割模块输出图像的像素级语义分割结果和深度恢复结果；然后原图像和每个像素点的语义标签以及对应深度图传递给视觉SLAM模块；S2.视觉SLAM模块利用步骤S1中的信息获知新图像与序列中历史图像的数据关联状况,并将得到的关联状况信息反馈回语义分割模块；S3.语义分割模块利用历史图像的分割结果及历史图像与新图像帧之间的数据关联状况,优化新图像帧的语义分割结果；S4.优化后的语义分割结果再一次传送回视觉SLAM模块,利用步骤S3中优化后的语义分割结果,作为最终的像素点语义标签,配合SLAM模块解算出的位姿结果,及深度恢复结果,生成输出带语义标签的三维重建点云。</td>   <td>G06T7/12;G06T17/05;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         余超;                   谭晋       </td>   <td>中山大学</td>   <td>基于强化学习的非完全信息博弈方法、系统以及电子设备</td>   <td>广东省</td>   <td>CN112926744A</td>   <td>2021-06-08</td>   <td>本发明提供一种基于强化学习的非完全信息博弈方法、系统以及电子设备,获取博弈场景及所述博弈场景所对应的至少两个智能体,并用多维向量表示所述智能体的各个博弈状态和博弈行为；获取博弈过程中各智能体的博弈数据；根据所述博弈数据,计算终局收益值；根据所述终局收益值,计算博弈过程中各博弈行为的反事实后悔值；根据所述不确定性指标调整所述反事实后悔值,得到训练数据；根据所述训练数据对所述至少两个智能体的神经网络进行训练,并输出策略模型。与现有技术相比,本发明度量了非完全信息环境带来的不确定性,从而消除了一部分来自非完全信息带来的影响,使得该博弈算法能在非完全信息环境下表现比传统算法更好。</td>   <td>1.一种基于强化学习的非完全信息博弈方法,其特征在于,包括步骤：获取博弈场景及所述博弈场景所对应的至少两个智能体,并用多维向量表示所述智能体的各个博弈状态和博弈行为；获取博弈过程中各智能体的博弈数据；所述博弈数据包括各个博弈行为的行为概率、以及各个博弈状态所对应的不确定性指标；根据所述博弈数据,计算终局收益值；根据所述终局收益值,计算博弈过程中各博弈行为的反事实后悔值；根据所述不确定性指标调整所述反事实后悔值,得到训练数据；根据所述训练数据对所述至少两个智能体的神经网络进行训练,并输出策略模型。</td>   <td>G06N20/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢宇彤;              蔡婷婷;              郑馥丹;              王莹;              邓楚富;                   陈志广       </td>   <td>中山大学</td>   <td>用于行人重识别的掩膜池化模型训练和行人重识别方法</td>   <td>广东省</td>   <td>CN109977798B</td>   <td>2021-06-04</td>   <td>本发明涉及一种用于行人重识别的掩膜池化模型训练和行人重识别方法,包括S1.获取锚图像a、正样本图像p、负样本图像n；S2.将a、p、n以及a、p、n对应的掩膜分别输入掩膜池化模型中,得到对应的三维张量T-a、T-p、T-n；S3.对T-a、T-p、T-n分别进行池化操作、卷积操作,得到对应的H-a、H-p、H-n；S4.将H-a、H-p、H-n分别输入分类器,得到对应的预测结果R-a、R-p、R-n；S5.根据预测结果R-a、R-p、R-n计算损失值；S6.根据损失值训练掩膜池化模型。本发明可以增强图像中的非背景信息,学习到图像最关键的特征。</td>   <td>1.一种用于行人重识别的掩膜池化模型训练方法,其特征在于,包括：S1.获取锚图像a、正样本图像p、负样本图像n；S2.将a、p、n以及a、p、n对应的掩膜分别输入掩膜池化模型中,得到对应的张量T-a、T-p、T-n；S3.对T-a、T-p、T-n分别进行池化操作、卷积操作,得到对应的张量H-a、H-p、H-n；S4.将H-a、H-p、H-n分别输入分类器,得到对应的预测结果R-a、R-p、R-n；S5.根据预测结果R-a、R-p、R-n计算损失值；S6.根据损失值训练掩膜池化模型；所述掩膜池化模型采用ResNet网络模型,所述掩膜池化模型具体包括：conv1卷积层、conv2-x卷积层、conv3-x卷积层、conv4-x卷积层、conv5-x卷积层；步骤S2具体包括：将锚图像a、正样本图像p、负样本图像n以及a、p、n对应的掩膜分别依次输入conv1卷积层、conv2-x卷积层、conv3-x卷积层、conv4-x卷积层、conv5-x卷积层,得到对应的张量T-a、T-p、T-n；a、p、n分别输入conv1卷积层时,进行7×7卷积操作,所述7×7卷积操作采用7×7卷积核、63个通道数、步幅为2,得到前63个conv1结果；a、p、n对应的掩膜输入conv1卷积层时,根据池化区域中的非背景像素比例进行7×7池化操作,所述池化操作采用7×7池化核、步幅为2,得到第64个conv1结果；前63个conv1结果输入conv2-x卷积层时,进行3×3卷积操作,所述3×3卷积操作采用3×3卷积核、步幅为2；第64个conv1结果输入conv2-x卷积层时,根据池化区域中的非背景像素比例进行3×3池化操作,所述3×3池化操作采用3×3池化核、步幅为2。</td>   <td>G06K9/00;G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈创荣;              成慧;                   范正平       </td>   <td>中山大学</td>   <td>一种基于3D卷积神经网络的双目视差计算方法</td>   <td>广东省</td>   <td>CN110060290B</td>   <td>2021-06-04</td>   <td>本发明涉及一种基于3D卷积神经网络的双目视差计算方法。包括：S1.根据定义的多尺度特征提取方法对输入的左右视图分别进行特征提取；S2.堆叠左右图相应视差对应位置的特征得到4D的cost volume；S3.使用3D CNN子网络进行代价聚合,得到视差值的对数似然估计,并且上采样到原图分辨率,得到每个像素的可能视差值的对数似然估计,进行对数归一化操作得到新的对数似然估计；S4.计算设置的真实分布；S5.进行反向传播训练；S6.得到每个像素的视差对数似然分布后,转换成概率得到视差概率分布；S7.找到对应最大概率的视差值,S8.由前述左右视差值和视差概率分布,得到归一化概率分布；S9.通过加权平均操作得到每个像素视差的最终估计值。本发明可以有效提高视差计算的精度。</td>   <td>1.一种基于3D卷积神经网络的双目视差计算方法,其特征在于,包括以下步骤：S1.构建一种用于多尺度特征提取网络结构,根据该结构定义一种多尺度特征提取方法；用于多尺度特征提取网络方法为：对输入的图像,每次经过一个CNN子网络,得到一个尺度的特征,设置每个CNN子网络的步长为2,总共有4个CNN子网络,总共可提取得到1/2,1/4,1/8,1/16共4个尺度下的子特征,将特征堆叠后输入另外一个CNN子网络得到对每个尺度特征的权重,最后利用该权重对前面4个尺度的特征进行加权操作,得到最终的多尺度特征；S2.根据S1步骤提供的特征提取网络方法,对输入的左右两幅图像分别进行特征提取,得到的特征设为F-1、F-2；S3.根据提取得到的左右图特征F-1和F-2,堆叠左右图相应视差对应位置的特征得到4D的costvolume；S4.基于构建的4Dcostvolume,使用3DCNN子网络进行代价聚合,得到视差值的对数似然估计,并且上采样到原图分辨率,得到每个像素的可能视差值的对数似然估计,进行对数归一化操作得到新的对数似然估计,定义为L；S5.根据训练数据的视差真实值,计算设置的真实分布；将真实分布设为高斯分布,设视差真实值为：gt,真实分布为：Di,则：                  其中,N为视差枚举值,0&lt;i&lt;N,v为预设值；S6.根据对数似然估计和真实分布,计算交叉熵,得到loss,利用该loss进行反向传播训练；S7.局部推断：得到每个像素的视差对数似然分布后,转换成概率得到视差概率分布P-i；S8.基于得到的视差概率分布P-i,找到对应最大概率的视差值,设为d-(max)；S9.由左右视差值和视差概率分布,得到归一化概率分布S10.通过加权平均操作得到每个像素视差的最终估计值</td>   <td>G06T7/55;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王金桥;              招继恩;              马援;              唐明;              张海;              段绪海;                   谭大伦       </td>   <td>杰创智能科技股份有限公司;中山大学</td>   <td>一种高精度锚点匹配策略的人脸检测方法</td>   <td>广东省</td>   <td>CN110197113B</td>   <td>2021-06-04</td>   <td>本发明涉及一种高精度锚点匹配策略的人脸检测方法,包括构建人脸识别系统,设定识别模型,图像识别及构建识别数据库及人脸识别等四个步骤。本发明有效的提高了人脸识别作业的工作效率和精度,并极大的提高了人脸识别作业使用灵活性和通用性,有效满足不同使用场合的需要,并具有良好的数据处理能力、数据通讯能力及数据管理能力,极大的提高了人脸识别作业的可靠性。</td>   <td>1.一种高精度锚点匹配策略的人脸检测方法,其特征在于：所述的高精度锚点匹配策略的人脸检测方法包括以下步骤：S1,构建人脸识别系统,根据人脸识别作业需要,首先构建包括CCD摄像机、承载座、转台机构、数据采集控制电路、通讯网络及基于云计算基础的人脸识别服务器,其中CCD摄像机至少一个,均安装在承载座上,且CCD摄像机通过转台机构与承载座连接,然后将承载座固定到指定工作位置上,此外另将数据采集控制电路安装在承载座内,并分别与CCD摄像机、转台机构及通讯网络相互连接,所述通讯网络与云计算基础的识别服务器间建立数据连接,从而构成人脸识别系统；S2,设定识别模型,完成S1步骤后,在基于云计算基础的识别服务器录入基于锚点计算为基础的人脸识别计算算法和基于“四邻域连通”图像预处理策略；S3,图像识别及构建识别数据库,完成S2步骤后,首先由基于云计算基础的识别服务器通过通讯网络一方面从第三方平台中下载先用人脸识别数据,并保存在基于云计算基础的识别服务器中,另一方面由CCD摄像机直接对目标人群进行面部图像信息采集,并保存至基于云计算基础的识别服务器中,共同构成人脸识别训练数据库,然后由基于云计算基础的识别服务器基于S2步骤中的“四邻域连通”图像预处理策略,对人脸识别训练数据库中的面部图像信息进行滤波、图像差分、二值化处理,并在二值化后,对基础视频图像进行连通域分析,在连通域上按照“四邻域连通”对基础视频图像中的人体进行分离并标记,并统计各区域面积,最后由基于云计算基础的识别服务器基于S2步骤中的基于锚点计算为基础的人脸识别计算算法,分别为各人脸识别训练数据库中的面部图像划分的连通域范围内进行锚点计算和定位,并对划分面域中分布的锚点数量和位置进行统计,从而完成识别数据库建设；S4,人脸识别,在完成S3步骤后,即可进行人脸识别作业,在人脸识别作业时,首先由S1步骤中CCD摄像机对待识别人员面部采集至少3张图像信息,然后将采集的图像信息通过通讯网络发送至云计算基础的识别服务器在内的人脸识别服务器中,由云计算基础的识别服务器在内的人脸识别服务器按照S3步骤,对新采集的图像信息分别进行图像识别,然后对识别后的图像信息首先根据S2步骤中的“四邻域连通”图像预处理策略进行划分,然后根据S2步骤中的基于锚点计算为基础的人脸识别计算算法对各划分区域内进行锚点锚点数量和位置进行统计,完成图像识别,最后将完成图像识别后的图像连通域划分信息及锚点数量和分布信息与S3步骤中识别数据库中存储数据进行比对,并在新识别图像信息于识别数据库建中相关图像新型存储信息相似度达到80％以上时,完成人脸识别,低于80％时则再次识别,并在连续识别3—5次后相似度均低于80％时,则向及基于云计算基础的人脸识别服务器发送信息拓展请求,并在信息拓展请求审批通过后再返回S3步骤进行图像信息识别并保存至识别数据库中。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘梦曦;                   石茜       </td>   <td>中山大学</td>   <td>一种基于多层次监督和深度度量学习的遥感变化检测方法</td>   <td>广东省</td>   <td>CN112906638A</td>   <td>2021-06-04</td>   <td>本发明公开了一种基于多层次监督和深度度量学习的遥感变化检测方法,包括：S1：获取若干幅可用于双时相变化检测的高分辨率遥感影像；S2：基于当前已有的数据资料和人工先验知识,通过目视解译,勾绘高分辨率遥感影像之间的变化区域,获得高分辨率遥感影像之间像素级的变化标记,基于已有的遥感影像对和变化标记,将其裁剪为若干特定尺寸大小的影像对,得到面向双时相变化检测的高分辨率遥感影像数据集；S3：构建基于多层次监督和深度度量学习的遥感变化检测模型；S4：对步骤S3构建的模型进行训练；S5：将待检测区域的双时相遥感影像输入至训练好的模型中,得到待检测区域的变化栅格图。本发明提高了检测效率和检测精度。</td>   <td>1.一种基于多层次监督和深度度量学习的遥感变化检测方法,其特征在于,包括以下步骤：S1：获取若干幅可用于双时相变化检测的高分辨率遥感影像；S2：基于当前已有的数据资料和人工先验知识,通过目视解译,勾绘高分辨率遥感影像之间的变化区域,获得高分辨率遥感影像之间像素级的变化标记,基于已有的遥感影像对和变化标记,将高分辨率遥感影像裁剪为若干特定尺寸大小的影像对,得到面向双时相变化检测的高分辨率遥感影像数据集；S3：构建基于多层次监督和深度度量学习的遥感变化检测模型；S4：利用面向双时相变化检测的高分辨率遥感影像数据集对步骤S3构建的模型进行训练；S5：将待检测区域的双时相遥感影像输入至训练好的模型中,得到待检测区域的变化栅格图。</td>   <td>G06K9/00;G06K9/46;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李晓岚;              洪筠;              李月;              潘彦睿;              邓欣怡;              曾振宇;                   罗敏       </td>   <td>中山大学附属口腔医院;广州格领医疗科技有限公司</td>   <td>一种口腔医生操作术者体位监测系统</td>   <td>广东省</td>   <td>CN112906670A</td>   <td>2021-06-04</td>   <td>本发明提供了一种口腔医生操作术者体位监测系统,属于医疗系统技术领域,包括计算机、与所述计算机通讯连接的口腔灯、前置式双目3D相机、数据分析单元和显示器；所述数据分析单元包括：系统连接模块；坐姿示教模块；关节识别模块；坐姿提示模块；数据记录模块；坐姿报告模块；系统设置模块；用户管理模块；本发明中的设计,可以应用于教学及考核中；能够实时监测口腔医学生在实操过程中的坐姿是否正确；在结业考、各类比赛及执医实操考核中,辅助或代替评委评价考生的坐姿是否正确；将大大提高评判的客观性,考生全程的坐姿情况都将被记录,并根据事先定好的规则进行打分,如发生申诉,也可查看后台数据进行公正处理,较为方便。</td>   <td>1.一种口腔医生操作术者体位监测系统,其特征在于,包括计算机、与所述计算机通讯连接的口腔灯、前置式双目3D相机、数据分析单元和显示器；所述前置式双目3D相机集成于所述口腔灯上；所述数据分析单元包括：系统连接模块,用于系统开机自动检测和连接前置式双目3D相机,并给出提示,后台记录连接状态；坐姿示教模块,用于通过显示器展示如何调整坐姿及标准坐姿示意图；关节识别模块,用于识别操作者肘部、颈部的弯曲程度以及上身前倾/后仰程度,与标准姿势进行对比；识别操作者的手部姿势,判断支点位置；坐姿提示模块,用于实时展现当前坐姿、手势的情况,并借助语音、图片给用户发出警示；数据记录模块,用于记录用户全过程的坐姿、手势的情况,并标示出错误的地方,方便后续对比查看；坐姿报告模块,用于根据评分规则,给出得分,并展示用户信息、失分点、改善建议；系统设置模块,用于设置评分规则、提示方式、评判基准点；用户管理模块,用于单个/批量导入、导出用户信息、操作数据、成绩单。可批量打印成绩单,操作数据的统计分析。</td>   <td>G06K9/00;A61B5/11;G06Q50/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘星成;              沈子雄;                   刘异橦       </td>   <td>中山大学</td>   <td>基于样本边界值及集成多样性的数据分类方法</td>   <td>广东省</td>   <td>CN112906779A</td>   <td>2021-06-04</td>   <td>本发明提供一种基于样本边界值及集成多样性的数据分类方法,包括如下：将初始数据集划分为训练集、验证集、测试集；对训练集行处理,得到采样集；对每个采样集采用基分类器进行训练,得到集成系统；利用集成系统对验证集进行分类,得到验证集的分类预测结果矩阵；根据分类预测结果矩阵进行统计得到投票数向量、验证集样本个数,计算出基分类器池中的每个分类器的平均边界值；计算关于数据集标签类别的概率分布,并引入J-S散度,计算得到某个基分类器与其它基分类器之间的平均差异程度；结合平均边界值、平均差异程度进行综合度量,得到新的集成系统,通过选取得到分类器子集合；利用分类器子集合对测试集进行分类预测,获取分类结果。</td>   <td>1.一种基于样本边界值及集成多样性的数据分类方法,其特征在于：所述的方法步骤包括如下：S1：将初始数据集划分为训练集D-(tr)、验证集D-(va)、测试集D-(te)；并采用bootstrap对训练集D-(tr)进行处理,得到采样集D-(tr-t),1≤t≤T；S2：对每个采样集D-(tr-t)采用基分类器进行训练,得到集成系统ES；利用集成系统ES的每个基分类器对验证集进行分类,得到验证集的分类预测结果矩阵；S3：根据分类预测结果矩阵进行统计得到投票数向量、验证集样本个数N-R,通过无监督形式的样本边界值度量标准算法计算出基分类器池中的每个分类器h-t的平均边界值；S4：计算关于数据集标签类别的概率分布,并引入J-S散度,进而计算得到某个基分类器与其它基分类器之间的平均差异程度；S5：结合平均边界值、平均差异程度进行综合度量,得到新的集成系统ES′,通过选取得到选择性集成后的分类器子集合ES-(new)；S6：利用分类器子集合ES-(new)对测试集进行分类预测,获取最终的分类结果。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         许曼玲;                   戴宪华       </td>   <td>中山大学</td>   <td>一种基于条件生成对抗网络的声音预测人脸方法</td>   <td>广东省</td>   <td>CN112906815A</td>   <td>2021-06-04</td>   <td>本发明提出了一种基于条件生成对抗网络的声音预测人脸方法,该方法包括：数据构建步骤,采集声音数据及人脸数据并进行数据清洗,分别根据年龄及性别标注生成one-hot标签；设计及训练声音分类模型步骤,从声音数据中提取梅尔频谱特征,并将特征及标签数据输入深度学习分类网络进行训练,进而得到分类网络模型权重；设计及训练人脸生成网络步骤,将标签及人脸数据输入预训练的条件生成对抗网络进行训练,得到人脸生成网络模型权重；模型预测步骤,将预处理后的声音数据输入声音分类器获得分类标签,再将分类标签输入人脸生成器,可获得预测人脸。本发明涉及深度学习技术应用领域,实现了根据输入声音预测说话者人脸图像的功能,弥补了该领域的空白。</td>   <td>1.一种基于条件生成对抗网络的声音预测人脸方法,其特征在于,所述预测方法包括下列步骤：S1、数据构建,采集声音数据,进行数据清洗并根据说话者年龄及性别标注制作one-hot标签编码,其中,标签共包括4类年龄属性和2类性别属性；采集人脸图像数据,进行数据清洗并根据人脸的年龄及性别标注制作one-hot标签编码,保持声音标签数据与人脸标签数据制作规则的一致性；S2、设计及训练声音分类网络模型,该网络模型分为三个子网络,分别为提取声音大尺度特征的梅尔频谱转化网络、对声音特征进行特征识别的预训练resnet50网络、根据识别出的特征对声音数据进行分类的全连接网络；以经过数据处理的声音数据作为输入,优化该网络的分类输出与声音标签编码之间的相似度,实现声音分类网络模型的收敛；S3、设计及训练人脸生成网络,该网络由预训练的CGAN网络构成,以随机种子及人脸标签数据为输入,使得CGAN网络的生成器与鉴别器在博弈中达到平衡,实现人脸生成网络的收敛；S4、模型预测,将声音数据经过预处理后输入声音分类网络,获得对应的标签编码；将标签编码输入人脸生成网络,获得预测的说话者人脸图像输出。</td>   <td>G06K9/62;G06N20/00;G10L25/30;G10L25/48</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              曹阳;                   冯展祥       </td>   <td>中山大学</td>   <td>一种基于轻量化网络的工业产品表面缺陷检测方法</td>   <td>广东省</td>   <td>CN112907523A</td>   <td>2021-06-04</td>   <td>本发明公开了一种基于轻量化网络的工业产品表面缺陷检测方法,所述方法包括以下步骤：确定深度学习网络模型的结构；将训练样本输入网络模型进行训练,其中,在使用网络对样本进行检测之前,需要对网络的参数进行训练,使每一个参数达到合适的数值；保存训练获得的参数文件；将参数赋值给网络并对测试样本进行检测；根据检测结果对样本图像中的缺陷进行标注。故因此,本发明的有益效果在于使用更少的参数的同时,达到了更高的检测准确率。</td>   <td>1.一种基于轻量化网络的工业产品表面缺陷检测方法,其特征在于,所述方法包括以下步骤：S1确定深度学习网络模型的结构；S2将训练样本输入网络模型进行训练,其中,在使用网络对样本进行检测之前,需要对网络的参数进行训练,使每一个参数达到合适的数值；S3保存训练获得的参数文件；S4将参数赋值给网络并对测试样本进行检测；S5根据检测结果对样本图像中的缺陷进行标注。</td>   <td>G06T7/00;G06K9/46;G06K9/62;G06N3/04;G06N3/08;G06K9/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;                   俞建聪       </td>   <td>中山大学</td>   <td>基于ACBlock的深度卷积神经网络信息取证方法</td>   <td>广东省</td>   <td>CN112883890A</td>   <td>2021-06-01</td>   <td>本发明提出一种基于ACBlock的深度卷积神经网络信息取证方法,解决了现有取证检测方法在面对较差质量的视频片段时,提取到的特征较少、检测准确率不高的问题,将非对称卷积结构ACBlock引入到深度卷积神经网络之中,利用原始视频集和篡改视频集的人脸内容训练网络,由待测视频进行人脸提取得到的结果作为待测样本,将待测样本通过训练好的卷积神经网络进行分类,即可判断此帧图像是否经过了篡改,ACBlock以多个非对称卷积核组合的形式来替代原本的对称卷积核,能够加强卷积对于中心位置的特征提取,克服现有技术在视频质量较差时,因提取特征的能力较差而表现出的检测准确率不高的缺陷,从而提高检测取证的准确率。</td>   <td>1.一种基于ACBlock的深度卷积神经网络信息取证方法,用于确认视频片段中的人脸信息是否经过篡改,其特征在于,至少包括：S1.构造原始视频集和篡改视频集；S2.分别提取原始视频集和篡改视频中的人脸内容,得到原始人脸视频集和篡改人脸视频集；S3.分别从原始人脸视频集和篡改人脸视频集中随机筛选出原始视频人脸信息样本和篡改视频人脸信息样本；S4.构建基于ACBlock的深度卷积神经网络模型,利用原始视频人脸信息样本和篡改视频人脸信息样本对基于ACBlock的深度卷积神经网络模型进行预训练；S5.保留预训练后基于ACBlock的深度卷积神经网络模型的权重参数,截取掉深度卷积神经网络模型末端的全连接层,替换为Capsule胶囊网络结构,利用原始视频人脸信息样本和篡改视频人脸信息样本再次训练深度卷积神经网络模型；S6.选取待取证视频,将待取证视频进行分帧,提取人脸内容,作为待测视频人脸样本；S7.利用训练好的深度卷积神经网络模型对待测视频帧样本进行分类,确认视频中的人脸信息是否进行了篡改。</td>   <td>G06K9/00;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢洪途;              李金膛;                   王国倩       </td>   <td>中山大学</td>   <td>一种基于深度学习的SAR图像舰船目标检测方法</td>   <td>广东省</td>   <td>CN112883971A</td>   <td>2021-06-01</td>   <td>本发明提供一种基于深度学习的SAR图像舰船目标检测方法,该方法首先采用了随机数据增强算法,通过一系列针对SAR图像特性提出的数据增强操作,可以增强图像特征、去除相干斑等噪声影响,同时扩充了训练样本,提高模型泛化能力和鲁棒性；此外,本发明提出的CenterNet目标检测模型是一个轻量级且快速的检测模型,通过预测目标关键点信息及检测框属性(宽、高和偏移量)以得出目标的位置,摒弃了以往检测模型基于生成密集锚框的思想,从而具有速度快和内存使用低等优势。本发明不仅适用于舰船图像,还适用于各类SAR图像进行数据增强。同时,提出的目标检测模型具有轻量快速的优点,有利于实现终端部署。</td>   <td>1.一种基于深度学习的SAR图像舰船目标检测方法,其特征在于,包括以下步骤：S1：SAR图像数据增强；S2：利用步骤S1得到的数据进行目标检测模型CenterNet训练；S3：通过步骤S2训练好的模型进行目标检测模型CenterNet预测。</td>   <td>G06K9/32;G06K9/46;G06K9/62;G06N3/04;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘星成;                   赵莹莹       </td>   <td>中山大学</td>   <td>一种基于决策树分类器的跳数矩阵恢复方法</td>   <td>广东省</td>   <td>CN112884067A</td>   <td>2021-06-01</td>   <td>本发明公开了一种基于决策树分类器的跳数矩阵恢复方法,其包括步骤如下：S1：通过泛洪过程,获取的跳数矩阵中含有缺失项；S2：根据跳数矩阵中部分被观测到的跳数之间的关系构建训练集,将跳数矩阵中观测到的跳数值建模为训练集的标签,最大跳数值表示为类别数；S3：根据步骤S2中得到的训练样本集合训练决策树分类器；S4：为没有观测到的跳数值构造特征,得到未知样本；将未知样本输入到训练好的决策树分类器,得到未知样本的类别,即得到矩阵中对应位置的缺失的跳数值,从而恢复出完整的跳数矩阵H。本发明对缺失跳数的预测结果更为准确,对跳数矩阵的恢复能力大大提高。</td>   <td>1.一种基于决策树分类器的跳数矩阵恢复方法,其特征在于：所述的方法包括步骤如下：S1：通过泛洪过程,获取的跳数矩阵中含有缺失项；S2：根据跳数矩阵中部分被观测到的跳数之间的关系构建训练集,将跳数矩阵中观测到的跳数值建模为训练集的标签,最大跳数值表示为类别数；S3：根据步骤S2得到的训练样本集合训练决策树分类器；S4：为没有观测到的跳数值构造特征,得到未知样本；将未知样本输入到训练好的决策树分类器,得到未知样本的类别,即得到矩阵中对应位置的缺失的跳数值,从而恢复出完整的跳数矩阵H。</td>   <td>G06K9/62;G06F17/16</td>  </tr>        <tr>   <td>中国专利</td>   <td>         汪涛;              杨逍;                   陈小莹       </td>   <td>中山大学</td>   <td>一种污染物扩散规律计算机辅助评估方法、系统及装置</td>   <td>广东省</td>   <td>CN112884310A</td>   <td>2021-06-01</td>   <td>本发明公开了一种污染物扩散规律计算机辅助评估方法、系统及装置。通过卫星提供的各个波段的污染物数据,计算出污染物位点数据并提炼整合为污染物边界,然后采集并输入污染物扩散范围边界顶点坐标按时间顺序排列的序列,再从序列中选取任意两个时刻的污染物扩散范围边界顶点集合,利用所述两个集合计算污染物的空间扩散速度集并不断优化,将所述优化后的速度集作为微分包含蔓延离散模型的参数,用于模拟污染物扩散和设置最优控制策略。本发明解决了基于微分包含式的预测技术缺少一种可以通过实时监控数据计算污染物扩建扩散速度集的方法的问题。</td>   <td>1.一种污染物扩散规律计算机辅助评估方法,其特征在于,包括以下步骤：步骤1、通过卫星提供的各个波段的污染物数据,计算出污染物位点数据并提炼整合为污染物边界；步骤2、采集并输入污染物扩散范围边界顶点坐标按时间顺序排列的序列P＝{P-1,P-2,…,P-n},所述序列至少包括两个不同时间点的污染物扩散范围边界顶点坐标,即n≥2,其中P-i＝{v-1,v-2,…,v-m}表示第i个时刻污染物扩散范围的边界近似多边形的顶点v-j的集合；步骤3、从上述序列中选取任意两个时刻的污染物扩散范围边界顶点集合P-a、P-a,其中b＞a,所述两个集合P-a、P-b的对应时刻的间隔记为t；步骤4、利用所述两个集合P-a、P-b计算污染物的空间扩散速度集F；步骤5、将计算得到的所述速度集F代入蔓延离散模型,比较模型模拟生成的区域边界M与实际的蔓延区域边界R,通过求解模拟区域边界与实际区域边界误差最小的最优化问题,进一步优化速度集F；步骤6、将所述优化后的速度集F作为微分包含蔓延离散模型的参数,用于模拟污染物扩散和设置最优控制策略。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈定安;              肖航;              夏林元;              陈逸敏;              黄英;                   李倩霞       </td>   <td>中山大学</td>   <td>一种面向点云配准的标靶球位置优化方法</td>   <td>广东省</td>   <td>CN112884902A</td>   <td>2021-06-01</td>   <td>本发明公开了一种面向点云配准的标靶球位置优化方法,该方法包括：获取参数；根据参数生成点云并建立仿真模型；对仿真模型的方位进行调整并建立配准模型,得到源点云和目标点云；在配准模型上源点云和目标点云的伪随机位置上分别生成多组球面点云数据并得到仿真标靶球点云数据；对仿真标靶球点云数据执行球面拟合操作,得到球心坐标数据集；计算位移矢量和旋转矩阵；对源点云进行处理,完成与目标点云的配准；计算误差；循环步骤得到最优精度的数据。本发明方法以大量的内业计算弥补高昂的外业成本,获取标靶球的相对最优摆放位置,提高点云数据配准质量。本发明作为一种面向点云配准的标靶球位置优化方法,可广泛应用于点云数据可视化领域。</td>   <td>1.一种面向点云配准的标靶球位置优化方法,其特征在于,包括以下步骤：S1、获取七个基本点参数、一个限高参数和一个地面范围参数；S2、根据基本点参数、限高参数和地面范围参数生成三维模型立面点云、地面点云和标靶球的伪随机位置集并建立仿真模型；S3、基于基本点的相对位置,调整仿真模型的方位并建立配准模型,得到源点云和目标点云；S4、在配准模型上源点云和目标点云对应标靶球的伪随机位置分别生成多组球面点云数据并得到仿真标靶球点云数据；S5、基于最小二乘法分别对仿真标靶球点云数据执行球面拟合操作,得到球心坐标数据集；S6、基于霍恩法对源点云与目标点云中的球心坐标数据集进行计算,得到位移矢量和旋转矩阵；S7、根据位移矢量和旋转矩阵对源点云进行处理,完成与目标点云的配准；S8、根据目标点云和源点云进行平面拟合,并计算均方根误差作为精度评价值；S9、返回步骤S1,直至达到预设循环次数,输出精度评价最优的10组位置数据。</td>   <td>G06T17/20;G06T7/33;G06T7/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              王子渊;                   冯展祥       </td>   <td>中山大学</td>   <td>基于度量学习的解决难分不平衡样本的表面缺陷检测方法</td>   <td>广东省</td>   <td>CN112862767A</td>   <td>2021-05-28</td>   <td>本发明公开了一种基于度量学习的解决难分不平衡样本的表面缺陷检测方法,所述方法包括以下步骤：对目标图像进行特征提取网络生成高维特征；将特征提取网络提取到的特征添加到自适应特征内存,根据特征偏移值调整特征内存大小并记录内存大小的改变历史,在每个迭代中,将特征内存大小的改变历史均值作为获取旧特征数量的参考值；在上一步获取到充分的对比样本对后,同时计算欧氏距离和余弦距离的双相似性度量来度量不同样本的特征相似性。使用前k难单中心聚类的三元组损失,每次迭代中充分挖掘训练批次中的困难样本,解决多分类任务的不平衡样本。提出的方法在不引入任何计算量的情况下,提高了模型的预测精度,并且优于最新方法。</td>   <td>1.基于度量学习的解决难分不平衡样本的表面缺陷检测方法,其特征在于,所述方法包括以下步骤：S1对目标图像进行特征提取网络生成高维特征；S2将特征提取网络提取到的特征添加到自适应特征内存,根据特征偏移值调整特征内存大小并记录内存大小的改变历史,在每个迭代中,将特征内存大小的改变历史均值作为获取旧特征数量的参考值；S3在上一步获取到充分的对比样本对后,同时计算欧氏距离和余弦距离的双相似性度量来度量不同样本的特征相似性。S4使用前k难单中心聚类的三元组损失,每次迭代中充分挖掘训练批次中的困难样本,解决多分类任务的不平衡样本。</td>   <td>G06T7/00;G06K9/46;G06K9/62;G06N3/04;G06N3/06;G06N3/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭键清;              张弛;              吴皓轩;                   韩瑜       </td>   <td>中山大学</td>   <td>一种柔性机器人的操作空间轨迹优化方法、系统及装置</td>   <td>广东省</td>   <td>CN112862812A</td>   <td>2021-05-28</td>   <td>本发明公开了一种柔性机器人的操作空间轨迹优化方法、系统及装置,该方法包括：获取图像并进行预处理；对预处理后的图像进行特征提取；基于提取的椭圆参数计算柔性机器人的末端位姿和臂型参数；计算误差；构建空间优化模型并得到最优关节角度；判断到误差小于预设阈值,优化结束。该系统包括：图像处理模块、特征提取模块、运动学参数计算模块、误差计算模块、轨迹优化模块和阈值判断模块。该装置包括基座、柔性机器人、固定相机、辅助相机和辅助机械臂。通过使用本发明,能实时感知柔性机器人臂型,提高机器人的运动精度。本发明作为一种柔性机器人的操作空间轨迹优化方法、系统及装置,可广泛应用于机器人轨迹优化领域。</td>   <td>1.一种柔性机器人的操作空间轨迹优化方法,其特征在于,包括以下步骤：获取臂杆截面图像并对图像进行预处理,得到预处理后的臂杆图像；对预处理后的臂杆图像进行特征提取,得到椭圆参数；基于椭圆参数计算得到柔性机器人的末端位姿和臂型参数；根据柔性机器人的末端位姿、臂型参数和对应的期望值计算末端位姿差和臂型误差；根据末端位姿差和预构建的空间优化模型,得到最优关节角度；判断到臂型误差和末端位姿差小于预设阈值,优化结束。</td>   <td>G06T7/00;G06T7/13;G06T7/73;G06T5/00;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄丹;                   黄方军       </td>   <td>中山大学</td>   <td>一种基于分块自适应直方图平移的可逆信息隐藏方法</td>   <td>广东省</td>   <td>CN105488773B</td>   <td>2018-04-10</td>   <td>本发明涉及多媒体信息安全领域,具体涉及一种基于分块自适应直方图平移的可逆信息隐藏方法,包括如下步骤：(1)将载体图像分块,计算各子块直方图的峰值；(2)依据各子块的嵌入容量,自适应的选择用于嵌入信息的子块；(3)在嵌入信息时,采用一种自适应选择直方图平移方向的方法。本发明是一种新型的直方图平移方法,能够高效的嵌入信息并能无损的提取所嵌入信息、恢复原始图像,采用分块的方法使得嵌入信息更加安全、提高整体嵌入率,自适应选择直方图平移方向则能有效提高图像的峰值信噪比,进一步改善图像质量。从而可以为医疗、军事等应用提供帮助,本发明方法对精度越高的图像的可逆信息隐藏效果越好。</td>   <td>1.一种基于分块自适应直方图平移的可逆信息隐藏方法,其特征在于,包括以下步骤：(1)对载体图像分块、自适应的选择待嵌入有效信息子块,其具体过程为：(11)将载体图像分为M个N*N大小的子块,并将其置乱,将所有子块分为两类S和A,S类子块用于嵌入有效信息,A类子块用于嵌入附加信息；(12)在嵌入有效信息之前,先计算每个子块的嵌入容量,依据待嵌入有效信息的长度计算嵌入容量门限值R,以此来选定对应的待嵌入有效信息子块；(13)为防止嵌入信息后直方图溢出,需对所有子块进行预处理,做溢出调整；(2)自适应的选择嵌入信息时直方图平移的方向,具体为：先得出子块的直方图,直方图横轴x为像素值,取值范围[0,255],纵轴h(x)为各像素值对应的像素点个数,设从0左起第一个非零h(x)对应像素值为a,从255右起第一个非零h(x)对应像素值为b,那么直方图对应的有效像素值取值范围为[a,b],比较该直方图中峰值像素值max与a、b的距离,若max距b较近,则该直方图向右平移,反之,该直方图向左平移；(3)将嵌入了有效信息的子块的附加信息嵌入到图像中传送,自适应选择附加信息的比特长度,具体为：(31)根据子块的直方图分布,计算其有效宽度range；(32)确定有效宽度表示为(range+1)的直方图所需的最少二进制位数k；(33)将峰值在直方图中的位置用k位二进制数表示,位置数从0开始计；(4)有效信息嵌完后,采用直方图平移的方法将附加信息嵌入到预留的A类子块中；(5)在收到携带有嵌入信息的图像后,提取信息、恢复原始图像的过程为：(51)将携带嵌入信息的图像分块并置乱,先提取出A类子块中的附加信息,得出定位图、以及嵌入块直方图峰值的位置信息,并恢复对A类子块的溢出调整；(52)扫描子块,找出携带了有效信息的子块,依据子块的直方图计算像素分布范围range,并确定峰值点的像素值；(53)若峰值在直方图中的位置大于等于即信息在嵌入时直方图是向右平移的,则在提取时,直方图向左平移；反之,提取信息时直方图向右平移；最后对提取信息后的图像做溢出调整；由此,能够提取出嵌入的信息,并无损的恢复出原始图像。</td>   <td>G06T5/40;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐永键;              陆许明;              刘志敏;                   谭洪舟       </td>   <td>中山大学花都产业科技研究院;中山大学</td>   <td>一种音频信号转视觉颜色信息的方法及系统</td>   <td>广东省</td>   <td>CN104464741B</td>   <td>2018-04-06</td>   <td>本发明提供一种音频信号转视觉颜色信息的方法及系统,方法包括S1：对音频信号进行采样；S2：计算音频信号的亮度V；S3：计算音频信号的色相H和饱和度S；S4：将亮度V、色相H和饱和度S进行RGB颜色格式转换；S5：将S4中得到的RGB值进行颜色混合最终提取音频信号的颜色值。本发明通过将采集的音频信号量化处理,计算出其能量值来代表亮度,通过FFT处理来计算其代表的色相和饱和度,再将得到的亮度、色相和饱和度转换成RGB颜色格式,整个方法都是依据科学原理计算推演,过程都是一个的量化处理过程,没有人的主观意思的表达,科学严谨。</td>   <td>1.一种音频信号转视觉颜色信息的方法,其特征在于,包括以下步骤：S1：对音频信号进行采样；S2：计算音频信号的亮度V；S3：计算音频信号的色相H和饱和度S；S4：将亮度V、色相H和饱和度S进行RGB颜色格式转换；S5：将S4中得到的RGB值进行颜色混合最终提取音频信号的颜色值；其中,音频信号包括模拟音频信号和数字音频信号；对模拟音频信号进行采样的过程如下：在单位时间T内采样N个点为一帧信号,N=2～M,M为正整数；对数字音频信号进行采样的过程如下：对数字音频信号进行重采样,根据音频的采样率与重采样的频率选择增采样或减采样倍数,获取单位时间T内N个点为一帧的采样信号,N=2～M,M为正整数；音频信号的亮度V的过程如下：单位时间T内的音频信号的平均能量：                  其中,u(n)是采样的一帧N点信号；设音频信号的最大能量为E-(max),一帧采样信号对应的亮度V：          ；对采样后的音频信号进行实时FFT得到一帧音频信号的音频频谱,令一帧音频频谱中第i个采样点的频率为f-(i),该采样点的色相H-i为：                  令一帧音频频谱中幅度F的最大值是F-(max),最小值是F-(min),一帧音频频谱中第i个采样点的颜色饱和度S-i与幅度F-i的关系为：          。</td>   <td>G10L19/032;H04N9/64</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              胡彬;                   郭春超       </td>   <td>中山大学</td>   <td>一种基于种子点选取与超像素融合的通用物体检测方法</td>   <td>广东省</td>   <td>CN105513066B</td>   <td>2018-02-27</td>   <td>本发明公开了一种基于种子点选取和超像素合并的通用物体检测方法,方法主要包括下述步骤：预处理；选择种子超像素；超像素合并；小物体检测；计算框体的得分并排序；筛选得到最终结果。主要贡献包括：(1)提出一个通用物体检测的三层框架；(2)提出新的超像素特征以计算相邻超像素的相似性；(3)提出一种新的基于种子超像素的框体排序方法；(4)实现了一种结合三类现有方法的通用物体检测算法。通过选取种子点,超像素合并,提取框体中层特征并计算得分和排序,最终进行筛选这四个主要步骤,完成了通用物体的检测。实验结果表明,本发明方法比Objectness和BING两个算法效果更好。</td>   <td>1.一种基于种子点选取与超像素融合的通用物体检测方法,其特征在于,该方法包括下述步骤：S1、预处理,对每幅图像进行过分割,得到超像素块；计算每个超像素块的表观特征；S2、选择种子超像素,将种子超像素点分为大种子点和小种子点两类,大种子点旨在寻找大的物体,小种子点是对大种子点的补充,旨在丰富框体的信息,增加框体数量,以确保更多的小物体被框到；S3、超像素合并,以每个种子超像素为中心,借鉴超像素融合算法,对种子点附近的超像素不断合并直至超像素的相似性达到阈值或者框体大小达到阈值为止,在超像素合并中,在每次合并时不仅仅是合并相似度最高的超像素,而是将相似度前N的超像素都进行合并,同时将最相似的超像素合并后的结果作为下一次合并的起始；S4、小物体检测,对于大多数小物体而言,超像素分割可能不准确,从而导致步骤S3无法将其框出,所以采用中层分割的方法,对这类小物体进行检测；S5、计算框体的得分并排序：对步骤S3和步骤S4中的所有框体计算得分,并对得分进行排序；S6、筛选,通过改进的非最大化抑制采样方法,根据需要,选取出M个框体作为最终的结果。</td>   <td>G06T7/00;G06T7/10;G06T7/136</td>  </tr>        <tr>   <td>中国专利</td>   <td>              张新长       </td>   <td>中山大学</td>   <td>一种基于遥感影像的地理空间数据动态更新的方法及系统</td>   <td>广东省</td>   <td>CN105551028B</td>   <td>2018-02-23</td>   <td>本发明公开了一种基于遥感影像的地理空间数据动态更新的方法及系统,其方法包括：影像预处理；识别出变化信息；进行滤波消除噪声；对变化区域的边界进行提取；生成影像变化地物的矢量边界图；对地物的边界进行规整；基于四叉树空间索引原理对更新数据进行分割快速定位变化区域；基于神经决策树的方法识别出要素的变化类型；将变化的类型提取出来；将变化的信息在原有数据库中进行更新入库。通过实施本发明,得到一种简单、快速而准确的变化检测方法,使用四叉树的格网划分方式,提高了检索的速度和精度,结合IGAC的边界提取方法使变化区域的边界更加准确。</td>   <td>1.一种基于遥感影像的地理空间数据动态更新的方法,其特征在于,包括如下步骤：对即将更新入库的遥感影像数据进行影像预处理；采用影像代数法和变化矢量分析法相结合的方式识别出变化信息；采用中值滤波的方法对识别出的变化信息进行滤波消除噪声；根据滤波处理后的差值图像确定地物变化的分布区域,分别对变化区域的历史影像和现势影像进行图像分类；采用改进的测地线主动轮廓模IGAC模型对变化地物的边界进行提取；采用面状栅格数据的矢量化方法对以IGAC模型提取处理的边界进行处理,生成影像变化区域的矢量边界图；对地物的边界进行规整,使近似弧状的多线段地物边界拟合成圆弧状；基于四叉树空间索引原理对更新数据进行分割定位变化区域；基于神经决策树的方法识别出要素的变化类型；将变化的类型提取出来；将变化的信息在原有数据库中进行更新入库；其中：所述对即将更新入库的遥感影像数据进行影像预处理包括：用选定的图像、图形或物体,对待处理的图像进行遮挡,控制图像处理的区域或处理过程；以历史影像作为参考,对现势影像进行重投影,使现势影像与历史影像的空间参考一致,检查现势影像和历史影像的空间分辨率是否一致,如若不同则以历史影像为基准对现势影像进行重采样,统一现势影像和历史影像的像元大小；使同一地区不同来源的影像上同名地物能具有相同的坐标,进行影像空间配准；基于直方图匹配的方法进行色彩校正。</td>   <td>G06T7/13;G06T7/11;G06T5/00;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄敏;              张旭;              郑健;              潘嘉杰;                   张学强       </td>   <td>中山大学</td>   <td>一种基于AutoCAD平面交叉口工程图的拓扑数据提取方法</td>   <td>广东省</td>   <td>CN104899357B</td>   <td>2018-02-13</td>   <td>本发明公开一种基于AutoCAD平面交叉口工程图的拓扑数据提取方法,包括以下步骤：提取路面标线层内所有线条形路面标线,聚类生成路段数组；遍历路段数组元素,提取车行道边缘线、导向箭头,判断路段是否双向行驶,提取对向行驶交通流分隔设施(双向行驶路段)、车行道分界线,生成几何拓扑子路段Link；根据所有Link延长线的交点的平均值生成几何拓扑结点Node,计算每条Link的北偏角NorthAngle；生成逻辑拓扑有向子路段Arc；生成逻辑拓扑车道Lane,关联车道与导向箭头；生成逻辑拓扑车道连接器LaneConnector。能够获得交叉口完整的几何拓扑、逻辑拓扑和转向规则,丰富了交叉口建模的方法。</td>   <td>1.一种基于AutoCAD平面交叉口工程图的拓扑数据提取方法,其特征在于,包含以下步骤：S1.提取路面标线层内所有线条形路面标线,聚类生成路段数组；S2.遍历路段数组Segment集合每一个元素Segment,提取该路段车行道边缘线、导向箭头,判断该路段是否为双向行驶路段,当该路段为双向行驶路段,则提取对向行驶交通流分隔设施和路段车行道分界线,当该路段为单向行驶路段,则提取路段车行道分界线；根据提取的信息生成几何拓扑子路段Link；S3.根据所有Link延长线的交点的平均值生成几何拓扑结点Node,计算每条Link的北偏角NorthAngle；S4.生成逻辑拓扑有向子路段Arc；S5.生成逻辑拓扑车道Lane,关联车道与导向箭头；S6.生成逻辑拓扑车道连接器LaneConnector；Link是指路网在交通组织发生变化处打断后得到的路段部分；Node是Link的端点；Arc是由不同的交通流向将Link划分而得；Lane是路网中车辆行驶所依附的最小载体,每条车道能有不同的转向；LaneConnector是记录不同路段间或路段内部每对车道之间的连通关系；步骤S1是使用基于密度和距离的聚类算法对线条形路面标线聚类形成路段数组,根据输入的数据计算获取得到输出数据,其中：输入的数据是由提取的线条形路面标线的中点坐标组成的数组,数组中每个点的初始状态包括：所属簇的编号为0,没有被处理过,不是核心点；输出的数据是多个簇,其中每一个簇代表一条路段,每一个簇包含多个中点坐标,一个中点代表了该路段内的一条标线；根据输入的数据计算获取得到输出数据具体过程方式为：1)遍历数组,以得到的第一个核心点作为聚类中心开始聚类,从距离该核心点最近的点开始判断是否将点加入该簇,若该点在核心点的E领域内,则加入簇,同时修改点的属性为已被处理过,标记上簇的标号,否则,判断下一个点,即次近的点；2)当点被加入簇以后,使用递归的方法,判断该点是否为核心点,若为核心点,以该点作为新的核心点,重复上述判断过程；若不是核心点,则判断下一个点,即次近的点；3)若所有的点都被判断过,则该簇的聚类完成；4)重新搜索一个未被加入已有簇的核心点,开始新簇的聚类；直到所有的点都被加入某个簇或者不被加入任何一个簇,不被加入任何一个簇的点标记为噪声点,算法结束；上述步骤中含有两个全局变量,分别为构成E领域的最小样本点数MinPts 和E领域的半径Eps,Eps的值由MinPts-dist图确定；MinPts-dist图的横坐标为所有的中点,纵坐标为每个点与它的第MinPts个最邻近的点之间的距离,距离按从大到小的顺序排列,上述MinPts-dist图中的第一个凹陷,即阈值点所对应的MinPts-dist的值是Eps的值。</td>   <td>G06F17/50;E01C1/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              陈荣军;              刘松劲;              杨崇灵;              朱雄泳;                   谢舜道       </td>   <td>中山大学;中山大学花都产业科技研究院</td>   <td>基于改进的GS算法的矩阵式二维码RS译码纠错方法</td>   <td>广东省</td>   <td>CN104915699B</td>   <td>2018-02-09</td>   <td>本发明提供了一种基于改进的GS算法的矩阵式二维码RS译码纠错方法,改进的GS算法可以降低插值的复杂度,因此可以提高算法的效率,同时译码纠错方法对RS码的两种编码方式及其转化关系进行了研究,因此可以利用两种编码方式的转化过程对RS码进行纠正,使二维码在出现脱落、污点、穿孔以及局部破损等情况时,也能正确地还原原始信息。</td>   <td>1.一种基于改进的GS算法的矩阵式二维码RS译码纠错方法,其中改进的GS算法包括改进的Kotter插值算法和Roth-Ruckenstein因式分解算法,其特征在于：所述纠错方法包括以下步骤：S1.对二维码图像进行去掩膜处理,获得去掩膜后的RS(n,k)码,在RS(n,k)码的末位填充(255-n)个零,构造RS(255,255+k-n)码；S2.通过码字RS(255,255+k-n)结合有限域GF(q～m)中非零元素(x-0,x-1,...,x-(255+k-n-1))构成255+k-n个插值点(x-0,r-0),(x-1,r-1),...,(x-(255+k-n-1),r-(255+k-n-1)),r-0、r-1、…、r-(255+k-n-1)表示码字RS(255,255+k-n),再基于(1,k-1)-加权字典反序表通过在每个插值点至少插值m次来构建一个二元多项式,其中m为内插重度；S3.利用改进的Kotter插值算法求取最小多项式,具体过程如下：S31.首先通过公式初始化一组二元多项式,其中为初始化的第j条二元多项式,l-m为该组二元多项式的数目,为初始化后的二元多项式组成的集合,i-k为迭代次数,此时i-k＝0；S32.通过公式消去集合内首阶大于C的二元多项式,其中表示求取的首阶；S33.通过公式对中的各个二元多项式的Hasse混合偏导数进行计算,然后判断集合中所有二元多项式的Hasse混合偏导数是否都等于0,若都等于0,则进行步骤S36,若不全等于0,进行步骤S34；S34.求取该组二元多项式中的最小多项式,如下式所示：    f    =                  m        i        n                    j        &amp;Element;                  J                      i            k                                      g                        i          k                ,        j            ]]>          j      *        =    arg                  m        i        n                    j        &amp;Element;                  J                      i            k                                      g                        i          k                ,        j            ]]>其中f为该组二元多项式中的最小多项式,j～*为最小多项式对应的序号；S35.对该组二元多项式中的最小多项式进行变换修改,公式如下：                                                      g                                                i                  k                                +                1                ,                                  j                  *                                                      =                                          &amp;lsqb;                x                f                ,                f                &amp;rsqb;                                            D                                  i                  k                                                      =                          &amp;Delta;                              j                *                                                    (              x              -                              x                i                            )                        f                                                j            =                          j              *                                            ,  ]]>其余的二元多项式也进行变换修改,公式如下：                                                      g                                                i                  k                                +                1                ,                j                                      =                                          &amp;lsqb;                                  g                                                            i                      k                                        ,                    j                                                  ,                f                &amp;rsqb;                                            D                                  i                  k                                                      =                          &amp;Delta;                              j                *                                                    g                                                i                  k                                ,                j                                      -                          &amp;Delta;              j                        f                                                j            &amp;NotEqual;                          j              *                                            ;  ]]>S36.选取另一组二元多项式重复步骤S31～S35的过程进行该组最小多项式的求取,并令i-k＝i-k+1；S37.若i-k＝C则停止迭代,此时各组二元多项式的最小多项式组成集合G-C,通过公式对C组二元多项式中的最小多项式Q(x,y)进行求解；S4.在求得Q(x,y)之后,利用Roth-Ruckenstein因式分解算法对Q(x,y)进行分解获得RS码频域编码对应的信息多项式m'(x)；S5.对信息多项式m'(x)采用频域编码方式进行n位编码,获得编码码字之后取编码码字第n-k+1到n位码字生成时域编码对应的信息多项式m(x),对m(x)采用时域编码方式进行编码,即可获得纠正的RS(n,k)码。</td>   <td>G06K19/06</td>  </tr>        <tr>   <td>中国专利</td>   <td>         常会友;              路永和;              韦婷婷;                   胡勇军       </td>   <td>中山大学</td>   <td>一种新闻在线话题检测方法</td>   <td>广东省</td>   <td>CN104715014B</td>   <td>2017-10-10</td>   <td>本发明公开一种新闻在线话题检测方法,属于计算机科学与技术领域,本发明旨在针对互联网中需要进行话题检测的网络文本,提出一种更有效的话题检测方法。主要通过构建聚类缓冲区来对一定数量或一段时间内所到达的文本使用X-means算法进行初始聚类,引入双阈值思想(话题聚合阈值、话题质心更新阈值),有效控制话题的漂移及提高聚类的效果。该方法取得的效果在各个评价指标上均优于经典的Single-Pass算法,更准确地识别出需要进行话题检测的话题。</td>   <td>1.一种新闻在线话题检测方法,其特征在于,具体包括：初始化：预设最大聚类簇maxNumClusters和最小聚类簇minNumClusters,话题聚合阈值lowTX,话题质心更新阈值highTX,初始类集合ClusterSet,初步类质心列表CentroidList-Cluster,话题集合TopicSet,话题质心列表CentroidList-Topic阶段一、初始静态聚类：S1.预处理：根据新闻发布的时间顺序,读取单位时间段内所发布的新闻或单位数量的新闻,并对这些新闻文本进行预处理,将新闻文本向量化；S2.对新读入的新闻文本使用X-means算法进行初始静态聚类；S3.将静态聚类所得到的初始类存入初始类集合ClusterSet中,并计算各个初始类的质心,将其加入到初始类质心列表CentroidList-Cluster中；阶段二、动态聚类：S4.取出初始类质心列表CentroidList-Cluster中的一个初始类质心,与话题质心列表CentroidList-Topic中的每一个话题质心进行相似度计算,记录最大相似度值及其所对应的话题；S5.当所得出的最大相似度值小于话题聚合阈值lowTX,则创建新的话题,将该初始类聚合到新建的话题中,并将该初始类的质心当作新建话题的质心加入到话题质心列表CentroidList-Topic中；当所得出的相似度值大于或等于话题聚合阈值lowTX,则将该初始类聚合到相似度最大的话题中；当所得出的相似度值大于或等于话题质心更新阈值highTX,则更新聚合后的话题质心；S6.将该初始类及其所对应的类质心分别从初始类集合ClusterSet以及初始类质心列表CentroidList-Cluster中删除；S7.转步骤S4,直至初始类质心列表CentroidList-Cluster为空,完成一次聚类分析；S8.等待下一单位时间或单位数量的新闻文本,转步骤S1。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴迪;                   田浩       </td>   <td>中山大学</td>   <td>一种应用于云游戏系统的自适应流适配和资源优化方法</td>   <td>广东省</td>   <td>CN104598292B</td>   <td>2017-10-03</td>   <td>本发明公开了一种应用于云游戏系统的自适应流适配和资源优化方法,是基于用户QoE模型和服务开销模型来进行用户分发以及资源分配,包括：将云游戏平台运行周期切割成若干个时间段；在每个时间段内,更新云游戏平台系统内的用户信息和虚拟机资源；根据当前系统状态决策出用户分发及资源分配方案,该方案在系统运行周期内最小化云游戏服务提供商的服务开销,同时最大化用户的QoE总和；将用户分发以及资源分配方案应用于每个游戏用户。本发明是通过建立用户QoE(用户体验质量)模型、用户效用模型以及云平台开销模型,基于Lyapunov优化框架,设计出基于游戏类型和自适应流适配技术的用户分发和资源分配的优化方法。</td>   <td>1.一种应用于云游戏系统的自适应流适配和资源优化方法,其特征在于,是基于用户QoE模型和服务开销模型来进行的自适应流适配和资源优化方法,包括以下步骤：S101：将云游戏平台运行周期切割成若干个时间段；S102：在每个时间段内,更新云游戏平台系统内的用户信息和虚拟机资源；S103：根据当前系统状态信息决策出用户分发及资源分配方案,其决策约束条件为：在系统运行周期内最小化云游戏服务提供商的服务开销且同时最大化用户的QoE总和；S104：将用户分发以及资源分配方案应用于每个游戏用户；所述用户QoE模型是指不同用户选择的游戏视频流码率不小于此游戏所需的基本码率大小,所述基本码率表示能够流畅玩该游戏所需要的最低码率；且游戏延时在可容忍范围内；不同用户选择的游戏视频流码率不小于此游戏所需的基本码率大小采用下式表示：          &amp;Sigma;              j        =        1            M        B          (      j      )        &amp;CenterDot;          X      t              (      i      ,      j      )        &amp;GreaterEqual;    A          (      G      (      i      )      )      ]]>其中,B(j)代表码率索引j对应的码率大小,X～t(i,j)为指示变量,代表用户i选择了索引j的码率,G(i)代表用户i请求的游戏类型,A(g)表示g游戏类型所需要的基本码率；游戏延时在可容忍范围内采用下式表示：          lim              T        &amp;RightArrow;        &amp;infin;                    &amp;Sigma;              t        =        0                    T        -        1                    1              N        l        t                    &amp;Sigma;              i        &amp;Element;                  U          l          t                            D      t              (      i      )        &amp;le;          &amp;epsiv;      l        ,    &amp;ForAll;    l  ]]>其中,D～t(i)表示用户i的游戏延时,表示所有玩游戏类型l的用户数量,ε-l表示游戏类型l的游戏所能容忍的最大延时阈值。</td>   <td>G06F9/455;G06F9/50;H04L29/08;A63F13/358</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              王可泽;              李亚龙;                   王小龙       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于可配置卷积神经网络的RGB-D人物行为识别方法</td>   <td>广东省</td>   <td>CN104217214B</td>   <td>2017-09-19</td>   <td>本发明公开一种基于可配置卷积神经网络的RGB-D人物行为识别方法,构建基于可动态调整结构(可配置)的深度卷积神经网络；该识别方法可以直接处理RGB-D视频数据,并根据人物行为在时域上的变化动态调整网络结构,进而有效地自动抽取复杂人物行为的时空特征,最终大幅度提高人物行为识别的准确率。</td>   <td>1.一种基于可配置卷积神经网络的RGB-D人物行为识别方法,其特征在于,包括以下步骤：S1.构建可配置的深度模型,该深度模型引入隐变量,其构建过程为；深度模型包括M个子网络和两个全连接层,每个子网络包括顺次连接的第一个三维卷积层、第一个降采样层、第二个三维卷积层、第二个降采样层和二维卷积层；M个子网络的输出合并在一起,连接两个串联的全连接层；在深度模型中引入隐变量,对输入的RGB-D视频帧在时间上进行划分,得到M个视频块,每个视频块作为一个子网络的输入；所述深度模型中每个子网络对应的输入的起始帧是可调整的,由隐变量控制；对于给定的输入RGB-D视频,使用前向传播算法来识别视频中人物的行为；对于单个视频样本,定义M个子网络的起始帧点为(s-1,...,s-M)并且对应的输入帧的数量为(t-1,...,t-M),其中1≤t-i≤m,则深度模型的隐变量表示为H＝(s-1,...,s-M,t-1,...,t-M),其表达的是每个子网络和视频段的对应关系；给定输入视频X,隐变量H以及模型的参数ω,参数ω包括网络的边权重和偏置,识别的结果表达成向量F(X,ω,H),其中每个元素表示视频X属于某一行为类别的概率,将属于第i类的概率简记为F-i(X,ω,H)；S2.学习深度模型的参数,通过隐式网络结构反向传播算法来学习深度模型的参数,其学习过程为：固定当前深度模型参数进行人物行为识别,同时获取每个训练样本视频在时域上的优化分解模式；固定输入视频的分解模式,使用反向传播算法学习网络的每层参数；S3.人物行为识别,在时间上枚举RGB-D视频流所有的分解模式,采用深度模型进行人物行为识别,获取最优分解模式,并在最优分解模式下输出人物行为的识别结果。</td>   <td>G06K9/62;G06N3/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卞静;              李焱;              詹宏钊;                   李百林       </td>   <td>中山大学</td>   <td>一种基于双目标蚁群算法的云任务分配方法</td>   <td>广东省</td>   <td>CN104915557B</td>   <td>2017-09-01</td>   <td>本发明涉及一种基于双目标蚁群算法的云任务分配方法,用于求解考虑双目标函数优化的云任务分配问题,该方法按不同概率为蚁群算法中的能见度选取与相应的目标函数有关的计算方式,来达到求解考虑双目标优化的云任务分配问题,与现有技术相比,求解过程简单且具有较好的完成时间和负载均衡。</td>   <td>1.一种基于双目标蚁群算法的云任务分配方法,用于求解考虑双目标函数优化的云任务分配问题,所述双目标函数包括任务完成时间函数f1和系统负载均衡函数f2,其特征在于：所述双目标蚁群算法包括以下步骤：S1.设云任务的数量为n,蚂蚁可以选择的虚拟机构成集合allowed-k,蚂蚁的数量为antNum,蚂蚁的编号用antid表示,迭代次数用t表示,总的迭代次数为times,迭代次数t&lt;times；S2.初始化迭代次数t＝0,初始化蚁群和信息素,初始化的信息素通过下式表示：          &amp;tau;              i        j                    (      0      )        =          w      1              &amp;tau;              i        j            1              (      0      )        +          w      2              &amp;tau;              i        j            2              (      0      )      ]]>其中τ-(ij)(0)表示初始化的信息素,i表示任务的序号,j表示虚拟机的编号,表示任务i到虚拟机j的与任务完成时间函数f1有关的初始信息素,表示任务i到虚拟机j的与系统负载均衡函数f2有关的初始信息素,w-1+w-2＝1；S3.将编号antid＝0的蚂蚁确定为第t次迭代中的第一只蚂蚁,然后经过计算确定云任务i分配的虚拟机j,将云任务分配到虚拟机j上,再将虚拟机j排除出allowed-k,并根据系统产生的值域为(0,1)的随机数r对能见度进行更新,具体如下：                            &amp;eta;              i        j            &amp;prime;              (      t      )        =          w      1              &amp;eta;              i        j                    &amp;prime;        1                    (      t      )        +          w      2              &amp;eta;              i        j                    &amp;prime;        2                    (      t      )      ]]>          &amp;eta;              i        j                    &amp;prime;        &amp;prime;              =                                                                      &amp;eta;                                  &amp;eta;                  &amp;CenterDot;&amp;CenterDot;                                                  &amp;prime;                  &amp;prime;                  1                                                            (                t                )                            ,              r              &amp;le;                              q                                  &amp;prime;                  &amp;prime;                                                                                                                        &amp;eta;                                  i                  j                                                  &amp;prime;                  &amp;prime;                  2                                                            (                t                )                            ,              r              &gt;                              q                                  &amp;prime;                  &amp;prime;                                                                        ]]>其中η-(ij)(t)为更新后的能见度,为antid＝0时任务i到虚拟机j的与任务完成时间函数f1有关的能见度,为antid＝0时任务i到虚拟机j的与系统负载均衡函数f2有关的能见度,为antid&gt;0时任务i到虚拟机j的与任务完成时间函数f1有关的能见度,为antid&gt;0时任务i到虚拟机j的与系统负载均衡函数f2有关的能见度,q″为系统的第一设定值；S4.令编号antid＝0的蚂蚁将所有的云任务分配完毕之后,计算该蚂蚁得出的分配方案的衡量S(t),然后进行信息素局部更新,其中计算该蚂蚁得出的分配方案衡量S(t)的过程具体如下：                            S      &amp;prime;              (      t      )        =                                                                      w                1                                            S                1                                            (                t                )                            ,              r              &amp;le;                              q                                  &amp;prime;                  &amp;prime;                                                                                                                        w                2                                            S                2                                            (                t                )                            ,              r              &gt;                              q                                  &amp;prime;                  &amp;prime;                                                                        ]]>S～1(t)表示与任务完成时间函数f1有关的分配方案的衡量,S～2(t)表示与系统负载均衡函数f2有关的分配方案的衡量；S5.令antid＝antid+1并通过该编号对应的蚂蚁重复执行步骤S3～S4,然后重复S5直至antid≥antNum；S6.通过步骤S5能够获得各个蚂蚁在第t次迭代中得出的分配方案的衡量,从中选择最优的分配方案的衡量并命名为S-(gl)(t),然后进行全局信息素更新；S7.令t＝t+1并重复步骤S3～S6的操作,再重复步骤S7直至t≥times；S8.通过步骤S7能够获得各次迭代获得的最优分配方案的衡量,根据各次迭代获得的最优分配方案的衡量选择出最佳的分配方案并进行输出；系统根据双目标蚁群算法输出的最佳分配方案对云任务进行分配。</td>   <td>G06F9/455;G06F9/50;G06N3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘洁;                   黄金程       </td>   <td>中山大学</td>   <td>一种三维空间裂缝分离识别与表征方法</td>   <td>广东省</td>   <td>CN106127777B</td>   <td>2017-08-29</td>   <td>本发明公开一种三维空间裂缝分离识别与表征方法,对采集的图像进行如下处理,以实现对三维空间裂缝进行分离识别与表征：1)图像数据预处理；2)统计分析图像数据基本信息：图像数据的基本信息包括孔隙度、各个孔隙的连通性、孔隙大小统计、每个孔隙的位置、大小、方向以及各向异性；3)过滤：去除图像数据中非裂隙结构；4)平滑：对图像数据进行平滑和修补；5)减薄：使空隙结构在三维中最窄方向上减薄到厚度d；6)分离：以断开连接的方式分离裂缝网络中互相交错的裂缝；7)合并：合并在前一步中被断开的延伸较长的裂缝,整合分离过程形成的微小结构并恢复至减薄前状态,最后给出裂缝的表征。</td>   <td>1.一种三维空间裂缝分离识别与表征方法,其特征在于,对采集的图像进行如下处理,以实现对三维空间裂缝进行分离识别与表征：1)图像数据预处理；2)统计分析图像数据基本信息：图像数据的基本信息包括孔隙度、各个空隙结构的连通性、位置、大小、方向以及各向异性；3)过滤：去除图像数据中非裂隙结构；4)平滑：对图像数据进行平滑和修补；5)减薄：使空隙结构在三维中最窄方向上减薄到厚度d；6)分离：以断开连接的方式分离裂缝网络中互相交错的裂缝；7)合并：合并在前一步中被断开的空隙结构,整合分离过程形成的微小结构,最后分析各个空隙结构的孔隙度、连通性、位置、大小、方向以及各向异性,完成对三维空间裂缝的分离识别与表征；所述步骤2)结构的各向异性的计算方式为：对于一个包含了n个体像素的空隙结构,每一个体像素i都表达为从团簇中心点到当前位置的向量,空隙结构中心点坐标通过计算孔隙中所有点坐标的平均值算出；那么此空隙结构的整体各向异性能够用方向矩阵R来表示：    R    =          &amp;Sigma;              i        =        1            n              a      i                      a        i            T        =                                                                      &amp;Sigma;                                  i                  =                  1                                n                                            a                                  x                  i                                2                                                                                        &amp;Sigma;                                  i                  =                  1                                n                                            a                                  x                  i                                                            a                                  y                  i                                                                                                        &amp;Sigma;                                  i                  =                  1                                n                                            a                                  x                  i                                                            a                                  z                  i                                                                                                                        &amp;Sigma;                                  i                  =                  1                                n                                            a                                  x                  i                                                            a                                  y                  i                                                                                                        &amp;Sigma;                                  i                  =                  1                                n                                            a                                  y                  i                                2                                                                                        &amp;Sigma;                                  i                  =                  1                                n                                            a                                  y                  i                                                            a                                  z                  i                                                                                                                        &amp;Sigma;                                  i                  =                  1                                n                                            a                                  x                  i                                                            a                                  z                  i                                                                                                        &amp;Sigma;                                  i                  =                  1                                n                                            a                                  y                  i                                                            a                                  z                  i                                                                                                        &amp;Sigma;                                  i                  =                  1                                n                                            a                                  z                  i                                2                                                        ]]>该矩阵有三个特征值τ-1&lt;τ-2&lt;τ-3,以及对应的特征向量μ-1,μ-2,μ-3；各向同性指标I＝τ-1/τ-3和延伸指数E＝1-τ-1/τ-3用来定义结构的各向异性；当E→0且I→1时就表明该结构是各向同性的；其中团簇是在二值数据中由具有共同面的相同材料体像素构成的独立结构,如果一个单独的体像素标识为1,没有与周围其它标示为1的体像素共面,则这一个体像素是一个团簇；多个相同标识的体像素能够通过共面方式连接成一个很大且很复杂的团簇,多条裂隙相互交错也构成一个团簇；团簇是内部相互连通,但是与外界不连通的一个结构；步骤3)所述过滤的过程为：当团簇满足过滤条件时,修改团簇内的所有体像素的材料标识,即将原空隙标识1修改为0,表示这一个小的空隙结构转变为岩石的一部分,在后续的分析中不存在,标识1表示为空隙结构,标识0表示为岩石的一部分；步骤4)所述平滑的过程为：对过滤后的图像数据进行平滑和修补操作,具体是使用数学形态学中的闭运算实现图像的平滑和修补,形态学闭运算包括一个膨胀运算和一个紧接着的腐蚀运算；膨胀运算是形态学中的基本运算,是一个求局部最大值的操作,首先用一个事先定义的结构元素B与图像A进行卷积,也即先计算结构元素B所覆盖的图像A的区域中的像素点灰度的最大值,并把这个最大值赋值给结构元素B的原点指定的像素点；这会使得灰度图像中高亮区域逐渐扩张,对于二值图像来说,也相当于将结构元素B与图像A进行或运算,运算结果决定原点指定的像素点的值；其中结构元素是指一个原点位于中心的形状,该形状能为任意形状和大小；腐蚀运算是形态学中的基本运算,与膨胀互为对偶,腐蚀本质上是一个求局部最小值的操作,操作方法与膨胀类似,最终用局部最小值赋值给结构元素B原点指定的像素点,此操作会使得灰度图像中的高亮区域逐渐缩减；对于二值图像来说,也相当于将结构元素B与图像A进行与运算,运算结果决定原点指定的像素点的值；由于腐蚀与膨胀互为对偶,故图像A被结构元素B腐蚀的补集等于A的补集被B膨胀；形态学闭运算是对过滤后的图像先进行一次膨胀操作,再做一次腐蚀操作；步骤5)所述减薄的过程为：判断当前点是否是需要处理的空隙点,对于空隙点,计算它在三个方向的延伸情况,即在x、y、z三个方向上逐点进行检查,如果在其中一个方向上遇到一个非空隙点,则停止该方向上的检查,并记录延伸长度；三个方向都检查完毕后,选取其中延伸长度最小的方向作为待减薄方向；之后将该方向减薄至3个体像素厚度,除此三个体像素,此次处理过程中该方向上的其他体像素全部改变赋值,即标识为0,使其成为岩石部分,并且记录相关信息；处理完成之后继续下一个点的计算；步骤6)所述分离是对减薄后的数据进行分离,使得原本相互交错的结构分开,成为独立的结构,分离的具体过程为：(1)利用局部网格从三维上进行逐点处理；以当前处理像素为中心,分别以给定的一大一小两个分析半径,在三个方向上分别生成两个二维正方形局部网格,每次逐点处理只利用网格里的图像信息；将当前处理像素视为原点,两个局部网格都被原点划分为四个象限,对于外部半径大的局部网格来说,若存在任意两个象限内的图像是线性的,且它们之间的夹角处于所限定范围之内,同时内部半径较小网格内的相应象限中含有的空隙体像素数量不少于预设的数量,则它们被视为两条相交的方向不同的裂缝在当前截面上的投影,所以改变当前原点处像素的值,使其成为岩石部分；(2)对于三维图像,处理步骤是将依次从三个方向上进行,直到确定当前像素是否应当被归为岩石。</td>   <td>G06T7/00;G06T7/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖兆荣;                   戴道清       </td>   <td>中山大学</td>   <td>一种基于对数差分的图片人脸轮廓特征提取方法</td>   <td>广东省</td>   <td>CN104463149B</td>   <td>2017-08-11</td>   <td>本发明涉及一种基于对数差分的图片人脸轮廓特征提取方法,该方法通过提取图片所有像素点的差分边界图,进行变换获得人脸轮廓特征,与现有技术相比,具有数值运算稳定、适应性强的特点,尤其在图片光照变化剧烈、或混有其他复杂变化的情况下,对图片的处理效果依然很好；同时,引入权值对子邻域的差分边界图进行调整,因此提取得到的人脸轮廓特征在进行识别的时候其识别率更加的稳定。</td>   <td>1.一种基于对数差分的图片人脸轮廓特征提取方法,其特征在于：提取图片像素点的差分边界图,进行arctan变换获得人脸轮廓特征,具体如下：S1.把图片的灰度值区间调为[1,256],设当前要处理的像素点为(x,y),以该像素点为中心划分出邻域N-((x,y)),对像素点(x,y)的灰度值f(x,y)进行分解：f(x,y)＝ρ(x,y)S(x,y)  (1)其中ρ(x,y)为反射率分量,ρ(x,y)包含有人脸轮廓特征,S(x,y)为光照分量；对f(x,y)取对数,得F(x,y)＝logf(x,y)＝logρ(x,y)+logS(x,y)  (2)对邻域N-((x,y))中的其他像素点利用式(1)、(2)进行处理,得                  令得                  由于对数函数log在[1,256]上是一致连续和非扩张的,因此                  由此可得令即I(x,y)为像素点(x,y)的差分边界图,对I(x,y)进行arctan变换,得                  即I～(MSLDE)(x,y)是从像素点(x,y)提取的人脸轮廓特征；S2.对图片其他像素点进行步骤S1的处理,获得相应的人脸轮廓特征。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卢伟;                   陀得意       </td>   <td>中山大学</td>   <td>一种基于纹理特征的视频跟踪方法</td>   <td>广东省</td>   <td>CN104392461B</td>   <td>2017-07-11</td>   <td>本发明提供一种基于纹理特征的视频跟踪方法,首先对视频进行背景模型构建,将当前帧与得到的背景模型进行比较,从而得到目标的前景图,再通过处理得到目标的矩形框。根据计算得到的纹理特征,将目标进行分块,对每一分块进行纹理特征的直方图统计,并将直方图的所有bin值作为该分块区域的特征向量。最后在目标一定半径范围内搜索当前帧目标的候选位置,根据候选目标的特征向量与目标的特征向量进行总体的相似度匹配,得到目标的当前位置。这种实时视频下的目标跟踪算法具有判断速度快、跟踪准确度较高等优点,从而为后续处理提供了很好的基础,并减少了视频监控人力的使用。</td>   <td>1.一种基于纹理特征的视频跟踪方法,其特征在于,包括以下步骤：S1：构建背景模型：对视频中连续N张图像进行背景提取并保存每一张图像的背景像素值组成背景像素值集,若背景像素值集中任一背景像素值的出现次数大于阈值λ,则保留该背景像素值对应的任一张背景图像作为所述N张图像的背景模型M；S2：提取目标前景：将视频中任一当前图像A与背景模型M进行比较处理求取前景图,并从该前景图中计算连续白色点像素个数达到阈值β的区域,将该区域作为当前图像的目标前景框T；S3：构建目标前景特征：对目标前景框T进行LBP纹理特征提取,把得到的纹理图按照区域面积大小为ε进行分割,对分割得到的每个区域进行直方图统计,并由直方图每个bin的值获得每一个区域的特征向量；S4：搜索当前帧目标：对于图像B,在图像B中以目标前景框T中的目标在原来图像A中的位置为圆心,半径为r范围内搜索候选目标集,对候选的目标框进行步骤S2-S3的处理,将所得到每个候选目标的每个区域的特征向量与目标前景框T中的目标的每一个区域的特征向量进行匹配程度计算,若小于匹配阈值σ则匹配成功,继而计算候选目标与目标前景框T中的目标的相似度,相似度最大的候选目标作为目标前景框T中的目标在图像B中的位置。</td>   <td>G06T7/292</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              周展鸿;                   陈韩杰       </td>   <td>中山大学</td>   <td>一种城市道路交通事故风险实时预测方法</td>   <td>广东省</td>   <td>CN104732075B</td>   <td>2017-07-07</td>   <td>本发明提供了一种城市道路交通事故风险实时预测方法,通过提取观测集中的各个观测对象的几何线形数据、交通事故发生前n分钟的历史交通流基础数据以及历史天气状况数据进行计算,得到交通事故发生前n分钟的交通流特征参数和天气状况数据转为分类变量后的等级以及该等级的分布概率,再建立基于泊松分布的城市道路交通事故实时预测模型,利用确定的交通流特征参数和天气状况数据的等级以及该等级的分布概率对预测模型进行标定,在对所需预测对象的交通事故风险进行预测的时候,只需实时计算所需预测对象的实时交通流特征参数和天气状况数据转为分类变量后的等级以及该等级的分布概率,即可利用标定的公式对所需预测对象的交通事故风险进行预测。</td>   <td>1.一种城市道路交通事故风险实时预测方法,其特征在于：包括以下步骤：S1.确定所需预测对象的类型,选择若干类型相同的城市道路作为观测对象组成观测集,所述城市道路的类型包括有：路段和交叉口；S2.提取观测集中各个对象的几何线形数据、历史交通事故数据和历史天气状况数据,根据历史交通事故数据获得每起交通事故发生的精确时间,在获取交通事故发生的精确时间之后,再获取每起交通事故发生前n分钟的交通流基础数据和天气状况数据；S3.对于每个观测对象,根据获取的每起交通事故发生前n分钟的交通流基础数据计算交通事故发生前n分钟浮动车车速的变异系数CVS,若所需预测对象的类型为路段,则还需要对交通事故发生时的交通流密度D进行求解,交通事故发生前n分钟浮动车车速的变异系数CVS以及交通事故发生时的交通流密度D均为交通流特征参数；S4.对于每个观测对象,提取观测对象某一天的交通流基础数据,计算当天每n分钟的变异系数CVS,形成变异系数CVS累计分布图；同时还需提取观测对象的历史天气状况数据,通过历史天气状况数据分别计算出历史时段无雨天气、有雨天气两种天气类型的分布概率,若所需预测对象的类型为路段,则还需计算当天每n分钟的交通流密度D,形成交通流密度D累计分布图；S5.将交通事故发生前n分钟浮动车车速的变异系数CVS转为分类变量,根据变异系数CVS累计分布图确定该分类变量的等级,并计算该等级在变异系数CVS累计分布图的分布概率p(CVS)；同时提取交通事故发生前n分钟的天气状况数据,通过该天气状况数据确定交通事故发生前n分钟的天气类型并将其转为分类变量,获得交通事故发生前n分钟的天气状况数据的分布概率p(W)；若所需预测对象的类型为路段,则还需要对交通事故发生时的交通流密度D进行上述处理,以确定交通事故发生时的交通流密度D这个分类变量的等级,以及该等级在交通流密度D累计分布图的分布概率p(D)；S6.在步骤S5的基础上,对观测行驶量EXP进行计算,若所需预测对象的类型为路段,观测行驶量EXP计算如下：EXP＝p(CVS)·p(D)·p(W)·AADT·L·T其中AADT为路段的年平均日交通流量,L为路段的长度,L包含于提取的几何线形数据中；T为观测时间；若所需预测对象的类型为交叉口,则观测行驶量EXP包括交叉口主干道观测量EXPA和交叉口次干道观测量EXPB,计算公式如下：EXPA＝p(CVS)·p(W)·AADTA·TIEXPB＝p(CVS)·p(W)·AADTB·TI其中AADTA和AADTB分别为交叉口主干道和次干道的年平均日交通流量,TI为观测时间；S7.在S6的基础上,构建基于泊松分布的交通事故风险预测模型,表达式如下：                  其中P(y)为路段或交叉口发生y次交通事故的概率；μ为交通事故风险指数；对于路段,μ的计算方式如下：μ＝EXP～εexp(θ+λ-(CVS(α))+λ-(D(β))+λ-(W(γ)))  (1)其中θ为常数项,ε为EXP的指数,λ-(CVS(α))、λ-(D(β))、λ-(W(γ))分别为交通事故发生前n分钟的变异系数CVS、交通事故发生时交通流密度D、交通事故发生前n分钟的天气状况数据的预测参数,ε、θ、λ-(CVS(α))、λ-(D(β))、λ-(W(γ))均为待标定的参数；对于交叉口,交通事故风险指数μ的计算方式如下：                  其中ρ为常数项,κ、ν分别为EXPA、EXPB的指数,λ-(CVS(α))和λ-(W(γ))分别为交通事故发生前n分钟的变异系数CVS、交通事故发生前n分钟的天气状况数据的预测参数,x-η表示交叉口的第η个静态变量,所述静态变量包括左转车道情况、右转车道情况,交叉口视距和信号相位数,静态变量包括于提取的几何线形数据中,λ-η为相应静态变量的系数；κ、ν、ρ、λ-(CVS(α))、λ-(W(γ))和λ-η均为待标定的参数；S8.根据各个观测对象的几何线形数据、历史交通事故数据和历史天气状况数据,利用构建的风险预测模型通过极大似然法对待标定的参数进行标定；S9.实时采集所需预测对象每n分钟的交通流基础数据和天气状况数据,根据天气状况数据确定预测对象每n分钟天气状况数据的分布概率,然后通过交通流基础数据计算获得实时交通流特征参数,确定实时交通流特征参数的等级以及该等级的分布概率之后,利用标定的式(1)或式(2)对所需预测对象的交通事故风险指数μ进行计算,获得μ之后将μ作为预测结果进行输出。</td>   <td>G06Q10/04;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘凯;              刘洋;                   柳林       </td>   <td>中山大学</td>   <td>一种HCS结合小波变换的遥感图像融合方法</td>   <td>广东省</td>   <td>CN104346790B</td>   <td>2017-06-20</td>   <td>本发明公开一种HCS结合小波变换的遥感图像融合方法,对低空间分辨率的多光谱影像和高空间分辨率的全色影像进行影像配准,将多光谱影像重采样至与全色影像相同像元尺寸,裁剪得到相同图幅范围的多光谱影像和全色影像等待融合；对多光谱影像进行HCS变换得到强度分量和若干角度分量；对强度分量和全色影像采用小波基进行多层二维小波分解,得到强度分量信号和全色信号；以权重将强度分量和全色信号在信号级别上加权求和,得到融合信号；采用小波基对融合信号进行多层二维小波重构,得到增强后的强度分量；对增强后的强度分量使用角度分量进行分解得到最终融合影像。本发明在接近完美地保留多光谱数据的光谱信息的同时,增强了融合结果的影像信息质量。</td>   <td>1.一种HCS结合小波变换的遥感图像融合方法,其特征在于,包括：S1.对低空间分辨率的多光谱影像和高空间分辨率的全色影像进行影像配准,并将低空间分辨率的多光谱影像重采样至与高空间分辨率的全色影像相同像元尺寸,裁剪得到相同图幅范围的多光谱影像和全色影像等待融合；S2.对低空间分辨率的多光谱影像进行HCS变换得到强度分量和若干角度分量；S3.对强度分量和高空间分辨率的全色影像采用一小波基进行多层二维小波分解,得到强度分量信号和全色信号；S4.采用权重将强度分量信号和全色信号在信号级别上进行加权求和,得到融合信号；S5.采用与所述步骤S3中相同的小波基对融合信号进行多层二维小波重构,得到增强后的强度分量；S6.对增强后的强度分量使用若干角度分量进行分解得到最终融合影像；所述步骤S6,对增强后的强度分量使用若干角度分量进行分解得到最终融合影像的方法为：                                                       式中：I-(adj)表示增强后的强度分量,n表示多光谱数据的波段总数；表示第1个波段的融合结果,表示第h个波段的融合结果,表示最后一个波段的融合结果；表示第h个角度分量,h取值范围表示2、3、4、…、n-1。</td>   <td>G06T5/50;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         柳林;              姜超;                   刘凯       </td>   <td>中山大学</td>   <td>一种服务于警务防控分区规划的犯罪风险时空模式识别方法</td>   <td>广东省</td>   <td>CN103955804B</td>   <td>2017-06-13</td>   <td>本发明提供一种服务于警务防控分区规划的犯罪风险时空模式识别方法,能够准确识别出研究区内存在的各种时空变化模式,并明确相应的空间位置范围和时间变化趋势。利用空间分析指标表征不同时段内犯罪风险的空间分布特征,并构建n维时间—信息特征空间,利用非监督分析技术获取各类警务防区的空间位置与范围,再结合各类警务防控区相对犯罪风险的时间变化情况,能够对未来特定时段内警力资源的空间部署策略提供决策支持。本发明的优点在于：面向应用实践部门、识别过程操作简单、能够综合时空维度信息,并且结果可视化效果较好,特别适用于“地方警务”模式中的警力资源部署。</td>   <td>1.一种服务于警务防控分区规划的犯罪风险时空模式识别方法,其特征在于,包括如下步骤：第一步、根据案件记录的表格数据进行地理编码,转换成GIS空间点数据,确保匹配成功率在85％以上；第二步、将需要研究的时期划分为n个时段,针对每个时段中的犯罪案件点,采用“移动窗口”和核密度估计的方法来度量各时段内犯罪案件的空间分布格局,所采用的核密度函数如下：                                  &amp;lambda;      &amp;tau;              (      s      )        =          &amp;Sigma;              d        i        &amp;le;        &amp;tau;                    3                        &amp;pi;&amp;tau;          2                                    (        1        -                              d            i            2                                &amp;tau;            2                          )            2       ]]>                  其中,s代表移动窗口的中心,τ为计算核密度时的搜索半径；d-i是落在搜索半径以内的每个事件点i到移动窗口中心位置的距离；λ-τ(s)是所求的犯罪事件核密度值；第三步、对各时段内犯罪案件的核密度估计结果进行标准化,所采用的标准化函数如下：                                          K                  i          &amp;prime;                    &amp;OverBar;        =                            K                      i            &amp;prime;                          -                  K          min                                      K                      m            a            x                          -                  K                      i            &amp;prime;                                &amp;times;    100   ]]>                  其中,为网格单元i'标准化后的核密度值；K-(i')为网格单元i'的原始核密度值；K-(min)为特定时段内研究区域内原始核密度的最小值；K-(max)为特定时段内研究区域内原始核密度的最大值；第四步、构建反映各时期核密度信息的n维特征空间,将研究区域内的网格单元投射到该空间中,并根据点的集聚离散程度进行分类；第五步、生成并评价表征分类结果之间距离的树状图,根据3至6类的类中心间距值,确定分类数量β,重新进行分类,得到最终的分类结果,即各类警务防控区的空间位置图；第六步、汇总统计每个类型区的数理指标作为该类型区的犯罪风险程度,据此判断特定时段内各类型区内相对犯罪风险程度的高低,并绘制出相应的时间变化图,相对风险程度的计算公式如下：RCR-(ti”)＝rk(ACR-(ti”))其中,RCR-(ti”)表示t时刻i”区域的相对犯罪风险程度,rk()表示将观察值按自小到大排序后的次序编号,ACR-(ti”)表示t时刻i”区域内的犯罪风险程度,即该区域内所有核密度估计值的均值。</td>   <td>G06Q10/06;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈荣军;              谭洪舟;              莫嘉永;              朱雄泳;              李智文;                   黄登       </td>   <td>中山大学;中山大学花都产业科技研究院</td>   <td>一种基于压缩感知的二维码图像光照均衡方法</td>   <td>广东省</td>   <td>CN104408698B</td>   <td>2017-06-06</td>   <td>本发明公开一种基于压缩感知的光照不均的二维码图像复原方法,包括以下步骤：采集同一个二维码图像,获取两张二维码图像,并对二维码图像进行稀疏性分析；分别对两张二维码图像进行傅里叶变换得到其频谱图像X1和X2,根据二维码图像的傅里叶特征设置一个非相关采样矩阵,此非相关矩阵是由十字形和同心圆所组成的,并且采样的十字形宽度和同心圆形的大小可以进行适当的调整,对频谱图像X1和X2在傅里叶域进行频谱采样到Y1和Y2；对Y1和Y2进行线性融合得到了新傅里叶频谱Y；用FISTA对频谱Y进行快速软阈值迭代,得到Y’,并且对Y’进行逆傅里叶变换的到恢复后的图像f,并且对图像f进行二值化处理,识别二维码图像。本发明能够均衡光照,在提高对光照不均图像处理速度的同时,又能比较准确的还原出原二维码图像。</td>   <td>1.一种基于压缩感知的二维码图像光照均衡方法,其特征是,包括以下步骤：1)采集同一个二维码图像,获取两张二维码图像,并对二维码图像进行稀疏性分析,得出二维码图像具有稀疏的特性；2)分别对两张二维码图像进行傅里叶变换得到其频谱图像X1和X2,根据二维码图像的傅里叶特征设置一个非相关采样矩阵,对频谱图像X1和X2在傅里叶域进行频谱采样到Y1和Y2；3)对Y1和Y2进行线性融合得到了新傅里叶频谱Y；4)用FISTA对频谱Y进行快速软阈值迭代,得到Y’,并且对Y’进行逆傅里叶变换的到恢复后的图像f,并且对图像f进行二值化处理,复原二维码图像；所述步骤2)中根据二维码图像的傅里叶特征设置一个非相关采样矩阵的具体过程为：2.1)非相关采样矩阵是根据二维码图像的傅里叶特征进行设置的,二维码图像的傅里叶变换是类似十字形的图像；2.2)构造出一个确定性的M(i,j)的观测矩阵,其中0≤i≤256；0≤j≤256,则上述非相关采样矩阵是一个同心圆和一个十字形的叠加而成的,其模型如下：                            D    =                                        (            i            -            128            )                    2                +                              (            j            -            128            )                    2                      ,    0    &amp;le;    i    &amp;le;    256    ;    0    &amp;le;    j    &amp;le;    256   ]]>                                    其中D表示同心圆内点到点的距离；2.3)上述确定性的M(i,j)的观测矩阵中采样的十字形宽度和同心圆形的大小能够通过统计二维码的黑色和白色点的比例来确定,其确定方法为:首先将QR码进行二值化处理,然后进行归一化处理,得出0和1的两个数值,统计0黑色点的个数,判断每一个像素点,如果是0,则n＝n+1；然后(256*256)-n得出白色点的个数,算出黑色点和白色点的比例,黑色点数越多,采样矩阵的宽度和长度越大,相反,就越小。</td>   <td>G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              赵杰;                   刘勇       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司</td>   <td>一种基于视觉注意力模型的关键帧提取方法和系统</td>   <td>广东省</td>   <td>CN103824284B</td>   <td>2017-05-10</td>   <td>本发明公开了一种基于视觉注意力模型的关键帧提取方法和系统。其提取方法包括：在空域上,该方法用二项式系数滤波全局对比度进行显著度检测,并且利用自适应阈值对目标区域进行提取。算法不但能较好地保持显著目标区域边界,而且区域内显著度较均匀。然后,在时域上,该方法定义了运动的显著度,通过单应性矩阵对目标运动进行估计,采用关键点代替目标进行显著度检测,之后融合空域显著度的数据,提出基于能量函数边界扩展的方法获得包围盒作为时域的显著目标区域。最后,该方法通过显著目标区域降低视频的丰富性,采用结合在线聚类的镜头自适应方法进行关键帧提取。</td>   <td>1.一种基于视觉注意力模型的关键帧提取方法,用于对视频的关键帧进行提取,其特征在于,包括：在空域上,用二项式系数滤波全局对比度进行显著度检测,并且利用自适应阈值对目标区域进行提取；在时域上,定义运动的显著度,通过单应性矩阵对目标运动进行估计,采用关键点代替目标进行显著度检测,融合空域显著度的数据,提出基于能量函数边界扩展的方法获得包围盒作为时域的显著目标区域；通过显著目标区域降低视频的丰富性,采用结合在线聚类的镜头自适应方法进行关键帧提取；在空域上,通过用二项式系数滤波全局对比度进行显著度检测,并且利用自适应阈值对目标区域进行提取,具体方法如下：(11)二项式系数按照杨辉三角构造,N层的归一化因子为2～N；选择第四层,滤波器系数B-4＝(1/16)[1 4 6 4 1]；(12)设I为原刺激强度,为周围刺激强度的均值,为I与B-4的卷积；将像素点采用CIELAB颜色空间的向量形式衡量刺激的强弱,刺激的对比度即为两CIELAB向量的欧式距离,因此对于像素点(x,y)的刺激度检测为                            S          (      x      ,      y      )        =    |    |          I              B        4                    (      x      ,      y      )        -          I      &amp;OverBar;        |    |    -    -    -          (      1      )       ]]>                  (13)得到显著度的测量集合S-s＝(s-(11),s-(12),…,s-(NM))后,利用自适应阈值对目标区域进行提取,其中s-(ij)为像素点(i,j)的显著度,0≤i≤N,0≤j≤M,M,N分别为图像的宽度和高度；通过以下方法实现自适应阈值对目标区域进行提取：(21)定义像素点(x,y)全局显著度检测计算式                                  S      g              (      x      ,      y      )        =          1      A              &amp;Sigma;              i        =        0            N              &amp;Sigma;              j        =        0            M        |    |          I              B        4                    (      x      ,      y      )        -    I          (      i      ,      j      )        |    |    -    -    -          (      2      )       ]]>                  其中A为检测的面积,为原图像经滤波器B-4滤波后像素点(x,y)的刺激强度,I(i,j)为像素点(i,j)的原刺激强度,M,N分别为图像的宽度和高度；(22)通过直方图进行运算加速,将原刺激强度I映射到刺激空间中,最终对于用户感受到的刺激的显著度如下所示                            S          (              I                  B          4                    (      I      )      )        =          1              (        m        -        1        )        D        (                  I                      B            4                          (        I        )        )                    &amp;Sigma;              i        =        1            m              (      D      (                        I                      B            4                                    (          I          )                    )      -      |      |              I                  B          4                    (      I      )      -              I                  B          4                    (              I        i            )      |      |      )              S      g              (              I                  B          4                    (      I      )      )        -    -    -          (      3      )       ]]>                  其中D为刺激在m个最近刺激之间的距离(23)通过改变阈值T-s指定前景和背景区域,然后以获得最小的能量函数的阈值作为最优阈值；以T-s为阈值的能量函数的定义如下：                            E          (      I      ,              T        s            ,      &amp;lambda;      ,      &amp;sigma;      )        =    &amp;lambda;          &amp;Sigma;              n        =        1            N              (      f      (                        T          s                ,                  S          n                    )              S        n            )        +    V          (      I      ,              T        s            ,      &amp;sigma;      )        -    -    -          (      4      )       ]]>                  其中S-n由公式(2)获得,λ为显著目标能量的权重,N为图像的总像素数,f(T-s,S-n)＝max(0,sign(S-n-T-s)),V(I,T-s,σ)为对周围刺激的相似度的衡量,选择当前T-s下显著点和其8邻域的像素点组成点对Pair进行计算,dist(p,q)为两点之间的空间距离,σ为控制参数。</td>   <td>G06T7/136;G06T7/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘凯;              刘洋;                   柳林       </td>   <td>中山大学</td>   <td>一种面向对象分割结合灰度形态学的道路提取方法</td>   <td>广东省</td>   <td>CN103996042B</td>   <td>2017-05-10</td>   <td>本发明公开了一种面向对象分割结合灰度形态学道路提取方法,步骤如下：对原始数据进行影像融合；对融合结果进行面向对象分割；基于分割得到的对象进行全局分类,类别为各级宽路、城建区和其他；采用水平算子对原始全色影像进行分割,基于灰度形态学相关技术进行窄路提取、降噪；采用基于灰度形态学的脊线法对各级宽路进行矫正,得到宽路路网；用城建区掩膜去除窄路提取结果中的非窄路纹理,得到窄路路网；合并多级路网,得到最终的分级路网提取结果。本发明结合了面向对象、线段匹配和脊线提取三种道路提取思想,通过减弱或消除四种道路提取中可能遇到的噪声,实现了一种可以兼顾宽路和窄路、具有较高精度和极强实用性的多级道路提取方法。</td>   <td>1.一种面向对象分割结合灰度形态学的道路提取方法,其特征在于,包括以下步骤：1.1.对原始全色影像和多光谱影像进行影像融合得到融合结果；1.2.对融合结果进行面向对象分割得到若干对象；1.3.基于对象进行全局分类,类别为各级宽路、城建区和其他；1.4.采用水平算子对原始全色影像进行分割,并进行窄路的提取和降噪；1.5.对各级宽路进行校正,得到宽路路网；1.6.用城建区的掩膜去除窄道提取结果中的非窄路纹理,得到最终窄路路网；1.7.对多级路网进行合并,得到最终的分级路网提取结果；步骤1.1中采用水平算子对原始全色影像进行分割,并采用基于灰度形态学的方法进行窄路的提取和降噪的子步骤包括：2.1、选取适当结构算子对全色影像进行水平算子分割,并对分割结果进行二值化处理,其中水平算子结构如下：                            X    &amp;CirclePlus;    B    =          {              p        &amp;Element;                  &amp;epsiv;          2                ,        p        =        x        +        b        ,        x        &amp;Element;        X        ,        b        &amp;Element;        B            }       ]]>                                              X    &amp;Theta;    B    =          {              p        &amp;Element;                  &amp;epsiv;          2                ,        p        +        b        &amp;Element;        X        ,        &amp;ForAll;        b        &amp;Element;        B            }       ]]>                                                                X    &amp;CenterDot;    B    =          (      X      &amp;CirclePlus;      B      )        &amp;Theta;    B   ]]>                                                                                          式中：X为待处理集,B为结构算子；x为X中单一元素,b为B中单一元素,p为运算结果集中的单一元素,p从属于二维欧式空间ε～2；为膨胀运算,Θ为腐蚀运算,为开运算,·为闭运算；为凸函数,为凹函数,G为水平算子,F为标记函数；为凸类,为扁平类,为凹类；2.2、采用一定长度、呈若干角度的线段状结构算子对二值化的分割结果进行线段匹配,即所有角度结构算子对分割结果开运算的并,并在匹配的结果上进行同伦细化和去除毛刺,公式如下：                  R-(thin)＝Thin(R,{L-N})R-(spur)＝Spur(R-(thin))式中：X-F为待处理二值化影像,R为线段匹配结果,R-(thin)为细化结果,R-(spur)为剔除毛刺结果；L-(θi)为某一长度以水平方向逆时针旋转θi得到的线状结构算子,{θ-N}为约束θi的角度集合,{L-N}为细化专用的L算子集；Thin()为细化函数,Spur()为剔除毛刺函数；2.3、对上一步的结果采用窗口法进行去噪,消除毛刺过程中产生的残渣；2.4、对上一步的结果采用适当大小的结构算子进行膨胀,消去由于噪声影响在窄路路网上产生的孔穴；2.5、对上一步的结果,选择适当结构算子和窗口大小,重复一次步骤2.2至步骤2.3,得到初步的窄道提取结果。</td>   <td>G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>              张纯禹       </td>   <td>中山大学</td>   <td>一种压痕数据分析方法</td>   <td>广东省</td>   <td>CN104077444B</td>   <td>2017-05-10</td>   <td>本发明涉及一种压痕数据分析方法,该方法的核心是基于Levenberg-Marquardt算法的数值优化,优化的目标函数为通过有限元模拟得到的压痕数据和实验压痕数据之间的差异,优化参数即为被测材料待求的力学参数。由于可在有限元模型中定义多种加-卸载方案和材料本构模型,因此本数据分析方法具有很强的通用性。</td>   <td>1.一种压痕数据分析方法,其特征在于,包括以下步骤：步骤1、建立压痕测试过程的有限元模型,其中,被测材料的力学参数定义为变量；步骤2、将给定的初始的力学参数输入至所述有限元模型,并对所述有限元模型进行计算,得到模拟压痕数据；步骤3、调用所述模拟压痕数据以及读取实验压痕数据,利用公式一计算模拟压痕数据与实验压痕数据之间的差异；                  其中,F(P～k)为目标函数的返回值；P～0为力学参数的初始值,P～k为修正k次后的力学参数；N为实验压痕数据包含的数据个数；f～(exp)(t-i)为加载时刻等于t-i时的实验压痕测试结果；f～(cal)(P～k,t-i)为加载时刻等于t-i时的模拟压痕测试结果；步骤4、利用Levenberg-Marquardt算法对目标函数进行优化,当判断到F(P～k)小于预设阈值时,输出P～k作为最终的优化结果；所述步骤4具体包括如下子步骤：(a)将P～0作为Levenberg-Marquardt算法的初始参数；(b)利用有限差分方法计算敏感度矩阵或Jacobi an矩阵(c)求解方程(A～TA+λI)g～k＝-A～TF(P～k),得到修正量g～k,其中I为单位矩阵,λ为非负的标量参数；(d)计算P～(k+1)＝P～k+g～k,并判断目标函数是否小于预设阈值,若是,则输出P～k作为最终的优化结果,若否,则重复步骤a至步骤d。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              佘永业;              余志;                   罗东华       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种融合实时交通状态信息的道路背景提取与更新方法</td>   <td>广东省</td>   <td>CN104077757B</td>   <td>2017-05-10</td>   <td>本发明公开了一种融合实时交通状态信息的道路背景提取与更新方法,包括：A、根据道路交通运行的实时状态和光照变化估测的结果构建选择性背景帧提取模型；B、根据构建的选择性背景帧提取模型依次进行初始背景选取、背景更新区域检测和背景更新处理,以实现对道路背景的自适应更新。本发明根据道路的实时交通运行状态和光照变化估测的结果构建选择性背景帧提取模型,在传统方法的基础上建立融合实时交通状态信息和光照变化信息的选择性背景帧提取模型,交通场景的适应性较好,且避免了因交通流骤变、运动车辆过多或光照变化而对背景图像造成的干扰,抗干扰能力强且鲁棒性较好。本发明可广泛应用于视频交通监控和图像处理领域。</td>   <td>1.一种融合实时交通状态信息的道路背景提取与更新方法,其特征在于：包括：A、根据道路交通运行的实时状态和光照变化估测的结果构建选择性背景帧提取模型；B、根据构建的选择性背景帧提取模型依次进行初始背景选取、背景更新区域检测和背景更新处理,以实现对道路背景的自适应更新；所述步骤A,其包括：A1、对交通监控视频图像进行采集；A2、对交通监控视频图像进行光照变化估测,得到道路背景更新时刻；A3、从交通监控视频图像中提取出宏观交通状态运行参数,并根据宏观交通状态运行参数评估道路的实时交通运行状态；A4、根据道路的实时交通运行状态参数计算选择性图像帧的模型置信度；A5、根据道路背景更新的光照变化估测结果、道路的实时交通运行状态和选择性图像帧的模型置信度构建选择性背景帧提取模型；所述步骤A4,其具体为：根据交通视频图像当前帧车辆区域的边缘占有率Occ-k和运动车辆边缘特征点的光流速度值Vel-k计算选择性图像帧的模型置信度参数值W-k,所述选择性图像帧的模型置信度参数值W-k的计算公式为：w-k＝Vel-k/Vel-(max)+(1-Occ-k/Occ-(max)),其中,{Vel-k,Occ-k}为当前帧宏观交通运行状态的参数特征集,Vel-(max)和Occ-(max)分别为参数特征集采样序列中光流速度的最大值和边缘占有率的最大值。</td>   <td>G06T5/40;G06K9/46;H04N7/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;                   陈玲       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种基于显著性分析的车辆颜色识别方法及系统</td>   <td>广东省</td>   <td>CN103425989B</td>   <td>2017-04-19</td>   <td>本发明公开了一种基于显著性分析的车辆颜色识别方法及系统,方法包括：A、获取原始车辆图像；B、对原始车辆图像进行特征显著性分析,从而提取出彩色显著区和车辆内部区域；根据彩色显著区的面积判定车辆颜色属于彩色色系或黑白色系,若属于彩色色系,则执行步骤D；反之,则执行步骤E；D、根据特征显著性分析的结果和彩色色系的车辆颜色判据,采用K-means聚类的方式识别出彩色色系内的车辆颜色；E、对原始车辆图像进行灰度化处理,然后根据灰度化处理后的图像和黑白色系的车辆颜色判据识别出黑白色系内的车辆颜色。本发明具有应用范围较广、识别精确度高、鲁棒性较好、实用性较高和运算量较小的优点,可广泛应用于图像处理领域。</td>   <td>1.一种基于显著性分析的车辆颜色识别方法,其特征在于包括：A、获取原始车辆图像；B、对原始车辆图像进行特征显著性分析,从而提取出彩色显著区和车辆内部区域；C、根据彩色显著区的面积判定车辆颜色属于彩色色系或黑白色系,若属于彩色色系,则执行步骤D,反之,则执行步骤E；D、根据特征显著性分析的结果和彩色色系的车辆颜色判据,采用K-means聚类的方式识别出彩色色系内的车辆颜色；E、对原始车辆图像进行灰度化处理,然后根据灰度化处理后的图像和黑白色系的车辆颜色判据识别出黑白色系内的车辆颜色；所述步骤D,其包括：D1、对彩色显著区和车辆内部区域进行与运算,从而得到彩色色系的颜色识别区；D2、在HSV空间中采用K-means算法对所述颜色识别区进行颜色聚类分析,并根据颜色聚类分析的结果得到所述颜色识别区的主颜色类；D3、根据彩色色系的车辆颜色判据对所述颜色识别区的主颜色类进行分层颜色判定,从而识别出彩色色系内的车辆颜色。</td>   <td>G06K9/60;G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黎夏;              许晓聪;              陈广亮;                   刘小平       </td>   <td>中山大学</td>   <td>一种基于粒子群算法的多级分辨率遥感影像自动配准方法</td>   <td>广东省</td>   <td>CN104268869B</td>   <td>2017-04-12</td>   <td>本发明公开一种基于粒子群算法的多级分辨率遥感影像自动配准方法,包括以下步骤：对多级遥感影像重采样为统一的分辨率；采用前期自适应粒子群算法粗略搜索和后期标准粒子群算法精细搜索进行多级分辨率影像的逐级配准；所有相邻级别分辨率影像的空间变换参数作乘积,输出结果即为待配准影像和参考影像的空间变换模型。本发明适用于遥感图像配准的问题,能够实现分辨率差异很大的待配准与参考影像在空间位置上的精确匹配,可以有效解决分辨率差异过大无法选取控制点进行配准的问题。</td>   <td>1.一种基于粒子群算法的多级分辨率遥感影像自动配准方法,其特征在于,包括以下步骤：S1：对遥感影像进行预处理,把相邻级别分辨率的影像依次重采样成相同的影像分辨率；S2：对已重采样处理后的最低级别分辨率待配准影像和次低级别分辨率参考影像的空间变换模型进行粗略搜索,初始化自适应粒子群,创建互信息的分布,设定最大的迭代次数T-(max)；S3：根据互信息的大小记录全局最优粒子和粒子历史最优位置,据此对每一个粒子的位置进行更新,迭代完成后进行下一步；S4：以粗略搜索得到的空间变换模型初始化标准粒子群进行精细搜索,创建互信息的分布,设定最大的迭代次数C-(max),每一个粒子的搜索步长随迭代次数递减；S5：精细搜索达到迭代次数后得到相邻级别分辨率影像的精准空间变换模型；S6：如果已完成所有相邻分辨率图像的配准,转到S7,否则转到S2,继续取下一相邻级别分辨率的两幅遥感影像进行配准；S7：以S6中获得的所有相邻级别分辨率影像的空间变换参数作乘积,输出结果即为待配准影像和参考影像的空间变换模型；在步骤S3中,当获取目标函数的最大值后,需要对自适应粒子群的所有粒子所在的位置进行更新,每个粒子的移动速度受三个因素的影响：粒子前一个时刻的速度、全局最优粒子的位置和粒子历史最优位置,其移动速度的公式为：V-i(t+1)＝ω·V-i(t)+C-1·rand·(p-(ib)-Z-i(t))+C-2·rand·(p-(gb)-Z-i(t))其中,V-i(t+1)是粒子i在t+1时刻的移动速度,V-i(t)是粒子i在t时刻的移动速度,Z-i(t)是粒子i在t时刻的位置,p-(ib)是粒子i的历史最优的位置,p-(gb)是全局最优粒子的位置；ω为惯性权重,即下一时刻的速度会在一定程度上受到上一时刻速度的影响；C-1和C-2分别为自身学习和社会经验的权重,rand为随机干扰因素,取值范围为0到1,ω、C-1和C-2的计算公式分别为：                            &amp;omega;          (      f      )        =          1              1        +        1.5                  e                      -            2.6            f                                &amp;Element;    &amp;lsqb;    0.4    ,    0.9    &amp;rsqb;   ]]>                                                    C      i        =                  C        i                              C          1                +                  C          2                      &amp;CenterDot;    4.0    ,    i    =    1    ,    2   ]]>                  其中f为进化因子,是评价全局粒子群的分布紧凑程度的函数,假设d-g为全局最优粒子到其余所有粒子位置的欧式距离的平均值,d-(min)为全局最优粒子到最近粒子的欧式距离,d-(max)为全局最优粒子到最远粒子的欧式距离,则f可定义为：                            f    =                            d          g                -                  d                      m            i            n                                                d                      m            a            x                          -                  d                      m            i            n                               ]]>                  因此,粒子最终的位置更新公式为：Z-i(t+1)＝Z-i(t)+V-i(t+1)。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         龚永义;              李可宏;              罗笑南;              关柏良;                   姜灵敏       </td>   <td>广东外语外贸大学;中山大学</td>   <td>基于网格变形的内容感知双目图像缩放方法</td>   <td>广东省</td>   <td>CN104166992B</td>   <td>2017-03-29</td>   <td>本发明公开了一种基于网格变形的内容感知双目图像缩放方法,步骤包括：A、输入原始左目视图和右目视图,并设定目标图像的分辨率；B、对左目视图和右目视图分别构造覆盖图像的均匀四边形网格；C、分别计算左、右目视图的网格级重要程度图；D、构造左、右目视图网格级直线特征集合；E、根据网格级重要程度图建立网格缩放能量函数；F、根据网格级直线特征集合建立直线特征约束,采用最小二乘法进行网格缩放能量函数最小化运算,得到缩放后的左、右目视图目标网格；G、采用贴图的方法将原始左、右目视图分别映射到目标网格,输出最终的左目视图和右目视图。本发明能够保留缩放后图像的直线特征,突出重要物体,并保持双目图像的立体信息。</td>   <td>1.一种基于网格变形的内容感知双目图像缩放方法,其特征在于,所述方法包括以下步骤：A、输入原始左目视图和右目视图,并设定目标图像的分辨率,确定双目图像在水平方向和垂直方向的缩放比例；B、对原始左目视图和右目视图分别构造覆盖图像的均匀四边形网格；C、对原始左目视图和右目视图分别计算左、右目视图的网格级重要程度图；D、利用Hough变换分别从左、右目梯度轮廓图识别直线特征,再将直线特征从像素级别映射到网格中,构造网格级直线特征集合；其中,网格级直线特征集合包括水平直线特征集合HL、垂直直线特征集合VL以及斜线特征集合OL；HL中每一条水平线经过的网格顶点的Y坐标均相同,VL中每一条垂直线经过的网格顶点X坐标均相同,OL中每一条斜线经过的网格顶点的X、Y坐标满足直线函数关系；E、根据步骤C得到的左、右目视图的网格级重要程度图,建立网格缩放能量函数；F、采用最小二乘法迭代求解网格缩放能量函数,将水平直线特征集、垂直直线特征集、斜线特征集上的网格顶点按照直线特征约束求出新的位置,更新网格顶点,保留直线特征,得到缩放后的左、右目视图目标网格；G、根据步骤F得到的左、右目视图目标网格,采用贴图的方法将原始左、右目视图分别映射到目标网格,输出最终的左目视图和右目视图。</td>   <td>G06T7/33;G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         胡建国;              谭宇泉;              李仕仁;                   白小楠       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;广州中大数码科技有限公司;中山大学</td>   <td>一种对二维条码精确定位的方法及装置</td>   <td>广东省</td>   <td>CN104298947B</td>   <td>2017-03-22</td>   <td>本发明公开了一种对二维条码精确定位的方法及装置,该方法包括：当图像传感器采集到二维图像后,对二维图像进行图像预处理；在图像预处理中完成二值化处理后,对二维图像进行精确定位,所述精确定位包括：依靠图像预处理后二维条码上黑白相间模块组成的图像特征对二维条码所在区域进行初步定位；对初步定位出的二维条码区域上进行二次遍历扫描,得到二维条码的四个顶点实现精确定位。本发明实施例依靠预处理后二维条码上黑白相间模块组成的独特图像特征,即有着明显的黑白轮廓线,从而尽可能较为精确地对二维条码所在区域进行初步定位；而最终定位是在上述初步定位出的二维条码区域上进行二次遍历扫描,最终实现精确定位。</td>   <td>1.一种对二维条码精确定位的方法,其特征在于,包括如下步骤：当图像传感器采集到二维图像后,对二维图像进行图像预处理；在图像预处理中完成二值化处理后,对二维图像进行精确定位,所述精确定位包括：依靠图像预处理后二维条码上黑白相间模块组成的图像特征对二维条码所在区域进行初步定位；对初步定位出的二维条码区域上进行二次遍历扫描,得到二维条码的四个顶点实现精确定位；其中：所述依靠图像预处理后二维条码上黑白相间模块组成的图像特征对二维条码所在区域进行初步定位包括：对经过二值化处理后的二维图像进行遍历扫描,首先定位出二维条码所在的水平区域,然后在定位出二维条码所在的垂直区域；其中：所述定位出二维条码所在的水平区域包括：从上往下扫描二维图像每一行,把每一行出现像素值从黑变白和从白变黑的变化次数用变化数组记录下来；将记录下来的变化次数大小使用堆排序算法对变化数组中的元素进行排序,以及利用行数组把排序后的数组中的元素所对应的行号记录下来；将变化数组中排在二维条码高度阈值常数前的元素提取出来,以及将行数组中排在二维条码高度阈值常数前的元素进行排序；按照顺序进行行行与行之间的判断,当判断行与行之间的距离在一个二维条码模块宽度以内,并且位于二维条码区域上时,记录下这两行的行号。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;              赖子舜;              洪福强;              丁浩宸;                   陈成       </td>   <td>中山大学</td>   <td>基于物联网的快递追踪派送方法</td>   <td>广东省</td>   <td>CN103955813B</td>   <td>2017-03-15</td>   <td>本发明公开了一种基于物联网的快递追踪派送方法,包括：通过第一智能终端识别快递件上的快递标签后获得对应的标签信息,并将该标签信息以及快递员识别码发送到服务器,服务器查找数据库中是否存在与标签信息匹配的标识号,若存在,获取对应的快递信息后判断该快递件是否已签收,若否,则继续执行；将快递员识别码作为快递信息的派件识别码并存储,同时将快件信息发送给第一智能终端；第一智能终端接收后,解析获得收件人的联系方式,向收件人发送派送通知；收件人接收派送通知后到取件地点签收快递件或通过物联网授权代领人到取件地点签收快递件。本发明使得快递件的派送更安全、方便、高效,可及时地对快递件进行追踪,可广泛应用于快递行业中。</td>   <td>1.基于物联网的快递追踪派送方法,其特征在于,包括：S1、通过第一智能终端识别快递件上的快递标签后获得对应的标签信息,并将该标签信息以及快递员识别码发送到服务器；S2、服务器查找数据库中是否存在与接收的标签信息匹配的标识号,若存在,则获取该标识号对应的快递信息后,根据快递信息中的签收状态判断该快递件是否已签收,若否,则继续执行步骤S3；S3、将接收的快递员识别码作为快递信息的派件识别码并存储,同时将快递信息中的快件信息发送给第一智能终端；S4、第一智能终端接收快件信息后,解析获得收件人的联系方式,进而向收件人发送派送通知；S5、收件人接收派送通知后到取件地点签收快递件或通过物联网授权代领人到取件地点签收快递件；所述快递信息包括快件信息、标识号、签收状态以及派件识别码；所述步骤S1中的快递标签是通过以下步骤生成后附着在快递件上的：S01、寄件人通过物联网的第三智能终端录入快件信息并上传到服务器；S02、服务器接收快件信息并对应生成唯一的标识号后,根据该快件信息和标识号生成对应的快递信息并存储到数据库中,同时将该标识号返回第三智能终端；S03、寄件人通过第三智能终端接收该标识号并在寄送快递件时将该标识号提供给快递员；S04、快递员通过第四智能终端将该标识号发送到服务器后,服务器接收该标识号并遍历所有快递信息,判断该标识号是否存在,若存在,则将该标识号对应的快递信息返回给第四智能终端；S05、第四智能终端接收到快递信息后将快递信息发送到标识生成设备,通过标识生成设备将该快递信息生成快递标签。</td>   <td>G06Q10/08;G06Q50/28;G06K17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         纪庆革;              何锐权;                   王福川       </td>   <td>中山大学;广州中大南沙科技创新产业园有限公司</td>   <td>一种基于复合势能场的人群疏散仿真系统</td>   <td>广东省</td>   <td>CN103995915B</td>   <td>2017-03-01</td>   <td>本发明提出一种基于复合势能场的人群疏散仿真系统,系统采用改进的势能场模型,通过将传统的采用狄利科雷边界条件的势能场与采用诺依曼边界条件的势能场线性组合,并将解决人与人之间避碰问题的局部势能场加入其中,得到复合势能场,结合行人的更新策略和对行人速度的控制方法,能根据实际场景布局,建立不同规模场景中在紧急情况下人员疏散的仿真系统。在人群仿真的过程中充分考虑运动个体的路径规划对疏散的影响,而势能场方法对于解决这一影响因素有一定的帮助。该系统在不同规模场景中的大量人员安全、快速疏散仿真研究中具有广泛的应用前景,能够查找场景中的设计缺陷,协助制定紧急情况执行方案,是一种比较经济可行的人群疏散仿真系统。</td>   <td>1.一种基于复合势能场的人群疏散仿真系统,其特征在于,构建复合势能场模型；结合行人的更新策略和对行人速度的控制方法,建立不同规模场景中在紧急情况下人群疏散的仿真系统；所述构建复合势能场模型是通过局部势能场与全局势能场加权平均得到的,具体方式为：采用狄利克雷边界条件和诺依曼边界条件的线性组合,通过设定不同λ值来找到一个平衡点以生成全局势能场P-W；P-W＝λP-D+(1-λ)P-N；其中P-D是用狄利克雷边界条件生产的势能场函数,P-N是用诺依曼边界条件生产的势能场函数；采用局部势能场解决人与人之间的避碰问题,为每个人局部设定一个X*X的视野,每一时刻都对X*X的网格进行与全局势能场相同的求解操作,即采用狄利克雷边界条件和诺依曼边界条件的线性组合,通过设定不同λ值来找到一个平衡点,从而得到局部势能场,其中将人当成障碍物,把X*X网格的边缘当作出口；设人当前处于某个位置,然后把人当前所处位置的势能值及临界的8个方向的势能值加上1得到局部势能场P-S,以该人所处位置为中心,其前、后、左、右、以及四个斜对角线方向位置的势能值为8个方向；再与全局势能场P-W加权平均就得到复合势能场P-(Total)：P-(Total)＝γP-S+(1-γ)P-W；其中γ为加权系数。</td>   <td>G06F17/50;G06Q50/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         丘晓青;              李昊东;              骆伟祺;                   黄继武       </td>   <td>中山大学;深圳大学</td>   <td>一种基于隐写分析的图像拼接篡改检测方法及装置</td>   <td>广东省</td>   <td>CN103914839B</td>   <td>2017-02-15</td>   <td>本发明公开一种基于隐写分析的图像拼接篡改检测方法及装置。其方法包括以下步骤：选取若干未经拼接篡改的图像作为原始图像,使用图像处理软件对原始图像,以图像拼接的方式对图像文件进行篡改,获取拼接篡改后的图像；使用高级隐写分析统计模型对原始图像和拼接篡改后的图像提取特征；根据得到的特征,用原始图像与拼接篡改后的图像对分类器进行训练,得到分类器模型；提取待测图像的特征,根据分类器模型判断待测图像是否被拼接篡改。本发明可以作为一种有效的手段将图像隐写分析方法应用于图像拼接篡改检测,对数字图像的真实性进行鉴别,从而为检测图像拼接篡改提供准确有效的自动化技术手段。</td>   <td>1.一种基于隐写分析的图像拼接篡改检测方法,其特征在于,包括以下步骤：S1：选取若干未经拼接篡改的图像作为原始图像,使用图像处理软件对原始图像,以图像拼接的方式对图像文件进行篡改,获取拼接篡改后的图像；S2：使用数字图像隐写分析富模型对原始图像和拼接篡改后的图像提取特征,具体包括以下步骤：(1)计算图像的残差矩阵：如果图像为彩色图象,首先将彩色图像转成灰度图像,或者选择彩色图像RGB通道的其中一个通道,分别利用线性和非线性滤波器,对图像进行滤波操作,分别得到不同的残差矩阵；(2)对得到的残差矩阵进行归一化：以q&gt;0的量化步长对残差矩阵进行量化,接着以T&gt;0对残差矩阵进行截断,只保留在[-T,T]范围的系数；(3)利用共生矩阵计算残差矩阵的统计特征：对于每个不同的残差矩阵,对于水平方向和垂直方向,分别利用共生矩阵统计同一方向相邻四个系数之间的相关性,得到四维度的共生矩阵系数；组合所有的共生矩阵系数特征,组织成向量形式,得到图像的富模型统计特征；S3：根据步骤S2中得到的特征,用原始图像与拼接篡改后的图像对分类器进行训练,得到分类器模型；S4：提取待测图像的特征,根据分类器模型判断待测图像是否被拼接篡改。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   黄立锋       </td>   <td>中山大学</td>   <td>基于服装图片的三维虚拟试衣方法</td>   <td>广东省</td>   <td>CN104123753B</td>   <td>2017-02-15</td>   <td>本发明涉及一种基于服装图片的三维虚拟试衣方法,使用服装图片作为输入数据的基础,通过结合虚拟人体模型的骨骼来提取所述服装图片中的服装信息,对所述服装进行属性设定,并结合机器学习算法与缝合自感应算法建立三维服装网格模型,最后将服装的图案与花纹一一映射至所述三维服装网格模型,完成三维物理仿真。本发明可以较好地解决二维服装样板数量过多,专业设计知识难以获取,缝合信息的设定复杂,降低良好的虚拟试衣体验等问题,并增加服装模型的真实感与表现力。对提高虚拟三维服装建模的质量和改善用户体验有重要意义。</td>   <td>1.一种基于服装图片的三维虚拟试衣方法,其特征在于：使用服装图片作为输入数据的基础,通过结合虚拟人体模型的骨骼来提取所述服装图片中的服装信息,对所述服装进行属性设定,并结合机器学习算法与缝合自感应算法建立三维服装网格模型,最后将服装的图案与花纹一一映射至所述三维服装网格模型,完成三维物理仿真；建立三维服装网格模型包括以下步骤：通过服装图片获得服装的前样板、后样板,对所述前样板、后样板均匀分段,分别获取轮廓点集；利用机器学习算法分别找到前样板、后样板中边与边的交点,即轮廓关键点；通过轮廓关键点将服装样板轮廓分为多条线段,再通过前样板、后样板间关键点的对应关系映射为前样板、后样板的轮廓边的对应关系；结合轮廓边与虚拟人体模型交叉信息得到样板的缝合信息；结合缝合信息,将前样板、后样板转为三维样片。</td>   <td>G06T17/00;G06Q30/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王莉;              梁栋;              吴泽鑫;              莫善军;                   余圣辉       </td>   <td>中山大学</td>   <td>一种电气火灾熔痕物证的自动鉴定方法</td>   <td>广东省</td>   <td>CN104156963B</td>   <td>2017-02-15</td>   <td>本发明公开了一种电气火灾熔痕物证的自动鉴定方法,包括以下步骤：1)金相图片预处理；2)图像特征提取；3)图像判定和识别。本发明基于支持向量机的电气火灾物证的金相图片识别和判断,确定电气火灾熔痕的性质,为火灾调查提供科学而有效的调查信息,避免了传统的人为经验的判断,可以使以后的火灾熔痕判断更加客观有效地进行。</td>   <td>1.一种电气火灾熔痕物证的自动鉴定方法,其特征在于,包括以下步骤：1)金相图片预处理1.1)图像灰度化彩色图像中每个像素点由R、G、B三个分量决定,每个分量有255个值,这样一个像素点有255×255×255个值可选,而灰度图是R、G、B三个分量是相同值的一种特殊彩色图片,所以每个像素点的可选值是255个；根据YUV的颜色空间,Y分量的物理意义是点的亮度,由该值反映亮度等级,根据RGB和YUV颜色空间的变化关系可建立亮度Y与R、G、B三个颜色分量的对应：Y＝0.3R+0.59G+0.11B,最后以这个亮度值表达图像的灰度值；1.2)图像的直方图处理对于一幅灰度图像,在[0,Y]内总共有L个灰度级,z-i是区间[0,Y]内的第i级亮度的灰度值,n-i表示灰度为z-i的图像中的像素数,n是图像中所有的像素总数,这样图像中灰度为z-i的像素出现概率是这个式子表达某亮度其灰度级为z-i出现的频数,p实际上是一个数字图像的直方图,将灰度级归一化到[0,1]的离散量；1.3)直方图的均衡化通过扩展输入图像的灰度级到较宽亮度范围的方式来实现图像增强,若P-r(r)表示原图像的PDF,用P-s(s)表示均衡化后图像的PDF,r,s分别表示均衡变化前后的灰度值,r,s属于[0,1],根据概率知识：公式中T～(-1)(S)代表T(r)的逆变换函数,因为要求的概率密度为1,即因此：进一步得出：ds＝p-r(r)·dr,等式两边对r积分,即可得到PDF的均衡化公式：公式中T(r)代表r的灰度变换函数,∫表示积分,w为假设变量,对于离散型灰度级表示为：图像经过直方图归一处理后,直方图的各值是图像取各灰度级的概率,对于离散的灰度级,其均衡化变换后图像中的亮度值为：                            S          (              z        i            )        =          &amp;Sigma;              j        =        0            i              P      r              (              z        j            )        ,    i    =    1    ,    2    ,    ...    L    ;   ]]>                  1.4)顶帽变换从原有的图像中减去开运算后的图像；2)图像特征提取包括均值,即平均亮度的度量；标准偏差,即平均对比度的度量；平滑度,即区域中亮度的相对平滑度度量；三阶矩,即度量直方图的倾斜；一致性,即度量一致性,当所有灰度值相等时,该度量值最大且从此处开始减小；熵,即随机性的度量；HOG描述子,即计算局部图像梯度的方向信息的统计值；3)图像判定和识别3.1)在提取金相图片的相关特征后,组成一个有标识的训练样本集,{(X-i,y-i)|X-i∈R～n,y-i∈{-1,1},i＝1,...,N},其中X-i＝(x-(i1),x-(i2),…,x-(i9))对应第i个样本的属性集,也就是特征集,y-i是它的标识号,其值不是-1就是1,这样就是一个包含N个训练样本的二元分类；3.2)低维度到高维度的转化基于低维度线性不可分,将低维度转化到高维度,从而实现决策边界在新高维空间是线性,选择多项式核函数K(x,y)＝(x·y+1)～p,设g(x)是一个具有有限L-2范数的函数,即∫g(x)～2dx＜∞,则：                                                                &amp;Integral;                                          (                x                &amp;CenterDot;                y                +                1                )                            p                        g                          (              x              )                        g                          (              y              )                        d            x            d            y                                                            =            &amp;Integral;                          &amp;Sigma;                              i                =                0                            p                                                                                            p                                                                                        i                                                                                                      (                x                &amp;CenterDot;                y                )                            i                        g                          (              x              )                        g                          (              y              )                        d            x            d            y                                                            =                          &amp;Sigma;                              i                =                0                            p                                                                                            p                                                                                        i                                                                        &amp;Integral;                          &amp;Sigma;                                                &amp;alpha;                  1                                ,                                  &amp;alpha;                  2                                ,                ...                                                                                                                                                                  i                                                                                                                                                                      &amp;alpha;                      1                                                                                                  &amp;alpha;                      2                                                                            ...                                                                        &amp;lsqb;                                                                                                      (                                              x                        1                                                                    y                        1                                            )                                                              &amp;alpha;                      1                                                                                                                                  (                                              x                        2                                                                    y                        2                                            )                                                              &amp;alpha;                      2                                                                                                                                  (                                              x                        3                                                                    y                        3                                            )                                                              &amp;alpha;                      3                                                                                        ...                                                      &amp;rsqb;            g                          (                              x                1                            ,                              x                2                            ,              ...              )                        g                          (                              y                1                            ,                              y                2                            ,              ...              )                                      dx              1                                      dx              2                        ...                          dy              1                                      dy              2                        ...                                                            =                          &amp;Sigma;                              i                =                0                            p                                      &amp;Sigma;                                                &amp;alpha;                  1                                ,                                  &amp;alpha;                  2                                ,                ...                                                                                                          p                                                                                        i                                                                                                                                                                                                    i                                                                                                                                                                      &amp;alpha;                      1                                                                                                  &amp;alpha;                      2                                                                            ...                                                                                                      &amp;lsqb;                &amp;Integral;                                  x                  1                                      &amp;alpha;                    1                                                                    x                  2                                      &amp;alpha;                    2                                                  ...                g                                  (                                      x                    1                                    ,                                      x                    2                                    ,                  ...                  )                                                  dx                  1                                                  dx                  2                                ...                &amp;rsqb;                            2                        &amp;GreaterEqual;            0                               ]]>                  积分结果非负,因此所选核函数满足Mercer定理；Mercer原理确保核函数在低维空间中的计算用高维空间中两个向量点积表示,又由于核函数是原属性空间中的相似度函数,故存在：K(x,y)＝Φ(x)·Φ(y)＝(x·y+1)～p,将原来的特征空间映射到一个新的高维空间,其属性集成为Φ(x),决策边界在这个空间为线性；3.3)假设决策边界函数在高维空间内,假设一个线性决策边界函数表达为：f(x)＝w·Φ(x)+b,其中,w和b是模型的参数,且任何位于决策边界上的样本都必须满足w·Φ(x)+b＝0；3.4)定义决策边界边缘考虑那些距离决策边界最近的数据,某些位于决策边界一边的数据,则存在关系：w·X-s+b≥0,位于决策边界另一边的数据,满足关系：w·X-x+b≤0,调整w和b,两个平行的超平面b-(i1)和b-(i2)表示为：b-(i1):w·X+b＝1b-(i2):w·X+b＝-1决策边界的边缘由这两个超平面之间的距离给出,令X-1是b-(i1)上的一个数据点,X-2是b-(i2)上的一个数据点,分别带入上两式,两式再相减得：w·(X-1-X-2)＝2,令X-1-X-2＝d,所以：3.5)估算参数w和b,确定决策边界在高维可分情况下,依据已有训练集和决策边界边缘的定义,估算边界函数的参数w和b,选择的参数必须满足下面的两个条件：如果y-i＝1,则w·X-i+b≥1,如果y-i＝-1,则w·X-i+b≤-1,将两个不等式概括为：y-i(w·X-i+b)≥1,i＝1,2,…,N,要求决策边界的边缘必须是最大的条件下,最大,等价为求目标函数：的最小值,也就是进一步概括等价形式为：且受限于y-i(w·X-i+b)≥1,i＝1,2,…,N,这是一个凸优化问题,通过拉格朗日乘子的方法进行求解：在考虑加在解上面的约束,将目标函数改写为拉格朗日函数：其中,η-i是拉格朗日乘子,拉格朗日函数将目标函数和不等式约束进行组合,将问题变为求解不违反不等式约束条件的可行解,按照一般求函数最小值的办法,拉格朗日函数对w和b求导后等于0,得到w和b的值：                                          &amp;part;                  L          P                            &amp;part;        w              =    0    &amp;DoubleRightArrow;    w    =          &amp;Sigma;              i        =        1            N              &amp;eta;      i              y      i              X      i       ]]>                                          ...</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>              陈佩       </td>   <td>中山大学</td>   <td>一种无特征提取的紧致SFM三维重建方法</td>   <td>广东省</td>   <td>CN103914874B</td>   <td>2017-02-01</td>   <td>本发明公开了一种无特征提取的紧致SFM三维重建方法,包括：输入关于某场景的n幅图像,n≥2；建立与某个相机坐标系相一致的世界坐标系；以三维场景的深度和相机投影矩阵作为变量,构造类似光流估计的目标函数,采用由粗到细的金字塔方法,设计迭代算法对目标函数进行优化,输出表示场景三维信息的深度和代表相机相对位姿信息的相机投影矩阵；根据表示场景三维信息的深度,实现紧致的射影、相似或者欧几里德重建。本发明能够一步完成紧致SFM三维重建。由于通过一步优化实现紧致三维信息的估计,以目标函数值作为指标,能够得到最优解,至少是局部最优解,比现有方法有很大改进,已初步得到实验验证。</td>   <td>1.一种无特征提取的紧致SFM三维重建方法,其特征在于,包括以下步骤：S1.输入关于某场景的n幅图像,n≥2；S2.建立与某个相机坐标系相一致的世界坐标系,设世界坐标系与第一相机的坐标系相一致,即世界坐标系的原点、x轴和y轴与第一相机的相机中心、第一相机成像平面的x轴和y轴重合,其z轴垂直指向第一相机的成像平面；S3.以三维场景的深度和相机投影矩阵作为变量,所述三维场景的深度是指第1幅图像像素点对应的三维空间点具有的深度q；所述相机投影矩阵是指其它(n-1)幅图像的3×4矩阵P-i,2≤i≤n；S4.构造类似光流估计的目标函数,所述目标函数是连续域上的变分目标函数或其离散形式的目标函数；S5.采用由粗到细的金字塔方法,在连续域或者离散域上设计迭代算法对目标函数进行优化,输出表示场景三维信息的深度和代表相机相对位姿信息的相机投影矩阵；S6.根据表示场景三维信息的深度,实现紧致的射影、相似或者欧几里德重建。</td>   <td>G06T17/00;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱炜湛;              陈健沛;              蔡志岗;              张吉;              温碧峰;                   伍俪璇       </td>   <td>广东互维科技有限公司;中山大学</td>   <td>红眼修复方法</td>   <td>广东省</td>   <td>CN104063850B</td>   <td>2017-02-01</td>   <td>视频红眼修复方法包括步骤A：对视频的每一帧图像进行边缘检测,以生成边缘图像；步骤B：对每一边缘图像进行形态学闭运算,以获取若干封闭的连通域；步骤C：获取每一连通域的圆度步骤D：获取每一连通域的面积；步骤E：获取每一连通域的平均灰度值；步骤F：判断每一连通域的圆度是否在预设的圆度阈值范围内,面积是否在预设的面积阈值范围内,平均灰度值是否在预设的平均灰度值阈值范围内,若均在对应的阈值范围内,执行步骤G；若三者中至少有一个不在对应的阈值范围内,执行步骤H；步骤G：认定该连通域为红眼区域,对红眼区域进行灰度替换处理；及步骤H：认定该连通域不是红眼区域。上述发明可消除视频的红眼。本发明还涉及相关系统。</td>   <td>1.一种红眼修复方法,其特征在于：其包括以下步骤：步骤A：对视频的每一帧图像进行边缘检测,以生成对应的边缘图像；步骤B：对每一边缘图像进行形态学闭运算,以获取若干封闭的连通域；步骤C：获取每一连通域的圆度；步骤D：获取每一连通域的面积；步骤E：获取每一连通域的平均灰度值；步骤F：判断每一连通域的圆度是否在预设的圆度阈值范围内,面积是否在预设的面积阈值范围内,平均灰度值是否在预设的平均灰度值阈值范围内,若三者均在对应的阈值范围内,则执行步骤G；若三者中至少有一个不在对应的阈值范围内,则执行步骤H；步骤G：认定该连通域为红眼区域,对红眼区域进行灰度替换处理,以消除红眼；以及步骤H：认定该连通域不是红眼区域；步骤G还包括以下子步骤：步骤G1：对该红眼区域进行膨胀操作,以生成在红眼区域外围的环状的矫正参考区域；步骤G2：计算该矫正参考区域的平均灰度值；以及步骤G3：将红眼区域的平均灰度值修改为对应矫正参考区域的平均灰度值的二分之一。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王海波;              蔡铭;                   余志       </td>   <td>中山大学</td>   <td>一种基于空间剖分的声线束追踪方法</td>   <td>广东省</td>   <td>CN103778657B</td>   <td>2017-01-25</td>   <td>本发明公开一种基于空间剖分的声线束追踪方法,是对现有声线束追踪法技术上的改进。具体过程为：采用四面体剖分对声音传播的全空间进行四面体剖分形成多个四面体空间,多个四面体空间构成四面体网格,为剖分后的四面体空间编号,四面体剖分技术符合声线束传播的空间几何规律；对四面体网格进行约束处理,恢复障碍物边界条件,并存储四面体网格各个要素；在剖分生成四面体网格后,对四面体空间采用递归方式的构建声线束树形结构；采用声线束追踪法在声线束树形结构中搜索所有节点并生成声音传播路径；对生成的声音传播路径计算声音衰减。本发明应用于复杂障碍物情况下三维声场的计算,可有效的解决高密度障碍物大区域声音计算时间效率过低的问题。</td>   <td>1.一种基于空间剖分的声线束追踪方法,其特征在于,包含以下步骤：(a)采用四面体剖分技术,对声音传播的全空间进行四面体剖分形成多个四面体空间,上述多个四面体空间构成四面体网格,为剖分后的四面体空间编号,上述四面体剖分技术符合声线束传播的空间几何规律；(b)对所述四面体网格进行约束处理,恢复障碍物边界条件,并存储四面体网格各个要素；(c)在剖分生成四面体网格后,对四面体空间采用递归方式的构建声线束树形结构；(d)采用声线束追踪法在声线束树形结构中搜索所有节点并生成声音传播路径；对生成的声音传播路径计算声音衰减；所述步骤(c)中采用递归方式构建声线束树形结构的具体方式为：采用逐点插入的方法,对于任意的点,找到距离该点最近的边,连接点和边构成一个平面,然后找到距离这个平面最近的点,形成一个初始四面体形,然后以此为基础向外扩展,直至所有点都被加入到构成的四面体网格中。</td>   <td>G06T15/06;G06T7/60</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杜晓荣;              平淑文;              武汇岳;                   张永       </td>   <td>中山大学</td>   <td>一种基于图像局部精确变形的人物五官变形方法</td>   <td>广东省</td>   <td>CN103824253B</td>   <td>2017-01-18</td>   <td>本发明公开了一种基于图像局部精确变形的人物五官变形方法。该方法预置了多种五官类型及五官变形模板,可自动生成变形控制点,并计算各控制点目标位置,实现多种常见的变形效果。在人脸图像变形过程中,该方法对已有的基于MLS的仿射变换变形函数做出改进,提出了一种图像精确变形的局部化处理技术；在控制点控制变形的基础上,通过设定控制区域,对MLS变形映射结果进行衰减计算,可在保证局部平滑变形的前提下,抑制图像边界处的混叠。该方法可实现人物五官精确变形,变形结果平滑,真实感强,且操作过程智能化,降低了用户操作复杂度；可广泛应用于广告、动画等领域。</td>   <td>1.一种基于图像局部精确变形的人物五官变形方法,其特征在于：其步骤包括：S1、导入原始图像文件；S2、控制点自动生成及定位步骤：S2.1将所述图像文件的目标变形区域设定为控制区域,绘制所述控制区域的边界；S2.2选择适当的五官类型,根据所述图像文件的图像信息及所述控制区域的边界信息,自动生成控制点；S2.3根据所述五官类型及目标变形效果,选择适当的变形模板,根据所述图像信息及所述各控制点的原始数据,自动计算该模板情况下各控制点的目标位置；S3、生成变形结果步骤：S3.1创建与所述原始图像等大小的空白目标图像；S3.2将所述目标图像切割为长宽为w×h的多个小矩形；S3.3计算出每个所述小矩形的四个顶点在原始图像上的对应位置；S3.4根据各所述小矩形的四个顶点在所述目标图像与所述原始图像上的位置对应关系,利用双线性插值填充目标图像上各矩形,即可得到目标变形图像。</td>   <td>G06T3/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱庆勇;              陈耀钦;                   颜益鹏       </td>   <td>中山大学</td>   <td>一种用于微电泳图像识别装置及其方法</td>   <td>广东省</td>   <td>CN103914695B</td>   <td>2017-01-11</td>   <td>本发明涉及微电泳识别的技术领域,更具体地,涉及一种用于微电泳图像识别装置及其方法。一种用于微电泳图像识别装置,其中,包括微电泳装置、与微电泳装置连接的用于观测带电颗粒位置的显微成像系统、与显微成像系统连接的用于采集颗粒的运动灰度图像的图像采集装置、与图像采集装置连接的计算机。本发明的装置简单,操作方便,成本低廉；其方法以高精度的数值方法处理带电颗粒的运动灰度图像,具有分辨率高、操作简单、成本低廉的特点。</td>   <td>1.一种用于微电泳图像识别方法,包括微电泳装置(1)、与微电泳装置(1)连接的用于观测带电颗粒位置的显微成像系统(2)、与显微成像系统(2)连接的用于采集颗粒的运动灰度图像的图像采集装置(3)、与图像采集装置(3)连接的计算机(4)；其特征在于,包括以下步骤：S1. 显微成像系统实时观测带电颗粒的位置,在给定的时间步长下对带电颗粒的位置进行拍照；S2. 图像采集装置采集颗粒的运动灰度图像；S3. 计算机读取不同时刻的灰度图像,通过高精度的计算程序计算出带电颗粒的准确位置,进而得到分散体系中带电颗粒的Zeta电位。</td>   <td>G06K9/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黄以华;                   陈小若       </td>   <td>广东顺德中山大学卡内基梅隆大学国际联合研究院;中山大学</td>   <td>基于动态时隙冲突跟踪树的RIFD防碰撞方法</td>   <td>广东省</td>   <td>CN103927506B</td>   <td>2017-01-11</td>   <td>本发明公开了一种基于动态时隙冲突跟踪树的RIFD防碰撞方法,该方法结合了动态时隙冲突跟踪树法和比特转换方法,在阅读器识别过程中对跟踪到的连续碰撞比特进行比特转换处理,避免了动态时隙冲突跟踪树法容易产生过多空闲时隙的缺点。新方法抑制了空闲时隙的产生,大幅度提升了系统识别速率和时隙利用效率,非常适合于标签数目大且变动频繁的RIFD应用系统中。</td>   <td>1.一种基于动态时隙冲突跟踪树的RIFD防碰撞方法,其特征在于,包括以下步骤：1)阅读器初始化查询前缀堆栈PS、替补队列CQ和碰撞状态堆栈CS；每轮查询开始时阅读器弹出堆栈PS和CS内的第一个数据分别赋给prefix和Cs,其中prefix表示查询前缀,Cs表示碰撞状态序列,向标签发送查询指令,并将时隙计数器SC初始化为0,设定基础应答时隙数T；2)与prefix匹配的标签根据Cs设定好基础应答时隙T和标签在本轮查询中的应答时隙r,将SC初始化为0,并在SC等于时隙r时向阅读器发送标识IDs；3)阅读器根据计数器执行如下操作：若SC&lt;T,跳转到步骤4)；若SC≥T,则跳转到步骤5)；4)阅读器对标签的应答信号进行跟踪：若阅读器检测到当前应答信号未发生碰撞,或者在当前应答中阅读器跟踪到的连续碰撞位数C′＜2,阅读器则采用动态时隙冲突跟踪树法进行处理；若连续碰撞位数C′≥2,阅读器向标签发送含有r-F、C′以及额外应答时隙e的特殊ACK信号,r-F表示首个碰撞位；并将新前缀写入替补队列CQ；然后阅读器的时隙计数器SC加1,跳转到步骤6)；其中动态时隙冲突跟踪树法的具体操作步骤为：阅读器在接收到连续碰撞位后的首个非碰撞位时立刻向标签发送ACK信号,将q-1 q-2 … q-k|D-C|r-(k+C+1)r-(k+C+2)…r-(F-1)存入堆栈PS,C′转换成二进制码并加上标志位1后存入堆栈CS,注意,其中若首个碰撞位r-F为标签IDs最末位时,阅读器收到末位后向标签发送ACK信号,将r-F设置为0和1,并识别这两个标签,对应的IDs为q-1 q-2 … q-k|D-C|r-(k+C+1)r-(k+C+2)…r-F,然后将SC加1并等待下一时隙到来；5)若CQ不为空,阅读器则弹出CQ中第一个数据,写入堆栈PS,并根据接收序列构成新的碰撞状态序列,写入堆栈CS,然后将SC加1；否则,跳转到步骤7)；其中构成新的碰撞状态序列是指等待标签应答转换比特c-1 c-2 … c-d,阅读器将接收到碰撞比特用1替换并在末尾加上比特1构成新的碰撞状态序列,然后存入堆栈CS；注意,若连续碰撞位到达末位,阅读器可根据收到的转换比特并结合STR即可识别出相应的标签ID；然后将SC加1并等待下一时隙到来；6)标签接收阅读器发送的ACK信号,将SC加1,若为普通ACK信号,则标签直接停止发送；若为特殊ACK信号,标签则停止发送,根据ACK信号再次设定应答时隙r＝e,并采用比特转换方法对连续碰撞位进行转换,等待发送转换比特；然后r＝SC的标签应答转到步骤3)；7)阅读器判断堆栈PS是否为空,如果不是,阅读器则取出PS中的第一条查询前缀和CS中的第一个数据,初始化SC并设定好T,开始新一轮查询,跳转到步骤2),否则,结束查询。</td>   <td>G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              陈玲;                   江倩殷       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种图像中对车辆进行定位与区域分割的方法与系统</td>   <td>广东省</td>   <td>CN103324935B</td>   <td>2016-12-28</td>   <td>本发明公开了一种图像中对车辆进行定位与区域分割的方法与系统,方法包括：从采集设备获取原始图像；采用Harris角点和水平边缘直线段对所述原始图像内的车辆图像区域进行定位,从而得到定位后的车辆图像；对定位后的车辆图像进行彩色显著区提取、显著平滑区提取以及水平边缘稀疏区与密集区提取；根据提取的结果和先验知识对车辆的典型区域进行定位,从而分割出发动机机罩区域、车脸区域以及车窗区域。本发明的方法在对车辆进行定位时能同时对多车辆进行定位,效率高,且准确率可达95%以上；在对车辆进行区域分割时,能有效消除挡风玻璃反光效果、光照不均和污染等因素的干扰,鲁棒性较好。本发明可广泛应用于图像处理领域。</td>   <td>1.一种图像中对车辆进行定位与区域分割的方法,其特征在于,包括：A、从采集设备获取原始图像；B、采用Harris角点和水平边缘直线段对所述原始图像内的车辆图像区域进行定位,从而得到定位后的车辆图像；C、对定位后的车辆图像进行彩色显著区提取、显著平滑区提取以及水平边缘稀疏区与密集区提取；D、根据提取的结果和先验知识对车辆的典型区域进行定位,从而分割出发动机机罩区域、车脸区域以及车窗区域；所述步骤C中对定位后的车辆图像进行彩色显著区提取这一步骤,其包括：C11、计算出定位后的车辆图像灰度化后像素点的像素值,所述灰度化后像素点的像素值的计算公式如下：                            I          (      x      ,      y      )        =                  r                  (          x          ,          y          )                +        g                  (          x          ,          y          )                +        b                  (          x          ,          y          )                    3        ,   ]]>                  上式中,(x,y)为像素点,I(x,y)为灰度化后像素点(x,y)的像素值,r(x,y)、g(x,y)和b(x,y)分别为I(x,y)的红、绿和蓝分量；C12、根据计算出的像素点像素值对定位后的车辆图像的彩色显著值进行计算,所述彩色显著值的计算公式如下：                                  S      c              (      x      ,      y      )        =          &amp;Sigma;              i        =        1            3              (              c        i            (              x        ,        y            )      -      I      (              x        ,        y            )      )        ,   ]]>                  上式中,S-c(x,y)为像素点(x,y)的彩色显著值,C-i(x,y)为像素点(x,y)在彩色空间一个通道的像素值,I(x,y)为步骤C11计算出的像素值；C13、根据计算出的灰度化后像素点像素值和彩色显著值提取出定位后的车辆图像的彩色显著区；所述步骤C中对定位后的车辆图像进行显著平滑区提取这一步骤,其包括：C21、对定位后的车辆图像进行灰度化处理,从而得到灰度图；C22、采用Canny算子对得到的灰度图进行二值化处理,从而得到Canny边缘二值图；C23、采用网格法统计Canny边缘二值图中任一个网格内边缘点的数目；C24、判断任一个网格内边缘点的数目是否小于预设的阈值,若是,则表明该网格所代表的图像区域位于显著平滑区内,反之,则表明该网格所代表的图像区域位于非显著平滑区内；所述步骤C中对定位后的车辆图像进行水平边缘稀疏区与密集区提取这一步骤,其包括：C31、对定位后的车辆图像进行灰度化处理,从而得到灰度图；C32、采用Canny算子对得到的灰度图进行二值化处理,从而得到Canny边缘二值图；C33、对Canny边缘二值图进行水平边缘提取,从而提取出Canny边缘的水平边缘点；C34、对所述水平边缘点的水平投影值进行滑动平均滤波和阈值抑制处理,从而生成由水平边缘点的密集行和稀疏行组成的二值向量；C35、对生成的二值向量进行带宽变换,然后根据带宽变换的结果和阈值条件区分出水平边缘稀疏区和水平边缘密集区。</td>   <td>G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;                   陈玲       </td>   <td>中山大学;广东方纬科技有限公司</td>   <td>一种车辆遮阳板状态的检测方法及系统</td>   <td>广东省</td>   <td>CN103440647B</td>   <td>2016-12-07</td>   <td>本发明公开了一种车辆遮阳板状态的检测方法及系统,方法包括：获取检测图像；对检测图像进行灰度预处理,从而得到灰度图像；对灰度图像进行主要连通区域提取,并计算主要连通区域的几何特征和矩形相似程度；对灰度图像进行水平长边缘提取,并将水平长边缘与主要连通区域进行特征匹配,从而得到区域边缘匹配关系；根据区域边缘匹配关系、主要连通区域的几何特征和主要连通区域的矩形相似程度对遮阳板的状态进行判定。本发明基于数学形态学和连通域理论,综合利用主要连通区域的几何特征、主要连通区域的矩形相似程度和区域边缘匹配关系来对遮阳板的状态进行检测,检测效率和检测精度高,实用性高。本发明可广泛应用于图像处理领域。</td>   <td>1.一种车辆遮阳板状态的检测方法,其特征在于,包括：A、获取检测图像；B、对检测图像进行灰度预处理,从而得到灰度图像；C、对灰度图像进行主要连通区域提取,并计算主要连通区域的几何特征和矩形相似程度；D、对灰度图像进行水平长边缘提取,并将水平长边缘与主要连通区域进行特征匹配,从而得到区域边缘匹配关系；E、根据区域边缘匹配关系、主要连通区域的几何特征和主要连通区域的矩形相似程度对遮阳板的状态进行判定；所述步骤E,其包括：E1、根据区域边缘匹配关系判断主要连通区域是否存在着匹配边缘,若不存在,则执行步骤E2,反之,则执行步骤E3；E2、根据主要连通区域的几何特征和水平长边缘判断主要连通区域的位置关系是否正确,若是,则执行步骤E3,反之,则执行步骤E5；E3、判断主要连通区域的矩形相似程度是否符合预设的阈值条件,若是,则执行步骤E4,反之,则执行步骤E5；E4、判定车辆遮阳板的状态为遮阳板已被放下,并记录灰度图像中遮阳板的位置；E5、判定车辆遮阳板的状态为遮阳板未被放下。</td>   <td>G06T7/00;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         徐颂华;              周凡;              邓伟财;                   盛建强       </td>   <td>中山大学</td>   <td>基于核函数与稀疏编码的高清图像分类方法</td>   <td>广东省</td>   <td>CN103177265B</td>   <td>2016-09-14</td>   <td>本发明公开了一种基于核函数与稀疏编码的高清图像分类方法,包括以下步骤：提取每张高清图像的视觉特征；对所述的视觉特征进行核函数映射,将视觉特征的欧氏空间变换成度量空间；根据所述变换后的视觉特征生成高清图像类别的稀疏编码；依据所述的高清图像类别的稀疏编码建立图像非线性分类器,对每个特征赋予权值,确定所述高清图像所属的类别。本发明能够通过视觉特征的核函数映射,自动地根据特征的相关性赋予权值,提高强相关性的特征对分类能力的影响,并利用核方法减少分类过程的运算时间,大大减少了计算量,有效地提高分类的效率,使分类方法对高清图像数据集的样本空间分布具有较强的自适应性,对复杂的图像具有更好的鲁棒性。</td>   <td>1.一种基于核函数与稀疏编码的高清图像分类方法,其特征在于,包括以下步骤：提取每张高清图像的视觉特征；对视觉特征的欧氏空间进行核函数映射；根据变换后的视觉特征生成高清图像类别的稀疏编码；依据所述的高清图像类别的稀疏编码建立图像非线性分类器,确定所述高清图像所属的类别；其中：根据变换后的视觉特征生成高清图像类别的稀疏编码包括：定义高清图像相互间的线性表示为                  定义高清图像的重构误差为                  根据重构误差最优化和编码尽量稀疏原则,确定高清图像类别的稀疏编码；根据重构误差最优化和编码尽量稀疏原则,确定高清图像类别的稀疏编码的步骤包括：高清图像的稀疏编码矩阵      R    =    &amp;lsqb;          r      j      k        &amp;rsqb;    ,    k    =    1    ,    2    ,    ...    K    ;    j    =    1    ,    2    ,    ...    ,    J    ,   ]]>为第j个类别的第k个特征的稀疏编码,K为所述视觉特征的数量,J为高清图像的类别数,则稀疏编码矩阵R应满足                  其中,为第k个视觉特征的核函数映射,为第j个类别的高清图像训练样本集的第k个视觉特征的特征向量,为第j个类别的高清图像的稀疏编码,μ为平衡参数,y～k为某个高清图像的第k个视觉特征的特征向量；依据所述的高清图像类别的稀疏编码建立图像非线性分类器,确定所述高清图像所属的类别的步骤包括：确定高清图像的K个视觉特征的权重w～k(k＝1,2,…K)；根据所述的稀疏编码矩阵R和视觉特征的权重向量w～k(k＝1,2,…K),构建高清图像非线性分类器为：                  其中,y～k为待分类的高清图像样本的第k个视觉特征的特征向量；为第i个高清图像样本的重构误差。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王国利;              刘佟;                   郭雪梅       </td>   <td>中山大学</td>   <td>一种压缩红外感知实现的手势识别装置及识别方法</td>   <td>广东省</td>   <td>CN103020656B</td>   <td>2016-09-14</td>   <td>本发明公开一种压缩红外感知实现的手势识别装置及识别方法,手势识别装置用热释电红外传感器阵列,采用随机编码方式对装在热释电传感器前的菲涅尔透镜组中的子视场进行可见性调制,将手势运动产生的高维红外辐射状态随机压缩投影到低维热释电红外传感阵列测量空间,实现手势运动特征的获取。手势识别的方法采用矢量量化为每个具有特殊动作的语义运动特征序列做特征参数估计,通过训练数据为每个特征序列分配一个码本作为语义表达模板,由分类器对测试数据表示语义进行决策,实现手势行为的识别。通过压缩红外感知,有效避免手势运动特征获取对冗余和无效信息的产生和处理过程,显著降低传感系统的复杂度和硬件成本,支持轻量手势识别算法的实现。</td>   <td>1.一种压缩红外感知实现的手势识别装置,其特征在于,包括用于获取手势运动特征数据的热释电红外传感器阵列和用于调制热释电红外传感器视场的经由掩模处理的菲涅尔透镜组,所述每个热释电红外传感器前安装一个菲涅尔透镜组；所述菲涅尔透镜组由N 个子透镜构成,形成的热释电红外传感器视场由N 个子透镜的子视场组成；所述菲涅尔透镜组采用随机编码的掩模调制热释电红外传感器的N 个子视场的可见性。</td>   <td>G06K9/66;G01J5/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              赖永周;                   冯展祥       </td>   <td>中山大学</td>   <td>基于SVM学习的人脸图像磨皮取证方法</td>   <td>广东省</td>   <td>CN103413153B</td>   <td>2016-09-14</td>   <td>本发明公开了一种基于SVM学习的人脸图像磨皮取证方法,包括：(1)训练阶段：对训练集中每张人脸图像提取图像内容不相关特征,对特征进行规范化形成训练样本的特征集,然后将特征向量输入LIBSVM进行训练,从而建立SVM模型；(2)取证阶段：对于测试输入人脸图像,提取图像内容不相关特征,对特征进行规范化,然后送入训练好的SVM模型,得出取证结果。本发明充分利用磨皮处理的先验信息,还引进了一种图像质量失真评价标准,构造了图像内容不相关特征,设计了SVM分类器,SVM分类器不需要原始图像,能够利用人脸图像经过磨皮处理后留下的痕迹提取分类器特征,能够更加准确、全面地获得人脸图像磨皮取证结果。</td>   <td>1.基于SVM学习的人脸图像磨皮取证方法,其特征在于,包括以下步骤：(1)训练阶段：对训练集中每张人脸图像均分别提取图像内容不相关特征,然后对提取的特征进行规范化形成训练样本的特征集,然后将特征集中的特征向量输入SVM分类器进行训练,从而建立SVM模型；其中,选取以下4个统计量作为图像内容不相关特征构造的基础：RGB颜色空间下,设位置为(i,j),第k个通道为C-k(i,j),i、j＝1,2...N,k＝1,2,3,设C(i,j)和分别表示原图像以及参考图像的颜色像素向量,则范数为：      |    |    C          (              i        ,        j            )        |    |    =                            C          1                                      (                          i              ,              j                        )                    2                +                  C          2                                      (                          i              ,              j                        )                    2                +                  C          3                                      (                          i              ,              j                        )                    2                      ;   ]]>内积为：      &lt;    C          (      i      ,      j      )        ,          C      ^              (      i      ,      j      )        &gt;    =          C      1              (      i      ,      j      )                      C        ^            1              (      i      ,      j      )        +          C      2              (      i      ,      j      )                      C        ^            2              (      i      ,      j      )        +          C      3              (      i      ,      j      )                      C        ^            3              (      i      ,      j      )        ;   ]]>角相关度量的一阶统计量为      cos          (              &amp;theta;                  i          j                    )        =                  &lt;        C                  (                      i            ,            j                    )                ,                  C          ^                          (                      i            ,            j                    )                &gt;                    |        |        C                  (                      i            ,            j                    )                |        |        |        |                  C          ^                          (                      i            ,            j                    )                |        |              ,   ]]>            d      1        =          u      &amp;theta;        =          1              N        2                    &amp;Sigma;              i        ,        j        =        0                    N        -        1              |    c    o    s          (              &amp;theta;                  i          j                    )        |    ,          d      2        =                  &amp;lsqb;                  1                      N            2                                    &amp;Sigma;                      i            ,            j            =            0                                N            -            1                                                (            c            o            s            (                          &amp;theta;                              i                j                                      )            -                          u              &amp;theta;                        )                    2                &amp;rsqb;                    1        /        2              ;   ]]>同理,Czenakowski度量的一阶统计量为            &amp;chi;              i        j              =                  2        &lt;        C                  (          i          ,          j          )                ,                  C          ^                          (          i          ,          j          )                &gt;                    |        |        C                  (          i          ,          j          )                |        |        +        |        |                  C          ^                          (          i          ,          j          )                |        |              ,   ]]>            d      3        =          u      &amp;chi;        =          1              N        2                    &amp;Sigma;              i        ,        j        =        0                    N        -        1              |          &amp;chi;              i        j              |    ,          d      4        =                  &amp;lsqb;                  1                      N            2                                    &amp;Sigma;                      i            ,            j            =            0                                N            -            1                                                (                          &amp;chi;                              i                j                                      -                          u              &amp;chi;                        )                    2                &amp;rsqb;                    1        /        2              ;   ]]>d-1、d-2、d-3、d-4这四个统计量,即为输入到SVM分类器的特征向量；(2)取证阶段：对于测试输入人脸图像,提取该图像的图像内容不相关特征,对特征进行规范化,然后送入训练好的SVM模型,得出取证结果。</td>   <td>G06K9/66</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              邓伟财;              徐颂华;                   陈湘萍       </td>   <td>中山大学</td>   <td>一种基于字典学习的高清图像分类方法</td>   <td>广东省</td>   <td>CN103258210B</td>   <td>2016-09-14</td>   <td>本发明公开了一种基于字典学习的高清图像分类方法,涉及数字图像处理领域。本发明的方法包括：提取所有高清图像样本的视觉特征；对于所述的视觉特征,对高清图像样本进行稀疏编码,通过迭代方法不断进行字典学习,直到分类误差小于阈值,确定高清图像类别的分类字典和根据视觉特征对重构误差的影响度确定对应的权值；依据所述的高清图像类别的字典和视觉特征对应的权值建立图像非线性分类器,确定所述高清图像所属的类别。本发明能够通过稀疏编码进行字典学习,获得具有较高区分度的稀疏编码,从而使分类方法对高清图像数据集的样本空间分布具有较强的自适应性,对复杂的图像具有更好的鲁棒性,具有很强的通用性和较高的实用价值。</td>   <td>1.一种基于字典学习的高清图像分类方法,其特征在于,包括如下步骤：提取每张图像的颜色、纹理、形状、方向梯度直方图、词袋特征、尺度不变特征转换特征作为其视觉特征X＝[x-1,…,x-k],k为视觉特征的数量；对于所述的视觉特征,对高清图像样本进行稀疏编码,通过迭代方法不断进行字典学习,直到分类误差小于阈值,确定高清图像类别的分类字典和根据视觉特征对重构误差的影响度确定对应的权值；依据所述的高清图像类别的字典和视觉特征对应的权值建立图像非线性分类器,确定所述高清图像所属的类别；其中,对高清图像样本进行稀疏表示,得到图像样本相应的稀疏编码的过程包括：对于高清图像的每一类别样本,其稀疏编码矩阵为第p个类别的第j个图像样本的稀疏编码,C为高清图像样本的类别数,m-p为第p个类别的样本数,t为迭代次数,则稀疏编码矩阵A应满足                                  &amp;Sigma;                        {                      D                          p              ,              t                                ,                      A                          p              ,              t                                }                          p          =          1...          C                            &amp;Sigma;              p        =        1            C        {                  ||                              X            p                    -                      D                          p              ,              t                                &amp;CenterDot;                      A                          p              ,              t                                      ||            2      2        +    &amp;lambda;          &amp;Sigma;              i        =        1                    m        p                    ||              &amp;alpha;        i                  p          ,          t                    ||        }   ]]>                  其中,D～(p,t)为分类字典,λ为平衡参数,X～p为初始化字典。</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              陈荣军;              徐秀峰;              熊文婷;                   朱雄泳       </td>   <td>中山大学</td>   <td>一种基于最小描述长度的多尺度图像弱边缘检测方法</td>   <td>广东省</td>   <td>CN103440644B</td>   <td>2016-09-07</td>   <td>本发明公开了一种基于最小描述长度(Minimum Description Length,MDL)原则的自适应多尺度图像弱边缘检测方法,首先,利用多尺度高斯平滑构造线性尺度空间；然后,计算图像的局部描述长度,利用最小描述长度原则确定最佳局部平滑尺度；最后,对局部平滑后的图像进行边缘检测,得到弱边缘图像的全部边缘。本发明能有效地滤除常见噪声和提取真实的弱边缘,避免边缘断裂、偏移和虚假边缘响应等现象,而且本发明中的算法为非迭代地滤波方式,不仅极大地提高运算速度,还使得算法的稳定性大为增强。</td>   <td>1.一种基于最小描述长度的多尺度图像弱边缘检测方法,其特征在于,该方法包含以下步骤：a)对图像的预处理,包括对图像进行灰度化与边缘增强,提高图像中的弱边缘的对比度；b)构造线性尺度空间；c)计算图像的局部描述长度；d)采用最小描述长度MDL原则确定局部区域的最佳平滑尺度；e)对图像中的每个点采用局部区域的最佳平滑尺度滤除噪声保持边缘；f)对平滑后的图像进行边缘检测,得到图像的全部边缘；步骤d)包括：d1)利用最小描述长度原则作为方差σ的选取标准；对于一般高斯平滑过程,可用下面的公式描述：                  其中ε-σ为残差,表示原图像与平滑后的图像之间差值；d2)先将最小描述长度应用于图像平滑,然后定义长度描述算子(dl),则上述平滑过程可重新表示为：                                  dl                        I          0                          (          x          ,          y          )                      =          dl                        I          &amp;sigma;                          (          x          ,          y          )                      +          dl                        &amp;epsiv;          &amp;sigma;                          (          x          ,          y          )                     ]]>                  d3)计算I-σ的描述长度对于任意的σ大于0,当σ→∞时,I-σ的信息量最小,以比特数来衡量信息的长度,I-0的描述长度远大于I-σ,以低通滤波器表示信息采样模型：由傅里叶变换可知,振幅为a的信号在空间域和频域之间满足缩放原理,从而得到：                            F    {    s          (      a      x      )        }    =          1      a        S          (              f        a            )        ;    a    &amp;NotEqual;    0   ]]>                  对于满足高斯分布的图像信号,空域和频域之间满足如下关系：                                  e              (        -                                            &amp;omega;              2                                      &amp;sigma;              2                                2                )              =          e              (        -                              x            2                                2                          &amp;sigma;              2                                      )              ,          &amp;sigma;      2        &amp;NotEqual;    0   ]]>                  由上式可见,高斯分布的空间尺度与频域的尺度成反比,即由抽样定理可知,若原始信号的最高频率为f,采样频率至少为2f,而高斯滤波器的σ-ω决定最高采样频率,因此,采样信息可重新表示为：                            s    =    n          (              &amp;alpha;&amp;sigma;        &amp;omega;        2            )        ;    n    &amp;GreaterEqual;    2   ]]>                  其中α为比例常量,结合频域与空域之间的反比关系,得到的空间尺度与频域尺度的反比关系：                            s    =    n          (              &amp;alpha;                  &amp;sigma;          x          2                    )        ,    n    &amp;GreaterEqual;    2   ]]>                  由上式可知s∝bits,若给定常量β表示某一个精确值,以bit数表示I-σ的信息量,将上述关系具体表示为：                                  dl              I        &amp;sigma;              =    n          (                        &amp;alpha;          &amp;beta;                          &amp;sigma;          x          2                    )        ;    n    &amp;GreaterEqual;    2   ]]>                  d4)ε-σ的描述长度依据中心极限定理,它的概率密度分布会近似满足零均值的高斯分布,噪声的概率分布函数可以用下式表示：                                  P      r              (      &amp;epsiv;      )        =          e              -                              &amp;epsiv;            2                                2                          &amp;sigma;              &amp;epsiv;              2                                           ]]>                  其中表示噪声方差,而ε～2表示原始图像I-0与平滑后的图像I-σ之间的二次残差,用对数log-2来表示上式,得到残差的信息量的描述长度如下所示                                  dl              &amp;epsiv;        &amp;sigma;              =    k          (                        &amp;epsiv;          2                          2                      &amp;sigma;            &amp;epsiv;            2                              )       ]]>                  其中定义信息长度和后,局部信息的描述长度可以表示为：                                  dl              I        0              =    n          (                        &amp;alpha;          &amp;beta;                          &amp;sigma;          x          2                    )        +    k          (                        &amp;epsiv;          2                          2                      &amp;sigma;            &amp;epsiv;            2                              )       ]]>                  由此,简化后得到：                                  dl              I        0              =          (              &amp;lambda;                  &amp;sigma;          x          2                    )        +          &amp;epsiv;      2       ]]>                  其中,所有参数均大于0。</td>   <td>G06T7/00;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              谢林华;                   马侠霖       </td>   <td>中山大学</td>   <td>建立基于暴露人群\面积\声环境功能区的交通噪声污染模型的方法</td>   <td>广东省</td>   <td>CN103440411B</td>   <td>2016-08-24</td>   <td>本发明公开了一种建立基于暴露人群\面积\声环境功能区的交通噪声污染模型的方法,该模型是在分析现有交通噪声评价模型和方法的基础上,根据交通噪声主观感受性和污染局部性的特点,综合考虑交通噪声对暴露人群数量、暴露区域面积和各类声环境功能区的影响程度差异上所提出的,并以已有城区城市交通噪声污染总量T-(NPI)、已有城区人均交通噪声污染指数A-(NPI)、待建城区交通噪声污染总量TP-(NPI)和待建城区平均交通噪声污染指数AP-(NPI)四种模型来适应不同需求下交通噪声污染的评价,且对A-(NPI)进行分级表征。本评价模型量化了噪声污染的大小,更加直观的评价城区噪声污染程度,可作为交通噪声超标排放的惩罚依据。</td>   <td>1.一种建立基于暴露人群\面积\声环境功能区的交通噪声污染模型的方法,其特征在于,包括以下步骤：S1.划分人口密度等级区域,判别各区域的声环境功能区,并以声环境功能区划分小区域；获取交通流基础信息和道路与建筑物的属性信息,根据交通流基础信息和道路与建筑物的属性信息渲染交通噪声地图；S2.根据S1中参数获取各个小区域的暴露面积s-i、暴露人群数量n-i和超标噪声声级ΔL-(Ai),所述暴露面积是指暴露在超过声环境功能区规定的噪声允许值的区域面积,所述暴露人群数量是指暴露在超过声环境功能区规定的噪声允许值的人口数量,所述超标噪声声级ΔL-(Ai)是指所有超过声环境功能区规定噪声值的超标部分的加权平均值；S3.根据暴露面积s-i、暴露人群数量n-i和超标噪声声级ΔL-(Ai)建立交通噪声污染模型NPI,交通噪声污染模型NPI包括已有城区交通噪声污染模型和待建城区交通噪声污染模型；所述已有城区交通噪声污染模型包括已有城区城市交通噪声污染总量T-(NPI)和已有城区人均交通噪声污染指数A-(NPI)；所述待建城区交通噪声污染模型包括待建城区交通噪声污染总量TP-(NPI)和待建城区平均交通噪声污染指数AP-(NPI)；已有城区城市交通噪声污染总量T-(NPI)是指以超标噪声声级ΔL-(Ai)作为因子,累加噪声对每个人的影响,其中n-i为各个小区域的暴露人群数量,ΔL-(Ai)为各个小区域的超标噪声声级；已有城区人均交通噪声污染指数A-(NPI)：其中待建城区交通噪声污染总量TP-(NPI)是指以超标噪声声级ΔL-(Ai)作为因子,累加噪声对每块区域的影响,s-i为各个小区域的暴露面积；待建城区平均交通噪声污染指数AP-(NPI),其中所述已有城区是指有人居住的城区,待建城区是指未投入兴建的、处于设计阶段的城区或者已经建成但暂时无人居住的城区。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王泳;                   黄继武       </td>   <td>中山大学;深圳大学</td>   <td>一种伪装声音的识别方法及装置</td>   <td>广东省</td>   <td>CN103730121B</td>   <td>2016-08-24</td>   <td>本发明公开一种伪装声音的识别方法及装置,该识别方法是利用语音的基频特性估计语音转换的系数,并对Mel频率倒谱系数提取算法进行了改进,即利用线性插值伸缩将估计的系数整合到Mel频率倒谱系数提取算法中,使其能近似计算出转换语音在转换前的Mel频率倒谱系数。最后,将以上方法整合到GMM-UBM(高斯混合模型-一致背景模型)识别框架中,计算语音之间的相似度。同时,还能利用该估计的转换系数将转换后的语音还原为原语音。本发明在识别性能上相比常规识别取证方法有极大的提高,漏检和虚警皆比常规的方案要低。</td>   <td>1.一种伪装声音的识别方法,其特征在于,所述方法包括：在训练阶段,利用最大期望值EM算法从背景语音库中计算一致背景模型UBMλ-(bkg)；在训练阶段,提取说话人j的测试语音S-j的Mel倒谱系数MFCC及基频,利用最大后验概率MAP算法计算说话人j的高斯混合模型GMMλ-j,计算基频平均值f-j；建立说话人j的模型V-j＝(λ-j,f-j),并存储在模型数据库中；在训练阶段获得阈值θ,阈值θ获取方法：计算客户分数及假冒者分数,利用这两类分数的分布选择阈值θ以达到符合应用要求的漏检率和虚警率,其中客户分数Client Scores,是说话人语音片段在说话人模型下的概率,假冒者分数Imposter Scores,是说话人语音片段在其它说话人模型下的概率；在测试阶段,语音Y为经过转换后的语音,提取语音Y的基频平均值f-Y；利用f-Y/f-j计算转换系数；利用改进型MFCC提取算法计算Y转换前的原始MFCC系数X；经基于GMM-UBM的概率估计算法得出Y为模型V-j的概率Λ(X)；比较概率Λ(X)与阈值θ,若所得概率大于阈值θ则语音Y为j所说片段；否则语音Y不为j所说；其中所述改进型MFCC提取算法具体为：在MFCC提取算法中的加窗和FFT变换之后,对FFT系数的幅值|F(k)|进行线性插值伸缩得出|F(k′)|,FFT系数的幅值线性插值伸缩如下公式所示：|F(k′)|＝μ|F(k)|+(1-μ)|F(k+1)| 0≤k&lt;N/2 0≤k′&lt;N/2                  μ＝k′/(1/α′)-k其中1/α′为估计的转换系数的倒数,α′为估计的转换系数,α′＝f-Y/f-j。</td>   <td>G10L17/04</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邓龙腾;              罗笑南;              薛凯军;                   肖剑       </td>   <td>东莞中山大学研究院;中山大学</td>   <td>一种基于距离加权最小折叠代价的三维模型边折叠简化的方法</td>   <td>广东省</td>   <td>CN103295266B</td>   <td>2016-08-17</td>   <td>本发明公开了一种基于距离加权最小折叠代价的三维模型边折叠简化的方法,包括如下步骤：读取三维模型的obj文件,求出平均起伏权值,确定参考阈值；根据模型文件中点的次序循环遍历模型中的顶点v；通过将v的顶点起伏权值与参考阈值进行比较；遍历该顶点v的所有相邻顶点；计算出该顶点与所有相邻非特征顶点之间的距离,求和并算出平均距离以及每个相邻顶点的距离比值；对每一对顶点都模拟进行边折叠操作；选择折叠代价最小的那对候选顶点对作为进行边折叠操作的输入；将简化后保留的顶点及面片信息保存到新的obj文件中。通过实施本发明,能够尽量减少简化模型产生狭长三角面片的出现,从而尽量保持了原始模型的拓扑结构和特征点。</td>   <td>1.一种基于距离加权最小折叠代价的三维模型边折叠简化的方法,其特征在于,包括如下步骤：步骤一：读取三维模型的obj文件,求出平均起伏权值,确定参考阈值；步骤二：根据三维模型的obj文件中点的次序循环遍历模型中的顶点v,全部遍历完则进入步骤八,否则进入步骤三；步骤三：通过将顶点v的顶点起伏权值与参考阈值进行比较,判断该点是否是特征点,是则进入步骤二；否则进入步骤四；步骤四：遍历该顶点v的所有相邻顶点,识别出未处理过的非特征顶点,并将该顶点与所有这些相邻非特征顶点均配对作为边折叠操作的候选顶点对；步骤五：计算出该顶点与所有相邻非特征顶点之间的距离,求和并算出平均距离以及该顶点与每个相邻顶点的距离比值；步骤六：对每一对顶点都模拟进行边折叠操作,计算边折叠之后产生的折叠代价,将其与相应顶点的距离比值的乘积作为新的折叠代价,进入步骤七；步骤七：选择折叠代价最小的那对候选顶点对作为进行边折叠操作的输入,如果有多个这样的顶点对存在,选择距离最近的顶点对；此时模型顶点数减少一个,然后转入步骤二,继续进行简化；步骤八：将简化后保留的顶点及面片信息保存到新的三维模型的obj文件中,以供下一次简化使用。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>              姚清河       </td>   <td>中山大学</td>   <td>一种基于数据并行处理的虚拟现实的3D仿真方法及系统</td>   <td>广东省</td>   <td>CN103679809B</td>   <td>2016-08-17</td>   <td>本发明公开一种基于数据并行处理的虚拟现实的3D仿真方法及系统,方法包括：构建三维模型,设定初始边界条件；对三维模型区域分解；将初始边界条件和各子模型中的元素信息输入到进程；以初始边界条件为计算条件,当计算过程中初始的边界条件发生改变则重新设置边界,重新对子模型进行计算,直到边界稳定或计算子结果为常数；对计算子结果进行合并产生模型整体的计算结果；设定相机角度、行进路径,设置渲染效果,根据计算结果生成3D文件；并通过3D播放器播放展示。本发明可广泛应用在三维设计行业,如虚拟手术、建筑物通风结构设计、通风设计等。通过计算仿真和虚拟现实技术的结果,立体展示虚拟物体的瞬时特性,提升展示度,增强设计效果。</td>   <td>1.一种基于数据并行处理的虚拟现实的3D仿真方法,其特征在于,包括以下步骤：S1.构建对象的三维模型,设定初始边界条件；S2.将步骤S1生成的三维模型进行区域分解,分解得到的子模型数目与并行计算服务器中的总进程数相同,并将初始边界条件和各子模型中的元素信息分别输入到各进程；S3.以初始边界条件为计算条件,当计算过程中初始的边界条件发生改变则重新启动边界设置程序,重新对该子模型进行计算,直到边界稳定或计算子结果为常数；S4.对产生的计算子结果进行合并,产生三维模型整体的计算结果；S5.根据步骤S4获取的计算结果生成3D文件,并导入虚拟现实场景中,通过设定相机角度、行进路径,设置渲染效果来实现虚拟现实操作,通过3D显示器播放展示；所述步骤S3的计算具体实现方式为：S31.读入当前进程中对应的输入文件；S32.利用并行特征曲线算法对控制方程中的非线性项进行线性化处理,得到正定、对称的局部线性系统；                      &amp;Sigma;i=1NR(i)K(i)R(i)Tu(i)=&amp;Sigma;i=1NR(i)f(i)---(1) ]]>                  其中K～((i))为局部刚度矩阵,u～((i))为局部未知变量,f～((i))为已知的局部外力向量,R～((i))为局部元素标编号和整体元素编号之间映射的0-1矩阵；S33.对上一步骤中的局部未知变量u～((i))区分表面自由度和内部自由度并整理,得到；                      &amp;Sigma;i=1NKII(i)KIB(i)KBI(i)KBB(i)uI(i)uB(i)=&amp;Sigma;i=1NfI(i)fB(i)---(2) ]]>                  其中          为当前小区域内部自由度,          当前小区域表面和其他区域接界部分自由度；          为当前小区域内部自由度对应的外力矢量；          为当前小区域表面自由度对应的外力矢量；          为矩阵进行初等行列变换后对应的分块矩阵；S34.运用平衡预条件迭代算法对表面自由度方程(3)进行求解,得到                      (KBB-KBIKII-1KIB)uB=fB-KBIKII-1fI---(3) ]]>                  S35.将代入到式(2)中的线性系统,采用直接法反解得到S36.将计算结果u～((i))输出到当前进程负责的输出文件中；S37.如果边界条件发生改变重新启动边界设置程序,再进行计算,直到边界稳定或者计算子结果定常为止；每完成一定时间步的计算,进行一次输出文件的读写操作。</td>   <td>G06T17/00;G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              陈荣军;              吴琦;                   朱雄泳       </td>   <td>中山大学</td>   <td>一种矩阵式二维条码的初步定位方法</td>   <td>广东省</td>   <td>CN103235951B</td>   <td>2016-06-15</td>   <td>本发明涉及一种矩阵式二维条码的初步定位方法,包括以下步骤：对二值化后的图像进行边缘检测,得到图像的边缘检测图；扫描检测图中的边缘点,将所有的边缘点标记；逐个对每个边缘点进行方向扫描,求得每个边缘点的最短距离跳变点；连接图像中所有的最短距离跳变点与其对应的边缘点；得到连接过后的图像,筛选出连通区域,提取出条码区域。本发明通过从复杂背景条件下得到条码的大概区域,提高条码的识别速度和精度,为后续的图像校正和提取信息等步骤做准备。</td>   <td>1.一种矩阵式二维条码的初步定位方法,其特征在于,包括以下步骤：		1.1)对二值化后的条码图像进行边缘检测,得到图像的边缘检测图；		1.2)扫描检测图中的边缘点,将所有的边缘点标记；		1.3)逐个对每个边缘点进行方向扫描,求得每个边缘点的最短距离跳变点；		1.4)连接图中所有的最短距离跳变点与其对应的边缘点；		1.5)得到连接过后的图像,筛选出连通区域,提取出条码区域；		所述步骤1.4)中连接图像中所有的最短距离跳变点与其对应的边缘点的步骤如下：将所有边缘点与它们所对应的最短距离跳变点连接,当跳变点为黑色像素点时,将以这两点为端点的线段上经过的所有的像素点都置为白色,当跳变点也为白色像素点时,则不进行操作。</td>   <td>G06K9/54</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              徐颂华;              王玉松;                   林谋广       </td>   <td>中山大学</td>   <td>基于模板匹配的图像分割方法</td>   <td>广东省</td>   <td>CN103236056B</td>   <td>2016-05-25</td>   <td>本发明公开了一种基于模板匹配的图像分割方法,包括以下步骤：步骤1：在待分割图像要对比部分的边缘和模板图像的边缘分别提取相同数量的像素点作为像素特征点；步骤2：分别对待分割图像要对比部分与模板图像计算每个像素特征点与同幅图像中的其他像素特征点之间的方差,对两幅图像中像素特征点的方差值进行对比,设定一误差值,若两个像素点之间的方差值误差在所述误差值之内则所述两个像素点相似,得到相似度的分割；步骤3：逐渐增加待分割图像要对比部分的大小,重复步骤1及步骤2,直到整幅图像都被分割完成。本发明的分割方法能够有效抵抗噪音的干扰,提高时间效率并进行准确分割,尤其对黏连部分可以进行有效的分割。</td>   <td>1.一种基于模板匹配的图像分割方法,其特征在于,包括以下步骤：步骤1：在待分割图像要对比部分的边缘和模板图像的边缘分别提取相同数量的像素点作为像素特征点；步骤2：分别对待分割图像要对比部分与模板图像计算每个像素特征点与同幅图像中的其他像素特征点之间的方差,对两幅图像中像素特征点的方差值进行对比,设定一误差值,若两个像素点之间的方差值误差在所述误差值之内则所述两个像素点相似,得到相似度的分割；步骤3：逐渐增加待分割图像要对比部分的大小,重复步骤1及步骤2,直到整幅图像都被分割完成；其中,所述步骤1进一步包括：步骤11：对待分割图像和模板图像分别进行去噪及边缘化处理；步骤12：根据待分割图像的大小选择一个分数作为基数对图像进行切割,切割形成待分割图像的对比部分；步骤13：根据待分割图像的对比部分及模板图像的大小均匀在该两幅图像边缘分别选取数量相同的像素特征点；步骤14：判断所选择的像素特征点,如果选择均匀,则结束像素特征点的提取,如果不均匀,返回步骤13,重新提取像素特征点。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   梁炎       </td>   <td>中山大学</td>   <td>基于迭代稀疏表达的人脸图像超分辨率重建方法</td>   <td>广东省</td>   <td>CN103325104B</td>   <td>2016-05-11</td>   <td>本发明公开了一种基于迭代稀疏表达的人脸图像超分辨率重建方法,包括以下步骤：将低分辨率输入图像进行插值得到高分辨率人脸估计图像；将高分辨率人脸估计图像用一个高分辨率人脸图像字典进行线性表达,并在一定的表达误差下要求非零的表达系数尽可能少；将上述稀疏表达结果作为新的高分辨率人脸估计图像；使用基于局部线性回归方法对上述高分辨率人脸估计图像进行局部细节补偿,得到新的高分辨率人脸估计结果；迭代重复上述步骤,最后收敛到稳定值,完成超分辨率重建。本发明不仅将全局和局部方法用迭代的方式有机地结合在一起,而且提供了一种整合不同的解决图像对齐不准问题的策略,迭代能快速收敛,实现由粗到精的超分辨率重建。</td>   <td>1.基于迭代稀疏表达的人脸图像超分辨率重建方法,其特征在于,包括以下步骤：		(1)将低分辨率输入图像进行插值得到高分辨率人脸估计图像；		(2)将高分辨率人脸估计图像进行稀疏表达,即将高分辨率人脸估计图像用一个高分辨率人脸图像字典进行线性表达,并在一定的表达误差下要求非零的表达系数尽可能少；之后将稀疏表达结果作为新的高分辨率人脸估计图像；		高分辨率人脸图像字典H的求解方法如下：		使用基准点对齐预先随机采样得到的一批高分辨率人脸图像；		通过准确定位基准点随机得到B幅对齐准确的高分辨率人脸图像；再通过1-8个像素的误差定位基准点随机得到Q幅对齐不准的高分辨率人脸图像；		将上述B幅对齐准确的高分辨率人脸图像以及Q幅对齐不准的高分辨率人脸图像作为训练样本X＝[x-(1),…,x-(N)]∈R～(n×N),其中x-(i)是第i个高分辨率人脸图像样本,n是图像空间维度,N是训练样本个数；		求解以下关于字典H和由N个系数向量组成的矩阵Α＝[α-(1),α-(2),…,α-(N)]∈R～(m×N)的联合最优化问题：		                  其中上述稀疏表达是指：		min||α||-(0),使满足x*＝Hα,		得到最优解α*,其中,x*是高分辨率人脸图像估计值,H＝[h-(1),…h-(m)]是高分辨率人脸图像字典,它包含m个基元素h-(i),i＝1,…,m,α∈R～(m×1)是以表达系数为元素组成的向量,简称系数向量,||α||-(0)是α的l-(0)范数,即α中非零元素的个数；		(3)使用基于局部线性回归方法得到的残差补偿对步骤(2)所得到的新的高分辨率人脸估计图像进行局部细节补偿,得到补偿后的高分辨率人脸估计图像；		使用基于局部线性回归方法得到残差补偿的方法如下：		对步骤(2)得到的高分辨率人脸估计图像进行下采样,然后被低分辨率输入图像减除,得到低分辨率残差图像,然后对低分辨率残差图像每一处脸部位置上的图像块进行局部线性回归,得到高分辨率残差图像；将高分辨率残差图像与步骤(2)得到的高分辨率人脸估计图像进行相加合并,完成脸部细节信息补偿,得到新的高分辨率人脸估计图像；		(4)迭代重复步骤(2)和步骤(3),最后收敛到稳定值,完成超分辨率重建。</td>   <td>G06T5/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴浩君;              王泳;                   黄继武       </td>   <td>中山大学</td>   <td>一种电子变调音频的鉴定方法</td>   <td>广东省</td>   <td>CN103440868B</td>   <td>2016-05-11</td>   <td>本发明公开了一种电子变调音频的鉴定方法,是根据电子变调的特点而提出的判别方法,属于多媒体信息安全领域。本发明方法包括以下步骤：(1)提取音频特征；(2)构造分类器模型；(3)按照步骤(1)提取待测音频片段的特征,利用步骤(2)得到的分类器模型进行检测判断。本发明方法能鉴定一段待测音频是原始音频还是电子变调音频,并且对不同的变调方法有很稳健的鲁棒性,从而可以为司法取证提供帮助。</td>   <td>1.一种电子变调音频的鉴定方法,其特征在于,包括：		S1.构造分类器模型,具体为：		建立训练音频库,其中包括原始音频集和电子变调音频集,根据不同的变调系数,将电子变调音频集划分为K个电子变调音频子集；		分别提取原始音频集的音频特征集和K个电子变调音频子集的音频特征集；		将原始音频集的特征集分别和K个电子变调音频子集的特征集合在一起,输入到分类器中,分别训练得到K个分类器模型；		S2.利用分类器模型对待测音频片段做检测判断,具体：		提取待测音频片段的特征；		将待测音频片段的特征输入到K个分类器中,分别获得K个鉴定结果；		如果K个鉴定结果都是原始音频,则待测音频片段被鉴定为原始音频；如果其中有一个鉴定结果是电子变调音频,则待测音频片段被鉴定为电子变调音频；		其中上述音频特征提取的具体方式为：		1)对音频进行语音检测,截掉音频的静音部分；		2)对音频的幅值进行归一化,使其分布在区间[-1,1]内；		3)对音频进行加窗、分帧,分帧后音频的帧数记作N；		4)提取每一帧音频的d阶梅尔频率倒谱系数MFCC,记作M-(1),M-(2),…,M-(N)；		5)对M-(1),M-(2),…,M-(N)做帧间一阶差分和帧间二阶差分,得到每一帧音频的MFCC一阶差分和二阶差分系数,记作△M-(1),△M-(2),…,△M-(N)和△△M-(1),△△M-(2),…,△△M-(N),基于第i帧音频提取的MFCC及其差分系数矢量,记作V-(i),i={1,2,…,N},V-(i)有D=3d个分量,V-(i)的第j分量记作v-(ij),所有N个第j分量的集合,记作X-(j)={v-(1j),v-(2j),…,v-(Nj)},j={1,2,…,D}；		6)计算每一个分量集合X-(j)的均值m-(j),j={1,2,…,D},以及不同的分量集合X-(j)和X-(j’)之间的相关系数c-(jj’)、j、j’={1,2,…,D},j≠j’；		7)将所得的均值和相关系数组合起来,作为音频特征f,f=[m-(1),m-(2),…,m-(D),c-(12),c-(13),…,c-(D-1D)]。</td>   <td>G10L21/003</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;                   吴泽瑜       </td>   <td>中山大学</td>   <td>一种基于视频分析的人群密度估计方法与人流量统计方法</td>   <td>广东省</td>   <td>CN103218816B</td>   <td>2016-05-04</td>   <td>本发明公开了一种基于视频分析的人群密度估计方法与人流量统计方法。人群密度估计方法包括下述步骤：(1)离线训练：人工统计人群密度数据并提取特征进行训练；(2)在线估计：提取特征并利用训练后的模型参数进行回归预测。人流量统计的方法是通过结合人群密度与小区域人流速度建立过线前景点与过线人数的鲁棒关系。本发明基于区域整体提取前景、边缘、灰度共生矩阵等特征进行人群密度估计,融合这些特征能较好地解决人群密集和遮挡等问题,实现了实时的人群密度估计；另外,在区域人群密度估计的基础上结合基于光流的人流速度进行人流量统计,避免了对复杂环境下大量个体的检测跟踪,实现了密集人群下精确鲁棒的双向人流量计数。</td>   <td>1.一种基于视频分析的人群密度估计方法,其特征在于,包括下述两个阶段：(1)人群密度估计的离线训练,人工统计人群密度数据并提取图像的前景、边缘、纹理特征,通过回归函数训练生成模型参数；具体为：(1-1)通过人工统计的方法对视频图像选定的一些区域进行人数统计,获取一定数量的区域人群密度数据；(1-2)利用基于低通滤波和Retinex理论的光照补偿去除光照变化的影响,获取亮度稳定的灰度图；去除光照变化影响的方法为：将一幅给定的图像S(x,y)分解成两幅不同的图像：反射物体图像R(x,y)和入射光图像L(x,y),即S(x,y)＝R(x,y)L(x,y),其中L(x,y)对应图像的低频部分,两边取对数可得log(S)＝log(R)+log(L),通过低通滤波获取log(L),去除log(L)部分并取指数即可得到不受光照变化影响的图像R(x,y)；(1-3)对去除光照影响的灰度图进行基于混合高斯背景建模的背景检测获取背景图和前景图,并对前景图进行阴影检测去除,采用Canny算子获取边缘图；对去除光照影响的图像R(x,y),采用基于归一化互相关函数与亮度比值的阴影检测去除前景图中的阴影,具体算法如下：像素点(x,y)处归一化的互相关函数为：                            N    C    C          (      x      ,      y      )        =                  B        R                  (          x          ,          y          )                            E        B                  (          x          ,          y          )                E        R                  (          x          ,          y          )                      -    -    -          (      1      )       ]]>                  其中：      B    R          (      x      ,      y      )        =          &amp;Sigma;              n        =        -        W            W              &amp;Sigma;              m        =        -        W            W        B          (      x      +      n      ,      y      +      m      )        R          (      x      +      n      ,      y      +      m      )       ]]>                            E    B          (      x      ,      y      )        =                            &amp;Sigma;                      n            =            -            W                    W                          &amp;Sigma;                      m            =            -            W                    W                B                              (            x            +            n            ,            y            +            m            )                    2                     ]]>                                              E    R          (      x      ,      y      )        =                            &amp;Sigma;                      n            =            -            W                    W                          &amp;Sigma;                      m            =            -            W                    W                R                              (            x            +            n            ,            y            +            m            )                    2                     ]]>                  其中B(x,y)为背景图像像素,W为设定的模板大小,阴影检测如下式(S(x,y)＝1为阴影)：                  (2)式中：阈值T-(ncc)为互相关系数阀值,接近1的常数；T-(s)为亮度比下限,T-(h)为亮度比上限；(1-4)把图像分割成若干小区域,通过灰度图与高斯核的卷积去除噪声；(1-5)使用前景图对边缘图与灰度图进行掩模处理,并对处理后的前景图、边缘图、灰度图提取特征；(1-6)使用所提取的特征与人工统计的人群密度数据通过支持向量机进行回归训练,生成模型参数；(2)人群密度估计的在线处理,提取与离线训练阶段相同的特征,并利用训练好的模型参数进行回归预测；具体为：(2-1)对图像中少量代表性人体大小进行人工标注,与训练阶段的标准库进行对比,得到尺度因子；(2-2)采用训练阶段的步骤(1-2)至(1-5)提取特征值,并采用尺度因子对特征向量进行规范化处理；(2-3)利用支持向量机回归算法与离线训练阶段得到的模型参数对所提取的特征进行回归预测,获取区域的人群密度估计,再对前后相邻几帧的估计结果进行平滑滤波,得到最终的区域人群密度估计值。</td>   <td>G06T7/00;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              陈荣军;              罗招华;                   朱雄泳       </td>   <td>中山大学</td>   <td>一种二维条码的自适应阈值二值化方法</td>   <td>广东省</td>   <td>CN103235948B</td>   <td>2016-04-20</td>   <td>本发明属于图像二值化处理方法,涉及一种二维条码的自适应阈值二值化方法,其包括以下步骤：1.1)将条码图像分成若干个大小相同的区域并计算每个区域的平均灰度值；1.2)计算每个区域的调和因子并利用每个区域的调和因子计算出相应的阈值；1.3)在每个区域中以对应的阈值将区域内的像素二值化。本发明既提高了局部阈值二值化算法的速度,又能动态的自适应的计算出每个区域的阈值,使得块效应消失,还能通过每个区域的调和因子,使得区域与区域之间的边界能够很好的融合,使伪边界很好的退化。</td>   <td>1.一种二维条码的自适应阈值二值化方法,其特征是：包括以下步骤：		1.1)将条码图像分成若干个大小相同的区域并计算每个区域的平均灰度值,步骤如下：		1.1.1)将条码图像分成个区域,且每个区域的大小为,其中m、n及r为大于0的整数；		1.1.2)计算每个区域的平均灰度值并储存,其中表示区域所在的位置,表示第行,第列个区域,其中,,计算公式如下：		          ；		其中D为存储每个区域的最大最小灰度值之差的矩阵；		1.1.3)计算每个区域的最大灰度值和最小灰度值并储存；		1.2)计算每个区域的调和因子并利用每个区域的调和因子计算出相应的阈值；		1.3)在每个区域中以对应的阈值将区域内的像素二值化。</td>   <td>G06K9/38</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              朱雄泳;              徐燕丽;                   陈荣军       </td>   <td>中山大学</td>   <td>一种基于直方图均衡化的色调映射方法</td>   <td>广东省</td>   <td>CN103353982B</td>   <td>2016-03-09</td>   <td>本发明公开了一种基于直方图均衡化的色调映射方法,包括：1)输入高动态范围图像；2)获取图像亮度并转换为对数域；3)进行直方图统计；4)计算图像的平均亮度,以平均亮度为分割点对直方图进行分段；5)差异化设置两段直方图的映射参数；6)分段进行直方图均衡化算法；7)把色调映射后的亮度通道还原到RGB色彩空间；8)输出可显示的低动态范围图像。本发明中对直方图进行分段后差异化设置两段的映射参数,对于明亮背景使之尽可能地线性映射,减少高亮部分细节的丢失；对于前景部分仍进行直方图均衡化处理,扩展图像的对比度。本发明在增强图像对比度的同时能有效地保持图像原来的亮度,有效改善经典直方图均衡化算法中亮度饱和现象。</td>   <td>1.一种基于直方图均衡化的色调映射方法,其特征在于方法的具体步骤如下：第1步：输入一幅高动态范围图像；第2步：根据输入图像的RGB色彩通道值获取该图像的亮度值并转换为对数域LI；第3步：直方图统计,找出第2步得到的转换为对数域LI公式中的最小值L-(min)以及最大值L-(max),然后划分区间并统计直方图；第4步：通过第3步得到直方图统计结果计算输入图像的平均亮度μ,以μ作为分割直方图的分割点,将直方图分割为两个区间段；第5步：差异化设置两段直方图的映射参数,对于前半段的直方图,映射参数α-(1)在0.5与1间找到最优值；对于后半段的直方图,映射参数α-(2)在0.3与0.5间找到最优值,映射参数α为0表示线性映射,α为1表示直方图均衡化映射；第6步：利用第5步获取的映射参数,对两段直方图进行均衡化映射；第7步：把色调映射后的亮度通道还原到RGB色彩空间；第8步：输出低动态范围图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴贺俊;              欧展飞;              刘伟伟;              赵勇健;                   叶浩荣       </td>   <td>中山大学</td>   <td>一种智能终端上的人工智能自然语言运行系统</td>   <td>广东省</td>   <td>CN102902664B</td>   <td>2016-03-02</td>   <td>本发明提供一种用户体验效果好的、结合上下文分析的智能终端上的人工智能自然语言运行系统,包括用户和智能终端,其特征是,所述智能终端与用户进行具有上下文逻辑的对话。所述智能终端设有状态存储器和有限状态机知识库,智能终端将用户输入的自然语言转化为字符串,智能终端在有限状态机知识库里检索所述字符串代表的状态,返回相应的应答,并且根据应答以及当前的状态,参照有限状态机知识库内的规则,改变状态储存器内的状态。</td>   <td>1.一种智能终端上的人工智能自然语言运行系统,智能终端内运行人工智能自然语言运行系统,其特征是,所述智能终端与用户进行具有上下文逻辑的对话,按照正确时序完成用户安排执行的程序；		所述人工智能自然语言运行系统包括人工智能自然语言交互智能体和程序处理系统,人工智能自然语言交互智能体包括人工智能标记语言知识库和人工智能标记语言解释器；		人工智能标记语言知识库使用人工智能标记语言编写,由解析器解释执行；人工智能标记语言是一种扩展的XML语言；人工智能标记语言使用到的标签：		category标签用于标识一条知识；		pattern是pattern子标签,用于标识匹配输入的正则表达式；		template是pattern的子标签,用于标识知识的应答模版；		random标签用于从多个应答模版中抽取一个作为应答；		li标签用于标识random标签内的每一个应答模版；		srai标签将标签内的内容作为输入重新处理；		set标签用于改变变量的值；		topic标签,只有当前topic变量的值等于topic标签里标注的值,系统才会匹配topic标签里的知识,而且会优先匹配；		think标签内的内容不显式返回给用户；		所述智能终端设有状态存储器和有限状态机知识库,智能终端将用户输入的自然语言转化为字符串,智能终端在有限状态机知识库里检索所述字符串代表的状态,返回相应的应答,并且根据应答以及当前的状态,参照有限状态机知识库内的规则,改变状态储存器内的状态；		所述人工智能自然语言运行系统的实现包括如下步骤：		步骤1,人工智能自然语言运行系统初始化,加载人工智能标记语言知识库；		步骤2,将用户的输入、程序处理系统的反馈信息转换为字符串；		步骤3,将字符串正规化；		步骤4,在人工智能标记语言知识库查询相应的知识,当前状态存储器里的状态与知识上标识的状态匹配一致；		步骤5,根据查询到的知识应答模版给出应答,根据当前状态储存器的状态以及有限状态机知识库内的规则做出状态的跳转,修改状态储存器里的内容,并发送分析得到的程序给程序处理系统运行；		步骤6,返回步骤2。</td>   <td>G06F17/27;G06F17/28;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         唐铁鑫;              杨得坡;              赵光伟;              范忠强;              徐新军;              周利民;              李青;                   郭依俐       </td>   <td>百正药业股份有限公司;中山大学</td>   <td>化合物平面分离结果的图像处理方法及其系统</td>   <td>河南省</td>   <td>CN102881007B</td>   <td>2016-01-20</td>   <td>本发明提供一种化合物平面分离结果的图像处理方法及其系统,通过对所述平面分离结果图像进行旋转、截取、缩放和灰度转换处理,转换为符合用户要求的灰度图像。再将所述平面分离结果图像中每一行的像素点用最小二乘法拟合基线二次曲线方程,用该方程校正该行各像素点的灰度值,通过图像平滑处理和谱带分割处理,对所述平面分离结果图像准确地进行谱带划分,提取各个谱带的像素,将所述平面分离结果图像中的各个谱带内的像素,沿水平方向进行灰度值累加,得到各谱带的累积光密度数据集和光密度曲线；对样品中指定化合物进行定性、定量分析。本发明能够消除所述平面分离结果图像中背景的影响,提高对化合物平面分离结果图像的处理精度。</td>   <td>1.一种化合物平面分离结果的图像处理方法,其特征在于,包括步骤：获取化合物样品的平面分离结果图像；对所述平面分离结果图像进行旋转、截取、缩放和灰度转换处理；将处理后的所述平面分离结果图像中每一行的像素点用最小二乘法拟合二次曲线方程,有限次剔除所述像素点的灰度值与所述像素点坐标对应的所述二次曲线方程计算值比较后确定的像素点,拟合获得理想的基线二次曲线方程,用该基线二次曲线方程校正该行各像素点的灰度值；对灰度校正后的所述平面分离结果图像进行图像平滑；对图像平滑后的所述平面分离结果图像进行谱带分割；将谱带分割后的所述平面分离结果图像中的各个谱带内的像素,沿水平方向进行灰度值累加,得到各谱带的累积光密度数据集,并绘制光密度曲线；根据所述光密度曲线对化合物样品中指定化合物进行定量、定性分析。</td>   <td>G06T7/00;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              郑洪滨;                   方溢西       </td>   <td>中山大学</td>   <td>利用通用文本模板自动生成辅助代码文件的方法及系统</td>   <td>广东省</td>   <td>CN103077284B</td>   <td>2016-01-13</td>   <td>本发明公开了一种利用通用文本模板自动生成辅助代码文件的方法及系统,该系统包括获取单元、判断载入单元以及生成单元。该方法包括：A、获取算法的高层次描述代码文件以及配置文件；B、根据配置文件的内容,进而判断是否需要载入用于生成辅助代码文件的功能处理单元,若判断的结果为是,则自动载入用于生成辅助代码文件的功能处理单元；C、执行用于生成辅助代码文件的功能处理单元,进而从算法的高层次描述代码文件中提取模块特征信息,并且将提取出的模块特征信息载入通用文本模板后,自动生成辅助代码文件。本发明能大大减少设计人员的工作量和压力,而且提高了硬件设计的效率。本发明广泛应用于硬件设计领域中。</td>   <td>1.利用通用文本模板自动生成辅助代码文件的方法,其特征在于：该方法包括：		A、获取算法的高层次描述代码文件以及与其相对应的配置文件；		B、根据配置文件的内容,进而判断是否需要载入用于生成辅助代码文件的功能处理单元,若判断的结果为是,则自动载入用于生成辅助代码文件的功能处理单元,并且执行步骤C；		C、执行用于生成辅助代码文件的功能处理单元,进而从算法的高层次描述代码文件中提取模块特征信息,并且将提取出的模块特征信息载入通用文本模板后,自动生成辅助代码文件；		所述步骤C中所述的模块特征信息包括全局变量特征信息以及函数特征信息；		所述步骤C包括：		C1、执行用于生成辅助代码文件的功能处理单元,进而对算法的高层次描述代码文件进行模块查找；		C2、对查找出的模块进行全局变量遍历,进而提取全局变量特征信息,并且将提取出的全局变量特征信息载入通用文本模板的相应位置中；		C3、对查找出的模块进行函数遍历,进而提取函数特征信息,并且将提取出的函数特征信息载入通用文本模板的相应位置中；		C4、将已载入全局变量特征信息和函数特征信息的通用文本模板进行存储,进而自动生成辅助代码文件。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              郑洪滨;              刘倾瑞;                   涂玏       </td>   <td>中山大学</td>   <td>一种软硬件协同仿真的验证平台及其构建方法</td>   <td>广东省</td>   <td>CN103150441B</td>   <td>2016-01-13</td>   <td>本发明公开了一种软硬件协同仿真的验证平台及其构建方法,该验证平台包括测试信息获取模块、硬件模型生成模块、软硬件接口层生成模块、第一计算模块、第二计算模块以及判断结果输出模块。该方法包括：对由功能函数综合输出的寄存器传输级硬件电路代码进行获取,并对获取的寄存器传输级硬件电路代码进行反编译后,得到基于SystemC的周期精度的硬件模型；生成软硬件接口层；通过生成的软硬件接口层调用所述的硬件模型进而对测试信息进行处理；调用功能函数对测试信息进行处理；判断第一计算处理结果和第二计算处理结果是否一致。本发明提高了高层次综合设计的仿真验证效率,而且还能检验高层次综合工具的正确性。本发明广泛应用于系统级设计中。</td>   <td>1.一种软硬件协同仿真的验证平台构建方法,其特征在于：该方法包括：		对输入的测试信息进行获取；		对由功能函数综合输出的寄存器传输级硬件电路代码进行获取,并对获取的寄存器传输级硬件电路代码进行反编译,进而得到基于SystemC的周期精度的硬件模型；		根据所述的硬件模型,进而生成与所述硬件模型相适配对应的软硬件接口层；		通过生成的软硬件接口层调用所述的硬件模型,进而对测试信息进行处理,并得到第一计算处理结果；		调用功能函数,进而对测试信息进行处理,并得到第二计算处理结果；		判断第一计算处理结果和第二计算处理结果是否一致,并且根据判断的结果进而验证由寄存器传输级硬件电路代码生成的硬件电路与功能函数之间的等价性。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;              刘镇;                   罗仰通       </td>   <td>中山大学</td>   <td>一种地下环境三维可视化漫游方法</td>   <td>广东省</td>   <td>CN102722903B</td>   <td>2015-11-25</td>   <td>本发明提供一种地下环境三维可视化漫游方法,本发明通过三维软件建立地下构筑物模型,由钻孔数据插值生成地层曲面进而构造三棱柱的方法建立三维地层模型,由地层与地下构筑物建立三维地下环境虚拟场景,通过光照、材质、半透明渲染、切割等手法获得高质量三维地下环境虚拟场景,用户可通过键盘、鼠标、游戏手柄等外部控制设备方便灵活的与系统进行交互,从而获得逼真的漫游体验。</td>   <td>1.一种地下环境三维可视化漫游方法,其特征在于包括下列步骤：(1)利用现有三维软件工具建立地下构筑物模型,将模型空间信息导入数据库,利用图形硬件对构筑物模型进行绘制；(2)根据钻孔数据将地层初始化为三棱柱体,对三棱柱体进行编号,然后将编号添加为索引值,并将边界上的三棱柱体水平投影至边界上,形成模型边界,通过图形硬件对边界进行绘制；(3)漫游初始化时,根据视点所在位置高度,识别相应地层和对应的三棱柱体索引值,根据索引值搜索三棱柱体并添加入显示链表；(4)然后通过三维图形编程接口编辑绘制程序,利用图形硬件对视点前方的三棱柱体进行半透明渲染绘制；(5)最后通过改变视点位置和视线角度来更新场景绘制实现地下环境漫游。</td>   <td>G06T15/00;G06T19/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周凡;              林格;                   饶洁       </td>   <td>中山大学</td>   <td>一种基于视频图像的智能搜索匹配方法</td>   <td>广东省</td>   <td>CN103116890B</td>   <td>2015-11-18</td>   <td>本发明公开了一种基于视频图像的智能搜索匹配方法,包括以下步骤：从视频图像中逐帧提取帧图像；对每一帧图像进行二值化处理；扫描二值化处理后的帧图像并提取目标图像特征流；对待匹配图像进行二值化处理并扫描提取待匹配图像特征流；对待匹配图像特征流和目标图像特征流进行匹配判断是否匹配。本发明的基于视频图像的智能搜索匹配方法,能够根据各个小块目标点分布的具体情况得出特征符并形成特征流进行图像匹配,并且只需一次扫描整个目标区域即可,避免了重复计算,匹配,大大加快了图像匹配速度和效率。</td>   <td>1.一种基于视频图像的智能搜索匹配方法,其特征在于,包括以下步骤：从视频图像中逐帧提取帧图像；对每一帧图像进行二值化处理；扫描二值化处理后的帧图像并提取目标图像特征流；对待匹配图像进行二值化处理并扫描提取待匹配图像特征流；对待匹配图像特征流和目标图像特征流进行匹配判断是否匹配；其中：所述提取特征流的步骤包括：将二值图依次分为相同大小的4、9、16部分；对每一部分,再平均分为4个区域；从上至下,从左至右,依次扫描整个二值图的每一部分的各个最小区域,查看每一区域像素点的分布情况,根据不同的分布情况得到该部分不同的特征符；扫描处理完整个二值图,得到图像基于4、9、16部分的3个特征流；其中：所述查看每一区域像素点的分布情况,根据不同的分布情况得到该区域不同的特征符的步骤中,像素点与特征符对应关系为：a＝1000；b＝0100；c＝0010；d＝0001；e＝1100；f＝0110；g＝0011；h＝1001；i＝1010；j＝0101；k＝0111；l＝1011；m＝1101；n＝1110；o＝1111；p＝0000,其中1代表该区域有像素点分布,0代表该区域无像素点分布,a至p表示特征符；其中：所述对目标图像特征流和待匹配图像特征流进行匹配判断的步骤包括：取出待匹配图像和目标图像的基于4、9、16部分的3个特征流；分别对比两图像的3个特征流,统计对应的特征流的相似度,并得出总的相似度；判断总的相似度是否小于或等于阀值,若是,判定两幅图是匹配的,若否,判定两幅图不匹配。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              朱雄泳;              麦建业;                   陈荣军       </td>   <td>中山大学</td>   <td>亮度可控与细节保持的色调映射方法</td>   <td>广东省</td>   <td>CN103295194B</td>   <td>2015-11-04</td>   <td>本发明公开了一种亮度可控与细节保持的色调映射方法,输入高动态范围图像；获取图像亮度并转换为对数域；计算输入图像平均亮度与标准差；划分亮度直方图；直方图分段修正；预设输出的低动态范围图像的平均亮度与标准差；计算低动态范围图像的灰度级分割点；通过数学模型估计输出的低动态范围图像的平均亮度与标准差；修正标准差直到预设的标准差与估计的标准差相对误差小于？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？？；对直方图分段进行色调映射；把色调映射后的亮度通道还原到RGB色彩空间；输出可显示的低动态范围图像。本发明具有亮度可控与细节保持的特点,在高亮度区域的处理效果优于其它基于全局的色调映射方法。</td>   <td>1.一种亮度可控与细节保持的色调映射方法,其特征在于,它包括：第1步：输入一幅高动态范围图像；第2步：根据输入图像的RGB色彩通道值获取该图像的亮度值并转换为对数域；第3步：分别计算图像的平均亮度与标准差,找出第2步得到的对数域公式LI中的最小值L-(min)以及最大值L-(min),然后划分区间并统计直方图,最后计算图像的平均亮度与标准差；第4步：通过第3步得到的平均亮度μ与标准差σ从而得到分割点的值th-(1)和th-(2),即可将直方图分割为三个区间段；第5步：通过第4步得到的三段直方图,分别进行直方图修正,即对每段直方图进行剪切,补偿图像的细节部分,使得处理的图像的直方图与估计的模型有相似的形态；第6步：预设输出的低动态范围图像的平均亮度mv与标准差std；第7步：计算低动态范围图像的灰度级分割点th-(1)′和th-(2)′,首先,计算第4步得到的三段直方图各自的像素数量；其次,计算低动态范围图像的灰度级分割点；第8步：估计输出的低动态范围图像的平均亮度与标准差,第9步：通过重复第7步和第8步修正估计的标准差直到预设的标准差与估计的标准差相对误差小于δ；第10步：对直方图分段进行色调映射；第11步：把色调映射后的亮度通道还原到RGB色彩空间；所述第5步的对得到的三段直方图,分别进行直方图修正,使得处理的图像的直方图与估计的模型有相似的形态,具体为：步骤(1)：对划分为三段的直方图分别设置三个不同的阈值,其公式如下：                                                                              T              l                        =                          1                                                th                  1                                                                    &amp;Sigma;                              i                =                0                                                              th                  1                                -                1                                      h                          (              i              )                                                                                      T              m                        =                          1                                                th                  2                                -                                  th                  1                                                                    &amp;Sigma;                              i                =                                  th                  1                                                                              th                  2                                -                1                                      h                          (              i              )                                                                                      T              u                        =                          1                              N                -                                  th                  2                                                                    &amp;Sigma;                              i                =                                  th                  2                                                            N                -                1                                      h                          (              i              )                                           ]]>                  N表示量化后的亮度级数；步骤(2)：对第一段直方图h-(l)将裁剪出的像素点个数按递增的方式补偿即：                                  h      l      &amp;prime;              (      i      )        =          h              l        c                    (      i      )        +                  2        c        -                  sum          l                                                  th            1                    2                      i   ]]>                  其中,h-(l)′(i)表示最终经过裁剪和补偿的第一段直方图,h-(lc)(i)为裁剪后的直方图,c-sum-(l)为第一段直方图经过裁剪出来的像素个数之和；第二段直方图h-(m)将裁剪出来的像素个数之和均匀补偿,即：                                  h      m      &amp;prime;              (      i      )        =          h              m        c                    (      i      )        +                  c        -                  sum          m                                      th          2                -                  th          1                     ]]>                  其中,h-(m)′(i)是最终经过裁剪和补偿的第二段直方图,h-(m)′(i)为裁剪后的直方图,c-sum-(m)为该段直方图经过裁剪出来的像素个数之和；第三段直方图h-(u)将裁剪出的多余的像素点个数在[th-(2),N-1]亮度级区间中按递减的方式补偿,即：                                  h      u      &amp;prime;              (      i      )        =          h              u        c                    (      i      )        +                  2        c        -                  sum          u                                      (          N          -                      th            2                    )                2                    (      N      -      i      )       ]]>                  其中,h-(u)′(i)是最终经过裁剪和补偿的第三段直方图,h-(uc)(i)为裁剪后的直方图,c-sum-(u)为该段直方图经过裁剪出来的像素个数之和；步骤(3)：对经过裁剪和补偿的子直方图合并,公式如下：h'(i)＝h-(l)'∪h-(m)'∪h-(u)'；所述第7步的计算低动态范围图像的灰度级分割点,具体为：步骤(11)：计算三段直方图各自的像素数量,公式如下：                                                                              r              1                        =                          1                              T                o                t                a                l                -                p                i                x                e                l                                                    &amp;Sigma;                              i                =                0                                                              th                  1                                -                1                                      h                          (              i              )                                                                                      r              2                        =                          1                              T                o                t                a                l                -                p                i                x                e                l                                                    &amp;Sigma;                              i                =                                  th                  1                                                                              th                  2                                -                1                                      h                          (              i              )                                                                                      T              3                        =                          1                              T                o                t                a                l                -                p                i                x                e                l                                                    &amp;Sigma;                              i                =                                  th                  2                                                            N                -                1                                      h                          (              i              )                                           ]]>                  步骤(12)：在反馈修正标准差的过程中计算低动态范围图像的灰度级分割点,公式如下：μ-(m)＝0.5[r-(1)(th-(1)′-1)+r-(2)(th-(1)′+th-(2)′-1)+r-(3)(th-(2)′+255)]th-(2)′＝th-(1)′+2std                                  th      1      &amp;prime;        =                  2                  &amp;mu;          m                +                  (                      r            1                    +                      r            2                    )                -        255                  r          3                -        2                  (                      r            2                    +                      r            3                    )                s        t        d                              r          1                +        2                  r          2                +                  r          3                     ]]>                  其中,th-(1)′和th-(2)′表示低动态范围图像的灰度级分割点,已知的是第6步中预设的标准差初值std；所述第8步的估计输出的低动态范围图像的平均亮度与标准差,具体为：假设估计的平均亮度μ-(m)与预设的平均亮度mv相等,由th-(1)′和th-(2)′的值再加上反馈修正标准差过程可求出估计的标准差σ-(m),公式如下：                                  &amp;sigma;      m        =                  (                  &amp;Sigma;                      i            =            0                                              th              1              &amp;prime;                        -            1                                                2                          r              1                        i                                              th              1                              &amp;prime;                2                                                                          (            i            -                          &amp;mu;              m                        )                    2                +                  &amp;Sigma;                      i            =                          th              1              &amp;prime;                                                          th              2              &amp;prime;                        -            1                                                r            2                                              th              2              &amp;prime;                        -                          th              1              &amp;prime;                                                            (            i            -                          &amp;mu;              m                        )                    2                +                  &amp;Sigma;                      i            =                          th              2              &amp;prime;                                255                                      2                          r              3                                      (              255              -              i              )                                                          (              255              -                              th                2                &amp;prime;                            )                        2                                                (            i            -                          &amp;mu;              m                        )                    2                )                    1        /        2             ]]>                  所述第9步的修正估计的标准差直到预设的标准差与估计的标准差相对误差小于δ,相对误差E公式如下：                            E    =                  |                  &amp;sigma;       ...</td>   <td>G06T5/00;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林格;              林谋广;                   李彦       </td>   <td>中山大学</td>   <td>一种拉普拉斯金字塔的图像处理方法及其装置</td>   <td>广东省</td>   <td>CN102646269B</td>   <td>2015-09-23</td>   <td>本发明实施例公开了一种基于拉普拉斯金字塔的图像处理方法及其装置,其中,该方法包括：构造输入图像所相对应的高斯金字塔；根据高斯金字塔以及映射函数r(x)生成中介图像；根据中介图像获得相应的拉普拉斯Laplace金字塔系数；将基于中介图像的Laplace金字塔系数对应地输出到Laplace金字塔上,直到Laplace金字塔的每一个点都被填满为止,获得新Laplace金字塔；根据新Laplace金字塔重构图像,并获得输出图像。实施本发明实施例,可以摆脱传统Laplace金字塔不能进行边缘保持图像增强的约束,利用Laplace金字塔进行边缘保持图像增加处理,可以比传统的边缘保持图像增加方法(如双边滤波、小波方法等)更简单、更灵活地实现图像增强,可以降低时间复杂度,同时不需要设置额外的过多参数。</td>   <td>1.一种基于拉普拉斯金字塔的图像处理方法,其特征在于,所述方法包括：构造输入图像所相对应的高斯金字塔；根据所述高斯金字塔以及映射函数r(x)生成中介图像；根据所述中介图像获得相应的拉普拉斯Laplace金字塔系数；将基于所述中介图像的Laplace金字塔系数对应地输出到Laplace金字塔上,直到所述Laplace金字塔的每一个点都被填满为止,获得新Laplace金字塔；根据所述新Laplace金字塔重构图像,并获得输出图像；其中,所述根据所述高斯金字塔以及映射函数r(x)生成中介图像的步骤包括：根据所述高斯金字塔以及                            r          (      i      )        =                                                      g              0                        +            sign                          (              i              -                              g                0                            )                                      &amp;sigma;              r                                      f              d                                      (                              i                a                            )                        ,                                |            i            -                          g              0                        |            &amp;le;            &amp;sigma;                                                              g              0                        +            sign                          (              i              -                              g                0                            )                        [                          f              e                                      (              |              i              -                              g                0                            |              -                              &amp;sigma;                r                            )                        +                          &amp;sigma;              r                        ]            ,                                otherwise                               ]]>                  生成中介图像；其中,参数σ-(r)是用于区分边界和纹理的阀值,g-(0)是表面该点的期望像素值,函数f-(d)和f-(e)是将[0,1]区间映射到[0,1]区间的光滑函数,f-(d)表示细节增强函数,f-(e)表示色调增强函数,i是该点本来的像素值,|i-g-(0)|是该点领域内的灰度变化,a是改变对调整细节增强的程度。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘玉葆;              李志杰;              陈程;                   陈梓潼       </td>   <td>中山大学</td>   <td>一种最大双色反向最近邻查询方法</td>   <td>广东省</td>   <td>CN102831162B</td>   <td>2015-08-26</td>   <td>本发明提供一种有效降低算法搜索空间、节省存储空间、效率高的最大双色反向最近邻查询方法。包括以下步骤：步骤1,为每个客户点,查找在服务点集中的最近邻,生成最近位置圆域；步骤2,对每个最近位置圆域,生成所有的相交弧,通过对圆周进行扫描,找到影响最大的弧；步骤3,返回影响值的最大值,以及覆盖该弧的最近位置圆域集合。步骤2具体包括以下步骤：步骤21,查找所有与当前最近位置圆域相交的最近位置圆域,并存储在集合L中；步骤22,对L中的每个最近位置圆域,计算与当前最近位置圆域的交点及其弧度值；步骤23,按交点的弧度值对交点进行排序；步骤24,扫描交点,根据交点是对应弧的起点或终点,更新影响值。</td>   <td>1.一种最大双色反向最近邻查询方法,其特征是,包括以下步骤：步骤1,为每个客户点,查找在服务点集中的最近邻,生成最近位置圆域；步骤2,对每个最近位置圆域,生成该圆域与其他圆域的相交弧,并将相交弧表示为一维的极角弧度值区间,然后扫描该圆域圆周上的相交弧对应的弧度值区间,找到该圆域上影响值最大的相交弧,通过对每个最近位置圆域圆周上的相交弧对应的弧度值区间进行扫描,找到所有相交弧中影响值最大的相交弧；步骤3,返回影响值的最大值,以及覆盖该弧的最近位置圆域集合。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         林倞;              江波;              徐元璐;                   梁小丹       </td>   <td>中山大学</td>   <td>一种基于局部时空流形学习的运动目标分割方法</td>   <td>广东省</td>   <td>CN102750712B</td>   <td>2015-06-17</td>   <td>本发明公开了一种基于局部时空流形学习的运动目标分割方法,包括：1.输入视频时空立方体的分割与光照不变性特征的提取；2.基于局部时空流形学习的背景模型的建立；3.基于局部时空流形的运动目标分割与模型的在线更新维护；利用本方法可以有效地描述局部的时空变化,处理输入视频中扩展图像中SIFT特征点集合的尺度适应性,解决在运动目标分割时不能有效排除动态背景,光照变化的问题,实现为智能监控平台提供可靠的,有效的运动目标。</td>   <td>1.一种基于局部时空流形学习的运动目标分割方法,其特征在于包括以下步骤：1)输入离线视频；2)对离线视频进行时空立方体分割与对称时空局部纹理编码特征提取,获得时空立方体特征的时空纹理变化描述序列；3)根据时空立方体特征的时空纹理变化描述序列建立基于局部时空流形学习的背景模型；4)输入运动视频；5)对运动视频进行时空立方体分割与对称时空局部纹理编码特征提取；6)通过判断运动视频时空立方体与通过背景模型预测的时空立方体间的距离,得到目标运动和背景部分；7)根据背景部分对背景模型进行更新和维护；8)输入新的运动视频,则跳至步骤4),否则结束；步骤2)包括以下步骤：21)对离线视频进行时空立方体分割得到视频中每个单元位置的时空立方体序列；22)对离线视频进行对称时空局部纹理编码特征提取,获得时空立方体特征的时空纹理变化描述序列；步骤22)对离线视频进行对称时空局部纹理编码特征提取包括以下步骤：221)取时空立方体任一像素点,在像素点的3*3*3的三维立方体临域中计算其特征向量,把3*3*3的三维立方体分割为4个时空平面提取像素点的时空局部纹理编码；222)使用中心像素点对称的像素对,通过设定尺度阈值对像素对进行比较编码,计算像素对的对称时空局部纹理编码,将对称时空局部纹理编码拉成一个大的特征向量作为该时空立方体的时空纹理变化描述。</td>   <td>G06T7/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>              孙雪冬       </td>   <td>孙雪冬;中山大学</td>   <td>一种基于集成化建模的个性化学习资源优化方法</td>   <td>广东省</td>   <td>CN102819769B</td>   <td>2015-06-17</td>   <td>本发明公开了一种基于集成化建模的过程驱动的个性化的学习资源优化方法。该方法通过基于知识点的、以过程为中心的、多视图集成化学习建模,并根据学习目标推荐相应的学习过程,根据学习者实际的背景知识,建立学习者与学习过程、资源环境之间的动态映射,得到用超图描述的针对该学习者的学习过程及可能的服务资源状况；在此基础上通过对过程模型进行结构变换,抽取学习活动序列(LAS),利用学习者、学习资源和学习过程属性之间的关系,通过对学习过程进行优化求解,得到过程和资源都优化的学习计划。本发明能根据学习者的目标、知识背景及所处资源环境给出相对优化的学习序列及组合服务资源,并能根据资源和目标的变化进行动态调整。</td>   <td>1.一种基于集成化建模的个性化学习资源优化方法,其特征在于：具体包括以下步骤：步骤1,对网络环境下的学习进行基于知识点的一致化、多视图集成化建模；该建模具体包括分别对课程知识点、学习过程、资源环境、学习任务以及学习者的建模；得到的多视图模型包括：任务模型(TCM)、过程模型(LPH)、知识点模型(KM)、资源模型(RCM)及学习者模型(UM),总的E-Learning模型可以形式化描述为：E-Learning＝(TCM,LPH,KM,RCM,UM)；所述步骤1中,各子模型的具建模过程为：1)课程知识点的建模利用有向超图对课程进行知识点之间的关系描述,用普通边描述简单逻辑,用超边描述逻辑“与”关系,用不同的边描述逻辑“或”关系,可以形式化描述为：LPH＝(KV,KE),其中,KV表示有向超图中的表示知识点的节点；KE是有向超图中的表示知识点关系的边；2)学习过程的建模利用有向超图,对学习过程进行基于知识点的建模,该过程可以形式化描述为：LPH’＝(V,E),V＝(AV,KV),E＝(DE,SRE),其中,AV和KV,是有向超图的节点,分别表示有向超图中的活动和资源需求包含的知识点；DE和SRE是有向超图中的边,分别表示活动的输入/输出和资源支持关系,并用超边描述逻辑“与”关系,用不同的边表示资源可能的支持情况和输入/输出的逻辑“或”关系；3)学习资源的建模由于网络上的课程资源繁多,因此,需要对这些课程资源进行分类组织；对于某个具体资源,主要用资源所包含的知识点来描述资源；假设ResSet表示资源集,那么,对于可以描述为(NK,K),其中NK为知识点无关的属性,K为资源包含的知识点；4)任务建模首先,对任务进行分类,并应用实现该任务需要的知识点进行该任务描述；假设FunSet表示任务节点集,那么,对于可以描述为(NK,K),其中NK为知识点无关的属性,K为实现功能需要的知识点；5)学习者建模主要包括学习目标、背景知识、学习过程和学习资源的描述；其中,学习目标又包括功能性目标和非功能性目标,可以形式化描述为：UM＝(UO,BK,LP,LR),其中,UM是用户模型,UO是学习目标,它又分为非功能性目标NFO和功能性目标FO,即UO＝(NFO,FO),对于功能性目标主要来源于任务模型；LP是给出了相关学习资源的学习计划；LR是学习者达到学习目标用到的资源,其中LP和LR是本发明所要解决的问题；步骤2,利用完成任务需要的知识点和学习过程输出知识点之间的关系,实现根据学习者的任务目标推荐相应的学习过程；所述步骤2中的具体操作为：根据步骤1中5)设定的学习者的功能目标,进行学习过程的选择,即学习过程输出的知识点应该包含完成任务需要的知识点；可形式化描述为：对于一个学习者u-(i),u-(i)的功能目标是FO-(i),如果存在一个过程p,p的输出是O-(p),如果存在那么u-(i)可以采用p来实现FO-(i)；步骤3,根据活动在不同知识背景下的不同的资源需求、学习者实际的背景知识以及环境资源所包含的知识点,建立学习者与学习过程、资源环境之间的动态映射,得到针对该学习者的学习过程可能的服务资源状况；并应用有向超图对学习过程、学习者以及学习资源之间的关系进行图形化的、形式化的描述；述步骤3中的具体操作为：对于步骤2得到的学习过程模型,根据学习者的背景知识进行相应的、可能的学习资源的选择；对于一个学习者u-(j),他要学习的知识点LK-(i),学习活动为a-(i),u-(j)相对于LK-(i)的背景知识为BK-(j),如果存在一个资源r-(k),r-(k)中包含的知识点为RK-(k),如果那么u-(j)可以应用r-(k)来学习LK-(i)；在步骤1中建立的过程模型的基础上,再加上两类边,分别描述学习者的知识背景及资源中包含的相关知识点；可以形式化描述为：PH＝(V,E),其中,V是超图的节点集合,它又分为两类节点,V＝(AV,KV),其中,AV为活动节点,KV为资源包含的知识点；E为超图的边集,它又可分为四类,E＝(DE,SRE,LE,RE),DE为输入/输出边,也称为活动之间的变迁边；SRE为资源对活动的支持；LE描述学习者,RE描述环境中的资源状况；并用超边来描述活动的逻辑“与”关系,以及在在一定的知识背景下资源需求,此模型为用于个性化优化的学习过程模型；步骤4,基于上述的模型,应用超图理论和模型上所附加的学习过程的语义对学习过程模型进行结构变换,抽取学习活动序列LAS(LAS,Learning ActivitySequence)；所述步骤4中抽取LAS包括以下判定步骤：步骤4.1,判断学习过程模型中是否具有并行活动,若为有,则判断并行活动是否能进行可串行化；步骤4.2,若为是,则进行串行化处理；步骤4.3,估算学习活动序列LAS,当一个过程包含n个活动a-(1),a-(2),...,a-(n),相应的独立支持资源种类数为rn-(1),rn-(2),...,rn-(n)时；1)若该n个活动串行时,则经过这n个活动可能的LAS数量为：2)若该n个活动并行时,则经过这n个活动可能的LAS数量为：步骤5,针对步骤4中的LAS,利用过程属性与活动属性、活动属性与学习者以及资源属性的关系,根据学习者的具体目标,对学习过程进行优化求解,得到学习过程和学习资源都优化的学习计划；所述步骤5具体包括：根据学习者的具体性能目标,选择评价LAS的性能指标,这些指标包括：学习者通过一次学习所掌握的知识点(OBJK)、所用的时间(OBJT)、完成LAS的成本(OBJC)、完成LAS的质量(OBJQ)；以及根据学习活动属性与学习者、资源属性的关系以及过程的属性和活动属性之间的关系,根据学习者和支持资源情况计算学习过程的属性；之后根据学习者的学习目标进行LAS和支持资源的选择；步骤6,监测资源环境及学习目标,若二者任一出现变化时,利用步骤3描述的超图模型来进行改变的过程相关性判断；对于过程相关的改变,在步骤3的超图模型的基础上,进行相应的调整,从而获得新的超图模型,重复步骤4和步骤5,达到新的过程和资源优化；所述步骤6具体包括：资源与过程的相关性判断具体为：在由步骤3得到的用于优化的超图模型中,判断资源边所包含知识点与过程输的资源需求边所包含的知识点的交集是否为空,若为空,则二者不相关；若不为空,则二者相关；所述相应的处理具体为：对于过程相关的资源,若资源改变时,则在用于优化的超图模型的基础上进行资源超边的调整,以描述资源环境的变化,获得环境改变后的用于优化的模型,重复步骤4、5进行优化；学习目标与过程的相关性判断具体为：判断变化前后两个目标的知识点的交集是否为空,若为空,则二者不相关,则可重复步骤2到步骤6进行过程及资源的选择与优化；若不为空,则二者相关,则先根据新目标选择学习过程,再根据原过程的执行情况进行相应处理；所述相应处理具体为：当一些活动属于前后两个相关的学习过程的活动集的交集时,若后一过程开始前,这些活动已执行完,则在后一过程模型中去掉这些活动；若这些活动没有执行,则前一过程对后一过程没有影响,对于处理后的模型重复步骤4、5进行优化。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              朱雄泳;              陈荣军;                   陆许明       </td>   <td>中山大学</td>   <td>一种快速二维条码图像运动去模糊方法</td>   <td>广东省</td>   <td>CN102708552B</td>   <td>2015-05-20</td>   <td>本发明公开了一种快速二维条码图像运动去模糊方法,包括：初步快速定位到含有二维条码图像的区域；及对含有二维条码图像的区域进行去模糊的处理。本发明先分析了二维条码图像的特征,从而获得两个重要的图像特征,即二维条码图像周边存在比较宽的空白区和二维条码图像整体外轮廓为矩形,根据这两个图像特征,本发明方法先从模糊图像中,定位出包含二维条码图像的区域,然后只针对该包含二维条码图像的区域进行运动去模糊的处理,避免对整幅图像进行去模糊的运算,从而减少了算法的运算时间,可用在需要实时处理的手持式设备上,从而进一步扩展二维条码图像识读设备的使用范围,提高使用上的人性化体验。</td>   <td>1.一种快速二维条码图像运动去模糊方法,其特征在于,包括以下步骤：		A.初步快速定位到含有二维条码图像的区域；		B.对含有二维条码图像的区域进行去模糊的处理；		所述步骤A具体包括：		A1.利用图像重采样得到源图像的差分图像；		A2.利用快速自适应阈值法对差分图像进行二值化处理得到二值图像；		A3.对二值图像进行矩形检测,提取出包含二维条码图像的最小矩形区域；		其中所述步骤A3具体包括：		对二值图像进行标记,将图像中重叠连通区域标记为同一区域；		统计标记为同一区域的像素数量以去除干扰区域；		对接近矩形的区域进行轮廓跟踪,并利用旋转法计算各次旋转中面积最小的外接矩形区域,所述面积最小的外接矩形区域即为包含了二维条码图像,且去除了背景图像干扰的最小矩形区域。</td>   <td>G06T5/00;G06K7/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>              孙雪冬       </td>   <td>孙雪冬;中山大学</td>   <td>基于有向超图的企业业务过程及资源的优化方法</td>   <td>广东省</td>   <td>CN102819790B</td>   <td>2015-05-06</td>   <td>本发明公开了一种基于有向超图的企业业务过程及其支持资源的优化方法。该方法具体包括以下步骤：对企业进行建模,建立各模型之间的动态映射；构建业务发起者模型,根据业务发起者的目标推荐相应的业务过程；根据实际的业务过程发起者的资源背景及环境企业的资源状况,建立用于优化的、基于有向超图的业务过程模型；根据企业的资源背景及环境企业中的资源条件,选择可能的合作企业；根据企业内外具体的资源环境状况,利用有向超图的性质及模型上所附加的过程语义进行过程结构优化变换和过程结构及支持资源的优选,获得结构和支持资源都优化的过程。本发明可根据中小企业的具体目标、资源条件以及其所处的动态业务环境,指导企业选择恰当的伙伴企业,并对信息系统进行整合。</td>   <td>1.一种基于有向超图的个性化企业业务过程及资源的优化方法,其特征在于：总的建模与优化过程包括以下步骤：步骤1,对企业进行建模,包括对企业自身建模、构建通用的相关领域模型,以及根据可能合作的企业的相关信息构建伙伴模型,总的模型框架VEF可以形式化描述为：VEF＝(VEM,DM,PM),其中,VEM为虚拟企业,DM为领域模型,PM为伙伴模型,伙伴企业拥有一定的业务相关的核心资源；其中,领域模型包括过程模型、资源模型及任务模型以及这些模型涉及的信息,采用与构成过程的活动相似的结构来描述能力,并应用能力对资源与任务进行一致化建模,通过能力建立各模型之间的动态映射,给出描述个性化资源需求的业务过程的有向超图模型；所述步骤1中,具体包括以下步骤：1)领域模型DM包括业务过程、资源、任务及信息模型,可形式化描述为：DM＝(Task,Process,Res,Info),Task表示任务,Process表示过程,Res表示资源,Info表示信息；为了能快速进行资源和任务的定位,分别对它们进行分类组织；2)采用有向超图进行业务过程建模,基于有向超图的业务过程模型PH'可以形式化描述为：PH'＝(AV,DE),其中,AV表示活动节点,DE为物(数据)流；3)采用与活动相似的结构来描述能力,能力可以形式化描述为：能力模型＝(ID,Name,Ope,IS,OS),其中,ID为能力的标识；Name为能力的名称；Ope为能力的操作；IS为操作的对象；OS为操作的输出对象；4)同时,为了建立模型之间的动态映射,任务模型描述为完成任务需要的能力,资源模型描述为具有某种能力；5)此外,利用活动的输入、输出,和资源具有的能力,建立业务过程模型和资源模型的动态映射,生成业务过程的资源需求模型：PH",可以形式化描述为：PH"＝(V,E),其中,V＝(AV,RV),其中,AV为活动节点,RV为资源节点；E＝(DE,RE),其中,DE为物(数据)流,RE为资源对活动的支持；步骤2,设定业务发起者的目标,构建业务发起者模型,其中,任务目标来源于任务模型,利用任务模型与过程模型的映射关系,实现根据企业的任务目标推荐相应的业务过程；所述步骤2中,根据企业的功能目标,进行业务过程的选择,即过程输出的能力应该包含完成任务所需要的能力；可形式化描述为：对于一个业务发起者u-(i),u-(i)的功能目标是FO-(i),如果存在一个过程p,p的输出是O-(p),如果存在那么u-(i)可以采用p来实现FO-(i)；步骤3,根据实际的过程发起者的资源背景及环境企业的核心资源状况,在业务过程的有向超图模型的基础上,用包含不同资源的边分别描述业务发起者企业和环境企业,从而建立用于优化的业务过程模型；所述步骤3中,在步骤5)所述的过程模型的基础上,用包含不同资源的边描述不同的企业,得到用于个性化优化的业务过程模型；该超图模型PH可以形式化描述为：PH＝(V,E),其中,V是超图的节点集合,它又分为两类节点,V＝(AV,RV),其中,AV为活动节点,RV为资源节点；E为超图的边集,它又可分为三类,E＝(DE,RE,EE),DE为输入/输出边,也称为活动之间的变迁边；RE为资源对活动的支持；EE为活动与资源的企业所属关系；并且用超边描述活动之间的“与”逻辑,用普通的边来描述“或”逻辑；用超边描述组合资源对活动的支持关系；用普通边描述单个资源对活动的支持关系；用多个边描述活动有多种可能支持资源的情况；对于描述资源和活动所属企业的超边又可以分为两类：一类描述过程发起企业的相关资源状况,一类描述环境企业的相关资源状况；步骤4,在用于优化的业务过程模型基础上,利用活动的个性化资源需求、企业具体的资源背景及环境企业中的资源条件三者中的资源包含关系,选择可能的合作企业,达到初步的合作企业优选；所述步骤4具体包括以下步骤：步骤4.1,进行企业间关系的判断,具体为：在一个过程超图模型PH中,对于e-(j)∈EE,如果SR(e-(i)),SR(e-(j))分别表示e-(i),e-(j)包含的过程相关资源,如果SR(e-(i))＝SR(e-(j)),则e-(i),e-(j)为竞争关系；如果则为合作关系；如果且SR(e-(i))≠SR(e-(j)),则这两个企业为既合作又竞争关系；步骤4.2,进行不同企业间关系的处理,选择合作企业及资源,具体为：在一个过程超图模型PH中,对于e-(j)∈EE,pe为处理后的相当企业,如果e-(i),e-(j)为合作关系,则pe＝e-(i)∪e-(j)；如果e-(i),e-(j)为竞争关系,则pe＝e-(i)或者pe＝e-(j)；步骤5,在达到初步合作企业优选的过程模型的基础上,利用有向超图的性质和模型上所附加的业务过程语义,根据企业内外具体的资源环境状况,进行过程结构优化变换；所述步骤5中的过程结构优化变化,具体包括以下步骤：步骤5.1,判断活动是否可合并；对于一个过程P,在其超图模型PH中,对于av-(i),av-(j)∈AV,且av-(i),av-(j)相邻,且相应的资源支持边为re-(i),re-(j)∈RE,|T(re-(i))|＝1,|T(re-(j))|＝1,re-(i),re-(j)为同一企业的资源,那么av-(i),av-(j)可合并,如果rv-(i)＝T(re-(i)),rv-(j)＝T(re-(j)),并且合并后的活动a-(u)的支持资源为rv-(i)和rv-(j)组合；步骤5.2,判断活动是否可划分；对于一个过程P,在其超图模型PH中,对于av-(i),av-(j)∈AV,av-(i),av-(j)相邻且存在公共支持资源rv-(k),对其进行或者C(av-(i),av-(j),rv-(k)～(+))划分或者C(av-(i),av-(j),rv-(k)～(-))划分,如果存在一种划分,划分后每个活动都有完全支持资源,则称这两个活动为可划分活动；步骤5.3,判断活动是否为必划分；对于一个过程P,在其超图模型PH中,对于av-(i)∈AV,如果r-(j)∈sr(av-(i)),r-(i)≠r-(j),且r-(i)∈{sr(av-(k))|k＝1,…,i-1},r-(j)∈{sr(av-(l))|l＝i+1,…,n},n为活动数,则av-(i)为必划分活动；步骤5.4,若活动可合并,则进行活动的合并处理；对于一个过程P,在其超图模型PH中,对于av-(i),av-(j)∈AV,且av-(i),av-(j)可合并,即相邻且存在公共完全支持资源,假设re-(j)∈RE,H(re-(i))＝av-(i),H(re-(j))＝av-(j),{T(re-(i))}＝{T(re-(j))},且合并后的活动为av-(u),则且H(re-(k))＝av-(u),T(re-(k))＝T(re-(i))；假设H(ie-(i))＝av-(i),T(oe-(j))＝av-(i),H(ie-(k))＝av-(j),T(oe-(l))＝av-(j),且如果H(ie-(m))＝av-(u),T(ie-(n))＝av-(u),则T(ie-(m))＝T(ie-(i))∪T(ie-(k))-H(oe-(j)),H(ie-(n))＝H(ie-(i))∪H(ie-(i))-T(ie-(j))；以及步骤5.5,若活动可划分,则对其资源进行资源划分处理；在过程P的有向超图模型PH中,对于av-(i),av-(j)∈AV,如果av-(i),av-(j)为可划分活动,且rv-(m)为一公共支持资源,如果边re-(i),re-(j)∈RE,且H(re-(i))＝av-(i),当进行C(av-(i),av-(j),rv-(m)～(+))切割时,则T(re-(i))＝T(re-(i))-rv-(m),T(re-(j))＝T(re-(j))；当进行C(av-(i),av-(j),rv-(m)～(-))切割时,则T(re-(i))＝T(re-(i)),T(re-(j))＝T(re-(j))-rv-(m)；至此,得到一组不同结构、不同支持资源的业务过程模型；步骤6,利用资源属性和过程属性之间的关系,及过程属性和活动属性之间的关系,根据业务过程发起者的目标,进行过程结构及支持资源的优选,获得结构和支持资源都优化的过程；所述步骤6中进行过程结构及支持资源的优选,具体为：计算业务过程的属性,定义过程属性为活动属性和过程结构的函数；活动属性是业务发起者企业和伙伴企业资源状况的函数,这样就建立了业务过程的属性和企业内外的资源属性之间的关系；之后,根据业务发起者的具体目标进行优化求解,至此,得到结构和支持资源都优化的业务过程。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;              林倞;                   王淮       </td>   <td>中山大学</td>   <td>一种数据驱动的物体图像修复系统及方法</td>   <td>广东省</td>   <td>CN102831584B</td>   <td>2015-04-22</td>   <td>本发明的一种数据驱动的物体图像修复系统及方法,属于图像修复技术领域。本发明的第一个目的是提供一种物体图像修复系统,包括依次连接的用户交互模块、物体匹配模块、形状修复模块和纹理修复模块以及独立的物体图像数据库和数据库标注模块；本发明的第二个目的是提供一种数据驱动的物体图像修复方法框架,包括以下步骤：数据预处理、轮廓与修复区域的标示、物体匹配、形状修复、纹理修复、数据后处理。本发明通过各模块的协同工作,克服了现有图像修复方法无法解决的物体缺失部分形状信息无法启发式推导、缺失部分无法在原图像中采样修复等问题,很好地对物体图像进行修复。</td>   <td>1.一种数据驱动的物体图像修复系统,其特征在于：包括依次连接的用户交互模块、物体匹配模块、形状修复模块、纹理修复模块和后处理模块以及独立作为数据准备与预处理的物体图像数据库和数据库标注模块；所述用户交互模块采用鼠标或数位板作为输入外设,用于在修复图片上标示修复区域和待修复物体的轮廓；所述物体匹配模块用于将用户标示的待修复物体轮廓在带标注的物体图像数据库中搜索具有最相似轮廓和颜色的物体的匹配图像；所述形状修复模块利用轮廓匹配模块搜索到的匹配图像,根据匹配图像是否与待修复物体的轮廓匹配来决定是否进行缩放处理,并在已与待修复物体的轮廓匹配的匹配图像的轮廓上按固定分块大小对纹理和结构信息进行采样组成样本字典,通过求全局最优解的方法在样本字典中寻找最优样本分块通过纹理合成技术合成到待修复物体的轮廓上完成形状修复；所述纹理修复模块用于对形状修复后剩余的物体内部、物体外部待修复区域,采用优先度引导的贪婪修复算法,即每修复一个图像分块时,都全局搜索一个最优的样本分块,进行纹理修复；所述后处理模块用于对纹理修复后的结果在物体边缘进行修边操作,消除人工修复痕迹；所述带标注的物体图像数据库为轮廓匹配模块寻找具有与待修复物体相似轮廓图像提供数据集,数据集中包括物体图像和标注对应图像中物体轮廓的掩膜图像；所述数据库标注模块用于人工对图像数据库中的物体图像进行轮廓标注并生成掩膜图像。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘小平;              黎夏;              黄康宁;              梁嘉咏;                   许晓聪       </td>   <td>中山大学</td>   <td>基于空间综合互信息的多时空谱遥感影像自动配准方法</td>   <td>广东省</td>   <td>CN102842137B</td>   <td>2015-04-22</td>   <td>本发明属于计算机图像处理和遥感技术领域,涉及一种基于空间综合互信息的多时空谱遥感影像自动配准方法。其包括如下步骤：利用配准变换参数对待配准影像进行映射；提取参考影像和映射后的待配准影像的边缘信息,通过边缘信息计算特征要素的空间位置信息；计算参考影像和映射后待配准影像之间的灰度相似性指数；构造空间综合互信息指数,其为灰度相似性指数与空间位置信息的乘积,其中空间位置信息和灰度相似性指数均为配准变换参数的目标函数；利用优化算法搜索最佳配准变换参数；利用最佳配准变换参数对待配准影像进行配准。本发明构造空间综合互信息作为相似性指数,实现多源遥感影像之间高精度、高鲁棒性、高性能的自动配准。</td>   <td>1.一种基于空间综合互信息的多时空谱遥感影像自动配准方法,其特征在于,包括如下步骤：		利用配准变换参数对待配准影像进行映射；		提取参考影像和映射后的待配准影像的边缘信息,通过边缘信息计算特征要素的空间位置信息；		计算参考影像和映射后待配准影像之间的灰度相似性指数；		构造空间综合互信息指数,其为灰度相似性指数与空间位置信息的乘积,其中空间位置信息和灰度相似性指数均为配准变换参数的目标函数；		利用优化算法搜索最佳配准变换参数；		利用最佳配准变换参数对待配准影像进行配准；		所述通过边缘信息计算特征要素的空间位置信息具体步骤是：		设定阈值,分别从参考影像和映射后的待配准影像的边缘信息中自动获取控制点；		根据自动获取的控制点用高斯距离模型来描述空间位置信息。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘宁;                   侯菊敏       </td>   <td>中山大学</td>   <td>一种基于Android的关键字驱动自动化测试框架</td>   <td>广东省</td>   <td>CN102819492B</td>   <td>2015-03-04</td>   <td>一种基于Android关键字驱动自动化测试框架,属于Android自动化测试领域。本发明的目的是实现从数据文件中直接导入测试用例进行测试,使测试数据与测试代码分离,降低测试数据与测试代码的耦合性。归纳出Android GUI测试的关键字,设计出与被测应用交互的关键字库,使得这些关键字可重用性高,实现了基于关键字驱动的Android GUI测试框架。本发明通过各模块的协调工作,克服了现有Android测试框架代码耦合性高,测试用例编写效率低下等缺点,使得测试用例的编写与测试代码的编写分离,提高了测试用例的编写效率。</td>   <td>1.一种基于Android的关键字驱动自动化测试框架,其特征在于：它包括了数据文件、处理器模块、驱动模块、测试脚本模块、结果分析模块；所述的数据文件包含了测试配置数据文件与业务测试数据文件；所述的测试配置数据文件,用于保存测试自动运行所需要的信息,是测试自动执行的核心,包含了应用程序运行的环境、被测应用路径、源数据文件的路径、测试结果保存路径；所述的处理器模块包括数据处理器、关键字处理器,其中所述的数据处理器主要用于处理不同的数据文件,从数据文件中读入数据,并根据下一级模块的需要,转换为相应的格式,以方便读取,为测试脚本代码提供数据。</td>   <td>G06F11/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谭洪舟;              朱雄泳;              陈荣军;                   陆许明       </td>   <td>中山大学</td>   <td>一种快速有效的图像增强方法</td>   <td>广东省</td>   <td>CN102722871B</td>   <td>2015-02-11</td>   <td>本发明公开了一种快速有效的图像增强方法,该方法步骤包括,首先获取灰度图,然后采用带背光补偿亮度保持的QDHE算法对获取的灰度图进行全局对比度的提升,进而得到全局对比度提升的灰度图,以及采用带噪声抑制的反锐化掩膜算法对获取的灰度图进行局部对比度的提升,进而得到局部对比度提升的灰度图,最后将全局对比度提升的灰度图和局部对比度提升的灰度图进行叠加,进而输出一幅增强图像的灰度图。本发明能够在防止高亮区域变得过增强的同时补偿暗区域以及在增强边缘信息的同时压制噪声点,进而大大提高图像的质量,而且具有较低的时间复杂度进而可实现实时处理。本发明作为一种快速有效的图像增强方法广泛应用在光学识别领域中。</td>   <td>1.一种快速有效的图像增强方法,其特征在于：该方法步骤包括：获取灰度图；采用带背光补偿亮度保持的QDHE算法对获取的灰度图进行全局对比度的提升,进而得到全局对比度提升的灰度图；采用带噪声抑制的反锐化掩膜算法对获取的灰度图进行局部对比度的提升,进而得到局部对比度提升的灰度图；将全局对比度提升的灰度图和局部对比度提升的灰度图进行叠加,进而输出一幅增强图像的灰度图；所述步骤采用带背光补偿亮度保持的QDHE算法对获取的灰度图进行全局对比度的提升,进而得到全局对比度提升的灰度图,其包括：采用压缩高亮直方图部分的方法对获取的灰度图的直方图进行处理,进而得到待处理灰度图；将待处理灰度图划分区域后计算出每个子区域的直方图；采用带门限剪切的动态区域划分方法对每个子区域的直方图进行处理后,每个子区域的直方图分别进行独立的直方图均衡,进而得到全局对比度提升的灰度图；所述步骤采用带噪声抑制的反锐化掩膜算法对获取的灰度图进行局部对比度的提升,进而得到局部对比度提升的灰度图,其包括：采用拉普拉斯算子对获取的灰度图进行边缘滤波,进而获得边缘图像；对边缘图像的直方图进行边缘判别,根据判别结果进而采用直方图均衡方法对边缘图像的直方图进行边缘自适应提升后得到局部对比度提升的灰度图；所述步骤采用压缩高亮直方图部分的方法对获取的灰度图的直方图进行处理,进而得到待处理灰度图中,所述压缩高亮直方图部分的方法,其采用的公式如下：h'(k)＝α(h(k))～(1/n)其中,h'(k)表示压缩后的灰度级k的直方图,h(k)表示原灰度图的灰度级k的直方图,α为常量,n为max(1,1+p-(1)-p-(2)),即n的值为1和1+p-(1)-p-(2)中较大的数,而p-(1)表示低照度区域的比例,p-(2)表示高照度区域的比例；所述步骤采用带门限剪切的动态区域划分方法对每个子区域的直方图进行处理后,每个子区域的直方图分别进行独立的直方图均衡,进而得到全局对比度提升的灰度图,其包括：对每个子区域的直方图进行动态分配范围；采用带门限剪切的方法对每个子区域的直方图进行修正；对每个子区域的直方图分别进行独立的直方图均衡后重建每个子区域内的亮度映射表,根据每个子区域的亮度映射表进而得到全局对比度提升的灰度图；所述步骤对每个子区域的直方图进行动态分配范围,其包括：计算每个子区域的直方图的动态划分范围,其计算的公式如下：span-(i)＝m-(i+1)-m-(i)其中,span-(i)表示第i个子区域的直方图的动态划分范围,m-(i)表示第i个子区域的直方图的最低端点,m-(i+1)表示第i个子区域的直方图的最高端点；计算每个子区域的直方图的动态划分范围和像素数量之和的比例因子,其计算的公式如下：factor-(i)＝span-(i)×log-(10)M-(i)其中,factor-(i)表示第i个子区域的比例因子,M-(i)表示第i个子区域的像素数量之和；计算每个子区域的直方图的新范围,其计算的公式如下：                                  range      i        =          (      L      -      1      )        &amp;times;          factor      i        /          &amp;Sigma;              k        =        1            N              factor      k       ]]>                  其中,range-(i)表示第i个子区域的直方图的新范围,L-1表示图像的最大亮度值,表示子区域的比例因子之和,N表示所有划分子区域的个数。</td>   <td>G06T5/00;G06T5/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         高成英;                   李招祺       </td>   <td>中山大学</td>   <td>一种改进的基于局部极值和像素值梯度的图像增强方法</td>   <td>广东省</td>   <td>CN102800066B</td>   <td>2015-01-07</td>   <td>本发明公开了一种基于图像梯度及局部极值的图像边缘保持滤波器算法。根据图像的像素值的梯度值以及局部极值点分布信息,判断图像中边缘的位置。由于本文所提算法是通过像素值梯度以及像素值的局部极值点判断图像边缘位置,因此能更精确地确定图像边缘。而在滤除图像中的噪音和细节纹理时,滤波器根据前面的判断,减少图像中的边缘在过滤中受到的影响,从而滤波器能将图像中物体的轮廓从原始图像中分离。</td>   <td>1.一种改进的基于局部极值和像素值梯度的图像增强方法,其特征在于：在双边滤波方法和局部极值滤波方法的基础上,通过将上述两种不同的滤波方法融合的方式,提出该方法,包括以下步骤：a.记输入图像I(x,y)大小为(b-a)×(d-c),在二维平面区域Ω:[a,b]×[c,d]上,输出图像为O(x,y)后采用以下步骤；b.将输出图像O(x,y)初始化为零；c.在输入图像左上角定义一个k×k的子图像I-(B)并设其水平与垂直方向移动的步长分别为h和v；d.对子图像I-(B)按照基于局部极值和像素梯度的滤波方法进行图像处理,要求对整个子图像的所有像素点进行处理,将其结果输出到子图像中心点所对应的输出图像O(x,y)的位置中；e.将子图像以水平方向移动步长h,若子图像没有超出图像边界,重复步骤e,否则进入下一步；f.将子图像以垂直方向移动步长v,若子图像没有超出图像边界,重复步骤e,否则进入下一步；g.当以上步骤完成后,将得到输出图像O(x,y)；其中,所述步骤d的计算方法步骤如下：(1).统计原始图像像素点的局部极值点个数:当点(x0,y0)的像素值最多比以其为中心的k×k邻域内k-1个点的像素值小时,算法则认为(x0,y0)是图像I的局部极大值点,类似地,算法用同样的方式判断图像的局部极小值点,上述计算方式相当于认为图像的纹理所造成的像素值振荡间隔最多只有k个像素；通过调整参数k的大小,最终的算法将各种频率的纹理去除,通过所述方法,统计像素点在k×k邻域内极值点的个数IExtrma；(2).计算基于局部极值和像素梯度的滤波器模板：在原始的双边滤波器基础上,通过引入局部极值信息到双边滤波器的模板,对双边滤波器的模板中像素域权重添加对应像素点的局部极值点个数IExtrma作为修正项,此时,滤波器模板不仅基于图像各点之间的像素值之差判断该点是否位于物体的边缘,同时根据像素点邻域内极值点的个数进行判断,从而避免将振动幅度大的纹理误判为物体的边缘。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         何嘉杰;              朝红阳;              杨铭;                   林倞       </td>   <td>中山大学</td>   <td>一种基于运动元素复用的二维动画合成方法</td>   <td>广东省</td>   <td>CN102609970B</td>   <td>2014-11-05</td>   <td>本发明公开了一种基于运动元素复用的二维动画合成方法,步骤1：选取角色素材和运动序列素材,其中角色素材背景色单一且角色单一,运动序列素材是二维骨架模型的姿态序列；步骤2：对选取的角色素材进行预处理操作；步骤3：为角色造型绑定运动序列,合成角色动画。本发明在创作效率上得到了很大的提高,用户只需要为角色造型设定关键控制点,绑定运动骨架,通过复用运动元素,即可轻松地赋予动漫角色任何运动,大大简化了动画合成的操作流程,减少重复创作的开销；支持复杂的骨骼运动,使得生成的动画相对于传统计算机辅助创作的刚性变化更为自然。</td>   <td>1.一种基于运动元素复用的二维动画合成方法,其特征在于包括：		步骤1：选取角色素材和运动序列素材,其中角色素材背景色单一且角色单一,运动序列素材是二维骨架模型的姿态序列；		步骤2：对选取的角色素材进行预处理操作,所述的预处理操作的具体流程如下：		21)从角色素材提取角色轮廓线；		22)根据取得的角色轮廓线,计算角色的轮廓闭包获得轮廓上关键的顶点集合；		步骤3：为角色造型绑定运动序列,合成角色动画,即生成形变网格；所述的运动序列目标素材从运动视频中提取；		上述二维骨架模型是扩展的骨架模型,模型上每一个关节点都带有相对深度信息,形变网格上的每个顶点的深度通过其与最近的两个关节点的距离来线性求解；		步骤3具体流程如下：		31)调整运动骨架模型的大小,使其符合角色造型的大小；		32)把角色造型上的各个关键控制点绑定到运动骨架模型上的关节点；		33)由这些关节点生成形变网格。</td>   <td>G06T13/80</td>  </tr>        <tr>   <td>中国专利</td>   <td>         江炼鑫;                   谭洪舟       </td>   <td>中山大学</td>   <td>一种用于RFID中间件的冗余数据过滤方法</td>   <td>广东省</td>   <td>CN102662988B</td>   <td>2014-10-29</td>   <td>本发明公开了一种用于RFID中间件的冗余数据过滤方法,包括以下步骤：在内存中创建用于存储RFID数据的多阶哈希表,所述多阶哈希表内创建有该RFID数据的标签节点；判断是否有RFID数据流,若否则结束进程,若是则执行下一步骤；判断RFID数据流中各RFID数据的状态；根据各RFID数据的状态对其进行冗余数据过滤处理。通过在内存中建立多阶哈希表,将中间件接收的RFID数据分配到多阶哈希表中,并通过判断该RFID数据的状态进行冗余数据过滤处理,实现了海量冗余RFID数据的过滤,大大减少了网络的传输量,从而为上层应用提供了更为干净、更有价值的RFID数据,并且本发明方法通过利用多阶哈希表的存储结构,大大提升了RFID数据的过滤效率。</td>   <td>1.一种用于RFID中间件的冗余数据过滤方法,其特征在于,包括以下步骤：		在内存中创建用于存储来自阅读器的RFID数据的多阶哈希表,所述多阶哈希表内创建有用于查询、删除该RFID数据的标签节点；		判断是否有RFID数据流,若否则结束进程,若是则执行下一步骤；		根据RFID数据的标签ID查询多阶哈希表中的标签节点,判断RFID数据流中各RFID数据的状态,所述RFID数据的状态包括：未知、捕捉和已存在；所述未知状态是指该RFID数据未存在多阶哈希表中；所述捕捉状态是指该RFID数据在多阶哈希表中已存在但未被确认；所述已存在状态是指该RFID数据在多阶哈希表中已被确认；		根据各RFID数据的状态对其进行冗余数据过滤处理,包括：		在未知状态下,将该RFID数据存储到多阶哈希表中,并为该RFID数据生成标签节点,将该RFID数据在整个数据传输通道中作为冗余数据过滤掉,转入捕捉状态；		在捕捉状态下,判断最近两次RFID数据的读取时间差是否超过时间阈值,若是则将该RFID数据从多阶哈希表中移除并转入未知状态,若否则更新该RFID数据的标签节点并判断该RFID数据的读取次数是否达到次数阈值,若未达到次数阈值则保持捕捉状态,将该RFID数据作为冗余数据过滤掉,若达到次数阈值则将该RFID数据加入输出队列,作为过滤后的干净数据提供给上层系统,并转入已存在状态；		在已存在状态下,判断最近两次RFID数据的读取时间差是否超过时间阈值,若是则将该RFID数据从多阶哈希表中移除并转入未知状态,若否则更新该RFID数据的标签节点并直接将该RFID数据作为冗余数据过滤掉；		所述多阶哈希表的创建包括以下步骤：		定义在多阶哈希表中存储RFID数据的标签节点,所述标签节点包括：标签ID、标签首次读取时间、标签末次读取时间及读取次数；		设定时间阈值、次数阈值及标签数据规模,所述时间阈值表征在该时间内一个RFID数据多次被读取则认定为重复数据；所述次数阈值表征只有读取次数达到该数值的RFID数据为稳定数据；所述标签数据规模表征该多阶哈希表内标签节点的容量；		设定多阶哈希表的最大桶数M和阶数N；		在内存中申请M*N个存储空间,以二维数组HashTable[M][N]表示,作为存储RFID数据的多阶哈希矩阵；		以基于标签ID的映射函数建立RFID数据与该RFID数据在多阶哈希表中存储位置的对应关系。</td>   <td>G06F17/30;G06K7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李小薪;                   戴道清       </td>   <td>中山大学</td>   <td>基于结构化误差编码的人脸遮挡检测方法</td>   <td>广东省</td>   <td>CN102750546B</td>   <td>2014-10-29</td>   <td>本发明提供一种检测准确率高、可行性好的基于结构化误差编码的人脸遮挡检测方法,适合于处理图像维数较低或遮挡面积较大情况。具体步骤为：步骤1：将待检测人脸图像数据和训练样本数据拉伸为列向量；步骤2：定义误差支撑,并初始化；步骤3：在最小化CD误差准则下,由误差支撑计算待检测人脸图像数据对由训练样本数据构成的字典的稀疏编码和重构误差；步骤4：根据重构误差估计误差支撑；步骤5：建立描述误差支撑的形态图,由形态图和重构误差,再次估计误差支撑；步骤6：迭代步骤3-5,得到重构误差序列和误差支撑序列；步骤7：选取最优误差支撑,并根据最优误差支撑获得待检测人脸图像中被遮挡像素点的集合。</td>   <td>1.基于结构化误差编码的人脸遮挡检测方法,其特征在于,包括以下步骤：步骤1：将待检测人脸图像数据和训练样本数据拉伸为列向量；步骤2：定义误差支撑,并初始化；步骤3：在最小化CD误差准则下,由误差支撑,计算待检测人脸图像数据对由训练样本数据构成的字典的稀疏编码和重构误差；步骤4：根据重构误差估计误差支撑；步骤5：建立描述误差支撑的形态图,由形态图和重构误差,再次估计误差支撑；步骤6：迭代步骤3-5,得到重构误差序列和误差支撑序列；步骤7：选取最优误差支撑,并根据最优误差支撑获得待检测人脸图像中被遮挡像素点的集合；所述步骤1中的将待检测的人脸图像和各训练样本拉伸为列向量是将m′n维的图像数据矩阵拉伸为M＝m′n维的列向量；所述步骤2中的误差支撑为s∈{-1,1}～(M),其中s-(i)＝-1表示未被遮挡,s-(i)＝1表示被遮挡；初始化误差支撑是将误差支撑s初始化为s-(i)＝-1,i＝1,...,M；i是s的下标,s-(i)表示s的第i个元素；所述步骤3中的由训练样本构成的字典是将每个拉伸处理后的训练样本,按列排放,构成字典；所述步骤3中的CD误差用于度量任意两个相同维数的向量和之间的误差,定义为：CD(a-(i),b-(i))＝1-exp(-|loga-(i)-logb-(i)|/σ),其中,q为经验常数；i是向量a和b的下标,a-(i),b-(i)表示a和b的第i个元素,M是拉伸后的列向量的维数,表示实数域中维数为M的向量的集合；所述步骤3中的待检测的人脸图像对由训练样本构成的字典的稀疏编码和重构误差按以下公式计算：            (      x      ,      e      )        =    arg          min              x        ,        e                    &amp;Sigma;              i        =        1            M              (                        s          &amp;CenterDot;                i            -                        s                      &amp;CenterDot;            &amp;CenterDot;                          i            )              e      i        s    .    t    .          e      i        =    CD          (              y        i            ,                        y          ^                i            )        ,          y      ^        =    Dx    ,    x    &amp;GreaterEqual;    0    ,   ]]>其中,x为非负稀疏编码,e为重构误差,D为由训练样本构成的字典,y为待检测的人脸图像；s.t.表示(x,e)需满足和x30的约束,e-(i)表示y-(i)和的CD误差；所述步骤4中估计误差支撑的具体步骤为：如果是首次迭代,t＝1,则对重构误差e进行两类均值聚类,得到误差支撑s,并初始化阈值t～((1))＝max{e-(i)|s-(i)＝-1}；否则,t&gt;1,对重构误差e进行阈值聚类,得到误差支撑            s      i        =                                        1            ,            |                          e              i                        |            >                          &amp;tau;                              (                t                )                                                                          -            1            ,            |                          e              i                        |            &amp;le;                          &amp;tau;                              (                t                )                                                          ,   ]]>其中,阈值            &amp;tau;              (        t        )              =                                                      &amp;tau;                              (                t                -                1                )                                      +                                          &amp;kappa;                -                1                                            T                -                1                                                    &amp;tau;                              (                1                )                                      ,            t            &amp;le;            T                                                              &amp;tau;                              (                t                -                1                )                                      -                                          &amp;kappa;                -                1                                            T                -                1                                                    &amp;tau;                              (                1                )                                      ,            t            >            T                                ,   ]]>T和k为经验参数,t为迭代次数；所述步骤5具体步骤为：步骤5.1：建立描述误差支撑s的形态图G＝(V,E,B),其中：V为G的顶点的集合V＝{1,2,...,M}且每个顶点v-(i)的类标为s-(i)；E为G的边的集合E＝{(i,j)|i,j∈V,||c-(i)-c-(j)||-(2)＝1},其中c-(i)＝[c-(i1),c-(i2)]～(T)、c-(j)＝[c-(j1),c-(j2)]～(T)是顶点v-(i)、v-(j)的坐标；B为G的各子图的边界的集合B＝{B-(k)|k＝-1,1},其中：B-(k)＝(V-(k),E-(k)),            v      ij      o        =    {          (      k      ,      l      )        |          (      k      ,      l      )        &amp;Element;    E    ,    k    &amp;Element;          v      i      0        ,    l    &amp;Element;          v      j      0        }    ;   ]]>k属于集合l属于集合步骤5.2：令s'＝s,由形态图G和重构误差e,再次估计误差支撑s：      s    =    arg          max      s              &amp;Sigma;                        (          i          ,          j          )                &amp;Element;        E                    &amp;lambda;      E              s      i              s      j        +          &amp;Sigma;              i        &amp;Element;        V              [          (      log              &amp;lambda;        &amp;CenterDot;            -              &amp;lambda;        &amp;CenterDot;                    e        i            )                      s        &amp;CenterDot;            i        +          (      log              &amp;lambda;                  &amp;CenterDot;          &amp;CenterDot;                    -              &amp;lambda;                  &amp;CenterDot;          &amp;CenterDot;                    +              &amp;lambda;                  &amp;CenterDot;          &amp;CenterDot;                            e        i            )                      s                  &amp;CenterDot;          &amp;CenterDot;                    i        +          &amp;lambda;      V              s      i        ]    -          &amp;Sigma;              i        &amp;Element;                  V          1                            &amp;lambda;      B              s      i        ,   ]]>其中,λ-(E)为光滑参数,            &amp;lambda;      &amp;CenterDot;        =          &amp;Sigma;              i        &amp;Element;        V                            s        &amp;CenterDot;            i      &amp;prime;        /          &amp;Sigma;              i        &amp;Element;        V                            s        &amp;CenterDot;            i      &amp;prime;              e      i        ,          &amp;lambda;              &amp;CenterDot;        &amp;CenterDot;              =          &amp;Sigma;              i        &amp;Element;        V                            s                  &amp;CenterDot;          &amp;CenterDot;                    i      &amp;prime;        /          &amp;Sigma;              i        &amp;Element;        V                            s                  &amp;CenterDot;          &amp;CenterDot;                    i      &amp;prime;              (      1      -              e        i            )        ,   ]]>λ-(B)为边界参数；所述步骤6的重构误差序列为E＝{e～((t))|t＝1,2,...,2T-1},其中e～((t))为步骤3-5的第t次迭代所产生的重构误差；误差支撑序列为S＝{s～((t))|t＝1,2,...,2T-1},其中s～((t))为步骤3-5的第t次迭代所产生的误差支撑；所述步骤7的具体步骤为：步骤7.1：令                    E        &amp;CenterDot;                    (        t        )              =          (      1      +      log              (                  &amp;Sigma;                      i            &amp;Element;            V                                                s            &amp;CenterDot;                    i                      (            t            )                                    e          i                      (            t            )                          /                  &amp;Sigma;                      i            &amp;Element;            V                                                s            &amp;CenterDot;                    i                      (            t            )                          )            )              &amp;Sigma;              i        &amp;Element;        V                            s        &amp;CenterDot;            i              (        t        )              ,   ]]>其中V＝{1,2,...,M}；其中步骤7.2：令            E      &amp;CenterDot;        =    {                  E        &amp;CenterDot;                    (        t        )              |    t    =    1    ,    .    .    .    ,    2    T    -    1    }   ]]>,对所有t＝1,...,2T-1,规范化和至区间[0,1]：                    E        &amp;CenterDot;                    (        t        )              =                                        E            &amp;CenterDot;                                (            t            )                          -        min                  E          &amp;CenterDot;                            max                  E          &amp;CenterDot;                -        min                  E          &amp;CenterDot;                      ,                  R                  &amp;CenterDot;          &amp;CenterDot;                            (        t        )              =                                        R                          &amp;CenterDot;              &amp;CenterDot;                                            (            t            )                          -        min                  R                      &amp;CenterDot;            &amp;CenterDot;                                      max                  R                      &amp;CenterDot;            &amp;CenterDot;                          -        min                  R                      &amp;CenterDot;            &amp;CenterDot;                                ;   ]]>步骤7.3：对误差能量进行边界正则化：            C              (        t        )              =                  E        &amp;CenterDot;                    (        t        )              -          &amp;lambda;      B                      R                  &amp;CenterDot;          &amp;CenterDot;                            (        t        )              ,   ]]>其中,            &amp;lambda;      B        =                            &amp;Sigma;                      t            =            1                                2            T            -            2                          |                              E            &amp;CenterDot;                                (            t            +            1            )                          -                              E            &amp;CenterDot;                                (            t            )                          |                              &amp;Sigma;                      t            =            1                                2            T            -            ...</td>   <td>G06K9/62</td>  </tr>        <tr>   <td>中国专利</td>   <td>              张力       </td>   <td>中山大学肿瘤防治中心</td>   <td>基于云计算的生活质量情况收集方法</td>   <td>广东省</td>   <td>CN103226798B</td>   <td>2014-10-15</td>   <td>本发明公开了一种基于云计算的生活质量情况收集方法,包括如下步骤：(1)利用移动端采集用户信息,将其保存到数据库中,并添加唯一标示符进行区别；(2)通过数据库中的标识符识别并上传没有同步过的数据,并下载服务器上的新数据。本发明对病人生活质量长期持续的个体化监测,科学的收集和分析每一个病人的生活质量情况,结合个体化情况,选择最合理、最经济的治疗方案,提高病人的生活质量和生存获益,使不同病人的不同生活质量变化情况得到充分的考虑,实现效益最优,避免经验性选择造成的医疗资源浪费。</td>   <td>1.一种基于云计算的生活质量情况收集方法,包括如下步骤：(1)利用移动端采集用户信息,将其保存到数据库中,并添加唯一标识符进行区别；(2)通过所述数据库中的标识符识别并上传没有同步过的数据,并下载服务器上的新数据；上传时,从数据库中提取用户数据以及相应的答卷数据,封装成轻量级的数据交换格式的数据包,然后进行加密上传,同时上传过程将上传上一次的同步时间,由服务器判断移动端的同步状态以及需要同步的数据,移动端从服务器同步到新的数据进行解密,再以固定的格式进行解析,保存到所述数据库。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郑慧诚;                   李俊       </td>   <td>中山大学</td>   <td>一种基于多摄像机信息融合的目标匹配与跟踪系统及方法</td>   <td>广东省</td>   <td>CN102629385B</td>   <td>2014-09-24</td>   <td>本发明公开了一种基于多摄像机信息融合的目标匹配与跟踪系统及方法,系统包括单摄像机目标检测模块、单摄像机目标跟踪模块、单摄像机目标关键点特征提取模块,多摄像机目标匹配模块以及目标模型在线更新模块；在系统中建立与目标对应的模型,分别基于局部颜色和方向直方图这两种特征计算目标与模型的相似度,最后进行决策级的融合,将融合的结果作为目标匹配的依据。匹配上的目标特征用于模型的更新,实现对目标的自适应跟踪。本发明可提高多摄像机目标匹配对于遮挡、环境、光照、角度等的鲁棒性,有利于实现多摄像机视频监控系统对目标的鲁棒协同跟踪。</td>   <td>1.一种基于多摄像机信息融合的运动目标匹配与跟踪方法,其特征在于,包括下述步骤：首先,利用高斯混合模型进行视频序列中运动目标的检测,利用均值偏移法对单摄像机内的目标进行跟踪,然后对检测到的目标区域进行小波变换,以检测具有视觉显著性的关键点；其次,在关键点局部区域提取颜色特征和局部方向直方图特征,以刻画前景目标,并作为目标模型更新的输入；最后,在融合关键点处局部颜色特征和方向直方图特征的基础上,实现运动目标与模型间的匹配；同时,与模型匹配的前景目标特征被用于在线更新模型,以实现对目标的自适应跟踪,匹配时,先分别基于目标关键点颜色特征和局部方向直方图特征进行相似度计算,然后融合两种相似度,设第一目标与第二目标基于颜色特征得到的相似度为S-(1),基于直方图特征得到的相似度为S-(2),则融合后的相似度为：S＝wS-(1)+(1-w)S-(2)其中w用于调整两种特征在匹配决策中的比重。</td>   <td>G06T7/20;H04N7/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈成龙;                   倪江群       </td>   <td>中山大学</td>   <td>一种数字图像中值滤波的盲检测方法</td>   <td>广东省</td>   <td>CN102592151B</td>   <td>2014-08-06</td>   <td>本发明提出一种数字图像中值滤波的盲检测方法,分析了中值滤波对图像边缘良好的保持特性,结合中值滤波处理对相邻像素相关性的影响以及对噪声的抑制,将边缘区域的统计特征用于检测图像是否经过中值滤波。本发明将图像分割成互不重叠的子块,并根据各子块的梯度特征将子块划分为不同类型；对子块应用邻域线性预测模型处理,提取子块的预测系数形成边缘预测矩阵EBPM；然后将EBPM特征作为支持向量机的输入,训练得到图像中值滤波检测器,从而通过检测器来检测图像是否经过中值滤波。本发明能够准确地检测出经过中值滤波的图像,具有良好的鲁棒性,能有效抵抗JPEG压缩处理,属于图像认证领域。</td>   <td>1.一种数字图像中值滤波的盲检测方法,其特征是,包括以下步骤： 		步骤一：图像分块,即将图像分割成互不重叠的子块,根据各子块的梯度特征,将子块划分为三种类型,三种类型为：水平类型、垂直类型和其他类型； 		步骤二：特征提取,即对每种类型的子块用邻域线性预测模型处理,用最小二乘法估计预测系数,并将各类型的系数重新排列形成边缘预测矩阵； 		步骤三：支持向量机训练,即将边缘预测矩阵作为支持向量机的输入进行训练；步骤四：检测图像,即通过训练得到中值滤波检测器来检测待测图像是否经过中值滤波； 		所述步骤二中的邻域线性预测模型为：列向量包含所有子块中点的灰度值,矩阵Y的每一行是每个子块中点的邻域像素值,列向量代表预测系数,则邻域线性预测模型由描述,所述最小二乘法得出的估计预测系数为 		                  所述步骤二中的边缘预测矩阵为：其中和分别为用最小二乘算法估计出来的三个类型子块的预测系数,FBBPM为边缘预测矩阵。</td>   <td>G06K9/66</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈立楷;              卢伟;              倪江群;              孙伟;                   戴路       </td>   <td>中山大学</td>   <td>一种图像区域描述方法和基于该描述方法的复制图像检测方法</td>   <td>广东省</td>   <td>CN102592276B</td>   <td>2014-07-09</td>   <td>本发明公开了一种图像区域描述方法和基于该描述方法的复制图像检测方法。所述图像区域描述方法包括如下步骤：构造扇形掩模,将扇形掩模的内角A旋转一周,得到m个方向上的扇形掩模S-(1),S-(2),……,S-(m)；提取统计特征向量重排统计特征向量：将统计特征向量中均值最大的扇形掩模S-(i)定为圆形区域的方向标记排在首位,其他m-1个扇形掩模按照原来的排列顺序依次进行重新排列,获得重排后的统计特征向量获得区域描述特征向量描述图像分块。本发明操作简单、辨别度高,有效地应用于数字图像的复制-旋转-粘贴检测和复制-翻转-粘贴检测中,不仅可通过图像描述特征之间的匹配来揭示复制的区域,还可确定复制区域之间相对旋转过的角度。</td>   <td>1.一种图像区域描述方法,其特征在于,包括如下步骤：构造扇形掩模,将所述扇形掩模的内角A旋转一周,得到m个方向上的扇形掩模S-(1),S-(2),……,S-(m),其中m=360/A,并将所述m个方向上的扇形掩模顺序排列；提取统计特征向量：计算图像中的图像分块在每个方向的扇形掩模中所有像素值的均值和标准差获得统计特征向量重排统计特征向量：将统计特征向量中均值最大的扇形掩模S-(i)定为圆形区域的方向标记排在首位,其他m-1个扇形掩模按照原来的排列顺序依次进行重新排列,获得一个重排后的统计特征向量获得区域描述特征向量描述所述图像分块：将所述重排后的统计特征向量附带上图像分块在完整图像上的位置信息(x,y),获得一个区域描述特征向量描述所述图像分块。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         蔡铭;              林郁山;                   罗鹏       </td>   <td>中山大学</td>   <td>一种不同行驶状态下的机动车噪声排放预测方法</td>   <td>广东省</td>   <td>CN102542121B</td>   <td>2014-07-02</td>   <td>本发明提供一种不同行驶状态下的机动车噪声排放预测方法,所述方法包括以下步骤：建立基于车辆的速度、加速度与噪声声压级的噪声关系统计模型；选择状态参数,包括车辆型号、速度值、加速度值；将选择的状态参数输入噪声关系统计模型中,计算出与所述状态参数对应的噪声声压值；所述噪声关系统计模型还包括：车辆参数、速度调节参数、与速度参数对应的加速度参数和噪声声压级；所述车辆参数与所述状态参数相对应,所述噪声声压级根据速车辆型号参数、度调节参数、与速度调节参数对应的加速度参数以及状态参数计算得出,可以很好的适用于道路场景复杂、车辆行驶状态变化频繁的城市道路交通噪声预测计算。</td>   <td>1.一种不同行驶状态下的机动车噪声排放预测方法,其特征在于,所述方法包括以下步骤:建立基于车辆的速度、加速度与噪声声压级的噪声关系统计模型；选择状态参数,包括车辆车型、速度值、加速度值；将选择的状态参数输入噪声关系统计模型中,计算出与所述状态参数对应的噪声声压值；所述噪声关系统计模型还包括：车辆参数、速度调节参数、与速度参数对应的加速度参数和噪声声压级；所述车辆参数、速度调节参数、与速度参数对应的加速度参数和噪声声压级与所述状态参数相对应,根据相应的状态参数调用相应的车辆参数、速度调节参数、与速度参数对应的加速度参数,从而计算出相应的噪声声压级；所述噪声关系统计模型包括：小型车噪声关系统计子模型、中型车噪声关系统计子模型和大型车噪声关系统计子模型；所述小型车噪声关系统计子模型还包括：小型车加速状态项,用于预测小型车处于加速状态时的噪声声压级；小型车减速状态项,用于预测小型车处于减速状态时的噪声声压级；小型车匀速状态项,用于预测小型车处于匀速状态时的噪声声压级；小型车怠速状态项,用于预测小型车处于怠速状态时的噪声声压级；所述中型车噪声关系统计子模型还包括：中型车加速状态项,用于预测中型车处于加速状态时的噪声声压级；中型车减速状态项,用于预测中型车处于减速状态时的噪声声压级；中型车匀速状态项,用于预测中型车处于匀速状态时的噪声声压级；中型车怠速状态项,用于预测中型车处于怠速状态时的噪声声压级；所述大型车噪声关系统计子模型还包括：大型车加速状态项,用于预测大型车处于加速状态时的噪声声压级；大型车减速状态项,用于预测大型车处于减速状态时的噪声声压级；大型车匀速状态项,用于预测大型车处于匀速状态时的噪声声压级；大型车怠速状态项,用于预测大型车处于怠速状态时的噪声声压级；所述噪声关系统计模型具体为：L-(0)=X+YlgV±Za,其中L-(0)为噪声声压级,X为车辆参数,Y为速度调节参数,V为速度值,Z为加速度参数,a为加速度值；所述小型车噪声关系统计子模型为：小型车加速状态项：L-(0)=35.559+19.4lgV+1.041a小型车减速状态项：L-(0)=24.862+25.747lgV+0.329a小型车匀速状态项：L-(0)=28.124+24.765lgV小型车怠速状态项：L-(0)=53.787；所述中型车噪声关系统计子模型为：中型车加速状态项：L-(0)=60.131+7.758lgV+0.758a中型车减速状态项：L-(0)=44.995+16.621lgV-0.32a中型车匀速状态项：L-(0)=16.795+36.323lgV中型车怠速状态项：L-(0)=58.485；所述大型车噪声关系统计子模型为：大型车加速状态项：L-(0)=68.924+6.435lgV+2.58a大型车减速状态项：L-(0)=61.896+10.205lgV+0.157a大型车匀速状态项：L-(0)=33.352+28.562lgV大型车怠速状态项：L-(0)=63.317。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王彪;                   黄卓垚       </td>   <td>中山大学</td>   <td>一种用于光学体全息虹膜识别的图像前处理方法</td>   <td>广东省</td>   <td>CN101866420B</td>   <td>2014-06-04</td>   <td>本发明涉及虹膜识别技术领域,特别是一种用于光学体全息虹膜识别的图像前处理方法,对采集的虹膜图像进行处理,所述方法包括：(11)对采集的虹膜图像进行虹膜区域的定位,确定虹膜内外边缘及人眼上下眼睑；(12)确定虹膜区域后,对虹膜进行特征提取与编码；(13)对编码后的数据进行光学体全息识别二次编码。本发明用于光学体全息虹膜识别的前处理过程,实现了把光学体全息图像识别技术应用到虹膜识别领域。光学体全息虹膜识别技术是光学体全息图像识别在虹膜识别中的应用,具有并行识别虹膜的功能。采用本发明的处理方法,实现虹膜的快速定位,减少计算量、提高计算准确度,同时提高虹膜识别率。</td>   <td>1.一种用于光学体全息虹膜识别的图像前处理方法,对采集的虹膜图像进行处理,其特征在于,所述方法包括：(11)对采集的虹膜图像进行虹膜区域的定位,确定虹膜内外边缘及人眼上下眼睑；(12)确定虹膜区域后,对虹膜进行特征提取与编码；(13)对编码后的数据进行光学体全息识别二次编码；所述步骤(11)的具体步骤如下：首先进行虹膜内外边缘定位,具体步骤如下：(211)将采集的虹膜图像按比例缩小；(212)进行形态学滤波；(213)按照亮度接近最小值和位置处于图像的中心附近为依据将图像二值化；(214)根据瞳孔区域的尺寸和虹膜半径之间的统计关系,确定虹膜外边缘和内边缘的搜索区域和搜索半径；(215)对(212)中所述形态学滤波之后的图像使用canny算子提取边缘,得到边缘图,并将虹膜外边缘搜索区域以外的边缘点去掉,对所有可能的半径进行霍夫变换,每一个可能半径得到的霍夫变换图中选取三个亮度最大的峰值作为候选最佳霍夫峰；(217)在找到外边缘半径之后,将(215)中所述边缘图放大,并将虹膜内边缘搜索区域以外的边缘点去掉,对所有可能的半径进行霍夫变换,每一个可能半径得到的霍夫变换图中选取三个亮度最大的峰值作为候选最佳霍夫峰,在所有候选最佳霍夫峰中选取符合最小判断依据的峰值点；进行人眼上下眼睑定位,具体步骤如下：(221)采用霍夫变换进行圆形搜索,离瞳孔圆心最近的圆弧是上眼睑；(222)对Imo进行180度旋转,所述Imo的获取方法为：先将虹膜图像进行形态学滤波得到定位图像Imr,去除反光点和睫毛的细节,然后再进行二值化,找出在图像中心附近的低亮度区域即为瞳孔的大致区域,然后找出这一区域重心C和此区域测量其横纵宽度再取两者平均值作为瞳孔的大致直径d；将Imr按比例缩小,然后选取以C为中心,直径为3d的圆形区域作为虹膜外边缘定位的目标区域；使用canny算子提取Imr的目标区域的边缘,其他部分先屏蔽掉,得到Imo；(223)采用霍夫变换进行圆形搜索,离瞳孔圆心最近的圆弧是下眼睑；(224)得到定位结果。</td>   <td>G06K9/36</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王俊祥;              倪江群;                   潘金伟       </td>   <td>中山大学</td>   <td>利用直方图平移的可逆水印方法</td>   <td>广东省</td>   <td>CN102567942B</td>   <td>2014-06-04</td>   <td>本发明提出一种基于直方图平移的可逆水印方法,对多媒体版权保护具有重大的实用价值。本发明对传统的直方图平移算法进行两大项改进：第一,通过将比特位图的生成过程放置于水印嵌入之后而非预处理阶段,能够使得比特图中的‘1’与‘0’更加失衡,从而更易于压缩,提高嵌入容量。第二,本发明提出“两步嵌入法”的可逆水印算法。通过将图像分为上下两大区域,对第一区域进行水印嵌入并将生成的边信息嵌入至该区域含水印像素的最低有效位中,然后将剩余的水印信息和替换出来的最低有效位信息嵌入至第二区域,实现了水印的盲提取,解决直方图平移算法需要额外传送边信息的困扰。</td>   <td>1.一种利用直方图平移的可逆水印方法,包括水印嵌入过程、水印提取过程和图像恢复过程,其特征是,对于一幅N-像素8-比特的灰度载体图像,x-(i)表示灰度图第i个像素的灰度值,其中0≤i≤N-1,需要嵌入的水印为w,所述水印嵌入过程包括以下步骤：(1)计算载体图像像素间的差值,生成直方图；(2)根据直方图和水印w确定嵌入的层数m；(3)图像像素值介于[0,m-1]∪[255-m+1,255]的像素标记为POPs,其余像素标记为R-POPs；(4)将水印w分成m部分,w={w-(1),w-(2)...,w-(m)},初始化层数k=1,进行水印嵌入：对于第k层嵌入,选择一对优化的峰值点和零点,分别用P-(k)和Z-(k)表示,然后用差值域直方图平移方法嵌入水印w-(k)；如果k≠m,则令k=k+1,并嵌入下一层的水印；直到进入最后一层,用两步嵌入法将w-(m),压缩的位图,边信息和总的嵌入层数m嵌入到第m层中；所述两步嵌入法包括以下步骤：(401)根据载体图像生成直方图,选择直方图中最高频率点作为“峰值点”,并以直方图中距峰值点最近的零频率点为“零点”；(402)第一步嵌入：将载体图像分成两个区域,其中用以嵌入边信息的区域为“区域一”,其他为“区域二”,对“区域一”进行直方图平移操作并嵌入部分水印；(403)边信息的嵌入：根据密钥K确定“区域一”中用于隐藏边信息的水印像素位置,利用最低有效位替换技术将直方图的边信息隐藏到水印像素的最低有效位中；(404)第二步嵌入：利用直方图平移技术将剩余水印信息和原替换像素的最低有效位嵌入到“区域二”；或所述两步嵌入法,包括以下步骤：(411)将水印w-(m)分为三部分,w-(m)={w-(m)(1),w-(m)(2),w-(m)(3)},令SI={(P-(k),Z-(k))|1≤k≤m},对标记为POPs的像素进行差值域直方图平移并嵌入水印w-(m)(1),识别出溢出的位置,生成位图,LM和SI分别标记压缩后的位图和边信息,并进行直方图收缩操作；(412)第一步嵌入：将载体图像分成两个区域,其中用以嵌入边信息的区域为“区域一”,其他为“区域二”；利用差值域直方图平移方法将w-(m)(2)隐藏到“区域一”的R-POPs中,对相应的像素重建图像；(413)用最低有效位替换的方法将LM、SI和m嵌入到“区域一”水印图像的最低有效位中,具体的位置由密钥K控制；(414)第二步嵌入：将替换出来的最低有效位信息和w-(m)(3)嵌入到“区域二”中的R-POPs中。</td>   <td>G06T1/00;G06F21/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李熙莹;              罗玲;              王镇波;                   陈玲       </td>   <td>中山大学</td>   <td>一种道路指路标志的快速定位方法以及系统</td>   <td>广东省</td>   <td>CN102609702B</td>   <td>2014-04-02</td>   <td>本发明公开了一种道路指路标志的快速定位方法以及系统,该系统包括获取单元、分割单元、区域获取单元以及定位单元。该方法是,首先获取道路图像,然后将获取的道路图像分割成上、下两部分图像,跟着采用基于RGB颜色模型的蓝色检测模型,对上部分图像进行有效候选区域的获取,最后对获取的有效候选区域进行水平长直线检测,进而定位指路标志。通过使用本发明,由于本发明采用直线特征检测替代传统的矩形形状特征检测,因此能够大大地缩短进行定位指路标志这一过程的时间,而且鲁棒性大大提高。本发明作为一种道路指路标志的快速定位方法以及系统广泛应用在交通标志识别领域中。</td>   <td>1.一种道路指路标志的快速定位方法,其特征在于：该方法步骤包括：		A、获取道路图像；		B、将获取的道路图像分割成上、下两部分图像；		C、采用基于RGB颜色模型的蓝色检测模型,对上部分图像进行有效候选区域的获取；		D、对获取的有效候选区域进行水平长直线检测,进而定位指路标志；		所述步骤C中基于RGB颜色模型的蓝色检测模型是根据蓝色的R、G、B三通道之间的关系进行建立的,该关系包括：		B通道的值是最大的,且B通道的值大于80；		R通道的值小于G通道的值；		(B-G)+(B-R)的值大于100；		G-R的绝对值小于80。</td>   <td>G06K9/32;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭怡适;              朝红阳;              王建明;              单梁;              梁柱锦;              钟华平;              姚良超;              付磊;              马冰磊;              陈芮;              黄缨宁;                   林宇       </td>   <td>中山大学</td>   <td>一种基于手机的色盲图像转换系统及其应用方法</td>   <td>广东省</td>   <td>CN102289789B</td>   <td>2014-03-26</td>   <td>一种基于手机的色盲图像转换系统,所述系统包括图像获取装置、用于对获取图像进行处理的图像处理装置和显示图像的显示装置,所述图像处理装置包括：用于在处理过程中创建一个或多个用户设置项的设置模块；用于在处理过程中根据用户设置项对图像上至少一种颜色进行转换的转换模块；所述转换模块包括：用于在处理过程中根据用户设置项对图像进行色盲模拟转换的模拟单元,所述模拟单元用于实现对各种异色觉的模拟；用于在处理过程中根据用户设置项对图像进行色觉颜色翻译转换的翻译单元；是一种能帮助色觉异常者在需要的时候能够随时随地对颜色信息进行有效沟通和理解的技术和装置。</td>   <td>1.一种基于手机的色盲图像转换系统所实现的应用方法,其特征在于,所述系统包括图像获取装置、用于对获取图像进行处理的图像处理装置和显示图像的显示装置,所述图像处理装置包括：用于在处理过程中创建一个或多个用户设置项的设置模块；用于在处理过程中根据用户设置项对图像上至少一种颜色进行转换的转换模块；所述转换模块包括：用于在处理过程中根据用户设置项对图像进行色盲模拟转换的模拟单元,所述模拟单元用于实现对各种异色觉的模拟；用于在处理过程中根据用户设置项对图像进行色觉颜色翻译转换的翻译单元；所述方法包括以下步骤：接收需要显示的图像信号然后进行处理；在处理过程中创建一个或多个用户设置项；在处理过程中根据用户设置项对所述图像上至少一种颜色进行转换；显示转换后的图像；所述色觉颜色翻译转换采用替代补偿算法,使用色觉异常者能够感知的信号,替代无法感知的颜色信息,具体步骤如下：根据色异类型,调用模拟单元得出原图的模拟图,表达式如式6,模拟图除去了色异者无法感知的那部分颜色信息；                                                                              R              x                                                                          G              x                                                                          B              x                                            =          D      ,                                            R                                                G                                                B                               ]]>              式6用原图减去模拟图,得到差分图,差分图代表色异者无法感知的那部分颜色信息,表达式如式7,                                                                              R              d                                                                          G              d                                                                          B              d                                            =                                        R                                                G                                                B                                -                                                      R              x                                                                          G              x                                                                          B              x                                           ]]>               式7利用替代补偿算法,将差分图替代为色异者能够感知的信号,得到替代图,矩阵                                          R            d                                                            G            d                                                            B            d                               ]]>表示差分图,                                          R            r                                                            G            r                                                            B            r                               ]]>表示替代图,D表示替代变换矩阵,替代算法可表示为：                                                                              R              r                                                                          G              r                                                                          B              r                                            =                                        D                                                                                                                          R                      d                                                                                                                                  G                      d                                                                                                                                  B                      d                                                                                                               ]]>          式8通过修改替代变换矩阵D,可以得到不同的替代信号,供色异者选择最合适的翻译效果。</td>   <td>G06T5/00;H04M1/725</td>  </tr>        <tr>   <td>中国专利</td>   <td>         吴昊天;                   黄继武       </td>   <td>中山大学</td>   <td>一种基于直方图中值保持的可逆水印嵌入和提取方法</td>   <td>广东省</td>   <td>CN102609896B</td>   <td>2014-03-26</td>   <td>本发明公开了一种基于直方图中值保持的可逆水印嵌入和提取方法。包括如下步骤：进行水印嵌入,其包括：统计原始媒体的直方图并计算直方图的中值；选取水印数据嵌入区间：选取直方图中值区间和经过平移获得的与中值区间相邻的一个空出区间；进行水印数据嵌入：将水印数据嵌入中值区间中,将中值区间中的部分值分割到与其相邻的空出区间内；进行水印提取,其包括：统计含水印数据媒体的直方图；计算直方图中值并定位水印数据嵌入区间；提取水印数据；将空出区间内的值移回到原来区间中,并将其他区间内的值进行反向平移恢复原始媒体。本发明可自动识别水印嵌入位置,无需任何边信息即可提取出嵌入在媒体中的水印信息并无失真地恢复原始媒体。</td>   <td>1.一种基于直方图中值保持的可逆水印嵌入和提取方法,其特征在于,包括如下步骤：		(1)进行水印嵌入,其包括：		(11)统计原始媒体的直方图并计算直方图的中值；		(12)选取水印数据嵌入区间：选取直方图中值区间,平移除直方图中值区间外的其他区间内的值将与直方图中值区间相邻的一个区间空出,将中值区间和空出区间作为水印嵌入数据区间；		(13)进行水印数据嵌入：将水印数据嵌入直方图中值区间中,根据嵌入的水印数据将直方图中值区间中的部分值分割到与其相邻的空出区间内,完成水印数据的嵌入；		(2)进行水印提取,其包括：		(21)统计含水印数据的媒体的直方图；		(22)计算直方图的中值并定位出水印数据嵌入区间；		(23)提取水印数据：根据水印数据嵌入区间内的值提取所嵌入的水印数据；		(24)媒体恢复：根据水印数据将空出区间内的值移回到原来区间中,并将其他区间内的值进行反向平移恢复原始媒体；		在所述步骤(11)中计算直方图中值前还对直方图区间进行防溢出预处理；		所述防溢出预处理的具体步骤是：判断直方图中是否存在边缘区间,若不存在则不执行修改操作直接进行直方图中值计算,否则修改所述边缘区间的值并记录被修改值的位置信息,并将被修改值的位置信息作为嵌入数据的一部分嵌入直方图中；		提取水印数据时还同时将被修改值的位置信息提取出来,进行媒体恢复时,还根据被修改值的位置信息将被修改值进行恢复。</td>   <td>G06T1/00;G06T5/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              蔡琼;              李峰;                   徐阳群       </td>   <td>中山大学</td>   <td>一种图像增强处理的方法</td>   <td>广东省</td>   <td>CN101882305B</td>   <td>2014-02-05</td>   <td>本发明实施例公开了一种图像增强处理的方法,包括：对原始图像通过二维经验模式分解BEMD得到图像的固有模态函数IMF；对IMF中的高频IMF进行小波变换,将IMF进行5层小波分解,分别得到每个IMF分量的小波系数；对进行小波变换的高频IMF进行小波自适应去噪,第1层使用双阈值增强,第2,3层使用自适应增强,第4,5层使用单阈值增强；对进行小波自适应去噪的高频IMF进行小波逆变换；对IMF中的低频IMF和进行小波逆变换的高频IMF进行合成处理,得到增强后的图像。通过实施本发明,能够使去除图像的噪声同时将图像增强,将有用的信息突出。</td>   <td>1.一种图像增强处理的方法,其特征在于,包括：对原始图像通过二维经验模式分解BEMD得到图像的固有模态函数IMF；对IMF中的高频IMF进行小波变换,将IMF进行5层小波分解,分别得到每个IMF分量的小波系数；对进行小波变换的高频IMF进行小波自适应去噪,第1层使用双阈值增强,第2,3层使用自适应增强,第4,5层使用单阈值增强；对进行小波自适应去噪的高频IMF进行小波逆变换；对IMF中的低频IMF和进行小波逆变换的高频IMF进行合成处理,得到增强后的图像。</td>   <td>G06T5/10</td>  </tr>        <tr>   <td>中国专利</td>   <td>         朱为鹏;                   罗笑南       </td>   <td>中山大学</td>   <td>一种面向普适终端的三维网格模型连续多分辨率编码方法</td>   <td>广东省</td>   <td>CN102324107B</td>   <td>2013-07-24</td>   <td>本发明实施例公开了一种面向普适终端的三维网格模型连续多分辨率编码方法,所述方法包括：服务器端采用特征强化的二次误差测度方法对网格模型进行简化；所述服务器端基于上述简化过程构建分辨率连续可调的多分辨率网格结构；所述服务器端将所述分辨率连续可调的多分辨率网格结构传输至普适终端；所述普适终端根据终端屏幕的分辨率大小和网格结构携带的分辨率信息确定所接收的多分辨率网格结构对应的分辨率大小。实施本发明实施例,可以避免三维网格模型在分辨率较小时所出现的网格特征损失过多的情况,从而避免多分辨率构造方法会碰到的在较小分辨率时出现的严重失真问题；另外,可较好改善模型分辨率与屏幕分辨率不匹配的情况。</td>   <td>1.一种面向普适终端的三维网格模型连续多分辨率的编码方法,其特征在于,所述方法包括：服务器端采用特征强化的二次误差测度方法对网格模型进行简化,所述服务器端采用特征强化的二次误差测度方法对网格模型进行简化的步骤包括：计算每一个网格顶点处对应的离散平均曲率值及二次误差测度值；根据所述每一个网格顶点处对应的离散平均曲率值及二次误差测度值计算每一条网格边对应的特征强化的二次误差测度；根据所述每一条网格边对应的基于特征强化的二次误差测度值的大小对所有网格边排序,对二次误差测度值最小的边删除并获得新的网络模型；判断所述新的网络模型的细节信息是否简化完毕,若是,则结束简化过程并获得最简化的基网络M-(0),若否,则返回继续计算每一个网格顶点处对应的离散平均曲率值及二次误差测度值；所述服务器端基于上述简化过程构建分辨率连续可调的多分辨率网格结构,所述服务器端基于上述简化过程构建分辨率连续可调的多分辨率网格结构的步骤包括：记录简化所得的最简化的基网格为M-(0)；根据基于特征强化的二次误差测度简化过程建立渐进网格模型：MultiR-M＝{M-(0),{split-(0),split-(1)…,split-(n)}},其中,split-(i)保存信息包括：被收缩的边对应的顶点对(v-(1),v-(2)),与(v-(1),v-(2))均相邻的两个顶点v-(l)和v-(r),边收缩所对应的类型,网格模型所对应的分辨率信息R-(i)；所述服务器端将所述分辨率连续可调的多分辨率网格结构传输至普适终端；所述普适终端根据终端屏幕的分辨率大小和网格结构携带的分辨率信息确定所接收的多分辨率网格结构对应的分辨率大小,所述普适终端根据终端屏幕的分辨率大小和网格结构携带的分辨率信息确定所接收的多分辨率网格结构对应的分辨率大小的步骤包括：所述普适终端根据从所述服务器端接收到的最简化的基网络M-(0)计算模型的包络盒尺寸,根据所述包络盒尺寸和终端屏幕的显示分辨率计算每个像素对应的面积；根据所接收到的三维网格模型的数据以及所述每个像素对应的面积进行解码重建,得到当前普适终端屏幕所能显示的最高分辨率模型。</td>   <td>G06T17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗达;              骆伟祺;              杨锐;                   黄继武       </td>   <td>中山大学</td>   <td>一种鉴定WAV数字音频信号是否经过压缩以及分析其此前被压缩的码率的方法</td>   <td>广东省</td>   <td>CN102394065B</td>   <td>2013-06-12</td>   <td>本发明提供了一种能够识别数字音频假音质WAVE的分析方法,包括步骤：S1音频特征的提取与分类器模型的构造；S2利用分类器对待测音频做检测判断。与现有技术相比,本发明的有益效果是：本发明方法依据音频压缩前后MDCT系数的变化,提出“MDCT零值数量特征”以及“MDCT均值特征”组合而成的MDCT系数统计特征,利用SVM技术进行分类,可以有效鉴别WAV格式的数字音频文件是否曾被压缩,进而还可以分析其此前被压缩的码率。本发明能较有效地对原来低码率的低音质音乐进行识别,从而为网络音乐搜索与服务提供方便。</td>   <td>1.一种鉴定WAV数字音频信号是否经过压缩以及分析其此前被压缩的码率的方法,其特征在于包括步骤：S1音频特征的提取与分类器模型的构造：①无压缩音频集的选择：首先选取无压缩格式的WAV格式文件,裁减成若干5秒钟长度的音频片段；②经压缩的音频集的构造：对选取的音频片段,分别以32kbps、48kbps、64kbps、80kbps、96kbps、128kbps的码率压缩成MP3格式和WMA格式的音频文件,再将它们解压缩成为WAV格式的音频片段,得到经压缩的音频集；③提取无压缩音频集与经压缩的音频集中的每个音频片段的MDCT零值数量特征和MDCT均值特征；④利用LibSVM分类器对③中得到的特征进行训练,得到一个能鉴定分析音频信号压缩历史的分类器模型Model；S2利用分类器对待测音频做检测判断：首先按步骤S1中的③提取待测音频的特征,然后利用步骤S1中的④得到的分类器Model进行判别；步骤S1的③中的特征提取方法包括步骤：a)首先按MP3标准中的方法将音频进行分帧,然后对每一帧进行“时频转换”,提取576个MDCT系数；b)对于所有的帧的MDCT系数,统计其值的绝对值严格等于0的总数,并除以帧的数量,得到平均每帧MDCT系数绝对值严格等于0的数量,称为“MDCT零值数量特征”；c)对于所有的帧,统计576个系数的平均值,然后将这些系数分成24组,每组24个系数,即第1-24个系数为第一组,第25-48个系数为第二组,以此类推,对于每一组的24个系数,取他们的绝对值的平均值,作为这一组系数的一个特征,24个组就可以产生一个24维的特征,由于后4维全是0,故舍弃,取前20维的均值作为一个音频片段的特征,称为“MDCT均值特征”；d)“MDCT零值数量特征”以及“MDCT均值特征”合并在一起,作为一个音频片段的特征。</td>   <td>G10L25/51;G10L25/69;G10L19/02</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈弟虎;              郑洪滨;                   王自鑫       </td>   <td>中山大学</td>   <td>一种高层次综合方法以及系统</td>   <td>广东省</td>   <td>CN102419789B</td>   <td>2013-05-01</td>   <td>本发明公开了一种高层次综合方法以及系统,该系统包括数据流图生成单元、预分配单元、调度单元、资源分配单元以及电路生成单元。该方法是,首先获取数字电路行为描述,进而生成数据流图,然后进行硬件资源预分配,进而生成资源约束列表,跟着进行调度以及资源分配,最后生成硬件电路结构。通过使用本发明,在执行调度时不仅包括硬件资源数目信息,还包括硬件互连的信息,而且能够免除人工确定调度约束,因此,这样能够更加快速地生成硬件电路结构,而且有效地减少了硬件电路结构中的互连开销。本发明作为一种高层次综合方法以及系统广泛应用在设计硬件电路结构领域中。</td>   <td>1.一种高层次综合方法,其特征在于：该方法步骤包括：		A、获取数字电路行为描述,进而生成数据流图；		B、根据数据流图,进行硬件资源预分配,进而生成资源约束列表；		C、根据资源约束列表以及数据流图,进行调度；		D、根据调度的结果进行资源分配；		E、根据资源分配结果以及调度结果生成硬件电路结构；		所述步骤B采用兼容图算法进行预分配；		所述步骤B包括：		B1、根据数据流图构建兼容图,以及建立资源约束列表；		B2、根据兼容图查找最长路径；		B3、根据查找的最长路径,将所述最长路径涉及的各个节点依次放入资源约束列表中；		B4、根据查找的最长路径,在兼容图中删除所述最长路径中涉及的节点以及边,并且对兼容图中剩余的各边的权重进行重新计算；		B5、判断兼容图中是否还存在节点,若存在,返回执行步骤B2；若不存在,生成资源约束列表,步骤B结束；		所述步骤B1构建兼容图中包括构建兼容图的节点、兼容图的边以及各边的权重；		构建各边权重的计算方法为：		W-(i,j)=(α* dependency-(i,j)+β*NIN-(i,j))		其中α、β为系数,dependency-(i,j)为布尔值,i和j为任意两个节点,若节点i和j有数据依赖关系,则dependency-(i,j)为1,没有则为0；NIN-(i,j)为整数,代表节点i和j所共有的输入端口数目。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         张敏;              颜权;                   潘仲康       </td>   <td>中山大学</td>   <td>一种数字电视的影视节目推荐方法及其装置</td>   <td>广东省</td>   <td>CN102207972B</td>   <td>2013-03-27</td>   <td>本发明实施例公开了一种数字电视的影视节目推荐方法及其装置,其中,该方法包括：收集数字电视用户的基本信息；根据所述用户的基本信息构造初始预测评分矩阵；根据所述初始预测评分矩阵创建相似影视节目列表；根据所述影视节目相似列表获得推荐结果。在本发明方法及装置实施例中,针对现有技术中协同过滤推荐系统的冷启动问题,在协同过滤推荐方法的基础上加入了基于内容的推荐方法,结合两种方法进行构造相似影视节目列表,并通过相似影视节目列表为用户提供推荐服务；可以帮助数字电视用户找到可能感兴趣的影视节目；可以确保数字电视的新用户能够得到较为准确的推荐服务；且避免了新加入的影视节目难以获得系统推荐的问题。</td>   <td>1.一种数字电视的影视节目推荐方法,其特征在于,所述方法包括：收集数字电视用户的基本信息；根据所述用户的基本信息构造初始预测评分矩阵；根据所述初始预测评分矩阵创建相似影视节目列表；根据所述影视节目相似列表获得推荐结果；其中：所述根据所述用户的基本信息构造初始预测评分矩阵的步骤包括：根据所述用户的基本信息计算同一类型的用户对同一影视节目评分的平均值以获得该影视节目的初始预测评分值；按照从高到低的顺序对所述同一类型的用户中所有影视节目的初始预测评分值进行排序,并获得所述初始预测评分值排名靠前的多个影视节目；将所述初始预测评分排名靠前的多个影视节目及所述多个影视节目各自对应的初始预测评分值构造每一类型用户的初始评分矩阵；所述根据所述初始预测评分矩阵创建相似影视节目列表的步骤包括：获取对同一影视节目评分的用户的数量；根据所述数量计算用户所评分的当前影视节目与其它影视节目的相似度；根据所述相似度对所述其它影视节目按照从高到低的顺序进行排序,并获得相似度较高的其它影视节目作为所述当前影视节目近邻的近邻信息；根据所述当前影视节目的近邻信息创建所述当前影视节目的相似影视节目列表；所述根据所述数量计算用户所评分的当前影视节目与其它影视节目的相似度的步骤包括：根据影视节目的内容相关度计算所述当前影视节目与其它影视节目的相似度；或者,根据皮尔逊相关度采用协同过滤算法计算当前影视节目与其它影视节目的相似度。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              吴娴;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于正则回归的秩-1张量投影的行为识别方法</td>   <td>广东省</td>   <td>CN102289685B</td>   <td>2013-02-06</td>   <td>本发明公开了一种基于正则回归的秩-1张量投影的行为识别方法,包括以下步骤：(1)训练过程：采用One Vs All策略对每种行为分别训练一个两类分类器,使用正则回归方法求得一个包括三个投影向量的投影向量集,通过投影向量集外积得到秩-1张量投影,将已知类别的训练行为按种类划分为多个子集,构建子集嵌入；(2)识别过程：将测试数据输入到各个两类分类器,然后将所有两类分类器的输出响应组成行向量,将此行向量与步骤(1)所得到的每一维的子集嵌入结果相乘,找到相乘结果最大的行向量,其所对应的两类分类器所代表的正样本类别即是测试行为所判定的类别。本发明行为识别率高且可大大降低方法的计算复杂度。</td>   <td>1.一种基于正则回归的秩-1张量投影的行为识别方法,其特征在于,包括以下步骤：(1)训练过程：对已知行为类别的训练数据进行预处理,得到完整的前景行为数据、原始行为数据和显著行为数据,然后对上述数据采用One Vs All的策略对每种行为分别训练一个两类分类器,进而求得一个包括三个投影向量的投影向量集,通过投影向量集外积得到秩-1张量投影,将已知类别的训练行为按种类划分为多个子集,构建子集嵌入；其中,采用如下方法求得一个包括三个投影向量的投影向量集：假设p-(1)和p-(2)已知,求解投影向量p-(3),首先随机初始化p-(1)和p-(2),m-(3)维向量x-(3)则通过得到；给定一组已知类别的训练样本其中y为类别标记,且y～(l)∈{-1,1),第l个训练样本投影到p-(1)和p-(2)的张量空间得到将所有训练样本投影到p-(1)和p-(2)的张量空间所得到的向量和其对应的类别标记转置后堆叠得到矩阵X-(3)和行向量y,然后通过传统的最小二乘法求解投影向量p-(3),即                            arg          min              p        3                            |        |        y        -                  p          3          T                          X          3                |        |            2        ;   ]]>                  依此方法,假设p-(1)和p-(3)已知,求解p-(2)；假设p-(2)和p-(3)已知,求解p-(1),待循环T-(max)次或相邻投影向量范数的差小于一定阈值,即得到投影向量集合构建子集嵌入的方法如下：首先将已知类别的原始训练数据按行为种类划分为N个子集每一个子集包含满足label(X)=λ-(i)条件的个训练样本,子集嵌入则是将已知类别的训练数据的所有子集投影到N维向量空间,对于其中的第i个子集,子集嵌入定义为通过以下步骤实现：对每个子集建立一个临时矩阵：                                  M              &amp;lambda;        i              =                                                      B              1                                      (              1              )                                                          B              2                                      (              1              )                                            .            .            .                                              B              N                                      (              1              )                                                                          B              1                                      (              2              )                                                          B              2                                      (              2              )                                            .            .            .                                              B              N                                      (              2              )                                                            .            .            .                                .            .            .                                .            .            .                                .            .            .                                                              B              1                                      (              |                              D                                  &amp;lambda;                  i                                            |              )                                                          B              2                                      (              |                              D                                  &amp;lambda;                  i                                            |              )                                            .            .            .                                              B              N                                      (              |                              D                                  &amp;lambda;                  i                                            |              )                                            ,   ]]>                  其中B-(i)(j)表示子集中第j个训练样本于第i个两类分类器中的输出,然后将临时矩阵中每一列和的平均值作为子集的一维嵌入中的每个对应元素,按照以上方法完成对所有子集的N维子集嵌入的构造；(2)识别过程：将测试数据输入到步骤(1)所得到的各个两类分类器,然后将所有两类分类器的输出响应组成行向量,将此行向量与步骤(1)所得到的每一维的子集嵌入结果相乘,找到相乘结果最大的行向量,其所对应的两类分类器所代表的正样本类别即是测试行为所判定的类别。</td>   <td>G06K9/66</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李春景;              罗笑南;                   曾巨泉       </td>   <td>中山大学</td>   <td>一种基于不可逆矩阵的图片验证码生成方法</td>   <td>广东省</td>   <td>CN101882298B</td>   <td>2013-01-02</td>   <td>本发明实施例公开了一种基于不可逆矩阵的图片验证码生成方法,包括：变换类型的选定及不可逆矩阵的生成；图片的不可逆变换；图片随机噪声的添加及多幅变换图片的组合。通过实施本发明实施例,提高图片的反破解性,又不会降低人对图像理解的准确率。</td>   <td>1.一种基于不可逆变换矩阵的图片验证码生成方法,其特征在于,包括：S101：变换类型的选定及不可逆变换矩阵的生成；S102：图片的不可逆变换；S103：图片随机噪声的添加及多幅变换图片的组合；其中,图片变换包括平移、缩放和旋转；对于图片上某点(x,y)通过实施以下的矩阵相乘达到(Δx,Δy)平移变换；                                                                1                                0                                &amp;Delta;x                                                0                                1                                &amp;Delta;y                                                0                                0                                1                                                                    x                                                y                                                1                                =                                        x            +            &amp;Delta;x                                                y            +            &amp;Delta;y                                                1                               ]]>                  对于图片上某点(x,y)通过实施以下的矩阵相乘达到(s,h)的缩放变换；                                                                s                                0                                0                                                0                                h                                0                                                0                                0                                1                                                                    x                                                y                                                1                                =                                        sx                                                hy                                                1                               ]]>                  对于图片上某点(x,y)通过实施以下的矩阵相乘达到逆时针θ的旋转变换；                                                                              x              &amp;prime;                                                                          y              &amp;prime;                                                            1                                =                                        cos            &amp;theta;                                -            sin            &amp;theta;                                0                                                sin            &amp;theta;                                cos            &amp;theta;                                0                                                0                                0                                1                                                                    x                                                y                                                1                                =                                        x            cos            &amp;theta;            -            y            sin            &amp;theta;                                                x            sin            &amp;theta;            +            y            cos            &amp;theta;                                                1                               ]]>                  上述的三种变换是基本的图片变换,而且变换矩阵均可逆,对变换矩阵做改动使得其为不可逆变换矩阵；首先是对平移矩阵的修改使之变为不可逆,对平移矩阵做以下修改：                                                                1                                0                                &amp;Delta;x                                                0                                1                                &amp;Delta;y                                                f                                g                                1                                                                    x                                                y                                                1                                =                                        x            +            &amp;Delta;x                                                y            +            &amp;Delta;y                                                fx            +            gy            +            1                               ]]>                  变换矩阵的行列式的值为1-gΔy-fΔx,根据设定的Δx,Δy取相应的g,f使得行列式的值为0,即变换矩阵不可逆,并通过线性规划求得g,f,使得fx+gy的值接近0,尔后对矩阵实施整体缩放,使得：                                                                1            /                          (              fx              +              gy              +              1              )                                            0                                0                                                0                                1            /                          (              fx              +              gy              +              1              )                                            0                                                0                                0                                1            /                          (              fx              +              gy              +              1              )                                                                                1                                0                                &amp;Delta;x                                                0                                1                                &amp;Delta;y                                                f                                g                                1                                                                    x                                                y                                                1                                                                    =                                                      (              x              +              &amp;Delta;x              )                        /                          (              fx              +              gy              +              1              )                                                                          (              y              +              &amp;Delta;y              )                        /                          (              fx              +              gy              +              1              )                                                            1                               ]]>                  1/(fx+gy+1)接近于1,因而变换后的平移接近原有平移,但此时使用不可逆变换矩阵实施变换；对旋转矩阵作出以下修改：                                                                              x              &amp;prime;                                                                          y              &amp;prime;                                                            1                                =                                        cos            &amp;theta;                                -            sin            &amp;theta;                                e                                                sin            &amp;theta;                                cos            &amp;theta;                                l                                                m                                n                                1                                                                    x                                                y                                                1                                =                                        x            cos            &amp;theta;            -            y            sin            &amp;theta;            +            e                                                y            cos            &amp;theta;            +            x            sin            &amp;theta;            +            l                                                1            +            mx            +            ny                               ]]>                  行列式的值为1-lncosθ+ensinθ-mlsinθ-mecosθ,变换后的矩阵取适当的值,使得1-lncosθ+ensinθ-mlsinθ-mecosθ为0,即矩阵不可逆,使得1+mx+ny接近1,e,l在1到3个像素内变换,再做缩放变换可得：                                                                              x              &amp;prime;                                                                          y              &amp;prime;                                                            1                                =                                        1            /            1            +            mx            +            ny                                0                                0                                                0                                1            /            1            +            mx            +            ny                                0                                                0                                0                                1            /            1            +            mx            +            ny                                                                    cos            &amp;theta;                                -            sin            &amp;theta;                                e                                                sin            &amp;theta;                                cos            &amp;theta;                                l                                                m                                n                                1                                                                    x                                                y                                                1                                                                                  (              x              cos              &amp;theta;              -              y              sin              &amp;theta;              +              e              )                        /                          (              1              +              mx              +              ny              )                                                                          (              y              cos      ...</td>   <td>G06T1/00;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘成明;                   罗笑南       </td>   <td>中山大学</td>   <td>一种基于细分方法的图像放大方法</td>   <td>广东省</td>   <td>CN101833748B</td>   <td>2013-01-02</td>   <td>本发明公开了一种基于细分方法的图像放大方法,属于图像技术领域。本发明把细分方法快速插入新数据的特点,利用到图像放大中,放大后的图像数据通过Ferguson曲面片计算得出。本发明方法步骤包括：(1)输入低分辨率图像I和放大倍数n；(2)根据所述放大倍数n确定所需要的细分次数k；(3)对象素进行分类标记；(4)根据象素的不同分类标记,计算该象素处的梯度和扭矢；(5)利用改进的插值细分对图像数据进行加细；(6)将加细后的数据按所要求的图像分辨率重采样,再将采样后的图像输出。本发明能够达到图像边缘保持的目的,使得图像更清晰。</td>   <td>1.一种基于细分方法的图像放大方法,其特征在于,包括：		(1)输入低分辨率图像I和放大倍数n；		(2)根据所述放大倍数n确定所需要的细分次数k；		(3)对象素进行分类标记；		(4)根据象素的不同分类标记,计算该象素处的梯度和扭矢；		(5)利用改进的插值细分对图像数据进行加细；		(6)将加细后的数据按所要求的图像分辨率重采样,再将采样后的图像输出；		所述对象素进行分类标记包括：		针对图像的一行或一列数据,根据每个数据点向前差分、或向后差分、或中心差分的方法,判定出该数据点是否为图像数据的跳跃点；		所述对象素进行分类标记具体为：		将图像数据的一行或一列记为p-(1),p-(2),···,p-(N),标记r定义为：		                  其中,T定义为		                  所述利用改进的插值细分对图像数据进行加细时,在细分过程中新加入的		点由Ferguson曲面片计算得出,其中Ferguson曲面片的梯度和扭矢按步骤(4)的方式进行计算；		记 		                  Ferguson曲面片S(u,v)定义为：		S(u,v)＝F(u)～(T)QF(v),		其中F(t)＝[H-(0)(t)H-(1)(t)G-(0)(t)G-(1)(t)]～(T),		                  其中p～(0),p～(1),p～(2),p～(3)为图1所示的Ferguson曲面片的四个顶点, 为p～(i)处的梯度, 为p～(i)处的扭矢,i＝0,1,2,3；		所述计算该象素处的梯度和扭矢时,梯度由一维数据的切向量构成,按差分计算,扭矢由二维差商计算；		p～(i)处的切向量m～(i)的计算公式为：		                                                      扭矢也用差分的方式计算,在图像的边缘处的扭矢直接设置为0,在象素(i,j)处的扭矢按下公式计算： 		                                    。</td>   <td>G06T3/40;G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              连国云;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种非重叠摄像机视点之间的行人匹配方法</td>   <td>广东省</td>   <td>CN102236785B</td>   <td>2012-12-19</td>   <td>本发明公开了一种非重叠摄像机视点之间的行人匹配方法,对于设置的非重叠摄像机C～(i)、C～(j),确定C～(j)中待匹配目标O-(j,b),及检测在一段时间内离开摄像机C～(i)进入摄像机C～(j)的R个目标,对摄像机C～(i)中的行人目标进行光照校正,计算这些目标中每个像素的DLBP～(riu2)值,然后计算每个目标的三个二维直方图R-DLBP,G-DLBP,和B-DLBP,将每个二维直方图按颜色成分的DLBP分布生成一个一维的直方图,三个一维的直方图串联起来就得到RGB-DLBP描述子；最后基于RGB-DLBP描述子的相似度来实现不同摄像机之间的行人匹配。本发明将彩色目标的颜色信息和空间结构信息相结合,能够更有效地表示彩色目标,且构造简单,计算方便,能够满足实际应用中非重叠摄像机视点之间行人匹配的要求。</td>   <td>1.一种非重叠摄像机视点之间的行人匹配方法,其特征在于,包括下述步骤：(1)对于设置的非重叠摄像机C～(i)、C～(j),确定C～(j)中待匹配目标O-(j,b),及摄像机C～(i)中检测到的在一段时间内离开C～(i)进入摄像机C～(j)的R个目标,将这些目标分别提取出来后进行保存；对于目标O-(j,b),直接进入步骤(3),对于C～(i)中的目标进入步骤(2)；(2)对摄像机C～(j)中检测到的一个目标O-(j,b),在寻找C～(i)中的哪一个目标与其对应时,先根据两个摄像机中检测到的对应行人目标进行训练,得到摄像机之间的累积亮度转移函数模型,即CBTF映射函数,然后应用该函数对摄像机C～(i)中的所有目标进行校正；进入步骤(3)；(3)对于目标中的每个像素点均做如下处理：(3-1)首先计算目标中各像素点和其邻域点之间的彩色像素距离,具体方法是：设C(p-(c))为当前像素点,C(p-(n))(n=0,...,P-1)为其一个邻域点,P为考虑的邻域内的像素个数,C(p-(c))=[R-(c)G-(c)B-(c)]和C(p-(n))=[R-(n)G-(n)B-(n)]分别表示像素p-(c)和p-(n)的颜色向量,二者的彩色像素距离为：                            d          (              p        n            ,              p        c            )        =                  |        C                  (                      p            c                    )                -        C                  (                      p            n                    )                |                    |        C                  (                      p            c                    )                +        C                  (                      p            n                    )                |             ]]>                                              =                                        (                          R              c                        -                          R              n                        )                    2                +                              (                          G              c                        -                          G              n                        )                    2                +                              (                          B              c                        -                          B              n                        )                    2                                                  R            c            2                    +                      G            c            2                    +                      B            c            2                          +                              R            n            2                    +                      G            n            2                    +                      B            n            2                                ;   ]]>                  按照上述计算公式,将当前像素点和其邻域点的距离均计算出来,得到一个距离图；然后进入步骤(3-2)；(3-2)设定一个阈值θ,对步骤(3-1)中得到的距离图进行二值化得到s′(p-(n),p-(c)),具体是：                                  s      &amp;prime;              (              p        n            ,              p        c            )        =                                        1            ,                                d                          (                              p                n                            ,                              p                c                            )                        &amp;GreaterEqual;            &amp;theta;                                                0            ,                                d                          (                              p                n                            ,                              p                c                            )                        &lt;            &amp;theta;                                ;   ]]>                  进而得到该像素点处的DLBP值,                                  DLBP              P        ,        R              =          &amp;Sigma;              n        =        0                    P        -        1                    s      &amp;prime;              (              p        n            ,              p        c            )              2      n        ;   ]]>                  (3-3)对(3-2)得到的DLBP进行局部旋转不变性变换,得到                                  DLBP              P        ,        R                    riu        2                    (              p        n            ,              p        c            )        =                                                      &amp;Sigma;                              n                =                0                                            P                -                1                                                    s              &amp;prime;                                      (                              p                n                            ,                              p                c                            )                        ,                                ifU                          (                              DLBP                                  P                  ,                  R                                            )                        &amp;le;            2                                                P            +            1            ,                                otherwise                               ]]>                  其中,                            U          (              DLBP                  P          ,          R                    )        =    |          s      &amp;prime;              (              p                  P          -          1                    ,              p        c            )        -          s      &amp;prime;              (              p        0            ,              p        c            )        |   ]]>                                              +          &amp;Sigma;              n        =        1                    P        -        1              |          s      &amp;prime;              (              p        n            ,              p        c            )        -          s      &amp;prime;              (              p                  n          -          1                    ,              p        c            )        |    ;   ]]>                  待目标中所有像素点处的DLBP～(riu2)值计算完毕后,进入步骤(4)；(4)根据步骤(3)得到的每个像素点的DLBP～(riu2)值和该点处的R、G、B值,计算出每个目标的三个二维直方图,每个直方图代表着DLBP～(riu2)与某种颜色之间的联合分布,直方图的每一列对应着具体颜色成分值上的DLBP～(riu2)分布；然后抽取每个二维直方图的每一列去生成一个一维的子直方图,将每个二维直方图中所抽取的所有一维子直方图进行串联,得到每个二维直方图的一维直方图,最后将三个二维直方图生成的一维直方图进行串联得到该目标的RGB DLBP直方图描述子；待所有目标的RGB-DLBP直方图描述子均计算完成后,进入步骤(5)；(5)将摄像机C～(i)中的所有目标分别与目标O-(j,b)进行相似度计算,相似度计算是基于两个目标的RGB-DLBP直方图描述子,摄像机C～(i)中相似度最大的目标即是寻找的目标。</td>   <td>G06K9/00;H04N7/18</td>  </tr>        <tr>   <td>中国专利</td>   <td>         杨锐;                   黄继武       </td>   <td>中山大学</td>   <td>网络MP3音质排序方法及系统</td>   <td>广东省</td>   <td>CN102253987B</td>   <td>2012-12-12</td>   <td>本发明涉及一种网络MP3音质排序方法及系统,所述方法包括步骤：后台单元抓取网络上MP3音乐的资源并存储在数据库中；提取网络MP3音乐资源的帧头信息并存储到数据库中；提取网络MP3音乐资源的帧数据进行假音质MP3检测分析并将分析结果存储到数据库中；查询页面获取输入的MP3音乐歌曲名字传递给后台单元；后台单元利用所述MP3音乐歌曲名字在数据库中进行搜索,如果存在所述MP3音乐歌曲名字的数据记录,从查询页面跳转到返回结果页面,返回结果页面读取所述数据记录并进行排序和输出,显示在返回结果页面中,供用户参考和下载。本发明集成了网络MP3音乐搜索和音质分析,为用户提供经过音质分析和排序的搜索结果。</td>   <td>1.一种网络MP3音质排序方法,其特征在于,包括以下步骤：		A. 后台单元根据接收到的MP3音乐歌曲名字抓取网络上所述MP3音乐的资源,并将所述网络MP3音乐资源存储在数据库中；		B.根据抓取的网络MP3音乐资源提取所述网络MP3音乐资源的帧头信息,并将所述帧头信息存储到数据库中；		C.提取所述网络MP3音乐资源的帧数据进行假音质MP3检测分析并将分析结果存储到数据库中；所述步骤C的具体步骤为：		C1：根据所述抓取的网络MP3音乐资源提取所述网络MP3音乐资源的帧数据；		C2:根据所述帧数据提取所述网络MP3音乐资源的音频特征,所述音频特征为MDCT系数值；		C3:进入训练过程,所述训练过程是利用已有MP3音乐样本的音频特征对分类器进行训练,产生训练模型,若后台单元中已存有训练模型,则跳过此步骤C3,直接进入步骤C4；		C4:进入预测过程,所述预测过程是利用所述训练模型和所述网络MP3音乐资源的音频特征对所述每个MP3音乐资源区分出假音质MP3音乐和正常MP3音乐并且得到假音质MP3的原始码率存储到数据库中;		D.前台单元的查询页面获取输入的MP3音乐歌曲名字传递给后台单元；		E.后台单元利用所述MP3音乐歌曲名字在数据库中进行搜索,如果存在所述MP3音乐歌曲名字的数据记录,从查询页面跳转到返回结果页面,返回结果页面读取所述数据记录,然后对所述数据记录进行排序和输出,显示在返回结果页面中,供用户参考和下载。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              王众;              纪帅;                   郑艳丽       </td>   <td>中山大学</td>   <td>一种三维“人体-服装”接触力学仿真分析系统</td>   <td>广东省</td>   <td>CN101393580B</td>   <td>2012-12-05</td>   <td>本发明是基于有限元接触分析的三维“人体-服装”接触力学仿真系统,包括有以下模块：3DCAD服装缝合系统模块、有限元模型构建模块、有限元仿真求解模块、系统后处理模块。它利用弹簧质点模型完成二维衣片缝合,实现三维初始服装构造,提供三维服装造型。弹簧质点模型最为简单,易于构造,算法容易实现,计算效率较高,速度快,所以造型效率极高。然后采用有限元模型实现服装效果模拟。由于有限元模型能够较全面表达织物的材质,因而仿真结束时能获得较真实的穿着效果,同时采用有限元模型的服装效果仿真也较易实现服装及人体的应力及位移分析。</td>   <td>1.一种三维“人体-服装”接触力学仿真分析系统,其特征在于,该系统包括以下模块：3DCAD服装缝合系统模块、有限元模型构建模块、有限元仿真求解模块、系统后处理模块；所述3DCAD服装缝合系统模块采用基于弹簧质点模型的服装缝合系统,完成从二维衣片到三维服装的缝合仿真和服装的三维造型设计；所述有限元模型构建模块包括几何模型建立模块和网格剖分模块,根据3DCAD服装缝合系统模块提供的三维初始服装及相关的缝合信息的基础上进行三维有限元离散模型的重构,所述有限元模型构建模块利用3DCAD服装缝合系统模块提供的三维初始服装及相关的缝合信息,对织物及人体定义单元类型和材料属性,生成三维服装几何模型,并通过分别对三维人体和服装进行网格剖分形成有限元离散模型；所述有限元仿真求解模块主要生成使用APDL语言描述的宏命令文件,然后自动调用ANSYS模块,转入ANSYS模块处理；所述系统后处理模块提取ANSYS模块的结果信息,对人模进行受力以及位移的图形化表示,把人模指定点处受力和位移数据显示出来,以便对人体进行压力舒适性分析。</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王建民;              麦灿章;              黄达尧;              陈佳鹏;                   罗笑南       </td>   <td>中山大学</td>   <td>一种实现重复单词列表的电子词典的查询方法</td>   <td>广东省</td>   <td>CN101419605B</td>   <td>2012-10-10</td>   <td>本发明公开了一种实现重复单词列表的电子词典的查询方法。在电子词典的词库中建立索引层、词头层和数据层,其中：索引层包含到词头层节点的索引,词头层包含单词的名称和音标信息,数据层包含了单词的详细解释信息,并在索引层中建立基于折半查找的索引方式；词头层用于根据具体需要而进行单词的排列,并支持单词的重复出现；数据层用于保存不同的数据属性；从词头层中的节点获得数据层偏移位移,并进入该单词响应的数据层结点,其中词头层包含了前一个词头层结点的长度,通过本结点的偏移位移减去前一个词头层结点的长度,获取前一个词头层结点的指针,并由此可以实现在词头层中的遍历；获得该单词的详细信息。</td>   <td>1.一种实现重复单词列表的电子词典的查询方法,其特征在于,所述方法包括：		在电子词典的词库中建立索引层、词头层和数据层,其中：索引层包含到词头层节点的索引,词头层包含单词的名称和音标信息,数据层包含了单词的详细解释信息,并在索引层中建立基于折半查找的索引方式；词头层用于根据具体需要而进行单词的排列,并支持单词的重复出现；数据层用于保存不同的数据属性；		从词头层中的节点获得数据层偏移位移,并进入该单词相应的数据层结点,其中词头层包含了前一个词头层结点的长度,通过本结点的偏移位移减去前一个词头层结点的长度,获取前一个词头层结点的指针,并由此可以实现在词头层中的遍历；词头层结点由普通词头层结点和重复词头层结点构成,可以根据词头层结点的第1个字节进行判断该结点属于哪种结点结构,某单词的重复词头层结点不仅有普通词头层结点的数据结构还包括了该单词的前一个和后一个重复词头层结点的指针；		获得该单词的详细信息。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         苗晓萍;                   郭栋       </td>   <td>中山大学</td>   <td>一种数码相机构图效果提高方法</td>   <td>广东省</td>   <td>CN102063709B</td>   <td>2012-07-18</td>   <td>本发明提供了一种数码相机构图效果提高方法,该方法使用主体检测模块检测照片中的主体位置,并且通过注视点检测模块以自底向上的视觉注意力模型检测照片中的注视点位置,然后通过分析主体位置与注视点位置的相对关系判断是否存在背景干扰,如果存在背景干扰则给出重新构图的建议。本发明可以在简单交互标定主体对象的基础上,自动检测出干扰,并建议重新构图,实验证明,本发明所采用的方法运行快速并且能有效改善构图效果。</td>   <td>1.一种数码相机构图效果提高方法,其特征在于该方法使用主体检测模块检测照片中的主体位置,并且通过注视点检测模块以自底向上的视觉注意力模型检测照片中的注视点位置,然后通过分析主体位置与注视点位置的相对关系判断是否存在背景干扰,如果存在背景干扰则给出重新构图的建议,所述重新构图的建议包括通过背景模糊去除背景干扰,或拉近镜头建议二次构图。</td>   <td>G06T5/00;G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李煌;              刘红梅;                   黄继武       </td>   <td>中山大学</td>   <td>一种视频媒体的水印保护方法</td>   <td>广东省</td>   <td>CN101894357B</td>   <td>2012-07-04</td>   <td>本发明提供一种保护视频媒体的水印方法,属于多媒体信号处理领域。通过修改视频媒体的帧结构,将水印数据分别嵌入到每一帧中,水印的嵌入通过直接修改视频媒体的控制信息实现。本发明具有如下优点：1)原理简单,容易实现；直接对码流进行操作,具有很强的实时性；2)嵌入时无须进行任何编解码过程,水印信息对视频基本没有影响,不可察觉性较高；3)有很好的通用性,只要知道码流的格式寻找到合适的嵌入位就可以用该方法进行水印嵌入。</td>   <td>1.一种视频媒体的水印保护方法,包括水印嵌入过程和水印提取过程,所述水印嵌入过程根据视频媒体的帧结构,将水印数据分别嵌入到每一帧中,其特征在于水印的嵌入通过直接修改视频媒体的控制信息实现,当视频为MPEG-2格式的TS流时,水印嵌入过程为修改视频媒体的PES包中控制信息比特率标识符的内容,当视频为MKV封装格式时,水印嵌入过程为修改视频媒体的全局控制信息Global elements中Void标识符的内容。</td>   <td>G06T1/00;H04N5/14</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              林淑金;                   陈巧珍       </td>   <td>中山大学</td>   <td>一种插值型细分和逼近型细分相融合的曲面造型方法</td>   <td>广东省</td>   <td>CN101408991B</td>   <td>2012-06-27</td>   <td>本发明公开了一种插值型细分和逼近型细分相融合的曲面造型方法,它属于计算机辅助设计与制造技术领域。它基于现存的插值型细分和逼近型细分的内在联系,提供了逼近的Catmull-Clark细分模式与基于张量积四点插值的插值模式相融合的方法,从而实现不需要反求控制顶点或解方程组就能得到局部插值细分曲线和细分网格以及生成介于插值网格和逼近网格之间的细分网格的目的,解决了多分辨率表示的时候存在的“扩张”或者“收缩”的跳跃问题。</td>   <td>1.一种插值型细分和逼近型细分相融合的曲面造型方法,其特征在于：它的步骤包括：(1)由现有的逼近型Catmull-Clark细分模式推导出新的插值型细分模式,所述的由现有的逼近型Catmull-Clark细分模式推导出新的插值型细分模式是基于张量积四点插值的插值模式；(2)通过添加顶点权重参数,实现Catmull-Clark细分模式和新的插值型细分模式的融合；(3)通过修改顶点权重参数,实现网格的局部插值；(4)通过修改顶点权重参数,生成介于插值网格和逼近网格之间的细分网格；所述的步骤(1)由现有的逼近型Catmull-Clark细分模式推导出新的插值型细分模式又分为以下步骤：a)给定初始控制网格对于网格上的每个面,是每个面的中点,是每条边的中点；b)在网格的每条边上添加一个新顶点p,对于非边界边,p的位置由如下公式得到：                            p    :    =          P              i        ,        j            1        -          &amp;Delta;              i        ,        j            0        =          P              i        ,        j            1        -          1      4              (              q        1        0                    (        e        )            +              q        2        0                    (        e        )            )        +          1              4        n                    &amp;Sigma;              v        &amp;Element;                  C          1          0                          (          e          )                      v    +          1              4        m                    &amp;Sigma;              v        &amp;Element;                  C          2          0                          (          e          )                      v   ]]>                                                    &amp;Delta;              i        ,        j            q        =          1      4              (              q        1        q                    (        e        )            +              q        2        q                    (        e        )            )        -          1              4        n                    &amp;Sigma;              v        &amp;Element;                  C          1          q                          (          e          )                      v    -          1              4        m                    &amp;Sigma;              v        &amp;Element;                  C          2          q                          (          e          )                      v   ]]>                                              n    =                            C          1          0                          (          e          )                    #        ,   ]]>                                      m    =          C      2      0                      (        e        )            #       ]]>                  c)在网格的每个面中添加一个新顶点p,p的几何位置是该面的中点：                            p    :                  =        P                    i        ,        j            2       ]]>                  对于每个非边界的旧顶点,改变它的几何位置：                                  P              i        ,        j            0        :    =          P              i        ,        j            0        -          &amp;Delta;              i        ,        j            0        =                  4        n        -        7                    4        n                    P              i        ,        j            0        +          1                        4          n                2                    &amp;Sigma;              v        &amp;Element;                  V          0                          (          p          )                      v    +          3                        2          n                2                    &amp;Sigma;              D        &amp;Element;                  D          0                          (          p          )                            1              m        l                    &amp;Sigma;              v        &amp;Element;        D                              m          l                =                  D          #                      v   ]]>                                                    &amp;Delta;              i        ,        j            q        =          7              4        n                    P              i        ,        j            q        -          1                        4          n                2                    &amp;Sigma;              v        &amp;Element;                  V          q                          (          p          )                      v    -          3                        2          n                2                    &amp;Sigma;              D        &amp;Element;                  D          q                          (          p          )                            1              m        l                    &amp;Sigma;              v        &amp;Element;        D                              m          l                =                  D          #                            v              n        =                  V          0                                      (            p            )                    #                     ]]>                  d)对于每个边界边,添加一个新的顶点p,p的几何位置是该边的中点：对于每个边界旧顶点将其移动到新的几何位置：                                  P              i        ,        j            0        :    =          3      4              P              i        ,        j            0        +          1      8              P              i        ,        j        -        1            0        +          1      8              P              i        ,        j        +        1            0       ]]>                  e)在网格的每一条边上添加一个新的顶点p,对于非边界边e,p的位置由以下公式计算而来：                                  &amp;Delta;              i        ,        j            2        =          1      4              (              q        1        2                    (        e        )            +              q        2        2                    (        e        )            )        -          1              4        n                    &amp;Sigma;              v        &amp;Element;                  C          1          2                          (          e          )                      v    -          1              4        m                    &amp;Sigma;              v        &amp;Element;                  C          2          2                          (          e          )                      v   ]]>                                              p    :    =          P              i        ,        j            1        +          &amp;Delta;              i        ,        j            0        =          1      2              (              q        1        0                    (        e        )            +              q        2        0                    (        e        )            )        +          1      4              (              q        1        2                    (        e        )            +              q        2        2                    (        e        )            )        -          1              4        n                    &amp;Sigma;              v        &amp;Element;                  C          1          2                          (          e          )                      v    -          1              4        m                    &amp;Sigma;              v        &amp;Element;                  C          2          2                          (          e          )                      v   ]]>                                              n    =                            C          1          2                          (          e          )                    #        ,   ]]>                                      m    =          C      2      2                      (        e        )            #       ]]>                  f)在每个面f中,添加一个顶点,其几何位置由以下公式计算得到：                                  &amp;Delta;              i        ,        j            2        =          7              4        n                    P              i        ,        j            2        -          1                        4          n                2                    &amp;Sigma;              v        &amp;Element;                  V          2                          (          f          )                      v    -          3                        2          n                2                    &amp;Sigma;              D        &amp;Element;                  D          2                          (          f          )                            1              m        l                    &amp;Sigma;              v        &amp;Element;        D                              m          l                =                  D          #                      v   ]]>                                              p    :    =          p              i        ,        j            2        +          &amp;Delta;              i        ,        j            2        =                  4        n        +        7                    4        ns                    &amp;Sigma;              v        &amp;Element;                  B          0                          (          f          )                      v    -          1                        4          n                2                    &amp;Sigma;              v        &amp;Element;                  V          2                          (          f          )                      v    -          3                        2          n                2                    &amp;Sigma;              D        &amp;Element;                  D          2                          (          f          )                            1              m        l                    &amp;Sigma;              v        &amp;Element;        D                              m          l                =                  D          #                      v   ]]>                  n＝V～(0)(p)～(#),s＝B～(0)(f)～(#)g)对于每条边界边,添加一个新顶点p,其几何位置由以下公式计算得到：                            p    :    =          5      4              P              i        ,        j            1        -          1      8              P              i        ,        j        -        1            1        -          1      8              P              i        ,        j        +        1            1        =    -          1      16              P              i        ,       ...</td>   <td>G06T19/00;G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              孟思明;                   杨彪       </td>   <td>中山大学</td>   <td>一种基于光子映射的全局光照方法</td>   <td>广东省</td>   <td>CN101826214B</td>   <td>2012-06-27</td>   <td>本发明公开了一种新的基于光子映射的全局光照方法,本发明属于图像处理技术领域。本发明方法的步骤主要包括：(1)光源向场景随机发射光子；(2)判断发射后的光子状态；(3)根据物体表面的信息递归跟踪光子；(4)保存光子信息；(5)进行渲染场景,包括将蒙特卡罗反向追踪方法与原光子映射方法相结合使用来进行渲染场景。使用本发明的技术方案,可以使得运行速度、渲染效果,以及使用的存储空间等方面得到一定的改进。</td>   <td>1.一种基于光子映射的全局光照方法,其特征在于,包括以下步骤：(1)光源向场景随机发射光子；(2)判断发射后的光子状态；(3)根据物体表面的信息递归跟踪光子；(4)保存光子信息；(5)进行渲染场景,包括将蒙特卡罗反向跟踪方法与原光子映射方法相结合使用来进行渲染场景,步骤(3)所述根据物体表面的信息递归跟踪光子具体为：在第一路运程里,跟踪光子运动时根据物体表面的全部光照特性来保存光子,并进行递归跟踪；步骤(5)所述进行渲染场景包括：步骤1：从视角开始向场景中发射反向跟踪光线；步骤2：当光线打中物体表面时,先根据物体表面的漫反射特性计算直接光照,然后根据物体表面的镜面反射特性和折射特性分别计算反射和折射光照,最后根据光子图计算间接光照；步骤3：在根据光子图计算间接光照的过程中,根据光子的坐标信息在光子图中搜索离它最近的设定数量的光子,并将这部分光子的能量叠加到交点处的光子能量上；步骤4：将直接光照,反射光照,折射光照和间接光照叠加到一起作为交点处的光照信息进行渲染；步骤5：保存得到的光照信息,并计算下一个像素点的光照信息,跳转至步骤1。</td>   <td>G06T15/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         骆伟祺;              黄方军;                   黄继武       </td>   <td>中山大学</td>   <td>一种基于相邻像素差异的自适应空域隐写方法</td>   <td>广东省</td>   <td>CN101582157B</td>   <td>2012-06-06</td>   <td>本发明提出一种基于相邻像素差异的自适应空域隐写方法,包括秘密信息的嵌入和秘密信息的提取两个步骤。本发明方法以图像中相邻的连续三个像素作为一个嵌入单元,通过改变每一个单元中间像素值达到信息隐藏的目的。在信息嵌入的过程中,隐写算法始终保持嵌入单元内各像素间的大小关系,并可通过一个参数根据图像本身内容自适应地调节嵌入信息的容量。经大量实验证明,本发明方法与现有的基于像素间差异的隐写方法相比具有更高的安全性和自适应能力。因此,对隐秘通信等应用领域有着十分重要的实际意义。</td>   <td>1.一种基于相邻像素差异的自适应空域隐写方法,包括秘密信息的嵌入和秘密信息的提取两个步骤,其特征在于所述秘密信息的嵌入包括如下子步骤：(11)将图像进行分块,并根据第一密钥生成的角度对每一个图像分块随机进行顺时针角度旋转；(12)将旋转后的图像按行优先顺序排列为一个行向量,并将该向量划分为无重叠区域的1×3大小的嵌入单元,初始化两个参数T与k,其中T反映相邻两像素间的差异,而k反映单个像素最大嵌入的比特数；(13)估计图像的嵌入容量,对每个嵌入单元[g-(i),g-(i+1),g-(i+2)],首先根据中间像素g-(i+1)与前后两个像素的差值及与参数T间的关系,确定g-(i+1)的可变化的范围然后通过与参数k得到嵌入单元[g-(i),g-(i+1),g-(i+2)]的嵌入容量n,若图像各嵌入单元的总容量小于要嵌入秘密信息M的容量,则修改参数T,并重新估计图像容量,否则进行下一步骤；(14)根据第二密钥生成的顺序遍历图像的每个嵌入单元,待处理的单元为[g-(i),g-(i+1),g-(i+2)],按照步骤(13)方法确定其中间像素的可变动范围及可嵌入的信息容量n,然后从秘密信息M中顺序提取n比特数据并转为十进制数b,按如下公式改变g-(i+1)为g′-(i+1)实现嵌入：                                          g        &amp;prime;                    i        +        1              =                  arg        min            e        {    |    e    -          g              i        +        1              |    |    |    e    -          g      i        |    &amp;equiv;    b          (                        mod          2                n            )        ,    e    &amp;Element;          range                        g          &amp;prime;                          i          +          1                      }   ]]>                  重复本步骤直至所有的秘密信息均被嵌入；(15)根据第一密钥生成的角度将每一个图像分块进行逆时针旋转,并将步骤(13)估计得到的参数T嵌入到一个预设的、不用于秘密信息嵌入的图像区域中,生成隐写后的图像；所述步骤(11)的图像分块具体操作为：首先把M×N大小的灰度图像I分解为无重叠Bz×Bz大小的图像块Blk(j),Bz＝3k,k∈N,j＝1,2...S,其中表示图像块的总个数；所述步骤(13)确定嵌入单元[g-(i),g-(i+1),g-(i+2)]嵌入容量的方法为：计算其中表示集合的元素个数,若n＞0,则表示嵌入单元[g-(i),g-(i+1),g-(i+2)]的嵌入容量为n比特；所述步骤(13)参数修改与图像容量重估计方法为：统计图像各嵌入单元的总嵌入容量,若该容量大于所要嵌入二进制秘密信息M的长度,则转步骤(14),否则将参数T减少为T-1,转步骤(13)重新估计图像的嵌入容量,若T减至0,则表示图像I无足够空间嵌入给定的秘密信息M；所述秘密信息的提取包括如下子步骤：(21)将图像进行分块,根据第一密钥生成的角度对每个图像块作随机顺时针角度旋转；(22)将图像以行优先顺序进行排列得到一个行向量,并将该行向量划分为无重叠区域的1×3大小的嵌入单元；(23)从隐写后图像的预设区域抽取出参数T,然后根据第二密钥生成的顺序遍历并提取各嵌入单元的秘密信息,直至所有秘密信息均被提取。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王钢;              吴家隐;                   麦宇翔       </td>   <td>中山大学</td>   <td>一种雪崩光电二极管等效电路模型的建立方法</td>   <td>广东省</td>   <td>CN101661521B</td>   <td>2012-05-09</td>   <td>本发明公开了一种雪崩光电二极管等效电路模型的建立方法,其包括以下步骤：a、推导出雪崩光电二极管的物理模型；b、将物理模型分解为多个部分,并等效为系统的频率响应；c、构造对应于这些系统的子电路模块；d、互联这些子电路模块,建立等效电路模型。本发明利用电路系统频率响应与物理模型在数学上的相似性,能方便对器件进行模拟与设计,并能用于光接收模块的模拟设计。</td>   <td>1.一种雪崩光电二极管等效电路的建立方法,其特征在于包括以下步骤：a、推导出雪崩光电二极管的物理模型；b、将雪崩光电二极管的物理模型分解为多个部分,将每部分等效为系统的频率响应；c、构造对应于这些系统的子电路模块；d、互联这些子电路模块,建立等效电路模型；所述的步骤a中,若该物理模型为正入射模型,则其表达式如下(1)、(2)、(3)、(4)、(5)、(6)所示,N(ω)表示光生电子的数目,P(ω)表示光生空穴的数目,Ns(ω)表示二次光生电子的数目,Ps(ω)表示二次光生空穴的数目,q表示电子电量,W-(a)示吸收层厚度,x-(g)表示缓冲层厚度,x-(c)表示电荷层厚度,x-(m)表示倍增层厚度,M表示增益,D表示吸收层、缓冲层、电荷层、倍增层厚度之和,v-(n)、v-(p)分别表示电子迁移率和空穴迁移率,α代表APD吸收系数,P-(0)为入射光功率,h为普朗克系数,v为入射光频率,η为外量子效率；雪崩光电二极管的归一化频率响应函数为：                  I-(ph)(ω)为雪崩光电二极管的输出电流的频率响应函数,I-(ph)(O)为雪崩光电二极管接收到光子后,将其转化成载流子的数量,在加入寄生电容C-(p)、寄生电阻R-(p)的影响后,雪崩光电二极管的输出电流为：                                  I      ph              (      &amp;omega;      )        =          q      D              I      ph              (      0      )        &amp;CenterDot;    H          (      &amp;omega;      )ifm0001        &amp;CenterDot;          1              1        +        j&amp;omega;                  R          p                          C          p                      -    -    -          (      2      )       ]]>                  其中            I      ph              (      0      )        =                  &amp;eta;                  P          0                    hv       ]]>对于正入射APD,P(ω)、N(ω)、Ps(ω)、Ns(ω)的物理模型表达式分别是(3)、(4)、(5)、(6),                            P          (      &amp;omega;      )        =                  &amp;eta;                  P          0                    hv        {          1              &amp;alpha;                  v          n                +        j&amp;omega;              [    1    -    exp          (      -      &amp;alpha;              W        a            -      j&amp;omega;              W        a            /              v        p            )        ]   ]]>          (3)                            -                  exp                  (          -          &amp;alpha;                      W            a                    )                    j&amp;omega;              (      1      -      exp              (        -        j&amp;omega;                  W          a                /                  v          p                )            )        }   ]]>                                              N          (      &amp;omega;      )        =                  &amp;eta;                  P          0                    hv        {    exp          (      -      j&amp;omega;              (                  x          t                +                  x          m                )            /              v        n            )        &amp;CenterDot;    [    exp                            (          -          &amp;alpha;                      W            a                    )                    -      exp              (        -        j&amp;omega;                  W          a                /                  v          n                )              ]   ]]>          (4)                                  (              1        j&amp;omega;            +              1                  &amp;alpha;                      v            n                    -          j&amp;omega;                    )        +          1      j&amp;omega;              (      1      -      exp              (        -        &amp;alpha;                  W          a                )            )        }   ]]>                                                    P      s              (      &amp;omega;      )        =                  &amp;eta;                  P          0                    hv        exp          (      -      j&amp;omega;              x        t            /              v        n            )        &amp;CenterDot;          (              1        j&amp;omega;            +              1                  &amp;alpha;                      v            n                    -          j&amp;omega;                    )        &amp;CenterDot;          (      1      -      exp              (        -        j&amp;omega;                                            x              t                        +                          W              a                                            v            p                          )            )       ]]>          (5)                            &amp;CenterDot;    [    exp          (      -      j&amp;omega;              W        a            /              v        n            )        -    exp          (      -      &amp;alpha;              W        a            )        ]    &amp;CenterDot;                  M        -        1                    1        +        j&amp;omega;                  (          M          -          1          )                          &amp;tau;          m                     ]]>                                                    N      s              (      &amp;omega;      )        =                  &amp;eta;                  P          0                    hv              (              1        j&amp;omega;            +              1                  &amp;alpha;                      v            n                    -          j&amp;omega;                    )        &amp;CenterDot;    [    exp          (      -      j&amp;omega;              W        a            /              v        n            )        -    exp          (      -      &amp;alpha;              W        a            )        ]   ]]>          (6)                            &amp;CenterDot;        exp          (      -      j&amp;omega;              x        t            /              v        n            )        &amp;CenterDot;          (      1      -      exp              (        -        j&amp;omega;                              x            m                                v            n                          )            )        &amp;CenterDot;                  M        -        1                    1        +        j&amp;omega;                  (          M          -          1          )                          &amp;tau;          m                     ]]>                  所述的步骤a中,若该物理模型为背入射模型,则其表达式如下(1)、(2)、(7)、(8)、(9)、(10)所示,N(ω)表示光生电子的数目,P(ω)表示光生空穴的数目,Ns(ω)表示二次光生电子的数目,Ps(ω)表示二次光生空穴的数目,q表示电子电量,W-(a)表示吸收层厚度,x-(g)表示缓冲层厚度,x-(c)表示电荷层厚度,x-(m)表示倍增层厚度,M表示增益,D表示吸收层、缓冲层、电荷层、倍增层厚度之和,v-(n)、v-(p)分别表示电子迁移率和空穴迁移率,α代表APD吸收系数,P-(0)为入射光功率,h为普朗克系数,v为入射光频率,η为外量子效率；雪崩光电二极管的归一化频率响应函数为：                  I-(ph)(ω)为雪崩光电二极管的输出电流的频率响应函数,I-(ph)(O)为雪崩光电二极管接收到光子后,将其转化成载流子的数量,在加入寄生电容C-(p)、寄生电阻R-(p)的影响后,雪崩光电二极管的输出电流为：                                  I      ph              (      &amp;omega;      )        =          q      D              I      ph              (      0      )        &amp;CenterDot;    H          (      &amp;omega;      )        &amp;CenterDot;          1              1        +        j&amp;omega;                  R          p                          C          p                      -    -    -          (      2      )       ]]>                  其中            I      ph              (      0      )        =                  &amp;eta;                  P          0                    hv        ,   ]]>对于背入射APD,P(ω)、N(ω)、Ps(ω)、Ns(ω)的物理模型表达式分别是(7)、(8)、(9)、(10),                            P          (      &amp;omega;      )        =                  &amp;eta;                  P          0                    hv        {          1              &amp;alpha;                  v          p                +        j&amp;omega;              [    exp                  (        -        &amp;alpha;                  W          a                )            -      exp              (        -        j&amp;omega;                  W          a                /                  v          p                )              ]   ]]>          (7)                            +          1      j&amp;omega;              (      1      -      exp              (        -        j&amp;omega;                  W          a                /                  v          p                )            )        }   ]]>                                              N          (      &amp;omega;      )        =                  &amp;eta;                  P          0                    hv        {    exp          (      -      j&amp;omega;              (                  x          t                +                  x          m                )            /              v        n            )        &amp;CenterDot;    [    1    -    exp                  (        -        &amp;alpha;                  W          a                            -        j&amp;omega;                  W          a                /                  v          n                )              ]   ]]>          (8)                                  (              1                  &amp;alpha;                      v            n                    +          j&amp;omega;                    -              1        j&amp;omega;            )        +          1      j&amp;omega;              (      1      -      exp              (        -        &amp;alpha;                  W          a                )            )        }   ]]>                                                    P      s              (      &amp;omega;      )        =                  &amp;eta;                  P          0                    hv        exp          (      -      j&amp;omega;              x        t            /              v        n            )        &amp;CenterDot;          (              1        j&amp;omega;            -              1                  &amp;alpha;                      v            n                    -          j&amp;omega;                    )        &amp;CenterDot;          (      1      -      exp              (        -        j&amp;omega;                                            x              t                        +                          W              a                                            v            p                          )            )       ]]>          (9)                            &amp;CenterDot;    [    1    -    exp          (      -      &amp;alpha;              W        a         ...</td>   <td>G06F17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘伟;              唐仕波;              肖斌;                   丁小燕       </td>   <td>珠海金联安警用技术研究发展中心有限公司;中山大学中山眼科中心</td>   <td>一种基于光学成像的视网膜三维建模装置</td>   <td>广东省</td>   <td>CN101853520B</td>   <td>2012-04-25</td>   <td>本发明公开了一种基于光学成像的视网膜三维建模装置,所述方法包括,步骤一、摄取视网膜各个部位的图像；步骤二、取位于相邻部位的两个图像,统一该两个图像的缩放比例和方向,按照视网膜血管走向特征找出该两个图像的重叠区；比较该两个图像在重叠区的视网膜血管的吻合度,将该两个图像拼接为满足预设吻合度的半径为R的球面,并去除该重叠区中的不吻合的视网膜血管；步骤三、遍历其他周边图像,将该周边图像拼接到所述半径为R的球面上,并去除该重叠区中的不吻合的视网膜血管。本发明采用非介入、无损害的可见光摄像,建立三维视网膜球面模型,可清晰、全面、立体呈现出最接近患者视网膜的三维影像。</td>   <td>1.一种基于光学成像的视网膜三维建模装置,其特征在于,包括拍摄模块、获取模块和拼接处理模块：拍摄模块,摄取视网膜各个部位的图像,位于相邻部位的两个图像有部分像素重叠；获取模块,取位于相邻部位的两个图像,统一该两个图像的缩放比例和方向,按照视网膜血管走向特征找出该两个图像的重叠区；在所述拼接处理模块拼接完该两个图像后,遍历与所述两个图像位于相邻部位的周边图像,统一该周边图像与所述两个图像的缩放比例和方向,按照视网膜血管走向特征找出该周边图像与所述两个图像的重叠区；拼接处理模块,比较该两个图像在重叠区的视网膜血管的吻合度,将该两个图像拼接为满足预设吻合度的半径为R的球面,并去除该两个图像的重叠区中的不吻合的视网膜血管；并将该周边图像拼接到所述半径为R的球面上,同时去除该周边图像与所述两个图像的重叠区中的不吻合的视网膜血管。</td>   <td>G06T17/00;G06T15/00;A61B3/12</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;                   叶梦       </td>   <td>中山大学</td>   <td>一种实现平移敏感的Laplacian网格编辑方法</td>   <td>广东省</td>   <td>CN101276483B</td>   <td>2012-04-18</td>   <td>本发明提供一种实现平移敏感的Laplacian网格编辑方法。Laplacian网格编辑方法常用于计算机动画和工业造型中的模型编辑,但Laplacian坐标不具有平移敏感性,不能很好地保持模型的几何细节特征。因此,本发明提出一种由顶点法线旋转Laplacian坐标的方法,通过原Laplacian坐标重建一个中间模型,计算该模型顶点法线,并旋转原Laplacian坐标至顶点法线的平行方向,再次重建模型获得最终结果。本发明的方法使Laplacian坐标实现了平移敏感的变形效果,且该方法自动计算顶点法线,避免了繁琐的Laplacian向量估算,实现简捷,较好地保持了模型的几何细节特征。</td>   <td>1.一种实现平移敏感的Laplacian网格编辑方法,其特征在于：该方法包括以下步骤：(1)输入三维网格模型M-(0),定义M-(0)＝(V,E,F)有|V|个顶点,其中V,E,F分别表示顶点、边、面的集合；(2)通过M-(0)的笛卡尔坐标构造其Laplacian坐标,记顶点v-(i)的Laplacian坐标为δ-(i)；其中,所述的顶点v-(i)的Laplacian坐标δ-(i)具体为：                                  &amp;delta;      i        =          (              &amp;delta;        i                  (          x          )                    ,              &amp;delta;        i                  (          y          )                    ,              &amp;delta;        i                  (          z          )                    )        =          v      i        -          1              d        i                    &amp;Sigma;              j        &amp;Element;        N                  (          i          )                            v      j        ;   ]]>                  且在公式中,N(i)＝{j|(i,j)∈E},d-(i)＝|N(i)|,d-(i)表示顶点v-(i)的邻接顶点个数；(3)用户通过交互手段对模型M-(0)实行变形操作；(4)根据已知的变形后的顶点集合c-(j),满足v-(j)＝c-(j),j∈{1,2,...,m},作为位置约束条件,从Laplacian坐标重建笛卡尔坐标中的模型M-(k),k＝1；其中,从Laplacian坐标重建笛卡尔坐标中的模型Mk的方法具体为：通过求解下面等式获得变形后的顶点集合V,                                  (              L                              &amp;omega;I                          m              &amp;times;              m                                |          0                    )        V    =                                        &amp;delta;                                                              &amp;omega;c                              1                :                m                                                         ]]>                  公式中,权值ω＞0用于调整位置约束条件的重要性,L为Laplacian算子,通过最小二乘系统求解近似解,系统满秩时存在唯一解：                                  V      ～        =                  arg                 min            V              (                        |          |          LV          -          &amp;delta;          |          |                2            +              &amp;Sigma;                  j          &amp;Element;          C                            &amp;omega;        2                              |          |                      v            j                    -                      c            j                    |          |                2            )       ]]>                  (5)当M-(k)与理想效果的模型的误差相差较大时,记为标记值ε＞E并继续步骤(6),否则跳到步骤(12)；(6)由中间模型M-(k)获取顶点v-(i)各邻接面的法线如果模型凹凸变化较多,继续步骤(7),否则跳到步骤(8)；(7)如果与δ-(i)的朝向不一致,调整令面法线与顶点的Laplacian坐标朝向一致；(8)计算顶点平均法线F(v-(i))；其中,顶点平均法线F(v-(i))根据顶点邻接面的法线计算所得,                            F          (              v        i            )        =                            &amp;Sigma;                      j            &amp;Element;            M                          (              i              )                                                &amp;mu;          j                                      n            j                    &amp;RightArrow;                            |        |                  &amp;Sigma;                      j            &amp;Element;            M                          (              i              )                                                &amp;mu;          j                                      n            j                    &amp;RightArrow;                |        |             ]]>                  其中,M(i)＝{j|(i,j)∈E},为面法线向量,μ-(j)为权重,其值为各邻接面对顶点v-(i)的Laplacian向量的影响,根据三角网格的面积决定；(9)旋转Laplacian坐标δ-(i)；其中,采用如下方式旋转Laplacian坐标的向量,δ-(i)＝‖δ-(i)‖·F(v-(i))；(10)求解中间模型M-(k+1),k＝k+1；其中,M-(k+1)的求解具体过程为：求解方程组,                                  (              L                              &amp;omega;I                          m              &amp;times;              m                                |          0                    )        V    =                                        |            |            &amp;delta;            |            |            &amp;CenterDot;            F                          (              V              )                                                                          &amp;omega;c                              1                :                m                                                         ]]>                  其中,通过求解最小二乘系统获得近似解,系统满秩时存在唯一解：                                  V      ～        =                  arg                 min            V              (                        |          |          LV          -          |          |          &amp;delta;          |          |          &amp;CenterDot;          F                      (            V            )                    |          |                2            +              &amp;Sigma;                  j          &amp;Element;          C                            &amp;omega;        2                              |          |                      v            j                    -                      c            j                    |          |                2            )       ]]>                  (11)如果M-(k+1)与理想效果的模型的误差满足阈值,继续步骤(12),否则,跳到步骤(5)；(12)获得最终模型M-(k+1),结束。</td>   <td>G06T17/20;G06T17/00;G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         许晓伟;              罗笑南;                   王召福       </td>   <td>中山大学</td>   <td>一种图形检索方法</td>   <td>广东省</td>   <td>CN101719140B</td>   <td>2012-04-18</td>   <td>本发明公开一种图形检索方法。该方法包括：(1)进行多边形建模,预先建立三维网格模型库；(2)三维网格模型与二维图像或图形的匹配；(3)三维网格模型骨架的提取；(4)根据骨架进行三维模型检索；(5)三维网格模型特征点提取；(6)三维网格模型控制点的计算；(7)三维网格模型控制点频谱的计算；(8)计算频谱相似度,根据相似度检索出对应的图形。本发明的技术方案可以使得检索更为方便,并且支持多模态检索。</td>   <td>1.一种图形检索方法,其特征在于,包括：1)建立三维网格模型库；2)当用户输入的是二维图形或图像时,与三维网格模型库中的三维网格模型的轮廓进行匹配,根据匹配参数将三维网格模型投影到二维空间,得到投影的二维图像或图形,然后计算投影得到的二维图像或图形与输入的图形或图像之间的相关度,根据相关度检索得到三维网格模型；3)当用户输入的是三维网格模型时,对输入的三维网格模型进行骨架提取,根据提取的三维网格模型骨架,在三维网格模型库中初步检索得到三维网格模型；4)将检索得到的三维网格模型和用户输入的三维网格模型进行特征点提取,代替原始三维网格模型,再进行三角剖分,对剖分后的分割线进行分段拟合,得到原始三维网格模型的控制点,然后根据拓扑结构对控制点进行频域变换；5)计算得到的用户输入三维网格模型的控制点频域坐标值与三维网格模型库中的三维网格模型的控制点频域坐标值之间的相似度,根据相似度检索出对应的图形；其中,步骤4)中根据三维网格模型的拓扑结构对得到的控制点进行频域变换,包括：(1)以控制点到网格中心的矢量的模对粗糙网格的控制点进行排序；(2)从网格拓扑关系获得Kirchhoff矩阵K＝D-A                                             (6)D是对角矩阵,其对角线上的元素Dii与顶点vi的价相对应,A是网格的邻接矩阵；对Kirchhoff矩阵进行特征值分解得到的n个特征向量w-(i)进行升序排列,组成的n*n映射矩阵W；(3)从先前排好序的n个控制点的空间坐标构造3个向量：X＝(x-(1),x-(2),…,x-(n)),Y＝(y-(1),y-(2),…,y-(n)),Z＝(z-(1),z-(2),…,z-(n)) (8)将这3个向量投影到特征向量基W上得到频域向量：                                                                              X              s                        =            WX                                                              Y              s                        =            WY                                                              Z              s                        =            WZ                                -    -    -          (      9      )       ]]>                  每个顶点对应的频谱的幅值S-(i)计算公式为：                                  S      i        =                            |          |                      X            s                    |          |                2            +                        |          |                      Y            s                    |          |                2            +                        |          |                      Z            s                    |          |                2              -    -    -          (      11      )        .   ]]></td>   <td>G06F17/30;G06T7/00;G06K9/68</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;              童随兵;              肖颖;              王艳丽;                   谭恒良       </td>   <td>中山大学</td>   <td>一种基于三次样条的红外热图像盲元补偿算法</td>   <td>广东省</td>   <td>CN101908209B</td>   <td>2012-03-28</td>   <td>本专利提出了一种基于三次样条的红外热图像盲元补偿算法。首先,通过盲元检测,获得红外热图像的盲元分布图。其次,对于每一个盲元点,分别以红外热图像中与该盲元同行同列的像元的坐标为插值节点,构造行方向和列方向二个方向的三次样条,分别求出这二个三次样条在盲元点的插值,取二个插值的均值为盲元的初次补偿值。经过对红外热图像所有盲元进行初次补偿后,再对盲元进行二次补偿：对于每一个盲元点,分别以红外热图像中与该盲元同行同列的像元和经过初次补偿的其他盲元的坐标为插值节点,构造行方向和列方向二个方向的三次样条,分别求出这二个三次样条在该盲元点的插值,取二个插值的均值为该盲元的二次补偿值。遍历所有红外热图像中所有盲元,得到实现二次盲元补偿的红外热图像。</td>   <td>1.一种基于三次样条的红外热图像盲元补偿算法,其特征在于：A、利用盲元所在行和列的像元构造三次样条插值函数对盲元点的灰度值进行初次插值补偿；B、利用盲元所在行和列的像元和经过第一次补偿的其他盲元构造三次样条插值函数对盲元点的灰度值进行二次插值补偿。</td>   <td>G06T5/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;                   林煜超       </td>   <td>中山大学</td>   <td>一种智能气候和交通状况提醒系统</td>   <td>广东省</td>   <td>CN1889110B</td>   <td>2012-03-21</td>   <td>本发明涉及一种利用xml、web service、页面获取与分析等网络技术及数据库技术,自动分析天气预报和道路交通状况,提醒用户做出相应措施的智能气候和交通状况提醒系统。该系统包括数据获取模块、数据处理分析模块、用户接口模块、数据库和外部软硬件等几个部分。当外部软硬件受到触发时,会通过用户接口模块引发数据获取模块从网络上获取数据,然后由数据处理模块根据数据库存储的各种配置处理获取到的信息数据,最终再通过用户接口模块返回结果数据。利用本发明不仅可以采用现有的和正在发展的技术获取天气和交通信息,更能利用获取的信息为用户提供各种服务功能。</td>   <td>1.一种智能气候和交通状况提醒系统,其特征在于该系统包括数据获取模块、数据处理分析模块、用户接口模块、数据库和外部软硬件；		数据获取模块从网络上获取数据后将数据存放到数据库中,留待数据处理分析模块对数据作进一步的分析和处理；		数据处理分析模块包含天气分析和交通情况分析两个子模块,它从数据库中获取存放天气和交通信息的XML文件,然后对其进行分析并提取出各种数据,再对照数据库中的用户设置,调用用户接口模块做出相应的结果返回：1)天气分析模块用于分析获取到的天气情况信息并按照用户设定做出处理；2)交通情况分析模块在条件触发下从数据库获取XML文件并进行分析,再对比用户设定的规则提醒用户,实现自动提前闹铃时间、自动路线推荐的功能；		用户接口模块为一个中间接口模块,一方面作为一个通用的接口提供给外部软硬件,外部软硬件可以通过本模块向本系统传递控制命令；另一个方面,该模块接受来自数据处理分析模块的结果信息,同时查找用户配置,按照用户设定的形式调用外部接口或是连接移动终端返回结果；		数据库存放着系统的各种数据,为系统各部分的运行提供规则和依据；		外部软硬件包括各种类型的用户终端和监测系统；		当外部软硬件受到触发时,它们会调用用户接口模块提供的各种函数接口,由用户接口模块动态生成数据获取模块、数据处理分析模块的具体实例并执行相关的操作,完成数据获取与分析的具体过程；然后,分析结果会被返回到用户接口模块并以用户设定的方式返回到用户终端或监测系统。</td>   <td>G06Q10/10;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              黎立宏;                   黄剑       </td>   <td>中山大学</td>   <td>基于分类识别的人脸跟踪方法</td>   <td>广东省</td>   <td>CN101567043B</td>   <td>2012-02-01</td>   <td>本发明提供一种带分类识别功能的人脸跟踪方法,包括步骤(一)当前帧的待匹配序列为{F-(1)～(C),F-(2)～(C)......F-(j)～(C)}；前面帧的为{F-(1)～(L),F-(2)～(L)......F-(j)～(L)}；(二)依次取出当前帧的F-(m)～(C)计算其LBP编码图；(三)得出LBP编码图后与前面帧的LBP编码图比对,找出与F-(m)～(C)匹配度最高的F-(n)～(L)；(四)根据匹配度、中心位置距离关系判断是否为同一个人；若是将同一人物的人脸图像归为同一类,若不是在F～(L)序列中添加F-(j+1)～(L)＝F-(m)～(C)；(五)重复(二)-(四),直到当前帧待匹配序列被历遍；(六)回到第(一)步处理下一帧。本发明采用旋转的统一模式的LBP特征对人物身份进行分类判别,使同一人的人脸归为一类,解决了传统人脸跟踪方法中人物被遮挡后信息随之丢失的问题,扩展了人脸跟踪系统的功能,提高了其应用价值。</td>   <td>1.基于分类识别的人脸跟踪方法,其特征在于包括以下步骤：(一)从当前帧跟踪到的人脸序列中截取出跟踪到的人脸图像,调整每一帧跟踪到的人脸图像,使其大小一致,保存到当前帧待匹配人脸序列前面帧待匹配人脸序列为(二)依次取出当前帧待匹配人脸序列中的每一个人脸图像计算其对应的LBP编码图；(三)得出人脸图像的LBP编码图后,与前面帧待匹配人脸序列的LBP编码图比对,找出与匹配度最高的(四)根据与的LBP特征匹配度、中心位置距离关系判断它们是否为同一个人；如果是,则将同一个人物的人脸图像归为同一类,如果不是,则在前面帧待匹配人脸序列F～(L)中添加(五)重复步骤(二)-(四),直到当前帧待匹配人脸序列被遍历为止；(六)当前面帧处理结束以后,回到第(一)步处理下一帧；步骤(一)中,用于记录前面帧待匹配人脸序列中对应的人脸目标连续没有出现的帧数的计时器序列为{C-(1),C-(2)......C-(j)},当所对应的人脸目标出现时计时器清零,当计时器超出允许的最大值C-(MAX)时判别该人脸目标已经离开画面范围；步骤(四)中,如果是同一个人时,把替换为计时器C-(n)置零；如果不是同一个人时,在计时器序列C中添加C-(j+1)＝0；步骤(六)中,当前面帧处理结束以后,所有计时器的值加1；步骤(二)计算LBP编码图的步骤如下：提取中心像素点的原始LBP特征；根据原始LBP特征,计算旋转的统一模式的LBP编码计算公式为：                                  LBP              P        ,        R                    riu        2              =                                                      &amp;Sigma;                              p                =                0                                            P                -                1                                      s                          (                              g                p                            -                              g                c                            )                        ,            U                          (                              G                p                            )                        &amp;le;            2                                                P            +            1            ,            U                          (                              G                p                            )                        >            2                               ]]>                  其中,g-(c)为中心点的灰度值,g-(0)......g-(P-1)为邻域中抽样点的灰度值；s(x)为步函数,当x大于等于0时取1,否则取0；P表示在邻域中取样点的个数,R表示取样邻域的半径。</td>   <td>G06K9/00;G06K9/48</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              汪卫星;                   李峰       </td>   <td>中山大学</td>   <td>一种基于颜色和形状特征的图像检索方法</td>   <td>广东省</td>   <td>CN101763429B</td>   <td>2012-01-25</td>   <td>本发明公开了一种基于颜色和形状特征的图像检索方法。该方法包括：将示例图像进行颜色空间转换与量化；对量化后的图像进行图像分块；对每个子块图像的每个像素点计算颜色复杂度,得到视觉权值；对每个子块图像计算不同颜色的视觉权值在子块图像视觉权值所占的比例,得到加权颜色直方图,根据加权颜色直方图得到每个子块的颜色特征；对示例图像通过灰度处理进行轮廓提取；采用曲率尺度空间描述算子提取经过轮廓提取后的图像的形状特征；对提取的所述颜色特征和所述形状特征进行归一化处理,得到归一化后的图像特征；将归一化后的图像特征,利用索引并根据相似性度量的公式在图像特征库中进行匹配,得到检索结果。本发明的检索方法更为准确。</td>   <td>1.一种基于颜色与形状特征图像检索方法,其特征在于,包括如下步骤：		将示例图像进行颜色空间转换与量化；		对量化后的图像进行图像分块；		对每个子块图像的每个像素点计算颜色复杂度,得到视觉权值；		对每个子块图像计算不同颜色的视觉权值在子块图像视觉权值所占的比例,得到加权颜色直方图,根据加权颜色直方图得到每个子块的颜色特征；		对示例图像通过灰度处理进行轮廓提取；		采用曲率尺度空间描述算子提取经过轮廓提取后的图像的形状特征；		对提取的所述颜色特征和所述形状特征进行归一化处理,得到归一化后的图像特征；		将归一化后的图像特征,利用索引并根据相似性度量的公式在图像特征库中进行匹配,得到检索结果；		其中,所述采用曲率尺度空间描述算子提取经过轮廓提取后的图像的形状特征的步骤包括：		通过拉普拉斯算子提取图像的轮廓曲线Γ,然后根据如下公式来获取图像的形状特征：		                  其中t表示轮廓曲线Γ＝{(x(t),y(t))|t∈[0,b]}的参数,b代表曲线参数的取值上限,σ代表高斯核的宽度,起始值设定为σ＝1,然后按照Δσ进行增长,直到曲率为0,这样得到的形状特征表示为K＝{K-(1),K-(2),...K-(i),K-(M)],M为特征维数。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>              邓孺孺       </td>   <td>中山大学</td>   <td>一种图像数据融合方法</td>   <td>广东省</td>   <td>CN101493893B</td>   <td>2012-01-11</td>   <td>本发明公开了本发明所采用的技术方案：一种图像数据融合方法,包括以下步骤：(1)对低分辨率彩色图像进行重采样,使其像元大小与高分辨率黑白图像相同；(2)通过精校正使低分辨率彩色图像与高分辨率黑白图像重合；(3)重采样后的彩色图像各像元的三个波段同乘以黑白图像的相应亮度比值；(4)输出结果图像。本发明所述的数据融合方法不仅完全集成了原始黑白图像的空间信息和彩色图像的光谱信息,无光谱信息的损失,图像颜色不发生变异；而且方法相对简单,运算量小,处理速度快,具有极高的应用价值。</td>   <td>1.一种图像数据融合方法,其特征在于,包括以下步骤：(1)对低分辨率彩色图像进行重采样,使其像元大小与高分辨率黑白图像相同；(2)通过精校正使低分辨率彩色图像与高分辨率黑白图像重合；(3)重采样后的彩色图像各像元的三个波段同乘以黑白图像的相应亮度比值,其计算公式为：式中：Z-(kij)为第k波段输出图像像元值,X-(kij)为第k波段经重采样后的原始图像像元值,Y-(ij)为黑白图像像元值,A为黑白图像像元的最大取值,i、j和k分别为图像行、列号和波段号；(4)输出结果图像。</td>   <td>G06K9/62;G01S17/89;G01S7/48</td>  </tr>        <tr>   <td>中国专利</td>   <td>         郭晓梅;              刘红梅;                   黄继武       </td>   <td>中山大学</td>   <td>一种数字图像的水印嵌入及认证方法</td>   <td>广东省</td>   <td>CN101582158B</td>   <td>2011-12-07</td>   <td>本发明提供了一种数字图像的水印嵌入及认证方法,将图像按块分成不重叠的两个区域——特征区域和水印区域,再提取特征区域的DWT-DCT双变换域内的特征矢量,生成水印嵌入到水印区域中,对图像内容进行真实性认证时,使用一致的分区方法将待检测图像分为两个不重叠的区域,通过计算特征区域的特征矢量与水印区域提取水印恢复得到的特征矢量之间的误差是否在可接受范围,从而判断出图像内容是否真实。</td>   <td>1.一种数字图像的水印嵌入及认证方法,包括水印嵌入和水印认证两大步骤,其特征在于：所述水印嵌入包括如下子步骤：(1)对数字图像按块分成不重叠的两个区域——特征区域和水印区域；(2)提取特征区域的DWT-DCT双变换域内的特征矢量；(3)将步骤(2)得到的实数的特征矢量量化为水印比特；(4)将水印嵌入到水印区域；所述水印认证包括如下子步骤：(5)采用与步骤(1)一致的分区方法将数字图像分为两个不重叠的区域；(6)计算特征区域的特征矢量；(7)提取水印区域的水印比特,并将该水印比特恢复为特征矢量；(8)计算步骤(6)和步骤(7)之间的特征矢量的误差是否超过设定的阈值,从而判断出该数字图像内容是否真实。</td>   <td>G06T1/00;G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              王建民;                   黄达尧       </td>   <td>中山大学</td>   <td>一种基于自适应字典树的电子词典单词检索方法</td>   <td>广东省</td>   <td>CN101271466B</td>   <td>2011-09-28</td>   <td>本发明公开了一种基于自适应字典树的电子词典单词检索方法,它涉及到一种电子词典中单词检索的技术。它定义了一种两层的检索结构,包括自适应字典树前缀匹配层和分段二分搜索的完整单词匹配层。检索方法为：首先在自适应字典树进行单词前缀的匹配,如果能够命中则返回单词信息,否则进入分段二分搜索层进行检索,找到要检索的单词或与它最接近的单词的信息并返回。利用本发明可以有效的提高单词检索的效率,保证时间效率与空间占用的平衡。</td>   <td>1.一种基于自适应字典树的电子词典单词检索方法,其特征在于其主要步骤包括：1)获取要检索的单词后,在载入内存的自适应字典树中进行单词前缀的检索,若在字典树中找到所述要检索的单词则返回所述单词信息,否则进入2)；2)根据在所述字典树中获得的指向分段二分搜索的指针定位到所述前缀所包含的所有单词的开始位置,将分段所包含的所有单词信息载入内存,在分段的二分搜索层进行完整单词的检索,找到要检索的单词或最接近的单词的信息并返回。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              林武;                   刘宁       </td>   <td>中山大学</td>   <td>一种实现嵌入式图像处理多DSP异步工作的系统及其方法</td>   <td>广东省</td>   <td>CN101276458B</td>   <td>2011-09-28</td>   <td>本发明公开了一种实现嵌入式图像处理多DSP异步工作的系统。包括载入图像数据模块、图像处理步骤列表、多DSP处理器异步工作模块、载出图像数据模块,所述的多DSP处理器异步工作模块是核心模块,包括添加处理信息模块,DSP调用模块,去除处理信息模块。所述的添加处理信息模块是DSP调用模块前的预处理；去除处理信息模块是DSP调用模块后的处理。本发明还公开了一种实现嵌入式图像处理多DSP异步工作的方法。本发明解决了多个DSP工作的通信和协调问题,使得多个DSP能够高效的协调工作。</td>   <td>1.一种实现嵌入式图像处理多DSP异步工作的系统,其特征在于：包括载入图像数据模块、图像处理步骤列表、多DSP处理器异步工作模块、载出图像数据模块；其中1)载入图像数据模块-用于实现从存储空间中获得需DSP处理的原始图像数据；2)图像处理步骤列表-用于存放原始图像数据必须经过的DSP的各个处理步骤；3)多DSP处理器异步工作模块-用于实现多个DSP在异步工作模式下的协调工作,包括以下组成部分：未处理存储区-用于存储从载入图像数据模块获得的数据,供添加处理信息模块使用；添加处理信息模块-实现对原始图像数据处理前的预处理,所述添加处理信息模块包括以下四个模块：提取图像数据单元模块-用于从未处理存储区中获得原始图像信息,提取的图像数据单元是一幅图像的一行或几个行；添加数据单元位置信息模块-用于给提取后的数据单元编号,该编号表明提取前其在原始图像数据中先后位置；添加数据单元处理步骤模块-用于把图像处理步骤列表中的信息添加到数据单元中,为DSP调用模块做准备；转发未处理数据单元模块-把添加完位置信息和处理步骤信息的数据单元发送到DSP处理队列；DSP处理队列-用于存放预处理后的图像数据和处理中的图像数据,是一个队列结构；DSP调用模块-实现调用空闲的DSP去异步处理DSP处理队列中的数据单元,所述DSP调用模块包括以下三个模块：维护DSP状态模块-用于维护各个DSP的状态,每一个DSP都是只有两种状态可选：空闲或运行中；分析装入DSP模块-如果DSP处理队列存在数据单元,并且有DSP处于空闲状态,则把队列中的数据单元分配给空闲的DSP去处理；如果没有DSP处于空闲状态或队列中没有数据单元,则等待；转发已处理数据单元模块-如果该数据单元已完成所有图像处理步骤,则把该单元传送到去除处理信息模块,否则,重新进入DSP处理队列等待分析装入DSP模块的调用；去除处理信息模块-执行添加处理信息模块的反操作,实现对已经全部执行完图像处理步骤的图像数据的处理信息的去除,所述去除处理信息模块包括以下三个模块：移除数据单元位置信息模块-执行添加数据单元位置信息模块的反操作；移除数据单元处理步骤信息模块-执行添加数据单元处理步骤模块的反操作；整合图像数据单元模块-把已经去除处理信息的数据单元按照原来的位置信息转入已处理存储区中；已处理存储区-存放已经处理完毕的图像数据,供载出图像数据模块使用；4)载出图像数据模块-用于实现将处理完毕的图像数据输出。</td>   <td>G06T1/20</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;                   齐鹏飞       </td>   <td>中山大学</td>   <td>基于XML和LOD技术的三维图形多分辨率显示方法</td>   <td>广东省</td>   <td>CN101499175B</td>   <td>2011-09-28</td>   <td>本发明公开了一种基于XML与LOD技术的三维图形多分辨率显示方法。该方法主要步骤包括：1)三维图形数据的XML封装。2)对三维图形数据进行LOD分解。3)根据显示终端的要求,利用XML查询工具从模型中抽取不同细节层次的数据,结合XSL模板生成HTML文件。4)将生成的HTML文件通过网络传输到终端,最终实现三维图形数据的显示。通过该方法,针对不同的显示要求进行灵活的数据传输,提高了数据传输的效率,满足了不同终端设备的显示精度要求。</td>   <td>1.基于XML与LOD技术的三维图形多分辨率显示方法,其特征在于其主要步骤包括：1)选择合适的数据存储结构,将三维图形数据存储为XML文件；2)对XML文档中的三维图形数据进行LOD分解,所述对三维图形数据进行LOD分解采用基于点删除的方法,形成具有多分辨率的层次细节模型；3)根据显示终端的要求,利用XML查询工具从模型中抽取不同细节层次的数据,结合XSL模板生成HTML文件；4)将生成的HTML文件通过网络传输到终端,最终实现三维图形数据的显示；对三维图形数据进行LOD分解采用基于点删除的方法,包括以下步骤：(1)计算三角形网格中每个给定顶点的局部几何和拓扑特征,并对顶点分类；(2)如果顶点曲率小于给定的近似误差值,就删除该点；(3)对删除顶点后留下的空洞进行局部三角化；(4)重复以上过程,直至无满足步骤(2)所述条件的点为止。</td>   <td>G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         冯国灿;              陈培炫;              邹卫文;                   邓慧       </td>   <td>中山大学</td>   <td>一种DCT域上的图像检索方法</td>   <td>广东省</td>   <td>CN101556600B</td>   <td>2011-08-24</td>   <td>本发明为一种DCT域上的图像检索方法,其特征在于包括以下步骤：确定主颜色模糊隶属度函数和纹理模糊隶属度函数；选取拟检索图像的主颜色特征块；根据主颜色模糊隶属度函数和主颜色特征块,提取主颜色模糊直方图特征,得到主颜色特征向量K；选取纹理特征块；根据纹理模糊隶属度函数和纹理特征块,提取纹理模糊直方图特征,得到纹理特征向量TK；综合主颜色特征向量和纹理特征向量,得到表达图像检索特征的综合向量Key＝[K,TK]；以拟检索图像的图像检索特征为索引,与图像库中的图像进行匹配检索。本发明检索特征表达简单、计算量少、适用性强,可应用于基于内容的图像检索。</td>   <td>1.一种DCT域上的图像检索方法,其特征在于包括以下步骤：步骤1,确定主颜色模糊隶属度函数和纹理模糊隶属度函数；步骤2,选取拟检索图像的主颜色特征块；步骤3,求步骤2所选取的主颜色特征块的Y、Cr、Cb三个空间的颜色均值,代入步骤1中所确定的主颜色模糊隶属度函数,得到函数值,提取主颜色模糊直方图特征,得到主颜色特征向量K；步骤4,选取拟检索图像的纹理特征块；步骤5,求步骤4所选取的纹理特征块的竖直、水平、对角三个方向的频率变换幅度,代入步骤1中所确定的纹理模糊隶属度函数,得到函数值,提取纹理模糊直方图特征,得到纹理特征向量TK；步骤6,综合步骤3得到的主颜色特征向量和步骤5得到的纹理特征向量,得到表达图像检索特征的综合向量Key＝[K,TK]；步骤7,以拟检索图像的图像检索特征为索引,与图像库中的图像进行匹配检索；步骤1包括以下步骤：步骤11,选取训练图库,分别确定Y、Cb及Cr空间分量的主颜色方差阈值T(Y)、T(Cb)、T(Cr),在Y空间主颜色方差阈值T(Y)基础上,确定纹理方差阈值T(TY)＝T(Y)-100；步骤12,选取Y、Cr及Cb空间分量方差都分别小于T(Y)、T(Cr)、T(Cb)的DCT子块,计算并保留该子块的Y空间颜色均值m-(1)、Cb空间颜色均值m-(2)、Cr空间颜色均值m-(3),得到各自的主颜色聚类中心；步骤13,Y、Cr及Cb空间分量分别以各自的主颜色聚类中心构造主颜色模糊隶属度函数；步骤14,选取Y空间分量方差大于纹理方差阈值T(TY)的子块,分别求该子块在水平、竖直和对角三个方向的频率变换幅度t-(1)、t-(2)、t-(3),得到各自的纹理聚类中心；步骤15,在竖直、对角和水平三个方向分别以各自的纹理聚类中心构造纹理模糊隶属度函数；步骤2为：选取Y、Cr及Cb空间分量方差都分别小于主颜色方差阈值T(Y)、T(Cr)、T(Cb)的DCT子块,作为主颜色特征块；步骤4为：选取Y空间分量方差大于纹理方差阈值T(TY)的DCT子块,作为纹理特征块。</td>   <td>G06F17/30;G06T7/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;                   朱凤贤       </td>   <td>中山大学</td>   <td>一种应用于复杂地层数字制图的筛分方法</td>   <td>广东省</td>   <td>CN101281557B</td>   <td>2011-07-06</td>   <td>本发明提供一种应用于复杂地层数字制图的筛分方法,通过步骤实现：(1)进行复杂地层分类,以钻孔地层为基础,将复杂地质情况在制图方法上分为基本情形,各种复杂地质情况都包括在其中,或由其组合衍生；(2)对钻孔及每个钻孔的地层进行绘制剖面图所需的信息预处理；(3)对复杂地层进行地层连线,构造不同的地层区域。本发明的优点是能快速有效地实现地层剖面自动化绘制,对正常地质状况和缺失、倒转、尖灭等复杂地质状况均有较好的实现效果。</td>   <td>1.一种应用于复杂地层数字制图的筛分方法,其特征在于通过如下步骤实现：(1)进行复杂地层分类,以钻孔地层为基础,将复杂地质情况在制图方法上分为基本情形,各种复杂地质情况都包括在其中,或由其组合衍生；(2)对钻孔及每个钻孔的地层进行绘制剖面图所需的信息预处理；(3)对复杂地层进行地层连线,构造不同的地层区域；所述步骤(1)将复杂地质情况分为六类基本情形,具体如下：设定有两钻孔D1与D2,且存在编号分别为1、2、3、4的四种地层：类型A：D1中层3、2倒转,且D2中存在层2；类型B：D1中层3、2倒转,但D2中无此两层；类型C：D1中层3、2倒转,且D2中倒转情况相同；类型D：D1中层3、2倒转,且在此倒转之上还有层2,D2中缺失层3,形成夹层；类型E：D1中层2、1倒转,并与下层的层1构成夹层之势,D2中存在层2；类型F：D1中层3、2倒转,但D2中层2、3依正常层序出现；所述步骤(2)的信息预处理具体包括如下：(21)设置一个算法数组,并确定剖面图最左侧的钻孔为算法数组起始钻孔,将其它钻孔按与起始钻孔的距离从小到大排序；(22)将地层主层号与亚层号相结合作为地层层序,即层序＝主层号*10+亚层号,并将地层信息按层深从小到大排序。</td>   <td>G06T11/00;G09B29/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王建民;              曹顺艇;              龚武明;              车春回;                   罗笑南       </td>   <td>中山大学</td>   <td>一种三维动画模型的自适应简化方法</td>   <td>广东省</td>   <td>CN101308579B</td>   <td>2011-05-18</td>   <td>本发明针对不同的三维动画模型和终端显示屏幕的分辨率,提出一种基于边折叠的移动图形简化算法,通过定义不同的模型精度感知因子,改进QEM误差度量,获得基于目标屏幕分辨率的感知度量,把不能被用户所感知的冗余数据进行简化,得到面片规模与屏幕显示精度匹配的简化模型。本发明中基于边折叠的简化方法可以在保证显示质量的前提下最大限度的降低三维动画模型的面片规模,因此它可以用在计算和显示能力比较低的三维动画终端显示应用中。</td>   <td>1.一种三维动画模型的自适应简化方法,其特征在于该简化方法基于边折叠简化算法,对网格图形的几何元素进行删除,以实现简化目的,并采用Garland的二次误差(QEM)来对简化进行误差控制,具体包括以下步骤：(1)检索动画模型中的空间三维动画前景模型和背景模型；(2)对前景模型进行自适应简化；(3)对背景模型进行自适应简化；其中,在步骤(1)中,所述动画模型定义为：在三维动画生成过程中使用的三维网格模型,具体可定义为空间中一个三角形的集合,这些三角形之间有公共点和公共边,把这样的三角形集合定义为动画模型M,M可由顶点集V＝(v-(1),v-(2),...,v-(n))和三角形集合T＝(T-(1),T-(2),...,T-(m))所组成的二元组(V,T)来表示；所述前景模型定义为：前景模型是指在动画中具有重要意义,参与动画动作的动画模型；具体来说就是在动画过程中位置角度发生变化,参与动画运动的动画模型；通常由动画作者在制作动画时设定；所述背景模型定义为：背景模型是指在动画中主要作为背景存在的,在动画过程中不发生位置移动和旋转的动画模型；通常由动画作者在制作动画时设定；其中,对前景模型进行自适应简化,具体包括如下步骤：1)获得精度控制系数n、图形视窗参数H-(window)和W-(window)、显示屏幕分辨率参数h-(screen)和w-(screen)参数；其中,所述精度控制系数n定义为：精度控制系数n表示在简化过程中使用的单位长度为n个屏幕像素所对应的空间长度；所述精度控制系数n由用户设定；所述图形视窗参数H-(window)和W-(window)定义为：H-(window)是图形空间中视窗的高度,W-(window)是图形空间中视窗的宽度；所述图形视窗参数H-(window)和W-(window)由系统获取；所述显示屏幕分辨率参数h-(screen)和w-(screen)定义为：h-(screen)是显示屏幕上一列所包含的像素数目,w-(screen)是显示屏幕上一行所包含的像素数目；2)对原始网格中的每个顶点V,计算其误差矩阵Q；其中,一个顶点移动到新顶点的误差表示为：                      &amp;Delta;(v)=&amp;Delta;(vxvyvz1T)=&amp;Sigma;p&amp;Element;planes(v)(pTv)2=&amp;Sigma;p&amp;Element;planes(v)vT(ppT)v ]]>                                        =vT(&amp;Sigma;p&amp;Element;planes(v)(Kp))v=vTQ(vi)v. ]]>                  其中,K-(P)为4×4对称矩阵,即3)对原始网格中的每条边E(u,v),计算精度感知因子M-(edge),把边的两个端点代入边误差计算,取使误差值较小的一点作为新顶点,并把折叠误差值进行排序；其中,所述边E(u,v)的精度感知因子M-(edge)定义为：                      Medge=1(||u-v||n&amp;CenterDot;&amp;epsiv;&amp;GreaterEqual;1)||u-v||n&amp;CenterDot;&amp;epsiv;(||u-v||n&amp;CenterDot;&amp;epsiv;&lt;1) ]]>                  其中||u-v||为点u与点v之间的空间距离；所述边E(u,v)的误差的计算公式定义为：Error′(uv)＝v～(T)(Q-(u)+Q-(v))v·(M-(edge))～(n)；4)选出误差最小的边进行折叠；5)更新相关信息；6)如果没有达到简化目标,转到4),否则结束；其中：所述简化目标为min(E)≥nε,其中min(E)为最短边长；步骤3)和步骤6)中n为精度控制系数,ε为一个屏幕像素在图形空间中所对应的长度；其中,对背景模型进行自适应简化,具体包括如下步骤：a)获得精度控制系数n、图形视窗参数H-(window)和W-(window)、显示屏幕分辨率参数h-(screen)和w-(screen)参数,其中：所述精度控制系数n定义为：精度控制系数n表示在简化过程中使用的单位长度为n个屏幕像素所对应的空间长度；所述图形视窗参数H-(window)和W-(window)定义为：H-(window)是图形空间中视窗的高度,W-(window)是图形空间中视窗的宽度；所述显示屏幕分辨率参数h-(screen)和w-(screen)定义为：h-(screen)是显示屏幕上一列所包含的像素数目,w-(screen)是显示屏幕上一行所包含的像素数目；b)对原始网格中的每个顶点V,计算其误差矩阵Q,其中：误差矩阵Q采用Garland的二次误差来计算获取,具体计算方法如下：一个顶点移动到新顶点的误差表示为：                      &amp;Delta;(v)=&amp;Delta;(vxvyvz1T)=&amp;Sigma;p&amp;Element;planes(v)(pTv)2=&amp;Sigma;p&amp;Element;planes(v)vT(ppT)v ]]>                                        =vT(&amp;Sigma;p&amp;Element;planes(v)(Kp))v=vTQ(vi)v. ]]>                  其中,K-(P)为4×4对称矩阵,即c)对原始网格中的每条边E(u,v),计算精度感知因子M-(edge),把边的两个端点代入边误差计算,取使误差值较小的一点作为新顶点,并把折叠误差值进行排序；其中,所述边E(u,v),u(a-(1),a-(2),a-(3)),v(b-(1),b-(2),b-(3))的精度感知因子M-(edge)定义为：                      Medge=1((a1-b1)2+(a2-b2)2n&amp;CenterDot;&amp;epsiv;&amp;GreaterEqual;1)(a1-b1)2+(a2-b2)2n&amp;CenterDot;&amp;epsiv;((a1-b1)2+(a2-b2)2n&lt;1); ]]>                  所述边E(u,v)的误差的计算公式定义为：Error′(uv)＝v～(T)(Q-(u)+Q-(v))v·(M-(edge))～(n)；d)选出误差最小的边进行折叠；e)更新相关信息；f)如果没有达到简化目标,转到d),否则转到g)；其中：所述简化目标为min(E)≥nε,其中min(E)为最短边长；g)根据三维动画的视点P-(view)(x-(0),y-(0),z-(0)),对简化后的背景模型进行背向面剔除；所述背向面的定义：动画模型中背向视点P-(view)(x-(0),y-(0),z-(0))的三角面片；所述背向面剔除的具体方法为：对视点P-(view)(x-(0),y-(0),z-(0))和三角面片F(u,v,w),u(a-(1),a-(2),a-(3)),v(b-(1),b-(2),b-(3)),w(c-(1),c-(2),c-(3)),该三角面片所在平面方程为：Ax+By+Cz+D＝0其中A＝a-(2)×(b-(3)-c-(3))+b-(2)×(c-(3)-a-(3))+c-(2)×(a-(3)-b-(3))B＝a-(3)×(b-(1)-c-(1))+b-(3)×(c-(1)-a-(1))+c-(3)×(a-(1)-b-(1))C＝a-(1)×(b-(2)-c-(2))+b-(1)×(c-(2)-a-(2))+c-(1)×(a-(2)-b-(2))D＝-a-(1)×(b-(2)×c-(3)-c-(2)×b-(3))-b-(1)×(c-(2)×a-(3)-a-(2)×c-(3))-c-(1)×(a-(2)×b-(3)-b-(2)×a-(3))当Ax-(0)+By-(0)+Cz-(0)+D≤0成立时,三角面片F(u,v,w)为无法在屏幕上显示,也无法被视点感知的背向面片,可以直接剔除；当Ax-(0)+By-(0)+Cz-(0)+D＞0成立时,三角面片F(u,v,w)为可以显示的正向面片,需要保留；如果有一个点v,包含v的所有面片都是背向面片,当所有背向面片都被剔除后,从点列表中将v剔除。</td>   <td>G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         骆伟祺;                   黄继武       </td>   <td>中山大学</td>   <td>一种基于彩色关系特征的图像近似拷贝检测方法</td>   <td>广东省</td>   <td>CN101504655B</td>   <td>2011-03-23</td>   <td>本发明提供一种基于彩色关系特征的图像近似拷贝检测方法,包括步骤：(1)记录图像分块的颜色关系特征；(2)图像鲁棒特征的提取；(3)阈值的选取方法与图像近似拷贝的识别。利用本发明能够快速提取出数字图像的鲁棒特征表示,并能通过该特征有效地判断两幅图像I,I′是否为近似拷贝版本。与现有方法相比,本发明的时间、空间复杂度均较低,并且能抵抗大部分常用的图像处理操作。</td>   <td>1.一种基于彩色关系特征的图像近似拷贝检测方法,其特征在于包括如下步骤：(1)将一幅图像分成多个图像块Blk(j),并计算每一个Blk(j)中红、绿、蓝三个颜色通道上像素的平均值,再根据这三个平均值的大小排列组成六种关系case i(i＝1,2,3,4,5,6)；(2)统计步骤(1)中各图像块Blk(j)中的颜色所属关系,令满足关系case i的图像块集合为P-(i),计算P-(i)占所有图像分块中的百分比H(i),从而得到整幅图像的鲁棒特征：[H(1),H(2),H(3),H(4),H(5),H(6)]；(3)计算图像I与图像I′之间相似度的距离：D(H,H&amp;prime;)=&amp;Sigma;i=16|H(i)-H&amp;prime;(i)|, ]]>其中,H,H′分别表示图像I,I′的鲁棒特征,并从图像训练集中提取阈值T,根据图像间的相似度距离与阈值T的比较确定两幅图像是否为近似拷贝。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>在不同尺度特征图像上进行人脸光照规一化的方法</td>   <td>广东省</td>   <td>CN101261678B</td>   <td>2011-01-05</td>   <td>本发明公开了一种在不同尺度特征图像上进行人脸光照规一化的方法,首先运用对数域的总变分模型将原始人脸图像分解为小尺度特征图像和大尺度特征图像；然后对受光照变化影响较大的大尺度特征图像进行光照处理,对小尺度特征图像进行带阈值的最小值滤波；最后运用处理过的不同尺度特征图像合成得到光照规一化后的人脸图像。本发明主要在受光照变化影响较大的大尺度特征图像上进行光照规一化,避免对光照不变的小尺度特征进行更改而影响人脸识别率,此外没有丢弃受光照影响的人脸大尺度特征,避免了仅用人脸小尺度特征进行人脸识别而导致识别信息不足的问题。本发明算法易于实现,不需对人脸图像进行严格对齐,也不需要任何训练样本,符合各种实际应用要求。</td>   <td>1.在不同尺度特征图像上进行人脸光照规一化的方法,其特征在于,它的步骤包括：1)对输入的人脸灰度图像进行对齐裁剪处理,分为三步进行：(1)对每张人脸图像,先检测定位该人脸的三个特征点：两只眼睛的瞳孔中心点和嘴巴的中心点；(2)通过旋转使得每张人脸的两只眼睛处于水平位置；(3)运用双插值算法拉伸图像,使得这三个特征点位于图像的固定位置,最后将图像裁剪为统一大小；2)用LTV模型对人脸图像进行分解：对每张裁剪对齐后的人脸图像I,对其进行对数变换f(x,y)＝logI(x,y)                                (1),求解以下变分模型：                      u=argmin&amp;Integral;u&amp;prime;|&amp;dtri;u&amp;prime;|+&amp;lambda;||f-u&amp;prime;||L1---(2) ]]>                  以及v＝f-u                                                        (3),此时得到人脸的大尺度特征图像S和小尺度特征图像ρ：S＝exp(u),ρ＝exp(v)                            (4)；3)对小尺度特征图像ρ进行带阈值的最小值滤波,以获得滤波后的小尺度特征图像ρ′；4)在对数域去掉大尺度特征图像的若干低频离散余弦变换(DCT)系数：即对u进行DCT,记DCT系数为C(α,β),α＝0,1,…,M-1,β＝0,1,…,N-1,其中M、N为人脸图像的长和宽,然后将频域原点周围n～(2)个DCT系数设置为0,C(α,β)＝0,α＝0,1,…,n-1,β＝0,1,…,n-1    (5),通过反DCT变换得到,最后进行指数变换获取光照规一化后的大尺度特征图像S-(norm)：                      Snorm(x,y)=expu^(x,y)---(6); ]]>                  5)合成光照规一化后的人脸图像：I-(norm)(x,y)＝ρ′(x,y)S-(norm)(x,y)                (7)。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;                   麦章灿       </td>   <td>中山大学;广州中珩电子科技有限公司</td>   <td>一种基于比特映射的压缩键树的单词检索方法</td>   <td>广东省</td>   <td>CN101299212B</td>   <td>2010-12-08</td>   <td>本发明公开了一种基于比特映射的压缩键树的单词检索方法,它涉及到一种电子词典中单词检索的技术。它定义了非完全的压缩规则,可以将关键字为单字符的键树的结点进行压缩,形成关键字为多字符的结点。关键字为单字符的结点和关键字为多字符的结点不会为兄弟结点,并且使用了比特映射的方法表示了键树结构中是否存在对应的子结点且不需要经过比较,而是通过计算直接定位到该子结点的位置,虽然牺牲了一定的存储空间,但是检索速度将可以得到大大的提高。</td>   <td>1.一种基于比特映射的压缩键树的单词检索方法,其特征在于包括以下步骤：(1)根据单词分布和压缩规则生成非完全压缩的键树,所述压缩规则包括关键字为单字符的结点和关键字为多字符的结点不为兄弟结点,如果某结点的子结点个数大于1,则该结点的所有子结点均为关键字为单字符的结点,如果关键字为Value[i]的树结点TreePoint[i]和关键字为Value[k]的子结点TreePoint[k]可以进行非完全压缩合并,形成新的关键字为STRCAT(Value[i],Value[k])的子树结点TreePoint[i,k],定义其压缩规则如下：TreePoint[i]没有兄弟结点,即TreePoint[i]的父亲结点只有唯一的子结点；TreePoint[i]没有对应的单词,即根结点到TreePoint[i]的路径对应的字符串在词典中没有对应的单词存在,TreePoint[i]没有单词记录指针；TreePoint[k]没有兄弟结点,即TreePoint[i]只有唯一的儿子结点TreePoint[k]；(2)在非完全压缩的键树上采用包括关键字、长子结点的指针、单词记录指针和具有比特映射关系的比特映射码的数据结构；(3)在基于比特映射关系的键树中进行单词检索,包括根据比特映射码确定下一字符对应的键树节点的指针,根据所述指针进行检索。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         黎夏;              刘小平;              李丹;              张亦汉;              何晋强;                   陈逸敏       </td>   <td>中山大学</td>   <td>地理模拟优化系统</td>   <td>广东省</td>   <td>CN101419623B</td>   <td>2010-09-08</td>   <td>本发明提供地理模拟与优化系统的概念、原理和软件实现,用来模拟、预测、优化并显示地理格局和过程。本发明的优点在于：将目前分散的元胞自动机、多智能体系统和地理优化知识进行了系统的整合,构建出了地理模拟与优化系统；将地理模拟与优化知识与软件工程思想和技术进行了有机结合,从软件角度进行了实现。</td>   <td>1.一种地理模拟优化系统,其特征在于综合元胞自动机,多智能体系统以及生物智能来模拟、预测、优化并显示地理格局和过程；所述元胞自动机,多智能体系统以及生物智能被整合在一起模拟微观实体之间的相互影响和相互作用,并定义为：其中,S-(i)～(t)和L-(i)～(t)代表的是实体i的状态和位置,所述实体包括静止元胞和可移动智能体,可移动智能体进一步细分为社会智能体和生物智能体,Et和F分别用来表征环境和互作用规则集；所述互作用规则集包括三个子集：F～(F-(CA),F-(SocialAgent),F-(AnimalAgent)),其中F-(CA)用来表示静止元胞的互作用规则,F-(SocialAgent)用来表示社会智能体和他们所处的环境之间的互作用规则,F-(AnimalAgent)用来表征生物智能体和其外在环境之间的互作用规则。</td>   <td>G06F17/30;G06N1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         凌若天;                   罗笑南       </td>   <td>中山大学</td>   <td>一种基于哼唱的乐曲自动选择装置和方法</td>   <td>广东省</td>   <td>CN1953046B</td>   <td>2010-09-01</td>   <td>本发明公开了一种基于哼唱的乐曲自动选择装置和方法,解决了用户在只记得乐曲的主旋律,而忘记乐曲的名字和歌手的信息等情况下,而通过哼唱旋律来选择歌曲。基于哼唱的乐曲自动选择装置包括音频采集设备、服务器、输入设备和输出设备,该方法包括通过哼唱选歌和通过口述乐曲基本属性选歌。用户只用哼唱或者口述乐曲的基本属性,音频采集设备采集音频数据并传送给服务器,服务器分析音频数据,并与数据库中的数据进行匹配寻找满足条件的乐曲,最后通过输出设备显示响应结果。</td>   <td>1.一种基于哼唱的乐曲自动选择装置,它包括音频采集设备,用于在开启状态下负责采集使用者哼唱的乐曲和采集使用者口述的乐曲基本属性,同时将集到的数据发送到系统的服务器；服务器,用于负责存储乐曲,接收所述音频采集设备采集的数据,并与之进行匹配,将匹配的结果传送回输出终端,并对输入终端传送过来的各种命令进行分析；所述输出终端,用于负责显示所述服务器匹配的结果和显示响应用户的各种输入；所述输入终端,用于负责输入匹配条件和向服务器发送各种命令。</td>   <td>G06F17/30;G10H1/36;G10L15/08</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              李峥;                   苏卓       </td>   <td>中山大学</td>   <td>一种基于局部坐标的线性约束图像变形方法</td>   <td>广东省</td>   <td>CN101276474B</td>   <td>2010-09-01</td>   <td>本发明涉及一种基于局部坐标的线性约束图像变形方法。该方法将图像转换为对应的四边域网格,用仿射和角度的线性约束描述网格的几何特征,并根据用户指定的控制顶点构造边界约束条件,求解线性方程组,快速地计算出变形后的图像。本方法能以交互式的速度获得具有平移敏感性质的变形效果,能通过调节两种线性约束的权值,控制仿射变形的比重,实现了良好的弯曲、平移敏感、各向异性缩放等复杂的变形效果。</td>   <td>1.一种基于局部坐标的线性约束图像变形方法,其特征在于,该方法包含以下步骤：(1)对输入的二维图像进行正方形的网格化操作,并采用局部坐标来描述网格的几何特征,表示为下式：                      V*=argminV&amp;prime;&amp;alpha;&amp;Sigma;vi&amp;Element;V||t(vi&amp;prime;)-t(vi)||2 ]]>                                        +&amp;beta;&amp;Sigma;em,en&amp;Element;E||r(em&amp;prime;,en&amp;prime;)-r(em,en)||2 ]]>          公式(1)                      +&amp;omega;&amp;Sigma;vk&amp;Element;&amp;Omega;||vk&amp;prime;-uk||2 ]]>                  其中V-(i)是原顶点位置,v-(i)′是新顶点位置,表示顶点在相邻标架中的局部坐标,e-(m)、e-(n)是相邻边,表示相邻边的旋转量,α、β、ω是相应的权重；(2)对顶点之间的相对位置进行仿射约束,得到关于位置的约束条件,其计算步骤为：每个顶点用v表示,通过v的下标表示不同顶点,得出线性关系：                      v1-v0=v0-v3v2-v0=v0-v4 ]]>          公式(2)新顶点在相邻局部坐标中的误差写作：                      E1{v0&amp;prime;}=||v0&amp;prime;-(v1&amp;prime;+v3&amp;prime;)/2||2 ]]>          公式(3)                      +||v0&amp;prime;-(v2&amp;prime;+v4&amp;prime;)/2||2 ]]>                  则全局的仿射误差为：                      E1=&amp;Sigma;vi&amp;prime;&amp;Element;V&amp;prime;E1{vi&amp;prime;} ]]>          公式(4)求解带线性边界约束的最小二乘线性方程组                      V*=argminV&amp;prime;&amp;alpha;&amp;Sigma;||HV&amp;prime;||2+&amp;omega;&amp;Sigma;vk&amp;prime;&amp;Element;&amp;Omega;||vk&amp;prime;-uk||2 ]]>          公式(5)求得使全局误差最小的新顶点位置V′,其中H是由公式(3)得到的权值矩阵,表示各顶点的相邻关系；(3)对相邻边之间的夹角进行角度约束,得到关于角度的约束条件,其计算步骤为：在二维平面中互相垂直的等长向量的x和y分量构成以下的线性约束关系：                      (v1-v0)x=(v2-v0)y(v1-v0)y=-(v2-v0)x ]]>          公式(6)则新顶点所构成的局部标架的误差为：                      E2{v0&amp;prime;}=||(v1-v0)x-(v2-v0)y||2 ]]>                                        +||(v1-v0)y+(v2-v0)x||2 ]]>          公式(7)相应得到全局角度误差为：                      E2=&amp;Sigma;vi&amp;prime;&amp;Element;V&amp;prime;E2{vi&amp;prime;} ]]>          公式(8)从而得到完整的带线性约束的最小二乘线性方程组：                      V*=argminV&amp;prime;&amp;alpha;&amp;Sigma;||HV&amp;prime;||2+&amp;beta;&amp;Sigma;||KVx&amp;prime;Vy&amp;prime;||2 ]]>                                        +&amp;omega;&amp;Sigma;vk&amp;prime;&amp;Element;&amp;Omega;||vk&amp;prime;-uk||2 ]]>          公式(9)其中K是由公式(7)得到的权值矩阵；(4)调节α和β的比值平衡两种约束条件,并求解线性方程组；(5)生成二维动画形象的多种复杂变形效果。</td>   <td>G06T13/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         周翠英;                   赵宏坚       </td>   <td>中山大学</td>   <td>一种应用于岩土工程建模的三角网格构建方法</td>   <td>广东省</td>   <td>CN101303770B</td>   <td>2010-08-25</td>   <td>本发明提供一种三角网格构建方法及其在岩土工程建模的应用,本发明的优点是能简单,快速的构造符合Delaunay三角网格规则的三角网格,并能同步进行网格优化,适用于根据二维或三维空间离散点集来构造符合Delaunay三角规则的三角网格,能很好的应用到不规整三维模型的构造,如三维地层层面模型的构造。</td>   <td>1.一种应用于岩土工程建模的三角网格构建方法,其特征在于根据工程单位提供的钻孔数据,建立钻孔信息数据库；提取工程所在区域的钻孔坐标数据,获取地层钻孔的层对应点,确定节点的x、y、z坐标,形成初始点集合,运用三角网格构建方法构建地层层面的模型,所述三角网格构建方法通过如下步骤实现：(1)根据所有离散构造点计算形心点P-(c),计算所有构造点到形心点的距离,并根据距离对构造点进行排序；(2)使用离形心点P-(c)最近的三个构造点构造中心三角形t-(1),把中心三角形t-(1)设为初始网格M,并根据三角形边界的逆时针方向构造初始边界环R；(3)按照距离由小到大插入构造点P,建立构造点P到中心点P-(c)的线段L,遍历边界环R,寻找线段L和边界有交点的边界线L-(b)；(4)使用构造点P和边界线L-(b)构造新的三角形T-(n),并使用Delaunay三角优化规则来优化三角形T-(n)和T-(n)的邻接三角形T-(n1)；(5)通过判断三角形T-(n)的新边和邻接边的夹角θ是否小于一个预设值来构造新的边界三角形t-(n),若小于则构造新的边界三角形t-(n),并使用Delaunay三角优化规则来优化三角形t-(n)和t-(n)的邻接三角形；(6)重复步骤(3)～(5),直到插入所有构造点。</td>   <td>G06T11/00;G06T17/50</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王若梅;              王众;              彭丽仪;                   刘林       </td>   <td>中山大学</td>   <td>一种基于SWRL-Bridge-Peer模型的本体关联方法</td>   <td>广东省</td>   <td>CN101382950B</td>   <td>2010-08-11</td>   <td>本发明使用了基于扩充的SWRL规则本体关联方法,并把方法进行了扩展,从单一类的关联扩展到混合类和属性的关联,完善了基于SWRL规则的本体关联方法。同时使用了基于Bridge-Peer的模型进行本体间的关联。其主要内容是把语义相关度高的本体划分为一个簇,语义不相关或相关度低的本体处于不同簇内,簇内本体通过扩充的SWRL规则实现关联,而簇间的本体通过bridge-peer节点进行关联。该模型在进行查询关联时解决了瓶颈问题。本发明保留了基于SWRL扩充规则的本体关联方法和基于super-peer模型的本体关联方法的优点。同时,也弥补了两者的不足,使得新模型的健壮性更好,使用范围更广。</td>   <td>1.一种基于SWRL-Bridge-Peer模型的本体关联方法,其特征在于在簇间的查询使用Super-Peer模型的机制,在基于Super-Peer模型的本体关联方法中,把网络中的本体根据一定规则划分为不同的簇,每个簇中有一个称为super-peer的特殊节点,这里使用一个称为bridge-peer的节点来连接不同的簇,进行不同簇间本体的关联；但在簇内,为了保持使用SWRL扩充规则进行的本体关联的灵活性和通用性,并消除Super-Peer模型中瓶颈问题,使用完善的SWRL扩充规则进行簇内的本体关联,具体步骤如下：步骤1.用户进入该本体关联平台,进行本体的选择；步骤2.系统根据用户提交的本体,列出本体中存在的类,数据属性以及对象属性信息；步骤3.用户提交查询需求,系统分析用户提交的谓词类型再进行分别处理；步骤4.如果规则中包含类谓词,且类谓词中的类是本地本体中的类,则执行步骤5；如果类谓词中的类是关联本体中的类,则执行步骤6；步骤5.查询本地本体关于步骤4类谓词中类的实例集；步骤6.向关联本体发出查询关于步骤4类谓词中的类的实例集的请求；步骤7.如果规则中包含属性谓词,且属性谓词中的属性是本地本体中的属性,则执行步骤8；如果属性谓词中的属性是关联本体中的属性,则执行步骤9；步骤8.查询本地本体关于步骤7属性谓词中的与该属性具有关系的实例集；步骤9.向关联本体发出查询关于步骤7属性谓词中的与该属性具有关系的实例集；步骤10.返回最终用户查询的结果。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         陈任;                   罗笑南       </td>   <td>广东中大讯通软件科技有限公司;中山大学</td>   <td>一种三维图形数据的压缩处理方法</td>   <td>广东省</td>   <td>CN101123000B</td>   <td>2010-06-23</td>   <td>本发明公开了一种三维图形数据的压缩处理方法,采用规整化的四边形面片代替三角形面片,通过重网格化、细分小波构造、零树压缩、熵编码步骤对图形数据进行压缩处理,提供了一种基于四边形面片的几何图形压缩方法。本发明能够更好地适应和满足三维显示数据采集技术的快速发展以及应用的需求。对于复杂模型可获得更好的压缩效果,可被渐进传输、压缩效果失真率较小并且可控制与调节,能够更好地利用目前已有的存储和传输能力,减少目前硬件和网络设施对三维显示技术所造成的制约和影响。</td>   <td>1.一种三维图形数据的压缩处理方法,包括以下步骤：a)获取模型外观的初始扫描网格；b)通过重网格化模块,对所述初始扫描网格进行规整处理,使获得的新网格具有细分连续性并支持拓扑信息简化操作；c)通过细分小波构造模块,对所述新网格信息数据进行分裂、预测、更新和合并处理,以实现网格信息数据的分解和重构过程,从而获得小波变换后的图像；d)通过零树压缩模块,以与小波系数相关的上下两层、四叉树形式来构建小波零树；e)通过EZW方法对获得的小波零树进行量化与压缩,从而获得小波图像零树压缩编码；f)通过熵编码模块,对所述零树压缩编码进行进一步的数据压缩,从而获得三维图形压缩数据；其特征在于：所述步骤b)中获得的新网格为规整的四边形面片网格；所述步骤d)的零树构建过程中,对于四边形面片,采用面、边、点的对应关系,且上、下两层四边形面片网格的非边界处的面和面之间、边和边之间可建立1-4对应关系,下层的顶点与上一层的边之间可以建立1-1对应关系,故通过传递作用在非边界处上下层顶点间建立1-4对应关系。</td>   <td>G06T9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         毛正华;                   罗笑南       </td>   <td>中山大学</td>   <td>图书馆中自动精确定位图书的方法及其系统</td>   <td>广东省</td>   <td>CN1952974B</td>   <td>2010-06-09</td>   <td>本发明公开了一种图书馆中自动精确定位图书的方法,包括确定图书书目信息的步骤和确定图书位置信息的步骤,图书的书目信息采用RFID技术进行感应读取,而位置信息的获取则利用红外感应器。本发明还公开了一种图书馆中自动精确定位图书的系统,包括电子标签、RFID阅读器、红外感应器、记录生成单元、缓冲存储器、编码模块、解码模块和数据库。本发明能够自动识别图书,以及自动反馈该图书的精确放置位置,结合书目信息和位置信息对数据库进行更新,从而实现图书的自动精确定位。本发明可以使读者自由快捷地归还图书,不仅节省了读者的宝贵时间,而且也减少了管理员的工作量,提高了工作效率,有利于进一步提高图书管理的智能化水平。</td>   <td>1.一种图书馆中自动精确定位图书的方法,包括如下图书书目信息的采集步骤：a1.在图书上附着记载有该图书相关书目信息的电子标签；a2.通过设置在感应区范围内的RFID阅读器探测采集图书电子标签上的书目信息；a3.RFID阅读器所读取到的图书书目信息存放在缓冲存储器中；其特征在于还包括如下图书位置信息的采集步骤：b1.在书架的各单元格上放置红外感应器,各红外感应器发出的红外光只照射到本身所放置的单元格；b2.读者携带图书进入感应区时,RFID阅读器感应读取到该图书电子标签上的信息,并通过与缓冲存储器内存放的图书记录信息进行比较,以确定是否是新进入该感应区的图书,如果是则将该图书的书目信息转存入记录生成单元；同时,启动相应感应区内的红外感应器；b3.读者将图书放入书架的某个单元格时,该单元格的红外感应器感应到读者将图书放入书架操作动作,并发送信号到编码模块；b4.编码模块根据红外感应器发出的信号,按照预先约定的规则对图书的归放位置进行编码从而生成位置编码,并将该位置编码存入记录生成单元；b5.记录生成单元将图书的书目信息以及图书的位置编码对应组合起来生成新的图书记录,并存放在缓冲存储器中；b6.将缓冲存储器中新生成的图书记录通过网络传输系统传送给解码模块,以解码、分析出图书归放的具体位置信息,然后将该图书的书目信息和具体位置信息传送给数据库进行更新。</td>   <td>G06Q50/00;G06K7/00;G01S17/74</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;              王建民;                   黄达尧       </td>   <td>中山大学</td>   <td>一种电子词典的快速单词查询系统</td>   <td>广东省</td>   <td>CN101251848B</td>   <td>2010-06-09</td>   <td>本发明公开了一种电子词典的快速单词查询系统,通过优化单词查询的各个主要环节来提高单词查询的效率。该系统主要包含四个模块：单词搜索模块、动态缓存模块、单词内容读取与解析模块、单词内容显示模块。该系统对电子词典中单词查询软件的开发提供了很好的参考,并在单词查询的时间效率和空间占用率之间达到了很好的平衡。</td>   <td>1.一种电子词典的快速单词查询系统,其特征在于包含如下四个模块：使用改进的二分搜索技术的单词搜索模块；通过在内存中使用动态数组来模拟的动态缓存模块；根据单词内容信息量大小来动态进行读取与解析的单词内容读取与解析模块；使用xml技术的自定义界面配置的单词内容显示模块；其中所述的改进的二分搜索技术的单词搜索模块采用了基于二分搜索的两层结构,第一层是指针层,第二层是单词词头层,单词词头层里面,词头是按顺序排放的,每个词头占用的空间是不相等的,大小就是单词词头的长度,而指针层是等长的,每个指针元素指向对应的单词词头,实际上该指针的值就是单词词头在词头层的偏移位置,用来确定词头位置的；所述的根据单词内容信息量大小来动态进行读取与解析的单词内容读取与解析模块中,设定一个单词内容信息量的阈值maxInfoLen,根据读取到的单词的信息量大小wordInfoLen来选择读取和解析方式：1)当wordInfoLen＜maxInfoLen时,查看可选内容频繁,则一次完成提取与解析的过程,将单词全部内容依次读到内存,并解析到该单词的结构中；2)当wordInfoLen＜maxInfoLen时,查看可选内容很少,则一次提取,多次解析,将单词全部内容依次读到内存,但事先不将其解析到单词的结构中,用户真正需要查看该单词的某一可选内容时再进行解析；3)当wordInfoLen＞＝maxInfoLen时,多次提取,多次解析,只将单词的基本内容读到内存,当用户需要查看该单词的某个可选内容时,再从外存中读取该部分可选的内容并进行解析。</td>   <td>G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              邹耀贤;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于核主成分分析的人脸超分辨率重构方法</td>   <td>广东省</td>   <td>CN101299235B</td>   <td>2010-06-02</td>   <td>本发明公开了一种基于核主成分分析的人脸超分辨率重构方法,首先利用核主成分分析算法建立了低分辨率特征空间和低分辨率特征空间的关系,利用这种关系学习出与输入低分辨率人脸图像所对应的高分辨率人脸图像在高分辨率特征空间中的象到高分辨率核主成分子空间投影的近似,然后采用Mika等人的迭代原象学习算法从高分辨率特征空间中获得高分辨率原象,针对高分辨率全局人脸图像过于平滑、缺少细节信息的现象,本发明还对高分辨率全局人脸图像进行了残差补偿,本发明采用了核主成分分析方法来建立不同分辨率图像之间的联系,跟线性方法相比,核主成分分析方法是一种非线性方法,能够学习出数据的线性和非线性特征,所以重构的图像更接近原图。</td>   <td>1.一种基于核主成分分析的人脸超分辨率重构方法,其特征在于包括下述步骤：(一)对训练图像进行人脸对齐,对齐后作为高分辨率训练样本；再通过模糊、降采样得到对应的低分辨率训练样本；(二)将高分辨率训练样本及对应的低分辨率训练样本分成两个部分,其中,一部分用于全局模型的训练；另一部分用于残差补偿的训练,并将残差补偿的低分辨率训练样本作为全局模型的低分辨率测试样本；(三)对于低分辨率测试样本,通过核主成分分析,计算其在低分辨率特征空间中的象到低分辨率核主成分子空间的投影；(四)构造与低分辨率测试样本所对应的高分辨率图像在高分辨率特征空间中的象到高分辨率核主成分子空间投影的近似；(五)利用迭代原象学习算法重构出高分辨率全局人脸图像；(六)通过计算高辨率残差脸和对应的低分辨率残差脸并对其进行分块,构造低分辨率残差块训练库和高分辨率残差块训练库,求得测试图像的高分辨率残差脸来对重构的高分辨率全局人脸图像进行残差补偿；(七)将(五)中得到的高分辨率全局人脸加上(六)中的高分辨率残差脸,得到最终的高分辨率人脸图像。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         邹才凤;                   罗笑南       </td>   <td>中山大学</td>   <td>一种外插法改进的基于ENO的图像插值方法</td>   <td>广东省</td>   <td>CN101281641B</td>   <td>2010-06-02</td>   <td>本发明公开了一种外插法改进的基于ENO的图像插值方法,它属于数字图像插值处理技术领域。本发明针对ENO插值方法没有解决的边缘处理问题,提出了改进方法。根据ENO方法的模板选择结果,可以检测出包含奇异点的边缘区间,使用外插法来对边缘区间进行插值,根据待插值边缘区间的左右相邻区间的插值多项式的交点位置,将包含奇异点的边缘区间分成两部分,在待插值边缘区间的左端点到奇异点之间,用左相邻区间的插值多项式来进行插值,在奇异点到待插值边缘区间的右端点之间,用右相邻区间的插值多项式来进行插值。对非边缘区间,使用ENO插值方法进行插值。本发明方法可以实现任意倍数的图像插值。</td>   <td>1.一种外插法改进的基于ENO的图像插值方法,其特征在于它的主要步骤包括：(1)检测当前待插值区间是否为边缘区间,即是否包含奇异点；(2)若待插值区间不是边缘区间,则使用ENO插值方法对该区间进行插值；(3)若待插值区间是边缘区间,则使用外插法对该边缘区间进行插值,所述外插法包括：根据待插值边缘区间的左右相邻区间的插值多项式的交点位置,将包含奇异点的边缘区间分成两部分,在待插值边缘区间的左端点到上述交点之间,用左相邻区间的插值多项式来进行插值,在上述交点到待插值边缘区间的右端点之间,用右相邻区间的插值多项式来进行插值；(4)对每一个待插值区间,按照步骤(1)至步骤(3)进行插值,得到一维数据的插值结果,分别对图像矩阵的行和列进行一维插值,得到图像插值结果。</td>   <td>G06T3/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;              刘金葵;              李静;              莫丽娴;                   谭恒良       </td>   <td>中山大学</td>   <td>一种快速准确的正面人脸判别方法</td>   <td>广东省</td>   <td>CN101383001B</td>   <td>2010-06-02</td>   <td>本发明提出一种利用Adaboost算法与肤色检测相结合来做正面人脸判别的方法,属于模式识别技术领域。本发明提出的算法首先利用Adaboost人脸分类器寻找人脸区域,再利用Adaboost眼睛分类器搜索眼睛区域,再基于肤色检测与质心计算方法确定眼眶中心,接着根据眼眶中心位置切割裸脸,最后利用眼睛位置与祼脸左右两侧窄条带肤色点数目比例来排除非正面姿态人脸,从而得到标准的正面人脸图像。本算法可过滤各种非正面人脸图像,获取标准的正面人脸图像,可作为人脸识别的前置步骤,保证同姿态识别,从而提高识别率,亦可用于建立人脸数据库时的正面姿态判别。</td>   <td>1.一种基于Adaboost算法与肤色检测相结合的正面人脸判别方法,其特征在于使用Adaboost分类器分别检测人脸与眼睛的区域、利用肤色检测与质心计算方法确定眼眶区域及其中心位置、根据两眼眶中心位置的纵坐标之差,来过滤向左右侧的非正面人脸、根据眼眶中心位置切割裸脸和通过计算裸脸两侧条带的肤色点数目的比例来判断人脸是否存在左右旋转问题。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         欧阳祥波;              宗志坚;                   熊会元       </td>   <td>中山大学</td>   <td>一种三维重构的双摄像机标定方法</td>   <td>广东省</td>   <td>CN101149836B</td>   <td>2010-05-19</td>   <td>本发明涉及一种三维重构的双摄像机标定方法,其特征是：以空间标定点的三维重建误差最小为目标函数,对双摄像机的相对位姿进行标定,包括如下步骤：1)打开两个摄像机,同时获取关于标定物点的一系列图像,采用传统的单摄像机标定方法,分别对两个摄像机进行标定；2)以双摄像机视线的公垂线的中点为三维重构的空间物点,建立三维重构的代数表达式,以物点的三维重构误差最小为目标函数,以上一步获得的内、外参数为初值,通过迭代求解,对双摄像机的相对位姿进行标定；对第2)步建立的立体标定模型进行数值化求解,完成双摄像机标定过程。本发明具有标定准确、误差最小的有益效果。</td>   <td>1.一种三维重构的双摄像机标定方法,其特征是：以空间标定点的三维重建误差最小为目标函数,对双摄像机的相对位姿进行标定,包括如下步骤：1)获得摄像机内参数和外参数的初值打开两个摄像机,同时获取关于标定物点的一系列图像,采用传统的单摄像机标定方法,分别对两个摄像机进行标定；2)建立双摄像机的立体标定模型以两个摄像机视线的公垂线的中点为三维重构的空间物点,建立三维重构的代数表达式,以物点的三维重构误差最小为目标函数,以第1)步获得的内、外参数为初值,通过迭代求解,对两个摄像机的相对位姿进行标定；3)对第2)步建立的立体标定模型进行数值化求解,完成两个摄像机标定过程。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         卫维恕;              罗笑南;              李峥;                   莫满春       </td>   <td>中山大学</td>   <td>一种基于混合插值参数化的人体模型设计方法</td>   <td>广东省</td>   <td>CN100595795C</td>   <td>2010-03-24</td>   <td>本发明公开了一种基于混合插值参数化的人体模型设计方法,主要是以特征层上的点作为控制点,非特征层上的点作为插值点,通过计算特征层的缩放因子,再计算非特征层的缩放因子,从而求得垂直方向插值点的高度h以及水平方向的变化率s,最后得出变化后的坐标。本发明数学原理简要明晰,参数易于控制,结合垂直方向及横向而采用混合插值参数化设计,利用样条拼接原理使得模型作全局参数化后保持C1连续性,而且具备整体缩放与局部细微调整效果,从而解决了模型参数化后的光滑问题。由于直接对特征层进行参数化操作,使得参数化后的人体模型能够直接应用于虚拟服装模拟。</td>   <td>1、一种基于混合插值参数化的人体模型设计方法,其特征在于包括以下步骤：(1)测量人体的特征尺寸,分围度与长度两类围度位于水平方向,其测量通过计算某一高度水平轮廓外凸包周长求得；长度位于垂直方向,其测量通过计算点到点的距离求得；(2)提取人体模型特征层特征层为包含特征点的水平层,由特征点所在高度的水平截面与人体模型相交所得；(3)根据人体模版本身的特征尺寸以及对应输入的人体参数尺寸,计算出各相应特征层的缩放因子S；(4)以特征层上的点作为控制点,非特征层上的点作为插值点,计算人体模型非特征层的缩放因子s；(5)根据非特征层的缩放因子,计算插值点新的坐标值,从而实现人体模型的设计。</td>   <td>G06T17/40</td>  </tr>        <tr>   <td>中国专利</td>   <td>         侯文邦;              曹颖;                   罗笑南       </td>   <td>中山大学</td>   <td>一种面向教学的服装热舒适度展示系统</td>   <td>广东省</td>   <td>CN100568246C</td>   <td>2009-12-09</td>   <td>本发明公开了一种面向教学的服装热舒适度展示系统,属于计算机仿真研究领域中的功能服装CAD技术领域。它包括一个可自定义的数据库模块、一个虚拟环境设计模块和一个系统总体架构模块,首先虚拟环境设计模块使用三维真实几何模型来构造虚拟场景,同时采用二维动画技术作为补充；然后将仿真场景及仿真结果数据保存在数据库中,用户可配置主要的仿真场景数据；最后据此确定相应的实际仿真结果数据,进行实时的服装热功能展示。基于本发明提出了一个半实时的仿真系统架构,用于服装热功能设计的教学展示,通过对仿真参数的优化抽取,用户可以用一种直观的方式进行参数调校,从而实现了对仿真过程的模拟。</td>   <td>1、一种面向教学的服装热舒适度展示系统,它包括一个可自定义的数据库模块、一个虚拟环境设计模块和一个系统总体架构模块,数据库模块用于保存系统的各种数据；虚拟环境设计模块用于设计虚拟环境；系统总体架构模块实现系统业务逻辑功能,其特征在于,所述数据库模块保存的数据包括：1)所有有关人体、环境和服装材料的参数和变量,2)根据指定的人体、服装和环境一起组成的仿真场景,3)由一个或多个仿真场景形成的仿真算例,4)系统对人体-服装热湿传递过程进行仿真计算的人体和服装的动态热状态；所述虚拟环境设计模块使用三维真实几何模型来构造虚拟场景,同时采用二维动画技术作为补充,主要有以下几个部分：1)选择人体和服装模型,模拟着装人体,2)用几何模型来表示人体和服装的重要参数：体重、表面积、人体皮肤服装覆盖率以及服装类型,3)对环境条件的可视化方面,构造一个虚拟气候室,包括用墙壁颜色表示空气温度,光照表示辐射温度,一个虚拟的温度计反映相对湿度,以及一个波动的含窗帘纹理曲面表示风速大小,4)采用二维动画和横断面显示可视化方法反映着装人体的热状态,5)对热舒适度仿真的时域数据,采用自适应的时域数据探索功能：首先利用windows系统里面时钟控件的时钟事件,计算实时时间,实现人体-服装间的动态热湿传递过程的实时模拟,然后采用自适应分析算法,对待分析的状态参数,预先设置一个激活值,将每个时间点的数据与其比较,最后仅显示那些大于激活值的数据,来实现对模拟速度的灵活控制；所述的系统总体架构模块的系统业务逻辑功能包括以下步骤：1)对于给定的人体和服装,设置仿真场景的主要参数,从数据库中得到计算结果,2)查表估算服装的热阻值,计算人体热舒适度,3)对仿真计算结果,直观得到模拟人体的热舒适度状态,通过分析不同场景下的热舒适度性能表现,实现对服装热功能仿真模型相关知识的学习。</td>   <td>G06F17/50;G06T17/00;G06T13/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;                   黄继武       </td>   <td>中山大学</td>   <td>一种可抗打印扫描和几何变换的多比特数字水印方法</td>   <td>广东省</td>   <td>CN100559396C</td>   <td>2009-11-11</td>   <td>本发明公开一种可抗打印扫描和几何变换的多比特数字水印方法。本发明在图像的离散傅立叶幅度系数中嵌入水印,每个水印比特嵌入哪些傅立叶幅度系数中根据傅立叶幅度系数的离散对数极坐标确定,当图像遭受缩放旋转等几何变换或者打印扫描时,会使水印检测提取失步；由于图像的缩放和旋转分别对应于傅立叶对数极坐标域的径向和角度方向上的平移,检测提取水印时,根据原始模板与嵌入的模板间相关来重同步信息水印,再提取有意义水印信息比特串,由于在水印嵌入和检测过程中不需要对图像或者其傅立叶幅度系数进行图像内插运算,因而不会引入插值失真并节省了时间,另外攻击者无法去除嵌入的模板,本发明可应用于数字图像、视频的版权保护,文件和证件防伪,以及视频广播监控等。</td>   <td>1、一种可抗打印扫描和几何变换的多比特数字水印方法,本方法包括水印嵌入和水印提取两大过程,其特征在于,所述水印嵌入过程的具体步骤为：a.根据所需嵌入的多比特水印,计算得到待嵌入的水印矩阵；水印包括多比特的有意义信息序列和模板序列；b.对原始图像做二维离散傅立叶变换,并平移直流成分到幅度谱中心,然后将步骤a中的水印矩阵嵌入所得的傅立叶系数幅度谱内；c.对嵌入水印后的傅立叶系数进行逆傅立叶变换,得到含水印图像,水印嵌入过程结束；所述水印提取是水印嵌入的逆过程,具体步骤如下：d.对待测图像进行d′×d′的二维离散傅立叶变换,并平移直流成分到幅度谱中心；e.对具有相同离散对数极坐标的傅立叶系数取平均值,得到一个二维的傅立叶系数幅度矩阵；f.将原始模板与幅度矩阵根据相关定理进行幅度相关或者相位相关快速匹配计算,并根据最大相关值确定嵌入水印在幅度矩阵中的位置,从而得到与嵌入水印同步的幅度矩阵；g.用原始伪随机调制序列对步骤f中得到的幅度矩阵进行解扩频调制,得到有意义的多比特水印信息。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              朱凤茹;              赖勇铨;                   吴娴       </td>   <td>中山大学</td>   <td>一种用于煤矿的矿工出入自动监测的方法</td>   <td>广东省</td>   <td>CN100555331C</td>   <td>2009-10-28</td>   <td>本发明提供一种用于煤矿的矿工出入自动监测的方法,包括下述步骤：(1)原始视频输入：利用安装在矿井出入口、位置固定的摄像头获取连续的视频图像序列；(2)运动物体检测：当矿工出现在视频界限内时,对其进行检测处理,作相应的记录并将其列入备追踪序列；(3)追踪统计：对于备追踪序列中的矿工人头,逐个进行追踪,并对相应的进/出人数总数进行统计,进而得到进/出矿井的矿工人数。本发明能进行实时直观的监视和记录矿井进出矿工的人数,进而对井下作业矿工总人数进行控制,及时发现事故隐患,同时能为事故发生后开展及时的救援工作提供准确资料,实时性和准确性都比较好。本发明在安全生产中可发挥明显的作用,具有显著的社会效益。</td>   <td>1、一种用于煤矿的矿工出入自动监测的方法,其特征在于：(1)原始视频输入：利用安装在矿井出入口上方、位置固定的摄像头获取连续的视频图像序列；(2)运动物体检测：当矿工出现在视频图像界面内时,对其进行检测处理,然后作相应的记录并将其列入备追踪序列；在进行运动物体检测之前对视频图像进行预处理,包括背景差处理及形态学处理过程；(2.1)所述背景差处理采用的背景差分公式是D-(ij)＝I-(ij)-B-(ij)                  其中D-(ij)代表背景差分后坐标(i,j)处的像素值,I-(ij),B-(ij)分别代表原始图像和背景图像(i,j)处的像素值；(2.2)所述形态学处理过程包括二值化步骤及形态学操作步骤；所述二值化步骤是将背景差分后的视频图像转化成二值图；所述形态学操作步骤是利用基本的开、闭运算对二值图做进一步的处理；(3)追踪统计：对于备追踪序列中的矿工人头,逐个进行追踪,并对相应的进/出人数总数进行统计,进而得到进/出矿井的矿工人数；本步骤采用Kalman追踪方法追踪备追踪序列中的矿工人头,当矿工人头满足设定的条件时做加或者减的操作；在视频图像界面设定四条线：在视频图像界面的上、下边界线之间依次设定进入结束线、出来开始线、进入开始线、出来结束线；进入开始线与视频图像界面的下边界线之间为检测区域,进入开始线与进入结束线之间为追踪区域；所述追踪过程具体如下：(3.1)人员进入时：首先,在检测区域中人员一旦被检测出来,则被列入备追踪序列中,当过了进入开始线后开始追踪,当在下一帧中追踪到该人员的视频图像时活跃值加2,追踪不到时减1,当活跃值超过一定的阈值并且当该人员过进入结束线,最初检测到的初始位置位于进入开始线与视频图像界面的下边界线之间,最初检测到的速度方向为朝向进入结束线的方向时,就把进入的人数加1,否则不加；(3.2)人员出来时：该过程和人员进入时的过程类似,当在进入结束线附近检测有人员的速度方向为朝向进入开始线的方向时,就把它记为出来人员的备追踪序列中,并记下检测到的初始位置,开始追踪过程,同样若在下一帧中追踪到时活跃值加2,否则减1,当活跃值达到一定的阈值,并且过出来结束线,最初检测到的初始位置位于出来开始线与视频图像界面的上边界线之间,最初检测到的速度方向为朝向出来结束线的方向时,就对出来的人员人数加1,否则不加。</td>   <td>G06T7/20;H04N7/18;G07C9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘红梅;              何妙谊;                   黄继武       </td>   <td>中山大学</td>   <td>一种基于Zernike矩的鲁棒哈希图像认证方法</td>   <td>广东省</td>   <td>CN100507936C</td>   <td>2009-07-01</td>   <td>本发明属于图像认证技术领域,具体公开一种基于Zernike矩的鲁棒哈希图像认证方法。在哈希算法中,图像特征的选取是其中关键的一步。本发明方法以图像的Zernike矩作为图像的特征,通过随机化得到图像的哈希值,通过比较图像哈希值之间的汉明距对图像进行认证。本方法利用Zernike矩的不变性实现哈希算法的稳健性。本发明方法对图像的旋转,JPEG压缩,加噪和滤波操作具有一定的稳健性,同时能够区分剪贴等恶意篡改。</td>   <td>1、一种基于Zernike矩的鲁棒哈希图像认证方法,该方法以图像的Zernike矩作为图像的特征,通过随机化得到图像的哈希值,通过比较图像哈希值之间的汉明距对图像进行认证,其特征是本方法包括以下步骤：a.分别提取两幅图像的Zernike矩；b.对Zernike矩值进行加密,生成图像的哈希值,其采用的计算图像的哈希值公式为：                                  h      i        =          1      N              &amp;Sigma;              n        ,        m              &amp;beta;          |              Z        i                    (        n        ,        m        )            |        ,    i    =    1,2    ,           ]]>                  其中β是一个符合正态分布的随机数,n和m分别表示Zernike矩的阶数和迭代数,N是Zernike矩阵中所有不为0的矩值的个数；c.对提取出的哈希值进行量化和格雷编码,得到二值化哈希序列；d.比较两幅图像的哈希序列的汉明距,判断图像是否近似,其中汉明矩采用如下公式计算：                            d          (              h        1            ,              h        2            )        =          1      L              &amp;Sigma;              k        =        1            L              |              h        1                    (        k        )            -              h        2                    (        k        )            |        ,           ]]>                  其中L是哈希(hash)值的字节数。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;                   李庆敏       </td>   <td>中山大学</td>   <td>一种基于自动匹配的文件管理系统</td>   <td>广东省</td>   <td>CN100468407C</td>   <td>2009-03-11</td>   <td>本发明公开了一种基于自动匹配的文件管理系统,本系统主要由资源监测装置、网络检测装置、控制中心和文件管理装置组成。资源监测装置,负责检测本地资源使用状况；网络检测装置,主要用于侦听网络是否连通,网络的带宽大小,网络的稳定状况等等；控制中心,是系统的核心控制部件,用于根据资源监测装置和网络检测装置获得的系统信息来决定是否应该暂停文件管理装置的运行或者改变其他方式等等；文件管理装置,用于根据资源使用情况和网络使用情况来进行文件匹配管理。本系统针对一些用户对本机上某些难以取舍的文件,可以通过网上服务器进行匹配寻找可替换文件,如果文件有所匹配,则将文件转换成一个链接到服务器上。</td>   <td>1.一种基于自动匹配的文件管理系统,其特征是：本系统由资源监测装置、网络检测装置、控制中心和文件管理装置组成；资源监测装置,负责检测本地资源使用状况,包括检测CPU使用率以及内存使用大小的功能,同时将情况收集之后提供给控制中心以及文件管理装置；网络检测装置,用于侦听网络是否连通、网络的带宽大小和网络的稳定状况,并将情况反应给控制中心以及文件管理装置；控制中心,是系统的核心控制部件,用于根据资源监测装置和网络检测装置获得的系统信息来决定是否应该暂停文件管理装置的运行；文件管理装置,包括文件检索模块、断点记忆模块、匹配设置模块、文件分类模块和文件匹配模块,用于根据资源使用情况和网络使用情况来进行文件匹配管理。</td>   <td>G06F17/30;H04L12/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马建平;                   罗笑南       </td>   <td>中山大学</td>   <td>一种基于逆Loop细分的渐进网格生成方法</td>   <td>广东省</td>   <td>CN100468464C</td>   <td>2009-03-11</td>   <td>本发明公开了一种基于逆Loop细分的渐进网格生成方法,它属于几何体造型技术领域,特别是涉及一种基于三角形网格的曲面简化方法。对于任意具有细分连接性的三角网格M～(j)＝(P～(j),K～(j)),本方法的步骤包括：1)网格分裂：将已有的三角网格M～(j)的顶点分裂成奇点集ODD～(j)和偶点集EVEN～(j)；2)奇点预测：对每个奇点,采用Loop细分预测其位置ODD′,将现有的各个奇点ODD～(j)与预测值对应相减得到一组误差值e～(j)；3)网格更新：删除掉奇点集ODD～(j)后,剩余的偶点集EVEN～(j)形成下一层的顶点P～(j-1),更新这些顶点的连接信息组成新的三角形连接信息K～(j-1),生成了一个简化后的新网格M～(j-1)；4)循环上述步骤,直到最终分裂的网格为基网格。利用本方法效率高,网格生成速度快,更易于在实际应用中使用。</td>   <td>1、一种基于逆Loop细分的渐进网格生成方法,对于任意具有细分连接性的三角网格M～(j)＝(P～(j),K～(j)),它的主要步骤包括：1)网格分裂：将已有的三角网格的顶点分裂成奇点集ODD～(j)和偶点集EVEN～(j)：2)奇点预测：为了三维曲面造型的网格还原和重建,在删除奇点之前,对每个奇点,采用Loop细分预测其位置ODD′,将现有的各个奇点ODD～(j)与预测值对应相减得到一组误差值e～(j),j表示网格层数；3)网格更新：删除掉奇点集ODD～(j)后,剩余的偶点集EVEN～(j)形成下一层的顶点P～(j-1),更新这些顶点的连接信息组成新的三角形连接信息K～(j-1),生成了一个简化后的新网格M～(j-1)；4)循环上述步骤,直到最终分裂的网格为基网格及一系列误差值。</td>   <td>G06T17/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         李少源;                   罗笑南       </td>   <td>中山大学</td>   <td>一种可实现在电脑上模拟手机基本功能的装置</td>   <td>广东省</td>   <td>CN100468339C</td>   <td>2009-03-11</td>   <td>本发明公开了一种可实现在电脑上模拟手机基本功能的装置,它涉及一种家用电器的组合优化技术。该装置包括一个嵌入手机内的手机模块和一个嵌入电脑内的电脑模块。手机模块包括身份子模块、网络子模块和信息复制子模块,它首先定义本机一个唯一的ID,手机接到搜寻指令和输入的ID后,进行网络搜寻操作,然后将手机SIM卡中的相关信息复制出来,待搜寻网络成功后,将它发送到电脑的端口中；电脑模块包括身份子模块、网络子模块、信息粘贴模块和手机服务界面子模块,它首先要定义一个唯一的ID,待手机和电脑的网络连接上后,电脑的端口接受来自手机的SIM卡的相关信息,并在电脑中形成一个手机服务界面,即用户在电脑上模拟手机操作的平台。</td>   <td>1、一种可实现在电脑上模拟手机基本功能的装置,其特征在于,手机内嵌入一个手机模块；电脑内嵌入一个电脑模块：手机模块首先定义本手机一个唯一的ID,便于身份的验证和搜寻网络,当手机和电脑的端口都在运行时,用户输入将要搜寻的电脑ID,手机接到搜寻指令和输入的ID后,进行网络搜寻操作,手机模块还能将手机SIM卡中的用户信息、通讯录、短信息和通话记录复制出来,待搜寻网络成功后,手机将连上对应ID的电脑,然后通过手机的端口以有线或无线的方式将相关信息发送到电脑的端口中；电脑模块首先要定义本电脑一个唯一的ID,便于身份的验证和搜寻网络,待手机和电脑的网络连接上后,电脑的端口接收来自手机的SIM卡的相关信息,并在电脑中形成一个手机服务界面,即用户在电脑上模拟手机操作的平台。</td>   <td>G06F9/455;H04W88/02;H04L12/28</td>  </tr>        <tr>   <td>中国专利</td>   <td>         骆伟祺;                   黄继武       </td>   <td>中山大学</td>   <td>一种JPEG图像合成区域的检测方法</td>   <td>广东省</td>   <td>CN100465996C</td>   <td>2009-03-04</td>   <td>一种JPEG图像合成区域的检测方法,是根据JPEG图像固有的块效应特点而提出的统计判别方法,属于多媒体信息安全领域。本发明方法针对JPEG图像的合成,分析JPEG图像块效应在合成前后的变化,构造出一个7×7大小具有“对称”性质的矩阵M以表征块效应特点,并从中提取出14个能度量此对称程度的特征,利用SVM技术进行分类。本发明方法包括以下步骤：1)选取怀疑被篡改的图像块；2)特征的提取与分类器的构造；3)利用分类器对待测图像块做检测判断。本发明能较有效地对选定的怀疑被篡改的区域进行识别,为JPEG格式合成虚假图像的检测提供了一个有效的方法。</td>   <td>1、一种JPEG图像合成区域的检测方法,其特征在于包括以下步骤：1)选取怀疑被篡改的图像块：假设给定的JPEG图像为f,其质量因子QF-(2),设选取怀疑被篡改的图像块D为l×w大小的长方体且其左上角在f中的坐标为(x,y),要求x＝0(mod8),y＝0(mod8)；2)特征的提取与分类器的构造:①自然图像集的构造:首先选取无压缩的图像n幅,大小为l×w,对选取的n幅图像以质量因子QF-(2)作JPEG压缩,得到自然图像集；②篡改图像集的构造：首先对选取的n幅无压缩图像,以质量因子QF-(1)作JPEG压缩,QF-(1)随机选取的范围在[a,b],然后模拟图像合成中篡改块的变化：随机剪切i行j列,其中0≤i≤7,0≤j≤7,i,j不同时为0或4,最后以QF-(2)的质量因子对剪切后图像再一次JPEG压缩,得到篡改图像集；③对自然图像集与篡改图像集中的每幅图像,按以下方法提取其特征：a)首先将图像无重叠地分解成8×8大小的小块；b)对于每一图像分块,统计：Z′-((i,j))＝|A+D-B-C|,Z＂-((i,j))＝|E+H-F-G|得到两个直方图Z′-((i,j))与Z＂-((i,j)),其中(i,j)表示A在8×8分块中的坐标,然后比较两个直方图的绝对差,并求其均值得到M-((i,j))；c)令1≤i≤8,1≤j≤8重复步骤b)中提取图像特征的方法,并归一化得到一个均值矩阵M；d)提取均值矩阵M的对称特性,沿水平、垂直、中心对称等方向提取M的14个特征；④利用LibSVM分类器对得到的特征进行训练,得到一个能区分图像块是否经过了剪切合成处理的分类器；3)利用分类器对待测图像块做检测判断:首先按步骤2)中的③提取待测图像块的14个特征,然后利用步骤2)中的④得到的分类器进行判别。</td>   <td>G06T7/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         王振华;                   罗笑南       </td>   <td>中山大学</td>   <td>一种数字家庭音乐控制器</td>   <td>广东省</td>   <td>CN100458783C</td>   <td>2009-02-04</td>   <td>本发明公开了一种数字家庭音乐控制器,该控制器利用网络资源,智能化搜索及下载网络音乐资源、根据用户喜爱播放音乐以及推荐用户尝试其他音乐风格的功能,属于数字家庭网络和控制领域。数字家庭音乐控制器由音乐搜索模块、音乐下载模块、关联推导模块、用户喜好设定模块、心情控制模块和音乐管理模块六个处理模块组成。本发明体现了以用户为中心的设计原则,智能化利用网络资源,节约用户时间,为用户提供舒适喜爱的音乐。</td>   <td>1、一种数字家庭音乐控制器,包括输入设备、信号接收设备、硬盘、中央处理器、网卡、内存、主板,其特征在于所述音乐控制器还包括音乐搜索模块、音乐下载模块、关联推导模块、用户喜好设定模块、心情控制模块、音乐管理模块：音乐搜索模块提供音乐搜索功能,自动在音乐服务器上搜索音乐,由CPU进行调度,从用户喜好设定模块与关联推导模块获取搜索信息,通过网卡连接到数字家庭网络,与音乐服务器通信；音乐下载模块提供音乐下载功能,自动在音乐服务器上下载音乐,由CPU控制,从音乐搜索模块将待下载文件链接地址保存到下载模块中通过一个下载控制程序将音乐文件下载保存到磁盘中；关联推导模块其功能是推荐用户尝试其他音乐风格,由CPU调至内存中运行,将推导结果保存后用于搜索音乐；用户喜好设定模块用于设定用户喜爱的音乐风格及喜爱的歌手信息,由CPU启动喜好设定程序,并在触摸屏中显示该程序界面,用户通过触摸屏控制键盘输入喜好信息；心情控制模块是根据天气情况会影响人情绪的原理,从网络中实时获取天气情况,用于播放适合用户心情的音乐,该模块设置了一个控制芯片,通过网络从音乐服务器中实时获取天气信息,当用户播放音乐时,将这些信息传递给CPU进行处理；音乐管理模块用于管理存储在用户磁盘中的音乐,提供删除、查找、添加音乐文件的功能,以及维护音乐播放列表,它由磁盘文件管理程序与音乐播放控制程序两部分组成；其特征在于所述音乐控制器的控制流程为：1)判断用户是否初次使用该音乐控制器,是,则执行2),否则执行3)；2)通过音乐管理模块初始化该音乐控制器,用户喜好设定模块设定用户喜爱的音乐风格及歌手信息；3)判断是否超过设定推导时间阀值,是,则执行4),否则执行5)；4)关联推导模块利用用户喜好设定模块中用户设定的信息,根据网络服务器中存在的相关信息进行关联推导,保存兴趣度最高的推导结果；5)音乐搜索模块根据用户设定的这些喜好信息在网上进行搜索,并将搜索结果提供给音乐下载模块；6)音乐下载模块筛选搜索到的音乐并下载到用户磁盘中；7)心情控制模块获取网上当前时间的天气情况,将这些信息传递给音乐管理模块；8)音乐管理模块根据这些信息以及用户喜好设定模块提供的信息,组织磁盘中的音乐,将它们添加到音乐播放列表中进行播放。</td>   <td>G06F17/30;G06Q10/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;              胡海峰;              张成言;              邓娜;                   袁红梅       </td>   <td>中山大学</td>   <td>一种基于块内相关性的二维主元分析人脸识别方法</td>   <td>广东省</td>   <td>CN100449567C</td>   <td>2009-01-07</td>   <td>本发明属模式识别技术领域,具体涉及一种基于块内相关性的二维主元分析(简称2DPCA)人脸识别方法。本方法根据人脸图像所具有的局域特征,将人脸图像划分成非重叠小块,然后将每一个小块中的元素按行相接产生相应的行向量,再把行向量按顺序排列成新的二维图像矩阵,最后将分块、重排之后的二维图像矩阵当作输入图像,进行2DPCA人脸识别。本方法的优点在于：充分利用了局部区域里行与列像素之间的相关性信息,能够较好地保留人脸的局域特征信息,可以达到较高的人脸识别率,而且计算复杂度较低。</td>   <td>1、一种基于块内相关性的人脸识别方法,其特征在于一个将人脸图像分块重排的算法、一个基于二维主元分析的最优投影方向计算方法和一个通过计算欧式距离比较相似度的识别算法,具体步骤分建库和识别两个阶段：(1)建库阶段①对样本图像进行标准化,包括光线归一化和尺寸归一化；②把经过步骤①得到的标准化样本图像分割成若干互不重叠的块,然后把每块的像素重排成一行,构成一幅新的二维图像矩阵,图像分块重排的目的是把原图像的块内相关性转化为新的二维图像矩阵的行内相关性；③将步骤②得到的新的二维图像矩阵作为输入图像,选择一定的主元数目,使用二维主元分析方法计算出最优投影向量组X-(1),X-(2),…,X-(d),根据二维主元分析方法,这些最优投影向量取决于新的二维图像矩阵的行内相关性,也即原图像的块内相关性,块内相关性也就是局部相关性,局部相关性是人脸识别的重要依据；④将新构造出的二维图像矩阵向最优投影方向上投影,抽取出反映人脸特征的数据,即特征矩阵,并将其全部保存在数据库中,待识别阶段使用；(2)识别阶段①对测试图像按照建库阶段步骤①描述的方法进行标准化；②对经过识别阶段步骤①得到的标准化测试图像按照建库阶段步骤②描述的方法进行分块重排,得到新的二维图像矩阵；③将识别阶段步骤②得到的新的二维图像矩阵按照建库阶段步骤④描述的方法向最优投影方向上投影,获得相应的特征矩阵；④计算识别阶段步骤③得到的特征矩阵与建库阶段步骤④得到的数据库中各特征矩阵之间的欧式距离,将距离最近的特征矩阵对应的人脸图像判别为匹配图像,匹配图像对应的分类即为识别结果。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;                   李英       </td>   <td>中山大学</td>   <td>基于活动形状模型的多表情整脸轮廓检测方法</td>   <td>广东省</td>   <td>CN100444191C</td>   <td>2008-12-17</td>   <td>本发明提供一种基于活动形状模型的多表情整脸轮廓检测方法,包括下述步骤(1)获取训练图像；(2)构建局部模型及全局模型；(3)获取目标人脸图像；(4)局部模型与全局模型相结合对人脸图像进行搜索；(5)用选择的全局模型初始化整脸,然后运算定位,得到整脸轮廓。本发明将局部ASM和全局ASM结合提出了多模型ASM方法,事先确定人脸的表情状态,选用更精细的单表情状态模型下进行检测,能提高ASM在形状有较大非线性变化的、多表情的人脸特征点的检测准确率,更好地为后续的人脸目标的识别以及图像的理解与分析等打下基础。</td>   <td>1、一种基于活动形状模型的多表情整脸轮廓检测方法,其特征在于包括下述步骤——(1)获取训练图像；(2)构建局部模型及全局模型；(3)获取目标人脸图像；(4)局部模型与全局模型相结合对人脸图像进行搜索；(5)用选择的全局模型初始化整脸,然后运算定位,得到整脸轮廓；所述局部模型分为眼睛模型和嘴巴模型；所述全局模型分为总体整脸形状模型和细分状态的整脸模型；所述总体整脸形状模型分为开眼的总体整脸形状模型和闭眼的总体整脸形状模型；所述细分状态的整脸模型包含开眼且张大的嘴的整脸模型、开眼且微笑的嘴的整脸模型、开眼且O型的嘴的整脸模型、开眼且紧闭的嘴的整脸模型、闭眼且张大的嘴的整脸模型、闭眼且微笑的嘴的整脸模型、闭眼且O型的嘴的整脸模型、闭眼且紧闭的嘴的整脸模型。</td>   <td>G06K9/00;G06K9/46</td>  </tr>        <tr>   <td>中国专利</td>   <td>         赖剑煌;              谢晓华;                   郑伟诗       </td>   <td>中山大学</td>   <td>一种基于二次多项式光照模型的人脸光照对齐方法</td>   <td>广东省</td>   <td>CN100444193C</td>   <td>2008-12-17</td>   <td>本发明公开了一种基于二次多项式光照模型的人脸光照对齐方法,包括以下步骤：(1)建立光照模型；(2)对所有训练图像以及目标图像均进行形状规一化；(3)训练系数矩阵A-(i)和B-(i),其中i＝2,…,64；(4)对目标人脸图像进行分解；(5)对目标人脸图像进行光照类型估计；(6)对目标人脸图像的光照分量进行对齐矫正；(7)目标人脸图像重构。本发明采用二次多项式描述了光照变化引起的图像变化,从而对基于LTV模型的光照处理算法中丢弃的人脸图像光照分量进行了对齐矫正再次利用,在获得更高的人脸识别率同时达到人脸视觉效果的改善。</td>   <td>1、一种基于二次多项式光照模型的人脸光照对齐方法,其特征在于包括以下步骤：(1)建立光照模型,具体是                                  L      object              (      x      ,      y      )        =                                                      A              i                                      (              x              ,              y              )                                      L                              s                tan                dard                            2                                      (              x              ,              y              )                        +                          B              i                                      (              x              ,              y              )                        ,            i            =            2            ,            .            .            .            ,            64                                                              L                              s                tan                dard                                                    (              x              ,              y              )                        ,            i            =            1                                ,           ]]>          其中i＝1时,L-(standrad)为正面标准光照条件下的光照分量；(2)对所有训练图像以及目标图像均进行形状规一化处理；(3)训练系数矩阵A-(i)和B-(i),其中i＝2,…,64；(4)对目标人脸图像进行分解,具体是对每张待进行光照对齐的目标人脸图像I-(object),根据光照-反射模型I-(object)(x,y)＝L-(object)(x,y)R-(object)(x,y),用对数域全变分模型对I-(object)进行分解,得到光照分量L-(object)和反射分量R-(object)；(5)对目标人脸图像进行光照类型估计；(6)对目标人脸图像的光照分量进行对齐矫正,具体是根据I-(object)的光照类型相应选取训练得到的系数矩阵A-(i)和B-(i),用            L      aligned              (      x      ,      y      )        =                                                                      [                                                                            L                      object                                                              (                      x                      ,                      y                      )                                        -                                          B                      i                                                              (                      x                      ,                      y                      )                                                                                                  A                      i                                                              (                      x                      ,                      y                      )                                                                      ]                                            1                2                                                                                        L              object                        ,            i            =            1                                ,           ]]>i＝2,…,64对L-(object)进行对齐矫正,并得到矫正结果L-(aligned)；(7)目标人脸图像重构,具体是用分解得到的反射分量R-(object)和光照对齐后得到的光照分量L-(aligned)重构最终图像：I-(aligned)(x,y)＝L-(aligned)(x,y)R-(object)(x,y)。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         骆伟祺;                   黄继武       </td>   <td>中山大学</td>   <td>一种鲁棒的图像区域复制篡改检测方法</td>   <td>广东省</td>   <td>CN100440255C</td>   <td>2008-12-03</td>   <td>本发明提出一种基于图像块相似性比较的鲁棒区域复制篡改检测方法,属于多媒体信息安全领域。本发明方法包括以下步骤：1)抽取图像块特征；2)寻找相似块对；3)去除错误的匹配块对；4)判定篡改图像和定位篡改区域。本发明方法首先将待测图像分解成有重叠区域的小块,从中提取出每块的特征,然后选择恰当的阈值度量各分块的相似性得到相似块对,最后去除错误的匹配块对以定位出篡改区域。可以利用本专利有效地对此篡改后的图像作检测,因此对图像数据真伪性的判断等有着重要的实际意义。</td>   <td>1、一种鲁棒的图像区域复制篡改检测方法,其特征在于包括了以下四个具体的步骤：1)抽取图像块特征：首先把待测图像f设其大小为M*N,分解为b×b大小有重叠区域的块B-(i),i＝1...(M-b+1)(N-b+1),对于每一个图像分块按如下的方式提取其七个特征：c-(1),c-(2),c-(3)分别记录图像块红、绿、蓝三个颜色通道的平均值,c-(4),c-(5),c-(6),c-(7)分别记录图像分块Y通道按上下、左右、斜向下45度与斜向上45度四种等分模式分解后,一等分区域的像素值总和占整个Y分块灰度值总和的比值,并用特征向量V(i)＝(c-(1),c-(2),c-(3),c-(4),c-(5),c-(6),c-(7))表示图像块B-(i)的信息,将所有的V(i)保存于数组A中；2)寻找相似块对：将存于数组A中所有特征向量先按字典排序,然后两两比较各图像块的特征向量,若图像块B-(i),B-(j)中对应的7个特征的绝对差小于：[2.5,1.5,3.0,0.006,0.005,0.005,0.005],且对应块对间的距离大于L,其中L表示在通常的图像区域复制篡改时,被复制区域位置与被粘贴位置对应块间距离的最小值,L取50,则认为B-(i),B-(j)是相似块对,并按如下方法记录相似块对间的“转移向量”d：d＝(d-(x),d-(y)),d-(x)＝x-(1)-x-(2),d-(y)＝y-(1)-y-(2),其中(x-(1),y-(1)),(x-(2),y-(2))是两个图像分块左上角位置的坐标；3)去除错误的匹配块对：统计步骤2)中的“转移向量”,令出现频率最多的一个作为“主转移向量”,把“转移向量”不等于“主转移向量”的所有相似块对认为是错误的块对给去除掉,在剩下的块对中寻找出最大的两个连通分量,并把连通分量中的空洞区域填补上；4)判定篡改图像和定位篡改区域：假设在步骤3)得到了两个区域R-(1),R-(2),若满足：min(|R-(1)|,|R-(2)|)＞αM*N*0.85％    ‖R-(1)|-|R-(2)‖/max(|R-(1)|,|R-(2)|)＜Tr则认为图像f经过了区域复制篡改,R-(1),R-(2)是检测到的篡改区域,其中参数α＝61％,Tr＝6％。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         谢宁;              莫武中;                   周渊平       </td>   <td>中山大学</td>   <td>基于FPGA和USB储存装置的无线通信仿真装置</td>   <td>广东省</td>   <td>CN100435158C</td>   <td>2008-11-19</td>   <td>本发明公开了一种基于FPGA和USB储存装置的无线通信仿真装置,该装置的信号产生装置包括一个USB存储装置、一个USB读写器、电平转换电路、SDRAM储存电路和一个以FPGA芯片作为主体的功能模块。本发明用简单的设备实现了复杂的仿真研究,大大加快了科研进程,有效解决了长期以来困扰科研人员的经费问题。其操作简便、用途广泛,不仅具有较高的处理速度,而且工作状态稳定可靠。</td>   <td>1.一种基于FPGA和USB储存装置的无线通信仿真装置,包括一个信号产生装置和一个信号接收处理装置,信号接收处理装置包括一台计算机、一块带数字信号处理芯片DSP的电路板和一个功能模块,计算机通过USB接口与电路板的JTAG接口串联连接；其特征在于：所述的信号产生装置包括一个USB存储装置、一个USB读写器、电平转换电路、SDRAM储存电路和一个功能模块；信号产生装置和信号接受处理装置的功能模块均设置有一个RJ45接口、一块含有低压差分信号技术LVDS接口的芯片和一块现场可编程门阵列FPGA芯片,5V外接稳压电源接口,电源电路,FPGA配置电路,复位电路,晶振器电路和状态指示电路；在信号接收处理装置部分,FPGA芯片通过I/O接口与DSP芯片的EMIF接口电气连接,电源电路的输入端与5V外接稳压电源接口电气连接,电源电路的输出端与功能模块上所有芯片的电源接口电气连接,FPGA配置电路与FPGA芯片的配置接口电气连接,复位电路与FPGA芯片的I/O接口电气连接,晶振器电路与FPGA芯片的全局时钟接口串联连接,状态指示电路与FPGA芯片的I/O接口电气连接；所述的LVDS接口芯片的输入端与RJ45接口连接,其输出端与FPGA芯片的I/O接口电气连接；在信号产生装置部分,所述的USB读写器的输入端与USB存储装置电气连接,USB读写器的输出端与电平转换电路的输入端电气连接；电源电路的输入端、USB读写器的5V电源接口和电平转换电路的5V电源接口与所述的5V外接稳压电源接口电气连接；FPGA芯片分别通过其I/O接口与电平转换电路和SDRAM储存电路电气连接,电源电路输出端与功能模块上所有芯片的电源接口以及电平转换电路、SDRAM储存电路的电源接口电气连接,FPGA配置电路与FPGA芯片的配置接口电气连接,复位电路与FPGA芯片的I/O接口电气连接,晶振器电路与FPGA芯片的全局时钟接口串联连接,状态指示电路与FPGA芯片的I/O接口电气连接；所述的LVDS接口芯片的输入端与FPGA芯片的I/O接口电气连接,其输出端与RJ45接口连接；所述的信号产生装置和信号接收处理装置通过各自的RJ45接口相互串联连接。</td>   <td>G06F17/50;H04L12/26</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马识佳;                   罗笑南       </td>   <td>中山大学</td>   <td>一种基于改进的一次一密乱码本的软件保护方法</td>   <td>广东省</td>   <td>CN100428262C</td>   <td>2008-10-22</td>   <td>本发明公开一种基于改进的一次一密乱码本的软件保护方法。本方法包括加密和解密两个过程,摒弃了传统的一步解密的方式,在运行时通过即时解码器以函数为单位一步步解密软件,仅对一次运行中必须的部分解密,使得攻击者难以获得完整的解密后程序,难以篡改并绕过未解密部分中的软件保护功能,增强了抗攻击性,在运行效果上,由于解密分散进行,就解决了启动延时长的问题。用基于一次一密加密技术,与传统的对称密钥加密算法相比,进一步减少了运行时开销,使得该技术在目前处理器上可以流畅运行。该方法增强了基于加密的软件保护的实用性,增大了破解的难度。</td>   <td>1、一种基于改进的一次一密乱码本的软件保护方法,本方法包括加密和解密两个过程,其特征是：所述加密过程步骤如下：a.为所保护软件正在运行的函数在改进的一次一密乱码本中随机选取加密密钥,在全局数据结构“已加密函数表”中标记该函数已被加密处理,并记录加密密钥；b.在函数体之前为函数添加一个跳板；c.扫描当前处理函数的每一条指令,对于函数调用做特殊处理,为其增加传递隐式参数的指令；d.对函数体的指令逐条扫描结束后,使用步骤a中产生的密钥对函数体使用改进的一次一密乱码本加密；所述解密过程是：在软件运行时,当每个函数第1次被调用的时候进行解密操作,即时解码器负责解密每个函数,解密后的函数体仍在主存中原来的位置,然后把函数体前面的跳板打上补丁去掉,当第2次执行所述函数的时候直接执行解密后的函数体,无须再次解密。</td>   <td>G06F21/24;G06F21/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;              胡海峰;              程永;              张成言;                   邓娜       </td>   <td>中山大学</td>   <td>一种基于结构主元分析的人脸识别方法</td>   <td>广东省</td>   <td>CN100423020C</td>   <td>2008-10-01</td>   <td>本发明属模式识别技术领域。本发明由几何规整、图像分块、二维主元分析(2DPCA)、相似度加权系数调节等关键步骤组成。本发明以眼睛和嘴巴做为基准进行几何规整。经过几何规整,所有人脸图像的尺寸都是一样的,人脸各个部分在人脸图像中的位置是固定的,经过图像分块,每个图像块包含的人脸局部区域也就随之固定。本发明采用2DPCA方法计算每个图像块的主元和主元特征。二个图像块之间的相似度为它们主元特征之间的距离,二副人脸图像之间的相似度为它们相应的图像块之间相似度的加权和。通过调整每个图像块的主元数目和图像块相似度的加权系数可以凸现或抑制某些图像块在人脸识别中的作用,从而适应各种不完整的人脸图像的识别任务。</td>   <td>1. 一种基于结构主元分析的人脸识别方法,其特征在于包含以下的主要步骤：(1)几何规整：将所有人脸图像的尺寸规整为80×96,并使得左眼中心点位于(16,24)位置,右眼中心点位于(64,24)位置,嘴巴中心点位于(40,72)位置,眼睛和嘴巴在规整后人脸图像中的相对位置符合第二代居民身份证人脸图像的要求,经过几何规整的人脸图像,人脸各个部位在人脸图像中的位置是固定的；(2)图像分块：将几何规整后的人脸图像分割为30个互不重迭的图像块,每个图像块的尺寸为16×16,从左到右从上到下为图像块编号,则根据图像块的序号可以推知图像块究竟包含人脸的哪一块局部区域；(3)计算图像块的结构主元：采用二维主元分析的方法计算每个图像块的主元,也即图像块二维协方差矩阵的主要特征向量,由于每个图像块都与人脸的某个具体的局部区域相联系,因此,图像块的主元反映了人脸的结构信息,故称之为结构主元,每个图像块结构主元的数目根据该图像块在人脸识别中贡献的大小而定；(4)计算图像块的结构主元特征：对于已知身份的人脸图像和未知身份的人脸图像,经过几何规整和图像分块后,可以计算它们的图像块在结构主元上的特征,图像块的结构主元特征由图像块左乘各个结构主元得到；(5)调整图像块相似度的加权系数：二个图像块之间的相似度就是它们相应的结构主元特征之间的距离,二副人脸图像的相似度就是对应于相同序号的各个图像块相似度的加权和,调整每个图像块相似度的加权系数可以凸现或抑制某些图像块在人脸识别中的作用。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         毕宁;                   孙伟       </td>   <td>中山大学</td>   <td>一种带参变量的数据分解重构方法</td>   <td>广东省</td>   <td>CN100419790C</td>   <td>2008-09-17</td>   <td>本发明提供一种带参变量的数据分解重构方法,使数据蕴含有隐藏信息,包括隐藏信息的嵌入过程和隐藏信息的提取过程,所述隐藏信息的嵌入过程通过如下步骤实现：A.通过由正整数M和随机参数λ所构造的滤波器对数据进行M进制小波分解,得到数据子带；B.将隐藏信息嵌入到数据子带中；C.将嵌入隐藏信息后的各数据子带,用同样的参数λ和M进行M进制小波逆变换,得到重构数据；所述隐藏信息的提取过程通过如下步骤实现：E.通过与隐藏信息的嵌入过程一致的参数λ和M,进行相应的M进制小波分解,得到数据子带；F.从E所得到的数据子带中提取隐藏信息。本发明可以公开信息的隐藏算法,使提取的水印能被认可,同时又达到保密的目的；还有效的弥补了方块效应。</td>   <td>1. 一种带参变量的数据分解重构方法,使数据蕴含有隐藏信息,包括隐藏信息的嵌入过程和隐藏信息的提取过程,其特征为所述隐藏信息的嵌入过程通过如下步骤实现：A、通过由正整数M和随机参数λ所构造的滤波器对数据进行M进制小波分解,得到数据子带；B、将隐藏信息嵌入到数据子带中,数据子带选取中频子带,即去除最低频子带和最高频子带,隐藏信息的嵌入过程通过将中频子带分割成均等的数据块,所述隐藏信息也分解成与数据块数量相等的子信息,再对每一个数据块进行经验模态分解,最后将子信息嵌入在每个平均趋势量中；C、将嵌入隐藏信息后的各数据子带,用同样的参数λ和M进行M进制小波逆变换,得到重构数据；所述隐藏信息的提取过程通过如下步骤实现：E、通过与隐藏信息的嵌入过程一致的参数λ和M,进行相应的M进制小波分解,得到数据子带；F、从步骤E所得到的数据子带中提取隐藏信息,数据子带选取中频子带,即去除最低频子带和最高频子带。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马争鸣;              胡海峰;              李莹;                   张成言       </td>   <td>中山大学</td>   <td>一种基于块内相关性的二维线性鉴别分析人脸识别方法</td>   <td>广东省</td>   <td>CN100410963C</td>   <td>2008-08-13</td>   <td>本发明属模式识别技术领域,具体涉及一种基于块内相关性的二维线性鉴别分析(简称2DFDA)人脸识别方法。本方法根据人脸图像所具有的局域特征,将人脸图像划分成非重叠小块,然后将每一个小块中的元素按行相接产生相应的行向量,再把行向量按顺序排列成新的二维图像矩阵,最后将分块、重排之后的二维图像矩阵当作输入图像,进行2DFDA人脸识别。本方法的优点在于：充分利用了局部区域里行与列像素之间的相关性信息,能够较好地保留人脸的局域特征信息,可以达到较高的人脸识别率,而且计算复杂度较低。</td>   <td>1. 一种基于块内相关性的人脸识别方法,其特征在于一个将人脸图像分块重排的算法、一个基于二维线性鉴别分析(简称2DFDA)的最优投影方向计算方法和一个通过计算欧式距离比较相似度的识别算法。具体步骤分建库和识别两个阶段：(1)建库阶段①对样本图像进行标准化,包括光线归一化和尺寸归一化,使得诸如眼睛、鼻子、嘴巴等人脸特征在各个图像中的位置保持一致；②把经过步骤①得到的标准化样本图像分割成若干互不重叠的块,然后把每块的像素重排成一行,构成一幅新的图像,从而把样本图像的块内相关转化为新图像的行内相关；③将步骤②得到的新图像作为输入图像,选择一个预设的数目d,使用2DFDA方法计算出Fisher最优投影向量X-(1),X-(2),…,X-(d),根据2DFDA方法,这些最优投影向量取决于新图像的行内相关性,也即标准化样本图像的块内相关性,块内相关性也就是局部相关性,局部相关性是人脸识别的重要依据；④将步骤②得到的新图像向步骤③得到的Fisher最优投影向量投影,抽取出反映人脸特征的数据,即Fisher特征矩阵,并将其全部保存在数据库中,待识别阶段使用。(2)识别阶段①对测试图像按照建库阶段步骤①描述的方法进行标准化；②对经过步骤①得到的标准化测试图像按照建库阶段步骤②描述的方法进行分块重排,得到新的图像；③将步骤②得到的新图像按照建库阶段步骤④描述的方法向Fisher最优投影向量投影,获得相应的Fisher特征矩阵；④计算测试图像的Fisher特征矩阵与数据库中保存的各个Fisher特征矩阵之间的欧式距离,将数据库中与测试图像的Fisher特征矩阵距离最近的Fisher特征矩阵所对应的人脸图像判别为匹配图像,匹配图像对应的分类即为识别结果。</td>   <td>G06K9/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         彭斌斌;              胡杏;                   罗笑南       </td>   <td>中山大学</td>   <td>一种基于数字家庭的智能化个人着装设计系统</td>   <td>广东省</td>   <td>CN100409244C</td>   <td>2008-08-06</td>   <td>本发明公开了一种基于数字家庭的智能化服装款式设计系统,包括系统控制模块、服装数据库、规则数据库、数据库管理模块、推理机制模块、款式生成和保存模块、交互模块、用户接口、款式修改模块和款式显示模块,服装数据库、规则数据库、推理机制模块以及款式生成和保存模块与数据库管理模块连接并传输数据；用户接口、款式修改模块以及款式显示模块与交互模块连接并传输数据；交互模块连接数据库管理模块。本发明面向数字家庭,具有强大的数据收集和设计能力,提供全新的交互式服务。用户可根据自身的情况和喜好,结合个人及公共服装信息进行服装的选择和搭配,能够体现专属个人的着装风格,从而满足人们在日常工作生活中对自身形象设计的需求。</td>   <td>1. 一种基于数字家庭的智能化个人着装设计系统,其特征在于包括：系统控制模块,用于控制整个系统的进程,协调模块之间的关系,启动或调整各模块的运行；服装数据库,用于存储各类服装信息,包括典型款式库、用户款式库、款式部件库和配件库；规则数据库,用于存储服装变化规则集合,包括部件的智能拼接计划、部件曲线变化规则、相应部件的风格变化规则、整体款式配件调整规则和相应的款式风格变化规则；数据库管理模块,用于管理和协调各类数据库；推理机制模块,用于支持并通过数据库管理模块实现设计规则的使用以及外界条件和限制的判断推理；款式生成和保存模块,用于为款式的生成提供基本功能,包括曲线的调整拟合以实现部件的拼接,并对生成的款式进行保存；交互模块,用于提供用户与系统之间的交互界面和手段；用户接口,用于连接用户并通过交互模块实现与系统之间常用的输入输出功能；款式修改模块,用于编辑服装款式图样,使用户通过交互模块实现人机交互修改或自动修改；款式显示模块,用于通过交互模块向用户显示服装款式；所述服装数据库、规则数据库、推理机制模块以及款式生成和保存模块与数据库管理模块连接并传输数据；所述用户接口、款式修改模块以及款式显示模块与交互模块连接并传输数据；所述交互模块连接数据库管理模块。</td>   <td>G06F17/50;G06Q50/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         马识佳;                   罗笑南       </td>   <td>中山大学</td>   <td>一种基于网格的三维人脸识别方法</td>   <td>广东省</td>   <td>CN100409249C</td>   <td>2008-08-06</td>   <td>本发明公开了一种基于网格的三维人脸识别方法,具体来说,公开了一种利用三维图形处理技术来识别人脸的方法,它属于电子信息领域。该方法主要步骤包括：1)建立三维人脸图形数据库；2)目击人根据记忆绘制出所要查询人物的人脸的三维草图；3)根据草图形成人脸关键点的三维控制网格,利用网格形成三维人脸模型,将生成的人脸模型与人脸数据库中人脸数据进行比较,求出每个人脸数据的误差能量函数E；4)根据信息比较结果,利用E值将最相似的人检索出来。鉴于三维人脸模型的光照无关性和姿态无关性的特点,利用此方法可以提高识别率,正确反映出人脸的基本特性。</td>   <td>1. 一种基于网格的三维人脸识别方法,其特征在于其主要步骤包括：1)建立三维人脸图形数据库；2)目击人根据记忆绘制出所要查询人物的人脸的三维草图；3)根据草图形成人脸关键点的三维控制网格,利用网格形成三维人脸模型,将生成的人脸模型与人脸数据库中人脸数据进行比较,求出每个人脸数据的误差能量函数E,误差能量函数E计算过程包括：(1)由绘制的人脸简化图形生成三角网格M,数据库中将要比较的人脸图形网格为Q；(2)求出网格M中的每一点的极限位置；(3)然后对每一个极限位置P-(i)～(∞),搜索最近点q-(i)∈Q,求出误差能量函数,网格每一点极限位置的具体公式为：                                P      i      &amp;infin;        =          (      1      -      K&amp;chi;      )              P      i        +    &amp;chi;          &amp;Sigma;              j        &amp;Element;                  i          *                            P      j        -    -    -          (      1      )       ]]>                  其中,网格M中的点用P-(i)表示,i为点P的序号,P-(i)有若干个邻接点,j∈i～(*)表示P-(j)邻接于P-(i),P-(i)的极限位置用P-(i)～(∞)表示,K为邻接P-(i)的顶点个数,    &amp;chi;    =                  (                  3                      8            &amp;beta;                          +        K        )                    -        1              ,   ]]>    &amp;beta;    =                                                      3              16                                      (              K              =              3              )                                                                          1              K                                      (                              5                8                            -                                                (                                      3                    8                                    +                                      1                    4                                    cos                                                            2                      &amp;pi;                                        K                                    )                                2                            )                                      (              K              >              3              )                                            ;   ]]>4)根据信息比较结果,利用E值将最相似的人检索出来。</td>   <td>G06K9/00;G06F17/30</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘红梅;              饶俊慧;                   黄继武       </td>   <td>中山大学</td>   <td>一种基于图像特征的电子印章认证方法</td>   <td>广东省</td>   <td>CN100399353C</td>   <td>2008-07-02</td>   <td>一种基于图像特征的电子印章认证方法是将印章的图像特征和半脆弱水印相结合的电子印章认证方法,本发明对原始印章图像进行预处理,然后提取印章的特征作为水印嵌入到印章图像中。当印章需要认证时,通过提取水印,计算水印与待认证印章的特征之间的误差是否在可接受范围,从而确定印章是否是可信的。如果不可信,进一步确定恶意篡改的位置。本发明方法能够正确判断对印章的处理是恶意篡改还是正常的图像处理,并可以对篡改的位置精确定位,属于多媒体信号处理领域。本发明为电子印章认证提供了一种新的方法。</td>   <td>1.一种基于图像特征的电子印章认证方法,其特征是本发明的方法分为水印嵌入和印章认证两个过程；水印嵌入过程步骤如下：1)对原始印章进行预处理；2)提取原始印章的图像特征；3)预处理水印；4)结构化嵌入水印；印章认证过程步骤如下：1)抽取待认证的印章图像特征；2)重构原始印章的图像特征；3)对待认证印章进行认证；所述水印嵌入过程步骤1)对原始印章进行预处理采用如下公式：                                X      &amp;prime;        =                                        X                                0            &amp;le;            X            &amp;le;            T                                                T                                T            &lt;            X            &amp;le;            255                               ]]>                  其中,X表示原始印章图像像素值,X′是预处理后印章图像的像素值,T为预处理的阈值,取245；所述水印嵌入过程步骤3)预处理水印方法如下：设嵌入的水印比特序列W长度为N,通过密匙k  生成一个长度为N的0、1随机序列R,对水印序列W和随即序列R进行异或操作生成待嵌入的水印信息W～(*)。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         梁小萍;                   黄继武       </td>   <td>中山大学</td>   <td>一种用于图像认证的可逆水印方法</td>   <td>广东省</td>   <td>CN100394443C</td>   <td>2008-06-11</td>   <td>一种用于图像认证的可逆水印方法,属于多媒体信息安全领域。本发明通过修改高频子带直方图将原始图像的SHA-256哈希值和用于图像恢复的数据嵌入高频子带,通过替换低频子带的最低比特平面将有意义的水印嵌入低频子带,根据提取的水印或者提取的水印与原水印的差值图进行篡改检测与定位,比较提取的哈希值和恢复的图像的哈希值进行内容完整性验证。本发明可抵抗伪造攻击,检测篡改并定位,图像通过认证的同时可无失真恢复原始图像。</td>   <td>1.一种可抵抗伪造攻击、检测篡改并定位的用于图像认证的可逆水印方法,其特征是将用于内容完整性检验的原始图像的SHA-256哈希值和用于图像恢复的数据通过修改高频子带直方图嵌入到高频子带中,将用于篡改检测与定位的有意义的水印通过替换低频子带的最低比特平面嵌入到低频子带中,验证时用提取的水印或者水印的差值图像进行篡改检测与定位,用提取出来的SHA-256哈希值和恢复的图像的SHA-256哈希值进行比较以验证内容完整性。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         罗笑南;                   陈华鸿       </td>   <td>中山大学</td>   <td>一种基于四边形折叠的三维网格图形简化方法</td>   <td>广东省</td>   <td>CN100385464C</td>   <td>2008-04-30</td>   <td>本发明公开了一种基于四边形折叠的三维网格图形简化方法,包括步骤：①获取三维图形的网格信息数据；②检索出网格中所含的四边形；③确定折叠代价最小的四边形；④折叠化简。其特征是以三维网格中任意两个相连的三角形组合定义为进行一次折叠操作的四边形,且定义四边形折叠的操作为四边形的四个顶点收缩为一个新顶点,一次操作具有减少3个顶点6个三角形面片的高折叠效率；指定以除边界边以外的边来唯一对应和检索网格中所含的四边形,降低四边形检索或指代时的复杂度。本方法不仅可以简化复杂的三维图形数据降低对存储、显示、传输等方面的指标要求,而且与已有方法相比,具有更高的简化速度,是一种快速高效的三维网格图形简化方法。</td>   <td>1.一种基于四边形折叠的三维网格图形简化方法,包括步骤：①获取三维图形的网格信息数据；②定义并检索出网格中所含的四边形；③确定折叠代价最小的四边形；④折叠化简操作；其特征在于：以三维网格中任意两个相连的三角形组合定义为进行一次折叠操作的四边形,且定义四边形折叠的操作为四边形的四个顶点收缩为一个新顶点,一次操作具有减少3个顶点6个三角形面片的高折叠效率；指定以除边界边以外的边来唯一对应和检索网格中所含的四边形,降低四边形检索或指代时的复杂度；所述的确定折叠代价最小的四边形中采用二次误差度量来计算一个原有顶点进行移动折叠的代价,由于四边形折叠需要同时考虑4个顶点移动后造成的误差,本方法以进行折叠操作的四边形4个顶点的误差之和作为折叠代价；所述的折叠化简操作包括新顶点位置的确定,新顶点的位置可以有如下方法选择：(a)子集位置：即四边形四个顶点的其中一个顶点,子集位置不产生新顶点,需要存储及处理开销较小；(b)最佳位置：由折叠代价函数计算出其最小值作为折叠后的新顶点；如无解,则选取四边形的四个顶点或各边中点这9个位置中的一个作为新顶点的位置；所述的折叠化简操作中图形的边界方法为：在四边形的边界边上作一个通过该边界边并与该边界边所在的边界三角形垂直的平面a,在计算折叠代价时要考虑新顶点到平面a的距离,保证新顶点不会偏离边界,在含多边界边的特殊情况下,解决方案为同时考虑每条边界边的边界保护,即新顶点到多个新作的垂直平面的距离,对于含有三条边界边的四边形,需要同时考虑三个垂直平面以保护边界。</td>   <td>G06T15/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         康显桂;                   黄继武       </td>   <td>中山大学</td>   <td>采用图象几何校准和保护数字图象的方法</td>   <td>广东省</td>   <td>CN1321393C</td>   <td>2007-06-13</td>   <td>本发明涉及一种多媒体信号处理领域,是一种图象几何校准和保护数字图象的方法。经过扩频调制和交织后嵌入于图象DWT域中的信息水印由嵌入于图象DFT域的匹配模板和嵌入于图象DWT域的训练序列来实现重同步检测。在水印图象同时经过JPEG压缩和几何变形的情况下,仍然可实现有意义信息的无差错检测。本发明可使通过网络上传播的数字图象或视频数据获得保护。本发明中提出的图象几何校准方法还可用于其他需要图象同步的场合,如卫星成象、交互式数字地图、数字水印等。</td>   <td>1.一种图象几何校准和保护数字图象的方法,其特征是该方法首先将信息水印经扩频调制和交织后与一个训练序列一起嵌入到图象DWT域中,再将一个匹配模板嵌入到图象DFT域,最后由嵌入于图象DFT域的匹配模板和嵌入于图象DWT域的训练序列来实现扩频调制和交织后嵌入于图象DWT域中的信息水印的重同步检测,具体做法是：1)水印嵌入：水印嵌入过程主要有包括信息水印、训练序列的DWT域水印的预处理、DWT域水印的嵌入和DFT域摸板水印的嵌入三部分；i)DWT域水印的预处理：直接序列扩频编码、交织；应用长度为N-(1)的PN码序列m＝{m-(j)；j＝1,...,N-(1)}对要嵌入的信息b{b-(i)；i＝1,...,L}其中b-(i)∈{0,1},进行扩频编码调制；“1”调制为m的正相序列,即+1×m-(j)；j＝1,...,N-(1),“0”调制为m的反相序列,即{-1×m-(j)；j＝1,...,N-(1)},这样可得到待嵌入的二进制水印数据W；在一个与图象DWT低频子带相同大小的二维矩阵的中心行和中心列上或者图象中需要重点保护部分对应的低频子带部位存放由密钥产生的伪随机训练序列T,其余位置顺序存放交织后的二进制水印数据W,将得到的二维矩阵按行扫描变成一个一维数组,记为X；ii)DWT域水印的嵌入原始图象f(x,y)进行三级DWT分解,把低频子带LL-(3)系数按行扫描变成一维数组,记为C；按下列公式,我们把二进制数据X加到低频系数C上,得到新的低频系数C′：                  其中C(i)、C′(i)、x-(i)分别为C、C′、X的第i个元素；α表示水印嵌入强度；将嵌入水印后的小波系数进行IDWT得到嵌入DWT域水印的图象f′(x,y)；iii)DFT域模板的嵌入：在嵌入DWT域水印后图象f′(x,y)的DFT域,沿过原点的两条直线增大一些中频点处傅立叶系数的模值,使这些点成为局部区域的极大值；改变量以不可见为标准,一般取极大值为局部平均值加上几倍到十几倍左右的方差；这些嵌入的沿两条直线分布的局部极大值点构成一个模板,用作水印图象变形后的同步信息；这些模板点的位置可由一个密钥控制产生；这两条过原点的直线称为模板线；2)水印的检测：检测过程如下：a)在水印检测时,首先要应用训练序列检测水印是否同步；若不同步,则必须先将测试图象经过重同步得到同步图象g～(*)(x,y),重同步包括DFT域摸板水印检测、逆仿射变换、应用训练序列平移同步；若同步,直接做下一步；b)对同步图象g～(*)(x,y)作DWT域水印检测,得到了实际隐藏的数据；重同步的第一步是：恢复原始几何形状；从待测图象g(x,y)中检测出嵌入的模板水印,并将之与原始的嵌入模板进行对比获得图象所经受的仿射变换矩阵B；假设原始图象大小为M-(1)×M-(1),模板水印检测的步骤如下：a)对待测图象g(x,y)作Barlette滤波；b)同嵌入模板时一样,将滤波后的待测图象扩展至1024×1024；c)作DFT变换；以一个半径为R′的圆形窗口,在傅立叶系数幅度矩阵的上半平面中搜索,提取所有局部极大值点；把DFT系数幅度矩阵上半平面以原点为顶点划分为N-(b)个扇形区域,每个扇形的顶角均为0.5°或1°；再按角度将所有局部极大值点分别归入各个扇形区域；d)找到与两条模板线对应的可能的模板点集合；在每个扇形区域中,在K-(min)＜K＜K-(max)范围内搜索这样的K值：它使得此扇区中至少有N-(m)个局部极大值点满足                  |  r li  - K  r Tj &amp;prime;  | &lt; threshold ,    ]]>其中N-(m)为一个预先规定的数,r-(li)是扇区i中局部极值点的极径(i＝1...N-(b)),r-(Tj)′是原模板线j(j＝1,2)上摸板点的极径,threshold＞0为一阈值。如果找到这样的K值,我们就把相应的局部极值点坐标记录下来；通过上述步骤,得到可能的匹配线的集合,称为“准匹配线”,线上的局部极值点称为“准匹配点”,坐标记为(x-(ij),y-(ij))；图象上半平面相应的原始模板点的坐标记为(x-(ij)′,y-(ij)′),其中i∈{1,2}表示第i条模板匹配线,j ∈{1,2,Λ}表示第j个模板匹配点；从对应于模板线1的准匹配点集中取出一个集合和对应于模板线2的准匹配点集中取出另一个集合；根据这两个集合的点与原始模板点间的对应关系计算得到的一个可能的变换矩阵A；寻找平均误差MAE最小的4；                        MAE =  1 nummatches  | | A       x 11     y 11      M   M      x  1 j      y  1 j        x 21     y 21      M   M      x  2 j      y  2 j       T  -       x 11 &amp;prime;     y 11 &amp;prime;      M   M      x  1 j  &amp;prime;     x  1 j  &amp;prime;       x 21 &amp;prime;     y 21 &amp;prime;      M   M      x  2 j  &amp;prime;     y  2 j  &amp;prime;      T  | |    ]]>                            其中模板点为(x-(ij)′,y-(ij)′)和“准匹配点”为(x-(ij),y-(ij)),nummatches是匹配点个数,运算符||Λ||中是一个2行的误差矩阵；f)将对应于模板线1的准匹配点加上180°,重复e),由最小的MAE值确定最后的频域变换矩阵A；可得空域变换矩阵B＝A～(T)；获得仿射变换矩阵B后,将待测图象g(x,y)进行图象几何逆变换恢复成M×N大小的图象g′(x,y),然后再填充0成M-(1)×M-(1)大小的图象I(x,y),被裁剪的部分以0填充,g(x,y)在图象I(x,y)中心；重同步的第二步是：平移同步,即用抽取的训练序列S与原始训练序列T的相关系数来确定图象的平移同步参数；平移同步方法是将图象I(x,y)做最多8×8＝64次平移即可：I-(t)(x,y)＝I((x-x-(t))mod N-(2),(y-y-(t))mod N-(2))；{-4≤x-(t),y-(t)＜4}每平移一次,做DWT分解,获得LL-(3)子带LL-(3t)(x,y)；将LL-(3t)(x,y)作平移：                        L  L  3 t  &amp;prime;   ( x , y )  = L  L  3 t    (  ( x -  x  t 1   )  mod 64 ,  ( y -  y  t 1   )  mod 64 )  ;    ]]>                    {-T-(1)≤x-(t1)＜T-(1)；-T-(2)≤y-(t1)＜T-(2)}上式中,T-(1)＝round(0.5×(M-(1)-M)/8),T-(2)＝round(0.5×(M-(1)-N)/8),每次平移从LL-(3)′,(x,y)的中心行和中心列抽取训练序列S,根据与原始训练序列T间的最大相关值来确定平移参数,最多64次平移搜索后即可确定图象的平移参数(8×x-(t)+x-(t1),8×y-(t)+y-(t1)),从而获得平移校准后的同步图象g～(*)(x,y)；DWT域水印的检测：把同步图象g～(*)(x,y)DWT分解后的低频子带LL-(3)系数按行扫描变成一维数组,记为C～(*)；抽取出来的二进制数据记为X～(*)＝{x-(i)～(*)},抽取公式如下：                            x i *  = + 1 ,  (  C *   ( i )  mod &amp;alpha; )  &amp;GreaterEqual;  &amp;alpha; 2       x i *  = - 1 , otherwise       ]]>                            将抽取的二进制数据X～(*)进行反交织(交织的逆过程)恢复嵌入的二进制数据序列W～(*)；然后W～(*)按N-(1)位比特进行分段,每段与序列m进行相关,若相关值大于0,则判决嵌入信息比特为“1”,否则判决嵌入信息比特为“0”；解扩之后就得到恢复的嵌入信息。</td>   <td>G06T1/00</td>  </tr>        <tr>   <td>中国专利</td>   <td>         刘红梅;                   黄继武       </td>   <td>中山大学</td>   <td>一种基于特征的数字图象认证方法</td>   <td>广东省</td>   <td>CN1315091C</td>   <td>2007-05-09</td>   <td>一种基于特征的数字图像认证方法是基于内容的半脆弱水印的图像认证方法,本发明将原始图像的具有半脆弱特性的特征作为水印,以结构化的方法嵌入到图像中。当图像需要认证时,通过判断提取水印,即原始图像的特征与待认证图像的特征之间的误差是否在可接受范围,从而认证图像内容是否是可信的。本发明方法能够正确判断对图像的处理是恶意篡改还是正常的图像处理,并可以对篡改的位置精确定位,属于多媒体信号处理领域。本发明为数字图像认证提供了一种新的方法。</td>   <td>1、一种基于特征的数字图象认证方法,其特征是该方法分为水印嵌入和图象认证两个过程；图象认证时利用基于图象特征的半脆弱水印正确判断对图象的处理是恶意篡改还是正常的图象处理,并对篡改的位置精确定位；具体步骤是：水印嵌入过程如下：1)对原始图象进行3级2-D DWT,抽取DWT低频子带系数；2)将低频子带系数映射到0-255级灰度上,得到低频子带图；3)抽取低频子带图的边缘并进行二值化；4)在二值化图象上计算49个ZMM；5)将ZMM均匀量化为16位,并取最高4位有效位作为半脆弱水印；6)将半脆弱水印以结构化的方法嵌入到DWT的HL3子带中,即每个ZMM的4个高有效位以2×2的块的结构化形式嵌入；7)小波逆变换得到嵌入水印的图象；图象认证过程不需要原始图象,步骤如下：1)对待认证图象进行3级2-D DWT,抽取DWT低频子带系数；2)将低频子带系数映射到0-255级灰度上,得到低频子带图；3)抽取低频子带图的边缘并进行二值化；4)在二值化图象上计算49个ZMM,记做ZMM-A；5)提取HL3子带中的水印信息并将其转换为49个ZMM,记做ZMM-O；6)依次计算49个对应ZMM-A与ZMM-O的差的平方,并判断是否超过了设定的阈值,如果存在1个超过阈值,则认为该图象遭受过恶意攻击；7)根据结构化嵌入的位置确定受恶意篡改的位置。</td>   <td>G06K9/00</td>  </tr> </table></body></html>